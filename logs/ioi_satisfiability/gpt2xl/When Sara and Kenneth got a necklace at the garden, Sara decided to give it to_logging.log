[2024-07-24 10:29:29,040][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isWhen Sara and Kenneth got a necklace at the garden, Sara decided to give it to
[2024-07-24 10:29:29,040][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Kenneth
[2024-07-24 10:29:29,040][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:29:29,040][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:29:29,041][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:29:29,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,041][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:29:29,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:29:29,041][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:29:29,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,041][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:29:29,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21']
[2024-07-24 10:29:29,042][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:29:29,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit20', 'circuit26']
[2024-07-24 10:29:29,042][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:29:29,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,042][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:29:29,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,043][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:29:29,043][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,043][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:29:29,043][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,043][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:29:29,043][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,043][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:29:29,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,044][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:29:29,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,044][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:29:29,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,044][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:29:29,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit5', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,045][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:29:29,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:29:29,045][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:29:29,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,045][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:29:29,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,045][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:29:29,046][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit4', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,046][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:29:29,046][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,046][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:29:29,046][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,046][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:29:29,046][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,047][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:29:29,047][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,047][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:29:29,047][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit5', 'circuit6', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,047][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:29:29,047][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,047][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:29:29,048][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,048][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:29:29,048][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,048][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:29:29,048][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,048][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:29:29,048][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,049][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:29:29,049][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,049][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:29:29,049][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,049][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,049][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:29:29,049][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,050][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,050][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:29:29,050][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,050][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit7', 'circuit13', 'circuit18']
[2024-07-24 10:29:29,050][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:29:29,050][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:29:29,050][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,050][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:29:29,050][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit19', 'circuit21']
[2024-07-24 10:29:29,050][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,051][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:29:29,051][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:29:29,051][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,051][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:29:29,051][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20']
[2024-07-24 10:29:29,051][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,051][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:29:29,051][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,051][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit3', 'circuit17']
[2024-07-24 10:29:29,051][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:29:29,051][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit25']
[2024-07-24 10:29:29,051][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15']
[2024-07-24 10:29:29,051][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:29:29,051][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:29:29,052][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,052][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:29:29,052][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,052][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit7']
[2024-07-24 10:29:29,052][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:29:29,052][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,052][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,052][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:29:29,052][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,052][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,052][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:29:29,052][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,052][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,052][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:29:29,053][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,053][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,053][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:29:29,053][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit23']
[2024-07-24 10:29:29,053][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit20']
[2024-07-24 10:29:29,053][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:29:29,053][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:29:29,053][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,053][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:29:29,053][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,053][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit18']
[2024-07-24 10:29:29,053][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:29:29,053][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:29:29,053][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,054][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:29:29,054][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,054][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,054][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:29:29,054][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:29:29,054][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,054][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:29:29,054][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,054][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18']
[2024-07-24 10:29:29,054][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:29:29,054][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,054][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,054][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:29:29,054][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24']
[2024-07-24 10:29:29,055][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,055][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:29:29,055][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:29:29,055][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,055][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:29:29,055][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,055][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit9']
[2024-07-24 10:29:29,055][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:29:29,055][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,055][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,055][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:29:29,055][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,055][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,056][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:29:29,056][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,056][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,056][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:29:29,056][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,056][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,056][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,056][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:29:29,056][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,056][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,056][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,056][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:29:29,056][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,056][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:29:29,057][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:29:29,057][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:29:29,057][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,057][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:29:29,057][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit18', 'circuit20', 'circuit27']
[2024-07-24 10:29:29,057][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:29:29,057][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,057][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,057][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23']
[2024-07-24 10:29:29,057][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:29:29,057][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,057][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,057][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,057][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:29:29,058][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,058][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit7', 'circuit8', 'circuit14']
[2024-07-24 10:29:29,058][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit9', 'circuit14', 'circuit15', 'circuit22']
[2024-07-24 10:29:29,058][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:29:29,058][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,058][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit5', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,058][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,058][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:29:29,058][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:29:29,058][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,058][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,058][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:29:29,058][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,058][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,059][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23']
[2024-07-24 10:29:29,059][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:29:29,059][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:29:29,059][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,059][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,059][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:29:29,059][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit23']
[2024-07-24 10:29:29,059][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit23']
[2024-07-24 10:29:29,059][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,059][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:29:29,059][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,059][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,059][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,059][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:29:29,060][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,060][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,060][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,060][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:29:29,060][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:29:29,060][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit8', 'circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:29:29,060][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,060][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:29:29,060][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:29:29,060][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,060][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:29:29,060][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:29:29,060][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:29:29,061][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,061][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,061][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:29:29,061][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit22']
[2024-07-24 10:29:29,061][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,061][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,061][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:29:29,061][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,061][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,061][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:29:29,061][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:29:29,061][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,061][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,061][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,062][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:29:29,062][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,062][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit16', 'circuit26']
[2024-07-24 10:29:29,062][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,062][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:29:29,062][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24', 'circuit27']
[2024-07-24 10:29:29,062][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit25']
[2024-07-24 10:29:29,062][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,062][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:29:29,062][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit26']
[2024-07-24 10:29:29,062][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,062][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,062][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:29:29,062][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:29:29,063][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,063][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,063][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:29:29,063][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit14', 'circuit20', 'circuit23', 'circuit24', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,063][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit26']
[2024-07-24 10:29:29,063][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,063][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:29:29,063][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,063][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,063][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,063][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:29:29,063][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,063][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,063][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,064][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:29:29,064][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,064][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,064][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,064][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:29:29,064][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,064][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,064][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,064][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:29:29,064][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,064][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,064][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,064][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,065][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:29:29,065][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,065][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,065][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,065][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,065][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:29:29,065][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,065][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit6', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,065][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,065][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,065][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:29:29,065][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,065][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit8', 'circuit15', 'circuit17', 'circuit20', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,065][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:29:29,066][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,066][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:29:29,066][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,066][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,066][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,066][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,066][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:29:29,066][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,066][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,066][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,066][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,066][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:29:29,066][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,066][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:29:29,067][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,067][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,067][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:29:29,067][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:29:29,067][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,067][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit23', 'circuit26']
[2024-07-24 10:29:29,067][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,067][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:29:29,067][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit26']
[2024-07-24 10:29:29,067][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,067][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit26']
[2024-07-24 10:29:29,067][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit20', 'circuit22']
[2024-07-24 10:29:29,067][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:29:29,068][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,068][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,068][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit16', 'circuit18', 'circuit19', 'circuit26']
[2024-07-24 10:29:29,068][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit20', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,068][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:29:29,068][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,068][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit25']
[2024-07-24 10:29:29,068][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:29:29,068][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,068][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:29:29,068][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,068][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit16']
[2024-07-24 10:29:29,068][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit19']
[2024-07-24 10:29:29,068][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit13', 'circuit15', 'circuit16', 'circuit27']
[2024-07-24 10:29:29,069][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:29:29,069][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18']
[2024-07-24 10:29:29,069][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,069][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,069][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,069][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:29:29,069][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,069][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,069][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,069][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,069][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:29:29,069][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit12', 'circuit13']
[2024-07-24 10:29:29,069][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,069][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,070][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,070][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:29:29,070][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,070][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,070][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,070][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,070][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:29:29,070][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,070][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20']
[2024-07-24 10:29:29,070][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:29:29,070][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:29:29,070][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:29:29,070][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit27']
[2024-07-24 10:29:29,070][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:29:29,071][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,071][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,071][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:29:29,071][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,071][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit6', 'circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,071][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:29:29,071][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:29:29,071][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:29:29,071][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit21', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,071][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,071][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,071][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,071][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:29:29,072][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,072][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit27']
[2024-07-24 10:29:29,072][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:29:29,072][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15']
[2024-07-24 10:29:29,072][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:29:29,072][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:29:29,072][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,072][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,072][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit25']
[2024-07-24 10:29:29,072][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:29:29,072][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit8', 'circuit9', 'circuit10', 'circuit27']
[2024-07-24 10:29:29,072][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:29:29,072][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,072][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,073][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:29:29,073][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,073][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,073][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,073][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,073][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:29:29,073][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit27']
[2024-07-24 10:29:29,073][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,073][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:29:29,073][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,073][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:29:29,073][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,073][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,073][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,074][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,074][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:29:29,074][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,074][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,074][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,074][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,074][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:29:29,074][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,074][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,074][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,074][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,074][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:29:29,074][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,075][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,075][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,075][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,075][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:29:29,075][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,075][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,075][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,075][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,075][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,075][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:29:29,075][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,075][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:29:29,075][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,075][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit20', 'circuit21', 'circuit27']
[2024-07-24 10:29:29,076][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,076][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:29:29,076][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-24 10:29:29,076][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit25']
[2024-07-24 10:29:29,076][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,076][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit25']
[2024-07-24 10:29:29,076][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit24', 'circuit27']
[2024-07-24 10:29:29,076][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:29:29,076][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,076][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8', 'circuit9', 'circuit15', 'circuit16', 'circuit20', 'circuit26']
[2024-07-24 10:29:29,076][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,076][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit22']
[2024-07-24 10:29:29,076][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,076][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:29:29,077][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,077][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,077][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit21', 'circuit27']
[2024-07-24 10:29:29,077][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,077][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:29:29,077][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:29:29,077][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,077][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16']
[2024-07-24 10:29:29,077][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,077][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,077][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21']
[2024-07-24 10:29:29,077][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:29:29,077][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:29:29,078][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,078][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17']
[2024-07-24 10:29:29,078][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,078][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:29:29,078][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:29:29,078][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,078][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,078][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,078][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,078][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit21', 'circuit22']
[2024-07-24 10:29:29,078][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:29:29,078][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18', 'circuit19']
[2024-07-24 10:29:29,078][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18']
[2024-07-24 10:29:29,078][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,079][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit26']
[2024-07-24 10:29:29,079][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,079][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:29:29,079][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:29:29,079][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,079][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit24']
[2024-07-24 10:29:29,079][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,079][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:29:29,079][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:29:29,079][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,079][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,079][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit22', 'circuit23']
[2024-07-24 10:29:29,079][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25', 'circuit27']
[2024-07-24 10:29:29,079][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit1', 'circuit2', 'circuit11', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,080][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:29:29,080][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:29:29,080][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,080][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,080][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,080][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,080][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:29:29,080][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,080][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,080][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:29:29,080][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit25']
[2024-07-24 10:29:29,080][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,080][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:29:29,081][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,081][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,081][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,081][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,081][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,081][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:29:29,081][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,081][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,081][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,081][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,081][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,081][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:29:29,081][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,081][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,082][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,082][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,082][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,082][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:29:29,082][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,082][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,082][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,082][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,082][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,082][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:29:29,082][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,082][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,082][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,082][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,083][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,083][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:29:29,083][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,083][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,083][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,083][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,083][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,083][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:29:29,083][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,083][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,083][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,083][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,083][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,083][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:29:29,084][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,084][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,084][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,084][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,084][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,084][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:29:29,084][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,084][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,084][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,084][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,084][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,084][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:29:29,084][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,084][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,085][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,085][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,085][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,085][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:29:29,085][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,085][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,085][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,085][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,085][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,085][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:29:29,085][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,085][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,085][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,085][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,086][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,086][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:29:29,086][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,086][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,086][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,086][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,086][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,086][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:29:29,086][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,086][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,086][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,086][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,086][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,087][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:29:29,087][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,087][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,087][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,087][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,087][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,087][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:29:29,087][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,087][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,087][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,087][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,087][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,087][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:29:29,087][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,088][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,088][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,088][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,088][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,088][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,088][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:29:29,088][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,088][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit26']
[2024-07-24 10:29:29,088][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,088][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,088][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,088][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit19', 'circuit23']
[2024-07-24 10:29:29,088][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:29:29,089][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit15']
[2024-07-24 10:29:29,089][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,089][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,089][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,089][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,089][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,089][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:29:29,089][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,089][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,089][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,089][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit26']
[2024-07-24 10:29:29,089][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,089][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit1', 'circuit5', 'circuit6', 'circuit9', 'circuit14', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:29:29,089][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:29:29,090][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,090][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit8', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit26']
[2024-07-24 10:29:29,090][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:29:29,090][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,090][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,090][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,090][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:29:29,090][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,090][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,090][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:29:29,090][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit5', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,090][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:29:29,090][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,091][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:29:29,091][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,091][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit25']
[2024-07-24 10:29:29,091][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,091][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,091][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,091][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,091][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:29:29,091][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,091][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,091][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,091][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit8', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,091][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,091][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,092][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:29:29,092][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:29:29,092][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,092][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,092][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit26']
[2024-07-24 10:29:29,092][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,092][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,092][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:29:29,092][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit27']
[2024-07-24 10:29:29,092][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,092][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,092][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,092][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23']
[2024-07-24 10:29:29,093][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,093][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:29:29,093][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,093][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit24']
[2024-07-24 10:29:29,093][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,093][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,093][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21']
[2024-07-24 10:29:29,093][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,093][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:29:29,093][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,093][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,093][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,093][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,093][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,094][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,094][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:29:29,094][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit26']
[2024-07-24 10:29:29,094][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,094][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit20']
[2024-07-24 10:29:29,094][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit25']
[2024-07-24 10:29:29,094][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,094][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,094][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:29:29,094][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,094][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,094][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,094][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit6', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,095][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,095][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,095][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:29:29,095][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,095][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,095][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22']
[2024-07-24 10:29:29,095][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,095][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,095][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,095][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:29:29,095][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit24', 'circuit27']
[2024-07-24 10:29:29,095][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,095][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,095][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,096][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,096][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14']
[2024-07-24 10:29:29,096][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:29:29,096][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,096][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,096][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,096][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit27']
[2024-07-24 10:29:29,096][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit16', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,096][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit23']
[2024-07-24 10:29:29,096][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:29:29,096][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,096][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:29:29,096][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,096][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,097][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,097][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit26']
[2024-07-24 10:29:29,097][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:29:29,097][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit10', 'circuit20']
[2024-07-24 10:29:29,097][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,097][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,097][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,097][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,097][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,097][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:29:29,097][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,097][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,097][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,098][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16']
[2024-07-24 10:29:29,098][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,098][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,098][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:29:29,098][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,098][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,098][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,098][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,098][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,098][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,098][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:29:29,098][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,098][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit21', 'circuit24']
[2024-07-24 10:29:29,098][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,099][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,099][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,099][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,099][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:29:29,099][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:29:29,099][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,099][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,099][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,099][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit12', 'circuit27']
[2024-07-24 10:29:29,099][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:29:29,099][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:29:29,099][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,099][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6']
[2024-07-24 10:29:29,099][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,100][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,100][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,100][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,100][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:29:29,100][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit15', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,100][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit26']
[2024-07-24 10:29:29,100][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit26']
[2024-07-24 10:29:29,100][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,100][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17']
[2024-07-24 10:29:29,100][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,100][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:29:29,100][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,100][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit13', 'circuit14', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:29:29,100][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:29:29,101][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,101][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,101][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit13']
[2024-07-24 10:29:29,101][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:29:29,101][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,101][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,101][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,101][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,101][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,101][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,101][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:29:29,101][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,101][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,102][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,102][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,102][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,102][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,102][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:29:29,102][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,102][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,102][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,102][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,102][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,102][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,102][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:29:29,102][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,103][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,103][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,103][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,103][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,103][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,103][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,103][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:29:29,103][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:29:29,103][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:29:29,103][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,103][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,103][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,103][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,103][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,104][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:29:29,104][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,104][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,104][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,104][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,104][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,104][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,104][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,104][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:29:29,104][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,104][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,104][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:29:29,104][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,104][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,105][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,105][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:29:29,105][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:29:29,105][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,105][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit23', 'circuit25']
[2024-07-24 10:29:29,105][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,105][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,105][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit24']
[2024-07-24 10:29:29,105][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:29:29,105][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,105][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:29:29,105][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit22']
[2024-07-24 10:29:29,105][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,106][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,106][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit6', 'circuit11', 'circuit12']
[2024-07-24 10:29:29,106][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,106][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,106][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,106][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:29:29,106][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit20', 'circuit24']
[2024-07-24 10:29:29,106][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,106][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,106][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,106][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,106][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,106][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,106][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:29:29,107][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit20', 'circuit21', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,107][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,107][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,107][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,107][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,107][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit26']
[2024-07-24 10:29:29,107][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit17', 'circuit22']
[2024-07-24 10:29:29,107][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:29:29,107][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,107][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,107][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,107][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,107][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,107][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,108][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,108][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:29:29,108][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,108][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit8', 'circuit13', 'circuit26']
[2024-07-24 10:29:29,108][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,108][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,108][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,108][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,108][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,108][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:29:29,108][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,108][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,108][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,108][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,109][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,109][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,109][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit14', 'circuit26']
[2024-07-24 10:29:29,109][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:29:29,109][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,109][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,109][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,109][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,109][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,109][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,109][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,109][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:29:29,109][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18', 'circuit21']
[2024-07-24 10:29:29,109][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15']
[2024-07-24 10:29:29,110][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,110][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:29:29,110][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit26']
[2024-07-24 10:29:29,110][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,110][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,110][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:29:29,110][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,110][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,110][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,110][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,110][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,110][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,110][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,111][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:29:29,111][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,111][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,111][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,111][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,111][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,111][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,111][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,111][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:29:29,111][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,111][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,111][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,111][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,111][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,112][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,112][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,112][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:29:29,112][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,112][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,112][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,112][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,112][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,112][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,112][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,112][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:29:29,112][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,112][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,112][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,113][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,113][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,113][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,113][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,113][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:29:29,113][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:29:29,113][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,113][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,113][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,113][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,113][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,113][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,113][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:29:29,113][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,114][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,114][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,114][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,114][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,114][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,114][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,114][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:29:29,114][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,114][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,114][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,114][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,114][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,114][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,115][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,115][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:29:29,115][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,115][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,115][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,115][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,115][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,115][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,115][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,115][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:29:29,115][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,115][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,115][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,115][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,116][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,116][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,116][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,116][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:29:29,116][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,116][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,116][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,116][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,116][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,116][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,116][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,116][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:29:29,116][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,116][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,117][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,117][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,117][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,117][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,117][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,117][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:29:29,117][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,117][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,117][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,117][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,117][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,117][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,117][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,117][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:29:29,118][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,118][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,118][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,118][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,118][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,118][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,118][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,118][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:29:29,118][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,118][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,118][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,118][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,118][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,119][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,119][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,119][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:29:29,119][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,119][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,119][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,119][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,119][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,119][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,119][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,119][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:29:29,119][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,119][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,119][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,120][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,120][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,120][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,120][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,120][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,120][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:29:29,120][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,120][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:29:29,120][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,120][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,120][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,120][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,120][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,121][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:29:29,121][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:29:29,121][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:29:29,121][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:29:29,121][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit20', 'circuit26']
[2024-07-24 10:29:29,121][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,121][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,121][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,121][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,121][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,121][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:29:29,121][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,121][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:29:29,121][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,122][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:29:29,122][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit24', 'circuit27']
[2024-07-24 10:29:29,122][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:29:29,122][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24']
[2024-07-24 10:29:29,122][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit15', 'circuit17']
[2024-07-24 10:29:29,122][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:29:29,122][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit28']
[2024-07-24 10:29:29,122][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16']
[2024-07-24 10:29:29,122][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,122][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,122][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:29:29,122][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24']
[2024-07-24 10:29:29,122][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,122][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,123][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:29:29,123][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,123][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit23']
[2024-07-24 10:29:29,123][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,123][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,123][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:29:29,123][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit17']
[2024-07-24 10:29:29,123][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit19']
[2024-07-24 10:29:29,123][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit17', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,123][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:29:29,123][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:29:29,123][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:29:29,123][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,124][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,124][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,124][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,124][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,124][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,124][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:29:29,124][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit26']
[2024-07-24 10:29:29,124][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,124][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit19', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:29:29,124][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,124][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23']
[2024-07-24 10:29:29,124][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit20', 'circuit23', 'circuit25']
[2024-07-24 10:29:29,124][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,124][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,125][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:29:29,125][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,125][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17']
[2024-07-24 10:29:29,125][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,125][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,125][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,125][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,125][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,125][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,125][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:29:29,125][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,125][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,125][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,125][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit25']
[2024-07-24 10:29:29,126][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit17', 'circuit21']
[2024-07-24 10:29:29,126][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,126][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,126][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,126][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:29:29,126][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit15', 'circuit16', 'circuit21', 'circuit25']
[2024-07-24 10:29:29,126][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit8', 'circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:29:29,126][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,126][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,126][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,126][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,126][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit14']
[2024-07-24 10:29:29,126][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,126][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:29:29,127][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit22', 'circuit23']
[2024-07-24 10:29:29,127][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,127][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,127][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,127][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,127][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,127][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,127][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,127][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:29:29,127][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:29:29,127][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,127][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,127][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,128][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,128][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,128][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,128][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,128][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:29:29,128][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,128][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,128][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,128][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit6', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,128][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,128][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,128][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,128][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,128][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:29:29,129][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,129][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,129][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:29:29,129][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,129][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,129][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,129][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,129][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,129][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:29:29,129][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,129][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,129][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,129][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,129][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,130][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit18']
[2024-07-24 10:29:29,130][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,130][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,130][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:29:29,130][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,130][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit6', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,130][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,130][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,130][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,130][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,130][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,130][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit5', 'circuit12', 'circuit21', 'circuit27']
[2024-07-24 10:29:29,130][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:29:29,131][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit27']
[2024-07-24 10:29:29,131][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,131][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,131][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,131][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,131][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,131][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,131][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,131][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:29:29,131][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit24']
[2024-07-24 10:29:29,131][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,131][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,131][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,131][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,132][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,132][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,132][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,132][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:29:29,132][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,132][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,132][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,132][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,132][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,132][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,132][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,132][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,132][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:29:29,132][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,133][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,133][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,133][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,133][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,133][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,133][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,133][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,133][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:29:29,133][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,133][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,133][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,133][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,133][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,133][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,134][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,134][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,134][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:29:29,134][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,134][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,134][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,134][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,134][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,134][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,134][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,134][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,134][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:29:29,134][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,135][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:29:29,135][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,135][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,135][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,135][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,135][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,135][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,135][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:29:29,135][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,135][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,135][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,135][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,135][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,135][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,136][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,136][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,136][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:29:29,136][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,136][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,136][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,136][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,136][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,136][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,136][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,136][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,136][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:29:29,136][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,136][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,137][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,137][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,137][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,137][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,137][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,137][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,137][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:29:29,137][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,137][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,137][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,137][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,137][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,137][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,138][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,138][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,138][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:29:29,138][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,138][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,138][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,138][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,138][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,138][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,138][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,138][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,138][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:29:29,138][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,139][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,139][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,139][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,139][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,139][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,139][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,139][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,139][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,139][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:29:29,139][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit28']
[2024-07-24 10:29:29,139][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit24']
[2024-07-24 10:29:29,139][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,139][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:29:29,139][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:29:29,140][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:29:29,140][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit17', 'circuit21']
[2024-07-24 10:29:29,140][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit15', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:29:29,140][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit23']
[2024-07-24 10:29:29,140][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:29:29,140][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22', 'circuit27']
[2024-07-24 10:29:29,140][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit17']
[2024-07-24 10:29:29,140][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,140][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:29:29,140][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit19', 'circuit21', 'circuit22']
[2024-07-24 10:29:29,140][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit18', 'circuit19', 'circuit21']
[2024-07-24 10:29:29,140][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,140][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,140][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,141][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:29:29,141][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit22']
[2024-07-24 10:29:29,141][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,141][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,141][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,141][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,141][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,141][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,141][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,141][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,141][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:29:29,141][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,141][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,142][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,142][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,142][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,142][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,142][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,142][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,142][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,142][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:29:29,142][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,142][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,142][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit5', 'circuit6', 'circuit12']
[2024-07-24 10:29:29,142][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit12']
[2024-07-24 10:29:29,142][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:29:29,142][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit5', 'circuit14', 'circuit17', 'circuit19', 'circuit26']
[2024-07-24 10:29:29,143][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit17']
[2024-07-24 10:29:29,143][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,143][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,143][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:29:29,143][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,143][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit25']
[2024-07-24 10:29:29,143][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,143][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:29:29,143][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,143][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,143][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,143][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,143][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,143][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:29:29,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,144][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,144][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:29:29,144][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,144][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit24']
[2024-07-24 10:29:29,144][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,144][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,144][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,144][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,144][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:29:29,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,144][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,144][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23']
[2024-07-24 10:29:29,144][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,145][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,145][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,145][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,145][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,145][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,145][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:29:29,145][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:29:29,145][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,145][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,145][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,145][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,145][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,145][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,146][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,146][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,146][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:29:29,146][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,146][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,146][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit26']
[2024-07-24 10:29:29,146][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit19']
[2024-07-24 10:29:29,146][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit18', 'circuit19']
[2024-07-24 10:29:29,146][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:29:29,146][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,146][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,146][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,146][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:29:29,146][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,147][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,147][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,147][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,147][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,147][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,147][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,147][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,147][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,147][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:29:29,147][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:29:29,147][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit19', 'circuit25']
[2024-07-24 10:29:29,147][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,147][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,147][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,148][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,148][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,148][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,148][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,148][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:29:29,148][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,148][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit6', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,148][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit5', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,148][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,148][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit18']
[2024-07-24 10:29:29,148][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit18', 'circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:29:29,148][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit11', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,148][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit14', 'circuit15', 'circuit18', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,149][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,149][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:29:29,149][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit24']
[2024-07-24 10:29:29,149][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,149][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,149][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,149][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,149][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,149][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,149][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,149][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,149][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:29:29,149][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:29:29,149][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,150][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,150][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,150][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,150][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,150][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,150][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,150][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit5']
[2024-07-24 10:29:29,150][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:29:29,150][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,150][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,150][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit22', 'circuit25']
[2024-07-24 10:29:29,150][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,150][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,150][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit25']
[2024-07-24 10:29:29,151][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24']
[2024-07-24 10:29:29,151][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,151][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit19', 'circuit22', 'circuit23']
[2024-07-24 10:29:29,151][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:29:29,151][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,151][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,151][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,151][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,151][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,151][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,151][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,151][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,151][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,151][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:29:29,152][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,152][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,152][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:29:29,152][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21']
[2024-07-24 10:29:29,152][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,152][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,152][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,152][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit17', 'circuit19', 'circuit20']
[2024-07-24 10:29:29,152][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,152][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:29:29,152][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,152][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,152][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,153][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,153][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,153][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,153][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:29:29,153][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,153][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,153][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:29:29,153][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,153][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,153][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,153][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,153][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,153][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,153][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:29:29,154][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,154][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,154][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:29:29,154][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,154][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,154][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,154][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,154][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,154][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,154][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,154][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,154][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,154][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:29:29,154][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,155][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,155][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,155][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,155][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,155][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,155][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,155][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,155][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,155][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:29:29,155][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,155][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,155][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,155][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,155][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,156][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,156][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,156][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,156][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,156][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:29:29,156][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,156][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,156][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,156][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,156][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,156][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,156][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,156][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,156][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,157][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:29:29,157][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,157][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,157][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,157][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,157][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,157][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,157][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,157][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,157][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,157][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:29:29,157][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,157][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,157][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,158][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,158][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,158][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,158][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,158][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,158][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,158][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:29:29,158][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,158][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,158][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,158][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,158][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,158][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,159][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,159][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,159][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,159][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:29:29,159][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,159][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,159][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,159][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,159][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,159][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,159][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,159][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,159][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,159][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:29:29,160][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,160][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,160][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,160][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,160][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit6', 'circuit7', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,160][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit10', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit26']
[2024-07-24 10:29:29,160][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,160][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,160][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,160][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,160][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:29:29,160][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:29:29,160][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,161][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:29:29,161][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,161][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:29:29,161][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,161][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,161][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,161][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,161][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,161][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:29:29,161][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,161][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,161][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit27']
[2024-07-24 10:29:29,161][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,161][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,162][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,162][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,162][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,162][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit10']
[2024-07-24 10:29:29,162][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,162][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:29:29,162][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15']
[2024-07-24 10:29:29,162][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,162][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,162][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,162][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,162][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,162][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,162][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit14', 'circuit18']
[2024-07-24 10:29:29,163][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,163][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,163][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:29:29,163][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,163][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,163][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,163][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,163][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,163][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,163][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,163][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,163][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,163][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,163][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:29:29,164][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,164][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,164][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,164][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,164][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,164][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,164][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,164][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,164][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,164][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,164][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:29:29,164][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,164][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,165][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,165][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,165][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,165][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,165][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,165][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,165][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,165][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit27']
[2024-07-24 10:29:29,165][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:29:29,165][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit15', 'circuit18']
[2024-07-24 10:29:29,165][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:29:29,165][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:29:29,165][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit27']
[2024-07-24 10:29:29,165][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit18']
[2024-07-24 10:29:29,166][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13']
[2024-07-24 10:29:29,166][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,166][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit15', 'circuit21']
[2024-07-24 10:29:29,166][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,166][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,166][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:29:29,166][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:29,166][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,166][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,166][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22']
[2024-07-24 10:29:29,166][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,166][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,166][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,166][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,167][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,167][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:29:29,167][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:29:29,167][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,167][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,167][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,167][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,167][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,167][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,167][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,167][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,167][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,167][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,167][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:29:29,168][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,168][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,168][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,168][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,168][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,168][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,168][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,168][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,168][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,168][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,168][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:29:29,168][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24']
[2024-07-24 10:29:29,168][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,169][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,169][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18']
[2024-07-24 10:29:29,169][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,169][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,169][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit20', 'circuit24']
[2024-07-24 10:29:29,169][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,169][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,169][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,169][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:29:29,169][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,169][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,169][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,169][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,169][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,170][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,170][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,170][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,170][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,170][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,170][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:29:29,170][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,170][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,170][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,170][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:29:29,170][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:29:29,170][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23']
[2024-07-24 10:29:29,170][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,170][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,171][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit23']
[2024-07-24 10:29:29,171][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,171][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:29:29,171][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,171][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,171][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,171][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,171][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,171][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,171][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,171][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,171][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,171][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,171][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:29:29,172][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,172][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,172][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,172][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,172][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,172][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,172][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,172][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,172][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,172][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,172][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:29:29,172][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,172][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,173][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,173][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,173][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,173][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,173][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,173][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,173][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,173][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,173][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:29:29,173][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,173][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,173][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,173][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,173][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,174][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,174][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,174][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,174][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,174][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,174][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:29:29,174][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,174][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,174][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,174][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,174][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,174][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,174][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,174][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,175][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,175][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,175][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:29:29,175][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,175][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,175][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,175][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,175][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,175][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,175][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,175][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,175][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,175][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,175][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:29:29,176][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,176][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,176][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,176][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,176][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,176][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,176][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,176][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,176][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,176][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,176][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:29:29,176][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,176][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,176][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,177][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,177][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,177][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,177][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,177][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,177][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,177][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,177][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:29:29,177][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,177][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,177][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,177][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,177][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,177][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,178][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,178][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,178][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,178][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,178][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:29:29,178][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,178][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,178][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,178][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,178][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,178][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,178][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,178][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,179][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,179][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,179][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:29:29,179][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,179][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,179][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,179][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,179][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,179][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,179][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,179][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,179][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,179][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,179][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:29:29,180][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,180][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,180][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,180][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,180][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,180][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,180][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,180][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,180][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,180][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,180][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:29:29,180][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,180][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,180][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,181][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,181][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,181][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,181][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,181][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,181][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,181][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,181][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:29:29,181][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,181][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,181][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,181][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,181][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,182][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,182][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,182][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,182][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,182][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,182][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:29:29,182][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,182][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,182][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,182][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,182][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,182][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,182][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,183][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,183][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,183][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,183][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:29:29,183][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:29,183][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit3', 'circuit14', 'circuit18', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,183][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:29:29,183][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit6', 'circuit11', 'circuit14', 'circuit19', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:29:29,183][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:29:29,183][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit19', 'circuit27']
[2024-07-24 10:29:29,183][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit22', 'circuit23']
[2024-07-24 10:29:29,183][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit8', 'circuit13', 'circuit27']
[2024-07-24 10:29:29,183][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:29,184][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:29:29,184][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit7', 'circuit12', 'circuit13', 'circuit14', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:29,184][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:29:29,184][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,184][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,184][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,184][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,184][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,184][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,184][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,184][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,184][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,184][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,184][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:29,185][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:29:29,185][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,185][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,185][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,185][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,185][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,185][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,185][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,185][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,185][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,185][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,185][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:29,185][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:29:29,185][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,186][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,186][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,186][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,186][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,186][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,186][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,186][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,186][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,186][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,186][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:29,186][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:29:29,186][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,186][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,186][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,187][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,187][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,187][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,187][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,187][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,187][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,187][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,187][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:29,187][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:29:29,187][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,187][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,187][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,187][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,188][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,188][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,188][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,188][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,188][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,188][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,188][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:29,188][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:29:29,188][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,188][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,188][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,188][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,188][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,188][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,189][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,189][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,189][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,189][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,189][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:29,189][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:29:29,189][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,189][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,189][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,189][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,189][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,189][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,189][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,189][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,190][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,190][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,190][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:29,190][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:29:29,190][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,190][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,190][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,190][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,190][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,190][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,190][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,190][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,190][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,190][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,191][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:29,191][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:29:29,191][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,191][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit26']
[2024-07-24 10:29:29,191][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit20', 'circuit23']
[2024-07-24 10:29:29,191][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,191][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,191][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,191][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,191][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,191][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,191][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,191][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit19']
[2024-07-24 10:29:29,192][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:29:29,192][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,192][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,192][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,192][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,192][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,192][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,192][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,192][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,192][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,192][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,192][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:29,192][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:29:29,192][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,193][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,193][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,193][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,193][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,193][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,193][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,193][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,193][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,193][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,193][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:29,193][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:29:29,193][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,193][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,193][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,194][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,194][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,194][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,194][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,194][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,194][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,194][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,194][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:29,194][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:29:29,194][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,194][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit24']
[2024-07-24 10:29:29,194][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,194][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,194][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,195][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,195][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,195][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,195][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,195][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:29:29,195][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:29,195][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:29:29,195][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,195][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,195][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,195][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,195][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,195][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,196][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,196][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,196][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,196][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,196][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:29,196][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:29:29,196][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,196][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,196][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,196][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,196][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,196][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,196][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,196][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,197][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,197][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,197][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:29,197][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:29:29,197][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,197][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,197][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,197][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,197][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,197][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,197][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,197][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,197][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,197][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,198][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:29,198][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:29:29,198][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,198][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,198][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,198][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,198][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,198][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,198][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,198][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,198][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,198][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,198][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:29,198][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:29:29,199][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,199][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,199][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,199][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,199][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,199][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,199][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,199][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,199][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,199][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,199][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:29,199][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:29:29,199][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,200][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,200][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,200][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,200][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,200][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,200][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,200][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,200][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,200][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,200][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:29,200][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:29:29,200][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,200][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,200][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,201][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,201][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,201][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,201][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,201][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,201][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,201][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,201][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:29,201][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:29:29,201][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,201][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,201][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,201][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,201][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,202][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,202][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,202][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,202][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,202][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,202][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:29,202][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:29:29,202][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,202][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,202][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,202][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,202][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,202][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,202][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,203][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,203][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,203][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,203][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:29,203][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:29:29,203][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,203][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,203][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,203][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,203][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,203][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,203][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,203][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,204][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,204][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,204][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:29,204][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:29:29,204][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,204][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,204][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,204][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,204][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,204][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,204][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,204][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,204][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,204][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,205][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:29,205][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:29:29,205][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:29,205][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:29,205][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:29,205][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:29,205][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:29,205][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:29,205][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:29,205][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:29,205][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:29,205][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:29,205][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:29,205][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:29:29,206][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,206][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,206][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,206][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,206][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,206][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,206][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,206][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,206][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,206][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,206][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,206][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:29:29,206][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,207][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,207][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,207][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,207][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,207][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,207][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,207][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,207][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,207][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,207][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,207][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:29:29,207][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,207][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,208][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,208][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,208][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,208][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,208][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,208][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,208][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,208][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:29,208][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:30,753][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:30,755][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:30,756][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:30,757][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:30,758][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:30,759][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:30,759][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:30,760][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:30,761][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:30,762][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:30,762][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:30,763][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:30,764][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:30,765][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Sara] are: tensor([0.7584, 0.2416], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:30,767][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Sara] are: tensor([4.7536e-05, 9.9995e-01], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:30,768][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Sara] are: tensor([0.8806, 0.1194], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:30,769][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Sara] are: tensor([0.0852, 0.9148], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:30,770][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Sara] are: tensor([0.1404, 0.8596], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:30,770][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Sara] are: tensor([0.0080, 0.9920], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:30,771][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Sara] are: tensor([0.7861, 0.2139], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:30,772][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Sara] are: tensor([0.9804, 0.0196], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:30,773][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Sara] are: tensor([0.8561, 0.1439], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:30,775][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Sara] are: tensor([0.9613, 0.0387], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:30,777][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Sara] are: tensor([0.7000, 0.3000], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:30,778][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Sara] are: tensor([0.6791, 0.3209], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:30,780][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.7898, 0.1496, 0.0605], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:30,782][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0042, 0.0010, 0.9947], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:30,783][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4043, 0.0515, 0.5442], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:30,785][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2550, 0.0572, 0.6877], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:30,786][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.5896, 0.2263, 0.1841], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:30,788][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2150, 0.0195, 0.7655], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:30,789][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6616, 0.3103, 0.0281], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:30,790][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.4689, 0.3080, 0.2231], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:30,790][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2523, 0.0329, 0.7147], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:30,791][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.6074, 0.1366, 0.2560], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:30,792][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.6547, 0.0927, 0.2526], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:30,793][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.5495, 0.1005, 0.3500], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:30,795][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Kenneth] are: tensor([0.4316, 0.0433, 0.2869, 0.2383], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:30,796][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Kenneth] are: tensor([1.6544e-04, 2.3240e-04, 2.2058e-04, 9.9938e-01], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:30,798][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Kenneth] are: tensor([0.6618, 0.1222, 0.1665, 0.0495], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:30,799][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Kenneth] are: tensor([7.9074e-03, 5.3956e-03, 6.6592e-05, 9.8663e-01], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:30,800][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Kenneth] are: tensor([0.0656, 0.0797, 0.0028, 0.8519], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:30,801][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Kenneth] are: tensor([6.6617e-04, 5.2427e-06, 2.5613e-09, 9.9933e-01], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:30,802][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Kenneth] are: tensor([0.3988, 0.1529, 0.2279, 0.2204], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:30,803][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Kenneth] are: tensor([0.2731, 0.3801, 0.2349, 0.1119], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:30,804][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Kenneth] are: tensor([0.4659, 0.1980, 0.2028, 0.1332], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:30,805][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Kenneth] are: tensor([0.5200, 0.2260, 0.2280, 0.0260], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:30,807][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Kenneth] are: tensor([0.4598, 0.0889, 0.1698, 0.2814], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:30,808][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Kenneth] are: tensor([0.2770, 0.1639, 0.3421, 0.2169], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:30,810][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.4957, 0.1215, 0.1125, 0.0496, 0.2207], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:30,811][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ got] are: tensor([4.9857e-04, 1.4738e-03, 9.1694e-04, 1.0304e-03, 9.9608e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:30,813][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.5657, 0.0638, 0.1904, 0.0539, 0.1261], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:30,814][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.0569, 0.0067, 0.0130, 0.0100, 0.9133], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:30,816][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.3736, 0.0617, 0.0451, 0.0452, 0.4744], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:30,817][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ got] are: tensor([1.2117e-02, 7.8094e-04, 9.5136e-05, 1.4329e-04, 9.8686e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:30,819][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.2860, 0.2664, 0.0336, 0.3400, 0.0740], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:30,820][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.3127, 0.0488, 0.2580, 0.1145, 0.2659], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:30,822][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.3576, 0.0938, 0.3506, 0.0958, 0.1023], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:30,823][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.4357, 0.1125, 0.2332, 0.1009, 0.1177], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:30,825][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.3810, 0.0890, 0.1941, 0.0643, 0.2716], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:30,827][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.4311, 0.0932, 0.2087, 0.1655, 0.1015], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:30,828][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.4686, 0.1958, 0.0455, 0.1165, 0.1401, 0.0334], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:30,828][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([3.4084e-03, 1.5734e-03, 6.0583e-03, 6.4141e-04, 1.3907e-03, 9.8693e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:30,829][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.4181, 0.0773, 0.2435, 0.0970, 0.1137, 0.0503], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:30,830][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0718, 0.0114, 0.0389, 0.0151, 0.1019, 0.7609], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:30,832][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2041, 0.0490, 0.0400, 0.0786, 0.4540, 0.1743], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:30,833][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1222, 0.0154, 0.1335, 0.0022, 0.0324, 0.6944], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:30,835][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2574, 0.3102, 0.0110, 0.2659, 0.1441, 0.0114], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:30,836][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1629, 0.0696, 0.1275, 0.1451, 0.2176, 0.2772], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:30,838][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0525, 0.0099, 0.2293, 0.0163, 0.0567, 0.6353], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:30,839][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.3697, 0.0977, 0.2035, 0.0846, 0.0946, 0.1498], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:30,841][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.3437, 0.0935, 0.2028, 0.0572, 0.0652, 0.2376], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:30,843][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.3305, 0.0925, 0.1677, 0.1670, 0.1164, 0.1258], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:30,845][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.3195, 0.0762, 0.2876, 0.0694, 0.0792, 0.1147, 0.0534],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:30,846][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([2.1729e-04, 9.2686e-03, 3.9276e-04, 5.4683e-04, 6.4152e-04, 2.1239e-04,
        9.8872e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:30,847][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.4098, 0.0640, 0.1541, 0.0898, 0.1207, 0.1307, 0.0308],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:30,849][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([6.8436e-03, 1.5427e-03, 1.9885e-05, 1.6455e-03, 8.8786e-04, 1.2616e-04,
        9.8893e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:30,850][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.0692, 0.0062, 0.0017, 0.0059, 0.0143, 0.0036, 0.8991],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:30,851][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([3.0910e-05, 3.3711e-05, 2.4235e-09, 1.1390e-07, 1.9881e-08, 3.9286e-10,
        9.9994e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:30,853][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.2130, 0.1501, 0.1344, 0.2333, 0.0223, 0.1050, 0.1418],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:30,855][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.1400, 0.0092, 0.1414, 0.0237, 0.2664, 0.3564, 0.0631],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:30,856][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.2944, 0.0697, 0.0980, 0.1001, 0.0842, 0.0769, 0.2767],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:30,858][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.3699, 0.1484, 0.1697, 0.0714, 0.0978, 0.1298, 0.0130],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:30,860][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.2641, 0.1269, 0.1589, 0.0502, 0.0749, 0.0812, 0.2439],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:30,861][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.1578, 0.0955, 0.1540, 0.1153, 0.1425, 0.1874, 0.1475],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:30,862][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.2750, 0.0969, 0.0448, 0.0997, 0.1644, 0.0626, 0.2281, 0.0286],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:30,862][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ at] are: tensor([1.6177e-03, 1.1898e-03, 5.4861e-03, 3.1507e-04, 1.2732e-04, 1.8803e-03,
        5.3727e-05, 9.8933e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:30,863][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.3234, 0.0601, 0.1700, 0.0727, 0.1298, 0.0603, 0.0396, 0.1440],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:30,864][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ at] are: tensor([3.9982e-03, 1.2200e-04, 2.7515e-03, 2.1192e-03, 1.2682e-02, 3.7453e-02,
        2.9611e-02, 9.1126e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:30,866][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.1271, 0.0151, 0.0193, 0.0317, 0.1891, 0.0740, 0.2416, 0.3021],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:30,867][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ at] are: tensor([7.7357e-02, 2.6834e-03, 1.4687e-02, 6.9675e-03, 7.9418e-03, 1.8343e-02,
        5.9119e-04, 8.7143e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:30,869][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.1369, 0.1929, 0.0155, 0.2656, 0.0880, 0.0183, 0.2628, 0.0201],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:30,870][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0889, 0.0207, 0.0579, 0.0486, 0.1051, 0.2094, 0.1437, 0.3256],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:30,872][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0631, 0.0125, 0.3105, 0.0150, 0.0670, 0.3364, 0.0333, 0.1623],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:30,874][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.2720, 0.0889, 0.1706, 0.0602, 0.0885, 0.1286, 0.0528, 0.1384],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:30,875][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.2329, 0.0741, 0.1732, 0.0557, 0.0575, 0.1235, 0.0292, 0.2539],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:30,877][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.2993, 0.0651, 0.1158, 0.1127, 0.0724, 0.0611, 0.1243, 0.1493],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:30,879][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.3812, 0.0815, 0.0270, 0.1155, 0.0939, 0.0216, 0.2347, 0.0208, 0.0238],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:30,880][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ the] are: tensor([9.2933e-03, 8.7866e-04, 5.7350e-02, 9.2113e-04, 1.7149e-04, 4.4567e-02,
        3.6158e-05, 5.6566e-02, 8.3022e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:30,882][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.3023, 0.0508, 0.1311, 0.0793, 0.1282, 0.0384, 0.0325, 0.2006, 0.0368],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:30,883][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0288, 0.0027, 0.0062, 0.0040, 0.0169, 0.0716, 0.0224, 0.1898, 0.6577],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:30,885][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1849, 0.0339, 0.0250, 0.0361, 0.1332, 0.0577, 0.1693, 0.1982, 0.1617],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:30,887][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1264, 0.0331, 0.1217, 0.0089, 0.0594, 0.2341, 0.0036, 0.0743, 0.3383],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:30,888][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1475, 0.2589, 0.0038, 0.2451, 0.0670, 0.0039, 0.2647, 0.0067, 0.0023],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:30,890][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0739, 0.0144, 0.0323, 0.0402, 0.0549, 0.0847, 0.1358, 0.2775, 0.2862],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:30,892][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0197, 0.0048, 0.1382, 0.0090, 0.0294, 0.3249, 0.0113, 0.0643, 0.3984],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:30,894][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.2665, 0.0719, 0.1371, 0.0689, 0.0747, 0.1028, 0.0493, 0.1163, 0.1124],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:30,895][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.2820, 0.0608, 0.1490, 0.0570, 0.0459, 0.1333, 0.0192, 0.0859, 0.1669],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:30,897][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.2032, 0.0670, 0.0973, 0.1268, 0.0664, 0.1013, 0.1306, 0.0960, 0.1115],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:30,899][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ garden] are: tensor([0.2465, 0.1133, 0.1248, 0.0503, 0.0402, 0.1045, 0.0706, 0.0987, 0.1029,
        0.0482], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:30,900][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ garden] are: tensor([2.7473e-04, 1.2956e-03, 1.0363e-04, 1.7042e-03, 5.7562e-04, 6.0919e-05,
        7.7071e-04, 5.3638e-05, 7.1313e-05, 9.9509e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:30,901][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ garden] are: tensor([0.2920, 0.0600, 0.1019, 0.0436, 0.0487, 0.1126, 0.0669, 0.1114, 0.1128,
        0.0501], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:30,902][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ garden] are: tensor([3.0342e-03, 1.0220e-04, 1.3734e-05, 2.8445e-04, 1.6372e-04, 5.5295e-05,
        2.3290e-03, 5.4463e-04, 3.7922e-04, 9.9309e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:30,902][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ garden] are: tensor([0.0182, 0.0961, 0.0018, 0.0137, 0.0144, 0.0040, 0.1100, 0.0110, 0.0114,
        0.7193], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:30,904][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ garden] are: tensor([4.4013e-03, 8.9074e-04, 3.2102e-06, 1.0579e-04, 1.2360e-06, 5.1084e-07,
        1.8786e-04, 2.9611e-07, 4.3041e-07, 9.9441e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:30,905][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ garden] are: tensor([0.1844, 0.1100, 0.0567, 0.2189, 0.0218, 0.0487, 0.1705, 0.0261, 0.0456,
        0.1172], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:30,907][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ garden] are: tensor([0.0598, 0.0175, 0.0293, 0.0015, 0.0502, 0.1094, 0.2628, 0.1578, 0.2884,
        0.0233], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:30,909][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ garden] are: tensor([0.3647, 0.0802, 0.1011, 0.0396, 0.0445, 0.0814, 0.0254, 0.0628, 0.0800,
        0.1203], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:30,911][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ garden] are: tensor([0.2795, 0.0633, 0.1136, 0.0906, 0.0599, 0.1009, 0.0825, 0.0846, 0.1062,
        0.0189], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:30,912][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ garden] are: tensor([0.2132, 0.0594, 0.1197, 0.0638, 0.0414, 0.0804, 0.0388, 0.0528, 0.0641,
        0.2664], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:30,914][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ garden] are: tensor([0.2526, 0.0852, 0.0812, 0.0965, 0.0536, 0.0426, 0.1268, 0.1255, 0.0429,
        0.0931], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:30,916][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3486, 0.0651, 0.0128, 0.0759, 0.0904, 0.0230, 0.1817, 0.0153, 0.0413,
        0.1364, 0.0094], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:30,917][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([4.0962e-03, 2.4938e-04, 2.0233e-02, 1.1013e-04, 2.6250e-04, 3.2645e-04,
        5.3587e-05, 2.4368e-03, 9.4242e-04, 2.3543e-04, 9.7105e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:30,919][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2709, 0.0506, 0.1052, 0.0214, 0.0258, 0.0094, 0.0314, 0.0502, 0.0117,
        0.0405, 0.3827], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:30,920][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([3.5099e-02, 5.7207e-04, 2.7316e-03, 7.5221e-04, 9.5963e-03, 1.2377e-02,
        7.2676e-03, 5.1308e-02, 1.3179e-01, 5.9895e-02, 6.8861e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:30,922][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3929, 0.0150, 0.0120, 0.0323, 0.0362, 0.0150, 0.0558, 0.0808, 0.0389,
        0.0765, 0.2446], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:30,924][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1209, 0.0231, 0.1755, 0.0121, 0.0381, 0.1316, 0.0161, 0.1115, 0.1238,
        0.0112, 0.2361], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:30,925][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1834, 0.1395, 0.0068, 0.2567, 0.0503, 0.0079, 0.1628, 0.0110, 0.0047,
        0.1726, 0.0044], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:30,927][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0340, 0.0128, 0.0144, 0.0279, 0.0279, 0.0415, 0.0535, 0.1044, 0.1649,
        0.1955, 0.3231], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:30,929][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0293, 0.0042, 0.1531, 0.0054, 0.0156, 0.1441, 0.0066, 0.0621, 0.2201,
        0.0119, 0.3477], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:30,931][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2278, 0.0663, 0.1182, 0.0589, 0.0671, 0.0822, 0.0481, 0.0950, 0.0880,
        0.0554, 0.0932], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:30,932][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1851, 0.0656, 0.1422, 0.0587, 0.0621, 0.0903, 0.0403, 0.1031, 0.0878,
        0.0596, 0.1052], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:30,933][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1928, 0.0605, 0.0918, 0.1029, 0.0666, 0.0562, 0.1188, 0.1013, 0.0479,
        0.0605, 0.1009], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:30,934][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Sara] are: tensor([0.1858, 0.0900, 0.1087, 0.0814, 0.0107, 0.0351, 0.1119, 0.0743, 0.0590,
        0.0492, 0.1095, 0.0843], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:30,935][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Sara] are: tensor([6.8137e-06, 4.3456e-01, 1.4774e-05, 5.6855e-06, 3.0562e-06, 1.5244e-06,
        6.8354e-05, 9.3226e-06, 1.6466e-06, 9.1884e-06, 2.5596e-07, 5.6532e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:30,936][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Sara] are: tensor([0.3268, 0.1148, 0.0621, 0.0292, 0.0463, 0.0739, 0.0504, 0.0608, 0.0786,
        0.0276, 0.0571, 0.0725], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:30,937][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Sara] are: tensor([6.0827e-04, 2.3823e-03, 8.1004e-07, 1.3798e-04, 8.2999e-06, 1.5527e-05,
        2.4661e-03, 3.5875e-05, 4.4614e-05, 8.4697e-04, 1.1244e-04, 9.9334e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:30,938][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Sara] are: tensor([5.6940e-03, 7.6254e-02, 4.4453e-04, 2.2705e-03, 4.4886e-04, 5.0102e-04,
        3.6370e-03, 1.3922e-03, 9.0649e-04, 4.8905e-03, 2.3401e-03, 9.0122e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:30,939][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Sara] are: tensor([3.4938e-04, 6.8663e-01, 9.3267e-08, 2.2584e-07, 8.8674e-07, 2.5317e-08,
        6.4315e-05, 5.2430e-09, 1.5014e-08, 3.1747e-07, 9.4916e-10, 3.1295e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:30,941][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Sara] are: tensor([0.1293, 0.1437, 0.0678, 0.1730, 0.0098, 0.0484, 0.0625, 0.0129, 0.0785,
        0.0760, 0.0743, 0.1238], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:30,943][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Sara] are: tensor([0.0903, 0.0042, 0.0285, 0.0223, 0.0242, 0.0527, 0.1088, 0.1118, 0.1404,
        0.0599, 0.2933, 0.0636], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:30,944][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Sara] are: tensor([0.2734, 0.1056, 0.1148, 0.0975, 0.0243, 0.0605, 0.0314, 0.0638, 0.0654,
        0.0144, 0.0727, 0.0763], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:30,946][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Sara] are: tensor([0.2581, 0.0139, 0.1007, 0.1330, 0.0379, 0.0821, 0.0719, 0.0725, 0.0922,
        0.0376, 0.0917, 0.0085], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:30,948][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Sara] are: tensor([0.1277, 0.2692, 0.0747, 0.0389, 0.0307, 0.0561, 0.0348, 0.0473, 0.0478,
        0.0272, 0.0464, 0.1993], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:30,950][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Sara] are: tensor([0.0865, 0.1019, 0.0748, 0.0573, 0.0831, 0.0547, 0.1311, 0.0802, 0.0456,
        0.0629, 0.0800, 0.1418], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:30,951][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.2782, 0.0989, 0.0309, 0.0363, 0.0586, 0.0278, 0.0635, 0.0327, 0.0339,
        0.0473, 0.0376, 0.1381, 0.1162], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:30,953][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([4.2034e-04, 3.4706e-04, 2.0287e-04, 3.7095e-03, 1.2719e-02, 4.1347e-04,
        1.9131e-04, 1.3279e-04, 9.4255e-05, 2.6070e-04, 5.3791e-05, 7.2009e-05,
        9.8138e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:30,954][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.2673, 0.0296, 0.0820, 0.1308, 0.1273, 0.0635, 0.0209, 0.0685, 0.0677,
        0.0276, 0.0307, 0.0221, 0.0621], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:30,956][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([9.1989e-04, 2.5826e-06, 8.9598e-06, 8.4581e-06, 9.8220e-05, 2.6836e-05,
        3.7562e-05, 1.0297e-04, 1.5242e-04, 3.8210e-04, 9.6007e-04, 1.8465e-04,
        9.9712e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:30,957][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.0399, 0.0011, 0.0050, 0.0030, 0.0078, 0.0071, 0.0045, 0.0239, 0.0147,
        0.0233, 0.0268, 0.0064, 0.8364], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:30,959][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([1.1283e-02, 1.8420e-04, 4.4789e-05, 2.7624e-04, 2.1533e-03, 5.7172e-06,
        2.0236e-05, 1.9066e-05, 1.8318e-06, 7.5035e-07, 1.9807e-06, 1.2200e-05,
        9.8600e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:30,960][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.1432, 0.1031, 0.0196, 0.1938, 0.0383, 0.0247, 0.0961, 0.0173, 0.0159,
        0.1126, 0.0155, 0.1210, 0.0988], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:30,962][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0420, 0.0043, 0.0118, 0.0181, 0.0210, 0.0390, 0.0106, 0.0696, 0.1084,
        0.0591, 0.2818, 0.1147, 0.2196], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:30,964][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.1420, 0.0277, 0.1120, 0.0334, 0.0768, 0.1132, 0.0437, 0.0925, 0.1472,
        0.0633, 0.0930, 0.0311, 0.0241], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:30,966][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.1997, 0.0437, 0.0895, 0.0550, 0.0744, 0.0679, 0.0703, 0.0708, 0.0742,
        0.0683, 0.0829, 0.0433, 0.0600], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:30,967][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.1755, 0.0412, 0.0801, 0.0455, 0.0740, 0.0674, 0.0407, 0.0572, 0.0672,
        0.0356, 0.0640, 0.0296, 0.2219], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:30,968][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.3077, 0.0467, 0.0759, 0.0551, 0.0439, 0.0410, 0.0736, 0.1018, 0.0307,
        0.0419, 0.0821, 0.0435, 0.0560], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:30,969][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2190, 0.0389, 0.0213, 0.0455, 0.0717, 0.0207, 0.1478, 0.0187, 0.0284,
        0.0817, 0.0249, 0.0497, 0.2164, 0.0153], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:30,969][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([5.7904e-03, 3.0347e-04, 3.9643e-02, 3.4349e-05, 4.6677e-04, 1.6736e-03,
        2.2310e-05, 1.9509e-02, 1.9048e-03, 6.7611e-05, 8.6300e-03, 1.0845e-04,
        2.9698e-05, 9.2182e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:30,971][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1912, 0.0400, 0.0969, 0.0244, 0.0526, 0.0253, 0.0219, 0.1325, 0.0279,
        0.0574, 0.0602, 0.0353, 0.0652, 0.1692], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:30,972][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([6.1242e-03, 5.8981e-05, 2.8178e-04, 2.0639e-05, 8.1956e-04, 1.6154e-03,
        2.2277e-03, 3.5069e-03, 1.5088e-02, 8.1884e-04, 3.7072e-02, 4.2682e-03,
        9.9231e-02, 8.2887e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:30,973][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.2015e-02, 1.0618e-03, 1.3429e-03, 3.8244e-04, 1.9471e-02, 3.7131e-03,
        1.1110e-02, 7.7913e-03, 6.1797e-03, 8.6890e-03, 9.1282e-03, 1.2427e-02,
        8.0850e-01, 9.8183e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:30,975][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([4.4101e-02, 7.2565e-03, 9.0092e-02, 3.3594e-04, 5.0077e-02, 2.1472e-01,
        6.2349e-04, 2.1026e-02, 1.7653e-01, 5.1702e-04, 1.7956e-02, 1.4492e-03,
        5.7578e-03, 3.6956e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:30,976][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0956, 0.0717, 0.0052, 0.0341, 0.0450, 0.0043, 0.0985, 0.0188, 0.0036,
        0.0973, 0.0043, 0.1025, 0.1378, 0.2813], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:30,978][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0269, 0.0039, 0.0056, 0.0067, 0.0095, 0.0114, 0.0200, 0.0245, 0.0405,
        0.0277, 0.1073, 0.1219, 0.3323, 0.2618], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:30,980][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0167, 0.0026, 0.0997, 0.0033, 0.0166, 0.1343, 0.0076, 0.0489, 0.2145,
        0.0155, 0.1796, 0.0041, 0.0076, 0.2491], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:30,982][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1568, 0.0452, 0.0943, 0.0374, 0.0547, 0.0765, 0.0376, 0.0788, 0.0826,
        0.0507, 0.0787, 0.0425, 0.0578, 0.1065], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:30,983][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1279, 0.0426, 0.1151, 0.0314, 0.0661, 0.0953, 0.0267, 0.0871, 0.0868,
        0.0418, 0.0808, 0.0311, 0.0476, 0.1196], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:30,985][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1645, 0.0510, 0.0765, 0.0794, 0.0605, 0.0486, 0.0816, 0.0776, 0.0369,
        0.0449, 0.0797, 0.0559, 0.0646, 0.0782], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:30,987][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.2215, 0.0564, 0.0276, 0.0170, 0.0627, 0.0240, 0.1134, 0.0168, 0.0277,
        0.0975, 0.0241, 0.0699, 0.1722, 0.0253, 0.0440], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:30,988][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ give] are: tensor([6.2486e-04, 1.5106e-04, 5.1200e-04, 6.0794e-04, 4.3828e-03, 4.6081e-04,
        2.4153e-04, 7.7480e-04, 2.1325e-04, 4.8495e-04, 1.6718e-04, 4.1214e-05,
        1.3258e-03, 5.6361e-04, 9.8945e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:30,990][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.1923, 0.0496, 0.0524, 0.0316, 0.0886, 0.0415, 0.0210, 0.0786, 0.0512,
        0.0435, 0.0338, 0.0465, 0.1086, 0.1109, 0.0500], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:30,991][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ give] are: tensor([8.9592e-04, 8.6606e-07, 4.9661e-06, 1.5773e-06, 3.2028e-05, 3.7224e-05,
        1.1771e-05, 6.5383e-05, 2.1133e-04, 5.9595e-04, 9.0885e-04, 1.2947e-04,
        8.8061e-03, 8.6068e-03, 9.7969e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:30,993][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0417, 0.0071, 0.0059, 0.0082, 0.0093, 0.0090, 0.0051, 0.0221, 0.0152,
        0.0436, 0.0262, 0.0435, 0.1228, 0.1157, 0.5245], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:30,994][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ give] are: tensor([9.2358e-03, 1.0121e-04, 5.0176e-05, 1.7573e-04, 1.4841e-03, 4.0214e-05,
        5.2101e-06, 3.3155e-05, 2.2243e-05, 9.1232e-06, 3.1447e-06, 5.5737e-06,
        1.6483e-04, 8.3999e-06, 9.8866e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:30,996][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.1167, 0.0894, 0.0126, 0.1640, 0.0287, 0.0141, 0.1372, 0.0119, 0.0121,
        0.1522, 0.0122, 0.1248, 0.0885, 0.0112, 0.0244], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:30,998][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0268, 0.0014, 0.0060, 0.0066, 0.0092, 0.0129, 0.0040, 0.0256, 0.0333,
        0.0251, 0.0918, 0.0260, 0.1538, 0.3293, 0.2483], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,000][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0677, 0.0135, 0.0801, 0.0201, 0.0665, 0.0658, 0.0906, 0.0583, 0.0837,
        0.1336, 0.0872, 0.0174, 0.0376, 0.1385, 0.0396], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,001][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.1304, 0.0421, 0.0755, 0.0398, 0.0607, 0.0645, 0.0628, 0.0626, 0.0651,
        0.0623, 0.0705, 0.0444, 0.0710, 0.0930, 0.0554], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,002][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.1069, 0.0293, 0.0695, 0.0338, 0.0763, 0.0605, 0.0388, 0.0669, 0.0575,
        0.0395, 0.0606, 0.0266, 0.0620, 0.0811, 0.1908], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,003][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.2593, 0.0474, 0.0887, 0.0571, 0.0514, 0.0260, 0.0511, 0.0779, 0.0200,
        0.0317, 0.0625, 0.0419, 0.0489, 0.0614, 0.0746], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,005][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.2455, 0.0501, 0.0180, 0.0378, 0.0427, 0.0112, 0.1387, 0.0145, 0.0165,
        0.0951, 0.0203, 0.0683, 0.1301, 0.0126, 0.0657, 0.0330],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,006][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ it] are: tensor([3.1340e-03, 6.3173e-04, 2.0982e-03, 1.7651e-04, 2.5799e-04, 3.3408e-03,
        1.1925e-05, 6.0178e-04, 1.0983e-02, 4.2726e-05, 7.2944e-04, 2.6634e-04,
        1.1513e-04, 3.1600e-03, 4.1432e-04, 9.7404e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,008][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.1609, 0.0335, 0.0768, 0.0383, 0.1041, 0.0233, 0.0229, 0.0632, 0.0243,
        0.0578, 0.0425, 0.0324, 0.1253, 0.0927, 0.0708, 0.0311],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,009][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ it] are: tensor([8.5268e-04, 9.6451e-06, 1.4938e-05, 6.9225e-06, 5.9192e-05, 1.0301e-04,
        3.5442e-05, 2.5978e-04, 8.7400e-04, 2.2336e-04, 3.2504e-03, 1.4439e-03,
        9.4365e-03, 1.8068e-02, 7.2847e-02, 8.9251e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,011][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.0465, 0.0013, 0.0057, 0.0050, 0.0162, 0.0063, 0.0135, 0.0133, 0.0136,
        0.0089, 0.0252, 0.0073, 0.2780, 0.0938, 0.1973, 0.2681],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,012][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ it] are: tensor([2.6295e-02, 1.4838e-02, 4.1260e-03, 1.0742e-04, 7.9996e-03, 6.4970e-03,
        1.6133e-03, 1.8724e-03, 8.2075e-03, 8.8936e-05, 4.4400e-04, 1.3850e-03,
        1.0152e-03, 1.8925e-03, 5.5723e-04, 9.2306e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,014][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.0951, 0.1070, 0.0049, 0.1251, 0.0358, 0.0047, 0.1101, 0.0052, 0.0032,
        0.1387, 0.0040, 0.1957, 0.1145, 0.0067, 0.0432, 0.0062],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,016][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.0262, 0.0014, 0.0041, 0.0036, 0.0061, 0.0068, 0.0072, 0.0165, 0.0191,
        0.0111, 0.0617, 0.0288, 0.0702, 0.1760, 0.3002, 0.2610],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,017][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.0310, 0.0045, 0.0856, 0.0076, 0.0333, 0.1320, 0.0131, 0.0408, 0.1828,
        0.0190, 0.1219, 0.0066, 0.0147, 0.1117, 0.0258, 0.1695],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,019][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ it] are: tensor([0.1580, 0.0385, 0.0771, 0.0427, 0.0514, 0.0587, 0.0421, 0.0613, 0.0656,
        0.0381, 0.0673, 0.0378, 0.0468, 0.0863, 0.0585, 0.0699],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,021][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.1130, 0.0325, 0.0708, 0.0245, 0.0386, 0.0690, 0.0197, 0.0523, 0.0871,
        0.0233, 0.0566, 0.0275, 0.0408, 0.0689, 0.0432, 0.2323],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,023][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ it] are: tensor([0.1992, 0.0492, 0.0567, 0.0746, 0.0419, 0.0345, 0.0729, 0.0635, 0.0300,
        0.0384, 0.0673, 0.0496, 0.0531, 0.0595, 0.0626, 0.0470],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,025][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1931, 0.0336, 0.0173, 0.0394, 0.0620, 0.0173, 0.1272, 0.0148, 0.0236,
        0.0697, 0.0200, 0.0433, 0.1858, 0.0123, 0.0729, 0.0529, 0.0147],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,026][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.8639e-03, 1.3412e-04, 1.7568e-02, 1.5676e-05, 2.1395e-04, 7.1501e-04,
        9.3605e-06, 8.8263e-03, 8.9400e-04, 3.2751e-05, 4.6300e-03, 5.6190e-05,
        1.4756e-05, 4.6285e-01, 4.0140e-04, 6.5262e-04, 5.0012e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,028][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1479, 0.0308, 0.0740, 0.0194, 0.0421, 0.0193, 0.0177, 0.1020, 0.0214,
        0.0463, 0.0467, 0.0287, 0.0530, 0.1303, 0.0547, 0.0266, 0.1394],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,029][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.6398e-03, 9.8258e-06, 4.0780e-05, 2.7263e-06, 8.5028e-05, 1.4147e-04,
        2.2947e-04, 2.4138e-04, 9.9470e-04, 5.5908e-05, 2.5224e-03, 3.1490e-04,
        6.2126e-03, 4.7920e-02, 4.0170e-01, 9.8676e-02, 4.3921e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,031][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.3378e-02, 9.3682e-04, 1.2188e-03, 3.1092e-04, 1.4692e-02, 2.5091e-03,
        7.8033e-03, 4.5566e-03, 3.5157e-03, 4.4844e-03, 4.9861e-03, 6.6057e-03,
        4.3028e-01, 4.9788e-02, 2.3327e-01, 6.1963e-02, 1.5970e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,032][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([2.6955e-02, 5.0233e-03, 6.1375e-02, 2.1437e-04, 3.5753e-02, 1.5456e-01,
        3.7246e-04, 1.5438e-02, 1.2541e-01, 3.3178e-04, 1.1390e-02, 1.0102e-03,
        3.9461e-03, 2.5852e-01, 9.0149e-03, 5.2452e-02, 2.3824e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,033][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0669, 0.0490, 0.0033, 0.0241, 0.0312, 0.0028, 0.0681, 0.0129, 0.0023,
        0.0694, 0.0028, 0.0729, 0.0981, 0.1973, 0.0530, 0.0074, 0.2384],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,034][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0209, 0.0022, 0.0032, 0.0036, 0.0043, 0.0045, 0.0082, 0.0079, 0.0126,
        0.0095, 0.0334, 0.0377, 0.0958, 0.0706, 0.1467, 0.2599, 0.2788],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,035][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0119, 0.0018, 0.0696, 0.0024, 0.0120, 0.0922, 0.0055, 0.0337, 0.1452,
        0.0116, 0.1252, 0.0029, 0.0055, 0.1719, 0.0140, 0.0889, 0.2058],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,037][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1220, 0.0353, 0.0725, 0.0301, 0.0438, 0.0589, 0.0308, 0.0603, 0.0632,
        0.0421, 0.0612, 0.0343, 0.0470, 0.0817, 0.0554, 0.0720, 0.0895],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,038][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0910, 0.0307, 0.0806, 0.0240, 0.0511, 0.0713, 0.0221, 0.0675, 0.0672,
        0.0359, 0.0655, 0.0273, 0.0412, 0.0989, 0.0493, 0.0764, 0.1003],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,040][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1493, 0.0452, 0.0672, 0.0674, 0.0536, 0.0427, 0.0653, 0.0652, 0.0316,
        0.0366, 0.0636, 0.0458, 0.0525, 0.0641, 0.0512, 0.0336, 0.0651],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,063][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:31,065][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,066][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,068][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,069][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,069][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,070][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,071][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,071][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,073][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,074][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,076][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,077][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,078][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Sara] are: tensor([0.7584, 0.2416], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,078][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Sara] are: tensor([4.7536e-05, 9.9995e-01], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,079][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Sara] are: tensor([0.8806, 0.1194], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,080][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Sara] are: tensor([0.0852, 0.9148], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,080][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Sara] are: tensor([0.1404, 0.8596], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,082][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Sara] are: tensor([0.0080, 0.9920], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,084][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Sara] are: tensor([0.7861, 0.2139], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,085][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Sara] are: tensor([0.9804, 0.0196], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,087][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Sara] are: tensor([0.8561, 0.1439], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,089][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Sara] are: tensor([0.9613, 0.0387], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,090][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Sara] are: tensor([0.7000, 0.3000], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,092][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Sara] are: tensor([0.6791, 0.3209], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,093][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.7898, 0.1496, 0.0605], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,095][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0042, 0.0010, 0.9947], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,096][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4043, 0.0515, 0.5442], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,098][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2550, 0.0572, 0.6877], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,100][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.5896, 0.2263, 0.1841], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,101][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2150, 0.0195, 0.7655], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,103][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6616, 0.3103, 0.0281], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,105][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4689, 0.3080, 0.2231], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,106][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2523, 0.0329, 0.7147], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,108][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.6074, 0.1366, 0.2560], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,110][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.6547, 0.0927, 0.2526], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,111][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.5495, 0.1005, 0.3500], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,112][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Kenneth] are: tensor([0.4316, 0.0433, 0.2869, 0.2383], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,113][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Kenneth] are: tensor([1.6544e-04, 2.3240e-04, 2.2058e-04, 9.9938e-01], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,113][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Kenneth] are: tensor([0.6618, 0.1222, 0.1665, 0.0495], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,114][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Kenneth] are: tensor([7.9074e-03, 5.3956e-03, 6.6592e-05, 9.8663e-01], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,116][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Kenneth] are: tensor([0.0656, 0.0797, 0.0028, 0.8519], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,117][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Kenneth] are: tensor([6.6617e-04, 5.2427e-06, 2.5613e-09, 9.9933e-01], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,118][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Kenneth] are: tensor([0.3988, 0.1529, 0.2279, 0.2204], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,120][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Kenneth] are: tensor([0.2731, 0.3801, 0.2349, 0.1119], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,122][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Kenneth] are: tensor([0.4659, 0.1980, 0.2028, 0.1332], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,123][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Kenneth] are: tensor([0.5200, 0.2260, 0.2280, 0.0260], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,125][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Kenneth] are: tensor([0.4598, 0.0889, 0.1698, 0.2814], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,127][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Kenneth] are: tensor([0.2770, 0.1639, 0.3421, 0.2169], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,128][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.4957, 0.1215, 0.1125, 0.0496, 0.2207], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,129][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([4.9857e-04, 1.4738e-03, 9.1694e-04, 1.0304e-03, 9.9608e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,131][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.5657, 0.0638, 0.1904, 0.0539, 0.1261], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,133][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.0569, 0.0067, 0.0130, 0.0100, 0.9133], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,134][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.3736, 0.0617, 0.0451, 0.0452, 0.4744], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,135][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([1.2117e-02, 7.8094e-04, 9.5136e-05, 1.4329e-04, 9.8686e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,137][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.2860, 0.2664, 0.0336, 0.3400, 0.0740], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,138][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.3127, 0.0488, 0.2580, 0.1145, 0.2659], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,140][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.3576, 0.0938, 0.3506, 0.0958, 0.1023], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,142][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.4357, 0.1125, 0.2332, 0.1009, 0.1177], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,143][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.3810, 0.0890, 0.1941, 0.0643, 0.2716], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,145][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.4311, 0.0932, 0.2087, 0.1655, 0.1015], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,146][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4686, 0.1958, 0.0455, 0.1165, 0.1401, 0.0334], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,146][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([3.4084e-03, 1.5734e-03, 6.0583e-03, 6.4141e-04, 1.3907e-03, 9.8693e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,147][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.4181, 0.0773, 0.2435, 0.0970, 0.1137, 0.0503], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,148][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0718, 0.0114, 0.0389, 0.0151, 0.1019, 0.7609], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,150][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.2041, 0.0490, 0.0400, 0.0786, 0.4540, 0.1743], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,151][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1222, 0.0154, 0.1335, 0.0022, 0.0324, 0.6944], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,153][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2574, 0.3102, 0.0110, 0.2659, 0.1441, 0.0114], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,155][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1629, 0.0696, 0.1275, 0.1451, 0.2176, 0.2772], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,156][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0525, 0.0099, 0.2293, 0.0163, 0.0567, 0.6353], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,158][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.3697, 0.0977, 0.2035, 0.0846, 0.0946, 0.1498], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,160][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.3437, 0.0935, 0.2028, 0.0572, 0.0652, 0.2376], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,161][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3305, 0.0925, 0.1677, 0.1670, 0.1164, 0.1258], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,163][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.3195, 0.0762, 0.2876, 0.0694, 0.0792, 0.1147, 0.0534],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,164][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([2.1729e-04, 9.2686e-03, 3.9276e-04, 5.4683e-04, 6.4152e-04, 2.1239e-04,
        9.8872e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,166][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.4098, 0.0640, 0.1541, 0.0898, 0.1207, 0.1307, 0.0308],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,167][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([6.8436e-03, 1.5427e-03, 1.9885e-05, 1.6455e-03, 8.8786e-04, 1.2616e-04,
        9.8893e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,168][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.0692, 0.0062, 0.0017, 0.0059, 0.0143, 0.0036, 0.8991],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,170][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([3.0910e-05, 3.3711e-05, 2.4235e-09, 1.1390e-07, 1.9881e-08, 3.9286e-10,
        9.9994e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,171][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.2130, 0.1501, 0.1344, 0.2333, 0.0223, 0.1050, 0.1418],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,173][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.1400, 0.0092, 0.1414, 0.0237, 0.2664, 0.3564, 0.0631],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,175][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.2944, 0.0697, 0.0980, 0.1001, 0.0842, 0.0769, 0.2767],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,176][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.3699, 0.1484, 0.1697, 0.0714, 0.0978, 0.1298, 0.0130],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,178][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.2641, 0.1269, 0.1589, 0.0502, 0.0749, 0.0812, 0.2439],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,179][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.1578, 0.0955, 0.1540, 0.1153, 0.1425, 0.1874, 0.1475],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,180][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.2750, 0.0969, 0.0448, 0.0997, 0.1644, 0.0626, 0.2281, 0.0286],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,181][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([1.6177e-03, 1.1898e-03, 5.4861e-03, 3.1507e-04, 1.2732e-04, 1.8803e-03,
        5.3727e-05, 9.8933e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,182][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.3234, 0.0601, 0.1700, 0.0727, 0.1298, 0.0603, 0.0396, 0.1440],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,183][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([3.9982e-03, 1.2200e-04, 2.7515e-03, 2.1192e-03, 1.2682e-02, 3.7453e-02,
        2.9611e-02, 9.1126e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,184][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.1271, 0.0151, 0.0193, 0.0317, 0.1891, 0.0740, 0.2416, 0.3021],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,186][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([7.7357e-02, 2.6834e-03, 1.4687e-02, 6.9675e-03, 7.9418e-03, 1.8343e-02,
        5.9119e-04, 8.7143e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,187][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.1369, 0.1929, 0.0155, 0.2656, 0.0880, 0.0183, 0.2628, 0.0201],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,189][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0889, 0.0207, 0.0579, 0.0486, 0.1051, 0.2094, 0.1437, 0.3256],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,190][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0631, 0.0125, 0.3105, 0.0150, 0.0670, 0.3364, 0.0333, 0.1623],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,192][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.2720, 0.0889, 0.1706, 0.0602, 0.0885, 0.1286, 0.0528, 0.1384],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,194][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.2329, 0.0741, 0.1732, 0.0557, 0.0575, 0.1235, 0.0292, 0.2539],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,196][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.2993, 0.0651, 0.1158, 0.1127, 0.0724, 0.0611, 0.1243, 0.1493],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,197][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.3812, 0.0815, 0.0270, 0.1155, 0.0939, 0.0216, 0.2347, 0.0208, 0.0238],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,198][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([9.2933e-03, 8.7866e-04, 5.7350e-02, 9.2113e-04, 1.7149e-04, 4.4567e-02,
        3.6158e-05, 5.6566e-02, 8.3022e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,200][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.3023, 0.0508, 0.1311, 0.0793, 0.1282, 0.0384, 0.0325, 0.2006, 0.0368],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,202][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0288, 0.0027, 0.0062, 0.0040, 0.0169, 0.0716, 0.0224, 0.1898, 0.6577],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,203][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1849, 0.0339, 0.0250, 0.0361, 0.1332, 0.0577, 0.1693, 0.1982, 0.1617],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,205][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1264, 0.0331, 0.1217, 0.0089, 0.0594, 0.2341, 0.0036, 0.0743, 0.3383],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,207][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.1475, 0.2589, 0.0038, 0.2451, 0.0670, 0.0039, 0.2647, 0.0067, 0.0023],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,209][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0739, 0.0144, 0.0323, 0.0402, 0.0549, 0.0847, 0.1358, 0.2775, 0.2862],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,211][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0197, 0.0048, 0.1382, 0.0090, 0.0294, 0.3249, 0.0113, 0.0643, 0.3984],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,212][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.2665, 0.0719, 0.1371, 0.0689, 0.0747, 0.1028, 0.0493, 0.1163, 0.1124],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,213][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.2820, 0.0608, 0.1490, 0.0570, 0.0459, 0.1333, 0.0192, 0.0859, 0.1669],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,214][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2032, 0.0670, 0.0973, 0.1268, 0.0664, 0.1013, 0.1306, 0.0960, 0.1115],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,214][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ garden] are: tensor([0.2465, 0.1133, 0.1248, 0.0503, 0.0402, 0.1045, 0.0706, 0.0987, 0.1029,
        0.0482], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,215][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ garden] are: tensor([2.7473e-04, 1.2956e-03, 1.0363e-04, 1.7042e-03, 5.7562e-04, 6.0919e-05,
        7.7071e-04, 5.3638e-05, 7.1313e-05, 9.9509e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,217][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ garden] are: tensor([0.2920, 0.0600, 0.1019, 0.0436, 0.0487, 0.1126, 0.0669, 0.1114, 0.1128,
        0.0501], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,218][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ garden] are: tensor([3.0342e-03, 1.0220e-04, 1.3734e-05, 2.8445e-04, 1.6372e-04, 5.5295e-05,
        2.3290e-03, 5.4463e-04, 3.7922e-04, 9.9309e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,220][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ garden] are: tensor([0.0182, 0.0961, 0.0018, 0.0137, 0.0144, 0.0040, 0.1100, 0.0110, 0.0114,
        0.7193], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,221][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ garden] are: tensor([4.4013e-03, 8.9074e-04, 3.2102e-06, 1.0579e-04, 1.2360e-06, 5.1084e-07,
        1.8786e-04, 2.9611e-07, 4.3041e-07, 9.9441e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,222][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ garden] are: tensor([0.1844, 0.1100, 0.0567, 0.2189, 0.0218, 0.0487, 0.1705, 0.0261, 0.0456,
        0.1172], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,224][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ garden] are: tensor([0.0598, 0.0175, 0.0293, 0.0015, 0.0502, 0.1094, 0.2628, 0.1578, 0.2884,
        0.0233], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,226][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ garden] are: tensor([0.3647, 0.0802, 0.1011, 0.0396, 0.0445, 0.0814, 0.0254, 0.0628, 0.0800,
        0.1203], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,227][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ garden] are: tensor([0.2795, 0.0633, 0.1136, 0.0906, 0.0599, 0.1009, 0.0825, 0.0846, 0.1062,
        0.0189], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,229][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ garden] are: tensor([0.2132, 0.0594, 0.1197, 0.0638, 0.0414, 0.0804, 0.0388, 0.0528, 0.0641,
        0.2664], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,231][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ garden] are: tensor([0.2526, 0.0852, 0.0812, 0.0965, 0.0536, 0.0426, 0.1268, 0.1255, 0.0429,
        0.0931], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,233][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3486, 0.0651, 0.0128, 0.0759, 0.0904, 0.0230, 0.1817, 0.0153, 0.0413,
        0.1364, 0.0094], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,234][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([4.0962e-03, 2.4938e-04, 2.0233e-02, 1.1013e-04, 2.6250e-04, 3.2645e-04,
        5.3587e-05, 2.4368e-03, 9.4242e-04, 2.3543e-04, 9.7105e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,236][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2709, 0.0506, 0.1052, 0.0214, 0.0258, 0.0094, 0.0314, 0.0502, 0.0117,
        0.0405, 0.3827], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,237][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([3.5099e-02, 5.7207e-04, 2.7316e-03, 7.5221e-04, 9.5963e-03, 1.2377e-02,
        7.2676e-03, 5.1308e-02, 1.3179e-01, 5.9895e-02, 6.8861e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,239][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3929, 0.0150, 0.0120, 0.0323, 0.0362, 0.0150, 0.0558, 0.0808, 0.0389,
        0.0765, 0.2446], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,240][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1209, 0.0231, 0.1755, 0.0121, 0.0381, 0.1316, 0.0161, 0.1115, 0.1238,
        0.0112, 0.2361], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,242][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1834, 0.1395, 0.0068, 0.2567, 0.0503, 0.0079, 0.1628, 0.0110, 0.0047,
        0.1726, 0.0044], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,244][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0340, 0.0128, 0.0144, 0.0279, 0.0279, 0.0415, 0.0535, 0.1044, 0.1649,
        0.1955, 0.3231], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,246][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0293, 0.0042, 0.1531, 0.0054, 0.0156, 0.1441, 0.0066, 0.0621, 0.2201,
        0.0119, 0.3477], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,247][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2278, 0.0663, 0.1182, 0.0589, 0.0671, 0.0822, 0.0481, 0.0950, 0.0880,
        0.0554, 0.0932], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,248][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1851, 0.0656, 0.1422, 0.0587, 0.0621, 0.0903, 0.0403, 0.1031, 0.0878,
        0.0596, 0.1052], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,248][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1928, 0.0605, 0.0918, 0.1029, 0.0666, 0.0562, 0.1188, 0.1013, 0.0479,
        0.0605, 0.1009], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,250][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Sara] are: tensor([0.1858, 0.0900, 0.1087, 0.0814, 0.0107, 0.0351, 0.1119, 0.0743, 0.0590,
        0.0492, 0.1095, 0.0843], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,251][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Sara] are: tensor([6.8137e-06, 4.3456e-01, 1.4774e-05, 5.6855e-06, 3.0562e-06, 1.5244e-06,
        6.8354e-05, 9.3226e-06, 1.6466e-06, 9.1884e-06, 2.5596e-07, 5.6532e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,253][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Sara] are: tensor([0.3268, 0.1148, 0.0621, 0.0292, 0.0463, 0.0739, 0.0504, 0.0608, 0.0786,
        0.0276, 0.0571, 0.0725], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,255][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Sara] are: tensor([6.0827e-04, 2.3823e-03, 8.1004e-07, 1.3798e-04, 8.2999e-06, 1.5527e-05,
        2.4661e-03, 3.5875e-05, 4.4614e-05, 8.4697e-04, 1.1244e-04, 9.9334e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,256][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Sara] are: tensor([5.6940e-03, 7.6254e-02, 4.4453e-04, 2.2705e-03, 4.4886e-04, 5.0102e-04,
        3.6370e-03, 1.3922e-03, 9.0649e-04, 4.8905e-03, 2.3401e-03, 9.0122e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,257][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Sara] are: tensor([3.4938e-04, 6.8663e-01, 9.3267e-08, 2.2584e-07, 8.8674e-07, 2.5317e-08,
        6.4315e-05, 5.2430e-09, 1.5014e-08, 3.1747e-07, 9.4916e-10, 3.1295e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,259][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Sara] are: tensor([0.1293, 0.1437, 0.0678, 0.1730, 0.0098, 0.0484, 0.0625, 0.0129, 0.0785,
        0.0760, 0.0743, 0.1238], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,260][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Sara] are: tensor([0.0903, 0.0042, 0.0285, 0.0223, 0.0242, 0.0527, 0.1088, 0.1118, 0.1404,
        0.0599, 0.2933, 0.0636], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,262][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Sara] are: tensor([0.2734, 0.1056, 0.1148, 0.0975, 0.0243, 0.0605, 0.0314, 0.0638, 0.0654,
        0.0144, 0.0727, 0.0763], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,264][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Sara] are: tensor([0.2581, 0.0139, 0.1007, 0.1330, 0.0379, 0.0821, 0.0719, 0.0725, 0.0922,
        0.0376, 0.0917, 0.0085], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,266][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Sara] are: tensor([0.1277, 0.2692, 0.0747, 0.0389, 0.0307, 0.0561, 0.0348, 0.0473, 0.0478,
        0.0272, 0.0464, 0.1993], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,267][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Sara] are: tensor([0.0865, 0.1019, 0.0748, 0.0573, 0.0831, 0.0547, 0.1311, 0.0802, 0.0456,
        0.0629, 0.0800, 0.1418], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,269][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.2782, 0.0989, 0.0309, 0.0363, 0.0586, 0.0278, 0.0635, 0.0327, 0.0339,
        0.0473, 0.0376, 0.1381, 0.1162], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,270][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([4.2034e-04, 3.4706e-04, 2.0287e-04, 3.7095e-03, 1.2719e-02, 4.1347e-04,
        1.9131e-04, 1.3279e-04, 9.4255e-05, 2.6070e-04, 5.3791e-05, 7.2009e-05,
        9.8138e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,272][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.2673, 0.0296, 0.0820, 0.1308, 0.1273, 0.0635, 0.0209, 0.0685, 0.0677,
        0.0276, 0.0307, 0.0221, 0.0621], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,273][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([9.1989e-04, 2.5826e-06, 8.9598e-06, 8.4581e-06, 9.8220e-05, 2.6836e-05,
        3.7562e-05, 1.0297e-04, 1.5242e-04, 3.8210e-04, 9.6007e-04, 1.8465e-04,
        9.9712e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,275][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0399, 0.0011, 0.0050, 0.0030, 0.0078, 0.0071, 0.0045, 0.0239, 0.0147,
        0.0233, 0.0268, 0.0064, 0.8364], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,276][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([1.1283e-02, 1.8420e-04, 4.4789e-05, 2.7624e-04, 2.1533e-03, 5.7172e-06,
        2.0236e-05, 1.9066e-05, 1.8318e-06, 7.5035e-07, 1.9807e-06, 1.2200e-05,
        9.8600e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,278][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.1432, 0.1031, 0.0196, 0.1938, 0.0383, 0.0247, 0.0961, 0.0173, 0.0159,
        0.1126, 0.0155, 0.1210, 0.0988], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,279][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0420, 0.0043, 0.0118, 0.0181, 0.0210, 0.0390, 0.0106, 0.0696, 0.1084,
        0.0591, 0.2818, 0.1147, 0.2196], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,280][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.1420, 0.0277, 0.1120, 0.0334, 0.0768, 0.1132, 0.0437, 0.0925, 0.1472,
        0.0633, 0.0930, 0.0311, 0.0241], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,281][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.1997, 0.0437, 0.0895, 0.0550, 0.0744, 0.0679, 0.0703, 0.0708, 0.0742,
        0.0683, 0.0829, 0.0433, 0.0600], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,282][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.1755, 0.0412, 0.0801, 0.0455, 0.0740, 0.0674, 0.0407, 0.0572, 0.0672,
        0.0356, 0.0640, 0.0296, 0.2219], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,284][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.3077, 0.0467, 0.0759, 0.0551, 0.0439, 0.0410, 0.0736, 0.1018, 0.0307,
        0.0419, 0.0821, 0.0435, 0.0560], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,285][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2190, 0.0389, 0.0213, 0.0455, 0.0717, 0.0207, 0.1478, 0.0187, 0.0284,
        0.0817, 0.0249, 0.0497, 0.2164, 0.0153], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,287][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([5.7904e-03, 3.0347e-04, 3.9643e-02, 3.4349e-05, 4.6677e-04, 1.6736e-03,
        2.2310e-05, 1.9509e-02, 1.9048e-03, 6.7611e-05, 8.6300e-03, 1.0845e-04,
        2.9698e-05, 9.2182e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,289][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1912, 0.0400, 0.0969, 0.0244, 0.0526, 0.0253, 0.0219, 0.1325, 0.0279,
        0.0574, 0.0602, 0.0353, 0.0652, 0.1692], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,290][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([6.1242e-03, 5.8981e-05, 2.8178e-04, 2.0639e-05, 8.1956e-04, 1.6154e-03,
        2.2277e-03, 3.5069e-03, 1.5088e-02, 8.1884e-04, 3.7072e-02, 4.2682e-03,
        9.9231e-02, 8.2887e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,291][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.2015e-02, 1.0618e-03, 1.3429e-03, 3.8244e-04, 1.9471e-02, 3.7131e-03,
        1.1110e-02, 7.7913e-03, 6.1797e-03, 8.6890e-03, 9.1282e-03, 1.2427e-02,
        8.0850e-01, 9.8183e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,292][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([4.4101e-02, 7.2565e-03, 9.0092e-02, 3.3594e-04, 5.0077e-02, 2.1472e-01,
        6.2349e-04, 2.1026e-02, 1.7653e-01, 5.1702e-04, 1.7956e-02, 1.4492e-03,
        5.7578e-03, 3.6956e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,294][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0956, 0.0717, 0.0052, 0.0341, 0.0450, 0.0043, 0.0985, 0.0188, 0.0036,
        0.0973, 0.0043, 0.1025, 0.1378, 0.2813], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,296][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0269, 0.0039, 0.0056, 0.0067, 0.0095, 0.0114, 0.0200, 0.0245, 0.0405,
        0.0277, 0.1073, 0.1219, 0.3323, 0.2618], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,297][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0167, 0.0026, 0.0997, 0.0033, 0.0166, 0.1343, 0.0076, 0.0489, 0.2145,
        0.0155, 0.1796, 0.0041, 0.0076, 0.2491], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,299][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1568, 0.0452, 0.0943, 0.0374, 0.0547, 0.0765, 0.0376, 0.0788, 0.0826,
        0.0507, 0.0787, 0.0425, 0.0578, 0.1065], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,301][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1279, 0.0426, 0.1151, 0.0314, 0.0661, 0.0953, 0.0267, 0.0871, 0.0868,
        0.0418, 0.0808, 0.0311, 0.0476, 0.1196], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,303][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1645, 0.0510, 0.0765, 0.0794, 0.0605, 0.0486, 0.0816, 0.0776, 0.0369,
        0.0449, 0.0797, 0.0559, 0.0646, 0.0782], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,305][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.2215, 0.0564, 0.0276, 0.0170, 0.0627, 0.0240, 0.1134, 0.0168, 0.0277,
        0.0975, 0.0241, 0.0699, 0.1722, 0.0253, 0.0440], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,306][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([6.2486e-04, 1.5106e-04, 5.1200e-04, 6.0794e-04, 4.3828e-03, 4.6081e-04,
        2.4153e-04, 7.7480e-04, 2.1325e-04, 4.8495e-04, 1.6718e-04, 4.1214e-05,
        1.3258e-03, 5.6361e-04, 9.8945e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,308][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.1923, 0.0496, 0.0524, 0.0316, 0.0886, 0.0415, 0.0210, 0.0786, 0.0512,
        0.0435, 0.0338, 0.0465, 0.1086, 0.1109, 0.0500], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,309][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([8.9592e-04, 8.6606e-07, 4.9661e-06, 1.5773e-06, 3.2028e-05, 3.7224e-05,
        1.1771e-05, 6.5383e-05, 2.1133e-04, 5.9595e-04, 9.0885e-04, 1.2947e-04,
        8.8061e-03, 8.6068e-03, 9.7969e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,311][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0417, 0.0071, 0.0059, 0.0082, 0.0093, 0.0090, 0.0051, 0.0221, 0.0152,
        0.0436, 0.0262, 0.0435, 0.1228, 0.1157, 0.5245], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,312][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([9.2358e-03, 1.0121e-04, 5.0176e-05, 1.7573e-04, 1.4841e-03, 4.0214e-05,
        5.2101e-06, 3.3155e-05, 2.2243e-05, 9.1232e-06, 3.1447e-06, 5.5737e-06,
        1.6483e-04, 8.3999e-06, 9.8866e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,313][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.1167, 0.0894, 0.0126, 0.1640, 0.0287, 0.0141, 0.1372, 0.0119, 0.0121,
        0.1522, 0.0122, 0.1248, 0.0885, 0.0112, 0.0244], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,314][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0268, 0.0014, 0.0060, 0.0066, 0.0092, 0.0129, 0.0040, 0.0256, 0.0333,
        0.0251, 0.0918, 0.0260, 0.1538, 0.3293, 0.2483], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,315][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0677, 0.0135, 0.0801, 0.0201, 0.0665, 0.0658, 0.0906, 0.0583, 0.0837,
        0.1336, 0.0872, 0.0174, 0.0376, 0.1385, 0.0396], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,317][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.1304, 0.0421, 0.0755, 0.0398, 0.0607, 0.0645, 0.0628, 0.0626, 0.0651,
        0.0623, 0.0705, 0.0444, 0.0710, 0.0930, 0.0554], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,318][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.1069, 0.0293, 0.0695, 0.0338, 0.0763, 0.0605, 0.0388, 0.0669, 0.0575,
        0.0395, 0.0606, 0.0266, 0.0620, 0.0811, 0.1908], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,320][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.2593, 0.0474, 0.0887, 0.0571, 0.0514, 0.0260, 0.0511, 0.0779, 0.0200,
        0.0317, 0.0625, 0.0419, 0.0489, 0.0614, 0.0746], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,322][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([0.2455, 0.0501, 0.0180, 0.0378, 0.0427, 0.0112, 0.1387, 0.0145, 0.0165,
        0.0951, 0.0203, 0.0683, 0.1301, 0.0126, 0.0657, 0.0330],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,324][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([3.1340e-03, 6.3173e-04, 2.0982e-03, 1.7651e-04, 2.5799e-04, 3.3408e-03,
        1.1925e-05, 6.0178e-04, 1.0983e-02, 4.2726e-05, 7.2944e-04, 2.6634e-04,
        1.1513e-04, 3.1600e-03, 4.1432e-04, 9.7404e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,325][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.1609, 0.0335, 0.0768, 0.0383, 0.1041, 0.0233, 0.0229, 0.0632, 0.0243,
        0.0578, 0.0425, 0.0324, 0.1253, 0.0927, 0.0708, 0.0311],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,327][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([8.5268e-04, 9.6451e-06, 1.4938e-05, 6.9225e-06, 5.9192e-05, 1.0301e-04,
        3.5442e-05, 2.5978e-04, 8.7400e-04, 2.2336e-04, 3.2504e-03, 1.4439e-03,
        9.4365e-03, 1.8068e-02, 7.2847e-02, 8.9251e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,328][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.0465, 0.0013, 0.0057, 0.0050, 0.0162, 0.0063, 0.0135, 0.0133, 0.0136,
        0.0089, 0.0252, 0.0073, 0.2780, 0.0938, 0.1973, 0.2681],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,330][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([2.6295e-02, 1.4838e-02, 4.1260e-03, 1.0742e-04, 7.9996e-03, 6.4970e-03,
        1.6133e-03, 1.8724e-03, 8.2075e-03, 8.8936e-05, 4.4400e-04, 1.3850e-03,
        1.0152e-03, 1.8925e-03, 5.5723e-04, 9.2306e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,331][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([0.0951, 0.1070, 0.0049, 0.1251, 0.0358, 0.0047, 0.1101, 0.0052, 0.0032,
        0.1387, 0.0040, 0.1957, 0.1145, 0.0067, 0.0432, 0.0062],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,333][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.0262, 0.0014, 0.0041, 0.0036, 0.0061, 0.0068, 0.0072, 0.0165, 0.0191,
        0.0111, 0.0617, 0.0288, 0.0702, 0.1760, 0.3002, 0.2610],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,335][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.0310, 0.0045, 0.0856, 0.0076, 0.0333, 0.1320, 0.0131, 0.0408, 0.1828,
        0.0190, 0.1219, 0.0066, 0.0147, 0.1117, 0.0258, 0.1695],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,337][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([0.1580, 0.0385, 0.0771, 0.0427, 0.0514, 0.0587, 0.0421, 0.0613, 0.0656,
        0.0381, 0.0673, 0.0378, 0.0468, 0.0863, 0.0585, 0.0699],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,339][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.1130, 0.0325, 0.0708, 0.0245, 0.0386, 0.0690, 0.0197, 0.0523, 0.0871,
        0.0233, 0.0566, 0.0275, 0.0408, 0.0689, 0.0432, 0.2323],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,341][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([0.1992, 0.0492, 0.0567, 0.0746, 0.0419, 0.0345, 0.0729, 0.0635, 0.0300,
        0.0384, 0.0673, 0.0496, 0.0531, 0.0595, 0.0626, 0.0470],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,342][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1931, 0.0336, 0.0173, 0.0394, 0.0620, 0.0173, 0.1272, 0.0148, 0.0236,
        0.0697, 0.0200, 0.0433, 0.1858, 0.0123, 0.0729, 0.0529, 0.0147],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,344][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.8639e-03, 1.3412e-04, 1.7568e-02, 1.5676e-05, 2.1395e-04, 7.1501e-04,
        9.3605e-06, 8.8263e-03, 8.9400e-04, 3.2751e-05, 4.6300e-03, 5.6190e-05,
        1.4756e-05, 4.6285e-01, 4.0140e-04, 6.5262e-04, 5.0012e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,346][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1479, 0.0308, 0.0740, 0.0194, 0.0421, 0.0193, 0.0177, 0.1020, 0.0214,
        0.0463, 0.0467, 0.0287, 0.0530, 0.1303, 0.0547, 0.0266, 0.1394],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,347][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.6398e-03, 9.8258e-06, 4.0780e-05, 2.7263e-06, 8.5028e-05, 1.4147e-04,
        2.2947e-04, 2.4138e-04, 9.9470e-04, 5.5908e-05, 2.5224e-03, 3.1490e-04,
        6.2126e-03, 4.7920e-02, 4.0170e-01, 9.8676e-02, 4.3921e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,347][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.3378e-02, 9.3682e-04, 1.2188e-03, 3.1092e-04, 1.4692e-02, 2.5091e-03,
        7.8033e-03, 4.5566e-03, 3.5157e-03, 4.4844e-03, 4.9861e-03, 6.6057e-03,
        4.3028e-01, 4.9788e-02, 2.3327e-01, 6.1963e-02, 1.5970e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,348][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.6955e-02, 5.0233e-03, 6.1375e-02, 2.1437e-04, 3.5753e-02, 1.5456e-01,
        3.7246e-04, 1.5438e-02, 1.2541e-01, 3.3178e-04, 1.1390e-02, 1.0102e-03,
        3.9461e-03, 2.5852e-01, 9.0149e-03, 5.2452e-02, 2.3824e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,349][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0669, 0.0490, 0.0033, 0.0241, 0.0312, 0.0028, 0.0681, 0.0129, 0.0023,
        0.0694, 0.0028, 0.0729, 0.0981, 0.1973, 0.0530, 0.0074, 0.2384],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,351][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0209, 0.0022, 0.0032, 0.0036, 0.0043, 0.0045, 0.0082, 0.0079, 0.0126,
        0.0095, 0.0334, 0.0377, 0.0958, 0.0706, 0.1467, 0.2599, 0.2788],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,353][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0119, 0.0018, 0.0696, 0.0024, 0.0120, 0.0922, 0.0055, 0.0337, 0.1452,
        0.0116, 0.1252, 0.0029, 0.0055, 0.1719, 0.0140, 0.0889, 0.2058],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,355][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1220, 0.0353, 0.0725, 0.0301, 0.0438, 0.0589, 0.0308, 0.0603, 0.0632,
        0.0421, 0.0612, 0.0343, 0.0470, 0.0817, 0.0554, 0.0720, 0.0895],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,356][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0910, 0.0307, 0.0806, 0.0240, 0.0511, 0.0713, 0.0221, 0.0675, 0.0672,
        0.0359, 0.0655, 0.0273, 0.0412, 0.0989, 0.0493, 0.0764, 0.1003],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,358][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1493, 0.0452, 0.0672, 0.0674, 0.0536, 0.0427, 0.0653, 0.0652, 0.0316,
        0.0366, 0.0636, 0.0458, 0.0525, 0.0641, 0.0512, 0.0336, 0.0651],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,362][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:31,364][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 9691],
        [31453],
        [24107],
        [    1],
        [36292],
        [33235],
        [22073],
        [29883],
        [36413],
        [19946],
        [11208],
        [25808],
        [17892],
        [17554],
        [15903],
        [38112],
        [17897]], device='cuda:0')
[2024-07-24 10:29:31,365][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[44266],
        [26286],
        [40666],
        [    1],
        [45492],
        [36682],
        [35308],
        [39007],
        [31729],
        [38621],
        [37570],
        [15661],
        [40743],
        [38326],
        [30809],
        [28524],
        [35333]], device='cuda:0')
[2024-07-24 10:29:31,367][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[2840],
        [4302],
        [3389],
        [5767],
        [7613],
        [6961],
        [5218],
        [2739],
        [1671],
        [5482],
        [1513],
        [5705],
        [3785],
        [1554],
        [2275],
        [1553],
        [1970]], device='cuda:0')
[2024-07-24 10:29:31,369][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[43681],
        [35716],
        [34822],
        [ 1257],
        [28908],
        [47095],
        [41409],
        [26583],
        [48131],
        [13890],
        [12318],
        [33002],
        [11675],
        [24060],
        [20466],
        [48274],
        [23433]], device='cuda:0')
[2024-07-24 10:29:31,371][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[23309],
        [22829],
        [28575],
        [23802],
        [27059],
        [27526],
        [27033],
        [30631],
        [31947],
        [30454],
        [26153],
        [27799],
        [30276],
        [36686],
        [34231],
        [33951],
        [37434]], device='cuda:0')
[2024-07-24 10:29:31,373][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[28600],
        [12372],
        [18607],
        [10522],
        [ 8102],
        [24732],
        [10383],
        [39080],
        [37885],
        [22774],
        [37928],
        [12063],
        [12965],
        [28117],
        [13759],
        [37796],
        [25576]], device='cuda:0')
[2024-07-24 10:29:31,375][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[39627],
        [15222],
        [27491],
        [  365],
        [34862],
        [29479],
        [44345],
        [39697],
        [31986],
        [ 5691],
        [16872],
        [12616],
        [32204],
        [32320],
        [20778],
        [27224],
        [28120]], device='cuda:0')
[2024-07-24 10:29:31,377][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[24568],
        [39772],
        [21394],
        [ 2400],
        [30072],
        [17508],
        [28082],
        [22468],
        [19889],
        [17696],
        [23026],
        [41559],
        [29239],
        [21349],
        [30773],
        [25486],
        [22464]], device='cuda:0')
[2024-07-24 10:29:31,379][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[32767],
        [25952],
        [22394],
        [13011],
        [ 2741],
        [ 3452],
        [ 5058],
        [ 2337],
        [ 2788],
        [ 2823],
        [ 2644],
        [ 4866],
        [ 3883],
        [11229],
        [ 4196],
        [ 6185],
        [12194]], device='cuda:0')
[2024-07-24 10:29:31,381][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 9576],
        [ 9537],
        [16546],
        [18401],
        [16277],
        [24953],
        [28412],
        [20005],
        [30200],
        [34012],
        [15257],
        [12918],
        [ 7005],
        [10380],
        [17404],
        [28101],
        [29722]], device='cuda:0')
[2024-07-24 10:29:31,382][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[17144],
        [20912],
        [22516],
        [21872],
        [21313],
        [24337],
        [29146],
        [23468],
        [17538],
        [19864],
        [18530],
        [23506],
        [19131],
        [17726],
        [18302],
        [17944],
        [17837]], device='cuda:0')
[2024-07-24 10:29:31,384][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[40655],
        [40467],
        [43310],
        [41946],
        [40156],
        [38996],
        [37921],
        [39866],
        [38775],
        [35292],
        [39582],
        [36574],
        [37152],
        [40832],
        [38817],
        [39519],
        [40954]], device='cuda:0')
[2024-07-24 10:29:31,385][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[  187],
        [ 3971],
        [  340],
        [ 6174],
        [  488],
        [ 7299],
        [10463],
        [ 1425],
        [ 8600],
        [17587],
        [ 4324],
        [31264],
        [ 3202],
        [ 3505],
        [ 3432],
        [19615],
        [ 4076]], device='cuda:0')
[2024-07-24 10:29:31,387][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[42477],
        [36540],
        [32186],
        [19388],
        [27705],
        [26509],
        [18624],
        [24082],
        [25437],
        [24073],
        [23432],
        [15817],
        [26469],
        [18229],
        [21373],
        [20404],
        [17551]], device='cuda:0')
[2024-07-24 10:29:31,389][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[45140],
        [46985],
        [44050],
        [    7],
        [50019],
        [49772],
        [34395],
        [45155],
        [50121],
        [42677],
        [33698],
        [46346],
        [42888],
        [40797],
        [37480],
        [49625],
        [40588]], device='cuda:0')
[2024-07-24 10:29:31,391][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[46179],
        [46689],
        [46395],
        [33682],
        [41761],
        [43228],
        [36624],
        [40778],
        [42597],
        [40255],
        [43185],
        [39070],
        [43855],
        [41013],
        [42085],
        [42383],
        [40845]], device='cuda:0')
[2024-07-24 10:29:31,392][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 9817],
        [22521],
        [10758],
        [37668],
        [25016],
        [ 4420],
        [18771],
        [16908],
        [ 4545],
        [26316],
        [19755],
        [23982],
        [28731],
        [ 9541],
        [19469],
        [ 6206],
        [ 9127]], device='cuda:0')
[2024-07-24 10:29:31,394][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[47725],
        [47769],
        [48418],
        [48157],
        [48205],
        [48681],
        [48527],
        [47247],
        [46782],
        [47202],
        [39812],
        [46624],
        [47831],
        [43947],
        [46558],
        [46741],
        [43215]], device='cuda:0')
[2024-07-24 10:29:31,396][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[  983],
        [10746],
        [12105],
        [ 5486],
        [ 9758],
        [14669],
        [ 7573],
        [26971],
        [21544],
        [ 6997],
        [20445],
        [13654],
        [15633],
        [31599],
        [17715],
        [17860],
        [21832]], device='cuda:0')
[2024-07-24 10:29:31,398][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[  561],
        [ 9929],
        [ 2616],
        [ 8252],
        [ 2170],
        [ 3147],
        [11325],
        [ 5306],
        [ 4330],
        [36908],
        [ 7179],
        [11444],
        [12501],
        [11895],
        [13488],
        [ 8000],
        [10966]], device='cuda:0')
[2024-07-24 10:29:31,400][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[12919],
        [ 1833],
        [18209],
        [ 8499],
        [ 5506],
        [11928],
        [ 4651],
        [11367],
        [12035],
        [ 4467],
        [10820],
        [ 1068],
        [ 3333],
        [ 8812],
        [ 1293],
        [ 7181],
        [ 7623]], device='cuda:0')
[2024-07-24 10:29:31,402][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[47652],
        [49329],
        [49349],
        [41324],
        [44829],
        [47068],
        [32469],
        [25231],
        [28653],
        [25504],
        [23732],
        [42277],
        [40591],
        [49858],
        [35938],
        [44630],
        [49481]], device='cuda:0')
[2024-07-24 10:29:31,403][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[41625],
        [41698],
        [40902],
        [35391],
        [31429],
        [29572],
        [26351],
        [25530],
        [25635],
        [28598],
        [29495],
        [29573],
        [30732],
        [27199],
        [19464],
        [18355],
        [16736]], device='cuda:0')
[2024-07-24 10:29:31,405][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[23154],
        [24570],
        [35643],
        [29760],
        [33227],
        [33793],
        [32316],
        [33035],
        [26758],
        [32011],
        [22237],
        [31299],
        [32423],
        [24968],
        [36179],
        [30354],
        [27438]], device='cuda:0')
[2024-07-24 10:29:31,407][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[34436],
        [34248],
        [32531],
        [31261],
        [34669],
        [34444],
        [34143],
        [35801],
        [35571],
        [34622],
        [33614],
        [32634],
        [34082],
        [34420],
        [34761],
        [34728],
        [34762]], device='cuda:0')
[2024-07-24 10:29:31,409][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[50003],
        [49951],
        [50190],
        [50036],
        [50071],
        [50026],
        [49970],
        [50069],
        [49939],
        [50048],
        [50129],
        [49869],
        [50030],
        [50054],
        [50091],
        [50003],
        [50045]], device='cuda:0')
[2024-07-24 10:29:31,411][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 7449],
        [19723],
        [37377],
        [49288],
        [47513],
        [49226],
        [49278],
        [46290],
        [47794],
        [45493],
        [48449],
        [46553],
        [46724],
        [48214],
        [47544],
        [45524],
        [46808]], device='cuda:0')
[2024-07-24 10:29:31,413][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[1939],
        [1002],
        [ 773],
        [1718],
        [1597],
        [1572],
        [2211],
        [2727],
        [3253],
        [1979],
        [2467],
        [3117],
        [1848],
        [1791],
        [2163],
        [2579],
        [2171]], device='cuda:0')
[2024-07-24 10:29:31,415][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 3351],
        [ 3198],
        [ 4949],
        [50221],
        [  223],
        [  350],
        [13706],
        [ 3853],
        [  125],
        [ 6274],
        [13883],
        [ 3721],
        [ 6185],
        [ 7811],
        [11092],
        [  691],
        [ 7917]], device='cuda:0')
[2024-07-24 10:29:31,416][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973]], device='cuda:0')
[2024-07-24 10:29:31,437][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:31,438][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,440][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,441][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,442][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,442][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,443][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,444][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,445][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,445][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,446][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,447][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,447][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,449][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Sara] are: tensor([0.6236, 0.3764], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,451][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Sara] are: tensor([0.7302, 0.2698], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,452][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Sara] are: tensor([0.5025, 0.4975], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,454][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Sara] are: tensor([0.5132, 0.4868], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,455][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Sara] are: tensor([0.1791, 0.8209], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,457][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Sara] are: tensor([0.1889, 0.8111], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,459][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Sara] are: tensor([0.0317, 0.9683], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,460][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Sara] are: tensor([0.0266, 0.9734], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,462][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Sara] are: tensor([0.9668, 0.0332], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,463][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Sara] are: tensor([0.9767, 0.0233], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,464][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Sara] are: tensor([1.3937e-04, 9.9986e-01], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,465][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Sara] are: tensor([0.0102, 0.9898], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,466][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3282, 0.2395, 0.4322], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,467][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1202, 0.8393, 0.0406], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,467][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3440, 0.3414, 0.3147], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,469][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.4134, 0.4238, 0.1628], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,470][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1262, 0.5594, 0.3144], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,472][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0142, 0.0051, 0.9808], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,474][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6199, 0.3566, 0.0235], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,475][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0763, 0.8628, 0.0609], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,477][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.4756, 0.0167, 0.5077], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,479][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.8231, 0.0092, 0.1677], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,480][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0005, 0.4929, 0.5066], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,482][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.3672, 0.0015, 0.6313], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,483][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Kenneth] are: tensor([0.2857, 0.1617, 0.3834, 0.1691], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,485][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Kenneth] are: tensor([0.0797, 0.3370, 0.2502, 0.3331], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,487][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Kenneth] are: tensor([0.2551, 0.2533, 0.2362, 0.2554], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,488][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Kenneth] are: tensor([0.3708, 0.2552, 0.1751, 0.1989], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,490][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Kenneth] are: tensor([0.0806, 0.4129, 0.2389, 0.2676], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,492][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Kenneth] are: tensor([0.0157, 0.3605, 0.3513, 0.2725], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,493][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Kenneth] are: tensor([0.3418, 0.0682, 0.5610, 0.0289], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,495][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Kenneth] are: tensor([0.0176, 0.7987, 0.0759, 0.1078], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,497][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Kenneth] are: tensor([0.4847, 0.0237, 0.4741, 0.0175], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,498][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Kenneth] are: tensor([0.7141, 0.0210, 0.2317, 0.0332], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,499][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Kenneth] are: tensor([0.0005, 0.3087, 0.4697, 0.2210], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,500][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Kenneth] are: tensor([1.4986e-02, 3.4967e-04, 2.5655e-02, 9.5901e-01], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,500][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.1579, 0.1096, 0.2311, 0.1238, 0.3776], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,501][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.0796, 0.3030, 0.0822, 0.3287, 0.2065], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,503][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.1929, 0.1917, 0.1772, 0.1889, 0.2493], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,504][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.3029, 0.2042, 0.1082, 0.1816, 0.2030], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,506][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.0652, 0.3128, 0.1806, 0.2157, 0.2257], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,508][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.1341, 0.0132, 0.1193, 0.0914, 0.6421], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,509][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.5925, 0.2793, 0.0938, 0.0067, 0.0276], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,511][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.0052, 0.2052, 0.0153, 0.1668, 0.6076], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,513][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.4890, 0.0219, 0.4014, 0.0151, 0.0726], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,514][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.7158, 0.0260, 0.1868, 0.0399, 0.0315], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,516][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.0005, 0.2177, 0.3122, 0.2032, 0.2664], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,517][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ got] are: tensor([3.1165e-03, 2.7315e-05, 3.5048e-03, 3.9940e-05, 9.9331e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,519][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0731, 0.0527, 0.1029, 0.0605, 0.1725, 0.5383], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,520][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1526, 0.0880, 0.0679, 0.3405, 0.3178, 0.0332], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,522][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1578, 0.1569, 0.1448, 0.1508, 0.2009, 0.1888], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,523][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2456, 0.1767, 0.0812, 0.1971, 0.1794, 0.1200], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,525][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0600, 0.2469, 0.1524, 0.1868, 0.1983, 0.1555], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,527][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0254, 0.1345, 0.6163, 0.1205, 0.0265, 0.0768], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,528][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1646, 0.3005, 0.0097, 0.4263, 0.0807, 0.0182], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,530][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0140, 0.2285, 0.0120, 0.2504, 0.4654, 0.0297], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,532][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.3534, 0.0191, 0.2964, 0.0120, 0.0570, 0.2622], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,533][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.6877, 0.0203, 0.1386, 0.0304, 0.0243, 0.0987], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,533][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0006, 0.1848, 0.2205, 0.1660, 0.1980, 0.2300], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,534][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.2468e-02, 3.5491e-04, 5.7095e-03, 4.5185e-04, 1.1038e-03, 9.7991e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,535][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.0479, 0.0278, 0.0759, 0.0329, 0.1278, 0.5482, 0.1396],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,537][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.0317, 0.0914, 0.0938, 0.2496, 0.3011, 0.1674, 0.0651],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,538][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.1343, 0.1335, 0.1204, 0.1240, 0.1626, 0.1519, 0.1732],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,540][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.2252, 0.1715, 0.1010, 0.1496, 0.1550, 0.0921, 0.1055],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,542][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.0449, 0.2300, 0.1360, 0.1486, 0.1612, 0.1265, 0.1528],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,543][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([7.8922e-05, 3.3067e-02, 4.2074e-04, 2.1876e-02, 4.4046e-03, 8.5243e-04,
        9.3930e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,544][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([3.9375e-04, 3.8894e-03, 1.5127e-03, 2.5968e-03, 1.8972e-04, 4.8771e-04,
        9.9093e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,546][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.0075, 0.2504, 0.0116, 0.1687, 0.4539, 0.0711, 0.0368],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,547][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.2978, 0.0184, 0.2578, 0.0105, 0.0534, 0.2636, 0.0986],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,549][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.3942, 0.0171, 0.1485, 0.0399, 0.0840, 0.2963, 0.0201],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,551][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.0004, 0.1480, 0.2023, 0.1330, 0.1654, 0.1711, 0.1799],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,552][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([1.7266e-02, 4.0830e-03, 2.1715e-02, 9.4011e-04, 6.1836e-04, 2.0963e-03,
        9.5328e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,554][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0514, 0.0377, 0.0693, 0.0433, 0.1129, 0.3460, 0.1346, 0.2048],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,555][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0182, 0.0811, 0.0349, 0.1591, 0.2688, 0.0795, 0.3500, 0.0084],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,557][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1123, 0.1114, 0.1002, 0.1055, 0.1419, 0.1371, 0.1568, 0.1348],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,559][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.2093, 0.1391, 0.0700, 0.1422, 0.1574, 0.0800, 0.1077, 0.0944],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,560][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0441, 0.1887, 0.1094, 0.1417, 0.1457, 0.1105, 0.1424, 0.1175],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,562][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.2883, 0.0278, 0.2266, 0.0560, 0.0047, 0.0542, 0.0797, 0.2627],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,564][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.3642, 0.0560, 0.0154, 0.0336, 0.0321, 0.0421, 0.4540, 0.0026],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,565][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0101, 0.1862, 0.0079, 0.1328, 0.2239, 0.0235, 0.3983, 0.0172],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,566][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.3074, 0.0185, 0.2689, 0.0113, 0.0527, 0.2382, 0.0886, 0.0144],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,567][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.6615, 0.0187, 0.0947, 0.0288, 0.0232, 0.0938, 0.0288, 0.0504],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,568][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0005, 0.1184, 0.1385, 0.1152, 0.1441, 0.1329, 0.1907, 0.1595],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,569][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ at] are: tensor([4.4318e-03, 6.9523e-05, 4.8815e-03, 1.4762e-03, 7.5652e-04, 3.9827e-04,
        1.1303e-04, 9.8787e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,570][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0359, 0.0271, 0.0512, 0.0318, 0.0868, 0.2644, 0.1001, 0.1539, 0.2487],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,572][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0261, 0.0634, 0.0576, 0.0953, 0.2171, 0.0571, 0.1540, 0.3189, 0.0105],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,574][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1025, 0.1017, 0.0918, 0.0961, 0.1264, 0.1210, 0.1382, 0.1188, 0.1035],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,576][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1755, 0.1221, 0.0597, 0.1459, 0.1425, 0.0840, 0.1108, 0.0794, 0.0801],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,577][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0392, 0.1640, 0.0961, 0.1256, 0.1316, 0.0987, 0.1385, 0.1029, 0.1034],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,578][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ the] are: tensor([2.2712e-02, 5.7694e-02, 2.2692e-01, 9.1406e-02, 1.2523e-02, 2.0040e-02,
        4.1194e-01, 1.2105e-04, 1.5665e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,580][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1569, 0.0137, 0.0064, 0.1063, 0.0112, 0.0051, 0.6914, 0.0024, 0.0066],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,582][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0076, 0.2002, 0.0054, 0.1122, 0.3369, 0.0228, 0.2731, 0.0210, 0.0207],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,584][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.2641, 0.0166, 0.2415, 0.0098, 0.0428, 0.2069, 0.0776, 0.0124, 0.1283],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,585][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.5541, 0.0251, 0.1081, 0.0286, 0.0274, 0.0700, 0.0499, 0.0366, 0.1003],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,587][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0006, 0.0940, 0.1153, 0.0988, 0.1155, 0.1281, 0.1649, 0.1318, 0.1510],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,588][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ the] are: tensor([3.2965e-02, 6.2057e-04, 2.0653e-02, 5.7780e-03, 2.6440e-03, 1.0346e-02,
        5.4738e-03, 7.0481e-03, 9.1447e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,590][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ garden] are: tensor([0.0285, 0.0166, 0.0413, 0.0184, 0.0681, 0.2827, 0.0711, 0.1389, 0.2521,
        0.0824], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,592][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ garden] are: tensor([0.0125, 0.0409, 0.0578, 0.1090, 0.1739, 0.0508, 0.1146, 0.3242, 0.0962,
        0.0202], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,593][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ garden] are: tensor([0.0913, 0.0906, 0.0813, 0.0855, 0.1126, 0.1084, 0.1242, 0.1073, 0.0937,
        0.1051], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,595][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ garden] are: tensor([0.1801, 0.1242, 0.0765, 0.1282, 0.1323, 0.0698, 0.0938, 0.0868, 0.0590,
        0.0494], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,597][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ garden] are: tensor([0.0314, 0.1616, 0.0934, 0.1073, 0.1110, 0.0905, 0.1125, 0.0961, 0.0942,
        0.1020], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,598][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ garden] are: tensor([8.2801e-05, 7.8664e-03, 5.8379e-04, 8.7311e-03, 2.4576e-04, 2.7509e-03,
        9.5545e-01, 2.2948e-05, 1.4437e-02, 9.8319e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,600][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ garden] are: tensor([0.3088, 0.0478, 0.1276, 0.0034, 0.0103, 0.1435, 0.0251, 0.0016, 0.0555,
        0.2763], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,601][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ garden] are: tensor([0.0048, 0.2417, 0.0068, 0.1643, 0.2021, 0.0837, 0.2358, 0.0202, 0.0390,
        0.0016], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,601][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ garden] are: tensor([0.2279, 0.0182, 0.2320, 0.0100, 0.0448, 0.2142, 0.0903, 0.0118, 0.1314,
        0.0194], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,602][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ garden] are: tensor([0.4127, 0.0245, 0.0973, 0.0474, 0.0725, 0.0737, 0.0383, 0.1005, 0.1128,
        0.0202], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,604][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ garden] are: tensor([0.0003, 0.1073, 0.1419, 0.0862, 0.1053, 0.1077, 0.1323, 0.1280, 0.1073,
        0.0839], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,605][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ garden] are: tensor([7.0475e-03, 1.4428e-03, 3.9841e-03, 1.9185e-04, 1.1804e-03, 1.7837e-03,
        1.0013e-03, 3.7828e-04, 5.2868e-04, 9.8246e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,607][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0253, 0.0189, 0.0351, 0.0217, 0.0598, 0.1942, 0.0715, 0.1098, 0.1833,
        0.0803, 0.2002], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,609][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0101, 0.0573, 0.0329, 0.1175, 0.2098, 0.0371, 0.2086, 0.1014, 0.0269,
        0.1821, 0.0161], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,610][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0844, 0.0839, 0.0735, 0.0738, 0.1030, 0.0960, 0.1084, 0.0954, 0.0824,
        0.0932, 0.1059], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,612][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1581, 0.1053, 0.0554, 0.1200, 0.1363, 0.0704, 0.0951, 0.0804, 0.0590,
        0.0546, 0.0653], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,614][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0334, 0.1368, 0.0804, 0.1036, 0.1101, 0.0809, 0.1070, 0.0853, 0.0834,
        0.0979, 0.0812], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,615][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([8.6909e-03, 1.7495e-02, 2.6852e-01, 2.3664e-02, 8.0556e-03, 1.1446e-02,
        5.2970e-01, 4.8621e-05, 1.2148e-01, 1.7834e-03, 9.1144e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,617][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2663, 0.0302, 0.0032, 0.0255, 0.0136, 0.0221, 0.6067, 0.0038, 0.0194,
        0.0008, 0.0085], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,618][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0137, 0.1542, 0.0188, 0.1858, 0.2433, 0.0357, 0.1909, 0.0494, 0.0371,
        0.0476, 0.0235], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,620][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2243, 0.0105, 0.2797, 0.0074, 0.0373, 0.1698, 0.0520, 0.0099, 0.1187,
        0.0141, 0.0763], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,622][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.4573, 0.0277, 0.0893, 0.0278, 0.0261, 0.0545, 0.0469, 0.0341, 0.0774,
        0.0286, 0.1304], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,624][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0005, 0.0719, 0.0929, 0.0786, 0.0964, 0.0878, 0.1260, 0.1050, 0.1008,
        0.0846, 0.1553], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,626][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2186, 0.0537, 0.1458, 0.0471, 0.0507, 0.0278, 0.0752, 0.0428, 0.0425,
        0.0772, 0.2186], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,627][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Sara] are: tensor([0.0266, 0.0140, 0.0349, 0.0150, 0.0552, 0.2004, 0.0491, 0.1120, 0.1995,
        0.0663, 0.2079, 0.0191], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,629][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Sara] are: tensor([0.0305, 0.0157, 0.0597, 0.2075, 0.1539, 0.0436, 0.1279, 0.1703, 0.0405,
        0.0280, 0.0884, 0.0340], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,631][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Sara] are: tensor([0.0756, 0.0751, 0.0666, 0.0690, 0.0935, 0.0881, 0.1004, 0.0867, 0.0749,
        0.0848, 0.0973, 0.0880], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,633][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Sara] are: tensor([0.1630, 0.1014, 0.0660, 0.1052, 0.1202, 0.0699, 0.0750, 0.0761, 0.0605,
        0.0458, 0.0705, 0.0464], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,633][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Sara] are: tensor([0.0284, 0.1313, 0.0812, 0.0917, 0.0956, 0.0774, 0.0916, 0.0807, 0.0801,
        0.0833, 0.0795, 0.0792], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,634][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Sara] are: tensor([3.2374e-03, 1.7058e-02, 1.5373e-02, 5.8459e-01, 2.2606e-04, 8.5573e-03,
        2.7499e-01, 9.5083e-04, 6.2487e-02, 4.1606e-03, 2.2079e-03, 2.6158e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,635][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Sara] are: tensor([0.0018, 0.0930, 0.0024, 0.0447, 0.0029, 0.0068, 0.7469, 0.0023, 0.0022,
        0.0008, 0.0028, 0.0933], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,636][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Sara] are: tensor([0.0027, 0.1693, 0.0178, 0.1803, 0.1538, 0.0507, 0.1057, 0.0313, 0.0640,
        0.0648, 0.0163, 0.1433], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,638][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Sara] are: tensor([0.2298, 0.0121, 0.2025, 0.0068, 0.0377, 0.2035, 0.0762, 0.0093, 0.1160,
        0.0160, 0.0593, 0.0307], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,640][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Sara] are: tensor([0.1225, 0.0216, 0.0473, 0.0266, 0.0342, 0.1484, 0.0240, 0.1810, 0.1451,
        0.0327, 0.1865, 0.0300], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,641][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Sara] are: tensor([0.0007, 0.0588, 0.1018, 0.0693, 0.0957, 0.0917, 0.1056, 0.1078, 0.1028,
        0.0742, 0.1475, 0.0441], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,643][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Sara] are: tensor([1.9884e-05, 4.3782e-01, 3.0658e-05, 2.6920e-04, 1.5043e-05, 6.1230e-05,
        3.7324e-04, 2.5968e-05, 1.4212e-05, 1.0885e-04, 2.0205e-03, 5.5924e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,644][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0197, 0.0132, 0.0283, 0.0153, 0.0475, 0.1743, 0.0576, 0.0982, 0.1732,
        0.0692, 0.1908, 0.0223, 0.0905], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,646][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0163, 0.0466, 0.0462, 0.1424, 0.0944, 0.0445, 0.1097, 0.0225, 0.0256,
        0.1075, 0.0975, 0.2185, 0.0283], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,648][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0689, 0.0684, 0.0610, 0.0626, 0.0867, 0.0807, 0.0911, 0.0793, 0.0680,
        0.0773, 0.0860, 0.0784, 0.0917], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,650][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.1490, 0.0964, 0.0524, 0.1018, 0.1177, 0.0583, 0.0830, 0.0676, 0.0524,
        0.0478, 0.0589, 0.0456, 0.0691], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,651][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.0258, 0.1185, 0.0702, 0.0860, 0.0905, 0.0672, 0.0872, 0.0736, 0.0705,
        0.0795, 0.0707, 0.0742, 0.0862], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,653][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([8.1225e-03, 1.9515e-04, 2.1023e-03, 9.4080e-03, 4.0607e-02, 7.1272e-04,
        1.2724e-02, 2.0778e-04, 4.1963e-03, 2.1580e-05, 2.9358e-04, 2.3093e-04,
        9.2118e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,654][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([1.9089e-02, 7.5431e-04, 7.0110e-03, 2.8752e-03, 1.4099e-03, 2.6947e-04,
        6.5236e-01, 1.8897e-04, 2.6674e-04, 1.4619e-04, 4.0230e-04, 7.9444e-04,
        3.1443e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,656][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0048, 0.1132, 0.0056, 0.0868, 0.3281, 0.0057, 0.2137, 0.0239, 0.0089,
        0.0171, 0.0054, 0.1082, 0.0785], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,657][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.2368, 0.0158, 0.1977, 0.0081, 0.0382, 0.1812, 0.0742, 0.0100, 0.1137,
        0.0163, 0.0530, 0.0330, 0.0220], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,659][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.1837, 0.0614, 0.0693, 0.0627, 0.0572, 0.0590, 0.0691, 0.0734, 0.0929,
        0.0478, 0.1139, 0.0581, 0.0516], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,661][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0004, 0.0594, 0.0840, 0.0694, 0.0863, 0.0689, 0.1141, 0.0960, 0.0871,
        0.0780, 0.1318, 0.0541, 0.0706], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,662][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([2.1803e-03, 1.3182e-05, 2.1907e-03, 3.9149e-04, 1.4089e-03, 7.9647e-04,
        5.2228e-05, 2.5134e-04, 1.1774e-03, 1.6913e-04, 1.0293e-02, 7.2058e-06,
        9.8107e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,664][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0192, 0.0145, 0.0250, 0.0160, 0.0439, 0.1292, 0.0525, 0.0797, 0.1288,
        0.0618, 0.1393, 0.0237, 0.0769, 0.1894], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,666][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0077, 0.0408, 0.0227, 0.0585, 0.0999, 0.0389, 0.1106, 0.0514, 0.0323,
        0.1111, 0.0275, 0.2095, 0.1863, 0.0028], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,667][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0640, 0.0635, 0.0545, 0.0561, 0.0780, 0.0727, 0.0842, 0.0708, 0.0613,
        0.0694, 0.0768, 0.0697, 0.0826, 0.0965], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,668][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1438, 0.0946, 0.0418, 0.1037, 0.1236, 0.0559, 0.0767, 0.0677, 0.0481,
        0.0452, 0.0522, 0.0436, 0.0681, 0.0350], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,669][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0272, 0.1073, 0.0620, 0.0792, 0.0851, 0.0654, 0.0822, 0.0674, 0.0671,
        0.0777, 0.0646, 0.0736, 0.0815, 0.0598], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,670][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.5489e-03, 1.6138e-03, 1.1463e-02, 4.8281e-02, 1.4293e-03, 5.1862e-04,
        2.6274e-01, 5.8086e-05, 3.4763e-03, 1.7237e-04, 3.5241e-05, 2.7444e-03,
        6.6233e-01, 3.5812e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,671][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([4.2900e-01, 6.0121e-03, 2.3238e-03, 2.4013e-04, 1.6437e-02, 1.3217e-02,
        1.3922e-01, 5.3601e-04, 3.3639e-03, 8.8859e-05, 6.8129e-04, 1.5424e-02,
        3.7274e-01, 7.1433e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,673][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0079, 0.0825, 0.0078, 0.0715, 0.1089, 0.0101, 0.2788, 0.0115, 0.0079,
        0.0206, 0.0136, 0.0745, 0.2977, 0.0065], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,675][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2297, 0.0124, 0.2225, 0.0076, 0.0350, 0.1711, 0.0661, 0.0098, 0.1086,
        0.0140, 0.0578, 0.0285, 0.0213, 0.0155], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,676][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.3754, 0.0177, 0.0338, 0.0217, 0.0373, 0.0788, 0.0357, 0.0284, 0.1013,
        0.0281, 0.0655, 0.0488, 0.0651, 0.0625], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,678][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0009, 0.0524, 0.0710, 0.0601, 0.0754, 0.0771, 0.0931, 0.0841, 0.0788,
        0.0588, 0.1159, 0.0419, 0.0714, 0.1192], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,679][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([4.5449e-02, 3.8541e-04, 8.9984e-02, 1.2126e-03, 1.4246e-03, 5.3186e-03,
        8.8873e-04, 5.2247e-03, 1.2264e-03, 2.9237e-03, 6.7149e-02, 1.0944e-04,
        1.6398e-03, 7.7706e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,681][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0142, 0.0101, 0.0203, 0.0119, 0.0352, 0.1229, 0.0460, 0.0712, 0.1221,
        0.0560, 0.1362, 0.0182, 0.0670, 0.1820, 0.0866], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,682][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0103, 0.0691, 0.0136, 0.0547, 0.0598, 0.0319, 0.1438, 0.0268, 0.0518,
        0.0424, 0.0258, 0.1913, 0.2211, 0.0193, 0.0384], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,684][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0619, 0.0614, 0.0517, 0.0514, 0.0713, 0.0653, 0.0749, 0.0639, 0.0558,
        0.0629, 0.0693, 0.0631, 0.0757, 0.0877, 0.0840], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,686][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.1547, 0.0840, 0.0461, 0.0943, 0.1092, 0.0514, 0.0702, 0.0662, 0.0460,
        0.0401, 0.0562, 0.0387, 0.0620, 0.0341, 0.0468], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,688][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0223, 0.1021, 0.0590, 0.0718, 0.0766, 0.0577, 0.0745, 0.0634, 0.0608,
        0.0681, 0.0609, 0.0654, 0.0785, 0.0540, 0.0848], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,689][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ give] are: tensor([4.2043e-03, 4.8150e-05, 1.2738e-03, 1.7671e-04, 7.3247e-03, 5.5605e-04,
        9.8212e-03, 6.9043e-06, 2.6038e-03, 8.2149e-06, 2.1430e-04, 5.9730e-05,
        4.8584e-01, 4.0760e-06, 4.8785e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,690][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ give] are: tensor([8.3104e-03, 2.6793e-03, 9.2718e-03, 1.0700e-04, 2.6361e-03, 2.4891e-04,
        9.5663e-01, 1.0153e-03, 1.5060e-04, 2.3409e-03, 1.8478e-04, 5.8816e-03,
        2.6907e-03, 6.5260e-04, 7.1972e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,692][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0013, 0.0609, 0.0026, 0.0316, 0.1510, 0.0021, 0.2299, 0.0078, 0.0036,
        0.0334, 0.0021, 0.0479, 0.4045, 0.0022, 0.0191], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,694][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.2265, 0.0128, 0.1971, 0.0073, 0.0361, 0.1690, 0.0667, 0.0099, 0.1124,
        0.0150, 0.0547, 0.0303, 0.0219, 0.0156, 0.0248], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,696][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.2028, 0.0135, 0.0281, 0.0235, 0.0417, 0.1011, 0.0230, 0.0560, 0.1325,
        0.0275, 0.0967, 0.0379, 0.0622, 0.1044, 0.0492], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,698][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0004, 0.0458, 0.0668, 0.0530, 0.0759, 0.0661, 0.0930, 0.0818, 0.0745,
        0.0627, 0.1081, 0.0421, 0.0656, 0.1071, 0.0573], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,699][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ give] are: tensor([5.2170e-04, 5.5011e-06, 6.9192e-04, 1.6642e-05, 1.7512e-03, 1.6589e-05,
        4.9140e-05, 2.8509e-05, 1.6079e-05, 5.5388e-05, 1.1076e-03, 8.0427e-07,
        1.9882e-05, 1.5412e-04, 9.9556e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:31,700][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.0146, 0.0109, 0.0199, 0.0123, 0.0345, 0.1047, 0.0425, 0.0622, 0.1018,
        0.0497, 0.1127, 0.0180, 0.0613, 0.1490, 0.0783, 0.1275],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,701][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ it] are: tensor([0.0061, 0.0340, 0.0149, 0.0334, 0.0625, 0.0280, 0.0585, 0.0318, 0.0088,
        0.0442, 0.0229, 0.1768, 0.1229, 0.0235, 0.3267, 0.0051],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,702][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.0563, 0.0559, 0.0482, 0.0483, 0.0652, 0.0595, 0.0674, 0.0583, 0.0511,
        0.0579, 0.0638, 0.0581, 0.0701, 0.0819, 0.0775, 0.0804],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,704][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ it] are: tensor([0.1391, 0.0843, 0.0411, 0.0948, 0.1015, 0.0517, 0.0687, 0.0569, 0.0472,
        0.0401, 0.0512, 0.0404, 0.0620, 0.0300, 0.0436, 0.0474],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,705][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.0222, 0.0934, 0.0550, 0.0697, 0.0733, 0.0556, 0.0725, 0.0588, 0.0586,
        0.0662, 0.0576, 0.0630, 0.0727, 0.0496, 0.0803, 0.0515],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,707][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ it] are: tensor([4.4132e-04, 8.4598e-04, 6.8528e-04, 5.6446e-04, 4.3664e-04, 4.3902e-04,
        7.0578e-03, 6.6124e-08, 1.0183e-02, 8.3203e-06, 3.4260e-05, 1.8910e-03,
        3.8408e-02, 2.3604e-08, 1.4237e-03, 9.3758e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,708][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ it] are: tensor([1.2045e-02, 8.0112e-04, 2.9722e-04, 4.2555e-04, 1.2866e-04, 9.7398e-05,
        9.8031e-01, 6.3056e-05, 2.1006e-04, 1.1407e-03, 3.1990e-05, 2.2144e-03,
        1.7196e-03, 2.6201e-05, 2.5416e-04, 2.3790e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,710][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.0027, 0.1386, 0.0053, 0.1192, 0.1162, 0.0125, 0.1740, 0.0125, 0.0127,
        0.0199, 0.0062, 0.1172, 0.2128, 0.0026, 0.0270, 0.0209],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,711][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.2358, 0.0140, 0.1779, 0.0076, 0.0349, 0.1658, 0.0660, 0.0101, 0.1106,
        0.0152, 0.0519, 0.0308, 0.0221, 0.0155, 0.0251, 0.0168],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,713][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ it] are: tensor([0.2474, 0.0185, 0.0370, 0.0223, 0.0325, 0.0886, 0.0298, 0.0329, 0.1102,
        0.0242, 0.0837, 0.0432, 0.0653, 0.0741, 0.0402, 0.0503],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,715][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.0008, 0.0395, 0.0578, 0.0539, 0.0625, 0.0702, 0.0889, 0.0703, 0.0750,
        0.0596, 0.1048, 0.0378, 0.0590, 0.0971, 0.0550, 0.0677],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,716][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ it] are: tensor([7.2403e-04, 2.0805e-05, 1.2612e-03, 3.9000e-05, 1.2894e-04, 3.2365e-05,
        1.4035e-04, 1.6085e-04, 2.0829e-04, 5.2442e-05, 3.8037e-03, 7.3696e-06,
        1.5021e-05, 5.6359e-04, 9.2539e-05, 9.9275e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:31,718][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0142, 0.0114, 0.0182, 0.0122, 0.0316, 0.0899, 0.0405, 0.0559, 0.0891,
        0.0461, 0.0964, 0.0184, 0.0549, 0.1261, 0.0686, 0.1077, 0.1188],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,720][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0056, 0.0320, 0.0171, 0.0421, 0.0740, 0.0281, 0.0821, 0.0372, 0.0224,
        0.0781, 0.0203, 0.1543, 0.1350, 0.0020, 0.2118, 0.0554, 0.0024],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,722][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0514, 0.0509, 0.0433, 0.0443, 0.0593, 0.0544, 0.0628, 0.0528, 0.0465,
        0.0526, 0.0598, 0.0533, 0.0647, 0.0761, 0.0741, 0.0775, 0.0762],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,723][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1302, 0.0808, 0.0371, 0.0884, 0.1088, 0.0486, 0.0670, 0.0600, 0.0420,
        0.0398, 0.0468, 0.0381, 0.0597, 0.0316, 0.0450, 0.0416, 0.0346],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,725][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0230, 0.0888, 0.0512, 0.0657, 0.0705, 0.0543, 0.0681, 0.0558, 0.0557,
        0.0642, 0.0536, 0.0613, 0.0676, 0.0496, 0.0782, 0.0484, 0.0441],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,727][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.5907e-03, 1.4880e-03, 1.1575e-02, 4.7308e-02, 1.4584e-03, 4.9436e-04,
        2.3105e-01, 5.9127e-05, 3.3857e-03, 1.4752e-04, 3.3669e-05, 2.5406e-03,
        6.6716e-01, 4.0165e-03, 2.2141e-02, 7.1510e-04, 4.8337e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,728][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([3.2283e-01, 2.8915e-03, 1.8554e-03, 1.4918e-04, 1.0309e-02, 1.1968e-02,
        7.2198e-02, 2.9029e-04, 3.4865e-03, 2.8354e-05, 4.6877e-04, 7.8572e-03,
        1.6163e-01, 5.3787e-04, 3.8039e-01, 2.2597e-02, 5.0105e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,730][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0076, 0.0787, 0.0076, 0.0679, 0.1023, 0.0095, 0.2638, 0.0112, 0.0073,
        0.0196, 0.0130, 0.0712, 0.2738, 0.0064, 0.0411, 0.0132, 0.0059],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,731][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2077, 0.0115, 0.2068, 0.0069, 0.0321, 0.1663, 0.0653, 0.0094, 0.1065,
        0.0138, 0.0560, 0.0285, 0.0203, 0.0158, 0.0232, 0.0155, 0.0145],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,733][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.2816, 0.0179, 0.0294, 0.0221, 0.0327, 0.0827, 0.0356, 0.0237, 0.1004,
        0.0292, 0.0500, 0.0462, 0.0547, 0.0532, 0.0424, 0.0428, 0.0554],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,734][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0011, 0.0387, 0.0563, 0.0485, 0.0598, 0.0636, 0.0766, 0.0700, 0.0654,
        0.0479, 0.0956, 0.0331, 0.0564, 0.0999, 0.0500, 0.0604, 0.0768],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,735][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.7370e-02, 2.7766e-04, 5.1460e-02, 1.1374e-03, 1.2320e-03, 5.2617e-03,
        5.8486e-04, 4.7100e-03, 1.0049e-03, 2.3584e-03, 6.0595e-02, 1.6717e-04,
        1.4073e-03, 4.4786e-01, 1.1956e-03, 5.9388e-04, 3.9278e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:31,763][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:31,765][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,766][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,768][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,769][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,770][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,772][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,773][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,774][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,775][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,775][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,776][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,777][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:31,778][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Sara] are: tensor([0.3089, 0.6911], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,780][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Sara] are: tensor([0.7147, 0.2853], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,781][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Sara] are: tensor([0.8238, 0.1762], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,783][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Sara] are: tensor([0.5687, 0.4313], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,784][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Sara] are: tensor([0.1836, 0.8164], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,786][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Sara] are: tensor([0.7976, 0.2024], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,787][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Sara] are: tensor([0.6904, 0.3096], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,789][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Sara] are: tensor([0.8458, 0.1542], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,790][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Sara] are: tensor([0.9491, 0.0509], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,792][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Sara] are: tensor([0.0200, 0.9800], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,793][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Sara] are: tensor([2.0219e-04, 9.9980e-01], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,795][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Sara] are: tensor([0.0543, 0.9457], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:31,796][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1553, 0.3917, 0.4530], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,798][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1155, 0.8423, 0.0422], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,799][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.5784, 0.1316, 0.2899], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,801][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.4453, 0.3426, 0.2121], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,802][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1247, 0.5447, 0.3306], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,804][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.7011, 0.0144, 0.2845], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,806][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.7072, 0.1345, 0.1583], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,807][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.6700, 0.1987, 0.1312], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,808][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.4482, 0.0112, 0.5407], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,809][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0087, 0.4716, 0.5197], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,810][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0007, 0.5445, 0.4548], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,810][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.3178, 0.0021, 0.6801], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:31,812][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Kenneth] are: tensor([0.1197, 0.2949, 0.4170, 0.1684], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,813][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Kenneth] are: tensor([0.1158, 0.3711, 0.2947, 0.2184], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,815][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Kenneth] are: tensor([0.4158, 0.0953, 0.2190, 0.2699], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,817][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Kenneth] are: tensor([0.3908, 0.2090, 0.1906, 0.2096], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,818][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Kenneth] are: tensor([0.0738, 0.3806, 0.2370, 0.3086], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,820][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Kenneth] are: tensor([0.2146, 0.4168, 0.3373, 0.0313], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,821][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Kenneth] are: tensor([0.7887, 0.0518, 0.1416, 0.0179], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,823][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Kenneth] are: tensor([0.6657, 0.1348, 0.1527, 0.0468], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,825][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Kenneth] are: tensor([0.4948, 0.1275, 0.3746, 0.0031], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,826][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Kenneth] are: tensor([0.0083, 0.4332, 0.4081, 0.1504], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,828][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Kenneth] are: tensor([0.0007, 0.3132, 0.3422, 0.3440], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,829][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Kenneth] are: tensor([1.7866e-02, 7.4877e-04, 4.1626e-03, 9.7722e-01], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:31,831][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.0909, 0.2433, 0.3619, 0.1278, 0.1761], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,832][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.1241, 0.3771, 0.1093, 0.2265, 0.1630], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,834][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.3147, 0.0767, 0.1660, 0.2121, 0.2304], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,836][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.3078, 0.1511, 0.1143, 0.1954, 0.2314], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,837][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.0588, 0.2835, 0.1774, 0.2453, 0.2350], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,839][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.7604, 0.0185, 0.1299, 0.0238, 0.0675], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,841][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.5992, 0.2012, 0.1093, 0.0275, 0.0627], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,841][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.5308, 0.1296, 0.0744, 0.1605, 0.1047], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,842][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.2668, 0.0206, 0.3385, 0.0015, 0.3726], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,843][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.0073, 0.3739, 0.3240, 0.1434, 0.1514], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,844][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.0007, 0.1982, 0.2016, 0.2697, 0.3297], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,845][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([2.0276e-02, 6.1725e-04, 1.2562e-02, 1.3534e-03, 9.6519e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:31,846][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0780, 0.1876, 0.2576, 0.0953, 0.1293, 0.2522], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,848][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.2902, 0.1038, 0.0911, 0.2334, 0.2616, 0.0199], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,850][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2517, 0.0639, 0.1365, 0.1715, 0.1854, 0.1910], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,851][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.2312, 0.1263, 0.0839, 0.2144, 0.2003, 0.1438], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,853][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0542, 0.2234, 0.1477, 0.2066, 0.2025, 0.1656], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,854][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.5184, 0.0593, 0.0768, 0.0322, 0.1403, 0.1730], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,856][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2833, 0.1881, 0.1452, 0.1603, 0.1238, 0.0992], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,858][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.3796, 0.1338, 0.0723, 0.1421, 0.1334, 0.1388], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,859][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([2.4201e-02, 1.7632e-03, 3.2882e-02, 1.1519e-04, 3.0541e-02, 9.1050e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,860][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0067, 0.3336, 0.2966, 0.1327, 0.1267, 0.1038], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,862][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0007, 0.1567, 0.1446, 0.2073, 0.2475, 0.2432], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,863][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([8.4208e-03, 3.5358e-04, 7.7543e-03, 7.3723e-04, 1.3072e-03, 9.8143e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:31,865][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.0528, 0.1382, 0.2365, 0.0827, 0.1161, 0.2794, 0.0943],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,866][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.0601, 0.1178, 0.1425, 0.1909, 0.2878, 0.1574, 0.0434],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,868][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.2009, 0.0488, 0.1107, 0.1436, 0.1567, 0.1620, 0.1772],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,870][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.1964, 0.1271, 0.0999, 0.1769, 0.1805, 0.1007, 0.1185],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,872][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.0385, 0.2001, 0.1275, 0.1621, 0.1606, 0.1314, 0.1797],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,873][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.1853, 0.0712, 0.0499, 0.0348, 0.1517, 0.4288, 0.0783],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,875][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.3766, 0.1506, 0.0751, 0.0993, 0.0803, 0.1221, 0.0960],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,876][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.3542, 0.0632, 0.0633, 0.0742, 0.2480, 0.1694, 0.0278],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,877][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([2.1699e-02, 2.9153e-03, 2.4232e-02, 1.5837e-04, 4.7859e-02, 7.9070e-01,
        1.1244e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,877][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.0055, 0.2880, 0.2440, 0.1088, 0.1151, 0.0971, 0.1415],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,878][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.0005, 0.1199, 0.1216, 0.1520, 0.1779, 0.1673, 0.2609],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,879][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([1.0504e-02, 7.9498e-03, 5.5837e-03, 2.2678e-03, 3.9839e-04, 1.1768e-03,
        9.7212e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:31,881][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0696, 0.1480, 0.2134, 0.0772, 0.1047, 0.2150, 0.0903, 0.0818],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,883][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0410, 0.1146, 0.0643, 0.1355, 0.2894, 0.0842, 0.2658, 0.0053],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,884][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1778, 0.0438, 0.0916, 0.1194, 0.1269, 0.1283, 0.1466, 0.1656],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,886][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.1951, 0.0933, 0.0703, 0.1417, 0.1665, 0.0878, 0.1219, 0.1234],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,888][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0381, 0.1640, 0.1026, 0.1512, 0.1436, 0.1141, 0.1638, 0.1226],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,889][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([2.3094e-02, 4.3046e-04, 2.1633e-03, 4.6346e-04, 2.9061e-03, 3.1657e-02,
        6.5766e-04, 9.3863e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,891][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.2187, 0.1288, 0.0552, 0.1511, 0.0371, 0.0576, 0.3335, 0.0179],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,892][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.2806, 0.1139, 0.0542, 0.1132, 0.0962, 0.0845, 0.1680, 0.0893],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,893][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([2.5961e-02, 1.2830e-03, 2.8730e-02, 7.5784e-05, 2.6065e-02, 8.3605e-01,
        7.7961e-02, 3.8728e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,895][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0044, 0.2145, 0.1898, 0.0916, 0.0871, 0.0757, 0.1088, 0.2281],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,897][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0007, 0.0838, 0.0753, 0.1159, 0.1425, 0.1236, 0.2526, 0.2055],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,898][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([1.3351e-02, 4.7454e-04, 1.4977e-02, 4.9898e-03, 2.2423e-03, 8.3018e-03,
        9.4571e-04, 9.5472e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:31,899][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0597, 0.1287, 0.1815, 0.0675, 0.0933, 0.1884, 0.0807, 0.0729, 0.1274],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,901][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0606, 0.0819, 0.1049, 0.0771, 0.2207, 0.0587, 0.1117, 0.2790, 0.0054],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,903][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1468, 0.0379, 0.0787, 0.1017, 0.1087, 0.1092, 0.1260, 0.1393, 0.1518],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,905][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.1524, 0.0790, 0.0577, 0.1448, 0.1462, 0.0917, 0.1209, 0.1000, 0.1074],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,906][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0333, 0.1414, 0.0888, 0.1321, 0.1283, 0.1001, 0.1559, 0.1058, 0.1144],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,908][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.2231, 0.0684, 0.0329, 0.0333, 0.0660, 0.1706, 0.0408, 0.2585, 0.1065],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,910][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2039, 0.1415, 0.1130, 0.0897, 0.0860, 0.0773, 0.1025, 0.0965, 0.0897],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,911][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.2483, 0.1049, 0.0449, 0.0668, 0.0709, 0.0912, 0.1427, 0.0826, 0.1478],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,913][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([7.6532e-03, 4.5398e-04, 9.5726e-03, 2.5515e-05, 7.6118e-03, 3.0066e-01,
        2.6830e-02, 1.2897e-03, 6.4591e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,914][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0037, 0.1995, 0.1754, 0.0847, 0.0802, 0.0679, 0.1026, 0.2100, 0.0760],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,915][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0007, 0.0652, 0.0605, 0.0939, 0.1133, 0.1100, 0.2095, 0.1674, 0.1796],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,916][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([7.0911e-03, 4.8151e-04, 1.2951e-02, 2.2260e-03, 1.7936e-03, 4.5846e-02,
        1.6979e-03, 1.3368e-02, 9.1455e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:31,917][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ garden] are: tensor([0.0426, 0.1067, 0.1787, 0.0593, 0.0840, 0.2159, 0.0678, 0.0692, 0.1381,
        0.0377], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,918][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ garden] are: tensor([0.0255, 0.0622, 0.1044, 0.0916, 0.2032, 0.0518, 0.0884, 0.2863, 0.0744,
        0.0121], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,919][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ garden] are: tensor([0.1265, 0.0317, 0.0693, 0.0909, 0.1001, 0.1015, 0.1129, 0.1310, 0.1421,
        0.0942], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,921][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ garden] are: tensor([0.1418, 0.0819, 0.0735, 0.1438, 0.1432, 0.0733, 0.1039, 0.1120, 0.0752,
        0.0514], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,923][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ garden] are: tensor([0.0263, 0.1365, 0.0855, 0.1135, 0.1074, 0.0913, 0.1274, 0.0979, 0.1049,
        0.1091], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,924][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ garden] are: tensor([0.1020, 0.0252, 0.0205, 0.0174, 0.0818, 0.2295, 0.0683, 0.2340, 0.1461,
        0.0752], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,926][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ garden] are: tensor([0.4417, 0.0791, 0.0352, 0.0429, 0.0632, 0.1036, 0.0071, 0.0413, 0.1537,
        0.0321], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,928][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ garden] are: tensor([0.2624, 0.0498, 0.0317, 0.0666, 0.1169, 0.1612, 0.0754, 0.0848, 0.1381,
        0.0130], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,929][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ garden] are: tensor([2.3526e-02, 2.2988e-03, 1.9339e-02, 2.3494e-04, 3.4864e-02, 3.6900e-01,
        9.4992e-02, 2.9081e-03, 4.4744e-01, 5.3960e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,931][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ garden] are: tensor([0.0035, 0.1721, 0.1369, 0.0736, 0.0765, 0.0576, 0.1057, 0.1998, 0.0796,
        0.0947], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,932][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ garden] are: tensor([0.0004, 0.0657, 0.0643, 0.0784, 0.0957, 0.0905, 0.1615, 0.1447, 0.1287,
        0.1700], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,934][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ garden] are: tensor([1.1421e-02, 3.4367e-03, 4.4991e-03, 2.1290e-03, 1.6367e-03, 1.8250e-03,
        3.7305e-03, 7.0049e-04, 7.3505e-04, 9.6989e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:31,935][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0457, 0.1019, 0.1615, 0.0555, 0.0837, 0.1856, 0.0703, 0.0679, 0.1221,
        0.0394, 0.0665], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,937][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0257, 0.0829, 0.0634, 0.1119, 0.2451, 0.0407, 0.1828, 0.0921, 0.0196,
        0.1236, 0.0121], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,939][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1117, 0.0304, 0.0622, 0.0784, 0.0855, 0.0848, 0.0992, 0.1118, 0.1221,
        0.0825, 0.1314], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,941][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1327, 0.0702, 0.0540, 0.1258, 0.1445, 0.0740, 0.1000, 0.1026, 0.0725,
        0.0553, 0.0684], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,942][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0280, 0.1165, 0.0735, 0.1074, 0.1058, 0.0809, 0.1186, 0.0862, 0.0908,
        0.1031, 0.0893], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,944][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0973, 0.0233, 0.0104, 0.0047, 0.0187, 0.0580, 0.0494, 0.0283, 0.0682,
        0.0112, 0.6304], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,946][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1481, 0.1076, 0.0559, 0.0443, 0.0532, 0.0624, 0.1860, 0.0625, 0.0669,
        0.1292, 0.0839], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,947][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1762, 0.1213, 0.0370, 0.0709, 0.0668, 0.0534, 0.1470, 0.0552, 0.0874,
        0.1082, 0.0766], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,948][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([7.1264e-03, 5.0848e-04, 1.2052e-02, 1.0060e-05, 9.8368e-03, 2.8613e-01,
        2.0748e-02, 6.8593e-04, 5.5751e-01, 4.2146e-04, 1.0497e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,949][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0035, 0.1580, 0.1236, 0.0671, 0.0642, 0.0499, 0.0937, 0.1681, 0.0619,
        0.0809, 0.1290], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,950][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0007, 0.0436, 0.0419, 0.0643, 0.0798, 0.0688, 0.1416, 0.1133, 0.1094,
        0.1525, 0.1841], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,951][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0654, 0.0185, 0.0454, 0.0325, 0.0234, 0.0862, 0.0328, 0.0860, 0.1654,
        0.0460, 0.3984], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:31,953][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Sara] are: tensor([0.0588, 0.1074, 0.1654, 0.0528, 0.0811, 0.1717, 0.0579, 0.0632, 0.1223,
        0.0363, 0.0593, 0.0237], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,954][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Sara] are: tensor([0.0675, 0.0224, 0.1065, 0.1768, 0.1873, 0.0475, 0.0954, 0.1547, 0.0331,
        0.0174, 0.0755, 0.0158], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,956][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Sara] are: tensor([0.0965, 0.0280, 0.0605, 0.0741, 0.0823, 0.0839, 0.0911, 0.1051, 0.1135,
        0.0737, 0.1265, 0.0647], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,958][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Sara] are: tensor([0.1430, 0.0677, 0.0625, 0.1047, 0.1213, 0.0713, 0.0769, 0.0897, 0.0737,
        0.0454, 0.0762, 0.0675], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,959][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Sara] are: tensor([0.0228, 0.1081, 0.0717, 0.0941, 0.0901, 0.0752, 0.1011, 0.0794, 0.0856,
        0.0873, 0.0860, 0.0985], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,961][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Sara] are: tensor([0.0308, 0.0429, 0.0235, 0.5265, 0.0011, 0.0314, 0.0089, 0.0460, 0.0443,
        0.0166, 0.1234, 0.1045], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,963][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Sara] are: tensor([0.1317, 0.1737, 0.0291, 0.1536, 0.0733, 0.0296, 0.0743, 0.0435, 0.0706,
        0.0119, 0.1061, 0.1029], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,965][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Sara] are: tensor([0.0911, 0.0301, 0.0390, 0.0569, 0.0849, 0.0625, 0.0578, 0.0702, 0.1168,
        0.1917, 0.1573, 0.0416], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,966][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Sara] are: tensor([1.1267e-02, 1.1509e-03, 6.3220e-03, 1.0778e-04, 1.2783e-02, 4.9989e-01,
        5.6868e-02, 1.1441e-03, 3.1565e-01, 1.7051e-03, 7.9710e-02, 1.3399e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,968][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Sara] are: tensor([0.0030, 0.1863, 0.1317, 0.0615, 0.0581, 0.0502, 0.0832, 0.1488, 0.0625,
        0.0750, 0.1352, 0.0046], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,969][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Sara] are: tensor([0.0009, 0.0334, 0.0382, 0.0524, 0.0713, 0.0627, 0.1120, 0.1008, 0.0990,
        0.1277, 0.1630, 0.1386], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,971][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Sara] are: tensor([2.0939e-04, 2.3378e-01, 1.3662e-04, 1.3335e-03, 6.1429e-05, 1.5850e-04,
        2.5668e-03, 9.5387e-05, 5.2602e-05, 4.3918e-04, 1.0232e-02, 7.5093e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:31,972][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.0403, 0.0909, 0.1522, 0.0540, 0.0748, 0.1797, 0.0646, 0.0645, 0.1199,
        0.0378, 0.0647, 0.0245, 0.0320], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,974][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.0441, 0.0805, 0.1013, 0.1424, 0.1169, 0.0513, 0.0984, 0.0201, 0.0210,
        0.0862, 0.0934, 0.1198, 0.0246], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,976][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0929, 0.0257, 0.0531, 0.0678, 0.0746, 0.0748, 0.0854, 0.0966, 0.1038,
        0.0698, 0.1145, 0.0626, 0.0784], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,978][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.1248, 0.0609, 0.0473, 0.0961, 0.1169, 0.0596, 0.0892, 0.0807, 0.0642,
        0.0495, 0.0627, 0.0684, 0.0796], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,980][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0210, 0.0976, 0.0624, 0.0877, 0.0848, 0.0658, 0.0954, 0.0728, 0.0759,
        0.0822, 0.0768, 0.0912, 0.0865], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,981][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.1872, 0.0086, 0.0118, 0.0250, 0.1843, 0.1991, 0.0130, 0.1812, 0.0742,
        0.0164, 0.0815, 0.0035, 0.0142], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,982][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.2006, 0.0055, 0.0577, 0.0605, 0.0719, 0.0467, 0.0219, 0.0471, 0.0751,
        0.0095, 0.2705, 0.0025, 0.1306], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,983][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.1772, 0.0684, 0.0303, 0.0416, 0.0984, 0.0542, 0.0982, 0.0558, 0.0932,
        0.0602, 0.1013, 0.0703, 0.0508], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,983][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([8.0257e-03, 3.0141e-04, 1.2024e-02, 3.1669e-05, 1.1432e-02, 1.7625e-01,
        1.6354e-02, 1.4906e-03, 5.8339e-01, 6.5474e-04, 1.8153e-01, 7.2820e-03,
        1.2342e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,985][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0034, 0.1546, 0.1132, 0.0631, 0.0578, 0.0453, 0.0840, 0.1462, 0.0559,
        0.0730, 0.1195, 0.0049, 0.0791], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,987][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.0006, 0.0298, 0.0306, 0.0463, 0.0577, 0.0466, 0.1036, 0.0826, 0.0786,
        0.1107, 0.1330, 0.1313, 0.1487], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,988][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([5.0666e-03, 8.4655e-05, 3.2375e-03, 2.2316e-03, 2.5680e-03, 2.1077e-03,
        2.5152e-04, 6.1650e-04, 2.7217e-03, 6.8807e-04, 4.4236e-02, 1.4723e-04,
        9.3604e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:31,990][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0430, 0.0870, 0.1341, 0.0516, 0.0756, 0.1544, 0.0652, 0.0588, 0.1013,
        0.0366, 0.0555, 0.0234, 0.0311, 0.0825], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,992][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0234, 0.0727, 0.0541, 0.0604, 0.1372, 0.0536, 0.1018, 0.0470, 0.0305,
        0.0847, 0.0270, 0.1201, 0.1860, 0.0016], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,994][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0986, 0.0183, 0.0406, 0.0600, 0.0645, 0.0639, 0.0781, 0.0841, 0.0873,
        0.0653, 0.1018, 0.0581, 0.0750, 0.1045], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,995][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1093, 0.0564, 0.0367, 0.1020, 0.1262, 0.0558, 0.0785, 0.0837, 0.0581,
        0.0448, 0.0529, 0.0681, 0.0791, 0.0483], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,997][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0220, 0.0892, 0.0553, 0.0802, 0.0799, 0.0635, 0.0890, 0.0662, 0.0707,
        0.0797, 0.0690, 0.0876, 0.0811, 0.0666], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:31,999][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0662, 0.0056, 0.0074, 0.0542, 0.0149, 0.0632, 0.0054, 0.0197, 0.0651,
        0.0041, 0.0253, 0.0028, 0.0063, 0.6598], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,001][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1740, 0.0873, 0.0870, 0.0287, 0.0443, 0.0771, 0.0839, 0.0483, 0.0570,
        0.0196, 0.0939, 0.0402, 0.0965, 0.0622], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,003][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1384, 0.0709, 0.0351, 0.0418, 0.0428, 0.0503, 0.1189, 0.0471, 0.0689,
        0.0754, 0.1014, 0.0625, 0.0573, 0.0890], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,004][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([7.6812e-03, 2.8370e-04, 1.0719e-02, 3.3822e-05, 8.1789e-03, 2.3938e-01,
        1.9149e-02, 1.3898e-03, 5.1376e-01, 7.0913e-04, 1.6755e-01, 5.9865e-03,
        1.2455e-03, 2.3937e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,006][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0045, 0.1360, 0.1157, 0.0456, 0.0536, 0.0424, 0.0681, 0.1561, 0.0637,
        0.0684, 0.1464, 0.0054, 0.0907, 0.0032], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,007][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0011, 0.0243, 0.0231, 0.0360, 0.0461, 0.0430, 0.0807, 0.0670, 0.0652,
        0.0825, 0.1109, 0.1051, 0.1388, 0.1763], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,009][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([7.8246e-03, 2.6709e-04, 1.7873e-02, 5.6075e-04, 1.0614e-03, 1.8432e-02,
        2.0396e-04, 1.4319e-02, 1.3587e-02, 7.9224e-04, 2.0985e-01, 5.3167e-03,
        3.1341e-03, 7.0678e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,010][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0376, 0.0873, 0.1312, 0.0523, 0.0646, 0.1502, 0.0606, 0.0554, 0.0973,
        0.0343, 0.0551, 0.0233, 0.0285, 0.0843, 0.0379], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,012][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0347, 0.1407, 0.0376, 0.0574, 0.0801, 0.0419, 0.1287, 0.0265, 0.0554,
        0.0295, 0.0262, 0.0946, 0.2112, 0.0131, 0.0222], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,014][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0774, 0.0220, 0.0444, 0.0574, 0.0622, 0.0611, 0.0724, 0.0787, 0.0844,
        0.0595, 0.0921, 0.0536, 0.0670, 0.1021, 0.0657], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,015][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.1250, 0.0482, 0.0410, 0.0878, 0.1085, 0.0517, 0.0709, 0.0811, 0.0551,
        0.0385, 0.0579, 0.0570, 0.0684, 0.0454, 0.0634], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,016][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0178, 0.0835, 0.0519, 0.0726, 0.0714, 0.0558, 0.0806, 0.0620, 0.0644,
        0.0698, 0.0651, 0.0789, 0.0777, 0.0607, 0.0878], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,017][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.1581, 0.0030, 0.0182, 0.0036, 0.0515, 0.1735, 0.0645, 0.0494, 0.1369,
        0.0054, 0.1781, 0.0018, 0.0487, 0.0323, 0.0748], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,019][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0586, 0.0709, 0.0284, 0.0464, 0.0509, 0.0254, 0.2862, 0.0285, 0.0276,
        0.0552, 0.0494, 0.0937, 0.0875, 0.0412, 0.0500], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,020][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.1094, 0.0704, 0.0285, 0.0343, 0.0436, 0.0428, 0.0890, 0.0462, 0.0676,
        0.0794, 0.1015, 0.0832, 0.0881, 0.0748, 0.0413], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,022][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([5.9485e-03, 1.8128e-04, 6.9930e-03, 1.9286e-05, 7.6862e-03, 2.5234e-01,
        2.1484e-02, 9.8882e-04, 5.0458e-01, 6.2260e-04, 1.6273e-01, 4.4882e-03,
        1.0335e-03, 2.0787e-02, 1.0115e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,023][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0034, 0.1400, 0.1147, 0.0627, 0.0556, 0.0445, 0.0766, 0.1375, 0.0536,
        0.0646, 0.1056, 0.0052, 0.0733, 0.0022, 0.0605], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,025][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0007, 0.0213, 0.0211, 0.0313, 0.0424, 0.0361, 0.0751, 0.0597, 0.0563,
        0.0769, 0.0960, 0.0946, 0.1174, 0.1439, 0.1272], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,027][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([3.4542e-03, 1.2211e-04, 3.2645e-03, 3.8648e-04, 6.1053e-03, 5.3153e-04,
        8.3945e-04, 5.8476e-04, 6.2139e-04, 4.7502e-04, 3.6206e-02, 1.6729e-04,
        7.0166e-04, 3.0401e-03, 9.4350e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,028][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([0.0400, 0.0856, 0.1275, 0.0499, 0.0655, 0.1366, 0.0600, 0.0526, 0.0896,
        0.0337, 0.0517, 0.0228, 0.0279, 0.0739, 0.0360, 0.0467],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,030][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([0.0178, 0.0611, 0.0353, 0.0348, 0.0823, 0.0408, 0.0573, 0.0332, 0.0081,
        0.0383, 0.0241, 0.1135, 0.1296, 0.0209, 0.2998, 0.0031],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,032][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.0741, 0.0214, 0.0431, 0.0543, 0.0591, 0.0587, 0.0669, 0.0745, 0.0801,
        0.0548, 0.0874, 0.0499, 0.0630, 0.0946, 0.0615, 0.0566],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,034][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([0.1062, 0.0501, 0.0354, 0.0891, 0.0975, 0.0514, 0.0696, 0.0671, 0.0573,
        0.0394, 0.0522, 0.0617, 0.0705, 0.0386, 0.0584, 0.0554],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,036][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.0177, 0.0763, 0.0483, 0.0698, 0.0681, 0.0535, 0.0778, 0.0572, 0.0614,
        0.0675, 0.0612, 0.0752, 0.0717, 0.0552, 0.0824, 0.0568],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,037][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([0.0579, 0.1135, 0.0076, 0.0151, 0.0027, 0.0606, 0.0117, 0.0082, 0.0728,
        0.0096, 0.1243, 0.0417, 0.0056, 0.0072, 0.0148, 0.4467],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,039][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([0.0800, 0.0824, 0.0245, 0.0113, 0.0111, 0.0355, 0.2017, 0.0349, 0.0514,
        0.2807, 0.0408, 0.0427, 0.0242, 0.0480, 0.0198, 0.0110],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,041][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.1322, 0.1016, 0.0297, 0.0489, 0.0198, 0.0613, 0.0871, 0.0352, 0.0835,
        0.0521, 0.0758, 0.0748, 0.0413, 0.0651, 0.0431, 0.0485],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,042][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([7.1487e-03, 4.2268e-04, 8.3296e-03, 2.8211e-05, 6.5457e-03, 2.5488e-01,
        2.2865e-02, 1.1509e-03, 5.3281e-01, 7.8221e-04, 1.1828e-01, 7.5434e-03,
        1.0425e-03, 1.7923e-02, 1.1396e-02, 8.8531e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,044][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([0.0028, 0.1290, 0.1111, 0.0553, 0.0483, 0.0401, 0.0643, 0.1206, 0.0466,
        0.0550, 0.0955, 0.0045, 0.0650, 0.0018, 0.0529, 0.1071],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,046][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.0011, 0.0167, 0.0173, 0.0280, 0.0338, 0.0337, 0.0656, 0.0488, 0.0512,
        0.0660, 0.0858, 0.0779, 0.0978, 0.1258, 0.1158, 0.1347],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,047][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([5.3361e-04, 3.0741e-05, 1.0230e-03, 4.4515e-05, 1.8068e-04, 4.5474e-04,
        1.3110e-04, 5.7434e-04, 2.8201e-03, 4.6409e-05, 3.2201e-02, 2.0029e-04,
        1.6640e-04, 4.4991e-03, 4.2282e-04, 9.5667e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,048][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0388, 0.0796, 0.1100, 0.0471, 0.0628, 0.1221, 0.0567, 0.0484, 0.0802,
        0.0312, 0.0453, 0.0212, 0.0266, 0.0632, 0.0340, 0.0426, 0.0903],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,049][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0185, 0.0606, 0.0457, 0.0472, 0.1039, 0.0419, 0.0812, 0.0376, 0.0235,
        0.0641, 0.0219, 0.0926, 0.1419, 0.0012, 0.1717, 0.0452, 0.0013],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,050][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0804, 0.0153, 0.0322, 0.0485, 0.0499, 0.0494, 0.0625, 0.0660, 0.0686,
        0.0530, 0.0794, 0.0456, 0.0593, 0.0856, 0.0535, 0.0454, 0.1054],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,051][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0980, 0.0467, 0.0321, 0.0825, 0.1067, 0.0464, 0.0665, 0.0709, 0.0484,
        0.0382, 0.0464, 0.0565, 0.0660, 0.0418, 0.0595, 0.0458, 0.0475],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,053][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0184, 0.0731, 0.0451, 0.0656, 0.0655, 0.0521, 0.0728, 0.0541, 0.0580,
        0.0651, 0.0564, 0.0719, 0.0664, 0.0544, 0.0795, 0.0528, 0.0489],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,055][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0389, 0.0041, 0.0041, 0.0325, 0.0066, 0.0548, 0.0030, 0.0144, 0.0497,
        0.0032, 0.0190, 0.0017, 0.0022, 0.3822, 0.0038, 0.0077, 0.3723],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,057][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0970, 0.0843, 0.0749, 0.0256, 0.0358, 0.0545, 0.0607, 0.0408, 0.0482,
        0.0169, 0.0746, 0.0426, 0.0633, 0.0558, 0.1122, 0.0635, 0.0494],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,058][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1163, 0.0649, 0.0341, 0.0342, 0.0261, 0.0359, 0.0982, 0.0406, 0.0540,
        0.0638, 0.0993, 0.0476, 0.0354, 0.0784, 0.0530, 0.0356, 0.0825],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,059][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([6.6945e-03, 2.5429e-04, 7.7338e-03, 1.8687e-05, 6.4485e-03, 2.7524e-01,
        2.2446e-02, 8.4195e-04, 4.7728e-01, 6.4602e-04, 1.2897e-01, 5.4312e-03,
        9.4302e-04, 1.8957e-02, 1.0243e-02, 7.1026e-03, 3.0750e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,061][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0039, 0.1118, 0.0898, 0.0352, 0.0440, 0.0349, 0.0576, 0.1282, 0.0533,
        0.0609, 0.1285, 0.0046, 0.0784, 0.0034, 0.0653, 0.0995, 0.0008],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,063][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0013, 0.0144, 0.0141, 0.0220, 0.0284, 0.0269, 0.0522, 0.0417, 0.0406,
        0.0498, 0.0713, 0.0650, 0.0847, 0.1145, 0.0999, 0.1154, 0.1579],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,064][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.7556e-03, 1.4661e-04, 7.4145e-03, 3.4520e-04, 5.2737e-04, 1.0407e-02,
        1.2841e-04, 8.4147e-03, 8.2137e-03, 4.0321e-04, 1.4012e-01, 5.3834e-03,
        1.5777e-03, 3.1054e-01, 1.0471e-03, 4.7383e-03, 4.9783e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,068][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:32,070][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[12546],
        [14207],
        [ 9186],
        [   14],
        [33776],
        [18046],
        [ 5313],
        [17985],
        [17504],
        [ 8776],
        [ 5457],
        [19366],
        [ 9468],
        [13400],
        [15660],
        [24201],
        [10754]], device='cuda:0')
[2024-07-24 10:29:32,072][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 4769],
        [31939],
        [20497],
        [    1],
        [38378],
        [30402],
        [18025],
        [30237],
        [31617],
        [26500],
        [14609],
        [32027],
        [20816],
        [16392],
        [17944],
        [33209],
        [16242]], device='cuda:0')
[2024-07-24 10:29:32,074][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[12725],
        [13835],
        [13094],
        [12898],
        [13883],
        [14743],
        [15374],
        [15176],
        [15521],
        [15362],
        [15012],
        [14999],
        [15263],
        [15403],
        [15478],
        [15244],
        [15280]], device='cuda:0')
[2024-07-24 10:29:32,076][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[32422],
        [24785],
        [ 7534],
        [13891],
        [11841],
        [19876],
        [24213],
        [13770],
        [21053],
        [23001],
        [11998],
        [17386],
        [ 9578],
        [ 8380],
        [ 8018],
        [11368],
        [10671]], device='cuda:0')
[2024-07-24 10:29:32,078][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[25761],
        [25682],
        [25258],
        [23391],
        [23535],
        [23258],
        [23578],
        [23489],
        [23644],
        [23553],
        [24201],
        [24446],
        [24300],
        [23988],
        [23972],
        [23941],
        [24019]], device='cuda:0')
[2024-07-24 10:29:32,080][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 875],
        [2839],
        [3718],
        [4968],
        [5601],
        [6631],
        [6333],
        [6745],
        [7292],
        [6675],
        [7751],
        [7834],
        [7659],
        [7884],
        [7661],
        [8281],
        [8527]], device='cuda:0')
[2024-07-24 10:29:32,082][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[30119],
        [26244],
        [26448],
        [24453],
        [25104],
        [26250],
        [25677],
        [26106],
        [26652],
        [26786],
        [27426],
        [27235],
        [26987],
        [27113],
        [27274],
        [27157],
        [27191]], device='cuda:0')
[2024-07-24 10:29:32,083][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[31645],
        [35428],
        [44034],
        [47429],
        [45611],
        [46566],
        [ 9553],
        [41451],
        [34240],
        [ 9181],
        [26245],
        [47424],
        [45674],
        [41449],
        [41799],
        [43297],
        [42098]], device='cuda:0')
[2024-07-24 10:29:32,084][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[29224],
        [ 9654],
        [22056],
        [25815],
        [22653],
        [  736],
        [ 8259],
        [ 9794],
        [ 5883],
        [12755],
        [ 8508],
        [ 6451],
        [ 5137],
        [12328],
        [ 8150],
        [ 8304],
        [ 5719]], device='cuda:0')
[2024-07-24 10:29:32,086][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[33821],
        [ 8737],
        [10100],
        [ 6136],
        [12632],
        [ 7973],
        [10929],
        [ 9477],
        [11552],
        [ 8362],
        [ 8957],
        [ 7554],
        [14942],
        [22962],
        [30111],
        [16333],
        [23091]], device='cuda:0')
[2024-07-24 10:29:32,088][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[18644],
        [18737],
        [15452],
        [16000],
        [16448],
        [17162],
        [17795],
        [17645],
        [17149],
        [17175],
        [16443],
        [16672],
        [16471],
        [16257],
        [16335],
        [16452],
        [16268]], device='cuda:0')
[2024-07-24 10:29:32,090][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[23999],
        [23852],
        [24351],
        [24651],
        [25795],
        [25983],
        [28540],
        [27653],
        [28681],
        [30096],
        [27699],
        [27663],
        [30869],
        [30650],
        [31126],
        [29356],
        [28781]], device='cuda:0')
[2024-07-24 10:29:32,092][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[43889],
        [12159],
        [ 6748],
        [ 4301],
        [ 4551],
        [ 2256],
        [ 2007],
        [ 1822],
        [ 2324],
        [ 1873],
        [ 2172],
        [ 2121],
        [ 2312],
        [ 2750],
        [ 2998],
        [ 3068],
        [ 3702]], device='cuda:0')
[2024-07-24 10:29:32,093][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[  922],
        [37954],
        [ 3623],
        [47592],
        [34221],
        [24694],
        [36117],
        [21171],
        [23126],
        [27324],
        [ 8017],
        [40591],
        [19973],
        [11070],
        [14274],
        [35241],
        [13220]], device='cuda:0')
[2024-07-24 10:29:32,095][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[15188],
        [24822],
        [ 8438],
        [13415],
        [25110],
        [14245],
        [ 4633],
        [14985],
        [15053],
        [13014],
        [14964],
        [31332],
        [ 6950],
        [12648],
        [14170],
        [25825],
        [14137]], device='cuda:0')
[2024-07-24 10:29:32,097][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[16024],
        [12356],
        [14189],
        [14028],
        [13559],
        [12906],
        [12621],
        [13192],
        [13256],
        [13194],
        [13131],
        [13094],
        [13119],
        [13185],
        [13269],
        [13398],
        [13446]], device='cuda:0')
[2024-07-24 10:29:32,099][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 2286],
        [ 8036],
        [25832],
        [22753],
        [19392],
        [10628],
        [12639],
        [14041],
        [16889],
        [16105],
        [16159],
        [13791],
        [16841],
        [17570],
        [16736],
        [ 8271],
        [11055]], device='cuda:0')
[2024-07-24 10:29:32,101][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[3710],
        [3494],
        [3499],
        [3159],
        [3299],
        [3364],
        [3298],
        [3384],
        [3468],
        [3480],
        [3467],
        [3415],
        [3437],
        [3200],
        [3227],
        [3246],
        [2906]], device='cuda:0')
[2024-07-24 10:29:32,103][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[36999],
        [32380],
        [25566],
        [21151],
        [15627],
        [14213],
        [15663],
        [16008],
        [16391],
        [16155],
        [15971],
        [15475],
        [15259],
        [13829],
        [14932],
        [13623],
        [12790]], device='cuda:0')
[2024-07-24 10:29:32,104][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[7372],
        [9929],
        [8094],
        [9447],
        [8089],
        [8215],
        [8312],
        [8059],
        [8222],
        [8075],
        [7626],
        [7939],
        [7882],
        [7836],
        [7418],
        [7381],
        [7336]], device='cuda:0')
[2024-07-24 10:29:32,106][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[13236],
        [29720],
        [22805],
        [25515],
        [18939],
        [33470],
        [42806],
        [41919],
        [38898],
        [39296],
        [30704],
        [31754],
        [39328],
        [45551],
        [38433],
        [46066],
        [43872]], device='cuda:0')
[2024-07-24 10:29:32,108][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[38819],
        [31294],
        [36849],
        [38190],
        [35612],
        [37744],
        [38677],
        [33683],
        [40309],
        [41941],
        [29165],
        [31041],
        [30853],
        [34720],
        [29954],
        [20140],
        [37604]], device='cuda:0')
[2024-07-24 10:29:32,110][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 9616],
        [12544],
        [14695],
        [15880],
        [26561],
        [33005],
        [29632],
        [34013],
        [33424],
        [34534],
        [35882],
        [39771],
        [34077],
        [34591],
        [33509],
        [33694],
        [32719]], device='cuda:0')
[2024-07-24 10:29:32,112][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[24777],
        [27170],
        [15642],
        [17166],
        [22506],
        [18814],
        [18831],
        [18818],
        [26101],
        [26060],
        [27277],
        [26079],
        [28357],
        [28321],
        [28391],
        [28029],
        [28302]], device='cuda:0')
[2024-07-24 10:29:32,113][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[36043],
        [30010],
        [33554],
        [32783],
        [33880],
        [34838],
        [36216],
        [35744],
        [35210],
        [35636],
        [35888],
        [35531],
        [36022],
        [36046],
        [35800],
        [34748],
        [34957]], device='cuda:0')
[2024-07-24 10:29:32,115][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[10417],
        [ 9064],
        [10750],
        [16105],
        [19462],
        [19872],
        [21357],
        [20296],
        [20585],
        [20757],
        [20888],
        [22606],
        [24049],
        [24041],
        [24014],
        [23240],
        [23286]], device='cuda:0')
[2024-07-24 10:29:32,117][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[48988],
        [ 7045],
        [49537],
        [11420],
        [12962],
        [41403],
        [ 8754],
        [44655],
        [40108],
        [ 4574],
        [49654],
        [38339],
        [23721],
        [49626],
        [17820],
        [44863],
        [49647]], device='cuda:0')
[2024-07-24 10:29:32,119][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[12967],
        [38772],
        [25573],
        [32566],
        [33075],
        [23701],
        [32305],
        [22974],
        [19610],
        [30602],
        [18398],
        [21100],
        [25676],
        [ 8454],
        [28447],
        [23117],
        [ 9621]], device='cuda:0')
[2024-07-24 10:29:32,120][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[31192],
        [35420],
        [16564],
        [41792],
        [29284],
        [35803],
        [45768],
        [32225],
        [32698],
        [37795],
        [18949],
        [13787],
        [35652],
        [28148],
        [32778],
        [20729],
        [27981]], device='cuda:0')
[2024-07-24 10:29:32,122][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430]], device='cuda:0')
[2024-07-24 10:29:32,164][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:32,165][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,167][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,169][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,170][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,171][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,173][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,174][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,175][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,176][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,178][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,179][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,180][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,181][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Sara] are: tensor([0.5547, 0.4453], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,182][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Sara] are: tensor([0.9958, 0.0042], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,183][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Sara] are: tensor([0.7488, 0.2512], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,184][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Sara] are: tensor([0.5814, 0.4186], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,184][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Sara] are: tensor([0.9980, 0.0020], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,186][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Sara] are: tensor([0.4452, 0.5548], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,187][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Sara] are: tensor([0.2765, 0.7235], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,189][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Sara] are: tensor([0.9413, 0.0587], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,191][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Sara] are: tensor([0.9801, 0.0199], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,192][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Sara] are: tensor([4.5635e-04, 9.9954e-01], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,193][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Sara] are: tensor([0.1274, 0.8726], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,195][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Sara] are: tensor([0.4947, 0.5053], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,197][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3373, 0.3583, 0.3044], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,198][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.8477, 0.0555, 0.0968], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,200][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0078, 0.9912, 0.0010], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,201][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.4442, 0.5024, 0.0534], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,203][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.8970, 0.0490, 0.0539], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,205][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1501, 0.7753, 0.0745], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,206][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1429, 0.3361, 0.5210], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,208][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.8640, 0.0418, 0.0942], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,210][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.8860, 0.0687, 0.0453], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,211][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([6.1214e-04, 9.8035e-01, 1.9043e-02], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,212][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1084, 0.5935, 0.2981], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,214][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.3173, 0.3365, 0.3462], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,215][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Kenneth] are: tensor([0.2329, 0.2445, 0.2894, 0.2332], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,216][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Kenneth] are: tensor([0.6355, 0.0393, 0.0848, 0.2404], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,217][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Kenneth] are: tensor([2.3348e-03, 9.5813e-01, 3.8654e-02, 8.8468e-04], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,217][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Kenneth] are: tensor([0.2240, 0.5578, 0.1218, 0.0963], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,218][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Kenneth] are: tensor([0.4525, 0.2343, 0.3043, 0.0089], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,220][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Kenneth] are: tensor([0.0359, 0.6791, 0.2628, 0.0222], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,221][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Kenneth] are: tensor([0.0615, 0.1713, 0.2736, 0.4936], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,223][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Kenneth] are: tensor([0.8992, 0.0048, 0.0207, 0.0752], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,225][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Kenneth] are: tensor([0.7308, 0.0670, 0.1984, 0.0038], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,225][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Kenneth] are: tensor([3.9685e-06, 1.1478e-02, 9.2432e-05, 9.8843e-01], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,227][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Kenneth] are: tensor([0.0366, 0.3237, 0.1755, 0.4641], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,228][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Kenneth] are: tensor([0.1865, 0.2270, 0.2491, 0.3373], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,230][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.1668, 0.1805, 0.2111, 0.2481, 0.1935], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,232][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.4938, 0.0348, 0.0674, 0.2162, 0.1877], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,233][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.0392, 0.5079, 0.2438, 0.1997, 0.0094], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,235][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.5495, 0.2504, 0.0968, 0.0687, 0.0346], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,237][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.7341, 0.0254, 0.2267, 0.0032, 0.0105], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,238][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.0203, 0.3534, 0.3832, 0.2322, 0.0109], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,240][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.0471, 0.1155, 0.1873, 0.3141, 0.3359], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,241][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.7654, 0.0103, 0.0326, 0.1043, 0.0874], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,243][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.4686, 0.0698, 0.2292, 0.2018, 0.0305], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,244][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ got] are: tensor([3.5096e-07, 1.9926e-03, 2.8514e-05, 9.9770e-01, 2.7963e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,246][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.0291, 0.2224, 0.1202, 0.2946, 0.3336], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,247][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.1406, 0.1660, 0.1879, 0.2800, 0.2256], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,249][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1512, 0.1485, 0.1748, 0.1784, 0.1748, 0.1724], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,250][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1731, 0.0448, 0.0742, 0.2306, 0.1856, 0.2918], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,251][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([5.2719e-02, 5.4774e-01, 2.1230e-01, 4.6626e-02, 1.4035e-01, 2.5575e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,251][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2568, 0.2336, 0.1209, 0.2401, 0.0880, 0.0606], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,252][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2315, 0.1781, 0.3173, 0.0184, 0.2346, 0.0200], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,254][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0505, 0.3105, 0.2705, 0.2311, 0.1267, 0.0107], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,255][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0339, 0.0837, 0.1394, 0.2456, 0.2732, 0.2243], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,257][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.7196, 0.0063, 0.0189, 0.0592, 0.0516, 0.1445], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,259][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2575, 0.0353, 0.1761, 0.0738, 0.4499, 0.0075], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,260][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([2.1985e-08, 2.8774e-04, 2.9691e-06, 9.9939e-01, 6.1609e-05, 2.6150e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,261][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0365, 0.1849, 0.1023, 0.2363, 0.2620, 0.1780], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,263][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1287, 0.1305, 0.1665, 0.2203, 0.2076, 0.1464], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,265][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.1063, 0.1258, 0.1478, 0.1654, 0.1706, 0.1427, 0.1414],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,267][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.9024, 0.0034, 0.0065, 0.0266, 0.0135, 0.0380, 0.0096],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,268][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.0188, 0.5818, 0.1255, 0.1796, 0.0497, 0.0414, 0.0032],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,270][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0532, 0.2008, 0.0500, 0.1926, 0.2085, 0.2695, 0.0253],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,272][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.3888, 0.0170, 0.2257, 0.0360, 0.2581, 0.0703, 0.0042],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,273][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.0456, 0.2201, 0.1945, 0.3121, 0.0876, 0.1266, 0.0136],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,275][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.0211, 0.0566, 0.0953, 0.1735, 0.1876, 0.1544, 0.3115],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,277][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.6646, 0.0046, 0.0144, 0.0402, 0.0384, 0.0909, 0.1469],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,278][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.4076, 0.0230, 0.2150, 0.0197, 0.2964, 0.0263, 0.0119],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,280][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([6.2296e-08, 1.6628e-04, 1.5901e-05, 5.5819e-01, 1.1971e-04, 1.1532e-03,
        4.4035e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,281][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.0142, 0.1105, 0.0659, 0.1658, 0.2252, 0.1154, 0.3029],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,283][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0825, 0.1078, 0.1134, 0.1858, 0.1645, 0.1019, 0.2440],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,284][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0933, 0.1132, 0.1009, 0.1371, 0.1193, 0.1192, 0.1384, 0.1787],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:32,284][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0672, 0.0235, 0.0439, 0.1577, 0.1012, 0.2067, 0.0918, 0.3080],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:32,285][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0513, 0.4591, 0.0965, 0.1379, 0.0739, 0.0709, 0.1096, 0.0009],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:32,286][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.2902, 0.1152, 0.0542, 0.0850, 0.1046, 0.2191, 0.1213, 0.0103],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:32,288][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.1455, 0.0730, 0.3072, 0.0235, 0.3106, 0.1154, 0.0062, 0.0187],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:32,289][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0368, 0.1472, 0.2129, 0.1363, 0.0748, 0.0659, 0.3185, 0.0074],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:32,291][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0234, 0.0554, 0.0886, 0.1428, 0.1620, 0.1367, 0.2465, 0.1445],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:32,293][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.4955, 0.0060, 0.0177, 0.0445, 0.0417, 0.0959, 0.1527, 0.1462],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:32,294][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0527, 0.0056, 0.0325, 0.0081, 0.8122, 0.0711, 0.0125, 0.0053],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:32,296][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ at] are: tensor([1.4202e-08, 5.7501e-05, 7.9199e-07, 7.9002e-02, 8.3535e-06, 6.2215e-05,
        9.2072e-01, 1.4662e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:32,297][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0190, 0.1137, 0.0556, 0.1617, 0.1625, 0.1099, 0.2475, 0.1301],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:32,299][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0802, 0.0874, 0.1057, 0.1524, 0.1354, 0.0988, 0.2100, 0.1302],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:32,301][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0889, 0.0961, 0.0961, 0.1038, 0.1008, 0.1006, 0.1088, 0.2047, 0.1004],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:32,302][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0871, 0.0224, 0.0408, 0.1370, 0.0870, 0.1519, 0.0775, 0.2160, 0.1803],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:32,304][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ the] are: tensor([2.3330e-02, 4.2686e-01, 8.6818e-02, 6.1847e-02, 2.2422e-01, 3.4439e-03,
        1.3347e-02, 1.6003e-01, 1.0781e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:32,305][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1610, 0.0984, 0.0768, 0.0848, 0.0901, 0.2103, 0.1153, 0.1258, 0.0375],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:32,307][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1230, 0.5652, 0.1382, 0.0336, 0.0403, 0.0369, 0.0097, 0.0479, 0.0053],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:32,309][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0251, 0.1649, 0.3189, 0.0829, 0.1006, 0.0342, 0.2373, 0.0295, 0.0066],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:32,310][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0177, 0.0439, 0.0748, 0.1275, 0.1451, 0.1221, 0.2187, 0.1279, 0.1222],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:32,312][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.5146, 0.0041, 0.0091, 0.0277, 0.0226, 0.0597, 0.0993, 0.0993, 0.1637],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:32,314][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0649, 0.0097, 0.1086, 0.0314, 0.2108, 0.0166, 0.0427, 0.5141, 0.0013],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:32,315][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ the] are: tensor([1.1757e-08, 5.3155e-05, 8.1860e-07, 1.7870e-01, 1.1353e-05, 4.1058e-05,
        8.1939e-01, 2.0618e-04, 1.5917e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:32,317][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0191, 0.1008, 0.0588, 0.1264, 0.1495, 0.1020, 0.2129, 0.1165, 0.1141],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:32,318][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0764, 0.0780, 0.1034, 0.1202, 0.1299, 0.0903, 0.1797, 0.1228, 0.0992],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:32,318][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ garden] are: tensor([0.0601, 0.0857, 0.0813, 0.0956, 0.1105, 0.0847, 0.0999, 0.1725, 0.0979,
        0.1119], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:32,319][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ garden] are: tensor([0.6190, 0.0049, 0.0104, 0.0415, 0.0284, 0.0703, 0.0204, 0.1162, 0.0657,
        0.0234], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:32,320][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ garden] are: tensor([0.0419, 0.2491, 0.0807, 0.2414, 0.0789, 0.1820, 0.0501, 0.0115, 0.0642,
        0.0003], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:32,322][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ garden] are: tensor([0.0493, 0.1931, 0.0504, 0.0774, 0.1774, 0.1458, 0.0862, 0.1045, 0.1075,
        0.0086], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:32,324][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ garden] are: tensor([0.1156, 0.0466, 0.2956, 0.0024, 0.1296, 0.0435, 0.0498, 0.1069, 0.2089,
        0.0011], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:32,325][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ garden] are: tensor([0.0156, 0.2534, 0.1814, 0.2635, 0.0923, 0.0542, 0.0472, 0.0391, 0.0526,
        0.0007], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:32,327][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ garden] are: tensor([0.0137, 0.0338, 0.0561, 0.0948, 0.1056, 0.0894, 0.1647, 0.0983, 0.0887,
        0.2549], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:32,329][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ garden] are: tensor([0.5280, 0.0026, 0.0073, 0.0224, 0.0201, 0.0501, 0.0785, 0.0846, 0.1294,
        0.0769], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:32,330][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ garden] are: tensor([0.0883, 0.0159, 0.1115, 0.0288, 0.0252, 0.0197, 0.1121, 0.5581, 0.0390,
        0.0015], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:32,331][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ garden] are: tensor([3.2377e-09, 5.6742e-06, 1.0793e-07, 3.2949e-02, 1.3734e-06, 9.2699e-06,
        8.8883e-01, 1.2568e-04, 2.0474e-03, 7.6035e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:32,333][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ garden] are: tensor([0.0090, 0.0772, 0.0422, 0.1102, 0.1350, 0.0773, 0.2159, 0.0843, 0.0906,
        0.1584], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:32,335][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ garden] are: tensor([0.0582, 0.0709, 0.0830, 0.1157, 0.1084, 0.0740, 0.1736, 0.0905, 0.0881,
        0.1377], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:32,337][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0637, 0.0719, 0.0698, 0.0856, 0.0878, 0.0839, 0.0879, 0.1443, 0.0860,
        0.1096, 0.1094], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:32,338][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1240, 0.0161, 0.0279, 0.1001, 0.0595, 0.1175, 0.0581, 0.1687, 0.1311,
        0.0706, 0.1264], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:32,340][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([2.7367e-02, 2.4127e-01, 5.7435e-02, 9.3922e-02, 2.8473e-01, 6.9014e-02,
        6.8791e-02, 6.5455e-02, 1.9335e-02, 7.2577e-02, 1.0655e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:32,341][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.2819, 0.0831, 0.0353, 0.0635, 0.1463, 0.1418, 0.0666, 0.0594, 0.0924,
        0.0240, 0.0058], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:32,343][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2169, 0.0612, 0.0347, 0.0554, 0.0527, 0.1893, 0.0356, 0.0358, 0.2756,
        0.0327, 0.0103], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:32,345][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0334, 0.1171, 0.2783, 0.0732, 0.1052, 0.0462, 0.1297, 0.0628, 0.0466,
        0.0302, 0.0772], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:32,346][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0134, 0.0314, 0.0529, 0.0862, 0.0980, 0.0856, 0.1444, 0.0893, 0.0850,
        0.2104, 0.1036], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:32,348][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.3627, 0.0043, 0.0097, 0.0239, 0.0204, 0.0460, 0.0783, 0.0763, 0.1096,
        0.0690, 0.1998], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:32,350][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2847, 0.0054, 0.0589, 0.0188, 0.1144, 0.0635, 0.0696, 0.3067, 0.0272,
        0.0432, 0.0076], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:32,351][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([7.7886e-09, 6.2576e-05, 3.3950e-07, 7.7475e-02, 3.9059e-06, 4.4551e-05,
        7.9144e-01, 6.5450e-05, 1.3441e-03, 1.2569e-01, 3.8800e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:32,352][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0153, 0.0795, 0.0449, 0.1031, 0.1161, 0.0766, 0.1714, 0.0877, 0.0899,
        0.1475, 0.0680], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:32,353][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0624, 0.0636, 0.0749, 0.0983, 0.0976, 0.0678, 0.1421, 0.0886, 0.0785,
        0.1277, 0.0986], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:32,354][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Sara] are: tensor([0.0537, 0.0489, 0.0624, 0.0696, 0.0794, 0.0748, 0.0786, 0.1499, 0.0853,
        0.1019, 0.1043, 0.0910], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:32,355][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Sara] are: tensor([0.7587, 0.0028, 0.0071, 0.0237, 0.0147, 0.0377, 0.0083, 0.0743, 0.0360,
        0.0086, 0.0225, 0.0057], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:32,357][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Sara] are: tensor([0.0607, 0.0092, 0.1946, 0.1459, 0.0799, 0.1330, 0.1916, 0.0052, 0.1462,
        0.0223, 0.0085, 0.0029], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:32,359][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Sara] are: tensor([0.0688, 0.0501, 0.0301, 0.1181, 0.0876, 0.1912, 0.0909, 0.0973, 0.1756,
        0.0499, 0.0155, 0.0249], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:32,360][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Sara] are: tensor([1.8856e-01, 2.4007e-04, 2.7310e-02, 1.7461e-02, 3.2954e-01, 1.3172e-01,
        1.7548e-01, 1.7249e-02, 5.2081e-02, 7.8461e-03, 5.2433e-02, 8.3862e-05],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:32,362][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Sara] are: tensor([0.0244, 0.0198, 0.1596, 0.1909, 0.0770, 0.1095, 0.1617, 0.0411, 0.0844,
        0.0160, 0.1078, 0.0078], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:32,364][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Sara] are: tensor([0.0092, 0.0229, 0.0406, 0.0749, 0.0775, 0.0632, 0.1237, 0.0724, 0.0646,
        0.2114, 0.0819, 0.1575], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:32,365][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Sara] are: tensor([0.3463, 0.0026, 0.0059, 0.0172, 0.0136, 0.0311, 0.0505, 0.0538, 0.0720,
        0.0473, 0.1423, 0.2175], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:32,367][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Sara] are: tensor([0.1948, 0.0043, 0.0931, 0.0262, 0.1048, 0.0263, 0.1000, 0.3247, 0.0411,
        0.0524, 0.0302, 0.0020], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:32,368][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Sara] are: tensor([1.3709e-09, 4.7212e-07, 3.5013e-08, 4.2609e-03, 1.5219e-07, 2.1005e-06,
        1.0721e-02, 8.4332e-06, 9.9717e-05, 4.7361e-03, 9.6310e-04, 9.7921e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:32,370][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Sara] are: tensor([0.0090, 0.0656, 0.0355, 0.0915, 0.1129, 0.0656, 0.1669, 0.0744, 0.0719,
        0.1255, 0.0646, 0.1165], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:32,372][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Sara] are: tensor([0.0517, 0.0548, 0.0629, 0.0918, 0.0895, 0.0591, 0.1304, 0.0748, 0.0721,
        0.1104, 0.0946, 0.1078], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:32,374][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0528, 0.0421, 0.0628, 0.0664, 0.0710, 0.0672, 0.0644, 0.1496, 0.0739,
        0.0925, 0.1092, 0.0868, 0.0613], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:32,375][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.1249, 0.0113, 0.0199, 0.0688, 0.0550, 0.1008, 0.0509, 0.1604, 0.1148,
        0.0566, 0.1066, 0.0347, 0.0952], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:32,377][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0258, 0.2397, 0.1983, 0.0147, 0.1181, 0.0336, 0.0203, 0.0136, 0.1262,
        0.0509, 0.0169, 0.1389, 0.0029], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:32,379][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.2172, 0.0930, 0.0326, 0.0360, 0.0528, 0.1720, 0.0483, 0.0835, 0.1249,
        0.0361, 0.0119, 0.0718, 0.0199], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:32,380][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([7.2290e-01, 1.8289e-03, 4.8385e-02, 6.3919e-04, 5.6339e-02, 2.9317e-02,
        1.1170e-03, 1.6613e-02, 7.4589e-02, 8.6237e-04, 4.5273e-02, 1.1673e-03,
        9.7345e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:32,382][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.0168, 0.1389, 0.1153, 0.0572, 0.0636, 0.0531, 0.1809, 0.0745, 0.0500,
        0.0107, 0.1399, 0.0811, 0.0179], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:32,384][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0099, 0.0237, 0.0402, 0.0651, 0.0724, 0.0614, 0.1075, 0.0691, 0.0617,
        0.1694, 0.0771, 0.1313, 0.1110], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:32,385][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.2995, 0.0020, 0.0057, 0.0152, 0.0137, 0.0288, 0.0506, 0.0481, 0.0732,
        0.0440, 0.1397, 0.2040, 0.0755], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:32,386][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.2588, 0.0253, 0.0501, 0.0491, 0.1125, 0.0652, 0.0308, 0.1501, 0.0503,
        0.0076, 0.1089, 0.0139, 0.0775], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:32,386][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([7.5234e-09, 2.9795e-06, 1.8469e-07, 6.5509e-03, 5.4050e-07, 6.0335e-06,
        7.0657e-03, 1.1904e-05, 7.6179e-05, 5.5460e-03, 7.7968e-04, 9.7978e-01,
        1.8090e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:32,387][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0077, 0.0595, 0.0329, 0.0792, 0.0897, 0.0571, 0.1329, 0.0663, 0.0655,
        0.1166, 0.0600, 0.1092, 0.1233], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:32,389][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0426, 0.0539, 0.0570, 0.0831, 0.0754, 0.0504, 0.1191, 0.0687, 0.0641,
        0.1002, 0.0841, 0.1024, 0.0990], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:32,391][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0510, 0.0467, 0.0520, 0.0602, 0.0624, 0.0584, 0.0730, 0.1160, 0.0604,
        0.0891, 0.0844, 0.0912, 0.0669, 0.0882], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,392][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0676, 0.0143, 0.0231, 0.0842, 0.0491, 0.0836, 0.0535, 0.1168, 0.0952,
        0.0665, 0.1020, 0.0459, 0.0943, 0.1038], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,394][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([7.1231e-02, 1.7655e-01, 7.1315e-02, 7.1601e-03, 9.1057e-02, 5.4888e-02,
        9.3692e-02, 3.0210e-02, 6.0729e-02, 5.0556e-03, 4.3936e-03, 6.7320e-02,
        2.6639e-01, 1.4032e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,395][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1794, 0.0785, 0.0446, 0.0615, 0.0368, 0.1922, 0.0548, 0.0403, 0.1338,
        0.0328, 0.0140, 0.0472, 0.0826, 0.0015], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,397][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.5664e-02, 2.0454e-02, 2.4643e-02, 3.2126e-04, 1.5535e-01, 1.5753e-02,
        1.2938e-02, 3.7953e-02, 1.3677e-02, 4.2289e-04, 2.8496e-02, 1.5450e-02,
        6.5564e-01, 3.2392e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,399][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0152, 0.1734, 0.1848, 0.0741, 0.0595, 0.0160, 0.0924, 0.0309, 0.0290,
        0.0620, 0.0700, 0.0803, 0.1098, 0.0027], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,400][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0093, 0.0219, 0.0376, 0.0587, 0.0701, 0.0595, 0.1012, 0.0620, 0.0593,
        0.1447, 0.0744, 0.1214, 0.1046, 0.0751], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,402][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.2743, 0.0023, 0.0052, 0.0125, 0.0108, 0.0227, 0.0385, 0.0405, 0.0481,
        0.0324, 0.0966, 0.1508, 0.0559, 0.2094], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,403][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([2.3535e-02, 1.5500e-03, 2.3034e-02, 5.4692e-03, 2.0371e-01, 1.1127e-02,
        5.8710e-02, 3.1799e-02, 7.7873e-03, 1.0714e-02, 1.7404e-02, 8.6451e-04,
        6.0416e-01, 1.3450e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,405][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.6841e-09, 2.3049e-07, 2.0015e-09, 1.1113e-03, 6.8216e-09, 3.0400e-08,
        1.1415e-02, 8.0971e-08, 1.4723e-06, 2.5712e-03, 1.7818e-05, 9.8431e-01,
        3.6227e-05, 5.4009e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,406][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0116, 0.0543, 0.0357, 0.0721, 0.0895, 0.0591, 0.1101, 0.0672, 0.0674,
        0.1013, 0.0573, 0.0968, 0.1115, 0.0661], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,408][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0427, 0.0437, 0.0578, 0.0729, 0.0707, 0.0529, 0.0987, 0.0725, 0.0629,
        0.0867, 0.0819, 0.0864, 0.0954, 0.0750], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,410][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0441, 0.0472, 0.0460, 0.0578, 0.0537, 0.0524, 0.0628, 0.1013, 0.0578,
        0.0796, 0.0735, 0.0911, 0.0803, 0.0981, 0.0545], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,412][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0593, 0.0114, 0.0174, 0.0635, 0.0395, 0.0751, 0.0411, 0.1078, 0.0864,
        0.0463, 0.0832, 0.0368, 0.0753, 0.0956, 0.1614], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,413][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0302, 0.1318, 0.0483, 0.0520, 0.0201, 0.0168, 0.0622, 0.0135, 0.0313,
        0.0413, 0.0079, 0.0437, 0.3373, 0.1628, 0.0008], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,415][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0767, 0.1027, 0.0324, 0.0250, 0.0499, 0.1896, 0.0809, 0.0450, 0.2113,
        0.0331, 0.0084, 0.0635, 0.0761, 0.0027, 0.0025], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,417][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.2445, 0.0539, 0.1636, 0.0064, 0.0334, 0.0429, 0.0260, 0.0461, 0.0941,
        0.0019, 0.1794, 0.0389, 0.0468, 0.0217, 0.0004], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,418][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0221, 0.1050, 0.1346, 0.0736, 0.0077, 0.0513, 0.1228, 0.0290, 0.0945,
        0.0347, 0.1273, 0.0462, 0.1109, 0.0381, 0.0022], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,419][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0080, 0.0189, 0.0336, 0.0519, 0.0609, 0.0521, 0.0889, 0.0572, 0.0520,
        0.1377, 0.0654, 0.1063, 0.0930, 0.0657, 0.1082], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,420][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.2094, 0.0025, 0.0060, 0.0141, 0.0124, 0.0252, 0.0400, 0.0397, 0.0527,
        0.0361, 0.0938, 0.1371, 0.0541, 0.1882, 0.0888], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,421][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0733, 0.0063, 0.0152, 0.0248, 0.0110, 0.0153, 0.0563, 0.0196, 0.0276,
        0.0035, 0.0155, 0.0030, 0.6835, 0.0384, 0.0068], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,422][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ give] are: tensor([7.3638e-09, 3.0135e-06, 1.9286e-07, 7.6753e-03, 7.1463e-07, 4.9612e-06,
        5.1293e-03, 7.0743e-06, 4.7387e-05, 8.5243e-03, 5.5909e-04, 9.1675e-01,
        2.7196e-04, 5.6859e-02, 4.1730e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,424][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0073, 0.0442, 0.0286, 0.0655, 0.0805, 0.0504, 0.1054, 0.0594, 0.0567,
        0.0925, 0.0520, 0.0833, 0.1165, 0.0542, 0.1034], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,426][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0356, 0.0438, 0.0473, 0.0700, 0.0664, 0.0455, 0.0971, 0.0608, 0.0570,
        0.0819, 0.0705, 0.0865, 0.0931, 0.0675, 0.0769], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,427][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.0390, 0.0450, 0.0463, 0.0553, 0.0579, 0.0493, 0.0572, 0.0977, 0.0508,
        0.0732, 0.0741, 0.0841, 0.0651, 0.0873, 0.0743, 0.0434],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,429][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ it] are: tensor([0.0165, 0.0084, 0.0146, 0.0448, 0.0351, 0.0596, 0.0346, 0.0931, 0.0813,
        0.0453, 0.0851, 0.0286, 0.0763, 0.0893, 0.1788, 0.1086],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,430][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ it] are: tensor([2.5330e-02, 7.3014e-02, 8.3570e-02, 2.8745e-02, 6.4107e-02, 2.5376e-02,
        1.9184e-02, 3.1490e-03, 3.4106e-03, 2.0536e-02, 2.1721e-03, 3.0794e-02,
        4.0038e-01, 1.1521e-02, 2.0871e-01, 9.0971e-06], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,432][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ it] are: tensor([0.2019, 0.0526, 0.0335, 0.0280, 0.0696, 0.1202, 0.0802, 0.1147, 0.0809,
        0.0185, 0.0107, 0.0327, 0.0871, 0.0177, 0.0465, 0.0053],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,434][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ it] are: tensor([9.0482e-02, 3.5295e-02, 2.3311e-01, 3.7921e-03, 3.1279e-02, 9.0984e-02,
        3.2042e-02, 4.0355e-02, 2.3457e-02, 1.6527e-03, 1.4431e-01, 4.1196e-02,
        1.3493e-01, 5.6028e-02, 4.0974e-02, 1.2050e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,435][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ it] are: tensor([0.0072, 0.0948, 0.1344, 0.0308, 0.0522, 0.0297, 0.2037, 0.0246, 0.0162,
        0.0435, 0.1164, 0.0564, 0.1008, 0.0222, 0.0650, 0.0021],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,437][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.0077, 0.0183, 0.0314, 0.0491, 0.0573, 0.0491, 0.0813, 0.0525, 0.0481,
        0.1227, 0.0607, 0.1004, 0.0866, 0.0638, 0.0980, 0.0731],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,439][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.2062, 0.0024, 0.0053, 0.0122, 0.0106, 0.0210, 0.0337, 0.0356, 0.0419,
        0.0288, 0.0804, 0.1231, 0.0464, 0.1636, 0.0791, 0.1096],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,440][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ it] are: tensor([3.1871e-02, 2.0030e-03, 2.3746e-02, 4.0770e-03, 3.9273e-02, 1.0034e-02,
        1.6448e-02, 1.7468e-01, 4.8479e-03, 4.2673e-02, 1.7831e-02, 1.1707e-03,
        3.4253e-01, 2.7195e-02, 2.6151e-01, 1.1861e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,442][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ it] are: tensor([4.9383e-09, 2.7398e-06, 6.6979e-08, 4.2592e-03, 3.1484e-07, 1.5940e-06,
        5.9453e-03, 2.1903e-06, 1.6124e-05, 5.0860e-03, 1.8884e-04, 9.4337e-01,
        1.6657e-04, 1.4127e-02, 5.5402e-03, 2.1298e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,443][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.0086, 0.0473, 0.0285, 0.0588, 0.0735, 0.0492, 0.1011, 0.0606, 0.0576,
        0.0784, 0.0465, 0.0854, 0.0997, 0.0539, 0.0865, 0.0644],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,445][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ it] are: tensor([0.0388, 0.0409, 0.0488, 0.0586, 0.0609, 0.0475, 0.0865, 0.0621, 0.0526,
        0.0757, 0.0715, 0.0783, 0.0817, 0.0673, 0.0752, 0.0536],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,447][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0425, 0.0393, 0.0432, 0.0488, 0.0514, 0.0478, 0.0602, 0.0953, 0.0491,
        0.0729, 0.0687, 0.0748, 0.0557, 0.0720, 0.0664, 0.0455, 0.0663],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,449][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0348, 0.0096, 0.0153, 0.0551, 0.0332, 0.0580, 0.0376, 0.0775, 0.0699,
        0.0487, 0.0768, 0.0333, 0.0676, 0.0769, 0.1264, 0.0918, 0.0878],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,450][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([5.8675e-02, 1.3251e-01, 5.7218e-02, 5.2863e-03, 7.1100e-02, 4.2779e-02,
        7.5794e-02, 2.4406e-02, 4.9386e-02, 3.8274e-03, 3.6649e-03, 5.2234e-02,
        2.0576e-01, 1.1117e-05, 1.8892e-01, 2.8428e-02, 7.6203e-06],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,452][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1764, 0.0719, 0.0388, 0.0488, 0.0308, 0.1654, 0.0484, 0.0391, 0.1128,
        0.0287, 0.0127, 0.0438, 0.0679, 0.0014, 0.0863, 0.0260, 0.0008],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,452][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.2183e-02, 1.4419e-02, 1.8015e-02, 2.1404e-04, 1.1829e-01, 1.1617e-02,
        9.6192e-03, 2.9136e-02, 1.0081e-02, 2.8396e-04, 2.2056e-02, 1.1108e-02,
        5.0579e-01, 2.4394e-03, 1.3692e-01, 9.5856e-02, 1.9681e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,453][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0139, 0.1605, 0.1698, 0.0650, 0.0503, 0.0134, 0.0827, 0.0274, 0.0260,
        0.0583, 0.0653, 0.0755, 0.0949, 0.0023, 0.0675, 0.0256, 0.0016],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,454][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0072, 0.0173, 0.0298, 0.0456, 0.0555, 0.0480, 0.0796, 0.0488, 0.0475,
        0.1121, 0.0593, 0.0952, 0.0821, 0.0599, 0.0877, 0.0690, 0.0553],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,456][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1875, 0.0023, 0.0044, 0.0098, 0.0085, 0.0173, 0.0274, 0.0301, 0.0325,
        0.0230, 0.0649, 0.1026, 0.0386, 0.1358, 0.0668, 0.0916, 0.1570],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,457][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([4.5077e-03, 2.8526e-04, 4.3820e-03, 1.0572e-03, 4.1748e-02, 2.1024e-03,
        1.2418e-02, 6.0587e-03, 1.4706e-03, 2.0634e-03, 3.3894e-03, 1.6010e-04,
        1.2096e-01, 2.5381e-05, 7.9899e-01, 3.5606e-04, 1.9117e-05],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,459][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([5.7245e-09, 3.0755e-07, 2.9851e-09, 1.0231e-03, 9.4740e-09, 3.4200e-08,
        7.6616e-03, 7.1792e-08, 1.3500e-06, 2.1132e-03, 1.9588e-05, 9.4644e-01,
        3.4147e-05, 7.2267e-04, 3.4473e-03, 1.3970e-02, 2.4567e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,461][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0092, 0.0439, 0.0283, 0.0583, 0.0715, 0.0472, 0.0886, 0.0532, 0.0536,
        0.0814, 0.0456, 0.0776, 0.0892, 0.0523, 0.0828, 0.0651, 0.0523],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,463][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0346, 0.0364, 0.0470, 0.0595, 0.0569, 0.0435, 0.0804, 0.0599, 0.0516,
        0.0706, 0.0665, 0.0709, 0.0773, 0.0621, 0.0679, 0.0569, 0.0578],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,503][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:32,504][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,505][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,506][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,507][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,507][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,508][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,509][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,509][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,510][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,511][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,511][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,513][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,515][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Sara] are: tensor([0.3910, 0.6090], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,516][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Sara] are: tensor([0.8151, 0.1849], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,517][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Sara] are: tensor([0.7488, 0.2512], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,518][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Sara] are: tensor([0.3006, 0.6994], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,518][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Sara] are: tensor([0.9503, 0.0497], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,519][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Sara] are: tensor([0.0342, 0.9658], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,520][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Sara] are: tensor([0.2349, 0.7651], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,521][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Sara] are: tensor([0.4196, 0.5804], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,521][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Sara] are: tensor([0.8305, 0.1695], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,522][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Sara] are: tensor([0.0550, 0.9450], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,523][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Sara] are: tensor([0.2116, 0.7884], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,524][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Sara] are: tensor([0.1080, 0.8920], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,524][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1339, 0.3390, 0.5271], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,526][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.7856, 0.0475, 0.1669], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,527][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0078, 0.9912, 0.0010], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,529][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0241, 0.9144, 0.0615], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,531][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.5608, 0.1299, 0.3094], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,532][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0048, 0.2746, 0.7205], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,534][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1625, 0.4703, 0.3672], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,536][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2873, 0.5214, 0.1913], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,536][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.4245, 0.1998, 0.3757], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,537][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0101, 0.9559, 0.0339], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,538][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1285, 0.4188, 0.4527], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,539][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0841, 0.5993, 0.3166], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,539][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Kenneth] are: tensor([0.0552, 0.1615, 0.5713, 0.2120], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,541][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Kenneth] are: tensor([0.6164, 0.0859, 0.2507, 0.0470], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,542][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Kenneth] are: tensor([2.3348e-03, 9.5813e-01, 3.8654e-02, 8.8468e-04], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,544][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Kenneth] are: tensor([0.0035, 0.2728, 0.0363, 0.6875], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,545][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Kenneth] are: tensor([0.3764, 0.1986, 0.3794, 0.0455], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,546][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Kenneth] are: tensor([2.1789e-04, 5.8544e-02, 3.9396e-01, 5.4728e-01], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,548][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Kenneth] are: tensor([0.0430, 0.1538, 0.1016, 0.7016], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,549][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Kenneth] are: tensor([0.2445, 0.3606, 0.1922, 0.2028], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,551][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Kenneth] are: tensor([0.3453, 0.1282, 0.3996, 0.1269], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,553][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Kenneth] are: tensor([0.0104, 0.8679, 0.0678, 0.0540], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,554][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Kenneth] are: tensor([0.0738, 0.2639, 0.2910, 0.3713], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,556][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Kenneth] are: tensor([0.0601, 0.3707, 0.2714, 0.2978], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,558][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.0261, 0.0770, 0.2978, 0.3630, 0.2360], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,559][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.4866, 0.0949, 0.2293, 0.0652, 0.1240], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,561][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.0392, 0.5079, 0.2438, 0.1997, 0.0094], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,563][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.0018, 0.1492, 0.0312, 0.7632, 0.0547], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,564][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.4573, 0.0552, 0.3204, 0.0428, 0.1243], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,565][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([8.6544e-05, 1.2033e-02, 1.0260e-01, 4.5626e-01, 4.2903e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,567][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.0338, 0.1210, 0.0852, 0.4601, 0.2999], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,569][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.2068, 0.2943, 0.1680, 0.2103, 0.1206], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,570][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.1902, 0.0723, 0.2518, 0.2839, 0.2017], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,571][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.0037, 0.6529, 0.0544, 0.2647, 0.0244], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,571][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.0500, 0.1710, 0.1890, 0.2404, 0.3496], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,572][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.0447, 0.2759, 0.1791, 0.2185, 0.2818], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,573][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0251, 0.0428, 0.1542, 0.1621, 0.3357, 0.2800], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,575][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.4191, 0.0697, 0.1898, 0.0639, 0.0526, 0.2049], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,576][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([5.2719e-02, 5.4774e-01, 2.1230e-01, 4.6626e-02, 1.4035e-01, 2.5575e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,577][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.8481e-04, 6.5885e-02, 1.1369e-02, 7.7130e-01, 6.0749e-02, 9.0511e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,579][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.2612, 0.0889, 0.2473, 0.0583, 0.2005, 0.1438], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,580][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.0714e-04, 6.6146e-03, 4.5898e-02, 1.6426e-01, 4.0526e-01, 3.7786e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,581][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0219, 0.0950, 0.0774, 0.4019, 0.2968, 0.1070], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,583][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1436, 0.2670, 0.1183, 0.2008, 0.1052, 0.1652], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,585][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1123, 0.0679, 0.1648, 0.2170, 0.3268, 0.1112], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,586][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0103, 0.4292, 0.0829, 0.3134, 0.0797, 0.0846], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,588][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0375, 0.1274, 0.1403, 0.1788, 0.2600, 0.2560], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,590][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0349, 0.2023, 0.1360, 0.1615, 0.2459, 0.2194], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,591][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.0132, 0.0258, 0.1275, 0.1132, 0.3662, 0.2382, 0.1158],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,593][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.2569, 0.0676, 0.1463, 0.0350, 0.0676, 0.2728, 0.1537],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,595][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.0188, 0.5818, 0.1255, 0.1796, 0.0497, 0.0414, 0.0032],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,596][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([1.0429e-04, 5.2500e-02, 5.4392e-03, 2.5153e-01, 3.7262e-02, 7.3038e-02,
        5.8013e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,597][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.3234, 0.0267, 0.1918, 0.0399, 0.2245, 0.1790, 0.0147],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,598][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([1.6605e-05, 1.4754e-03, 1.5821e-02, 7.0414e-02, 2.0420e-01, 4.0298e-01,
        3.0509e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,600][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.0107, 0.0465, 0.0292, 0.2322, 0.1514, 0.0394, 0.4907],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,602][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.1534, 0.2057, 0.1272, 0.1185, 0.0968, 0.1389, 0.1596],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,603][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.1357, 0.0358, 0.1828, 0.0912, 0.3194, 0.1486, 0.0866],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,604][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.0054, 0.3956, 0.0446, 0.1711, 0.1339, 0.1569, 0.0925],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,605][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.0260, 0.0984, 0.1087, 0.1402, 0.2082, 0.2058, 0.2127],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,606][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.0373, 0.1637, 0.1418, 0.1331, 0.2123, 0.2071, 0.1045],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,607][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0066, 0.0157, 0.0458, 0.0615, 0.0654, 0.1438, 0.2301, 0.4313],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:32,608][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.3003, 0.0427, 0.1600, 0.0337, 0.0793, 0.1954, 0.0989, 0.0897],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:32,610][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0513, 0.4591, 0.0965, 0.1379, 0.0739, 0.0709, 0.1096, 0.0009],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:32,611][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([5.3671e-05, 1.8787e-02, 3.2841e-03, 2.3016e-01, 1.7143e-02, 4.7154e-02,
        6.2805e-01, 5.5370e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:32,613][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.1757, 0.0539, 0.2346, 0.0470, 0.1510, 0.2203, 0.0340, 0.0835],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:32,614][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([1.0900e-05, 2.3113e-04, 2.3430e-03, 1.0372e-02, 2.8400e-02, 7.8274e-02,
        4.6915e-01, 4.1122e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:32,615][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0151, 0.0582, 0.0427, 0.2176, 0.1472, 0.0589, 0.3885, 0.0718],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:32,617][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.1291, 0.1863, 0.0844, 0.1498, 0.0924, 0.1281, 0.1562, 0.0738],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:32,619][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0594, 0.0320, 0.0972, 0.0923, 0.3038, 0.1706, 0.0843, 0.1605],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:32,621][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0031, 0.2704, 0.0371, 0.2828, 0.0575, 0.1452, 0.1873, 0.0165],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:32,622][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0261, 0.0864, 0.0948, 0.1196, 0.1722, 0.1698, 0.1767, 0.1544],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:32,624][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0313, 0.1529, 0.0978, 0.1140, 0.1672, 0.1584, 0.0961, 0.1823],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:32,626][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0058, 0.0095, 0.0270, 0.0350, 0.0395, 0.0604, 0.1074, 0.4531, 0.2623],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:32,627][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.2045, 0.0511, 0.1353, 0.0379, 0.0697, 0.1455, 0.1480, 0.0747, 0.1333],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:32,629][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([2.3330e-02, 4.2686e-01, 8.6818e-02, 6.1847e-02, 2.2422e-01, 3.4439e-03,
        1.3347e-02, 1.6003e-01, 1.0781e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:32,630][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([8.2472e-06, 5.9990e-03, 1.4358e-03, 1.3321e-01, 8.6308e-03, 3.2662e-02,
        5.1547e-01, 6.1854e-02, 2.4073e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:32,632][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1667, 0.1457, 0.1453, 0.0627, 0.0814, 0.1419, 0.0628, 0.1046, 0.0889],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:32,633][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([4.3235e-06, 8.9245e-05, 8.0719e-04, 2.2489e-03, 7.7037e-03, 1.6897e-02,
        1.2082e-01, 2.9650e-01, 5.5493e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:32,635][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0117, 0.0519, 0.0432, 0.2098, 0.1575, 0.0608, 0.3415, 0.0789, 0.0447],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:32,636][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1124, 0.1665, 0.0875, 0.1241, 0.0766, 0.1188, 0.1504, 0.0735, 0.0902],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:32,637][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0430, 0.0303, 0.0826, 0.1142, 0.1611, 0.0848, 0.1094, 0.3292, 0.0453],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:32,638][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0067, 0.2363, 0.0501, 0.2143, 0.0572, 0.0539, 0.2400, 0.1026, 0.0389],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:32,639][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0214, 0.0723, 0.0800, 0.1013, 0.1464, 0.1453, 0.1503, 0.1334, 0.1496],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:32,640][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0285, 0.1257, 0.0773, 0.0877, 0.1414, 0.1212, 0.0776, 0.1432, 0.1974],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:32,642][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ garden] are: tensor([0.0033, 0.0089, 0.0213, 0.0269, 0.0570, 0.0509, 0.0766, 0.3959, 0.2287,
        0.1305], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:32,643][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ garden] are: tensor([0.2525, 0.0182, 0.0950, 0.0129, 0.0199, 0.1751, 0.0759, 0.0635, 0.2537,
        0.0335], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:32,645][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ garden] are: tensor([0.0419, 0.2491, 0.0807, 0.2414, 0.0789, 0.1820, 0.0501, 0.0115, 0.0642,
        0.0003], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:32,646][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ garden] are: tensor([1.2807e-05, 7.2648e-03, 1.1102e-03, 5.8272e-02, 8.4249e-03, 2.0599e-02,
        2.6592e-01, 5.1023e-02, 2.4033e-01, 3.4705e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:32,647][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ garden] are: tensor([0.1487, 0.0313, 0.1793, 0.0131, 0.1308, 0.1357, 0.0316, 0.1074, 0.2070,
        0.0151], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:32,649][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ garden] are: tensor([1.1489e-06, 3.2172e-05, 2.8374e-04, 1.2582e-03, 6.2452e-03, 7.6686e-03,
        2.0697e-02, 1.8539e-01, 6.4701e-01, 1.3142e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:32,650][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ garden] are: tensor([0.0106, 0.0368, 0.0249, 0.1543, 0.0894, 0.0325, 0.2678, 0.0453, 0.0276,
        0.3109], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:32,652][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ garden] are: tensor([0.1118, 0.1846, 0.0914, 0.1017, 0.0711, 0.1031, 0.1394, 0.0627, 0.0722,
        0.0620], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:32,654][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ garden] are: tensor([0.0559, 0.0203, 0.0899, 0.0644, 0.0940, 0.0804, 0.0916, 0.3532, 0.0889,
        0.0613], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:32,656][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ garden] are: tensor([0.0021, 0.3599, 0.0330, 0.1590, 0.0462, 0.0838, 0.1488, 0.0690, 0.0821,
        0.0160], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:32,657][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ garden] are: tensor([0.0174, 0.0618, 0.0686, 0.0866, 0.1270, 0.1254, 0.1292, 0.1153, 0.1278,
        0.1408], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:32,659][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ garden] are: tensor([0.0227, 0.0892, 0.0784, 0.0667, 0.1035, 0.1092, 0.0579, 0.1445, 0.1774,
        0.1506], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:32,661][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0046, 0.0058, 0.0180, 0.0176, 0.0307, 0.0500, 0.0473, 0.2100, 0.1872,
        0.1405, 0.2884], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:32,663][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1757, 0.0323, 0.0876, 0.0272, 0.0530, 0.1341, 0.0837, 0.0854, 0.1612,
        0.0483, 0.1115], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:32,664][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([2.7367e-02, 2.4127e-01, 5.7435e-02, 9.3922e-02, 2.8473e-01, 6.9014e-02,
        6.8791e-02, 6.5455e-02, 1.9335e-02, 7.2577e-02, 1.0655e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:32,665][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([5.4734e-06, 5.2033e-03, 8.5352e-04, 6.7041e-02, 5.6351e-03, 1.5597e-02,
        1.9718e-01, 2.8388e-02, 1.6800e-01, 3.6909e-01, 1.4301e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:32,667][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1477, 0.0373, 0.0901, 0.0451, 0.0722, 0.1604, 0.0467, 0.0652, 0.1909,
        0.0476, 0.0969], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:32,668][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([4.6470e-07, 5.5416e-06, 5.7951e-05, 1.5217e-04, 8.4829e-04, 1.8393e-03,
        5.6622e-03, 2.8912e-02, 1.2627e-01, 1.4676e-01, 6.8949e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:32,670][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0099, 0.0381, 0.0336, 0.1352, 0.1104, 0.0436, 0.2332, 0.0545, 0.0329,
        0.2852, 0.0235], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:32,671][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1047, 0.1587, 0.0745, 0.1122, 0.0701, 0.1005, 0.1249, 0.0636, 0.0746,
        0.0717, 0.0445], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:32,671][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0543, 0.0193, 0.0553, 0.0724, 0.1116, 0.0822, 0.0930, 0.2281, 0.0650,
        0.1510, 0.0679], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:32,672][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0037, 0.2052, 0.0373, 0.1555, 0.0344, 0.1399, 0.1513, 0.0742, 0.1136,
        0.0645, 0.0204], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:32,673][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0177, 0.0564, 0.0626, 0.0784, 0.1120, 0.1109, 0.1158, 0.1017, 0.1139,
        0.1223, 0.1083], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:32,675][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0261, 0.0976, 0.0574, 0.0620, 0.0986, 0.0829, 0.0514, 0.0929, 0.1283,
        0.1299, 0.1730], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:32,676][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Sara] are: tensor([0.0018, 0.0010, 0.0074, 0.0062, 0.0119, 0.0299, 0.0110, 0.1202, 0.1414,
        0.0355, 0.3141, 0.3194], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:32,678][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Sara] are: tensor([0.1262, 0.0706, 0.0972, 0.0364, 0.0371, 0.1175, 0.1287, 0.0593, 0.1031,
        0.0791, 0.1057, 0.0392], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:32,680][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Sara] are: tensor([0.0607, 0.0092, 0.1946, 0.1459, 0.0799, 0.1330, 0.1916, 0.0052, 0.1462,
        0.0223, 0.0085, 0.0029], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:32,681][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Sara] are: tensor([2.0851e-06, 8.3513e-04, 1.5974e-04, 8.5289e-03, 9.1094e-04, 2.7619e-03,
        4.1543e-02, 6.5377e-03, 3.0055e-02, 7.3474e-02, 3.5898e-02, 7.9929e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:32,683][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Sara] are: tensor([0.1582, 0.0080, 0.0795, 0.0220, 0.1387, 0.1591, 0.0648, 0.0570, 0.1301,
        0.0228, 0.1548, 0.0051], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:32,684][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Sara] are: tensor([4.4232e-08, 2.8513e-07, 5.0794e-06, 2.5250e-05, 7.6616e-05, 2.8192e-04,
        9.7454e-04, 3.6884e-03, 1.8418e-02, 1.6541e-02, 3.0807e-01, 6.5192e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:32,686][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Sara] are: tensor([0.0075, 0.0294, 0.0191, 0.1251, 0.0705, 0.0252, 0.1937, 0.0337, 0.0199,
        0.2455, 0.0134, 0.2171], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:32,688][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Sara] are: tensor([0.1052, 0.1373, 0.0754, 0.0891, 0.0616, 0.0996, 0.1034, 0.0639, 0.0750,
        0.0631, 0.0521, 0.0745], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:32,689][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Sara] are: tensor([0.0487, 0.0113, 0.0620, 0.0528, 0.0990, 0.0667, 0.0779, 0.2738, 0.0750,
        0.1049, 0.0969, 0.0309], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:32,691][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Sara] are: tensor([0.0042, 0.0525, 0.0348, 0.1586, 0.0703, 0.0996, 0.1479, 0.0921, 0.1361,
        0.1346, 0.0385, 0.0307], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:32,693][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Sara] are: tensor([0.0139, 0.0497, 0.0546, 0.0703, 0.1026, 0.1012, 0.1017, 0.0937, 0.1036,
        0.1129, 0.0973, 0.0985], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:32,695][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Sara] are: tensor([0.0172, 0.0643, 0.0415, 0.0478, 0.0680, 0.0619, 0.0324, 0.0787, 0.1049,
        0.0919, 0.1595, 0.2320], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:32,697][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.0017, 0.0008, 0.0065, 0.0050, 0.0146, 0.0187, 0.0164, 0.0659, 0.0785,
        0.0384, 0.2949, 0.3156, 0.1429], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:32,698][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.2432, 0.0217, 0.1648, 0.0225, 0.0546, 0.0964, 0.0736, 0.0525, 0.1051,
        0.0259, 0.1032, 0.0172, 0.0193], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:32,700][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0258, 0.2397, 0.1983, 0.0147, 0.1181, 0.0336, 0.0203, 0.0136, 0.1262,
        0.0509, 0.0169, 0.1389, 0.0029], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:32,701][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([5.4936e-06, 1.4000e-03, 1.9720e-04, 9.4523e-03, 7.0536e-04, 1.7773e-03,
        2.3678e-02, 3.4869e-03, 1.5754e-02, 4.4838e-02, 2.7502e-02, 8.3910e-01,
        3.2098e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:32,703][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.1923, 0.0131, 0.0993, 0.0118, 0.1029, 0.1089, 0.0158, 0.0607, 0.1451,
        0.0232, 0.1779, 0.0175, 0.0313], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:32,704][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([1.1489e-08, 1.3155e-07, 1.2403e-06, 3.0298e-06, 1.6606e-05, 5.6864e-05,
        1.8778e-04, 6.7324e-04, 3.8215e-03, 2.6578e-03, 1.0544e-01, 7.1154e-01,
        1.7560e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:32,705][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0075, 0.0283, 0.0196, 0.1106, 0.0656, 0.0247, 0.1527, 0.0344, 0.0200,
        0.2232, 0.0147, 0.1923, 0.1064], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:32,706][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0867, 0.1205, 0.0790, 0.0918, 0.0507, 0.0873, 0.0913, 0.0584, 0.0668,
        0.0543, 0.0566, 0.0684, 0.0882], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:32,707][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0469, 0.0169, 0.0467, 0.0574, 0.0786, 0.0664, 0.0524, 0.1498, 0.0604,
        0.0715, 0.0950, 0.0455, 0.2125], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:32,708][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0034, 0.1676, 0.0355, 0.1179, 0.0344, 0.1114, 0.1293, 0.0877, 0.0885,
        0.0492, 0.0427, 0.1043, 0.0279], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:32,710][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.0136, 0.0451, 0.0509, 0.0636, 0.0925, 0.0915, 0.0915, 0.0842, 0.0928,
        0.1005, 0.0888, 0.0868, 0.0982], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:32,712][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0208, 0.0574, 0.0448, 0.0370, 0.0620, 0.0553, 0.0308, 0.0706, 0.0913,
        0.0684, 0.1634, 0.1780, 0.1200], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:32,713][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.1233e-04, 3.2475e-04, 1.9191e-03, 1.2560e-03, 3.3160e-03, 4.0533e-03,
        9.3501e-03, 1.9613e-02, 1.8151e-02, 2.0310e-02, 7.4862e-02, 1.0974e-01,
        9.7484e-02, 6.3871e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,715][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.2027, 0.0187, 0.0742, 0.0147, 0.0236, 0.1261, 0.0652, 0.0431, 0.1398,
        0.0244, 0.1350, 0.0231, 0.0235, 0.0860], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,716][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([7.1231e-02, 1.7655e-01, 7.1315e-02, 7.1601e-03, 9.1057e-02, 5.4888e-02,
        9.3692e-02, 3.0210e-02, 6.0729e-02, 5.0556e-03, 4.3936e-03, 6.7320e-02,
        2.6639e-01, 1.4032e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,717][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.8611e-06, 1.1225e-03, 1.6908e-04, 9.4587e-03, 7.5438e-04, 2.3439e-03,
        3.3780e-02, 4.4773e-03, 2.2826e-02, 5.0186e-02, 2.9564e-02, 7.6023e-01,
        5.7694e-02, 2.7394e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,719][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0769, 0.0345, 0.1030, 0.0107, 0.1033, 0.0868, 0.0314, 0.0684, 0.0783,
        0.0131, 0.1304, 0.0335, 0.1685, 0.0611], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,721][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.8563e-08, 6.6490e-08, 5.1756e-07, 8.4001e-07, 2.7970e-06, 1.1491e-05,
        5.9315e-05, 1.3074e-04, 8.4643e-04, 1.2572e-03, 2.1608e-02, 1.4663e-01,
        1.1153e-01, 7.1793e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,722][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0071, 0.0271, 0.0212, 0.1005, 0.0729, 0.0254, 0.1389, 0.0321, 0.0186,
        0.2052, 0.0139, 0.2074, 0.1157, 0.0141], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,724][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0755, 0.1077, 0.0569, 0.0868, 0.0627, 0.0780, 0.1002, 0.0547, 0.0648,
        0.0585, 0.0426, 0.0635, 0.1098, 0.0383], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,726][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0200, 0.0103, 0.0413, 0.0435, 0.1124, 0.0449, 0.0766, 0.1026, 0.0365,
        0.0953, 0.0619, 0.0326, 0.2927, 0.0294], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,728][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0028, 0.1637, 0.0240, 0.1375, 0.0239, 0.1166, 0.1188, 0.0279, 0.1037,
        0.0609, 0.0322, 0.0958, 0.0872, 0.0051], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,730][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0132, 0.0426, 0.0465, 0.0587, 0.0834, 0.0826, 0.0862, 0.0756, 0.0846,
        0.0918, 0.0796, 0.0806, 0.0886, 0.0860], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,731][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0272, 0.0615, 0.0383, 0.0336, 0.0586, 0.0484, 0.0269, 0.0535, 0.0750,
        0.0635, 0.1139, 0.1393, 0.1128, 0.1473], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:32,733][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([4.3691e-04, 3.0071e-04, 1.1196e-03, 1.0890e-03, 8.5794e-04, 2.3583e-03,
        6.6336e-03, 1.1135e-02, 1.3313e-02, 1.1578e-02, 5.0267e-02, 7.9435e-02,
        6.4866e-02, 6.3813e-01, 1.1848e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,734][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.1343, 0.0351, 0.1150, 0.0275, 0.0612, 0.0838, 0.0848, 0.0431, 0.1038,
        0.0410, 0.0941, 0.0211, 0.0466, 0.0508, 0.0579], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,736][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0302, 0.1318, 0.0483, 0.0520, 0.0201, 0.0168, 0.0622, 0.0135, 0.0313,
        0.0413, 0.0079, 0.0437, 0.3373, 0.1628, 0.0008], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,737][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([4.5484e-06, 1.3331e-03, 2.4944e-04, 8.9531e-03, 8.3711e-04, 2.5300e-03,
        3.7545e-02, 4.5240e-03, 2.5199e-02, 4.7803e-02, 2.9749e-02, 6.8961e-01,
        6.0588e-02, 3.3564e-02, 5.7507e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,738][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.1145, 0.0253, 0.1097, 0.0173, 0.0597, 0.0888, 0.0273, 0.0612, 0.1143,
        0.0176, 0.1810, 0.0329, 0.0690, 0.0736, 0.0078], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,739][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([5.7661e-09, 1.8175e-08, 1.6536e-07, 4.5178e-07, 4.7585e-07, 4.7013e-06,
        1.9507e-05, 3.4950e-05, 3.2705e-04, 5.4548e-04, 8.9846e-03, 4.2054e-02,
        4.8712e-02, 6.0488e-01, 2.9444e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,740][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0056, 0.0237, 0.0162, 0.0927, 0.0559, 0.0196, 0.1426, 0.0265, 0.0149,
        0.2038, 0.0106, 0.1782, 0.0960, 0.0098, 0.1039], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,742][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0797, 0.1029, 0.0640, 0.0702, 0.0529, 0.0831, 0.0752, 0.0518, 0.0593,
        0.0415, 0.0418, 0.0556, 0.1092, 0.0393, 0.0736], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,743][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0339, 0.0115, 0.0330, 0.0453, 0.0425, 0.0401, 0.0528, 0.0801, 0.0418,
        0.0475, 0.0515, 0.0264, 0.3285, 0.0799, 0.0854], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,745][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0035, 0.1537, 0.0180, 0.0805, 0.0199, 0.0934, 0.1428, 0.1087, 0.0882,
        0.0542, 0.0270, 0.1071, 0.0806, 0.0101, 0.0124], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,747][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0114, 0.0372, 0.0423, 0.0528, 0.0762, 0.0758, 0.0757, 0.0698, 0.0767,
        0.0828, 0.0732, 0.0715, 0.0806, 0.0798, 0.0941], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,749][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0224, 0.0440, 0.0341, 0.0251, 0.0467, 0.0417, 0.0201, 0.0477, 0.0625,
        0.0447, 0.1012, 0.1128, 0.0879, 0.1362, 0.1729], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:32,750][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([2.5636e-04, 1.3733e-04, 4.8025e-04, 5.0749e-04, 1.0692e-03, 9.9976e-04,
        2.2850e-03, 6.6570e-03, 3.7371e-03, 5.7034e-03, 2.6007e-02, 4.4173e-02,
        1.7769e-02, 2.9148e-01, 4.1608e-01, 1.8266e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,752][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([0.1510, 0.0399, 0.0688, 0.0266, 0.0566, 0.1072, 0.0928, 0.0466, 0.0826,
        0.0378, 0.0821, 0.0311, 0.0236, 0.0464, 0.0308, 0.0760],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,753][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([2.5330e-02, 7.3014e-02, 8.3570e-02, 2.8745e-02, 6.4107e-02, 2.5376e-02,
        1.9184e-02, 3.1490e-03, 3.4106e-03, 2.0536e-02, 2.1721e-03, 3.0794e-02,
        4.0038e-01, 1.1521e-02, 2.0871e-01, 9.0971e-06], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,754][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([1.6043e-06, 7.8341e-04, 1.3652e-04, 6.8193e-03, 7.6067e-04, 2.2729e-03,
        3.4388e-02, 5.0767e-03, 2.5758e-02, 4.4217e-02, 3.2603e-02, 6.2599e-01,
        4.9715e-02, 4.9209e-02, 7.9017e-02, 4.3248e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,756][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.0789, 0.0292, 0.0911, 0.0146, 0.0468, 0.1154, 0.0428, 0.0524, 0.0893,
        0.0183, 0.1698, 0.0411, 0.0860, 0.0909, 0.0241, 0.0094],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,757][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([1.6197e-09, 6.6701e-09, 4.9419e-08, 5.5248e-08, 2.1937e-07, 8.0101e-07,
        7.2307e-06, 7.3033e-06, 5.4780e-05, 1.3845e-04, 2.2241e-03, 1.3074e-02,
        9.2116e-03, 1.7041e-01, 3.4743e-01, 4.5745e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,759][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([0.0064, 0.0230, 0.0183, 0.0870, 0.0597, 0.0232, 0.1186, 0.0316, 0.0180,
        0.1892, 0.0135, 0.1652, 0.0989, 0.0126, 0.1028, 0.0321],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,761][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.0780, 0.0993, 0.0565, 0.0652, 0.0496, 0.0746, 0.0804, 0.0512, 0.0568,
        0.0472, 0.0414, 0.0562, 0.0895, 0.0371, 0.0616, 0.0555],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,763][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.0219, 0.0090, 0.0331, 0.0301, 0.0550, 0.0382, 0.0374, 0.1293, 0.0298,
        0.0797, 0.0522, 0.0226, 0.2038, 0.0737, 0.1690, 0.0150],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,764][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([0.0023, 0.1061, 0.0311, 0.1332, 0.0319, 0.1057, 0.1287, 0.0514, 0.0742,
        0.0541, 0.0403, 0.0628, 0.0733, 0.0146, 0.0742, 0.0160],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,766][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.0109, 0.0355, 0.0395, 0.0493, 0.0707, 0.0706, 0.0717, 0.0647, 0.0719,
        0.0768, 0.0679, 0.0671, 0.0750, 0.0743, 0.0870, 0.0671],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,768][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([0.0221, 0.0404, 0.0283, 0.0211, 0.0354, 0.0336, 0.0170, 0.0387, 0.0483,
        0.0387, 0.0825, 0.0901, 0.0706, 0.1096, 0.1452, 0.1785],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:32,769][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([2.4531e-04, 6.5572e-05, 2.8648e-04, 2.3473e-04, 4.9611e-04, 4.9254e-04,
        1.6502e-03, 2.6846e-03, 2.0928e-03, 3.2811e-03, 1.1555e-02, 1.7074e-02,
        1.1782e-02, 8.0997e-02, 1.2821e-01, 1.1436e-01, 6.2450e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,771][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1555, 0.0159, 0.0568, 0.0123, 0.0192, 0.1020, 0.0518, 0.0366, 0.1134,
        0.0198, 0.1102, 0.0198, 0.0204, 0.0684, 0.0358, 0.0897, 0.0726],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,772][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([5.8675e-02, 1.3251e-01, 5.7218e-02, 5.2863e-03, 7.1100e-02, 4.2779e-02,
        7.5794e-02, 2.4406e-02, 4.9386e-02, 3.8274e-03, 3.6649e-03, 5.2234e-02,
        2.0576e-01, 1.1117e-05, 1.8892e-01, 2.8428e-02, 7.6203e-06],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,773][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.4532e-06, 9.6432e-04, 1.3977e-04, 8.1639e-03, 7.1364e-04, 2.3943e-03,
        3.4974e-02, 4.6349e-03, 2.1707e-02, 4.7166e-02, 2.7886e-02, 5.9396e-01,
        4.6886e-02, 2.3960e-02, 7.6645e-02, 6.2153e-02, 4.7654e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,774][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0632, 0.0243, 0.0826, 0.0081, 0.0867, 0.0722, 0.0232, 0.0596, 0.0655,
        0.0103, 0.1113, 0.0237, 0.1578, 0.0547, 0.0411, 0.0713, 0.0444],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,775][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.1054e-09, 1.4350e-09, 1.0508e-08, 1.2976e-08, 3.4980e-08, 1.6252e-07,
        9.5188e-07, 1.4887e-06, 1.0138e-05, 1.6460e-05, 3.0439e-04, 1.6840e-03,
        1.2098e-03, 7.8538e-03, 4.2556e-02, 2.0031e-01, 7.4605e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,776][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0059, 0.0226, 0.0189, 0.0842, 0.0643, 0.0224, 0.1116, 0.0284, 0.0163,
        0.1740, 0.0125, 0.1768, 0.0993, 0.0118, 0.1045, 0.0341, 0.0122],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,778][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0631, 0.0905, 0.0473, 0.0731, 0.0529, 0.0652, 0.0843, 0.0465, 0.0550,
        0.0494, 0.0362, 0.0541, 0.0924, 0.0325, 0.0614, 0.0643, 0.0318],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,780][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0143, 0.0069, 0.0290, 0.0308, 0.0833, 0.0302, 0.0556, 0.0706, 0.0250,
        0.0663, 0.0430, 0.0219, 0.2026, 0.0199, 0.2579, 0.0233, 0.0193],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,781][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0026, 0.1459, 0.0216, 0.1177, 0.0218, 0.1008, 0.1049, 0.0252, 0.0909,
        0.0521, 0.0283, 0.0860, 0.0770, 0.0048, 0.0647, 0.0510, 0.0046],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,783][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0107, 0.0339, 0.0372, 0.0466, 0.0657, 0.0655, 0.0671, 0.0602, 0.0669,
        0.0721, 0.0629, 0.0636, 0.0697, 0.0681, 0.0798, 0.0623, 0.0677],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,785][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0233, 0.0394, 0.0248, 0.0195, 0.0341, 0.0284, 0.0153, 0.0306, 0.0421,
        0.0337, 0.0620, 0.0735, 0.0594, 0.0807, 0.1135, 0.1623, 0.1574],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:32,789][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:32,791][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[14509],
        [14601],
        [13649],
        [  106],
        [27472],
        [14157],
        [ 5562],
        [13620],
        [15947],
        [15729],
        [ 4626],
        [13951],
        [ 4934],
        [12678],
        [ 8060],
        [15337],
        [ 8134]], device='cuda:0')
[2024-07-24 10:29:32,793][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[14167],
        [16132],
        [10219],
        [   12],
        [35869],
        [18974],
        [ 5036],
        [18823],
        [18628],
        [ 9049],
        [ 5907],
        [20662],
        [ 9704],
        [13876],
        [16181],
        [25629],
        [10802]], device='cuda:0')
[2024-07-24 10:29:32,794][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[1118],
        [ 869],
        [1016],
        [1132],
        [1011],
        [1016],
        [ 933],
        [ 791],
        [ 780],
        [ 787],
        [ 880],
        [ 808],
        [ 768],
        [ 732],
        [ 702],
        [ 698],
        [ 692]], device='cuda:0')
[2024-07-24 10:29:32,796][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[15378],
        [15387],
        [14858],
        [16571],
        [12549],
        [10742],
        [13796],
        [ 9509],
        [ 9171],
        [10258],
        [ 8851],
        [11172],
        [ 8330],
        [ 8236],
        [ 6698],
        [ 6354],
        [ 6778]], device='cuda:0')
[2024-07-24 10:29:32,798][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 2674],
        [ 4524],
        [33438],
        [32602],
        [19708],
        [21848],
        [27242],
        [27769],
        [22827],
        [22938],
        [29289],
        [13967],
        [18707],
        [18311],
        [15229],
        [11518],
        [13261]], device='cuda:0')
[2024-07-24 10:29:32,800][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[20386],
        [15375],
        [13444],
        [10650],
        [14568],
        [11773],
        [16737],
        [20373],
        [19765],
        [15087],
        [16879],
        [16668],
        [17687],
        [17161],
        [16875],
        [17499],
        [16482]], device='cuda:0')
[2024-07-24 10:29:32,802][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 9867],
        [ 9867],
        [10388],
        [13963],
        [10827],
        [18185],
        [14223],
        [18705],
        [20636],
        [17018],
        [13517],
        [ 8366],
        [12333],
        [16173],
        [15907],
        [14217],
        [16491]], device='cuda:0')
[2024-07-24 10:29:32,804][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[20504],
        [12910],
        [12646],
        [15773],
        [19695],
        [19035],
        [19373],
        [13857],
        [17868],
        [17639],
        [20449],
        [18151],
        [14793],
        [17204],
        [16960],
        [15294],
        [17034]], device='cuda:0')
[2024-07-24 10:29:32,805][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[36695],
        [34028],
        [34511],
        [33344],
        [34179],
        [34921],
        [32461],
        [33586],
        [34175],
        [32668],
        [33011],
        [32112],
        [32297],
        [32494],
        [32259],
        [32319],
        [32394]], device='cuda:0')
[2024-07-24 10:29:32,807][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[28902],
        [28723],
        [27320],
        [27351],
        [26501],
        [26677],
        [27037],
        [26042],
        [26080],
        [26141],
        [25855],
        [26116],
        [26226],
        [26363],
        [26321],
        [26407],
        [26415]], device='cuda:0')
[2024-07-24 10:29:32,808][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[44867],
        [44959],
        [45458],
        [46348],
        [45228],
        [36664],
        [42962],
        [18028],
        [31572],
        [36389],
        [40486],
        [39872],
        [44446],
        [29063],
        [36249],
        [27219],
        [15508]], device='cuda:0')
[2024-07-24 10:29:32,810][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 4321],
        [26442],
        [25721],
        [12408],
        [12413],
        [12413],
        [22170],
        [39906],
        [38467],
        [39323],
        [37735],
        [39635],
        [39604],
        [39690],
        [37740],
        [38975],
        [38910]], device='cuda:0')
[2024-07-24 10:29:32,812][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[18167],
        [17266],
        [14060],
        [13555],
        [12492],
        [10958],
        [12930],
        [13299],
        [12185],
        [13792],
        [13941],
        [14300],
        [14259],
        [14544],
        [14654],
        [13815],
        [14218]], device='cuda:0')
[2024-07-24 10:29:32,814][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[37481],
        [35483],
        [36591],
        [38383],
        [39214],
        [39140],
        [39665],
        [39349],
        [39262],
        [40826],
        [40194],
        [40050],
        [39585],
        [39664],
        [39636],
        [39372],
        [39487]], device='cuda:0')
[2024-07-24 10:29:32,815][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[14399],
        [12563],
        [29516],
        [ 6971],
        [27407],
        [26791],
        [23063],
        [25116],
        [32867],
        [37300],
        [29508],
        [13608],
        [16741],
        [36130],
        [21609],
        [27957],
        [35546]], device='cuda:0')
[2024-07-24 10:29:32,817][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 6503],
        [15446],
        [ 7025],
        [ 5890],
        [ 4350],
        [ 2425],
        [ 3079],
        [ 6015],
        [ 3998],
        [ 5132],
        [ 3849],
        [ 3538],
        [ 3884],
        [ 5475],
        [ 5100],
        [ 3331],
        [ 4786]], device='cuda:0')
[2024-07-24 10:29:32,819][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[16085],
        [15649],
        [17688],
        [19457],
        [22375],
        [20047],
        [17754],
        [19123],
        [18754],
        [17546],
        [18468],
        [16937],
        [17880],
        [16976],
        [18924],
        [18915],
        [18251]], device='cuda:0')
[2024-07-24 10:29:32,821][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[38358],
        [39724],
        [13184],
        [14203],
        [32458],
        [33322],
        [24789],
        [30301],
        [35858],
        [35038],
        [34992],
        [46976],
        [39196],
        [44345],
        [45630],
        [44681],
        [44082]], device='cuda:0')
[2024-07-24 10:29:32,823][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[14589],
        [12705],
        [14167],
        [ 6324],
        [ 5205],
        [ 5643],
        [ 6263],
        [ 6122],
        [ 9712],
        [ 9124],
        [ 8269],
        [11610],
        [11439],
        [11177],
        [10572],
        [10065],
        [ 9924]], device='cuda:0')
[2024-07-24 10:29:32,824][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[14401],
        [14454],
        [15610],
        [15252],
        [15575],
        [15894],
        [16138],
        [15427],
        [14830],
        [15985],
        [16274],
        [16293],
        [16536],
        [16192],
        [16213],
        [15944],
        [15719]], device='cuda:0')
[2024-07-24 10:29:32,826][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[33433],
        [ 8648],
        [14334],
        [12008],
        [ 7449],
        [10319],
        [10867],
        [11126],
        [12975],
        [14382],
        [23114],
        [ 9721],
        [ 5881],
        [ 8984],
        [13351],
        [20117],
        [15387]], device='cuda:0')
[2024-07-24 10:29:32,828][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[7338],
        [9327],
        [8727],
        [7608],
        [7210],
        [6738],
        [6530],
        [6534],
        [6405],
        [7437],
        [7203],
        [7380],
        [7512],
        [7423],
        [7570],
        [7422],
        [7342]], device='cuda:0')
[2024-07-24 10:29:32,830][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[6133],
        [4054],
        [6147],
        [7113],
        [7733],
        [7127],
        [9156],
        [8465],
        [8794],
        [9310],
        [9296],
        [8743],
        [8629],
        [8602],
        [8279],
        [8597],
        [8682]], device='cuda:0')
[2024-07-24 10:29:32,832][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[19129],
        [18324],
        [16502],
        [17466],
        [19188],
        [20071],
        [19915],
        [19770],
        [18740],
        [19151],
        [20256],
        [19183],
        [18327],
        [18061],
        [17880],
        [18546],
        [18991]], device='cuda:0')
[2024-07-24 10:29:32,834][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[30117],
        [31217],
        [31467],
        [32381],
        [30617],
        [31744],
        [32026],
        [30942],
        [33717],
        [32273],
        [31016],
        [29783],
        [33232],
        [31409],
        [34012],
        [32271],
        [31599]], device='cuda:0')
[2024-07-24 10:29:32,835][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[8544],
        [7248],
        [6967],
        [7139],
        [7446],
        [7428],
        [7283],
        [7171],
        [7015],
        [6645],
        [6782],
        [6756],
        [6602],
        [6626],
        [6445],
        [6500],
        [6595]], device='cuda:0')
[2024-07-24 10:29:32,837][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[10939],
        [31014],
        [25369],
        [29849],
        [28012],
        [27362],
        [26781],
        [28511],
        [30235],
        [29894],
        [29389],
        [30940],
        [31403],
        [31413],
        [32142],
        [31004],
        [31383]], device='cuda:0')
[2024-07-24 10:29:32,839][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[28721],
        [30518],
        [34830],
        [36133],
        [36361],
        [36864],
        [36443],
        [34043],
        [33215],
        [32556],
        [31360],
        [31205],
        [33788],
        [32134],
        [29393],
        [28432],
        [30051]], device='cuda:0')
[2024-07-24 10:29:32,841][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[20989],
        [29718],
        [16857],
        [35877],
        [26998],
        [23348],
        [26119],
        [26371],
        [20138],
        [21185],
        [19663],
        [35364],
        [30247],
        [17624],
        [21697],
        [21332],
        [16544]], device='cuda:0')
[2024-07-24 10:29:32,842][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070]], device='cuda:0')
[2024-07-24 10:29:32,890][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:32,891][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,893][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,894][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,896][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,896][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,897][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,898][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,898][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,899][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,900][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,900][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,901][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:32,902][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Sara] are: tensor([0.7903, 0.2097], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,903][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Sara] are: tensor([0.5981, 0.4019], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,904][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Sara] are: tensor([0.5660, 0.4340], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,906][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Sara] are: tensor([0.1943, 0.8057], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,907][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Sara] are: tensor([0.8212, 0.1788], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,909][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Sara] are: tensor([0.3154, 0.6846], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,911][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Sara] are: tensor([0.4903, 0.5097], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,912][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Sara] are: tensor([0.4624, 0.5376], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,914][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Sara] are: tensor([0.3634, 0.6366], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,915][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Sara] are: tensor([0.5439, 0.4561], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,917][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Sara] are: tensor([0.6433, 0.3567], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,919][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Sara] are: tensor([0.7541, 0.2459], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:32,920][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.6414, 0.1836, 0.1750], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,921][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.5153, 0.3520, 0.1327], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,921][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3555, 0.4434, 0.2011], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,922][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0686, 0.4315, 0.4999], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,923][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4582, 0.3208, 0.2210], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,925][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3511, 0.3779, 0.2710], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,926][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.5298, 0.2255, 0.2447], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,928][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1378, 0.7887, 0.0736], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,929][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1634, 0.4948, 0.3418], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,931][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.3857, 0.2073, 0.4070], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,932][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4763, 0.2697, 0.2540], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,934][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4002, 0.1590, 0.4408], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:32,936][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Kenneth] are: tensor([0.4859, 0.1691, 0.1636, 0.1815], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,937][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Kenneth] are: tensor([0.4152, 0.3339, 0.1540, 0.0969], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,939][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Kenneth] are: tensor([0.2129, 0.3505, 0.2435, 0.1931], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,941][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Kenneth] are: tensor([0.0407, 0.3925, 0.3408, 0.2260], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,942][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Kenneth] are: tensor([0.7171, 0.0962, 0.1447, 0.0419], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,944][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Kenneth] are: tensor([0.1747, 0.1912, 0.2820, 0.3521], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,946][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Kenneth] are: tensor([0.4883, 0.1673, 0.2066, 0.1378], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,947][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Kenneth] are: tensor([0.1779, 0.5868, 0.1142, 0.1212], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,949][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Kenneth] are: tensor([0.1275, 0.3287, 0.4231, 0.1207], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,950][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Kenneth] are: tensor([0.1102, 0.6363, 0.1959, 0.0576], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,952][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Kenneth] are: tensor([0.3692, 0.1986, 0.1895, 0.2426], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,953][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Kenneth] are: tensor([0.2631, 0.1660, 0.4174, 0.1535], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:32,954][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.3690, 0.1566, 0.1545, 0.1725, 0.1473], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,955][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.3682, 0.2598, 0.1305, 0.0874, 0.1541], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,955][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.1602, 0.2660, 0.1952, 0.3022, 0.0763], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,956][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.0512, 0.2238, 0.2677, 0.3556, 0.1018], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,958][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.4708, 0.1789, 0.1698, 0.1137, 0.0668], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,959][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.0815, 0.1144, 0.1598, 0.4260, 0.2183], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,961][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.4351, 0.1235, 0.1399, 0.0990, 0.2024], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,963][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.2414, 0.4230, 0.1168, 0.1952, 0.0236], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,964][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.0874, 0.2092, 0.3401, 0.1730, 0.1903], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,966][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.6046, 0.0901, 0.1252, 0.0314, 0.1487], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,968][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.2951, 0.1592, 0.1517, 0.1946, 0.1994], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,969][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.2199, 0.0377, 0.2042, 0.0629, 0.4753], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:32,971][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.3237, 0.1314, 0.1272, 0.1444, 0.1217, 0.1516], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,972][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.3147, 0.2248, 0.1146, 0.0794, 0.1430, 0.1236], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,974][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1076, 0.1580, 0.1902, 0.3344, 0.1089, 0.1009], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,976][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0268, 0.1741, 0.1813, 0.2184, 0.1672, 0.2322], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,977][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2181, 0.2054, 0.1553, 0.1589, 0.1070, 0.1553], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,979][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0852, 0.0808, 0.0797, 0.5303, 0.1522, 0.0718], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,981][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3264, 0.0945, 0.1264, 0.0862, 0.2358, 0.1306], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,982][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0739, 0.4017, 0.0741, 0.3249, 0.0750, 0.0505], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,984][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0729, 0.1840, 0.2421, 0.1475, 0.2471, 0.1064], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,986][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1754, 0.1266, 0.1042, 0.0456, 0.5436, 0.0047], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,987][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2462, 0.1333, 0.1269, 0.1645, 0.1701, 0.1590], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,988][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0381, 0.0278, 0.0956, 0.1036, 0.6714, 0.0635], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:32,988][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.3033, 0.1109, 0.1076, 0.1221, 0.1033, 0.1294, 0.1234],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,989][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.2583, 0.1938, 0.1110, 0.0740, 0.1255, 0.1092, 0.1282],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,991][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.1100, 0.1877, 0.1420, 0.1256, 0.0761, 0.2944, 0.0642],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,992][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0173, 0.1005, 0.1688, 0.1657, 0.0930, 0.4088, 0.0459],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,994][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.2599, 0.1381, 0.2071, 0.0916, 0.1167, 0.1465, 0.0401],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,996][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.0440, 0.0968, 0.1057, 0.2443, 0.2807, 0.0996, 0.1288],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,997][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.3465, 0.0922, 0.0927, 0.0744, 0.1602, 0.0863, 0.1476],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:32,999][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.1674, 0.3701, 0.0921, 0.1673, 0.0389, 0.1516, 0.0126],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,001][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.0586, 0.1485, 0.2327, 0.1008, 0.2533, 0.1292, 0.0769],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,002][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.1000, 0.1651, 0.2570, 0.0323, 0.1266, 0.1833, 0.1356],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,004][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.2117, 0.1155, 0.1091, 0.1420, 0.1467, 0.1366, 0.1383],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,006][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0225, 0.0304, 0.1241, 0.1005, 0.4578, 0.1148, 0.1498],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,007][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.3042, 0.0930, 0.0897, 0.1035, 0.0874, 0.1109, 0.1064, 0.1047],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,009][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.2189, 0.1760, 0.1055, 0.0698, 0.1146, 0.0997, 0.1102, 0.1054],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,011][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0781, 0.1404, 0.1400, 0.1344, 0.0574, 0.2632, 0.1579, 0.0287],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,012][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0149, 0.1035, 0.1322, 0.2053, 0.1246, 0.1927, 0.0647, 0.1621],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,014][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.1470, 0.2008, 0.1346, 0.1350, 0.1255, 0.1137, 0.0734, 0.0701],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,016][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0685, 0.1448, 0.0674, 0.3300, 0.1569, 0.0695, 0.1071, 0.0557],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,017][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.2955, 0.0470, 0.0691, 0.0467, 0.1448, 0.0782, 0.1314, 0.1875],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,019][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0552, 0.4549, 0.0465, 0.1377, 0.0716, 0.0898, 0.1315, 0.0127],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,020][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0460, 0.1618, 0.1454, 0.0851, 0.1349, 0.0846, 0.1077, 0.2347],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,021][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0539, 0.1507, 0.2079, 0.0159, 0.3166, 0.0696, 0.1488, 0.0366],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,022][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.1817, 0.1023, 0.0963, 0.1277, 0.1304, 0.1205, 0.1219, 0.1193],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,023][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0200, 0.0123, 0.0529, 0.0457, 0.6257, 0.0659, 0.1023, 0.0753],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,024][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.2649, 0.0864, 0.0830, 0.0958, 0.0810, 0.1015, 0.0967, 0.0959, 0.0948],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,025][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.2899, 0.1485, 0.0669, 0.0426, 0.0817, 0.0695, 0.0789, 0.0735, 0.1484],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,027][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0626, 0.1090, 0.1073, 0.1616, 0.0933, 0.1036, 0.1750, 0.0779, 0.1096],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,029][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0110, 0.1132, 0.0933, 0.1451, 0.0946, 0.1127, 0.0626, 0.1505, 0.2170],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,030][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2400, 0.0960, 0.1001, 0.0710, 0.0706, 0.1195, 0.0452, 0.0926, 0.1650],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,032][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0723, 0.1166, 0.0607, 0.3267, 0.0966, 0.0552, 0.1145, 0.0746, 0.0827],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,033][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.3556, 0.0291, 0.0272, 0.0194, 0.0761, 0.0405, 0.0740, 0.0999, 0.2782],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,035][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0381, 0.3438, 0.0449, 0.1870, 0.0605, 0.0635, 0.1413, 0.0216, 0.0993],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,037][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0347, 0.1220, 0.1338, 0.0814, 0.1383, 0.0713, 0.0805, 0.2818, 0.0561],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,038][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1787, 0.0372, 0.0913, 0.0558, 0.2665, 0.0037, 0.3303, 0.0314, 0.0052],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,040][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1650, 0.0931, 0.0866, 0.1152, 0.1178, 0.1090, 0.1104, 0.1080, 0.0948],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,042][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0699, 0.0150, 0.0585, 0.0753, 0.3042, 0.0777, 0.1065, 0.1501, 0.1427],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,044][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ garden] are: tensor([0.2515, 0.0775, 0.0753, 0.0862, 0.0738, 0.0928, 0.0872, 0.0861, 0.0857,
        0.0838], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,045][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ garden] are: tensor([0.2142, 0.1490, 0.0684, 0.0420, 0.0754, 0.0690, 0.0767, 0.0713, 0.1501,
        0.0839], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,047][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ garden] are: tensor([0.0657, 0.0890, 0.1030, 0.0742, 0.0680, 0.1594, 0.0717, 0.0958, 0.2399,
        0.0334], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,049][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ garden] are: tensor([0.0101, 0.0653, 0.0978, 0.1135, 0.0478, 0.1740, 0.0377, 0.1514, 0.2500,
        0.0524], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,051][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ garden] are: tensor([0.2224, 0.0729, 0.1046, 0.0525, 0.0543, 0.1034, 0.0539, 0.1224, 0.1583,
        0.0553], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,052][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ garden] are: tensor([0.0541, 0.0757, 0.0892, 0.1344, 0.1647, 0.0676, 0.1248, 0.0909, 0.1171,
        0.0814], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,054][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ garden] are: tensor([0.2132, 0.0418, 0.0419, 0.0303, 0.0782, 0.0438, 0.0722, 0.0993, 0.2671,
        0.1121], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,054][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ garden] are: tensor([0.0854, 0.2608, 0.0782, 0.1194, 0.0599, 0.0778, 0.0402, 0.0711, 0.1878,
        0.0196], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,055][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ garden] are: tensor([0.0378, 0.0909, 0.1387, 0.0609, 0.1337, 0.0677, 0.0545, 0.3194, 0.0577,
        0.0388], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,056][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ garden] are: tensor([0.0308, 0.1594, 0.1717, 0.0288, 0.0150, 0.0956, 0.2104, 0.0778, 0.1756,
        0.0348], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,058][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ garden] are: tensor([0.1493, 0.0836, 0.0790, 0.1034, 0.1056, 0.0977, 0.0992, 0.0970, 0.0849,
        0.1003], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,059][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ garden] are: tensor([0.0420, 0.0118, 0.0461, 0.0347, 0.2389, 0.0489, 0.0772, 0.1573, 0.2437,
        0.0995], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,061][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2896, 0.0669, 0.0626, 0.0741, 0.0632, 0.0781, 0.0746, 0.0735, 0.0721,
        0.0714, 0.0739], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,063][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.2652, 0.1332, 0.0568, 0.0334, 0.0601, 0.0528, 0.0557, 0.0540, 0.1074,
        0.0612, 0.1202], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,065][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0628, 0.0812, 0.0780, 0.0955, 0.0519, 0.1463, 0.0648, 0.0571, 0.2242,
        0.0700, 0.0682], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,066][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0125, 0.0634, 0.0612, 0.1122, 0.0593, 0.1377, 0.0399, 0.0934, 0.2312,
        0.0849, 0.1043], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,068][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1182, 0.0813, 0.1093, 0.0640, 0.0808, 0.0863, 0.0431, 0.0811, 0.1361,
        0.0357, 0.1640], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,070][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0679, 0.0715, 0.0539, 0.3345, 0.0924, 0.0519, 0.0618, 0.0404, 0.1306,
        0.0692, 0.0259], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,071][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3184, 0.0257, 0.0175, 0.0126, 0.0421, 0.0226, 0.0369, 0.0508, 0.1408,
        0.0621, 0.2705], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,073][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0402, 0.3094, 0.0292, 0.1177, 0.0488, 0.0664, 0.0583, 0.0216, 0.1828,
        0.1115, 0.0140], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,075][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0313, 0.0998, 0.0936, 0.0662, 0.1169, 0.0680, 0.0489, 0.2047, 0.0559,
        0.0665, 0.1480], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,077][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2007, 0.0664, 0.1059, 0.0424, 0.0375, 0.0232, 0.3437, 0.0515, 0.0285,
        0.0863, 0.0139], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,078][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1328, 0.0790, 0.0715, 0.0969, 0.0966, 0.0902, 0.0935, 0.0890, 0.0788,
        0.0934, 0.0782], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,080][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0236, 0.0057, 0.0379, 0.0228, 0.2087, 0.0438, 0.0375, 0.0786, 0.1263,
        0.1010, 0.3142], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,082][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Sara] are: tensor([0.2521, 0.0648, 0.0618, 0.0700, 0.0606, 0.0752, 0.0712, 0.0701, 0.0689,
        0.0677, 0.0710, 0.0665], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:33,084][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Sara] are: tensor([0.1843, 0.1112, 0.0541, 0.0326, 0.0562, 0.0491, 0.0548, 0.0525, 0.1096,
        0.0656, 0.1283, 0.1018], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:33,085][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Sara] are: tensor([0.0490, 0.0485, 0.1040, 0.0797, 0.0484, 0.1160, 0.0996, 0.0801, 0.1644,
        0.0489, 0.1171, 0.0444], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:33,087][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Sara] are: tensor([0.0071, 0.0280, 0.0675, 0.1512, 0.0429, 0.1413, 0.0263, 0.1025, 0.2192,
        0.0650, 0.1148, 0.0343], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:33,087][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Sara] are: tensor([0.0975, 0.0796, 0.1028, 0.0552, 0.0578, 0.1027, 0.0452, 0.0688, 0.1555,
        0.0592, 0.1462, 0.0295], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:33,088][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Sara] are: tensor([0.0313, 0.0572, 0.0499, 0.1755, 0.1047, 0.0507, 0.1031, 0.0973, 0.1260,
        0.0889, 0.0515, 0.0639], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:33,089][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Sara] are: tensor([0.1605, 0.0209, 0.0200, 0.0132, 0.0375, 0.0216, 0.0349, 0.0449, 0.1703,
        0.0617, 0.3454, 0.0691], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:33,091][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Sara] are: tensor([0.0817, 0.1139, 0.0504, 0.0969, 0.0334, 0.0615, 0.0385, 0.0595, 0.2254,
        0.1273, 0.0262, 0.0853], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:33,093][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Sara] are: tensor([0.0259, 0.0507, 0.0979, 0.0452, 0.0995, 0.0533, 0.0453, 0.2616, 0.0458,
        0.0687, 0.1640, 0.0422], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:33,094][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Sara] are: tensor([0.0556, 0.0685, 0.1935, 0.0140, 0.0248, 0.0543, 0.1459, 0.1821, 0.0630,
        0.0205, 0.1244, 0.0532], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:33,096][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Sara] are: tensor([0.1218, 0.0723, 0.0658, 0.0890, 0.0885, 0.0815, 0.0826, 0.0801, 0.0707,
        0.0851, 0.0691, 0.0935], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:33,098][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Sara] are: tensor([0.0274, 0.0046, 0.0194, 0.0176, 0.0834, 0.0251, 0.0600, 0.0515, 0.1277,
        0.1151, 0.3300, 0.1381], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:33,099][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.2915, 0.0556, 0.0538, 0.0614, 0.0534, 0.0669, 0.0639, 0.0622, 0.0611,
        0.0601, 0.0619, 0.0577, 0.0505], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:33,101][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.2558, 0.1311, 0.0459, 0.0245, 0.0457, 0.0430, 0.0421, 0.0417, 0.0819,
        0.0453, 0.0901, 0.0713, 0.0816], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:33,103][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0615, 0.0888, 0.0515, 0.0796, 0.0294, 0.1307, 0.0520, 0.0592, 0.1947,
        0.0488, 0.0825, 0.0952, 0.0262], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:33,105][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0139, 0.0628, 0.0659, 0.1053, 0.0348, 0.1065, 0.0359, 0.1192, 0.1567,
        0.0612, 0.1109, 0.0768, 0.0501], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:33,107][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.2023, 0.0694, 0.0663, 0.0225, 0.0411, 0.0767, 0.0395, 0.0438, 0.1308,
        0.0548, 0.1248, 0.0481, 0.0798], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:33,108][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.0446, 0.0236, 0.0893, 0.2172, 0.0969, 0.0405, 0.0601, 0.0750, 0.0834,
        0.0689, 0.0401, 0.0261, 0.1343], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:33,110][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.2718, 0.0177, 0.0122, 0.0082, 0.0228, 0.0148, 0.0199, 0.0300, 0.0746,
        0.0340, 0.1711, 0.0361, 0.2867], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:33,112][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0560, 0.2130, 0.0421, 0.1176, 0.0159, 0.0776, 0.0403, 0.0441, 0.1681,
        0.0654, 0.0190, 0.1351, 0.0057], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:33,114][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0324, 0.0873, 0.0846, 0.0510, 0.0793, 0.0487, 0.0404, 0.1996, 0.0377,
        0.0768, 0.1343, 0.0672, 0.0607], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:33,115][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.3189, 0.0591, 0.0667, 0.1272, 0.0768, 0.0187, 0.1201, 0.0450, 0.0116,
        0.0287, 0.0616, 0.0603, 0.0052], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:33,117][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.1133, 0.0659, 0.0601, 0.0810, 0.0809, 0.0747, 0.0759, 0.0727, 0.0642,
        0.0770, 0.0621, 0.0840, 0.0881], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:33,119][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0405, 0.0027, 0.0255, 0.0086, 0.0456, 0.0311, 0.0194, 0.0382, 0.0621,
        0.0260, 0.2689, 0.0649, 0.3665], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:33,120][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2471, 0.0558, 0.0535, 0.0613, 0.0529, 0.0656, 0.0625, 0.0614, 0.0605,
        0.0595, 0.0619, 0.0579, 0.0496, 0.0505], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:33,121][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.2047, 0.1175, 0.0451, 0.0250, 0.0446, 0.0421, 0.0426, 0.0416, 0.0801,
        0.0452, 0.0887, 0.0694, 0.0809, 0.0726], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:33,122][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0352, 0.0714, 0.0522, 0.0709, 0.0481, 0.0990, 0.0943, 0.0302, 0.1817,
        0.0580, 0.0916, 0.0748, 0.0803, 0.0123], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:33,123][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0090, 0.0687, 0.0522, 0.0572, 0.0660, 0.0965, 0.0397, 0.0661, 0.1636,
        0.0477, 0.0964, 0.0829, 0.0966, 0.0574], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:33,125][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1214, 0.0646, 0.0683, 0.0515, 0.0589, 0.0752, 0.0307, 0.0564, 0.0921,
        0.0417, 0.1035, 0.0359, 0.0854, 0.1145], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:33,126][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0546, 0.0417, 0.0426, 0.2552, 0.0752, 0.0518, 0.0529, 0.0458, 0.0978,
        0.0539, 0.0455, 0.0532, 0.1114, 0.0183], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:33,128][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2024, 0.0159, 0.0123, 0.0079, 0.0234, 0.0153, 0.0210, 0.0287, 0.0688,
        0.0327, 0.1525, 0.0347, 0.2495, 0.1349], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:33,130][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0264, 0.2176, 0.0252, 0.0969, 0.0304, 0.0509, 0.0468, 0.0119, 0.1401,
        0.1338, 0.0164, 0.1696, 0.0271, 0.0067], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:33,131][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0199, 0.0591, 0.0816, 0.0562, 0.0834, 0.0448, 0.0377, 0.1299, 0.0431,
        0.0695, 0.1509, 0.0552, 0.0975, 0.0712], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:33,133][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0463, 0.0145, 0.0663, 0.0081, 0.1254, 0.0175, 0.3075, 0.0062, 0.0208,
        0.0266, 0.0312, 0.0097, 0.3175, 0.0022], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:33,135][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1027, 0.0610, 0.0566, 0.0747, 0.0751, 0.0700, 0.0704, 0.0678, 0.0602,
        0.0707, 0.0583, 0.0770, 0.0814, 0.0740], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:33,137][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0206, 0.0006, 0.0055, 0.0027, 0.0363, 0.0068, 0.0053, 0.0097, 0.0175,
        0.0065, 0.0764, 0.0122, 0.3659, 0.4340], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:33,139][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.1681, 0.0579, 0.0555, 0.0626, 0.0542, 0.0671, 0.0645, 0.0634, 0.0623,
        0.0617, 0.0651, 0.0602, 0.0518, 0.0520, 0.0534], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:33,140][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.1573, 0.1063, 0.0503, 0.0268, 0.0429, 0.0391, 0.0370, 0.0384, 0.0773,
        0.0448, 0.0924, 0.0656, 0.0865, 0.0739, 0.0614], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:33,142][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0435, 0.0830, 0.0516, 0.0501, 0.0198, 0.1244, 0.0401, 0.0595, 0.1780,
        0.0490, 0.0782, 0.0853, 0.0442, 0.0785, 0.0149], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:33,144][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0090, 0.0444, 0.0655, 0.0581, 0.0335, 0.0934, 0.0234, 0.1065, 0.1377,
        0.0462, 0.1044, 0.0575, 0.0676, 0.1082, 0.0448], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:33,146][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.1594, 0.0541, 0.0804, 0.0188, 0.0323, 0.0511, 0.0263, 0.0361, 0.0853,
        0.0284, 0.0986, 0.0352, 0.0936, 0.1670, 0.0333], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:33,148][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0279, 0.0491, 0.0598, 0.1316, 0.1166, 0.0380, 0.0873, 0.0474, 0.0539,
        0.0625, 0.0375, 0.0479, 0.1447, 0.0232, 0.0728], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:33,150][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.1317, 0.0205, 0.0159, 0.0103, 0.0237, 0.0156, 0.0185, 0.0305, 0.0725,
        0.0313, 0.1420, 0.0407, 0.2195, 0.1563, 0.0709], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:33,151][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0542, 0.2088, 0.0373, 0.0913, 0.0169, 0.0870, 0.0403, 0.0345, 0.1508,
        0.0689, 0.0210, 0.1352, 0.0179, 0.0176, 0.0185], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:33,153][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0234, 0.0609, 0.0631, 0.0414, 0.0834, 0.0368, 0.0333, 0.1607, 0.0319,
        0.0527, 0.1203, 0.0547, 0.1059, 0.0830, 0.0485], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:33,153][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.1939, 0.0332, 0.0353, 0.0082, 0.0707, 0.0317, 0.2416, 0.0175, 0.0298,
        0.0145, 0.0587, 0.0281, 0.0839, 0.1383, 0.0145], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:33,154][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0959, 0.0568, 0.0524, 0.0694, 0.0693, 0.0646, 0.0652, 0.0625, 0.0554,
        0.0655, 0.0541, 0.0718, 0.0754, 0.0680, 0.0736], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:33,155][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0168, 0.0009, 0.0049, 0.0021, 0.0117, 0.0050, 0.0044, 0.0097, 0.0127,
        0.0093, 0.0684, 0.0159, 0.1897, 0.4847, 0.1638], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:33,157][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.1449, 0.0559, 0.0530, 0.0596, 0.0512, 0.0635, 0.0608, 0.0604, 0.0602,
        0.0592, 0.0629, 0.0578, 0.0502, 0.0507, 0.0511, 0.0588],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:33,159][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ it] are: tensor([0.1599, 0.1009, 0.0459, 0.0246, 0.0394, 0.0362, 0.0345, 0.0354, 0.0708,
        0.0411, 0.0830, 0.0606, 0.0795, 0.0687, 0.0573, 0.0620],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:33,160][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.0416, 0.0494, 0.0688, 0.0664, 0.0387, 0.0664, 0.0688, 0.0788, 0.0911,
        0.0527, 0.0747, 0.0461, 0.0983, 0.0651, 0.0618, 0.0312],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:33,162][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ it] are: tensor([0.0083, 0.0458, 0.0517, 0.0641, 0.0516, 0.0794, 0.0349, 0.0740, 0.1066,
        0.0504, 0.0823, 0.0555, 0.0723, 0.0799, 0.0732, 0.0700],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:33,164][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.1198, 0.0850, 0.0839, 0.0372, 0.0377, 0.0546, 0.0251, 0.0425, 0.0907,
        0.0240, 0.1092, 0.0363, 0.0703, 0.1022, 0.0351, 0.0464],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:33,166][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ it] are: tensor([0.0381, 0.0585, 0.0520, 0.1482, 0.0503, 0.0475, 0.0412, 0.0390, 0.1129,
        0.0527, 0.0362, 0.0737, 0.0881, 0.0165, 0.0438, 0.1013],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:33,168][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.1620, 0.0195, 0.0120, 0.0078, 0.0190, 0.0125, 0.0163, 0.0233, 0.0602,
        0.0277, 0.1186, 0.0314, 0.2019, 0.1298, 0.0664, 0.0915],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:33,169][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.0341, 0.2288, 0.0291, 0.0951, 0.0273, 0.0414, 0.0505, 0.0218, 0.0801,
        0.1014, 0.0191, 0.1575, 0.0289, 0.0104, 0.0386, 0.0361],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:33,171][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.0194, 0.0608, 0.0619, 0.0385, 0.0682, 0.0348, 0.0358, 0.1502, 0.0268,
        0.0575, 0.1119, 0.0508, 0.0878, 0.0826, 0.0877, 0.0253],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:33,173][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ it] are: tensor([0.2075, 0.0069, 0.0374, 0.0109, 0.0653, 0.0067, 0.1522, 0.0314, 0.0063,
        0.0197, 0.0241, 0.0057, 0.1572, 0.0445, 0.2207, 0.0036],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:33,175][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.0868, 0.0531, 0.0482, 0.0653, 0.0649, 0.0607, 0.0611, 0.0588, 0.0521,
        0.0618, 0.0494, 0.0671, 0.0703, 0.0631, 0.0686, 0.0687],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:33,177][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ it] are: tensor([0.0178, 0.0005, 0.0031, 0.0025, 0.0083, 0.0039, 0.0029, 0.0052, 0.0091,
        0.0042, 0.0449, 0.0096, 0.0831, 0.4099, 0.2619, 0.1330],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:33,178][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1921, 0.0495, 0.0471, 0.0534, 0.0464, 0.0573, 0.0544, 0.0538, 0.0533,
        0.0523, 0.0549, 0.0511, 0.0442, 0.0447, 0.0457, 0.0527, 0.0469],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:33,180][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1654, 0.1044, 0.0393, 0.0212, 0.0366, 0.0356, 0.0351, 0.0350, 0.0682,
        0.0379, 0.0753, 0.0571, 0.0669, 0.0601, 0.0521, 0.0563, 0.0537],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:33,182][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0289, 0.0586, 0.0424, 0.0584, 0.0376, 0.0814, 0.0775, 0.0233, 0.1449,
        0.0460, 0.0754, 0.0601, 0.0636, 0.0098, 0.0589, 0.1233, 0.0099],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:33,184][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0071, 0.0557, 0.0395, 0.0423, 0.0498, 0.0762, 0.0318, 0.0503, 0.1261,
        0.0367, 0.0737, 0.0672, 0.0722, 0.0433, 0.0581, 0.1334, 0.0364],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:33,186][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0676, 0.0476, 0.0557, 0.0416, 0.0505, 0.0662, 0.0262, 0.0456, 0.0905,
        0.0361, 0.0917, 0.0287, 0.0717, 0.0928, 0.0466, 0.0645, 0.0764],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:33,187][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0469, 0.0350, 0.0348, 0.2063, 0.0642, 0.0410, 0.0425, 0.0369, 0.0769,
        0.0462, 0.0359, 0.0442, 0.0969, 0.0139, 0.0601, 0.1061, 0.0122],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:33,188][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1420, 0.0153, 0.0118, 0.0074, 0.0195, 0.0135, 0.0170, 0.0245, 0.0581,
        0.0262, 0.1215, 0.0299, 0.1856, 0.1045, 0.0625, 0.0885, 0.0722],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:33,189][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0238, 0.1699, 0.0195, 0.0753, 0.0247, 0.0402, 0.0410, 0.0094, 0.1179,
        0.1150, 0.0128, 0.1331, 0.0211, 0.0055, 0.0542, 0.1327, 0.0039],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:33,190][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0165, 0.0521, 0.0661, 0.0486, 0.0713, 0.0382, 0.0331, 0.1056, 0.0361,
        0.0608, 0.1231, 0.0484, 0.0787, 0.0584, 0.0704, 0.0425, 0.0502],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:33,192][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0341, 0.0120, 0.0469, 0.0063, 0.0962, 0.0138, 0.2252, 0.0050, 0.0168,
        0.0191, 0.0227, 0.0083, 0.2105, 0.0015, 0.2497, 0.0307, 0.0012],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:33,194][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0813, 0.0498, 0.0458, 0.0609, 0.0609, 0.0570, 0.0573, 0.0552, 0.0492,
        0.0578, 0.0470, 0.0627, 0.0661, 0.0599, 0.0647, 0.0645, 0.0599],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:33,195][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.4344e-02, 2.1084e-04, 1.8674e-03, 7.4806e-04, 9.8809e-03, 2.3764e-03,
        1.3469e-03, 2.5427e-03, 5.5362e-03, 1.6602e-03, 2.3630e-02, 3.0509e-03,
        9.5503e-02, 1.2263e-01, 2.0137e-01, 6.5280e-02, 4.4802e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:33,232][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:33,233][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:33,234][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:33,235][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:33,235][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:33,237][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:33,237][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:33,238][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:33,239][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:33,239][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:33,240][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:33,241][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:33,241][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:33,242][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Sara] are: tensor([0.9193, 0.0807], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:33,243][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Sara] are: tensor([0.2873, 0.7127], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:33,245][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Sara] are: tensor([0.9608, 0.0392], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:33,248][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Sara] are: tensor([5.4682e-07, 1.0000e+00], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:33,251][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Sara] are: tensor([0.4995, 0.5005], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:33,255][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Sara] are: tensor([0.9440, 0.0560], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:33,256][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Sara] are: tensor([0.4458, 0.5542], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:33,256][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Sara] are: tensor([0.5760, 0.4240], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:33,257][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Sara] are: tensor([0.8832, 0.1168], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:33,259][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Sara] are: tensor([0.6947, 0.3053], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:33,262][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Sara] are: tensor([0.7459, 0.2541], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:33,266][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Sara] are: tensor([0.7541, 0.2459], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:33,270][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.8159, 0.0934, 0.0907], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:33,271][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1784, 0.4255, 0.3960], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:33,272][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.7980, 0.1810, 0.0210], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:33,272][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([6.7720e-06, 8.1834e-01, 1.8165e-01], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:33,273][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3225, 0.2999, 0.3777], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:33,275][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9287, 0.0393, 0.0320], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:33,278][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.3102, 0.4031, 0.2866], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:33,282][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.3640, 0.2971, 0.3389], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:33,286][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.4302, 0.4842, 0.0856], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:33,287][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4436, 0.1142, 0.4422], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:33,288][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.5156, 0.1921, 0.2922], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:33,288][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4002, 0.1590, 0.4408], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:33,290][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Kenneth] are: tensor([0.7173, 0.0912, 0.0941, 0.0975], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:33,293][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Kenneth] are: tensor([0.1148, 0.2852, 0.2746, 0.3253], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:33,297][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Kenneth] are: tensor([0.4054, 0.2941, 0.2377, 0.0628], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:33,300][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Kenneth] are: tensor([2.3831e-06, 4.6548e-01, 3.8267e-01, 1.5185e-01], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:33,302][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Kenneth] are: tensor([0.2424, 0.2995, 0.2958, 0.1623], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:33,303][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Kenneth] are: tensor([0.9000, 0.0360, 0.0399, 0.0241], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:33,303][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Kenneth] are: tensor([0.2081, 0.3644, 0.2995, 0.1281], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:33,304][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Kenneth] are: tensor([0.2518, 0.2464, 0.2438, 0.2580], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:33,306][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Kenneth] are: tensor([0.3542, 0.2010, 0.3492, 0.0956], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:33,308][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Kenneth] are: tensor([0.1089, 0.6453, 0.2051, 0.0406], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:33,313][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Kenneth] are: tensor([0.4287, 0.1957, 0.1384, 0.2372], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:33,317][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Kenneth] are: tensor([0.2631, 0.1660, 0.4174, 0.1535], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:33,318][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.7302, 0.0672, 0.0715, 0.0700, 0.0610], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:33,319][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.0883, 0.2136, 0.2087, 0.2376, 0.2517], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:33,319][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.2764, 0.2159, 0.1981, 0.3071, 0.0026], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:33,321][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([8.1793e-07, 3.6081e-01, 3.6402e-01, 1.6609e-01, 1.0908e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:33,324][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.1765, 0.1781, 0.2189, 0.1844, 0.2422], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:33,328][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.9001, 0.0284, 0.0208, 0.0170, 0.0337], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:33,332][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.1601, 0.3607, 0.2695, 0.1507, 0.0589], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:33,333][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.2235, 0.1720, 0.1936, 0.2339, 0.1770], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:33,334][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.1908, 0.1580, 0.2123, 0.3654, 0.0734], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:33,335][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.6919, 0.0406, 0.0944, 0.0177, 0.1554], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:33,336][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.3713, 0.1359, 0.1416, 0.1743, 0.1769], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:33,338][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.2199, 0.0377, 0.2042, 0.0629, 0.4753], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:33,341][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.6052, 0.0800, 0.0790, 0.0795, 0.0659, 0.0904], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:33,344][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0718, 0.1764, 0.1687, 0.1944, 0.2093, 0.1794], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:33,348][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0686, 0.0339, 0.1766, 0.7020, 0.0160, 0.0029], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:33,349][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([3.7752e-07, 3.7178e-01, 1.9298e-01, 2.1263e-01, 9.4268e-02, 1.2834e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:33,350][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1445, 0.1300, 0.1781, 0.1150, 0.2157, 0.2166], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:33,351][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.8471, 0.0278, 0.0220, 0.0164, 0.0354, 0.0513], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:33,353][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1456, 0.3421, 0.2638, 0.1485, 0.0603, 0.0397], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:33,356][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1603, 0.1247, 0.1615, 0.1894, 0.1597, 0.2044], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:33,360][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1126, 0.0620, 0.0863, 0.3121, 0.3209, 0.1061], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:33,364][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0830, 0.0377, 0.0418, 0.0224, 0.8143, 0.0009], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:33,364][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1937, 0.1353, 0.1478, 0.2301, 0.1515, 0.1417], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:33,365][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0381, 0.0278, 0.0956, 0.1036, 0.6714, 0.0635], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:33,366][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.5991, 0.0654, 0.0655, 0.0655, 0.0561, 0.0774, 0.0711],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,368][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.0567, 0.1433, 0.1424, 0.1607, 0.1742, 0.1483, 0.1743],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,371][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.1165, 0.1587, 0.1041, 0.0390, 0.0091, 0.5717, 0.0010],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,373][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([1.8038e-08, 1.9640e-01, 2.8130e-01, 1.3014e-01, 6.6052e-02, 3.0117e-01,
        2.4945e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,377][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.1313, 0.1554, 0.1699, 0.1257, 0.1729, 0.1861, 0.0588],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,380][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.7155, 0.0305, 0.0362, 0.0236, 0.0464, 0.0801, 0.0677],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,380][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.1031, 0.3363, 0.2794, 0.1605, 0.0607, 0.0419, 0.0181],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,381][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.1311, 0.1128, 0.1446, 0.1506, 0.1372, 0.1921, 0.1317],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,382][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.1429, 0.0438, 0.0739, 0.0793, 0.2253, 0.4102, 0.0246],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,384][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.0879, 0.0986, 0.2511, 0.0261, 0.1737, 0.2518, 0.1108],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,388][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.2360, 0.1098, 0.1463, 0.1766, 0.1308, 0.1226, 0.0780],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,391][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.0225, 0.0304, 0.1241, 0.1005, 0.4578, 0.1148, 0.1498],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,395][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.6696, 0.0458, 0.0441, 0.0452, 0.0385, 0.0538, 0.0510, 0.0520],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,396][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0508, 0.1245, 0.1191, 0.1398, 0.1477, 0.1263, 0.1529, 0.1387],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,396][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([9.1469e-02, 7.6017e-02, 1.4347e-01, 8.3605e-02, 5.4963e-03, 5.7272e-01,
        2.6841e-02, 3.8306e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,397][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([2.7039e-05, 2.4982e-01, 1.7714e-01, 1.3325e-01, 1.2287e-01, 1.6319e-01,
        2.8708e-02, 1.2500e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,399][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.1163, 0.1005, 0.1476, 0.0963, 0.1653, 0.1522, 0.1334, 0.0883],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,402][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.8211, 0.0183, 0.0129, 0.0103, 0.0219, 0.0323, 0.0523, 0.0310],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,406][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.1572, 0.3017, 0.2393, 0.1292, 0.0525, 0.0383, 0.0151, 0.0667],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,410][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.1438, 0.0934, 0.1151, 0.1323, 0.1053, 0.1415, 0.1320, 0.1365],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,411][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0577, 0.0904, 0.0316, 0.1200, 0.0642, 0.1705, 0.4281, 0.0376],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,412][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0279, 0.0868, 0.1645, 0.0075, 0.5690, 0.0613, 0.0584, 0.0245],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,413][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.2754, 0.0870, 0.1622, 0.1056, 0.0704, 0.0582, 0.0537, 0.1876],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,415][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0200, 0.0123, 0.0529, 0.0457, 0.6257, 0.0659, 0.1023, 0.0753],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,417][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.5308, 0.0579, 0.0563, 0.0567, 0.0483, 0.0652, 0.0602, 0.0628, 0.0617],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,422][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0466, 0.1101, 0.1053, 0.1223, 0.1309, 0.1114, 0.1348, 0.1236, 0.1149],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,426][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0744, 0.0533, 0.1497, 0.4716, 0.0647, 0.0275, 0.1053, 0.0436, 0.0098],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,427][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([1.4231e-06, 1.4796e-01, 9.7573e-02, 1.2112e-01, 3.8109e-02, 5.4393e-02,
        1.2378e-02, 7.3823e-02, 4.5464e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,428][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1029, 0.0975, 0.1350, 0.0800, 0.1317, 0.1544, 0.0895, 0.0790, 0.1302],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,428][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.7980, 0.0164, 0.0128, 0.0092, 0.0194, 0.0295, 0.0374, 0.0305, 0.0467],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,430][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2227, 0.2648, 0.1847, 0.0962, 0.0396, 0.0296, 0.0118, 0.0508, 0.0998],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,433][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1117, 0.0750, 0.0985, 0.1129, 0.0951, 0.1205, 0.1157, 0.1209, 0.1496],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,437][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0445, 0.0405, 0.0324, 0.1222, 0.1568, 0.0941, 0.3306, 0.0864, 0.0925],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,442][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1483, 0.0153, 0.0616, 0.0400, 0.5363, 0.0008, 0.1775, 0.0194, 0.0008],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,442][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1856, 0.0783, 0.0716, 0.1430, 0.1024, 0.0682, 0.0502, 0.0629, 0.2378],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,443][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0699, 0.0150, 0.0585, 0.0753, 0.3042, 0.0777, 0.1065, 0.1501, 0.1427],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,444][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ garden] are: tensor([0.5079, 0.0519, 0.0517, 0.0529, 0.0456, 0.0629, 0.0553, 0.0578, 0.0581,
        0.0559], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,446][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ garden] are: tensor([0.0372, 0.0936, 0.0917, 0.1066, 0.1144, 0.0962, 0.1188, 0.1084, 0.1006,
        0.1325], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,448][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ garden] are: tensor([8.2575e-02, 1.8317e-02, 1.2572e-01, 1.5146e-02, 1.3270e-02, 1.6799e-01,
        1.7199e-03, 9.9970e-02, 4.7497e-01, 3.2478e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,451][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ garden] are: tensor([2.9872e-07, 1.2180e-01, 8.2712e-02, 6.6579e-02, 2.9231e-02, 9.9613e-02,
        1.3078e-02, 5.7544e-02, 5.1708e-01, 1.2365e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,455][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ garden] are: tensor([0.0935, 0.0768, 0.1364, 0.0841, 0.1411, 0.1510, 0.0913, 0.0715, 0.1088,
        0.0456], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,457][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ garden] are: tensor([0.6248, 0.0206, 0.0257, 0.0159, 0.0325, 0.0533, 0.0468, 0.0578, 0.0720,
        0.0506], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,458][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ garden] are: tensor([0.1250, 0.2746, 0.2031, 0.1147, 0.0409, 0.0299, 0.0123, 0.0556, 0.1103,
        0.0336], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,459][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ garden] are: tensor([0.1166, 0.0763, 0.0985, 0.1088, 0.0832, 0.1327, 0.0878, 0.1185, 0.1575,
        0.0202], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,460][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ garden] are: tensor([0.0604, 0.0207, 0.0539, 0.0632, 0.0904, 0.2341, 0.0428, 0.1708, 0.2584,
        0.0054], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,462][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ garden] are: tensor([0.0258, 0.0951, 0.1663, 0.0255, 0.0141, 0.1229, 0.2081, 0.0970, 0.2096,
        0.0354], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,464][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ garden] are: tensor([0.1851, 0.0744, 0.0897, 0.0980, 0.0773, 0.0707, 0.0558, 0.1213, 0.1903,
        0.0375], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,468][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ garden] are: tensor([0.0420, 0.0118, 0.0461, 0.0347, 0.2389, 0.0489, 0.0772, 0.1573, 0.2437,
        0.0995], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,473][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.6119, 0.0389, 0.0350, 0.0380, 0.0320, 0.0434, 0.0408, 0.0401, 0.0411,
        0.0393, 0.0395], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,474][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0358, 0.0852, 0.0811, 0.0968, 0.1007, 0.0862, 0.1028, 0.0980, 0.0913,
        0.1144, 0.1077], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,474][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0821, 0.0117, 0.0352, 0.0321, 0.0054, 0.1151, 0.0007, 0.0181, 0.6939,
        0.0047, 0.0010], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,475][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([3.0498e-06, 7.8234e-02, 6.9940e-02, 8.9485e-02, 4.2946e-02, 6.2735e-02,
        1.4862e-02, 6.2081e-02, 4.4120e-01, 4.2824e-02, 9.5691e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,477][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0806, 0.0669, 0.1037, 0.0709, 0.1090, 0.1150, 0.0903, 0.0628, 0.0976,
        0.0694, 0.1338], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,481][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.7465, 0.0137, 0.0119, 0.0086, 0.0163, 0.0240, 0.0263, 0.0255, 0.0368,
        0.0317, 0.0587], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,484][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2099, 0.2127, 0.1390, 0.0719, 0.0297, 0.0228, 0.0082, 0.0372, 0.0772,
        0.0261, 0.1653], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,488][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1299, 0.0693, 0.0927, 0.1125, 0.0756, 0.1092, 0.0949, 0.1041, 0.1345,
        0.0261, 0.0512], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,489][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0388, 0.0332, 0.0141, 0.1272, 0.1397, 0.1573, 0.1154, 0.0559, 0.2262,
        0.0442, 0.0480], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,490][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2862, 0.0534, 0.1064, 0.0439, 0.0409, 0.0167, 0.2459, 0.0724, 0.0221,
        0.1082, 0.0040], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,491][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1556, 0.0477, 0.1080, 0.0742, 0.0766, 0.0475, 0.0284, 0.1000, 0.1592,
        0.0349, 0.1679], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,493][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0236, 0.0057, 0.0379, 0.0228, 0.2087, 0.0438, 0.0375, 0.0786, 0.1263,
        0.1010, 0.3142], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,495][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Sara] are: tensor([0.5541, 0.0400, 0.0382, 0.0409, 0.0342, 0.0469, 0.0423, 0.0422, 0.0421,
        0.0402, 0.0410, 0.0379], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:33,499][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Sara] are: tensor([0.0293, 0.0742, 0.0732, 0.0866, 0.0917, 0.0775, 0.0932, 0.0882, 0.0827,
        0.1083, 0.0953, 0.0998], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:33,504][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Sara] are: tensor([0.0748, 0.0047, 0.2469, 0.0558, 0.0161, 0.1136, 0.0192, 0.1786, 0.2539,
        0.0068, 0.0269, 0.0026], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:33,505][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Sara] are: tensor([1.6081e-06, 6.4531e-02, 9.6670e-02, 7.4176e-02, 2.9694e-02, 6.0449e-02,
        8.8785e-03, 6.2798e-02, 3.2141e-01, 1.9259e-02, 1.9643e-01, 6.5705e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:33,506][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Sara] are: tensor([0.0729, 0.0690, 0.0986, 0.0741, 0.0952, 0.0987, 0.0705, 0.0656, 0.0843,
        0.0609, 0.1173, 0.0928], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:33,507][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Sara] are: tensor([0.6253, 0.0155, 0.0186, 0.0110, 0.0235, 0.0394, 0.0325, 0.0394, 0.0495,
        0.0374, 0.0824, 0.0256], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:33,510][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Sara] are: tensor([0.1492, 0.2170, 0.1514, 0.0742, 0.0254, 0.0179, 0.0060, 0.0323, 0.0712,
        0.0193, 0.1666, 0.0693], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:33,514][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Sara] are: tensor([0.0890, 0.0567, 0.0881, 0.0929, 0.0813, 0.1125, 0.0852, 0.1078, 0.1278,
        0.0262, 0.0550, 0.0774], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:33,518][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Sara] are: tensor([0.0358, 0.0082, 0.0294, 0.0585, 0.0796, 0.2032, 0.0447, 0.1501, 0.1830,
        0.0633, 0.1160, 0.0283], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:33,519][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Sara] are: tensor([0.0461, 0.0338, 0.2144, 0.0079, 0.0198, 0.0500, 0.0894, 0.3179, 0.0516,
        0.0136, 0.1322, 0.0232], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:33,520][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Sara] are: tensor([0.1572, 0.0557, 0.0681, 0.0948, 0.0602, 0.0364, 0.0261, 0.0904, 0.1686,
        0.0272, 0.1268, 0.0885], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:33,521][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Sara] are: tensor([0.0274, 0.0046, 0.0194, 0.0176, 0.0834, 0.0251, 0.0600, 0.0515, 0.1277,
        0.1151, 0.3300, 0.1381], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:33,523][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.6815, 0.0247, 0.0251, 0.0261, 0.0227, 0.0320, 0.0293, 0.0295, 0.0286,
        0.0275, 0.0274, 0.0242, 0.0213], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:33,526][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.0284, 0.0679, 0.0663, 0.0772, 0.0815, 0.0702, 0.0842, 0.0802, 0.0759,
        0.0967, 0.0865, 0.0889, 0.0961], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:33,528][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([1.9039e-01, 2.5429e-02, 1.8417e-02, 5.2048e-02, 1.4130e-03, 1.4678e-01,
        1.4381e-03, 5.4520e-02, 4.7797e-01, 4.4663e-03, 6.4714e-03, 2.0247e-02,
        4.0888e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:33,530][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([1.0478e-06, 8.0102e-02, 7.5728e-02, 4.3826e-02, 2.9200e-02, 6.5543e-02,
        1.2845e-02, 3.5917e-02, 3.6158e-01, 1.2794e-02, 2.2331e-01, 4.9006e-02,
        1.0147e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:33,534][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0811, 0.0699, 0.0800, 0.0589, 0.0934, 0.0944, 0.0601, 0.0528, 0.0804,
        0.0597, 0.1020, 0.0948, 0.0726], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:33,535][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.6605, 0.0136, 0.0150, 0.0089, 0.0193, 0.0273, 0.0294, 0.0297, 0.0386,
        0.0355, 0.0677, 0.0224, 0.0322], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:33,536][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.1616, 0.2086, 0.1254, 0.0684, 0.0242, 0.0193, 0.0068, 0.0318, 0.0672,
        0.0217, 0.1349, 0.0666, 0.0636], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:33,538][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0780, 0.0541, 0.0765, 0.0924, 0.0704, 0.1036, 0.0833, 0.0942, 0.1259,
        0.0250, 0.0527, 0.0823, 0.0616], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:33,542][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0269, 0.0428, 0.0327, 0.0861, 0.0733, 0.1473, 0.0960, 0.1063, 0.0999,
        0.1080, 0.0727, 0.0795, 0.0286], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:33,545][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.4347, 0.0420, 0.0550, 0.1350, 0.0908, 0.0126, 0.0628, 0.0449, 0.0050,
        0.0230, 0.0581, 0.0328, 0.0033], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:33,549][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.1238, 0.0488, 0.0685, 0.1021, 0.0595, 0.0394, 0.0400, 0.0472, 0.1468,
        0.0296, 0.1210, 0.1026, 0.0707], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:33,552][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0405, 0.0027, 0.0255, 0.0086, 0.0456, 0.0311, 0.0194, 0.0382, 0.0621,
        0.0260, 0.2689, 0.0649, 0.3665], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:33,553][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.5096, 0.0369, 0.0368, 0.0385, 0.0325, 0.0442, 0.0405, 0.0406, 0.0411,
        0.0394, 0.0407, 0.0366, 0.0306, 0.0320], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:33,553][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0285, 0.0629, 0.0621, 0.0707, 0.0759, 0.0661, 0.0767, 0.0723, 0.0688,
        0.0844, 0.0812, 0.0811, 0.0883, 0.0809], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:33,554][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.2518e-02, 9.8905e-03, 1.7650e-02, 2.6190e-02, 5.5358e-03, 5.2302e-02,
        5.0695e-03, 1.9686e-03, 8.3497e-01, 3.6532e-03, 7.3386e-03, 7.8014e-03,
        1.5100e-02, 1.6700e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:33,556][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([4.4045e-06, 6.6277e-02, 5.6393e-02, 2.5904e-02, 3.9273e-02, 7.0824e-02,
        8.2380e-03, 3.4120e-02, 4.6232e-01, 1.2888e-02, 1.4738e-01, 4.8053e-02,
        1.3502e-02, 1.4825e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:33,559][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0608, 0.0536, 0.0796, 0.0491, 0.0941, 0.0957, 0.0664, 0.0517, 0.0774,
        0.0512, 0.1031, 0.0800, 0.0724, 0.0648], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:33,563][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.7411, 0.0109, 0.0083, 0.0063, 0.0114, 0.0164, 0.0209, 0.0176, 0.0253,
        0.0235, 0.0440, 0.0185, 0.0202, 0.0356], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:33,567][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1491, 0.1641, 0.1036, 0.0567, 0.0202, 0.0158, 0.0054, 0.0250, 0.0528,
        0.0175, 0.1084, 0.0506, 0.0539, 0.1769], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:33,568][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1053, 0.0574, 0.0718, 0.0858, 0.0586, 0.0844, 0.0779, 0.0825, 0.1071,
        0.0204, 0.0412, 0.0787, 0.0504, 0.0785], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:33,569][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0341, 0.0294, 0.0268, 0.1555, 0.0749, 0.0956, 0.0714, 0.0265, 0.2101,
        0.0453, 0.0755, 0.0324, 0.0886, 0.0339], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:33,570][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.3262e-02, 2.4572e-03, 2.0524e-02, 1.9749e-03, 9.3339e-02, 4.8121e-03,
        1.3233e-01, 1.3286e-03, 4.4801e-03, 1.2955e-02, 6.2185e-03, 1.7558e-03,
        7.0440e-01, 1.6668e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:33,572][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1238, 0.0431, 0.0670, 0.0734, 0.0736, 0.0293, 0.0255, 0.0884, 0.1023,
        0.0251, 0.0890, 0.0580, 0.0428, 0.1589], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:33,574][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0206, 0.0006, 0.0055, 0.0027, 0.0363, 0.0068, 0.0053, 0.0097, 0.0175,
        0.0065, 0.0764, 0.0122, 0.3659, 0.4340], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:33,578][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.4192, 0.0412, 0.0411, 0.0415, 0.0356, 0.0485, 0.0451, 0.0455, 0.0448,
        0.0435, 0.0473, 0.0409, 0.0342, 0.0348, 0.0368], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:33,583][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0248, 0.0575, 0.0582, 0.0650, 0.0698, 0.0596, 0.0710, 0.0672, 0.0623,
        0.0794, 0.0757, 0.0749, 0.0829, 0.0750, 0.0766], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:33,584][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([5.4801e-02, 2.3811e-02, 8.2410e-03, 8.5263e-03, 3.9771e-04, 1.3968e-01,
        4.4252e-04, 5.3071e-02, 4.8653e-01, 2.5614e-03, 3.7513e-03, 1.4107e-02,
        1.7219e-03, 2.0233e-01, 3.1020e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:33,585][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([1.0920e-06, 6.6389e-02, 6.3399e-02, 3.2910e-02, 2.9790e-02, 4.7560e-02,
        8.1026e-03, 3.2902e-02, 3.4076e-01, 1.0350e-02, 2.5356e-01, 4.9771e-02,
        1.1813e-02, 2.6546e-02, 2.6153e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:33,586][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0598, 0.0557, 0.0720, 0.0505, 0.0839, 0.0822, 0.0572, 0.0447, 0.0714,
        0.0461, 0.0886, 0.0805, 0.0843, 0.0608, 0.0623], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:33,587][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.5989, 0.0127, 0.0125, 0.0077, 0.0152, 0.0213, 0.0301, 0.0255, 0.0337,
        0.0332, 0.0632, 0.0219, 0.0283, 0.0453, 0.0503], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:33,590][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.1029, 0.1527, 0.0970, 0.0548, 0.0194, 0.0149, 0.0053, 0.0253, 0.0524,
        0.0174, 0.1056, 0.0540, 0.0532, 0.1761, 0.0690], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:33,594][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.1006, 0.0543, 0.0710, 0.0840, 0.0561, 0.0840, 0.0709, 0.0756, 0.0983,
        0.0194, 0.0380, 0.0725, 0.0467, 0.0762, 0.0525], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:33,599][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0462, 0.0252, 0.0248, 0.0730, 0.0776, 0.0821, 0.0602, 0.0628, 0.1260,
        0.0348, 0.0706, 0.0387, 0.1519, 0.1103, 0.0159], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:33,599][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.2199, 0.0161, 0.0167, 0.0034, 0.0662, 0.0211, 0.1412, 0.0138, 0.0218,
        0.0082, 0.0460, 0.0113, 0.1329, 0.2745, 0.0070], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:33,600][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.1111, 0.0468, 0.0503, 0.0790, 0.0836, 0.0444, 0.0247, 0.0487, 0.1191,
        0.0228, 0.0735, 0.0644, 0.0495, 0.0996, 0.0825], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:33,601][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0168, 0.0009, 0.0049, 0.0021, 0.0117, 0.0050, 0.0044, 0.0097, 0.0127,
        0.0093, 0.0684, 0.0159, 0.1897, 0.4847, 0.1638], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:33,604][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([0.3681, 0.0436, 0.0409, 0.0420, 0.0352, 0.0473, 0.0446, 0.0448, 0.0448,
        0.0438, 0.0477, 0.0420, 0.0354, 0.0356, 0.0369, 0.0473],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:33,607][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([0.0241, 0.0542, 0.0538, 0.0609, 0.0657, 0.0563, 0.0666, 0.0630, 0.0589,
        0.0746, 0.0703, 0.0711, 0.0773, 0.0711, 0.0728, 0.0592],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:33,610][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.1388, 0.0090, 0.0826, 0.0587, 0.0164, 0.0312, 0.0076, 0.3722, 0.0546,
        0.0118, 0.0064, 0.0048, 0.0630, 0.1199, 0.0202, 0.0029],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:33,613][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([1.6763e-06, 7.4418e-02, 8.4127e-02, 5.1804e-02, 3.8164e-02, 6.0007e-02,
        9.3794e-03, 3.9576e-02, 3.2459e-01, 1.5771e-02, 1.7792e-01, 5.2658e-02,
        1.2214e-02, 2.1467e-02, 2.9373e-02, 8.5293e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:33,614][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.0504, 0.0466, 0.0661, 0.0445, 0.0668, 0.0816, 0.0515, 0.0387, 0.0683,
        0.0420, 0.0923, 0.0790, 0.0702, 0.0503, 0.0626, 0.0891],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:33,615][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([0.6204, 0.0118, 0.0091, 0.0063, 0.0131, 0.0178, 0.0283, 0.0202, 0.0302,
        0.0309, 0.0552, 0.0218, 0.0240, 0.0437, 0.0446, 0.0227],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:33,616][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([0.1069, 0.1385, 0.0870, 0.0478, 0.0159, 0.0122, 0.0043, 0.0220, 0.0445,
        0.0144, 0.0971, 0.0440, 0.0470, 0.1615, 0.0625, 0.0942],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:33,617][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.0867, 0.0519, 0.0655, 0.0737, 0.0563, 0.0763, 0.0681, 0.0754, 0.0946,
        0.0197, 0.0386, 0.0678, 0.0459, 0.0753, 0.0553, 0.0489],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:33,619][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.0233, 0.0207, 0.0176, 0.0422, 0.0785, 0.0437, 0.0803, 0.0627, 0.0369,
        0.0829, 0.0587, 0.0351, 0.1564, 0.0851, 0.1410, 0.0350],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:33,623][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([0.1899, 0.0016, 0.0162, 0.0040, 0.0562, 0.0019, 0.0606, 0.0200, 0.0011,
        0.0102, 0.0068, 0.0010, 0.2975, 0.0269, 0.3058, 0.0004],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:33,626][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.1030, 0.0482, 0.0479, 0.0776, 0.0595, 0.0244, 0.0304, 0.0491, 0.1292,
        0.0295, 0.0621, 0.0708, 0.0526, 0.0755, 0.0628, 0.0776],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:33,630][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([0.0178, 0.0005, 0.0031, 0.0025, 0.0083, 0.0039, 0.0029, 0.0052, 0.0091,
        0.0042, 0.0449, 0.0096, 0.0831, 0.4099, 0.2619, 0.1330],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:33,631][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.4110, 0.0371, 0.0357, 0.0369, 0.0314, 0.0424, 0.0390, 0.0395, 0.0399,
        0.0384, 0.0408, 0.0363, 0.0304, 0.0315, 0.0331, 0.0417, 0.0350],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:33,632][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0234, 0.0508, 0.0501, 0.0572, 0.0616, 0.0538, 0.0622, 0.0585, 0.0556,
        0.0685, 0.0662, 0.0661, 0.0714, 0.0662, 0.0671, 0.0566, 0.0648],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:33,633][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([5.6584e-03, 4.2821e-03, 6.6917e-03, 1.1318e-02, 2.2176e-03, 2.3220e-02,
        2.1503e-03, 8.1903e-04, 3.8440e-01, 1.4593e-03, 2.7926e-03, 3.5381e-03,
        5.5908e-03, 6.5707e-06, 3.3771e-03, 5.4247e-01, 5.2617e-06],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:33,634][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.9074e-06, 6.5519e-02, 6.0491e-02, 2.8709e-02, 3.7152e-02, 6.0256e-02,
        7.2873e-03, 3.1658e-02, 3.9228e-01, 1.2326e-02, 1.5662e-01, 4.6114e-02,
        1.2134e-02, 1.4172e-02, 3.8053e-02, 1.3231e-02, 2.3991e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:33,637][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0501, 0.0426, 0.0648, 0.0403, 0.0755, 0.0793, 0.0539, 0.0432, 0.0648,
        0.0420, 0.0845, 0.0638, 0.0585, 0.0537, 0.0577, 0.0753, 0.0500],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:33,641][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.7068, 0.0093, 0.0072, 0.0053, 0.0091, 0.0135, 0.0168, 0.0148, 0.0211,
        0.0182, 0.0362, 0.0149, 0.0159, 0.0293, 0.0256, 0.0141, 0.0419],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:33,646][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1040, 0.1233, 0.0778, 0.0434, 0.0148, 0.0115, 0.0039, 0.0184, 0.0384,
        0.0128, 0.0779, 0.0369, 0.0391, 0.1270, 0.0511, 0.0785, 0.1411],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:33,647][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0963, 0.0527, 0.0616, 0.0750, 0.0480, 0.0712, 0.0668, 0.0695, 0.0906,
        0.0159, 0.0321, 0.0664, 0.0397, 0.0628, 0.0480, 0.0440, 0.0592],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:33,648][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0253, 0.0189, 0.0212, 0.1026, 0.0534, 0.0688, 0.0512, 0.0222, 0.1619,
        0.0330, 0.0618, 0.0212, 0.0733, 0.0272, 0.0312, 0.2033, 0.0234],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:33,649][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([8.5258e-03, 1.4964e-03, 1.1289e-02, 1.2214e-03, 6.4451e-02, 3.0121e-03,
        8.2968e-02, 7.8830e-04, 2.6864e-03, 7.3260e-03, 3.6503e-03, 1.1231e-03,
        4.2870e-01, 9.8995e-05, 3.7412e-01, 8.4589e-03, 8.8962e-05],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:33,651][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0933, 0.0326, 0.0500, 0.0571, 0.0553, 0.0214, 0.0199, 0.0634, 0.0745,
        0.0187, 0.0641, 0.0428, 0.0311, 0.1134, 0.0627, 0.0594, 0.1401],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:33,653][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.4344e-02, 2.1084e-04, 1.8674e-03, 7.4806e-04, 9.8809e-03, 2.3764e-03,
        1.3469e-03, 2.5427e-03, 5.5362e-03, 1.6602e-03, 2.3630e-02, 3.0509e-03,
        9.5503e-02, 1.2263e-01, 2.0137e-01, 6.5280e-02, 4.4802e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:33,656][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:33,659][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[13452],
        [13411],
        [ 8301],
        [  929],
        [27215],
        [14528],
        [ 2848],
        [ 6226],
        [12520],
        [10338],
        [ 2529],
        [18587],
        [ 3367],
        [ 8296],
        [ 3097],
        [ 5181],
        [ 6261]], device='cuda:0')
[2024-07-24 10:29:33,661][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[14334],
        [16549],
        [14059],
        [ 1404],
        [31649],
        [15811],
        [ 4418],
        [11904],
        [13809],
        [15546],
        [ 4305],
        [15932],
        [ 4062],
        [11681],
        [ 7893],
        [12051],
        [ 6778]], device='cuda:0')
[2024-07-24 10:29:33,664][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[16739],
        [16726],
        [17392],
        [17856],
        [18495],
        [18785],
        [18970],
        [18912],
        [19320],
        [19536],
        [19362],
        [19601],
        [19398],
        [19794],
        [20332],
        [20336],
        [19935]], device='cuda:0')
[2024-07-24 10:29:33,665][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[19939],
        [17889],
        [14811],
        [12311],
        [10907],
        [10570],
        [10756],
        [10151],
        [11966],
        [11447],
        [12094],
        [12901],
        [12571],
        [11895],
        [11296],
        [11941],
        [12282]], device='cuda:0')
[2024-07-24 10:29:33,667][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[20170],
        [25804],
        [20879],
        [22067],
        [24900],
        [25749],
        [27416],
        [29112],
        [27860],
        [22658],
        [23766],
        [24141],
        [24613],
        [24137],
        [22191],
        [23168],
        [23848]], device='cuda:0')
[2024-07-24 10:29:33,668][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[8652],
        [7908],
        [8318],
        [6766],
        [6283],
        [7553],
        [7804],
        [7118],
        [7206],
        [7679],
        [7276],
        [7271],
        [7045],
        [7297],
        [7818],
        [8100],
        [8863]], device='cuda:0')
[2024-07-24 10:29:33,671][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[38015],
        [25251],
        [ 8542],
        [17956],
        [13976],
        [15626],
        [15235],
        [15412],
        [19041],
        [18910],
        [15408],
        [15964],
        [19086],
        [17954],
        [17607],
        [17029],
        [18870]], device='cuda:0')
[2024-07-24 10:29:33,674][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[13527],
        [23636],
        [15537],
        [21663],
        [22420],
        [24912],
        [12956],
        [17726],
        [16966],
        [10923],
        [17043],
        [13416],
        [12988],
        [15078],
        [10272],
        [14059],
        [14548]], device='cuda:0')
[2024-07-24 10:29:33,677][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[27507],
        [26402],
        [29316],
        [28956],
        [27964],
        [27801],
        [26836],
        [28287],
        [29558],
        [28348],
        [29732],
        [29431],
        [28974],
        [29953],
        [30168],
        [29946],
        [30289]], device='cuda:0')
[2024-07-24 10:29:33,679][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[22536],
        [27144],
        [30534],
        [29761],
        [28571],
        [28293],
        [29105],
        [29337],
        [28909],
        [28752],
        [27878],
        [27463],
        [28480],
        [27789],
        [28507],
        [27939],
        [27639]], device='cuda:0')
[2024-07-24 10:29:33,682][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 6558],
        [ 7142],
        [ 9709],
        [ 9614],
        [ 8565],
        [ 8455],
        [ 8405],
        [ 8910],
        [ 9848],
        [10314],
        [10657],
        [11395],
        [10811],
        [11225],
        [10932],
        [10594],
        [10764]], device='cuda:0')
[2024-07-24 10:29:33,683][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[21174],
        [18951],
        [37719],
        [27396],
        [28729],
        [35346],
        [40746],
        [38871],
        [27666],
        [40273],
        [25503],
        [41816],
        [27375],
        [33490],
        [30754],
        [24381],
        [26494]], device='cuda:0')
[2024-07-24 10:29:33,685][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[5179],
        [5258],
        [6968],
        [6713],
        [6661],
        [6877],
        [6434],
        [6474],
        [6445],
        [6182],
        [6429],
        [6590],
        [6917],
        [7010],
        [6896],
        [6817],
        [6856]], device='cuda:0')
[2024-07-24 10:29:33,686][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[27316],
        [26834],
        [27374],
        [32065],
        [34041],
        [35735],
        [34991],
        [35680],
        [34880],
        [32516],
        [33909],
        [34774],
        [26224],
        [24812],
        [30527],
        [31680],
        [31315]], device='cuda:0')
[2024-07-24 10:29:33,689][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[31275],
        [38003],
        [28530],
        [45072],
        [18769],
        [34222],
        [44506],
        [36400],
        [35350],
        [35236],
        [31704],
        [44568],
        [35616],
        [29000],
        [15457],
        [16748],
        [32081]], device='cuda:0')
[2024-07-24 10:29:33,690][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[11439],
        [ 9980],
        [ 7971],
        [ 6070],
        [ 6127],
        [ 5196],
        [ 5530],
        [ 5937],
        [ 6060],
        [ 6333],
        [ 6130],
        [ 6027],
        [ 6477],
        [ 6026],
        [ 6600],
        [ 6952],
        [ 6421]], device='cuda:0')
[2024-07-24 10:29:33,693][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[13575],
        [13129],
        [13862],
        [14232],
        [13145],
        [12474],
        [13281],
        [13219],
        [13008],
        [13148],
        [13036],
        [12974],
        [12863],
        [12746],
        [12734],
        [12648],
        [12615]], device='cuda:0')
[2024-07-24 10:29:33,696][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[20487],
        [20735],
        [19742],
        [13623],
        [19247],
        [22459],
        [44645],
        [43265],
        [29273],
        [32174],
        [24735],
        [24925],
        [37418],
        [18739],
        [31483],
        [21532],
        [34100]], device='cuda:0')
[2024-07-24 10:29:33,699][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[44085],
        [42032],
        [42295],
        [39744],
        [39970],
        [39778],
        [38816],
        [40324],
        [36118],
        [35602],
        [34735],
        [34672],
        [34636],
        [34633],
        [34585],
        [35746],
        [35710]], device='cuda:0')
[2024-07-24 10:29:33,701][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[18802],
        [23324],
        [23007],
        [24109],
        [25589],
        [23249],
        [23227],
        [21983],
        [21726],
        [21959],
        [21702],
        [21577],
        [21787],
        [21243],
        [21356],
        [21811],
        [21338]], device='cuda:0')
[2024-07-24 10:29:33,703][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[7161],
        [6166],
        [6014],
        [5785],
        [5617],
        [5601],
        [6018],
        [6158],
        [6516],
        [7580],
        [6939],
        [7740],
        [7375],
        [6856],
        [7816],
        [7773],
        [7270]], device='cuda:0')
[2024-07-24 10:29:33,704][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[30803],
        [29444],
        [26932],
        [26456],
        [26496],
        [26297],
        [26084],
        [26495],
        [26768],
        [26362],
        [26610],
        [26399],
        [26711],
        [26511],
        [26533],
        [26305],
        [26168]], device='cuda:0')
[2024-07-24 10:29:33,706][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[6339],
        [5690],
        [7598],
        [6798],
        [6126],
        [7247],
        [6536],
        [6576],
        [7556],
        [7681],
        [7268],
        [7034],
        [6876],
        [6873],
        [6748],
        [6790],
        [6866]], device='cuda:0')
[2024-07-24 10:29:33,708][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 5802],
        [ 6056],
        [ 8172],
        [ 5221],
        [22177],
        [28307],
        [11360],
        [37866],
        [38071],
        [11507],
        [25751],
        [18469],
        [29711],
        [27265],
        [28929],
        [37017],
        [29516]], device='cuda:0')
[2024-07-24 10:29:33,711][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[20579],
        [30655],
        [32888],
        [17813],
        [24507],
        [12976],
        [17508],
        [14831],
        [15005],
        [16096],
        [33470],
        [18151],
        [30780],
        [ 2386],
        [29609],
        [10335],
        [ 9009]], device='cuda:0')
[2024-07-24 10:29:33,714][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[37575],
        [35157],
        [41214],
        [40725],
        [41741],
        [38940],
        [37786],
        [41311],
        [43442],
        [42801],
        [44438],
        [42660],
        [42255],
        [43119],
        [43363],
        [42536],
        [43008]], device='cuda:0')
[2024-07-24 10:29:33,716][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 4384],
        [ 5285],
        [ 7591],
        [ 6698],
        [12733],
        [12486],
        [ 9247],
        [10299],
        [ 6803],
        [ 6974],
        [ 6959],
        [ 6399],
        [ 6607],
        [ 7993],
        [ 7767],
        [ 7668],
        [ 7819]], device='cuda:0')
[2024-07-24 10:29:33,719][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[32243],
        [31610],
        [29386],
        [35109],
        [30106],
        [30913],
        [30648],
        [26506],
        [30804],
        [33262],
        [31433],
        [33288],
        [30184],
        [36172],
        [30041],
        [31948],
        [33035]], device='cuda:0')
[2024-07-24 10:29:33,721][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[32933],
        [18059],
        [18926],
        [11901],
        [23329],
        [13315],
        [ 9729],
        [11293],
        [13050],
        [19779],
        [15935],
        [12358],
        [15775],
        [17228],
        [26909],
        [23397],
        [15562]], device='cuda:0')
[2024-07-24 10:29:33,722][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145]], device='cuda:0')
[2024-07-24 10:29:33,765][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:33,766][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:33,767][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:33,767][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:33,769][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:33,769][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:33,770][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:33,771][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:33,771][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:33,772][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:33,773][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:33,773][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:33,774][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:33,775][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Sara] are: tensor([0.5341, 0.4659], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:33,775][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Sara] are: tensor([0.0067, 0.9933], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:33,776][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Sara] are: tensor([0.6178, 0.3822], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:33,777][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Sara] are: tensor([0.4329, 0.5671], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:33,778][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Sara] are: tensor([0.9849, 0.0151], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:33,778][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Sara] are: tensor([0.7847, 0.2153], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:33,779][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Sara] are: tensor([0.8647, 0.1353], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:33,780][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Sara] are: tensor([0.1553, 0.8447], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:33,780][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Sara] are: tensor([0.0417, 0.9583], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:33,781][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Sara] are: tensor([0.1868, 0.8132], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:33,782][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Sara] are: tensor([0.4016, 0.5984], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:33,782][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Sara] are: tensor([1.0000e+00, 4.2254e-21], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:33,785][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3956, 0.3327, 0.2717], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:33,788][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0046, 0.3874, 0.6080], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:33,792][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4197, 0.3638, 0.2165], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:33,794][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0477, 0.3947, 0.5576], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:33,795][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.9313, 0.0229, 0.0458], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:33,796][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0688, 0.7487, 0.1825], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:33,796][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.7204, 0.1723, 0.1074], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:33,797][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0883, 0.4845, 0.4272], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:33,799][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0215, 0.4420, 0.5365], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:33,801][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0904, 0.4400, 0.4696], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:33,805][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2044, 0.3824, 0.4132], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:33,808][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([1.0000e+00, 1.6168e-13, 8.1715e-26], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:33,810][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Kenneth] are: tensor([0.2789, 0.2058, 0.2279, 0.2874], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:33,811][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Kenneth] are: tensor([0.0010, 0.3305, 0.6147, 0.0538], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:33,812][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Kenneth] are: tensor([0.3925, 0.2834, 0.1867, 0.1373], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:33,812][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Kenneth] are: tensor([0.0997, 0.1867, 0.4073, 0.3063], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:33,813][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Kenneth] are: tensor([0.8893, 0.0188, 0.0377, 0.0542], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:33,815][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Kenneth] are: tensor([0.0595, 0.3713, 0.0571, 0.5120], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:33,817][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Kenneth] are: tensor([0.6655, 0.1454, 0.1323, 0.0568], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:33,821][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Kenneth] are: tensor([0.0776, 0.3803, 0.2658, 0.2763], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:33,825][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Kenneth] are: tensor([0.0152, 0.2744, 0.3316, 0.3788], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:33,826][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Kenneth] are: tensor([0.0589, 0.3330, 0.3512, 0.2569], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:33,827][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Kenneth] are: tensor([0.1596, 0.2370, 0.2829, 0.3205], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:33,827][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Kenneth] are: tensor([1.0000e+00, 2.6417e-15, 9.0558e-15, 3.0674e-23], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:33,828][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.2020, 0.1633, 0.1350, 0.1772, 0.3227], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:33,829][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ got] are: tensor([6.9673e-04, 5.2045e-02, 1.3922e-01, 7.7371e-03, 8.0030e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:33,832][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.3544, 0.2207, 0.1391, 0.0966, 0.1892], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:33,835][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.0131, 0.1335, 0.3031, 0.3285, 0.2218], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:33,839][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.8548, 0.0169, 0.0341, 0.0473, 0.0470], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:33,841][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.0547, 0.2053, 0.0208, 0.3030, 0.4162], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:33,842][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.5596, 0.1428, 0.1213, 0.0974, 0.0790], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:33,843][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.0686, 0.3324, 0.2181, 0.1899, 0.1910], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:33,844][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.0096, 0.2014, 0.2430, 0.2795, 0.2665], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:33,844][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.0477, 0.2212, 0.2751, 0.1851, 0.2709], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:33,846][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.1278, 0.1809, 0.2296, 0.2346, 0.2270], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:33,848][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ got] are: tensor([1.0000e+00, 2.3287e-12, 8.9711e-14, 7.7539e-16, 1.7516e-20],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:33,852][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1464, 0.1620, 0.1232, 0.1792, 0.2722, 0.1170], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:33,855][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([5.5546e-04, 1.4281e-02, 3.0061e-02, 1.4530e-03, 2.1457e-01, 7.3908e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:33,857][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.3231, 0.2201, 0.1297, 0.0856, 0.1853, 0.0563], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:33,858][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0104, 0.0881, 0.2372, 0.2633, 0.3035, 0.0975], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:33,859][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.8062, 0.0156, 0.0305, 0.0437, 0.0409, 0.0630], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:33,860][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0491, 0.1280, 0.0037, 0.1667, 0.5067, 0.1459], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:33,861][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.5864, 0.1246, 0.0982, 0.0690, 0.0666, 0.0551], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:33,863][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0493, 0.2610, 0.1814, 0.1457, 0.1473, 0.2153], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:33,866][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0090, 0.1535, 0.1852, 0.2112, 0.2017, 0.2395], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:33,870][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0333, 0.1958, 0.2011, 0.1523, 0.2153, 0.2022], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:33,873][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0674, 0.1494, 0.1761, 0.2138, 0.2122, 0.1811], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:33,874][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.0000e+00, 4.8150e-14, 3.1351e-16, 2.7161e-17, 1.1887e-17, 1.4679e-23],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:33,874][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.1134, 0.1000, 0.0953, 0.1340, 0.2100, 0.0985, 0.2486],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,875][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([3.8933e-04, 4.3010e-03, 2.7548e-02, 3.2980e-04, 2.3290e-01, 5.6260e-01,
        1.7192e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,876][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.2633, 0.1989, 0.1192, 0.0862, 0.1775, 0.0619, 0.0930],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,878][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0106, 0.0729, 0.1725, 0.1142, 0.2902, 0.1148, 0.2247],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,882][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.7768, 0.0139, 0.0282, 0.0398, 0.0361, 0.0594, 0.0460],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,885][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.0054, 0.0295, 0.0041, 0.0477, 0.3291, 0.1853, 0.3989],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,889][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.4714, 0.0957, 0.1145, 0.0789, 0.0934, 0.0923, 0.0539],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,890][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.0431, 0.2118, 0.1468, 0.1492, 0.1292, 0.1657, 0.1542],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,890][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.0087, 0.1239, 0.1484, 0.1680, 0.1616, 0.1899, 0.1996],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,891][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.0291, 0.1829, 0.1806, 0.1324, 0.1785, 0.1713, 0.1251],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,892][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.0507, 0.1024, 0.1335, 0.1648, 0.1686, 0.1661, 0.2140],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,894][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([1.0000e+00, 1.2398e-12, 4.7933e-13, 1.1093e-17, 3.1459e-16, 3.6865e-16,
        1.0472e-21], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:33,896][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.1199, 0.0940, 0.0816, 0.1038, 0.1865, 0.0960, 0.2408, 0.0774],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,898][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ at] are: tensor([2.0389e-04, 5.3010e-03, 1.1135e-02, 5.4963e-04, 1.1882e-01, 3.4136e-01,
        9.0747e-02, 4.3189e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,903][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.2503, 0.1659, 0.1131, 0.0791, 0.1660, 0.0582, 0.0963, 0.0712],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,905][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0059, 0.0358, 0.0888, 0.0927, 0.3326, 0.0785, 0.2357, 0.1300],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,906][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.7427, 0.0134, 0.0272, 0.0386, 0.0372, 0.0570, 0.0419, 0.0419],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,906][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0008, 0.0089, 0.0020, 0.0302, 0.3536, 0.1137, 0.4568, 0.0339],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,907][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.5171, 0.1129, 0.0830, 0.0610, 0.0662, 0.0567, 0.0715, 0.0316],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,909][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0302, 0.2069, 0.1381, 0.1077, 0.1161, 0.1413, 0.1250, 0.1348],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,912][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0071, 0.1032, 0.1243, 0.1408, 0.1355, 0.1589, 0.1666, 0.1637],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,916][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0285, 0.1459, 0.1520, 0.1081, 0.1530, 0.1427, 0.1017, 0.1680],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,920][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0520, 0.0972, 0.1238, 0.1468, 0.1399, 0.1347, 0.1709, 0.1348],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,921][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ at] are: tensor([1.0000e+00, 1.5454e-10, 4.2147e-19, 1.1016e-15, 1.4063e-16, 5.3398e-17,
        2.9856e-12, 3.0743e-23], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:33,922][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1027, 0.1058, 0.0749, 0.1079, 0.1570, 0.0735, 0.2011, 0.0645, 0.1126],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,923][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ the] are: tensor([2.9951e-05, 1.7157e-03, 4.2606e-03, 3.0693e-04, 1.0883e-01, 3.1749e-01,
        8.8437e-02, 4.3255e-01, 4.6381e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,923][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.2683, 0.1654, 0.1012, 0.0702, 0.1373, 0.0487, 0.0769, 0.0632, 0.0688],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,926][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0222, 0.0309, 0.1028, 0.0657, 0.2384, 0.0562, 0.2090, 0.1430, 0.1319],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,929][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.7179, 0.0128, 0.0259, 0.0353, 0.0335, 0.0507, 0.0394, 0.0395, 0.0450],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,932][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0148, 0.0278, 0.0085, 0.0855, 0.2497, 0.0813, 0.3317, 0.1513, 0.0493],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,936][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.5159, 0.1101, 0.0804, 0.0546, 0.0530, 0.0532, 0.0620, 0.0384, 0.0326],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,937][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0315, 0.1770, 0.1075, 0.1048, 0.1006, 0.1430, 0.1159, 0.1090, 0.1107],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,938][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0054, 0.0885, 0.1066, 0.1210, 0.1159, 0.1362, 0.1438, 0.1411, 0.1415],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,939][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0216, 0.1294, 0.1275, 0.0983, 0.1342, 0.1271, 0.0917, 0.1510, 0.1193],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,940][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0375, 0.0908, 0.1050, 0.1382, 0.1418, 0.1192, 0.1436, 0.1095, 0.1143],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,943][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ the] are: tensor([1.0000e+00, 3.4059e-13, 1.9112e-17, 1.8127e-16, 1.9670e-16, 5.2180e-23,
        2.7762e-14, 1.2895e-15, 2.6028e-24], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:33,947][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ garden] are: tensor([0.0885, 0.0866, 0.0646, 0.0892, 0.1184, 0.0622, 0.1609, 0.0531, 0.0955,
        0.1810], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,950][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ garden] are: tensor([2.9038e-06, 1.7120e-04, 1.0480e-03, 5.3770e-05, 8.3403e-02, 2.8358e-01,
        1.1182e-01, 4.8383e-01, 3.4373e-02, 1.7233e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,952][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ garden] are: tensor([0.2258, 0.1586, 0.0913, 0.0669, 0.1350, 0.0498, 0.0775, 0.0631, 0.0719,
        0.0600], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,953][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ garden] are: tensor([0.0251, 0.0407, 0.1031, 0.0706, 0.2682, 0.0483, 0.0835, 0.0842, 0.1643,
        0.1120], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,954][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ garden] are: tensor([0.6794, 0.0129, 0.0263, 0.0355, 0.0321, 0.0507, 0.0410, 0.0377, 0.0445,
        0.0399], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,955][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ garden] are: tensor([0.0164, 0.0329, 0.0141, 0.0441, 0.1021, 0.0736, 0.2325, 0.1510, 0.1585,
        0.1746], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,956][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ garden] are: tensor([0.3881, 0.1008, 0.0910, 0.0660, 0.0687, 0.0615, 0.0686, 0.0489, 0.0581,
        0.0482], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,959][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ garden] are: tensor([0.0233, 0.1674, 0.0958, 0.1105, 0.0861, 0.1138, 0.1191, 0.0891, 0.0870,
        0.1078], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,963][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ garden] are: tensor([0.0051, 0.0776, 0.0932, 0.1063, 0.1018, 0.1199, 0.1264, 0.1236, 0.1242,
        0.1218], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,968][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ garden] are: tensor([0.0190, 0.1188, 0.1216, 0.0865, 0.1211, 0.1158, 0.0811, 0.1453, 0.1117,
        0.0790], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,969][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ garden] are: tensor([0.0396, 0.0682, 0.0915, 0.1116, 0.1170, 0.1129, 0.1336, 0.0931, 0.1064,
        0.1261], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,969][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ garden] are: tensor([1.0000e+00, 1.3989e-12, 1.1942e-12, 2.2258e-17, 6.1045e-15, 1.6975e-13,
        3.1004e-16, 1.2163e-13, 1.4531e-13, 5.2585e-20], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:33,970][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0912, 0.0806, 0.0470, 0.0630, 0.1009, 0.0619, 0.1614, 0.0546, 0.0942,
        0.1646, 0.0807], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,971][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([2.2581e-05, 1.1412e-03, 3.1725e-03, 3.1000e-04, 7.9802e-02, 2.7216e-01,
        1.3425e-01, 4.1457e-01, 5.3382e-02, 7.0941e-03, 3.4097e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,973][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2303, 0.1365, 0.0854, 0.0618, 0.1113, 0.0455, 0.0677, 0.0571, 0.0619,
        0.0549, 0.0877], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,977][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0148, 0.0183, 0.0395, 0.0345, 0.1449, 0.0448, 0.1078, 0.0840, 0.1067,
        0.1462, 0.2585], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,980][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.6736, 0.0117, 0.0249, 0.0315, 0.0289, 0.0463, 0.0364, 0.0369, 0.0415,
        0.0372, 0.0310], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,984][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0020, 0.0063, 0.0021, 0.0249, 0.0663, 0.0558, 0.1577, 0.0298, 0.0372,
        0.0374, 0.5806], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,985][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.5022, 0.0945, 0.0617, 0.0498, 0.0488, 0.0417, 0.0552, 0.0269, 0.0338,
        0.0653, 0.0203], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,986][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0263, 0.1315, 0.1040, 0.0821, 0.0719, 0.0955, 0.0925, 0.0951, 0.0799,
        0.1017, 0.1196], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,986][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0041, 0.0694, 0.0836, 0.0951, 0.0915, 0.1074, 0.1133, 0.1110, 0.1111,
        0.1100, 0.1033], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,988][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0210, 0.1067, 0.1012, 0.0833, 0.1094, 0.1036, 0.0754, 0.1254, 0.0975,
        0.0736, 0.1030], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,991][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0462, 0.0748, 0.0830, 0.1096, 0.1099, 0.0966, 0.1077, 0.0901, 0.0899,
        0.1034, 0.0890], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,995][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([1.0000e+00, 1.3751e-14, 1.9858e-29, 7.4456e-20, 6.5450e-21, 5.1643e-21,
        2.4473e-18, 4.6478e-24, 1.2225e-20, 6.0446e-15, 3.2907e-32],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:33,998][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Sara] are: tensor([0.0567, 0.0640, 0.0472, 0.0678, 0.1034, 0.0583, 0.1546, 0.0510, 0.0846,
        0.1494, 0.0616, 0.1015], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,000][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Sara] are: tensor([1.0694e-05, 1.0751e-03, 4.0248e-03, 8.8589e-05, 5.2217e-02, 3.5704e-01,
        1.1921e-01, 4.0268e-01, 3.0796e-02, 2.3608e-03, 2.4461e-02, 6.0325e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,001][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Sara] are: tensor([0.2205, 0.1230, 0.0780, 0.0567, 0.1018, 0.0397, 0.0588, 0.0526, 0.0543,
        0.0473, 0.0828, 0.0846], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,002][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Sara] are: tensor([0.0363, 0.0130, 0.0356, 0.0189, 0.0903, 0.0251, 0.0515, 0.0360, 0.0689,
        0.0595, 0.3017, 0.2631], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,003][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Sara] are: tensor([0.6337, 0.0119, 0.0245, 0.0334, 0.0312, 0.0467, 0.0365, 0.0344, 0.0409,
        0.0348, 0.0279, 0.0441], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,005][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Sara] are: tensor([0.0175, 0.0034, 0.0015, 0.0072, 0.0209, 0.0204, 0.0619, 0.0107, 0.0197,
        0.0343, 0.5788, 0.2237], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,007][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Sara] are: tensor([0.3753, 0.0697, 0.0803, 0.0602, 0.0597, 0.0564, 0.0587, 0.0490, 0.0478,
        0.0692, 0.0388, 0.0349], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,011][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Sara] are: tensor([0.0237, 0.1230, 0.0765, 0.0892, 0.0685, 0.0987, 0.0793, 0.0751, 0.0739,
        0.0874, 0.0875, 0.1172], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,016][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Sara] are: tensor([0.0037, 0.0625, 0.0754, 0.0858, 0.0829, 0.0973, 0.1022, 0.1000, 0.1005,
        0.0983, 0.0922, 0.0991], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,017][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Sara] are: tensor([0.0201, 0.0918, 0.0944, 0.0717, 0.0955, 0.0977, 0.0681, 0.1179, 0.0944,
        0.0675, 0.0993, 0.0816], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,017][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Sara] are: tensor([0.0441, 0.0644, 0.0811, 0.0946, 0.0934, 0.0918, 0.0905, 0.0789, 0.0864,
        0.0902, 0.0848, 0.0998], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,018][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Sara] are: tensor([1.0000e+00, 1.4138e-22, 1.5990e-18, 2.3856e-19, 4.8973e-19, 4.3243e-19,
        7.5923e-21, 1.3942e-17, 2.6236e-18, 5.8233e-19, 1.2487e-21, 2.1838e-24],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,020][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0533, 0.0738, 0.0450, 0.0646, 0.0937, 0.0539, 0.1451, 0.0423, 0.0783,
        0.1370, 0.0506, 0.0894, 0.0730], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,022][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([2.7400e-06, 3.8591e-04, 1.1440e-03, 1.8922e-04, 4.7077e-02, 3.4658e-01,
        1.7054e-01, 3.6532e-01, 2.5420e-02, 3.7652e-03, 2.2111e-02, 1.0709e-02,
        6.7583e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,027][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.2190, 0.1119, 0.0702, 0.0520, 0.0929, 0.0369, 0.0542, 0.0479, 0.0484,
        0.0431, 0.0716, 0.0755, 0.0763], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,030][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0035, 0.0154, 0.0479, 0.0441, 0.0422, 0.0153, 0.0351, 0.0361, 0.0274,
        0.0252, 0.1484, 0.3328, 0.2266], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,032][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.5999, 0.0113, 0.0232, 0.0322, 0.0307, 0.0438, 0.0358, 0.0340, 0.0378,
        0.0347, 0.0259, 0.0427, 0.0482], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,033][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.0047, 0.0033, 0.0026, 0.0129, 0.0218, 0.0319, 0.0225, 0.0050, 0.0115,
        0.0117, 0.4637, 0.1765, 0.2319], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,034][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.3535, 0.0857, 0.0639, 0.0479, 0.0408, 0.0435, 0.0624, 0.0466, 0.0415,
        0.0905, 0.0365, 0.0477, 0.0394], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,034][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0186, 0.1115, 0.0710, 0.0739, 0.0638, 0.0790, 0.0842, 0.0662, 0.0588,
        0.0836, 0.0818, 0.1055, 0.1020], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,036][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0034, 0.0569, 0.0691, 0.0783, 0.0759, 0.0889, 0.0930, 0.0911, 0.0919,
        0.0902, 0.0848, 0.0907, 0.0858], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,040][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0167, 0.0793, 0.0905, 0.0630, 0.0899, 0.0866, 0.0601, 0.1072, 0.0845,
        0.0602, 0.0916, 0.0706, 0.0998], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,043][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0382, 0.0572, 0.0718, 0.0793, 0.0799, 0.0756, 0.0845, 0.0725, 0.0737,
        0.0824, 0.0843, 0.0918, 0.1088], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,047][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([1.0000e+00, 8.4250e-13, 4.0836e-13, 4.7141e-15, 6.9166e-19, 5.2265e-15,
        1.3537e-13, 1.7368e-11, 1.0627e-15, 8.0669e-14, 4.5071e-17, 7.6779e-15,
        7.1113e-19], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,050][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0623, 0.0760, 0.0401, 0.0549, 0.0850, 0.0478, 0.1260, 0.0392, 0.0688,
        0.1228, 0.0523, 0.0983, 0.0807, 0.0457], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:34,051][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.9240e-06, 1.7210e-04, 4.4791e-04, 1.4784e-04, 4.3919e-02, 2.2472e-01,
        3.0653e-01, 3.5897e-01, 2.0474e-02, 7.6950e-03, 1.7553e-02, 1.0370e-02,
        6.6921e-03, 2.3103e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:34,051][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1736, 0.1096, 0.0643, 0.0478, 0.0929, 0.0372, 0.0547, 0.0453, 0.0498,
        0.0441, 0.0680, 0.0716, 0.0714, 0.0696], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:34,053][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0087, 0.0053, 0.0161, 0.0131, 0.0424, 0.0107, 0.0265, 0.0181, 0.0188,
        0.0169, 0.0954, 0.1284, 0.3061, 0.2935], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:34,056][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.5652, 0.0116, 0.0234, 0.0322, 0.0297, 0.0423, 0.0346, 0.0359, 0.0364,
        0.0361, 0.0271, 0.0418, 0.0487, 0.0352], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:34,058][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.4096e-03, 6.6271e-04, 4.5318e-04, 2.7744e-03, 2.2339e-02, 5.6069e-03,
        1.4159e-02, 3.7883e-03, 1.8424e-03, 1.9655e-03, 2.1932e-01, 7.6041e-02,
        4.6547e-01, 1.8416e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:34,063][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.3824, 0.0809, 0.0655, 0.0486, 0.0467, 0.0427, 0.0540, 0.0388, 0.0357,
        0.0664, 0.0256, 0.0366, 0.0542, 0.0220], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:34,065][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0179, 0.0960, 0.0744, 0.0637, 0.0589, 0.0730, 0.0774, 0.0718, 0.0622,
        0.0736, 0.0777, 0.0897, 0.0878, 0.0759], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:34,066][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0033, 0.0531, 0.0635, 0.0720, 0.0695, 0.0815, 0.0855, 0.0836, 0.0841,
        0.0830, 0.0778, 0.0834, 0.0785, 0.0812], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:34,067][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0151, 0.0750, 0.0784, 0.0595, 0.0802, 0.0822, 0.0558, 0.1003, 0.0777,
        0.0566, 0.0816, 0.0720, 0.0908, 0.0747], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:34,067][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0295, 0.0525, 0.0618, 0.0785, 0.0808, 0.0727, 0.0817, 0.0645, 0.0707,
        0.0778, 0.0672, 0.0806, 0.1077, 0.0741], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:34,069][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.0000e+00, 5.9031e-14, 4.3798e-23, 7.4371e-18, 1.2496e-18, 2.5031e-20,
        1.3417e-13, 2.3260e-23, 4.4212e-18, 2.0181e-12, 2.6153e-24, 2.7364e-16,
        1.1691e-13, 4.8678e-30], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:34,072][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0621, 0.0679, 0.0389, 0.0562, 0.0871, 0.0494, 0.1217, 0.0382, 0.0673,
        0.1138, 0.0494, 0.0861, 0.0710, 0.0422, 0.0488], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:34,074][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ give] are: tensor([2.8862e-05, 1.5336e-03, 4.8442e-03, 1.7567e-04, 4.4772e-02, 2.4069e-01,
        1.5352e-01, 3.2676e-01, 2.6014e-02, 2.9007e-03, 2.9612e-02, 8.6785e-03,
        6.3270e-03, 3.1393e-03, 1.5100e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:34,078][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.1997, 0.1066, 0.0615, 0.0434, 0.0818, 0.0290, 0.0458, 0.0384, 0.0397,
        0.0358, 0.0610, 0.0623, 0.0640, 0.0640, 0.0672], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:34,081][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0046, 0.0055, 0.0134, 0.0118, 0.0144, 0.0059, 0.0206, 0.0161, 0.0089,
        0.0101, 0.0523, 0.0978, 0.0797, 0.2371, 0.4218], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:34,081][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.5306, 0.0111, 0.0222, 0.0301, 0.0291, 0.0420, 0.0342, 0.0326, 0.0365,
        0.0324, 0.0247, 0.0407, 0.0446, 0.0332, 0.0560], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:34,082][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0084, 0.0019, 0.0004, 0.0035, 0.0046, 0.0051, 0.0069, 0.0015, 0.0017,
        0.0026, 0.0948, 0.1150, 0.1988, 0.2825, 0.2724], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:34,084][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.3279, 0.0782, 0.0632, 0.0501, 0.0449, 0.0470, 0.0480, 0.0375, 0.0377,
        0.0688, 0.0298, 0.0416, 0.0545, 0.0285, 0.0424], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:34,087][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0140, 0.0947, 0.0665, 0.0644, 0.0564, 0.0685, 0.0720, 0.0588, 0.0526,
        0.0665, 0.0727, 0.0873, 0.0794, 0.0686, 0.0776], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:34,091][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0029, 0.0492, 0.0586, 0.0665, 0.0643, 0.0753, 0.0792, 0.0772, 0.0777,
        0.0766, 0.0719, 0.0770, 0.0729, 0.0752, 0.0755], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:34,095][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0133, 0.0703, 0.0753, 0.0536, 0.0769, 0.0730, 0.0494, 0.0940, 0.0716,
        0.0510, 0.0765, 0.0650, 0.0901, 0.0708, 0.0691], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:34,096][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0293, 0.0451, 0.0576, 0.0680, 0.0687, 0.0643, 0.0795, 0.0623, 0.0629,
        0.0726, 0.0668, 0.0716, 0.0954, 0.0702, 0.0859], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:34,097][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ give] are: tensor([1.0000e+00, 6.9782e-09, 1.2728e-10, 4.4065e-13, 4.3851e-16, 9.4439e-14,
        8.4363e-12, 6.4224e-12, 8.3426e-13, 9.9245e-13, 8.2200e-13, 2.4649e-11,
        6.0503e-11, 2.9108e-13, 1.4049e-15], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:34,098][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.0575, 0.0652, 0.0402, 0.0586, 0.0870, 0.0462, 0.1132, 0.0370, 0.0623,
        0.1097, 0.0424, 0.0814, 0.0671, 0.0405, 0.0454, 0.0462],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:34,099][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ it] are: tensor([6.7007e-06, 1.0854e-03, 2.2941e-03, 9.6951e-05, 3.5448e-02, 2.1220e-01,
        1.5266e-01, 3.1347e-01, 2.3447e-02, 3.3005e-03, 2.5250e-02, 8.8370e-03,
        8.9322e-03, 3.8630e-03, 1.6029e-01, 4.8820e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:34,102][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.1856, 0.0906, 0.0587, 0.0397, 0.0707, 0.0251, 0.0437, 0.0355, 0.0368,
        0.0349, 0.0591, 0.0605, 0.0650, 0.0641, 0.0626, 0.0676],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:34,106][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ it] are: tensor([0.0043, 0.0014, 0.0028, 0.0014, 0.0058, 0.0035, 0.0142, 0.0087, 0.0127,
        0.0202, 0.0359, 0.0401, 0.0491, 0.2263, 0.4085, 0.1652],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:34,110][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.5076, 0.0102, 0.0210, 0.0287, 0.0280, 0.0387, 0.0316, 0.0302, 0.0343,
        0.0300, 0.0236, 0.0380, 0.0420, 0.0302, 0.0531, 0.0528],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:34,111][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ it] are: tensor([1.3525e-02, 7.0269e-04, 5.1056e-05, 8.1081e-04, 6.5140e-03, 2.2851e-03,
        3.3741e-03, 8.9063e-04, 1.8857e-03, 1.0640e-03, 6.4251e-02, 5.1784e-02,
        2.3422e-01, 1.7412e-01, 2.8682e-01, 1.5770e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:34,112][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.3077, 0.0807, 0.0572, 0.0483, 0.0435, 0.0432, 0.0557, 0.0341, 0.0315,
        0.0606, 0.0261, 0.0393, 0.0501, 0.0255, 0.0697, 0.0270],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:34,113][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.0161, 0.0911, 0.0604, 0.0598, 0.0554, 0.0709, 0.0633, 0.0538, 0.0547,
        0.0671, 0.0619, 0.0819, 0.0762, 0.0658, 0.0640, 0.0576],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:34,115][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.0030, 0.0458, 0.0545, 0.0615, 0.0592, 0.0694, 0.0729, 0.0712, 0.0717,
        0.0706, 0.0659, 0.0709, 0.0667, 0.0688, 0.0690, 0.0788],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:34,118][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ it] are: tensor([0.0129, 0.0642, 0.0673, 0.0508, 0.0713, 0.0680, 0.0474, 0.0832, 0.0650,
        0.0486, 0.0674, 0.0608, 0.0823, 0.0644, 0.0671, 0.0791],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:34,122][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.0241, 0.0431, 0.0534, 0.0636, 0.0655, 0.0617, 0.0717, 0.0568, 0.0624,
        0.0711, 0.0601, 0.0701, 0.0912, 0.0661, 0.0788, 0.0603],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:34,125][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ it] are: tensor([1.0000e+00, 6.7973e-12, 3.3928e-14, 1.9596e-14, 7.2687e-16, 7.5433e-21,
        3.8907e-14, 1.3719e-11, 1.7420e-22, 1.9863e-12, 4.1976e-17, 5.4325e-15,
        5.2740e-13, 1.4043e-16, 1.0423e-09, 1.7116e-21], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:34,127][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0587, 0.0685, 0.0356, 0.0496, 0.0734, 0.0419, 0.1071, 0.0335, 0.0600,
        0.1070, 0.0450, 0.0862, 0.0702, 0.0393, 0.0437, 0.0464, 0.0340],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:34,128][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([3.0505e-06, 1.5977e-04, 5.3912e-04, 1.1676e-04, 4.0509e-02, 1.6070e-01,
        2.6077e-01, 3.2049e-01, 1.6618e-02, 5.5680e-03, 1.6806e-02, 6.1754e-03,
        4.9255e-03, 2.0016e-03, 1.1837e-01, 4.0089e-02, 6.1572e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:34,129][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1446, 0.0856, 0.0519, 0.0378, 0.0724, 0.0286, 0.0437, 0.0355, 0.0390,
        0.0354, 0.0555, 0.0580, 0.0600, 0.0582, 0.0647, 0.0652, 0.0641],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:34,130][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0042, 0.0012, 0.0026, 0.0017, 0.0080, 0.0020, 0.0062, 0.0032, 0.0042,
        0.0039, 0.0190, 0.0230, 0.0642, 0.0600, 0.4273, 0.1648, 0.2043],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:34,132][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.5234, 0.0094, 0.0198, 0.0270, 0.0249, 0.0357, 0.0288, 0.0289, 0.0304,
        0.0284, 0.0225, 0.0345, 0.0394, 0.0294, 0.0475, 0.0442, 0.0257],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:34,134][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([8.6566e-04, 1.2301e-04, 2.0067e-05, 2.0240e-04, 2.3770e-03, 6.4592e-04,
        1.7476e-03, 2.6651e-04, 2.0375e-04, 1.7528e-04, 1.5937e-02, 7.4787e-03,
        4.8429e-02, 1.3292e-02, 2.6861e-01, 1.5210e-01, 4.8752e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:34,138][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.3140, 0.0709, 0.0573, 0.0441, 0.0462, 0.0411, 0.0501, 0.0373, 0.0337,
        0.0602, 0.0252, 0.0345, 0.0516, 0.0215, 0.0579, 0.0354, 0.0189],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:34,142][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0152, 0.0769, 0.0616, 0.0511, 0.0460, 0.0593, 0.0648, 0.0589, 0.0512,
        0.0608, 0.0650, 0.0725, 0.0711, 0.0654, 0.0639, 0.0527, 0.0637],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:34,143][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0026, 0.0423, 0.0504, 0.0573, 0.0553, 0.0650, 0.0681, 0.0666, 0.0671,
        0.0661, 0.0618, 0.0664, 0.0625, 0.0646, 0.0647, 0.0739, 0.0654],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:34,144][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0126, 0.0615, 0.0631, 0.0486, 0.0652, 0.0659, 0.0453, 0.0793, 0.0612,
        0.0456, 0.0644, 0.0589, 0.0734, 0.0594, 0.0608, 0.0726, 0.0622],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:34,146][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0211, 0.0435, 0.0489, 0.0652, 0.0671, 0.0594, 0.0688, 0.0535, 0.0579,
        0.0643, 0.0523, 0.0670, 0.0908, 0.0599, 0.0754, 0.0509, 0.0540],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:34,149][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.0000e+00, 1.1097e-13, 1.0378e-22, 1.8956e-17, 7.7475e-19, 6.6660e-20,
        3.4595e-13, 5.6777e-23, 1.1653e-17, 3.0919e-12, 7.4898e-24, 4.4780e-16,
        4.8062e-14, 1.0441e-29, 1.0832e-15, 2.4063e-11, 6.0641e-30],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:34,192][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:34,192][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:34,193][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:34,194][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:34,195][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:34,195][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:34,196][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:34,197][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:34,197][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:34,198][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:34,199][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:34,199][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:34,200][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:34,201][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Sara] are: tensor([0.2080, 0.7920], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:34,202][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Sara] are: tensor([0.1667, 0.8333], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:34,202][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Sara] are: tensor([0.0691, 0.9309], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:34,204][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Sara] are: tensor([0.0760, 0.9240], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:34,205][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Sara] are: tensor([0.1619, 0.8381], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:34,206][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Sara] are: tensor([0.3951, 0.6049], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:34,207][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Sara] are: tensor([0.1568, 0.8432], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:34,207][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Sara] are: tensor([0.1708, 0.8292], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:34,208][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Sara] are: tensor([0.3487, 0.6513], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:34,209][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Sara] are: tensor([0.7201, 0.2799], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:34,209][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Sara] are: tensor([0.3631, 0.6369], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:34,210][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Sara] are: tensor([0.9561, 0.0439], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:34,211][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1646, 0.8331, 0.0023], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:34,212][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1277, 0.2951, 0.5773], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:34,213][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0318, 0.5398, 0.4284], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:34,213][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0296, 0.5141, 0.4564], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:34,214][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0864, 0.3606, 0.5530], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:34,215][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.7079, 0.2849, 0.0071], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:34,216][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1487, 0.5340, 0.3172], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:34,216][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0650, 0.3197, 0.6153], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:34,217][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.5280, 0.2649, 0.2071], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:34,218][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.5706, 0.2654, 0.1640], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:34,218][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1059, 0.4438, 0.4503], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:34,219][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([7.9726e-05, 9.9755e-01, 2.3733e-03], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:34,220][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Kenneth] are: tensor([0.0559, 0.6453, 0.2710, 0.0278], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:34,221][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Kenneth] are: tensor([0.0681, 0.1724, 0.4617, 0.2978], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:34,221][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Kenneth] are: tensor([0.0251, 0.3726, 0.2956, 0.3067], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:34,222][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Kenneth] are: tensor([0.0370, 0.3484, 0.3110, 0.3036], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:34,226][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Kenneth] are: tensor([0.0585, 0.2645, 0.3487, 0.3283], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:34,229][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Kenneth] are: tensor([0.2672, 0.5276, 0.1228, 0.0824], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:34,230][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Kenneth] are: tensor([0.0563, 0.5519, 0.3082, 0.0837], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:34,230][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Kenneth] are: tensor([0.0501, 0.2582, 0.4386, 0.2532], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:34,231][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Kenneth] are: tensor([0.1191, 0.8445, 0.0271, 0.0093], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:34,232][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Kenneth] are: tensor([0.4476, 0.2280, 0.1476, 0.1769], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:34,234][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Kenneth] are: tensor([0.1590, 0.0365, 0.4964, 0.3081], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:34,237][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Kenneth] are: tensor([0.0096, 0.4165, 0.4615, 0.1124], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:34,241][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.0015, 0.4894, 0.4454, 0.0590, 0.0047], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:34,245][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.0591, 0.0630, 0.1774, 0.1348, 0.5658], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:34,245][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.0183, 0.2740, 0.2188, 0.2272, 0.2617], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:34,246][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.0218, 0.2640, 0.2342, 0.2319, 0.2481], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:34,247][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.0423, 0.1948, 0.2945, 0.2411, 0.2274], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:34,249][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.1925, 0.6209, 0.0166, 0.1432, 0.0267], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:34,251][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.0419, 0.4617, 0.2208, 0.1200, 0.1555], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:34,255][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.0327, 0.1710, 0.3298, 0.1680, 0.2985], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:34,260][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.1718, 0.1943, 0.1421, 0.1417, 0.3501], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:34,260][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.3597, 0.1072, 0.0937, 0.2564, 0.1831], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:34,261][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.0931, 0.0708, 0.0499, 0.4286, 0.3575], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:34,262][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([5.3944e-05, 1.0921e-02, 1.8104e-03, 9.8482e-01, 2.3910e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:34,263][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4457, 0.3052, 0.0395, 0.1386, 0.0679, 0.0031], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:34,265][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0146, 0.0368, 0.1139, 0.0760, 0.3707, 0.3880], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:34,267][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0134, 0.2294, 0.1767, 0.1844, 0.2161, 0.1799], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:34,271][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0143, 0.2162, 0.1917, 0.1889, 0.2005, 0.1884], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:34,275][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0319, 0.1610, 0.2374, 0.1991, 0.1741, 0.1964], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:34,276][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.4188, 0.3534, 0.0277, 0.1119, 0.0763, 0.0120], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:34,277][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1667, 0.2770, 0.1602, 0.1011, 0.1290, 0.1661], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:34,278][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0263, 0.1339, 0.2409, 0.1294, 0.2247, 0.2448], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:34,279][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0953, 0.2043, 0.0660, 0.0569, 0.3996, 0.1779], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:34,282][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1482, 0.0991, 0.0795, 0.2663, 0.3248, 0.0821], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:34,286][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0263, 0.1389, 0.0423, 0.4217, 0.3041, 0.0667], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:34,289][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([3.6739e-06, 1.1399e-03, 1.5860e-04, 4.2384e-01, 5.7477e-01, 8.6650e-05],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:34,291][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.0356, 0.0364, 0.7092, 0.0073, 0.0150, 0.1912, 0.0053],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:34,292][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.0062, 0.0204, 0.0976, 0.0463, 0.3342, 0.4345, 0.0608],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:34,293][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.0129, 0.1839, 0.1416, 0.1493, 0.1733, 0.1474, 0.1916],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:34,293][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.0164, 0.1758, 0.1578, 0.1542, 0.1672, 0.1556, 0.1730],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:34,295][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.0289, 0.1403, 0.1958, 0.1704, 0.1499, 0.1475, 0.1673],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:34,298][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.1847, 0.4779, 0.1397, 0.0456, 0.0467, 0.1012, 0.0044],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:34,302][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.0411, 0.2524, 0.1652, 0.0789, 0.1544, 0.2074, 0.1006],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:34,307][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.0180, 0.1184, 0.2205, 0.1114, 0.1857, 0.1921, 0.1539],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:34,307][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.0914, 0.2238, 0.0293, 0.1501, 0.1332, 0.1557, 0.2166],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:34,308][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.0933, 0.0810, 0.0946, 0.1673, 0.2818, 0.1001, 0.1818],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:34,309][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.0222, 0.0090, 0.0205, 0.0681, 0.0067, 0.0063, 0.8671],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:34,310][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([1.3349e-05, 1.9945e-02, 1.9520e-04, 3.6610e-01, 5.7255e-01, 1.3976e-02,
        2.7217e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:34,313][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0961, 0.5071, 0.0500, 0.0592, 0.0695, 0.1428, 0.0671, 0.0081],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:34,318][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0271, 0.0257, 0.0785, 0.0574, 0.2625, 0.2903, 0.0535, 0.2050],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:34,322][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0109, 0.1538, 0.1212, 0.1269, 0.1481, 0.1263, 0.1672, 0.1456],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:34,323][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0133, 0.1512, 0.1357, 0.1338, 0.1467, 0.1344, 0.1457, 0.1393],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:34,323][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0230, 0.1149, 0.1817, 0.1289, 0.1314, 0.1331, 0.1344, 0.1526],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:34,324][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.4239, 0.2784, 0.1087, 0.0200, 0.0641, 0.0878, 0.0118, 0.0053],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:34,325][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0973, 0.2457, 0.1330, 0.0761, 0.1211, 0.1632, 0.0904, 0.0732],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:34,327][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0226, 0.0916, 0.1559, 0.0854, 0.1526, 0.1580, 0.1254, 0.2085],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:34,331][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0885, 0.0759, 0.0367, 0.0247, 0.1447, 0.2038, 0.2721, 0.1535],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:34,334][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0753, 0.0560, 0.0554, 0.1079, 0.2511, 0.0791, 0.2280, 0.1471],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:34,338][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0348, 0.2384, 0.0237, 0.2695, 0.0180, 0.0311, 0.3298, 0.0547],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:34,339][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([2.4660e-06, 3.8727e-04, 3.5327e-06, 3.7543e-03, 6.7327e-02, 1.0425e-04,
        9.2839e-01, 3.0681e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:34,340][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([1.0360e-01, 6.9324e-01, 7.2071e-03, 3.8395e-02, 2.9798e-02, 4.1794e-04,
        4.2124e-02, 8.5020e-02, 1.9721e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:34,340][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0052, 0.0174, 0.0617, 0.0406, 0.1951, 0.2296, 0.0481, 0.1965, 0.2057],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:34,342][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0090, 0.1392, 0.1068, 0.1122, 0.1305, 0.1109, 0.1462, 0.1256, 0.1196],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:34,345][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0082, 0.1326, 0.1196, 0.1182, 0.1280, 0.1201, 0.1342, 0.1253, 0.1139],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:34,349][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0235, 0.1016, 0.1510, 0.1307, 0.1098, 0.1143, 0.1233, 0.1174, 0.1284],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:34,353][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.3218, 0.3382, 0.0421, 0.1416, 0.0484, 0.0210, 0.0030, 0.0661, 0.0178],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:34,354][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2662, 0.1283, 0.0955, 0.0550, 0.0738, 0.1045, 0.0525, 0.0668, 0.1572],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:34,355][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0181, 0.0850, 0.1195, 0.0788, 0.1269, 0.1329, 0.1037, 0.1652, 0.1698],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:34,356][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0715, 0.0529, 0.0429, 0.0628, 0.2230, 0.1051, 0.2622, 0.1443, 0.0354],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:34,357][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1130, 0.0425, 0.0411, 0.1148, 0.2085, 0.0463, 0.1514, 0.1688, 0.1136],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:34,359][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0177, 0.0253, 0.0232, 0.0542, 0.3948, 0.0416, 0.3315, 0.0153, 0.0963],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:34,362][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0203, 0.0011, 0.0010, 0.0154, 0.7431, 0.0012, 0.0622, 0.0714, 0.0842],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:34,366][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ garden] are: tensor([0.0036, 0.0938, 0.0668, 0.0190, 0.0013, 0.0279, 0.0079, 0.7756, 0.0033,
        0.0009], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:34,370][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ garden] are: tensor([0.0065, 0.0206, 0.0546, 0.0372, 0.1783, 0.2313, 0.0473, 0.1633, 0.2389,
        0.0220], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:34,370][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ garden] are: tensor([0.0094, 0.1245, 0.0933, 0.0988, 0.1162, 0.0994, 0.1282, 0.1127, 0.1085,
        0.1091], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:34,371][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ garden] are: tensor([0.0099, 0.1217, 0.1082, 0.1071, 0.1172, 0.1093, 0.1194, 0.1135, 0.1033,
        0.0905], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:34,372][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ garden] are: tensor([0.0233, 0.0974, 0.1382, 0.1099, 0.0948, 0.1019, 0.1111, 0.1085, 0.1146,
        0.1003], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:34,374][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ garden] are: tensor([0.1407, 0.1527, 0.2469, 0.0496, 0.0239, 0.0542, 0.0251, 0.2552, 0.0378,
        0.0139], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:34,378][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ garden] are: tensor([0.0389, 0.2204, 0.1072, 0.0500, 0.0887, 0.1202, 0.0824, 0.0516, 0.2130,
        0.0277], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:34,381][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ garden] are: tensor([0.0149, 0.0767, 0.1167, 0.0693, 0.1105, 0.1171, 0.0959, 0.1550, 0.1477,
        0.0963], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:34,385][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ garden] are: tensor([0.0562, 0.2120, 0.0174, 0.0468, 0.0328, 0.0479, 0.3942, 0.1695, 0.0181,
        0.0053], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:34,386][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ garden] are: tensor([0.1145, 0.0486, 0.0398, 0.0883, 0.1182, 0.0451, 0.1582, 0.1612, 0.1223,
        0.1038], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:34,387][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ garden] are: tensor([0.0077, 0.0110, 0.0064, 0.0105, 0.0126, 0.0047, 0.6183, 0.0107, 0.0181,
        0.2999], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:34,388][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ garden] are: tensor([1.4667e-03, 2.3025e-03, 1.3683e-04, 4.0236e-03, 4.1631e-02, 5.7231e-03,
        3.7077e-02, 7.5386e-03, 8.7763e-01, 2.2468e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:34,389][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1400, 0.4951, 0.0038, 0.0616, 0.0249, 0.0122, 0.1305, 0.0605, 0.0080,
        0.0619, 0.0014], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:34,392][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0113, 0.0122, 0.0449, 0.0269, 0.1357, 0.1789, 0.0254, 0.1397, 0.1804,
        0.0175, 0.2269], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:34,396][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0078, 0.1100, 0.0845, 0.0894, 0.1027, 0.0896, 0.1145, 0.1004, 0.0959,
        0.0975, 0.1078], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:34,401][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0062, 0.1144, 0.0997, 0.0974, 0.1052, 0.1005, 0.1074, 0.1020, 0.0943,
        0.0833, 0.0897], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:34,402][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0202, 0.0809, 0.1221, 0.0969, 0.0928, 0.0939, 0.0969, 0.0981, 0.1029,
        0.0834, 0.1120], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:34,402][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.5860, 0.1030, 0.0232, 0.0236, 0.0301, 0.0488, 0.0016, 0.0415, 0.0200,
        0.1212, 0.0010], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:34,403][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2241, 0.1062, 0.0760, 0.0400, 0.0597, 0.0844, 0.0412, 0.0535, 0.1379,
        0.0332, 0.1438], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:34,405][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0099, 0.0651, 0.1107, 0.0598, 0.0947, 0.1036, 0.0800, 0.1337, 0.1316,
        0.0864, 0.1245], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:34,409][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1097, 0.0424, 0.0397, 0.0373, 0.0844, 0.1476, 0.1861, 0.1296, 0.0633,
        0.0987, 0.0612], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:34,412][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0765, 0.0351, 0.0332, 0.0808, 0.1137, 0.0404, 0.1039, 0.1238, 0.1052,
        0.1085, 0.1789], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:34,416][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0180, 0.0444, 0.0095, 0.0634, 0.0633, 0.0439, 0.4087, 0.0061, 0.0580,
        0.1394, 0.1456], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:34,417][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([4.0590e-03, 1.1233e-03, 1.0823e-05, 4.2817e-03, 1.8175e-02, 2.2270e-04,
        2.7932e-01, 3.4155e-04, 4.4107e-03, 3.6416e-01, 3.2390e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:34,418][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Sara] are: tensor([0.0095, 0.0452, 0.1632, 0.0141, 0.0040, 0.2147, 0.0104, 0.2921, 0.1258,
        0.0014, 0.1029, 0.0168], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,419][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Sara] are: tensor([0.0077, 0.0086, 0.0384, 0.0234, 0.1244, 0.1484, 0.0284, 0.1312, 0.1513,
        0.0171, 0.2696, 0.0515], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,421][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Sara] are: tensor([0.0076, 0.1008, 0.0764, 0.0809, 0.0930, 0.0805, 0.1028, 0.0904, 0.0866,
        0.0873, 0.0975, 0.0962], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,424][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Sara] are: tensor([0.0101, 0.0968, 0.0885, 0.0871, 0.0975, 0.0899, 0.0947, 0.0926, 0.0865,
        0.0743, 0.0827, 0.0992], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,428][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Sara] are: tensor([0.0188, 0.0858, 0.1091, 0.1002, 0.0822, 0.0790, 0.0842, 0.0843, 0.0896,
        0.0768, 0.1020, 0.0879], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,432][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Sara] are: tensor([0.1521, 0.0554, 0.1138, 0.0856, 0.0350, 0.0551, 0.0133, 0.2550, 0.0662,
        0.0944, 0.0373, 0.0369], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,433][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Sara] are: tensor([0.0761, 0.0742, 0.0641, 0.0384, 0.0489, 0.0772, 0.0369, 0.0432, 0.1627,
        0.0271, 0.2219, 0.1293], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,434][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Sara] are: tensor([0.0143, 0.0685, 0.0926, 0.0589, 0.0858, 0.0951, 0.0712, 0.1275, 0.1177,
        0.0805, 0.1056, 0.0824], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,435][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Sara] are: tensor([0.0527, 0.0753, 0.0143, 0.2081, 0.0566, 0.0633, 0.1169, 0.1164, 0.0485,
        0.1739, 0.0223, 0.0517], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,437][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Sara] are: tensor([0.0859, 0.0286, 0.0234, 0.0496, 0.0742, 0.0258, 0.0689, 0.0732, 0.0589,
        0.0607, 0.1822, 0.2684], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,440][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Sara] are: tensor([0.0225, 0.0321, 0.0349, 0.1745, 0.0338, 0.0543, 0.2463, 0.0205, 0.1363,
        0.1487, 0.0508, 0.0453], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,443][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Sara] are: tensor([9.8362e-02, 1.9053e-06, 2.2594e-06, 4.2685e-05, 2.6799e-04, 7.7243e-06,
        2.0730e-04, 3.8548e-05, 3.4309e-03, 1.8391e-03, 7.9911e-01, 9.6691e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,445][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([3.7583e-03, 1.0468e-01, 4.8335e-02, 7.9242e-03, 5.3094e-04, 8.0556e-03,
        6.6931e-03, 7.1676e-01, 3.1972e-03, 2.5335e-03, 1.9372e-02, 7.7807e-02,
        3.6018e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,448][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.0101, 0.0112, 0.0412, 0.0244, 0.1202, 0.1371, 0.0284, 0.1174, 0.1496,
        0.0175, 0.2468, 0.0595, 0.0364], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,449][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0060, 0.0916, 0.0696, 0.0739, 0.0853, 0.0739, 0.0963, 0.0838, 0.0796,
        0.0805, 0.0914, 0.0904, 0.0775], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,449][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.0084, 0.0916, 0.0824, 0.0818, 0.0906, 0.0833, 0.0879, 0.0852, 0.0785,
        0.0665, 0.0732, 0.0891, 0.0815], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,450][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0176, 0.0702, 0.1022, 0.0887, 0.0770, 0.0755, 0.0776, 0.0827, 0.0842,
        0.0594, 0.0958, 0.0705, 0.0985], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,452][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.1078, 0.1461, 0.0426, 0.1297, 0.0223, 0.0300, 0.0070, 0.1637, 0.0184,
        0.1668, 0.0191, 0.1272, 0.0195], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,455][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0178, 0.1262, 0.0641, 0.0331, 0.0634, 0.0753, 0.0467, 0.0402, 0.1289,
        0.0222, 0.1601, 0.1733, 0.0486], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,459][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0086, 0.0594, 0.0963, 0.0527, 0.0833, 0.0861, 0.0691, 0.1113, 0.1062,
        0.0708, 0.1059, 0.0691, 0.0812], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,463][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0461, 0.0375, 0.0617, 0.0220, 0.1810, 0.1513, 0.0696, 0.1165, 0.0432,
        0.0113, 0.0439, 0.0404, 0.1756], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,464][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0392, 0.0164, 0.0226, 0.0486, 0.0714, 0.0201, 0.0487, 0.0584, 0.0544,
        0.0523, 0.1831, 0.2010, 0.1836], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,465][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.0306, 0.0239, 0.0305, 0.0170, 0.0793, 0.0132, 0.1220, 0.0430, 0.0709,
        0.1643, 0.0503, 0.0284, 0.3266], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,466][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([2.4400e-04, 5.6656e-05, 1.0524e-05, 6.7989e-04, 9.0597e-05, 9.9520e-06,
        1.0252e-03, 7.0031e-06, 1.6316e-04, 2.9840e-03, 1.3420e-02, 9.2029e-01,
        6.1018e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,467][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.8993e-01, 1.6071e-01, 5.6619e-03, 2.2371e-02, 6.7598e-02, 4.9207e-02,
        6.3630e-02, 8.2058e-03, 4.1076e-02, 5.7597e-02, 5.2042e-03, 1.1455e-01,
        2.1405e-01, 1.9786e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:34,470][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0069, 0.0115, 0.0365, 0.0250, 0.1134, 0.1207, 0.0276, 0.1046, 0.1312,
        0.0173, 0.2179, 0.0640, 0.0391, 0.0842], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:34,474][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0056, 0.0858, 0.0632, 0.0670, 0.0790, 0.0689, 0.0894, 0.0777, 0.0743,
        0.0744, 0.0840, 0.0833, 0.0710, 0.0763], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:34,478][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0047, 0.0871, 0.0775, 0.0767, 0.0822, 0.0777, 0.0838, 0.0796, 0.0727,
        0.0634, 0.0689, 0.0841, 0.0755, 0.0660], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:34,479][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0142, 0.0648, 0.0943, 0.0757, 0.0697, 0.0744, 0.0774, 0.0746, 0.0794,
        0.0636, 0.0891, 0.0667, 0.0779, 0.0782], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:34,480][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.4508, 0.1990, 0.0144, 0.0306, 0.0260, 0.0228, 0.0012, 0.0177, 0.0367,
        0.0739, 0.0061, 0.1011, 0.0147, 0.0050], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:34,481][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1999, 0.0566, 0.0479, 0.0314, 0.0438, 0.0576, 0.0254, 0.0389, 0.0936,
        0.0227, 0.1036, 0.0827, 0.0436, 0.1522], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:34,483][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0124, 0.0536, 0.0849, 0.0485, 0.0759, 0.0794, 0.0639, 0.0999, 0.0969,
        0.0656, 0.0883, 0.0611, 0.0730, 0.0967], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:34,486][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0640, 0.0231, 0.0262, 0.0139, 0.0670, 0.0656, 0.0701, 0.1078, 0.0200,
        0.0775, 0.0331, 0.0277, 0.3621, 0.0417], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:34,490][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0703, 0.0084, 0.0130, 0.0253, 0.0341, 0.0122, 0.0227, 0.0363, 0.0283,
        0.0302, 0.1186, 0.1174, 0.1788, 0.3044], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:34,494][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0166, 0.0196, 0.0625, 0.0806, 0.1636, 0.0647, 0.0452, 0.0455, 0.1346,
        0.0449, 0.0623, 0.0231, 0.1470, 0.0897], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:34,495][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([4.9858e-05, 3.0799e-07, 2.7142e-09, 1.1662e-06, 1.7769e-05, 7.9454e-08,
        6.0420e-04, 1.2289e-08, 2.7137e-07, 3.6575e-05, 1.9056e-04, 3.1580e-03,
        8.8740e-01, 1.0854e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:34,496][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0036, 0.1482, 0.0317, 0.0071, 0.0119, 0.0635, 0.0353, 0.4022, 0.0324,
        0.0023, 0.0269, 0.1076, 0.0113, 0.1153, 0.0006], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:34,498][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0099, 0.0084, 0.0337, 0.0205, 0.0995, 0.1107, 0.0242, 0.0983, 0.1223,
        0.0148, 0.2225, 0.0462, 0.0333, 0.0896, 0.0662], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:34,501][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0062, 0.0796, 0.0598, 0.0631, 0.0727, 0.0636, 0.0814, 0.0711, 0.0680,
        0.0683, 0.0767, 0.0760, 0.0658, 0.0703, 0.0772], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:34,505][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0055, 0.0805, 0.0719, 0.0715, 0.0759, 0.0723, 0.0775, 0.0739, 0.0682,
        0.0587, 0.0634, 0.0785, 0.0702, 0.0626, 0.0696], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:34,509][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0129, 0.0606, 0.0913, 0.0686, 0.0674, 0.0709, 0.0682, 0.0701, 0.0758,
        0.0534, 0.0858, 0.0623, 0.0750, 0.0749, 0.0629], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:34,510][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.1777, 0.0651, 0.0110, 0.0067, 0.0045, 0.0054, 0.0022, 0.0250, 0.0068,
        0.0271, 0.0074, 0.1075, 0.0370, 0.4999, 0.0166], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:34,511][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0558, 0.0755, 0.0392, 0.0234, 0.0325, 0.0465, 0.0219, 0.0249, 0.0885,
        0.0152, 0.1107, 0.0997, 0.0380, 0.1508, 0.1772], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:34,512][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0084, 0.0467, 0.0826, 0.0443, 0.0698, 0.0732, 0.0593, 0.0907, 0.0880,
        0.0569, 0.0901, 0.0540, 0.0628, 0.0915, 0.0815], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:34,514][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0306, 0.0174, 0.0116, 0.0031, 0.0961, 0.0251, 0.0699, 0.1227, 0.0087,
        0.0133, 0.0154, 0.0256, 0.4998, 0.0422, 0.0186], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:34,517][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0261, 0.0046, 0.0060, 0.0130, 0.0162, 0.0067, 0.0199, 0.0231, 0.0195,
        0.0187, 0.0580, 0.0491, 0.2029, 0.3129, 0.2233], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:34,521][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0490, 0.0614, 0.0264, 0.1057, 0.1420, 0.0452, 0.1279, 0.0121, 0.0469,
        0.0220, 0.0195, 0.0789, 0.0215, 0.0235, 0.2179], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:34,523][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([3.1397e-05, 2.0677e-07, 2.3521e-08, 1.0393e-06, 2.2904e-06, 2.6991e-08,
        1.1822e-06, 1.1349e-08, 1.9363e-07, 1.0904e-06, 2.7953e-05, 1.7159e-03,
        1.6802e-02, 3.4205e-01, 6.3937e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:34,525][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([2.5333e-02, 1.0652e-01, 3.8802e-03, 4.4075e-02, 5.0081e-02, 2.1147e-03,
        5.5817e-02, 2.6215e-01, 5.9685e-04, 6.0746e-02, 9.4412e-03, 3.9416e-02,
        2.5648e-01, 6.0399e-02, 2.2802e-02, 1.3858e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:34,526][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([0.0035, 0.0104, 0.0337, 0.0207, 0.0972, 0.1104, 0.0261, 0.0955, 0.1139,
        0.0154, 0.1981, 0.0517, 0.0327, 0.0837, 0.0699, 0.0371],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:34,527][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.0056, 0.0716, 0.0555, 0.0581, 0.0672, 0.0583, 0.0757, 0.0654, 0.0627,
        0.0637, 0.0713, 0.0707, 0.0615, 0.0656, 0.0719, 0.0752],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:34,529][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([0.0056, 0.0755, 0.0668, 0.0663, 0.0702, 0.0671, 0.0714, 0.0684, 0.0642,
        0.0547, 0.0597, 0.0737, 0.0655, 0.0585, 0.0650, 0.0676],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:34,533][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.0153, 0.0547, 0.0831, 0.0659, 0.0609, 0.0591, 0.0645, 0.0623, 0.0698,
        0.0544, 0.0752, 0.0555, 0.0726, 0.0656, 0.0514, 0.0897],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:34,536][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([0.1149, 0.0298, 0.0182, 0.0318, 0.0608, 0.0144, 0.0027, 0.0885, 0.0055,
        0.0299, 0.0080, 0.0209, 0.0537, 0.4827, 0.0356, 0.0026],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:34,540][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([0.0488, 0.0715, 0.0425, 0.0280, 0.0325, 0.0465, 0.0265, 0.0264, 0.0751,
        0.0183, 0.0891, 0.0865, 0.0373, 0.1303, 0.1676, 0.0732],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:34,542][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.0090, 0.0464, 0.0697, 0.0418, 0.0687, 0.0711, 0.0535, 0.0833, 0.0851,
        0.0579, 0.0767, 0.0540, 0.0626, 0.0811, 0.0719, 0.0673],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:34,543][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.0343, 0.0248, 0.0226, 0.0333, 0.0598, 0.0351, 0.0416, 0.0453, 0.0161,
        0.0254, 0.0168, 0.0301, 0.4446, 0.0407, 0.0972, 0.0323],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:34,544][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([0.0305, 0.0039, 0.0053, 0.0095, 0.0236, 0.0052, 0.0095, 0.0194, 0.0143,
        0.0134, 0.0381, 0.0471, 0.1063, 0.2457, 0.3462, 0.0819],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:34,545][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.0412, 0.0091, 0.0390, 0.0069, 0.1727, 0.0254, 0.0318, 0.0467, 0.0434,
        0.0043, 0.0510, 0.0121, 0.2714, 0.1062, 0.0714, 0.0674],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:34,546][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([4.4991e-07, 9.7556e-12, 3.6082e-13, 1.3815e-11, 6.4388e-09, 3.1010e-12,
        3.7748e-10, 1.5498e-11, 1.7016e-10, 8.3092e-10, 7.0753e-08, 4.8419e-08,
        7.5220e-05, 1.0933e-04, 9.9912e-01, 6.9577e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:34,549][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.4098e-01, 1.1431e-01, 4.0179e-03, 1.9786e-02, 5.5717e-02, 2.9988e-02,
        5.3045e-02, 8.3607e-03, 2.5723e-02, 4.7788e-02, 3.4010e-03, 8.1038e-02,
        1.4274e-01, 1.9016e-04, 2.5125e-01, 2.1505e-02, 1.5503e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:34,553][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0052, 0.0095, 0.0306, 0.0212, 0.0887, 0.1011, 0.0230, 0.0866, 0.1105,
        0.0140, 0.1823, 0.0517, 0.0311, 0.0714, 0.0575, 0.0344, 0.0813],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:34,556][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0044, 0.0678, 0.0508, 0.0536, 0.0631, 0.0547, 0.0718, 0.0620, 0.0590,
        0.0594, 0.0673, 0.0669, 0.0570, 0.0611, 0.0682, 0.0712, 0.0617],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:34,558][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0038, 0.0716, 0.0634, 0.0628, 0.0667, 0.0636, 0.0688, 0.0653, 0.0597,
        0.0519, 0.0563, 0.0685, 0.0616, 0.0544, 0.0611, 0.0634, 0.0572],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:34,559][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0123, 0.0529, 0.0758, 0.0614, 0.0575, 0.0602, 0.0626, 0.0607, 0.0643,
        0.0517, 0.0716, 0.0544, 0.0641, 0.0630, 0.0480, 0.0768, 0.0628],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:34,560][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.4036, 0.1602, 0.0120, 0.0260, 0.0184, 0.0177, 0.0010, 0.0136, 0.0256,
        0.0628, 0.0045, 0.0755, 0.0109, 0.0040, 0.0455, 0.1134, 0.0052],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:34,561][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1586, 0.0346, 0.0284, 0.0211, 0.0272, 0.0345, 0.0153, 0.0250, 0.0555,
        0.0150, 0.0659, 0.0468, 0.0302, 0.0963, 0.1134, 0.0674, 0.1647],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:34,563][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0107, 0.0433, 0.0669, 0.0395, 0.0614, 0.0636, 0.0512, 0.0795, 0.0772,
        0.0530, 0.0699, 0.0491, 0.0590, 0.0763, 0.0653, 0.0604, 0.0735],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:34,566][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0567, 0.0210, 0.0210, 0.0118, 0.0586, 0.0509, 0.0695, 0.0923, 0.0173,
        0.0629, 0.0292, 0.0256, 0.3174, 0.0355, 0.0382, 0.0557, 0.0366],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:34,570][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0436, 0.0041, 0.0060, 0.0108, 0.0151, 0.0044, 0.0103, 0.0117, 0.0110,
        0.0129, 0.0473, 0.0458, 0.0706, 0.1394, 0.2353, 0.0939, 0.2377],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:34,574][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0125, 0.0131, 0.0480, 0.0666, 0.1388, 0.0634, 0.0354, 0.0335, 0.1401,
        0.0325, 0.0484, 0.0160, 0.1037, 0.0715, 0.0659, 0.0357, 0.0748],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:34,574][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([5.2586e-07, 1.4408e-10, 4.7946e-13, 6.2759e-11, 1.8177e-08, 4.1189e-11,
        8.0244e-08, 2.7375e-12, 1.0340e-10, 2.3484e-09, 4.2839e-08, 2.2264e-07,
        4.6076e-04, 3.2955e-05, 8.4404e-01, 1.4885e-01, 6.6150e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:34,578][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:34,581][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[13131],
        [26658],
        [14235],
        [15112],
        [30583],
        [28956],
        [12853],
        [22008],
        [29575],
        [30444],
        [19690],
        [39897],
        [20125],
        [32469],
        [25811],
        [20494],
        [31355]], device='cuda:0')
[2024-07-24 10:29:34,584][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[13756],
        [19424],
        [12181],
        [ 8221],
        [29707],
        [18047],
        [ 3691],
        [ 9930],
        [16693],
        [18938],
        [ 4569],
        [30466],
        [ 6305],
        [15017],
        [ 7751],
        [ 9154],
        [13014]], device='cuda:0')
[2024-07-24 10:29:34,586][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[3279],
        [2727],
        [4359],
        [5087],
        [4536],
        [4365],
        [3318],
        [3196],
        [3121],
        [2850],
        [2827],
        [2729],
        [2781],
        [2804],
        [2854],
        [2838],
        [2798]], device='cuda:0')
[2024-07-24 10:29:34,589][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[21686],
        [46579],
        [45877],
        [45582],
        [44007],
        [47590],
        [47306],
        [48308],
        [48313],
        [48360],
        [48153],
        [48283],
        [48203],
        [47880],
        [48184],
        [48208],
        [47974]], device='cuda:0')
[2024-07-24 10:29:34,592][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[20978],
        [24304],
        [24069],
        [24356],
        [23869],
        [23644],
        [24125],
        [23527],
        [23299],
        [23437],
        [23171],
        [23406],
        [23647],
        [23844],
        [23886],
        [23814],
        [23779]], device='cuda:0')
[2024-07-24 10:29:34,593][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[15550],
        [15573],
        [31479],
        [32737],
        [27762],
        [26020],
        [25544],
        [23699],
        [26978],
        [28341],
        [28802],
        [25082],
        [26596],
        [26800],
        [20897],
        [22158],
        [20791]], device='cuda:0')
[2024-07-24 10:29:34,594][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[14326],
        [14732],
        [16374],
        [17400],
        [18515],
        [19113],
        [19626],
        [20269],
        [20386],
        [20667],
        [20520],
        [21061],
        [21499],
        [21509],
        [21553],
        [21749],
        [21338]], device='cuda:0')
[2024-07-24 10:29:34,596][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 3394],
        [ 6420],
        [16708],
        [37852],
        [21433],
        [13852],
        [ 9724],
        [ 9609],
        [17353],
        [28807],
        [23223],
        [30449],
        [29436],
        [29052],
        [35664],
        [37873],
        [41052]], device='cuda:0')
[2024-07-24 10:29:34,599][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[28640],
        [38002],
        [39231],
        [40007],
        [41821],
        [40829],
        [41586],
        [42098],
        [41677],
        [42492],
        [41688],
        [42021],
        [42935],
        [42425],
        [42473],
        [42457],
        [41881]], device='cuda:0')
[2024-07-24 10:29:34,602][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[13887],
        [19076],
        [21815],
        [22414],
        [21793],
        [22032],
        [22115],
        [21732],
        [21672],
        [21783],
        [21583],
        [21744],
        [21606],
        [21497],
        [21667],
        [21571],
        [21465]], device='cuda:0')
[2024-07-24 10:29:34,604][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[23470],
        [23909],
        [23302],
        [24829],
        [25210],
        [26083],
        [25861],
        [25645],
        [25968],
        [25909],
        [25983],
        [26131],
        [26111],
        [26520],
        [26513],
        [26642],
        [26915]], device='cuda:0')
[2024-07-24 10:29:34,607][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[27085],
        [43804],
        [44019],
        [44758],
        [43865],
        [44176],
        [44479],
        [44376],
        [44528],
        [44507],
        [44639],
        [44624],
        [44881],
        [45131],
        [45106],
        [45046],
        [45181]], device='cuda:0')
[2024-07-24 10:29:34,610][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[16873],
        [13836],
        [13279],
        [14377],
        [13074],
        [12672],
        [12628],
        [12548],
        [12590],
        [13856],
        [15046],
        [14887],
        [15398],
        [15886],
        [16784],
        [16678],
        [17148]], device='cuda:0')
[2024-07-24 10:29:34,611][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[3694],
        [3694],
        [3694],
        [3694],
        [3694],
        [3694],
        [3694],
        [3694],
        [3694],
        [3694],
        [3694],
        [3694],
        [3694],
        [3694],
        [3694],
        [3694],
        [3694]], device='cuda:0')
[2024-07-24 10:29:34,612][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[18631],
        [39589],
        [16658],
        [33114],
        [16564],
        [15705],
        [19180],
        [24115],
        [21776],
        [21862],
        [27664],
        [26990],
        [19687],
        [25260],
        [22542],
        [19623],
        [28152]], device='cuda:0')
[2024-07-24 10:29:34,614][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[18467],
        [34714],
        [34560],
        [27382],
        [20402],
        [31816],
        [13146],
        [31967],
        [36007],
        [22063],
        [33494],
        [19590],
        [23573],
        [29110],
        [23830],
        [21690],
        [37798]], device='cuda:0')
[2024-07-24 10:29:34,617][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[22831],
        [19527],
        [18710],
        [19009],
        [19925],
        [20499],
        [20747],
        [21085],
        [21206],
        [21219],
        [21034],
        [21009],
        [20928],
        [21029],
        [20928],
        [20887],
        [21056]], device='cuda:0')
[2024-07-24 10:29:34,619][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[16123],
        [11856],
        [ 9916],
        [ 9030],
        [ 8677],
        [ 8639],
        [ 8808],
        [ 9265],
        [ 9628],
        [ 9753],
        [ 9951],
        [ 9794],
        [ 9800],
        [ 9682],
        [ 9631],
        [ 9684],
        [ 9597]], device='cuda:0')
[2024-07-24 10:29:34,622][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[16482],
        [18080],
        [19100],
        [17986],
        [17024],
        [16579],
        [16316],
        [16174],
        [16206],
        [15911],
        [16282],
        [16248],
        [16020],
        [15823],
        [15391],
        [15140],
        [14926]], device='cuda:0')
[2024-07-24 10:29:34,625][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 2300],
        [13665],
        [ 9356],
        [13757],
        [12538],
        [12014],
        [13332],
        [12972],
        [12508],
        [13203],
        [12718],
        [14218],
        [13215],
        [12326],
        [11292],
        [10539],
        [ 9992]], device='cuda:0')
[2024-07-24 10:29:34,628][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[32104],
        [35533],
        [41174],
        [39588],
        [37024],
        [38316],
        [34467],
        [37281],
        [40507],
        [42744],
        [36010],
        [40356],
        [38625],
        [38402],
        [31080],
        [31107],
        [40634]], device='cuda:0')
[2024-07-24 10:29:34,629][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 8186],
        [24312],
        [22334],
        [22607],
        [22061],
        [19870],
        [20226],
        [19747],
        [17155],
        [18124],
        [16166],
        [16256],
        [17317],
        [16055],
        [17059],
        [17268],
        [16526]], device='cuda:0')
[2024-07-24 10:29:34,630][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[1097],
        [1080],
        [1014],
        [1023],
        [1013],
        [ 974],
        [ 940],
        [ 993],
        [ 978],
        [ 978],
        [ 948],
        [ 956],
        [ 923],
        [ 926],
        [ 915],
        [ 912],
        [ 914]], device='cuda:0')
[2024-07-24 10:29:34,632][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[17473],
        [21171],
        [31023],
        [19977],
        [39764],
        [39930],
        [29816],
        [31275],
        [33219],
        [20824],
        [31266],
        [29307],
        [39943],
        [40252],
        [41999],
        [40675],
        [39699]], device='cuda:0')
[2024-07-24 10:29:34,635][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[16394],
        [24614],
        [24120],
        [18224],
        [16032],
        [16136],
        [19394],
        [19218],
        [19188],
        [18425],
        [20416],
        [22865],
        [14748],
        [12025],
        [10619],
        [12187],
        [13196]], device='cuda:0')
[2024-07-24 10:29:34,637][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[25102],
        [12662],
        [ 7898],
        [23973],
        [ 5954],
        [ 7157],
        [21095],
        [17108],
        [14547],
        [19119],
        [17053],
        [19296],
        [11143],
        [14281],
        [14284],
        [15184],
        [21915]], device='cuda:0')
[2024-07-24 10:29:34,640][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[42683],
        [42180],
        [34218],
        [39739],
        [28069],
        [39407],
        [39931],
        [18227],
        [37055],
        [38783],
        [23926],
        [31793],
        [29674],
        [22993],
        [29250],
        [19415],
        [23950]], device='cuda:0')
[2024-07-24 10:29:34,643][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[42373],
        [41273],
        [38793],
        [39210],
        [40248],
        [38578],
        [40260],
        [39927],
        [37719],
        [39404],
        [39087],
        [39110],
        [38958],
        [40074],
        [40279],
        [40848],
        [37826]], device='cuda:0')
[2024-07-24 10:29:34,645][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[36503],
        [10878],
        [32765],
        [15200],
        [26597],
        [30883],
        [26602],
        [28907],
        [32278],
        [26499],
        [32775],
        [26702],
        [32823],
        [28817],
        [30108],
        [30927],
        [27915]], device='cuda:0')
[2024-07-24 10:29:34,647][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344]], device='cuda:0')
[2024-07-24 10:29:34,696][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:34,697][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:34,697][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:34,698][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:34,699][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:34,699][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:34,700][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:34,701][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:34,701][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:34,702][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:34,703][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:34,703][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:34,704][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:34,705][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Sara] are: tensor([0.7356, 0.2644], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:34,705][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Sara] are: tensor([0.6472, 0.3528], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:34,706][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Sara] are: tensor([0.5339, 0.4661], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:34,709][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Sara] are: tensor([0.9790, 0.0210], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:34,713][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Sara] are: tensor([0.3331, 0.6669], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:34,714][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Sara] are: tensor([0.0461, 0.9539], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:34,715][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Sara] are: tensor([0.9969, 0.0031], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:34,715][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Sara] are: tensor([0.8296, 0.1704], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:34,716][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Sara] are: tensor([0.0865, 0.9135], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:34,718][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Sara] are: tensor([0.5786, 0.4214], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:34,721][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Sara] are: tensor([0.6718, 0.3282], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:34,725][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Sara] are: tensor([0.1886, 0.8114], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:34,728][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3953, 0.5000, 0.1047], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:34,730][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.4444, 0.2490, 0.3066], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:34,730][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3462, 0.5203, 0.1335], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:34,731][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.9682, 0.0175, 0.0143], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:34,732][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2560, 0.4184, 0.3256], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:34,733][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0148, 0.4320, 0.5532], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:34,736][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.9905, 0.0057, 0.0038], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:34,740][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.7821, 0.1370, 0.0809], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:34,743][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0384, 0.4815, 0.4801], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:34,745][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2777, 0.3536, 0.3687], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:34,746][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.9866, 0.0084, 0.0050], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:34,747][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1269, 0.4160, 0.4571], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:34,747][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Kenneth] are: tensor([0.4752, 0.3165, 0.1369, 0.0714], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:34,749][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Kenneth] are: tensor([0.3783, 0.2020, 0.2454, 0.1743], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:34,752][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Kenneth] are: tensor([0.1212, 0.1944, 0.6037, 0.0807], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:34,756][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Kenneth] are: tensor([0.9380, 0.0218, 0.0184, 0.0219], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:34,759][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Kenneth] are: tensor([0.1830, 0.3068, 0.2959, 0.2142], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:34,761][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Kenneth] are: tensor([0.0169, 0.2870, 0.4050, 0.2911], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:34,762][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Kenneth] are: tensor([9.9910e-01, 5.2324e-04, 3.3581e-04, 4.4184e-05], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:34,763][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Kenneth] are: tensor([0.5887, 0.1544, 0.0976, 0.1593], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:34,763][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Kenneth] are: tensor([0.0271, 0.3166, 0.3414, 0.3150], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:34,765][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Kenneth] are: tensor([0.1946, 0.3380, 0.3193, 0.1482], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:34,768][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Kenneth] are: tensor([0.5501, 0.0367, 0.0130, 0.4002], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:34,772][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Kenneth] are: tensor([0.0914, 0.3407, 0.3097, 0.2582], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:34,775][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.3586, 0.1993, 0.2023, 0.0814, 0.1585], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:34,777][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.3205, 0.1711, 0.2057, 0.1454, 0.1573], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:34,778][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.0562, 0.2513, 0.5572, 0.1007, 0.0347], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:34,778][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.9362, 0.0172, 0.0143, 0.0176, 0.0147], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:34,779][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.1299, 0.2404, 0.3027, 0.2110, 0.1160], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:34,781][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.0069, 0.1722, 0.2648, 0.3339, 0.2223], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:34,783][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ got] are: tensor([9.9519e-01, 1.6328e-03, 2.5912e-03, 4.4734e-04, 1.3416e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:34,786][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.5723, 0.1162, 0.0735, 0.1312, 0.1069], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:34,790][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.0179, 0.2242, 0.2236, 0.2191, 0.3153], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:34,792][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.2273, 0.2069, 0.1825, 0.1373, 0.2460], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:34,793][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.9164, 0.0312, 0.0131, 0.0326, 0.0067], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:34,794][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.0711, 0.2665, 0.2466, 0.1785, 0.2372], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:34,795][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.3802, 0.1546, 0.1358, 0.0530, 0.1760, 0.1004], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:34,796][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.2686, 0.1475, 0.1785, 0.1249, 0.1346, 0.1460], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:34,799][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1012, 0.2473, 0.4166, 0.1448, 0.0752, 0.0149], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:34,803][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.9020, 0.0216, 0.0178, 0.0209, 0.0175, 0.0202], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:34,806][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1226, 0.1905, 0.1990, 0.2218, 0.1374, 0.1287], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:34,808][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0043, 0.1102, 0.2221, 0.2110, 0.2187, 0.2337], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:34,809][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([9.9419e-01, 2.1792e-03, 2.7243e-03, 5.9532e-04, 2.6572e-04, 5.0300e-05],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:34,810][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.4248, 0.0993, 0.0665, 0.1347, 0.1429, 0.1318], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:34,811][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0137, 0.1820, 0.1842, 0.1727, 0.2601, 0.1874], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:34,812][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1734, 0.1481, 0.1669, 0.1000, 0.2065, 0.2051], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:34,815][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.9204, 0.0108, 0.0053, 0.0483, 0.0032, 0.0120], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:34,819][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0562, 0.2060, 0.2122, 0.1442, 0.1842, 0.1973], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:34,822][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.4519, 0.1423, 0.1061, 0.0383, 0.1112, 0.0768, 0.0735],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:34,824][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.2351, 0.1298, 0.1574, 0.1111, 0.1182, 0.1280, 0.1204],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:34,825][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.0213, 0.1919, 0.4838, 0.1029, 0.1185, 0.0681, 0.0136],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:34,826][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.8755, 0.0231, 0.0207, 0.0224, 0.0189, 0.0228, 0.0168],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:34,827][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.0697, 0.1643, 0.1982, 0.1649, 0.1078, 0.1683, 0.1268],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:34,829][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.0076, 0.1089, 0.1586, 0.1850, 0.1845, 0.1826, 0.1728],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:34,831][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([9.9868e-01, 5.1941e-04, 6.6845e-04, 8.3498e-05, 3.2360e-05, 8.1838e-06,
        3.9505e-06], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:34,835][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.3807, 0.0803, 0.0482, 0.1038, 0.0973, 0.1951, 0.0946],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:34,838][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.0119, 0.1538, 0.1538, 0.1411, 0.2154, 0.1680, 0.1560],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:34,840][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.1321, 0.1584, 0.1619, 0.1269, 0.1953, 0.1670, 0.0583],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:34,841][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.5585, 0.0369, 0.0015, 0.0563, 0.0037, 0.0061, 0.3371],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:34,841][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0453, 0.2009, 0.1723, 0.1410, 0.1605, 0.1560, 0.1240],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:34,842][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.3932, 0.1295, 0.0723, 0.0364, 0.1227, 0.0755, 0.0996, 0.0706],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:34,844][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.2168, 0.1138, 0.1431, 0.0969, 0.1038, 0.1119, 0.1026, 0.1112],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:34,847][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1615, 0.2648, 0.2671, 0.1299, 0.0644, 0.0310, 0.0590, 0.0223],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:34,851][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.8496, 0.0250, 0.0216, 0.0244, 0.0204, 0.0251, 0.0192, 0.0146],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:34,855][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0881, 0.1647, 0.1456, 0.1598, 0.1086, 0.1290, 0.1310, 0.0732],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:34,856][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0027, 0.0753, 0.1272, 0.1204, 0.1362, 0.1744, 0.2059, 0.1579],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:34,857][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ at] are: tensor([9.9652e-01, 1.6314e-03, 1.3957e-03, 3.0087e-04, 1.1256e-04, 2.1830e-05,
        1.8690e-05, 1.1043e-06], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:34,857][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.2770, 0.0852, 0.0563, 0.1088, 0.1016, 0.1603, 0.1259, 0.0851],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:34,858][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0111, 0.1239, 0.1288, 0.1229, 0.1788, 0.1366, 0.1304, 0.1676],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:34,860][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.1006, 0.1230, 0.1263, 0.0962, 0.1647, 0.1535, 0.1244, 0.1113],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:34,863][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.8523, 0.0269, 0.0058, 0.0421, 0.0035, 0.0058, 0.0568, 0.0069],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:34,867][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0486, 0.1532, 0.1632, 0.1129, 0.1437, 0.1392, 0.0999, 0.1393],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:34,871][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.2700, 0.1206, 0.0857, 0.0331, 0.1095, 0.0883, 0.0877, 0.1158, 0.0894],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:34,872][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1890, 0.1031, 0.1287, 0.0886, 0.0951, 0.1020, 0.0917, 0.0987, 0.1033],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:34,872][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.3158, 0.1500, 0.2432, 0.1001, 0.0447, 0.0183, 0.0294, 0.0581, 0.0405],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:34,873][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.8365, 0.0239, 0.0208, 0.0226, 0.0191, 0.0230, 0.0186, 0.0137, 0.0218],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:34,874][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0647, 0.1462, 0.1274, 0.1525, 0.1150, 0.1074, 0.1105, 0.0866, 0.0896],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:34,876][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0021, 0.0574, 0.1085, 0.1015, 0.1103, 0.1225, 0.1635, 0.1885, 0.1457],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:34,878][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ the] are: tensor([9.8182e-01, 8.1797e-03, 6.9118e-03, 1.9606e-03, 8.3108e-04, 1.4788e-04,
        1.0915e-04, 2.0572e-05, 1.9014e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:34,882][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.3203, 0.0760, 0.0578, 0.0955, 0.0812, 0.1224, 0.0858, 0.0837, 0.0773],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:34,887][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0089, 0.1123, 0.1144, 0.1083, 0.1601, 0.1191, 0.1141, 0.1478, 0.1151],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:34,888][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0970, 0.1061, 0.1156, 0.0676, 0.1320, 0.1388, 0.1035, 0.1078, 0.1316],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:34,888][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.8892, 0.0085, 0.0026, 0.0313, 0.0013, 0.0026, 0.0597, 0.0023, 0.0025],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:34,889][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0411, 0.1354, 0.1434, 0.0980, 0.1269, 0.1256, 0.0874, 0.1118, 0.1303],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:34,891][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ garden] are: tensor([0.3574, 0.1262, 0.0924, 0.0290, 0.0736, 0.0700, 0.0660, 0.0662, 0.0775,
        0.0417], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:34,894][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ garden] are: tensor([0.1685, 0.0945, 0.1169, 0.0824, 0.0874, 0.0933, 0.0856, 0.0904, 0.0935,
        0.0872], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:34,898][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ garden] are: tensor([0.0876, 0.1798, 0.3635, 0.0790, 0.0620, 0.0314, 0.0134, 0.0238, 0.1108,
        0.0489], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:34,901][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ garden] are: tensor([0.8202, 0.0227, 0.0204, 0.0217, 0.0192, 0.0234, 0.0180, 0.0145, 0.0230,
        0.0168], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:34,903][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ garden] are: tensor([0.0544, 0.1240, 0.1447, 0.1216, 0.0712, 0.1200, 0.1050, 0.0835, 0.1036,
        0.0719], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:34,904][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ garden] are: tensor([0.0054, 0.0574, 0.0965, 0.0975, 0.0902, 0.1050, 0.1080, 0.1539, 0.1571,
        0.1289], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:34,905][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ garden] are: tensor([9.9743e-01, 1.2779e-03, 1.0390e-03, 1.5698e-04, 5.5052e-05, 1.9665e-05,
        6.7548e-06, 1.8513e-06, 3.4521e-06, 1.1671e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:34,905][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ garden] are: tensor([0.2738, 0.0842, 0.0489, 0.1023, 0.0623, 0.0905, 0.0857, 0.0860, 0.0595,
        0.1066], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:34,907][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ garden] are: tensor([0.0085, 0.0927, 0.0975, 0.0910, 0.1373, 0.1054, 0.1001, 0.1295, 0.1044,
        0.1337], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:34,910][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ garden] are: tensor([0.0849, 0.1042, 0.1076, 0.0734, 0.1260, 0.1180, 0.0946, 0.1039, 0.1079,
        0.0795], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:34,914][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ garden] are: tensor([0.2437, 0.0266, 0.0011, 0.0145, 0.0016, 0.0025, 0.0458, 0.0010, 0.0018,
        0.6613], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:34,919][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ garden] are: tensor([0.0364, 0.1428, 0.1235, 0.0963, 0.1217, 0.1083, 0.0834, 0.0966, 0.1093,
        0.0817], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:34,919][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2027, 0.1724, 0.0581, 0.0400, 0.1180, 0.0684, 0.0878, 0.0705, 0.0753,
        0.0573, 0.0496], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:34,920][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1474, 0.0836, 0.1060, 0.0736, 0.0792, 0.0838, 0.0766, 0.0843, 0.0853,
        0.0787, 0.1014], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:34,921][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2646, 0.2256, 0.0876, 0.1138, 0.0577, 0.0139, 0.0230, 0.0337, 0.0903,
        0.0816, 0.0081], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:34,923][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.7882, 0.0241, 0.0219, 0.0227, 0.0210, 0.0262, 0.0206, 0.0153, 0.0242,
        0.0190, 0.0168], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:34,926][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0838, 0.1108, 0.0952, 0.1182, 0.0913, 0.1001, 0.0889, 0.0641, 0.0888,
        0.0781, 0.0808], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:34,930][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0020, 0.0409, 0.0760, 0.0760, 0.0758, 0.0919, 0.1088, 0.1191, 0.1282,
        0.1530, 0.1284], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:34,933][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([9.9798e-01, 9.5865e-04, 7.3434e-04, 2.1262e-04, 7.4075e-05, 1.3172e-05,
        1.1267e-05, 9.8987e-07, 1.1877e-06, 1.3804e-05, 4.8399e-06],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:34,935][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.3403, 0.0555, 0.0404, 0.0665, 0.0537, 0.1189, 0.0647, 0.0610, 0.0727,
        0.0954, 0.0307], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:34,936][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0074, 0.0848, 0.0850, 0.0827, 0.1200, 0.0919, 0.0868, 0.1144, 0.0897,
        0.1172, 0.1202], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:34,936][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0686, 0.0834, 0.0914, 0.0662, 0.1142, 0.1048, 0.0850, 0.0832, 0.1040,
        0.0941, 0.1051], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:34,937][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7890, 0.0124, 0.0041, 0.0345, 0.0025, 0.0038, 0.0404, 0.0052, 0.0046,
        0.1005, 0.0029], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:34,939][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0329, 0.1116, 0.1213, 0.0798, 0.1025, 0.0996, 0.0723, 0.0900, 0.1024,
        0.0715, 0.1161], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:34,942][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Sara] are: tensor([0.3356, 0.1065, 0.0710, 0.0267, 0.0564, 0.0507, 0.0467, 0.0611, 0.0649,
        0.0372, 0.0764, 0.0667], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,946][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Sara] are: tensor([0.1417, 0.0790, 0.0974, 0.0688, 0.0721, 0.0760, 0.0701, 0.0764, 0.0768,
        0.0713, 0.0912, 0.0792], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,950][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Sara] are: tensor([0.0941, 0.0790, 0.2689, 0.0792, 0.1014, 0.0380, 0.0132, 0.0285, 0.1308,
        0.0659, 0.0489, 0.0520], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,951][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Sara] are: tensor([0.8031, 0.0201, 0.0182, 0.0198, 0.0185, 0.0225, 0.0172, 0.0141, 0.0221,
        0.0158, 0.0157, 0.0128], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,952][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Sara] are: tensor([0.0540, 0.0945, 0.1079, 0.0992, 0.0610, 0.0899, 0.0794, 0.0675, 0.0827,
        0.0629, 0.0916, 0.1093], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,953][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Sara] are: tensor([0.0026, 0.0363, 0.0746, 0.0810, 0.0805, 0.0824, 0.0851, 0.1060, 0.1119,
        0.1352, 0.1429, 0.0614], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,955][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Sara] are: tensor([9.9843e-01, 5.5538e-04, 7.4481e-04, 1.3706e-04, 5.4167e-05, 1.9353e-05,
        8.1819e-06, 1.1866e-06, 2.5269e-06, 1.0273e-05, 1.0671e-05, 2.3508e-05],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,957][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Sara] are: tensor([0.2680, 0.0602, 0.0358, 0.0774, 0.0518, 0.1417, 0.0599, 0.0574, 0.0781,
        0.0822, 0.0346, 0.0530], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,962][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Sara] are: tensor([0.0065, 0.0694, 0.0761, 0.0732, 0.1094, 0.0830, 0.0808, 0.1014, 0.0809,
        0.1104, 0.1102, 0.0988], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,966][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Sara] are: tensor([0.1055, 0.0544, 0.0796, 0.0579, 0.0978, 0.1026, 0.0869, 0.0888, 0.1031,
        0.0839, 0.0947, 0.0448], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,967][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Sara] are: tensor([0.3311, 0.1649, 0.0007, 0.0388, 0.0068, 0.0015, 0.0736, 0.0021, 0.0040,
        0.1880, 0.0010, 0.1874], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,968][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Sara] are: tensor([0.0306, 0.1108, 0.1010, 0.0752, 0.0923, 0.0859, 0.0667, 0.0823, 0.0895,
        0.0644, 0.0945, 0.1068], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:34,969][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.2284, 0.0933, 0.0857, 0.0322, 0.0772, 0.0590, 0.0579, 0.0655, 0.0744,
        0.0429, 0.0733, 0.0755, 0.0345], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,971][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.1300, 0.0727, 0.0891, 0.0627, 0.0667, 0.0702, 0.0649, 0.0704, 0.0707,
        0.0656, 0.0838, 0.0714, 0.0818], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,973][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0414, 0.0886, 0.2197, 0.0357, 0.0359, 0.0227, 0.0107, 0.0509, 0.1662,
        0.0789, 0.0618, 0.1062, 0.0812], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,978][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.7968, 0.0214, 0.0186, 0.0198, 0.0167, 0.0210, 0.0165, 0.0129, 0.0205,
        0.0149, 0.0146, 0.0123, 0.0140], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,982][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.0632, 0.0873, 0.1168, 0.0955, 0.0529, 0.0939, 0.0615, 0.0656, 0.0735,
        0.0551, 0.0799, 0.1001, 0.0548], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,983][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.0016, 0.0385, 0.0613, 0.0559, 0.0599, 0.0769, 0.0937, 0.1026, 0.0950,
        0.1381, 0.1251, 0.0888, 0.0626], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,984][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([9.9540e-01, 1.8820e-03, 2.1531e-03, 2.6287e-04, 1.2013e-04, 2.2037e-05,
        9.4643e-06, 2.0639e-06, 3.2107e-06, 1.8872e-05, 1.2682e-05, 4.6911e-05,
        7.0744e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,985][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.2905, 0.0505, 0.0430, 0.0713, 0.0367, 0.1556, 0.0555, 0.0675, 0.0642,
        0.0657, 0.0309, 0.0404, 0.0281], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,987][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0062, 0.0673, 0.0676, 0.0657, 0.0949, 0.0721, 0.0694, 0.0887, 0.0700,
        0.0951, 0.0979, 0.0904, 0.1148], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,989][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0741, 0.0710, 0.0604, 0.0437, 0.0916, 0.0884, 0.0705, 0.0726, 0.0805,
        0.0712, 0.0852, 0.0691, 0.1218], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,993][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.7144, 0.0249, 0.0023, 0.0421, 0.0068, 0.0047, 0.0356, 0.0031, 0.0050,
        0.0664, 0.0018, 0.0294, 0.0633], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,998][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0311, 0.0953, 0.0943, 0.0694, 0.0907, 0.0813, 0.0633, 0.0757, 0.0837,
        0.0587, 0.0899, 0.0919, 0.0746], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:34,999][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2502, 0.1104, 0.0506, 0.0224, 0.0706, 0.0625, 0.0586, 0.0598, 0.0745,
        0.0389, 0.0587, 0.0603, 0.0358, 0.0466], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:35,000][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1134, 0.0658, 0.0816, 0.0578, 0.0614, 0.0652, 0.0592, 0.0644, 0.0662,
        0.0607, 0.0761, 0.0650, 0.0742, 0.0889], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:35,001][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1070, 0.1774, 0.1031, 0.0472, 0.0285, 0.0150, 0.0188, 0.0340, 0.0728,
        0.0811, 0.0322, 0.1576, 0.0950, 0.0303], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:35,003][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.7613, 0.0242, 0.0193, 0.0210, 0.0183, 0.0224, 0.0183, 0.0135, 0.0214,
        0.0162, 0.0153, 0.0137, 0.0152, 0.0199], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:35,005][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0312, 0.0827, 0.0719, 0.0921, 0.0656, 0.0688, 0.0757, 0.0457, 0.0721,
        0.0634, 0.0735, 0.1224, 0.0855, 0.0495], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:35,009][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0011, 0.0308, 0.0505, 0.0558, 0.0532, 0.0706, 0.0878, 0.0812, 0.1020,
        0.1226, 0.1230, 0.0743, 0.0824, 0.0646], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:35,012][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([9.9579e-01, 1.7046e-03, 1.6096e-03, 3.6517e-04, 1.4206e-04, 3.0355e-05,
        1.5286e-05, 2.6268e-06, 3.3794e-06, 2.2396e-05, 1.3310e-05, 5.4596e-05,
        1.3788e-04, 1.0418e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:35,014][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.2683, 0.0556, 0.0348, 0.0548, 0.0673, 0.1013, 0.0648, 0.0600, 0.0592,
        0.0790, 0.0318, 0.0434, 0.0516, 0.0282], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:35,015][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0063, 0.0618, 0.0639, 0.0602, 0.0863, 0.0667, 0.0618, 0.0804, 0.0655,
        0.0840, 0.0895, 0.0823, 0.1042, 0.0871], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:35,016][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0508, 0.0603, 0.0664, 0.0456, 0.0847, 0.0779, 0.0654, 0.0670, 0.0779,
        0.0701, 0.0802, 0.0609, 0.1228, 0.0700], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:35,017][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([7.0811e-01, 7.3813e-03, 1.4603e-03, 2.6715e-02, 2.0773e-03, 2.3434e-03,
        4.8580e-02, 2.3230e-03, 2.9334e-03, 1.8948e-01, 1.2244e-03, 3.8344e-03,
        3.1527e-03, 3.8445e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:35,020][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0281, 0.0855, 0.0935, 0.0616, 0.0817, 0.0791, 0.0561, 0.0720, 0.0784,
        0.0563, 0.0880, 0.0785, 0.0596, 0.0816], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:35,023][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.1559, 0.1335, 0.0750, 0.0305, 0.0645, 0.0649, 0.0467, 0.0714, 0.0635,
        0.0397, 0.0717, 0.0738, 0.0277, 0.0507, 0.0305], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:35,027][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.1081, 0.0619, 0.0758, 0.0535, 0.0573, 0.0608, 0.0555, 0.0598, 0.0608,
        0.0563, 0.0704, 0.0607, 0.0694, 0.0828, 0.0670], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:35,032][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0389, 0.1401, 0.1496, 0.0382, 0.0183, 0.0195, 0.0125, 0.0348, 0.0970,
        0.0778, 0.0633, 0.1517, 0.0854, 0.0499, 0.0229], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:35,032][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.7931, 0.0198, 0.0156, 0.0174, 0.0152, 0.0187, 0.0147, 0.0109, 0.0177,
        0.0131, 0.0126, 0.0113, 0.0124, 0.0168, 0.0107], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:35,033][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0387, 0.0755, 0.0881, 0.0853, 0.0479, 0.0778, 0.0662, 0.0566, 0.0717,
        0.0470, 0.0775, 0.0998, 0.0681, 0.0556, 0.0441], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:35,035][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0019, 0.0385, 0.0497, 0.0642, 0.0496, 0.0612, 0.0803, 0.0922, 0.0866,
        0.1140, 0.0995, 0.0716, 0.0670, 0.0673, 0.0566], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:35,038][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ give] are: tensor([9.8472e-01, 6.4104e-03, 5.7166e-03, 1.3664e-03, 4.4869e-04, 9.2386e-05,
        4.7533e-05, 8.9937e-06, 1.2575e-05, 7.6062e-05, 3.6657e-05, 2.1614e-04,
        2.9283e-04, 4.9338e-04, 6.1442e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:35,042][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.2751, 0.0532, 0.0352, 0.0478, 0.0457, 0.1083, 0.0532, 0.0648, 0.0518,
        0.0594, 0.0379, 0.0451, 0.0322, 0.0303, 0.0600], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:35,045][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0052, 0.0590, 0.0568, 0.0551, 0.0782, 0.0602, 0.0592, 0.0753, 0.0596,
        0.0795, 0.0826, 0.0769, 0.0943, 0.0799, 0.0782], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:35,047][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0625, 0.0681, 0.0566, 0.0438, 0.0784, 0.0742, 0.0493, 0.0591, 0.0679,
        0.0578, 0.0690, 0.0602, 0.1281, 0.0667, 0.0584], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:35,048][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ give] are: tensor([7.2779e-01, 1.3832e-02, 2.3056e-03, 2.1751e-02, 1.4805e-03, 3.7584e-03,
        1.6330e-01, 3.2013e-03, 4.6597e-03, 2.5089e-02, 3.3913e-03, 7.8908e-03,
        1.7558e-02, 7.0032e-04, 3.2978e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:35,049][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0257, 0.0808, 0.0866, 0.0597, 0.0756, 0.0720, 0.0540, 0.0651, 0.0738,
        0.0514, 0.0822, 0.0773, 0.0549, 0.0723, 0.0688], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:35,050][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.1907, 0.0848, 0.0570, 0.0291, 0.0666, 0.0606, 0.0594, 0.0717, 0.0550,
        0.0400, 0.0720, 0.0599, 0.0232, 0.0448, 0.0388, 0.0463],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:35,052][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ it] are: tensor([0.1017, 0.0578, 0.0704, 0.0498, 0.0530, 0.0567, 0.0515, 0.0555, 0.0571,
        0.0525, 0.0652, 0.0562, 0.0644, 0.0767, 0.0617, 0.0697],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:35,056][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.0843, 0.1120, 0.1395, 0.0706, 0.0312, 0.0162, 0.0095, 0.0258, 0.0524,
        0.0688, 0.0372, 0.0898, 0.0937, 0.0756, 0.0313, 0.0622],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:35,059][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ it] are: tensor([0.7755, 0.0203, 0.0162, 0.0177, 0.0161, 0.0193, 0.0153, 0.0111, 0.0178,
        0.0134, 0.0126, 0.0112, 0.0126, 0.0172, 0.0111, 0.0125],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:35,063][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.0441, 0.0827, 0.0750, 0.0691, 0.0567, 0.0614, 0.0558, 0.0532, 0.0527,
        0.0541, 0.0702, 0.1009, 0.0704, 0.0614, 0.0493, 0.0430],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:35,064][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ it] are: tensor([0.0009, 0.0238, 0.0449, 0.0437, 0.0460, 0.0515, 0.0758, 0.0841, 0.0675,
        0.1192, 0.1040, 0.0597, 0.0602, 0.0707, 0.0868, 0.0614],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:35,065][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ it] are: tensor([9.8094e-01, 6.5672e-03, 5.2917e-03, 2.2049e-03, 1.0732e-03, 3.4283e-04,
        1.3106e-04, 3.1634e-05, 6.2777e-05, 2.7323e-04, 1.4817e-04, 5.6749e-04,
        1.0635e-03, 7.5929e-04, 2.8981e-04, 2.5416e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:35,067][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.2528, 0.0523, 0.0320, 0.0441, 0.0430, 0.0752, 0.0470, 0.0529, 0.0508,
        0.0542, 0.0349, 0.0396, 0.0415, 0.0301, 0.0875, 0.0623],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:35,070][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.0051, 0.0525, 0.0545, 0.0508, 0.0745, 0.0567, 0.0544, 0.0695, 0.0554,
        0.0730, 0.0768, 0.0699, 0.0898, 0.0744, 0.0741, 0.0684],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:35,074][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ it] are: tensor([0.0544, 0.0522, 0.0540, 0.0329, 0.0713, 0.0686, 0.0602, 0.0521, 0.0674,
        0.0637, 0.0727, 0.0517, 0.1215, 0.0603, 0.0634, 0.0534],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:35,078][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.8222, 0.0084, 0.0042, 0.0296, 0.0037, 0.0061, 0.0307, 0.0050, 0.0033,
        0.0540, 0.0025, 0.0049, 0.0183, 0.0009, 0.0013, 0.0050],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:35,079][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ it] are: tensor([0.0274, 0.0794, 0.0782, 0.0531, 0.0696, 0.0645, 0.0477, 0.0598, 0.0713,
        0.0485, 0.0725, 0.0725, 0.0527, 0.0664, 0.0592, 0.0773],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:35,080][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1900, 0.0924, 0.0425, 0.0186, 0.0586, 0.0540, 0.0557, 0.0529, 0.0662,
        0.0362, 0.0564, 0.0539, 0.0303, 0.0405, 0.0375, 0.0730, 0.0412],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:35,081][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0910, 0.0530, 0.0657, 0.0465, 0.0495, 0.0530, 0.0480, 0.0523, 0.0539,
        0.0493, 0.0614, 0.0523, 0.0597, 0.0715, 0.0575, 0.0643, 0.0710],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:35,083][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0743, 0.1716, 0.0843, 0.0381, 0.0224, 0.0129, 0.0124, 0.0222, 0.0643,
        0.0613, 0.0265, 0.1299, 0.0594, 0.0221, 0.0247, 0.1465, 0.0272],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:35,086][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.7129, 0.0233, 0.0193, 0.0203, 0.0181, 0.0219, 0.0179, 0.0134, 0.0213,
        0.0164, 0.0157, 0.0137, 0.0154, 0.0203, 0.0138, 0.0157, 0.0207],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:35,090][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0232, 0.0656, 0.0598, 0.0782, 0.0575, 0.0607, 0.0678, 0.0397, 0.0634,
        0.0532, 0.0650, 0.0995, 0.0754, 0.0431, 0.0540, 0.0593, 0.0347],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:35,094][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0009, 0.0256, 0.0410, 0.0455, 0.0429, 0.0560, 0.0702, 0.0639, 0.0803,
        0.0962, 0.0958, 0.0594, 0.0656, 0.0505, 0.0718, 0.0808, 0.0537],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:35,095][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([9.9763e-01, 9.3757e-04, 8.3969e-04, 1.8441e-04, 8.4438e-05, 2.1787e-05,
        7.2250e-06, 1.5746e-06, 2.5441e-06, 1.1680e-05, 7.7461e-06, 3.0650e-05,
        7.6956e-05, 5.9946e-05, 2.0852e-05, 2.6546e-05, 5.2918e-05],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:35,096][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1992, 0.0394, 0.0282, 0.0419, 0.0558, 0.0944, 0.0497, 0.0551, 0.0528,
        0.0623, 0.0323, 0.0310, 0.0442, 0.0255, 0.1155, 0.0474, 0.0254],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:35,098][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0051, 0.0500, 0.0515, 0.0480, 0.0689, 0.0535, 0.0500, 0.0644, 0.0529,
        0.0676, 0.0722, 0.0662, 0.0830, 0.0695, 0.0682, 0.0647, 0.0643],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:35,101][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0434, 0.0493, 0.0568, 0.0373, 0.0674, 0.0640, 0.0559, 0.0550, 0.0637,
        0.0571, 0.0680, 0.0507, 0.0977, 0.0587, 0.0591, 0.0608, 0.0550],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:35,103][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([6.8299e-01, 9.2402e-03, 2.2835e-03, 2.6692e-02, 2.3460e-03, 3.7033e-03,
        4.5059e-02, 3.0873e-03, 4.6884e-03, 2.0144e-01, 2.0350e-03, 5.2669e-03,
        4.5080e-03, 5.6896e-04, 9.8603e-04, 4.1615e-03, 9.5034e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:35,107][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0238, 0.0689, 0.0761, 0.0499, 0.0666, 0.0640, 0.0455, 0.0586, 0.0635,
        0.0462, 0.0718, 0.0629, 0.0480, 0.0662, 0.0566, 0.0637, 0.0676],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:35,175][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:35,176][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:35,177][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:35,178][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:35,178][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:35,179][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:35,180][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:35,181][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:35,181][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:35,182][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:35,183][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:35,183][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:35,184][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:35,185][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Sara] are: tensor([0.8285, 0.1715], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:35,185][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Sara] are: tensor([0.0775, 0.9225], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:35,186][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Sara] are: tensor([0.5115, 0.4885], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:35,189][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Sara] are: tensor([0.3838, 0.6162], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:35,189][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Sara] are: tensor([0.6746, 0.3254], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:35,190][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Sara] are: tensor([0.5307, 0.4693], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:35,193][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Sara] are: tensor([0.7246, 0.2754], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:35,195][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Sara] are: tensor([0.8341, 0.1659], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:35,196][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Sara] are: tensor([0.6103, 0.3897], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:35,197][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Sara] are: tensor([0.9764, 0.0236], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:35,198][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Sara] are: tensor([0.8096, 0.1904], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:35,199][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Sara] are: tensor([0.7449, 0.2551], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:35,201][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9071, 0.0563, 0.0366], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:35,204][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.3242, 0.4893, 0.1865], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:35,208][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2054, 0.6995, 0.0951], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:35,211][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1132, 0.3514, 0.5353], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:35,212][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3938, 0.1930, 0.4132], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:35,212][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3410, 0.4575, 0.2014], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:35,213][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.4782, 0.1327, 0.3891], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:35,215][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.5063, 0.0683, 0.4254], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:35,218][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.4858, 0.3457, 0.1685], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:35,222][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.9292, 0.0359, 0.0349], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:35,226][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.8029, 0.1083, 0.0888], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:35,226][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.6777, 0.0687, 0.2536], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:35,227][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Kenneth] are: tensor([0.8564, 0.0359, 0.0725, 0.0351], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:35,228][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Kenneth] are: tensor([0.3641, 0.1156, 0.3934, 0.1269], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:35,229][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Kenneth] are: tensor([0.2235, 0.1858, 0.1674, 0.4233], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:35,231][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Kenneth] are: tensor([0.0691, 0.1238, 0.3213, 0.4858], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:35,233][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Kenneth] are: tensor([0.1657, 0.1519, 0.4690, 0.2134], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:35,237][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Kenneth] are: tensor([0.6339, 0.0744, 0.1535, 0.1381], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:35,241][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Kenneth] are: tensor([0.3068, 0.2455, 0.3620, 0.0856], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:35,242][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Kenneth] are: tensor([0.5208, 0.1024, 0.2677, 0.1091], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:35,243][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Kenneth] are: tensor([0.3777, 0.0884, 0.2854, 0.2484], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:35,244][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Kenneth] are: tensor([0.9146, 0.0492, 0.0216, 0.0145], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:35,246][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Kenneth] are: tensor([0.8814, 0.0301, 0.0384, 0.0501], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:35,248][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Kenneth] are: tensor([0.7522, 0.0704, 0.1315, 0.0458], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:35,249][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.8507, 0.0307, 0.0197, 0.0349, 0.0640], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:35,251][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.3803, 0.3073, 0.0722, 0.1496, 0.0906], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:35,255][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.0940, 0.3266, 0.0746, 0.3965, 0.1083], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:35,259][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.0370, 0.0904, 0.2060, 0.3846, 0.2821], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:35,259][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.1645, 0.0628, 0.1933, 0.2198, 0.3596], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:35,260][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.1811, 0.3144, 0.0981, 0.3363, 0.0701], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:35,261][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.1688, 0.0735, 0.3048, 0.1511, 0.3018], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:35,263][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.2966, 0.0361, 0.1500, 0.1137, 0.4036], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:35,265][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.3314, 0.1668, 0.0680, 0.2778, 0.1560], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:35,270][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.8663, 0.0335, 0.0237, 0.0367, 0.0398], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:35,274][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.8177, 0.0554, 0.0518, 0.0384, 0.0367], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:35,274][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.7007, 0.0709, 0.1201, 0.0267, 0.0816], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:35,275][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.7572, 0.0463, 0.0416, 0.0329, 0.0982, 0.0238], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:35,276][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1772, 0.2956, 0.0958, 0.1915, 0.1964, 0.0436], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:35,278][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0473, 0.2119, 0.0556, 0.4788, 0.1281, 0.0783], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:35,281][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0193, 0.0671, 0.1353, 0.3978, 0.3138, 0.0667], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:35,285][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0447, 0.0627, 0.0777, 0.2814, 0.4374, 0.0962], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:35,289][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1470, 0.1820, 0.1836, 0.2390, 0.1771, 0.0714], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:35,290][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0820, 0.0396, 0.1205, 0.0786, 0.5767, 0.1026], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:35,291][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0902, 0.0298, 0.0947, 0.1094, 0.5708, 0.1050], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:35,291][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1123, 0.1250, 0.1115, 0.2063, 0.3759, 0.0689], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:35,292][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.8589, 0.0343, 0.0211, 0.0250, 0.0334, 0.0273], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:35,294][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.6980, 0.0768, 0.0630, 0.0735, 0.0531, 0.0356], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:35,297][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.5436, 0.0890, 0.1230, 0.0353, 0.0481, 0.1610], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:35,301][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.6473, 0.0849, 0.0321, 0.0482, 0.0652, 0.0275, 0.0948],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:35,305][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.0495, 0.2349, 0.1964, 0.1360, 0.1017, 0.0583, 0.2233],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:35,306][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.0240, 0.2013, 0.0494, 0.3753, 0.1513, 0.1283, 0.0704],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:35,307][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.0115, 0.0734, 0.1336, 0.2953, 0.3176, 0.0917, 0.0770],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:35,307][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.0179, 0.0486, 0.0980, 0.2104, 0.3857, 0.1373, 0.1020],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:35,309][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.1876, 0.2361, 0.0804, 0.2056, 0.0707, 0.0648, 0.1548],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:35,312][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.0649, 0.0277, 0.0743, 0.0416, 0.4189, 0.1766, 0.1960],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:35,316][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.0496, 0.0170, 0.0694, 0.0510, 0.5785, 0.1216, 0.1128],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:35,321][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.0869, 0.1225, 0.0799, 0.2041, 0.2367, 0.1088, 0.1611],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:35,321][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.8706, 0.0352, 0.0116, 0.0133, 0.0246, 0.0241, 0.0207],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:35,322][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.6465, 0.0312, 0.0531, 0.0361, 0.0555, 0.0336, 0.1440],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:35,323][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.4431, 0.1062, 0.1122, 0.0396, 0.0364, 0.1032, 0.1592],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:35,324][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.7087, 0.0482, 0.0216, 0.0270, 0.0606, 0.0220, 0.0922, 0.0198],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:35,326][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.3009, 0.3510, 0.0422, 0.0689, 0.0743, 0.0313, 0.1200, 0.0112],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:35,330][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0430, 0.1814, 0.0361, 0.2571, 0.1747, 0.1258, 0.1362, 0.0456],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:35,333][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0127, 0.0434, 0.1061, 0.3030, 0.2709, 0.0569, 0.1042, 0.1028],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:35,337][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0294, 0.0241, 0.0417, 0.1598, 0.3679, 0.1286, 0.1272, 0.1214],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:35,338][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.1193, 0.1795, 0.1202, 0.1495, 0.1605, 0.0782, 0.1400, 0.0528],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:35,339][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.1480, 0.0166, 0.0513, 0.0259, 0.3935, 0.0804, 0.2509, 0.0334],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:35,339][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0790, 0.0236, 0.0596, 0.0652, 0.5106, 0.0756, 0.1217, 0.0648],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:35,342][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.1189, 0.1626, 0.0911, 0.1557, 0.2587, 0.0923, 0.0821, 0.0385],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:35,345][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.8519, 0.0193, 0.0141, 0.0200, 0.0201, 0.0242, 0.0347, 0.0157],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:35,348][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.7644, 0.0299, 0.0301, 0.0209, 0.0453, 0.0283, 0.0580, 0.0231],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:35,352][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.5721, 0.0619, 0.1075, 0.0252, 0.0372, 0.0857, 0.0488, 0.0615],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:35,353][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.7926, 0.0516, 0.0168, 0.0270, 0.0470, 0.0072, 0.0369, 0.0128, 0.0082],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:35,354][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.2279, 0.3827, 0.0308, 0.1192, 0.0587, 0.0125, 0.1270, 0.0149, 0.0265],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:35,355][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1091, 0.0962, 0.0366, 0.2136, 0.1084, 0.0887, 0.0806, 0.1025, 0.1644],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:35,357][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0234, 0.0473, 0.0841, 0.2327, 0.2366, 0.0489, 0.1000, 0.1130, 0.1141],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:35,360][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0817, 0.0193, 0.0472, 0.0943, 0.2428, 0.0865, 0.0710, 0.2385, 0.1186],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:35,364][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1554, 0.1795, 0.1096, 0.1626, 0.1086, 0.0436, 0.1289, 0.0779, 0.0339],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:35,368][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.1985, 0.0200, 0.0680, 0.0252, 0.2767, 0.0619, 0.1629, 0.1139, 0.0728],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:35,369][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1048, 0.0166, 0.0656, 0.0479, 0.3082, 0.0759, 0.1125, 0.1849, 0.0836],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:35,370][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1039, 0.1397, 0.0747, 0.1965, 0.2196, 0.0583, 0.0848, 0.0709, 0.0517],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:35,370][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.8808, 0.0180, 0.0122, 0.0152, 0.0159, 0.0155, 0.0229, 0.0100, 0.0095],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:35,372][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.8194, 0.0243, 0.0290, 0.0283, 0.0325, 0.0159, 0.0251, 0.0127, 0.0128],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:35,375][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.5343, 0.0651, 0.0885, 0.0200, 0.0243, 0.1000, 0.0514, 0.0228, 0.0936],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:35,379][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ garden] are: tensor([0.7858, 0.0319, 0.0151, 0.0282, 0.0501, 0.0141, 0.0375, 0.0150, 0.0157,
        0.0066], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:35,383][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ garden] are: tensor([0.3750, 0.1551, 0.0986, 0.0571, 0.0756, 0.0259, 0.0929, 0.0229, 0.0610,
        0.0359], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:35,384][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ garden] are: tensor([0.0661, 0.1018, 0.0557, 0.1868, 0.0998, 0.0895, 0.0769, 0.0673, 0.1996,
        0.0564], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:35,385][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ garden] are: tensor([0.0141, 0.0472, 0.0857, 0.1864, 0.1892, 0.0535, 0.0724, 0.0928, 0.1317,
        0.1270], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:35,386][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ garden] are: tensor([0.0454, 0.0164, 0.0455, 0.0584, 0.1440, 0.0764, 0.0706, 0.1622, 0.2548,
        0.1264], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:35,388][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ garden] are: tensor([0.2359, 0.1082, 0.1147, 0.1320, 0.1292, 0.0689, 0.0813, 0.0606, 0.0504,
        0.0187], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:35,391][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ garden] are: tensor([0.1334, 0.0160, 0.0465, 0.0186, 0.1590, 0.0972, 0.1084, 0.1343, 0.2156,
        0.0711], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:35,395][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ garden] are: tensor([0.0619, 0.0286, 0.0641, 0.0503, 0.2609, 0.0519, 0.1492, 0.1307, 0.0900,
        0.1123], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:35,399][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ garden] are: tensor([0.1016, 0.0638, 0.0778, 0.1419, 0.2317, 0.0786, 0.0831, 0.0534, 0.1291,
        0.0389], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:35,400][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ garden] are: tensor([0.8722, 0.0215, 0.0108, 0.0181, 0.0118, 0.0134, 0.0285, 0.0080, 0.0106,
        0.0051], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:35,401][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ garden] are: tensor([0.7783, 0.0134, 0.0377, 0.0274, 0.0513, 0.0164, 0.0131, 0.0135, 0.0108,
        0.0382], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:35,402][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ garden] are: tensor([0.4869, 0.0904, 0.1058, 0.0402, 0.0405, 0.0717, 0.0412, 0.0301, 0.0592,
        0.0339], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:35,404][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.8332, 0.0247, 0.0044, 0.0286, 0.0262, 0.0101, 0.0313, 0.0153, 0.0120,
        0.0068, 0.0075], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:35,408][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.3712, 0.1697, 0.0201, 0.1062, 0.0390, 0.0221, 0.1165, 0.0239, 0.0605,
        0.0412, 0.0295], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:35,411][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1153, 0.0672, 0.0200, 0.1172, 0.0749, 0.0642, 0.0485, 0.0571, 0.1942,
        0.0811, 0.1602], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:35,415][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0222, 0.0273, 0.0398, 0.1134, 0.1092, 0.0283, 0.0533, 0.0526, 0.0789,
        0.1094, 0.3655], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:35,416][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0634, 0.0100, 0.0295, 0.0310, 0.1218, 0.0755, 0.0345, 0.0961, 0.1263,
        0.0723, 0.3396], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:35,417][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1307, 0.0543, 0.1105, 0.1139, 0.1129, 0.0563, 0.0886, 0.1145, 0.0659,
        0.0810, 0.0715], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:35,418][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3542, 0.0089, 0.0306, 0.0144, 0.1741, 0.0797, 0.0945, 0.0318, 0.0580,
        0.0525, 0.1014], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:35,420][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1319, 0.0051, 0.0717, 0.0259, 0.1726, 0.0631, 0.0760, 0.0821, 0.0471,
        0.0588, 0.2658], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:35,422][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1509, 0.0640, 0.0396, 0.1142, 0.1902, 0.0643, 0.0545, 0.0826, 0.0959,
        0.0464, 0.0974], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:35,426][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.8561, 0.0138, 0.0127, 0.0181, 0.0170, 0.0157, 0.0169, 0.0120, 0.0104,
        0.0168, 0.0106], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:35,431][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.8158, 0.0144, 0.0251, 0.0206, 0.0296, 0.0136, 0.0182, 0.0139, 0.0107,
        0.0105, 0.0276], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:35,432][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.5031, 0.0421, 0.0974, 0.0165, 0.0269, 0.0810, 0.0494, 0.0269, 0.0495,
        0.0191, 0.0881], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:35,433][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Sara] are: tensor([0.7190, 0.0339, 0.0288, 0.0332, 0.0605, 0.0196, 0.0476, 0.0130, 0.0117,
        0.0084, 0.0132, 0.0111], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:35,433][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Sara] are: tensor([0.2636, 0.2531, 0.0909, 0.1694, 0.0704, 0.0190, 0.0518, 0.0139, 0.0154,
        0.0246, 0.0198, 0.0083], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:35,436][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Sara] are: tensor([0.1400, 0.0391, 0.0249, 0.1029, 0.0764, 0.0428, 0.0399, 0.0427, 0.0790,
        0.0485, 0.1365, 0.2274], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:35,439][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Sara] are: tensor([0.0155, 0.0170, 0.0398, 0.0825, 0.0815, 0.0191, 0.0307, 0.0368, 0.0551,
        0.0938, 0.3200, 0.2081], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:35,442][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Sara] are: tensor([0.0419, 0.0059, 0.0206, 0.0231, 0.0794, 0.0337, 0.0334, 0.0602, 0.0681,
        0.0774, 0.3726, 0.1837], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:35,446][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Sara] are: tensor([0.1670, 0.1023, 0.0623, 0.2807, 0.0671, 0.0349, 0.0899, 0.0334, 0.0464,
        0.0567, 0.0388, 0.0204], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:35,447][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Sara] are: tensor([0.2194, 0.0052, 0.0257, 0.0111, 0.0728, 0.0673, 0.0607, 0.0450, 0.1206,
        0.0556, 0.2636, 0.0530], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:35,448][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Sara] are: tensor([0.1999, 0.0094, 0.0334, 0.0186, 0.1432, 0.0454, 0.0788, 0.0696, 0.0369,
        0.0519, 0.2292, 0.0838], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:35,449][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Sara] are: tensor([0.1503, 0.0389, 0.0568, 0.1641, 0.1529, 0.0587, 0.0583, 0.0440, 0.0603,
        0.0444, 0.1101, 0.0614], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:35,451][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Sara] are: tensor([0.8156, 0.0099, 0.0127, 0.0365, 0.0229, 0.0172, 0.0245, 0.0085, 0.0123,
        0.0223, 0.0104, 0.0072], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:35,454][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Sara] are: tensor([0.7172, 0.0573, 0.0302, 0.0206, 0.0381, 0.0192, 0.0292, 0.0121, 0.0123,
        0.0088, 0.0192, 0.0357], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:35,458][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Sara] are: tensor([0.5091, 0.0472, 0.0818, 0.0170, 0.0260, 0.0708, 0.0477, 0.0195, 0.0612,
        0.0229, 0.0632, 0.0336], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:35,462][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.4081, 0.0658, 0.0254, 0.0379, 0.0669, 0.0359, 0.1098, 0.0468, 0.0382,
        0.0254, 0.0495, 0.0329, 0.0573], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:35,463][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.0448, 0.1923, 0.0567, 0.0841, 0.1506, 0.0283, 0.0875, 0.0246, 0.0327,
        0.0319, 0.0490, 0.0298, 0.1877], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:35,464][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0217, 0.0307, 0.0097, 0.0638, 0.0290, 0.0328, 0.0213, 0.0366, 0.1081,
        0.0337, 0.1446, 0.3392, 0.1289], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:35,466][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.0092, 0.0121, 0.0222, 0.0539, 0.0589, 0.0194, 0.0217, 0.0276, 0.0685,
        0.0552, 0.2816, 0.2025, 0.1670], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:35,469][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0271, 0.0042, 0.0147, 0.0174, 0.0332, 0.0283, 0.0220, 0.0362, 0.0595,
        0.0361, 0.2735, 0.1419, 0.3059], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:35,473][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.1439, 0.1375, 0.0373, 0.0638, 0.1403, 0.0458, 0.0763, 0.0348, 0.0256,
        0.0563, 0.0380, 0.0532, 0.1471], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:35,477][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0949, 0.0062, 0.0443, 0.0075, 0.1591, 0.0429, 0.0328, 0.0250, 0.0421,
        0.0290, 0.1218, 0.0346, 0.3597], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:35,478][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.1030, 0.0028, 0.0251, 0.0120, 0.0827, 0.0205, 0.0431, 0.0432, 0.0227,
        0.0355, 0.1769, 0.0392, 0.3933], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:35,479][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0966, 0.0483, 0.0141, 0.0379, 0.1202, 0.0393, 0.0364, 0.0401, 0.0581,
        0.0275, 0.1299, 0.1302, 0.2213], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:35,480][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.7763, 0.0177, 0.0125, 0.0196, 0.0246, 0.0201, 0.0266, 0.0143, 0.0131,
        0.0155, 0.0154, 0.0179, 0.0264], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:35,482][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.7127, 0.0180, 0.0349, 0.0183, 0.0405, 0.0240, 0.0158, 0.0181, 0.0142,
        0.0067, 0.0355, 0.0124, 0.0488], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:35,485][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.4546, 0.0430, 0.1019, 0.0205, 0.0571, 0.0836, 0.0229, 0.0252, 0.0424,
        0.0095, 0.0494, 0.0303, 0.0595], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:35,489][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.7783, 0.0204, 0.0076, 0.0145, 0.0290, 0.0143, 0.0275, 0.0067, 0.0157,
        0.0047, 0.0122, 0.0120, 0.0494, 0.0076], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:35,493][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1768, 0.1116, 0.0227, 0.0696, 0.0725, 0.0261, 0.0893, 0.0077, 0.0511,
        0.0335, 0.0333, 0.0256, 0.2578, 0.0222], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:35,494][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1355, 0.0276, 0.0051, 0.0399, 0.0236, 0.0270, 0.0188, 0.0218, 0.0866,
        0.0269, 0.0706, 0.2086, 0.2162, 0.0918], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:35,495][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0210, 0.0109, 0.0170, 0.0514, 0.0376, 0.0135, 0.0231, 0.0209, 0.0392,
        0.0386, 0.1830, 0.1386, 0.1848, 0.2204], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:35,497][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0426, 0.0018, 0.0059, 0.0059, 0.0344, 0.0157, 0.0090, 0.0140, 0.0203,
        0.0101, 0.0889, 0.0358, 0.3165, 0.3992], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:35,501][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1807, 0.0816, 0.0473, 0.0603, 0.1003, 0.0442, 0.0592, 0.0323, 0.0577,
        0.0404, 0.0481, 0.0363, 0.1715, 0.0403], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:35,504][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0876, 0.0016, 0.0091, 0.0036, 0.0729, 0.0160, 0.0231, 0.0108, 0.0131,
        0.0099, 0.0379, 0.0126, 0.5255, 0.1762], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:35,508][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0434, 0.0016, 0.0140, 0.0048, 0.0709, 0.0106, 0.0128, 0.0207, 0.0145,
        0.0114, 0.1057, 0.0242, 0.3135, 0.3519], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:35,510][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1300, 0.0218, 0.0122, 0.0326, 0.0844, 0.0305, 0.0227, 0.0219, 0.0599,
        0.0188, 0.1128, 0.0940, 0.2316, 0.1268], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:35,511][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.8180, 0.0139, 0.0101, 0.0127, 0.0161, 0.0133, 0.0205, 0.0097, 0.0085,
        0.0102, 0.0096, 0.0124, 0.0324, 0.0126], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:35,512][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.7806, 0.0085, 0.0193, 0.0111, 0.0343, 0.0122, 0.0074, 0.0130, 0.0066,
        0.0041, 0.0182, 0.0046, 0.0461, 0.0339], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:35,513][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.4860, 0.0294, 0.0889, 0.0169, 0.0361, 0.0522, 0.0186, 0.0224, 0.0253,
        0.0108, 0.0415, 0.0221, 0.0405, 0.1094], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:35,515][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.4821, 0.0562, 0.0192, 0.0315, 0.0315, 0.0233, 0.0884, 0.0404, 0.0296,
        0.0133, 0.0406, 0.0274, 0.0334, 0.0222, 0.0608], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:35,519][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0819, 0.1971, 0.0321, 0.0641, 0.0284, 0.0352, 0.1389, 0.0535, 0.0551,
        0.0567, 0.0929, 0.0500, 0.0617, 0.0260, 0.0265], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:35,522][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0780, 0.0307, 0.0057, 0.0291, 0.0129, 0.0189, 0.0116, 0.0266, 0.0514,
        0.0202, 0.0459, 0.1361, 0.0973, 0.1246, 0.3112], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:35,526][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0241, 0.0061, 0.0119, 0.0290, 0.0304, 0.0086, 0.0169, 0.0137, 0.0365,
        0.0350, 0.1123, 0.0862, 0.1508, 0.2677, 0.1708], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:35,527][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0529, 0.0028, 0.0056, 0.0070, 0.0137, 0.0083, 0.0054, 0.0092, 0.0147,
        0.0075, 0.0504, 0.0473, 0.1473, 0.3517, 0.2763], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:35,528][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.1366, 0.1331, 0.0349, 0.0922, 0.0270, 0.0282, 0.0955, 0.0752, 0.0430,
        0.0700, 0.0669, 0.0586, 0.0688, 0.0254, 0.0446], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:35,529][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0458, 0.0043, 0.0144, 0.0068, 0.0360, 0.0103, 0.0165, 0.0094, 0.0103,
        0.0128, 0.0369, 0.0181, 0.2249, 0.3582, 0.1953], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:35,531][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0720, 0.0019, 0.0111, 0.0072, 0.0336, 0.0121, 0.0108, 0.0158, 0.0100,
        0.0097, 0.0783, 0.0189, 0.1402, 0.4317, 0.1467], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:35,533][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.1774, 0.0353, 0.0088, 0.0441, 0.0200, 0.0250, 0.0278, 0.0520, 0.0559,
        0.0252, 0.1057, 0.0990, 0.0678, 0.1148, 0.1412], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:35,537][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.7432, 0.0267, 0.0101, 0.0123, 0.0159, 0.0169, 0.0244, 0.0108, 0.0108,
        0.0141, 0.0123, 0.0231, 0.0356, 0.0175, 0.0263], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:35,542][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.5111, 0.0273, 0.0332, 0.0283, 0.0209, 0.0194, 0.0519, 0.0187, 0.0180,
        0.0106, 0.0421, 0.0264, 0.0789, 0.0583, 0.0549], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:35,543][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.3629, 0.0528, 0.0600, 0.0224, 0.0277, 0.0610, 0.0533, 0.0224, 0.0391,
        0.0177, 0.0480, 0.0348, 0.0273, 0.0477, 0.1230], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:35,544][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([0.5879, 0.0313, 0.0226, 0.0403, 0.0461, 0.0212, 0.0471, 0.0331, 0.0109,
        0.0075, 0.0216, 0.0126, 0.0543, 0.0197, 0.0366, 0.0072],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:35,545][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([0.0736, 0.1645, 0.1209, 0.0988, 0.0620, 0.0230, 0.0788, 0.0476, 0.0098,
        0.0242, 0.0385, 0.0143, 0.1270, 0.0506, 0.0567, 0.0098],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:35,547][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.0764, 0.0211, 0.0063, 0.0233, 0.0177, 0.0153, 0.0089, 0.0127, 0.0346,
        0.0142, 0.0342, 0.0854, 0.0993, 0.1127, 0.3145, 0.1236],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:35,549][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([0.0096, 0.0047, 0.0107, 0.0194, 0.0286, 0.0062, 0.0142, 0.0135, 0.0255,
        0.0318, 0.1107, 0.0629, 0.1469, 0.2664, 0.1801, 0.0688],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:35,553][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.0145, 0.0014, 0.0026, 0.0040, 0.0138, 0.0054, 0.0025, 0.0077, 0.0068,
        0.0067, 0.0430, 0.0210, 0.1215, 0.3016, 0.3989, 0.0486],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:35,558][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([0.0718, 0.0413, 0.0551, 0.0641, 0.0352, 0.0220, 0.0570, 0.0797, 0.0334,
        0.0595, 0.0857, 0.0282, 0.1175, 0.0918, 0.1408, 0.0167],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:35,559][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([0.0947, 0.0025, 0.0074, 0.0022, 0.0428, 0.0102, 0.0145, 0.0121, 0.0137,
        0.0145, 0.0375, 0.0113, 0.2503, 0.1201, 0.3319, 0.0343],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:35,559][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.0369, 0.0016, 0.0101, 0.0046, 0.0456, 0.0054, 0.0068, 0.0106, 0.0071,
        0.0070, 0.0605, 0.0159, 0.0797, 0.3132, 0.3598, 0.0354],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:35,560][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.0461, 0.0180, 0.0196, 0.0258, 0.0372, 0.0179, 0.0129, 0.0374, 0.0384,
        0.0196, 0.1006, 0.0390, 0.1109, 0.1707, 0.2666, 0.0393],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:35,563][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([0.7538, 0.0168, 0.0110, 0.0099, 0.0178, 0.0150, 0.0180, 0.0109, 0.0088,
        0.0155, 0.0097, 0.0164, 0.0379, 0.0147, 0.0357, 0.0080],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:35,566][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.6495, 0.0062, 0.0129, 0.0060, 0.0181, 0.0131, 0.0298, 0.0177, 0.0161,
        0.0109, 0.0404, 0.0063, 0.0494, 0.0588, 0.0446, 0.0201],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:35,569][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([0.3950, 0.0400, 0.0396, 0.0228, 0.0141, 0.0455, 0.0318, 0.0187, 0.0347,
        0.0127, 0.0293, 0.0297, 0.0261, 0.0404, 0.0503, 0.1693],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:35,573][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.7282, 0.0229, 0.0054, 0.0148, 0.0264, 0.0158, 0.0319, 0.0075, 0.0178,
        0.0063, 0.0117, 0.0161, 0.0431, 0.0065, 0.0246, 0.0134, 0.0076],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:35,574][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1760, 0.1612, 0.0106, 0.0547, 0.0334, 0.0280, 0.1162, 0.0100, 0.0573,
        0.0434, 0.0341, 0.0309, 0.1550, 0.0088, 0.0223, 0.0333, 0.0248],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:35,575][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0967, 0.0132, 0.0021, 0.0137, 0.0100, 0.0088, 0.0060, 0.0062, 0.0275,
        0.0075, 0.0194, 0.0661, 0.0945, 0.0311, 0.3155, 0.1922, 0.0895],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:35,576][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0159, 0.0065, 0.0098, 0.0217, 0.0193, 0.0056, 0.0117, 0.0088, 0.0218,
        0.0214, 0.0885, 0.0629, 0.1053, 0.1354, 0.1579, 0.0830, 0.2244],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:35,578][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0247, 0.0011, 0.0019, 0.0022, 0.0124, 0.0058, 0.0027, 0.0042, 0.0062,
        0.0028, 0.0259, 0.0131, 0.0947, 0.1083, 0.2703, 0.1111, 0.3126],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:35,582][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1642, 0.0670, 0.0279, 0.0461, 0.0549, 0.0321, 0.0533, 0.0342, 0.0524,
        0.0408, 0.0474, 0.0386, 0.1090, 0.0226, 0.0900, 0.0798, 0.0396],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:35,585][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0491, 0.0009, 0.0033, 0.0010, 0.0389, 0.0077, 0.0102, 0.0038, 0.0064,
        0.0038, 0.0154, 0.0051, 0.2066, 0.0660, 0.3540, 0.0951, 0.1327],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:35,589][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0190, 0.0006, 0.0040, 0.0015, 0.0235, 0.0028, 0.0033, 0.0057, 0.0043,
        0.0027, 0.0313, 0.0080, 0.0767, 0.1330, 0.2296, 0.0305, 0.4234],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:35,590][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0948, 0.0134, 0.0050, 0.0139, 0.0262, 0.0123, 0.0123, 0.0111, 0.0303,
        0.0117, 0.0581, 0.0515, 0.0859, 0.0491, 0.2402, 0.1653, 0.1189],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:35,591][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.7440, 0.0133, 0.0083, 0.0114, 0.0154, 0.0130, 0.0199, 0.0099, 0.0090,
        0.0096, 0.0094, 0.0114, 0.0390, 0.0130, 0.0437, 0.0143, 0.0154],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:35,592][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.7433, 0.0076, 0.0118, 0.0073, 0.0241, 0.0087, 0.0076, 0.0097, 0.0049,
        0.0028, 0.0143, 0.0040, 0.0400, 0.0260, 0.0327, 0.0094, 0.0457],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:35,594][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.4268, 0.0220, 0.0534, 0.0078, 0.0256, 0.0449, 0.0212, 0.0166, 0.0226,
        0.0089, 0.0356, 0.0176, 0.0290, 0.0734, 0.0573, 0.0397, 0.0977],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:35,598][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:35,600][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[13491],
        [36714],
        [16394],
        [34174],
        [38349],
        [39954],
        [26416],
        [34365],
        [39367],
        [36434],
        [29834],
        [46342],
        [33544],
        [40194],
        [36772],
        [33185],
        [39580]], device='cuda:0')
[2024-07-24 10:29:35,602][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[13364],
        [38447],
        [16934],
        [33307],
        [35994],
        [39769],
        [24242],
        [33110],
        [38685],
        [36859],
        [28936],
        [47165],
        [31704],
        [40932],
        [36601],
        [31925],
        [40696]], device='cuda:0')
[2024-07-24 10:29:35,605][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[23912],
        [11298],
        [ 8878],
        [10241],
        [17147],
        [18867],
        [18323],
        [19304],
        [18918],
        [17707],
        [17115],
        [17549],
        [18044],
        [17782],
        [17341],
        [18779],
        [18497]], device='cuda:0')
[2024-07-24 10:29:35,608][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[47092],
        [47492],
        [47301],
        [47101],
        [47153],
        [47153],
        [47197],
        [47290],
        [47307],
        [47342],
        [47425],
        [47470],
        [47454],
        [47415],
        [47397],
        [47378],
        [47368]], device='cuda:0')
[2024-07-24 10:29:35,609][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 4915],
        [ 2385],
        [ 4748],
        [19184],
        [16257],
        [11605],
        [14754],
        [ 7762],
        [ 8924],
        [11899],
        [ 4609],
        [10245],
        [ 9249],
        [ 5614],
        [ 7072],
        [ 6879],
        [ 5855]], device='cuda:0')
[2024-07-24 10:29:35,611][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[29888],
        [29991],
        [30010],
        [30267],
        [30195],
        [30161],
        [30275],
        [30335],
        [30281],
        [30210],
        [30248],
        [30200],
        [30125],
        [30019],
        [30030],
        [30001],
        [29958]], device='cuda:0')
[2024-07-24 10:29:35,612][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 9653],
        [12751],
        [17439],
        [17263],
        [18188],
        [19074],
        [22715],
        [22091],
        [22610],
        [24093],
        [23945],
        [23172],
        [22798],
        [22461],
        [23098],
        [22795],
        [23255]], device='cuda:0')
[2024-07-24 10:29:35,615][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[40190],
        [41452],
        [40727],
        [43549],
        [43701],
        [42627],
        [41407],
        [40077],
        [40469],
        [40656],
        [40120],
        [40339],
        [39946],
        [40070],
        [40238],
        [39731],
        [39991]], device='cuda:0')
[2024-07-24 10:29:35,618][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[26812],
        [26520],
        [26014],
        [26734],
        [26385],
        [26273],
        [26694],
        [26498],
        [25183],
        [26573],
        [26627],
        [26670],
        [26406],
        [26428],
        [25460],
        [25014],
        [26589]], device='cuda:0')
[2024-07-24 10:29:35,620][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[4285],
        [3700],
        [3995],
        [2195],
        [2512],
        [2506],
        [2848],
        [3452],
        [3331],
        [3415],
        [3364],
        [3335],
        [3729],
        [4423],
        [4594],
        [5146],
        [5551]], device='cuda:0')
[2024-07-24 10:29:35,623][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[34112],
        [ 6219],
        [ 7622],
        [ 7825],
        [ 8826],
        [ 9626],
        [ 9290],
        [10151],
        [10467],
        [10677],
        [11076],
        [11146],
        [11538],
        [11580],
        [11586],
        [11674],
        [11490]], device='cuda:0')
[2024-07-24 10:29:35,626][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 7389],
        [12545],
        [14780],
        [17005],
        [17355],
        [16748],
        [18605],
        [19415],
        [18271],
        [19074],
        [18794],
        [18342],
        [19235],
        [19278],
        [19008],
        [18767],
        [18449]], device='cuda:0')
[2024-07-24 10:29:35,627][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[15351],
        [ 6241],
        [14642],
        [ 6328],
        [10433],
        [10508],
        [ 5219],
        [ 6914],
        [ 7863],
        [ 7765],
        [ 6843],
        [ 5139],
        [ 8398],
        [ 6665],
        [ 6014],
        [ 8358],
        [ 6911]], device='cuda:0')
[2024-07-24 10:29:35,629][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[20134],
        [31390],
        [24632],
        [34824],
        [30258],
        [29135],
        [28830],
        [28108],
        [28145],
        [29132],
        [28777],
        [30438],
        [29663],
        [29287],
        [29589],
        [28937],
        [28447]], device='cuda:0')
[2024-07-24 10:29:35,630][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[23675],
        [17906],
        [17634],
        [16881],
        [17519],
        [17788],
        [24891],
        [23161],
        [21233],
        [21958],
        [20496],
        [22864],
        [21358],
        [18439],
        [21953],
        [23578],
        [20542]], device='cuda:0')
[2024-07-24 10:29:35,633][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[30715],
        [31177],
        [31144],
        [28927],
        [26571],
        [20574],
        [21089],
        [21507],
        [25688],
        [25012],
        [28043],
        [21945],
        [19844],
        [25592],
        [20505],
        [19932],
        [23626]], device='cuda:0')
[2024-07-24 10:29:35,636][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[27205],
        [33075],
        [32048],
        [27301],
        [29344],
        [27562],
        [25977],
        [28844],
        [29282],
        [26998],
        [27133],
        [28204],
        [20278],
        [18051],
        [24052],
        [21995],
        [21538]], device='cuda:0')
[2024-07-24 10:29:35,638][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 2935],
        [21472],
        [21344],
        [12233],
        [11222],
        [11027],
        [11604],
        [11642],
        [14050],
        [14511],
        [16333],
        [12517],
        [15582],
        [17129],
        [12677],
        [12217],
        [12005]], device='cuda:0')
[2024-07-24 10:29:35,641][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[23431],
        [22794],
        [38632],
        [42634],
        [43928],
        [43759],
        [42710],
        [41933],
        [40510],
        [41343],
        [40000],
        [35234],
        [35352],
        [34796],
        [35160],
        [34967],
        [32210]], device='cuda:0')
[2024-07-24 10:29:35,644][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[25248],
        [ 8270],
        [31287],
        [26155],
        [18972],
        [14424],
        [14057],
        [11237],
        [10705],
        [11693],
        [12648],
        [ 9804],
        [10598],
        [10912],
        [ 6958],
        [ 6534],
        [ 7206]], device='cuda:0')
[2024-07-24 10:29:35,645][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[41594],
        [30862],
        [31500],
        [38597],
        [29446],
        [28468],
        [30651],
        [28880],
        [29524],
        [29515],
        [27032],
        [29086],
        [24827],
        [24424],
        [25986],
        [23341],
        [24917]], device='cuda:0')
[2024-07-24 10:29:35,647][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[37971],
        [27629],
        [27366],
        [23293],
        [26752],
        [26632],
        [24890],
        [26417],
        [32703],
        [39136],
        [32798],
        [38086],
        [32101],
        [32302],
        [31339],
        [30679],
        [31384]], device='cuda:0')
[2024-07-24 10:29:35,648][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[30547],
        [35805],
        [16036],
        [22520],
        [17099],
        [19587],
        [22998],
        [26390],
        [31547],
        [34485],
        [28526],
        [33097],
        [25548],
        [33884],
        [35809],
        [32395],
        [38349]], device='cuda:0')
[2024-07-24 10:29:35,651][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[45617],
        [44402],
        [45469],
        [39977],
        [39061],
        [39849],
        [41003],
        [40967],
        [40694],
        [42070],
        [42402],
        [41981],
        [43286],
        [42667],
        [45203],
        [44886],
        [44546]], device='cuda:0')
[2024-07-24 10:29:35,654][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[10998],
        [11274],
        [11189],
        [11561],
        [10793],
        [10100],
        [10354],
        [ 9897],
        [10077],
        [10220],
        [ 9694],
        [ 9557],
        [ 9270],
        [ 9535],
        [ 9055],
        [ 8795],
        [ 8468]], device='cuda:0')
[2024-07-24 10:29:35,656][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[34458],
        [27498],
        [34724],
        [38001],
        [37524],
        [37511],
        [41688],
        [42295],
        [41536],
        [42265],
        [42450],
        [40433],
        [41951],
        [41945],
        [38276],
        [43379],
        [42926]], device='cuda:0')
[2024-07-24 10:29:35,659][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[17421],
        [18304],
        [19263],
        [22139],
        [20016],
        [25958],
        [16886],
        [21959],
        [23317],
        [19303],
        [20992],
        [19644],
        [18131],
        [15439],
        [17100],
        [19986],
        [21545]], device='cuda:0')
[2024-07-24 10:29:35,662][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[11154],
        [17504],
        [13033],
        [14432],
        [18069],
        [19910],
        [19626],
        [18832],
        [16179],
        [13917],
        [15877],
        [18128],
        [21612],
        [20718],
        [22359],
        [21724],
        [21380]], device='cuda:0')
[2024-07-24 10:29:35,663][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[20014],
        [21007],
        [17295],
        [18949],
        [19489],
        [18853],
        [15424],
        [16951],
        [17214],
        [17153],
        [18630],
        [18307],
        [20273],
        [16247],
        [14939],
        [17646],
        [15951]], device='cuda:0')
[2024-07-24 10:29:35,665][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076]], device='cuda:0')
[2024-07-24 10:29:35,724][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:35,725][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:35,725][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:35,726][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:35,727][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:35,728][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:35,728][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:35,729][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:35,730][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:35,730][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:35,731][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:35,732][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:35,732][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:35,733][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Sara] are: tensor([0.9990, 0.0010], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:35,734][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Sara] are: tensor([0.9919, 0.0081], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:35,735][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Sara] are: tensor([0.4994, 0.5006], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:35,736][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Sara] are: tensor([9.9960e-01, 4.0422e-04], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:35,736][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Sara] are: tensor([0.0402, 0.9598], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:35,737][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Sara] are: tensor([0.8654, 0.1346], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:35,738][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Sara] are: tensor([0.1277, 0.8723], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:35,739][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Sara] are: tensor([0.5034, 0.4966], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:35,741][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Sara] are: tensor([0.9671, 0.0329], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:35,745][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Sara] are: tensor([0.0136, 0.9864], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:35,748][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Sara] are: tensor([0.0616, 0.9384], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:35,750][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Sara] are: tensor([0.9861, 0.0139], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:35,751][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([9.9960e-01, 1.5884e-04, 2.4586e-04], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:35,752][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.9372, 0.0617, 0.0010], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:35,752][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3444, 0.3420, 0.3136], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:35,753][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([9.9977e-01, 1.3925e-04, 9.0849e-05], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:35,755][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0168, 0.4672, 0.5161], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:35,758][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.7997, 0.0468, 0.1534], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:35,762][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0495, 0.5317, 0.4188], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:35,766][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3520, 0.3478, 0.3002], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:35,766][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7145, 0.2285, 0.0570], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:35,767][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0058, 0.5050, 0.4891], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:35,768][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1439, 0.6218, 0.2343], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:35,769][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.9481, 0.0240, 0.0279], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:35,770][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Kenneth] are: tensor([9.9793e-01, 5.9129e-04, 1.1623e-03, 3.1354e-04], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:35,773][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Kenneth] are: tensor([0.5518, 0.3602, 0.0573, 0.0307], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:35,777][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Kenneth] are: tensor([0.2703, 0.2618, 0.2376, 0.2303], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:35,779][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Kenneth] are: tensor([9.9964e-01, 1.4586e-04, 9.9526e-05, 1.1143e-04], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:35,782][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Kenneth] are: tensor([0.0127, 0.3005, 0.3290, 0.3579], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:35,782][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Kenneth] are: tensor([0.6770, 0.1186, 0.1132, 0.0912], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:35,783][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Kenneth] are: tensor([0.0475, 0.3886, 0.2989, 0.2651], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:35,784][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Kenneth] are: tensor([0.2334, 0.2634, 0.2591, 0.2442], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:35,786][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Kenneth] are: tensor([0.6562, 0.0730, 0.1366, 0.1342], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:35,788][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Kenneth] are: tensor([0.0041, 0.3450, 0.3449, 0.3060], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:35,792][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Kenneth] are: tensor([0.0630, 0.3752, 0.1656, 0.3961], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:35,796][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Kenneth] are: tensor([0.8863, 0.0140, 0.0782, 0.0215], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:35,797][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ got] are: tensor([9.9774e-01, 5.0052e-04, 9.8465e-04, 3.5044e-04, 4.2688e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:35,798][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.2241, 0.3221, 0.3090, 0.1174, 0.0274], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:35,799][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.2084, 0.2053, 0.1884, 0.1857, 0.2122], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:35,800][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ got] are: tensor([9.9908e-01, 2.4443e-04, 1.6132e-04, 1.9165e-04, 3.2009e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:35,802][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.0070, 0.2253, 0.2500, 0.2708, 0.2469], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:35,804][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.7537, 0.0419, 0.0847, 0.0624, 0.0574], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:35,808][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.0331, 0.3121, 0.2539, 0.1394, 0.2615], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:35,811][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.2234, 0.2027, 0.2705, 0.2030, 0.1003], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:35,813][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.4235, 0.0535, 0.1782, 0.2964, 0.0484], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:35,814][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.0032, 0.2698, 0.2567, 0.2327, 0.2376], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:35,815][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.0549, 0.2964, 0.1389, 0.2578, 0.2519], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:35,816][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.7726, 0.0176, 0.0811, 0.0318, 0.0970], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:35,817][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([9.9933e-01, 1.3955e-04, 2.6074e-04, 9.5239e-05, 1.2510e-04, 4.6197e-05],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:35,820][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.8296, 0.0288, 0.0803, 0.0306, 0.0207, 0.0100], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:35,824][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1639, 0.1663, 0.1541, 0.1531, 0.1753, 0.1873], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:35,826][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([9.9952e-01, 9.9435e-05, 6.4584e-05, 8.1053e-05, 1.4052e-04, 9.1064e-05],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:35,829][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0071, 0.1765, 0.1959, 0.2108, 0.1945, 0.2152], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:35,830][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.4721, 0.0406, 0.0966, 0.1311, 0.1556, 0.1040], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:35,830][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0300, 0.2283, 0.2491, 0.1157, 0.1971, 0.1798], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:35,831][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.2131, 0.1449, 0.1980, 0.2021, 0.1158, 0.1261], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:35,833][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2999, 0.0411, 0.1270, 0.3883, 0.1185, 0.0251], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:35,836][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0024, 0.2118, 0.2072, 0.1861, 0.1884, 0.2040], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:35,840][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0682, 0.2072, 0.1112, 0.2397, 0.1753, 0.1984], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:35,843][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.7139, 0.0070, 0.0199, 0.0219, 0.1641, 0.0733], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:35,845][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([9.9620e-01, 5.5352e-04, 1.5457e-03, 5.0471e-04, 6.9718e-04, 3.7968e-04,
        1.1789e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:35,845][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.2092, 0.0915, 0.1971, 0.0585, 0.1606, 0.1369, 0.1462],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:35,846][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.1359, 0.1412, 0.1295, 0.1280, 0.1472, 0.1581, 0.1602],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:35,847][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([9.9932e-01, 1.2487e-04, 7.7258e-05, 9.8228e-05, 1.7417e-04, 1.2213e-04,
        8.2717e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:35,849][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.0078, 0.1407, 0.1574, 0.1709, 0.1576, 0.1722, 0.1934],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:35,852][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.5618, 0.0375, 0.0496, 0.0425, 0.0588, 0.0479, 0.2019],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:35,855][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.0445, 0.2361, 0.1494, 0.1150, 0.1441, 0.1304, 0.1805],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:35,859][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.1620, 0.1610, 0.1742, 0.1756, 0.1138, 0.0985, 0.1149],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:35,861][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.3970, 0.0430, 0.1191, 0.1506, 0.1446, 0.0706, 0.0751],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:35,861][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.0021, 0.1699, 0.1681, 0.1520, 0.1558, 0.1706, 0.1816],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:35,862][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.0399, 0.1658, 0.0743, 0.1797, 0.1238, 0.1601, 0.2563],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:35,863][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.1576, 0.0047, 0.0751, 0.0198, 0.1121, 0.6195, 0.0113],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:35,864][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ at] are: tensor([9.9927e-01, 1.3803e-04, 2.3200e-04, 1.0011e-04, 1.1913e-04, 4.9947e-05,
        2.3882e-05, 6.3435e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:35,867][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.5064, 0.1726, 0.0910, 0.0206, 0.0665, 0.0297, 0.1115, 0.0017],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:35,871][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1219, 0.1234, 0.1150, 0.1132, 0.1295, 0.1373, 0.1372, 0.1225],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:35,873][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ at] are: tensor([9.9916e-01, 1.2569e-04, 7.4316e-05, 9.2586e-05, 1.6627e-04, 1.1384e-04,
        7.7018e-05, 1.8806e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:35,876][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0050, 0.1197, 0.1321, 0.1430, 0.1308, 0.1449, 0.1685, 0.1561],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:35,877][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.6559, 0.0125, 0.0323, 0.0331, 0.0380, 0.0292, 0.1473, 0.0519],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:35,878][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0294, 0.1566, 0.1597, 0.0957, 0.1218, 0.1094, 0.0929, 0.2346],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:35,879][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.1414, 0.1338, 0.1607, 0.1396, 0.0725, 0.1023, 0.1496, 0.1001],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:35,880][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.2930, 0.0257, 0.1017, 0.1358, 0.1562, 0.0509, 0.2162, 0.0205],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:35,883][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0018, 0.1509, 0.1482, 0.1323, 0.1371, 0.1453, 0.1561, 0.1282],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:35,887][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0408, 0.1044, 0.1034, 0.1377, 0.1078, 0.1396, 0.2253, 0.1410],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:35,892][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.6237, 0.0106, 0.0249, 0.0295, 0.1310, 0.0984, 0.0616, 0.0204],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:35,893][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ the] are: tensor([9.9975e-01, 4.2308e-05, 6.3395e-05, 2.4392e-05, 2.9658e-05, 1.2670e-05,
        5.0569e-06, 2.2250e-05, 4.8177e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:35,893][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.8299, 0.0305, 0.0186, 0.0119, 0.0064, 0.0104, 0.0694, 0.0034, 0.0193],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:35,894][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1071, 0.1102, 0.1023, 0.1016, 0.1150, 0.1225, 0.1246, 0.1108, 0.1059],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:35,895][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ the] are: tensor([9.9951e-01, 5.9154e-05, 3.7287e-05, 4.7653e-05, 8.4444e-05, 5.6087e-05,
        3.7350e-05, 1.1011e-04, 5.4767e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:35,897][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0049, 0.1054, 0.1164, 0.1249, 0.1143, 0.1250, 0.1421, 0.1328, 0.1342],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:35,901][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.2157, 0.0319, 0.0636, 0.0786, 0.0929, 0.0651, 0.2853, 0.1065, 0.0604],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:35,904][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0211, 0.1481, 0.1292, 0.0680, 0.1187, 0.1037, 0.0798, 0.1669, 0.1646],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:35,908][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1233, 0.1031, 0.1309, 0.1247, 0.0813, 0.0987, 0.1405, 0.1074, 0.0902],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:35,909][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.4039, 0.0165, 0.0505, 0.1616, 0.0712, 0.0211, 0.1527, 0.0832, 0.0393],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:35,910][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0016, 0.1320, 0.1304, 0.1177, 0.1181, 0.1272, 0.1370, 0.1124, 0.1235],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:35,910][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0668, 0.1132, 0.0890, 0.1149, 0.0995, 0.1002, 0.1534, 0.1407, 0.1223],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:35,913][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.7355, 0.0060, 0.0079, 0.0062, 0.0444, 0.0240, 0.1146, 0.0379, 0.0236],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:35,915][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ garden] are: tensor([9.9858e-01, 1.7761e-04, 3.4972e-04, 1.2532e-04, 1.4460e-04, 8.1017e-05,
        2.5445e-05, 1.1673e-04, 3.2262e-04, 7.3927e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:35,919][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ garden] are: tensor([0.0155, 0.1685, 0.3265, 0.0607, 0.1779, 0.0967, 0.0337, 0.0255, 0.0807,
        0.0143], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:35,922][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ garden] are: tensor([0.0959, 0.1010, 0.0917, 0.0903, 0.1042, 0.1115, 0.1128, 0.1013, 0.0974,
        0.0939], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:35,924][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ garden] are: tensor([9.9912e-01, 8.7703e-05, 5.7301e-05, 6.8295e-05, 1.3789e-04, 9.9975e-05,
        6.8320e-05, 1.9263e-04, 9.6644e-05, 7.4111e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:35,925][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ garden] are: tensor([0.0048, 0.0914, 0.1018, 0.1105, 0.1003, 0.1106, 0.1242, 0.1179, 0.1186,
        0.1200], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:35,926][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ garden] are: tensor([0.1985, 0.0205, 0.0251, 0.0428, 0.0431, 0.0468, 0.1846, 0.1158, 0.0559,
        0.2670], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:35,927][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ garden] are: tensor([0.0169, 0.1395, 0.0959, 0.0650, 0.0940, 0.0846, 0.0903, 0.1663, 0.1443,
        0.1032], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:35,929][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ garden] are: tensor([0.0991, 0.1082, 0.1490, 0.0952, 0.0804, 0.0944, 0.0710, 0.1122, 0.0945,
        0.0960], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:35,931][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ garden] are: tensor([0.5020, 0.0147, 0.0542, 0.0845, 0.0587, 0.0292, 0.0579, 0.0425, 0.1044,
        0.0519], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:35,935][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ garden] are: tensor([0.0015, 0.1177, 0.1153, 0.1027, 0.1055, 0.1141, 0.1215, 0.1020, 0.1113,
        0.1084], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:35,940][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ garden] are: tensor([0.0316, 0.0947, 0.0540, 0.1098, 0.1051, 0.1190, 0.1521, 0.1149, 0.1193,
        0.0994], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:35,941][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ garden] are: tensor([0.1119, 0.0097, 0.1128, 0.0167, 0.0751, 0.3682, 0.0120, 0.1341, 0.1511,
        0.0086], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:35,941][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([9.9976e-01, 3.2373e-05, 4.0349e-05, 1.7911e-05, 1.8117e-05, 7.7603e-06,
        3.3590e-06, 1.2604e-05, 2.7830e-05, 9.5623e-06, 6.6570e-05],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:35,942][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([8.8027e-01, 2.6271e-02, 3.6804e-03, 3.2341e-03, 1.8061e-02, 5.9425e-03,
        8.6001e-03, 1.5353e-03, 1.4816e-02, 3.6795e-02, 7.9064e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:35,944][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0900, 0.0929, 0.0852, 0.0840, 0.0953, 0.1005, 0.1006, 0.0894, 0.0873,
        0.0849, 0.0898], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:35,946][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([9.9931e-01, 6.3048e-05, 3.7749e-05, 4.5830e-05, 9.4468e-05, 6.3949e-05,
        4.1124e-05, 1.1904e-04, 5.6873e-05, 4.4260e-05, 1.2038e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:35,951][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0041, 0.0818, 0.0915, 0.0992, 0.0900, 0.0988, 0.1107, 0.1061, 0.1060,
        0.1068, 0.1051], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:35,954][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.3793, 0.0136, 0.0464, 0.0465, 0.0600, 0.0448, 0.1676, 0.0514, 0.0335,
        0.0961, 0.0608], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:35,956][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0140, 0.1167, 0.1031, 0.0488, 0.0902, 0.0793, 0.0596, 0.1461, 0.1229,
        0.0629, 0.1564], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:35,957][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1015, 0.0846, 0.0925, 0.0966, 0.0622, 0.0822, 0.0771, 0.0805, 0.0859,
        0.1334, 0.1035], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:35,958][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1954, 0.0352, 0.0294, 0.1459, 0.0673, 0.0432, 0.1378, 0.0477, 0.1411,
        0.1465, 0.0106], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:35,958][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0013, 0.1044, 0.1028, 0.0937, 0.0932, 0.1022, 0.1101, 0.0917, 0.1007,
        0.0996, 0.1002], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:35,960][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0156, 0.0648, 0.0500, 0.0929, 0.0728, 0.1000, 0.1649, 0.0767, 0.1090,
        0.0950, 0.1582], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:35,963][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.5519, 0.0031, 0.0027, 0.0037, 0.0352, 0.0558, 0.0192, 0.0107, 0.0542,
        0.1590, 0.1045], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:35,965][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Sara] are: tensor([9.9898e-01, 1.1013e-04, 1.6801e-04, 6.7742e-05, 6.3732e-05, 2.7774e-05,
        1.0898e-05, 4.1664e-05, 1.0994e-04, 3.2855e-05, 2.4271e-04, 1.4095e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:35,969][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Sara] are: tensor([0.5467, 0.0181, 0.0676, 0.0187, 0.0084, 0.0618, 0.0302, 0.0288, 0.0848,
        0.0448, 0.0718, 0.0184], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:35,972][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Sara] are: tensor([0.0817, 0.0852, 0.0783, 0.0765, 0.0883, 0.0925, 0.0934, 0.0836, 0.0809,
        0.0786, 0.0827, 0.0784], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:35,973][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Sara] are: tensor([9.9882e-01, 9.7270e-05, 6.2207e-05, 7.9996e-05, 1.3241e-04, 8.9922e-05,
        6.9235e-05, 1.5528e-04, 8.7602e-05, 7.6293e-05, 1.8752e-04, 1.3741e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:35,973][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Sara] are: tensor([0.0035, 0.0743, 0.0827, 0.0896, 0.0809, 0.0892, 0.1018, 0.0954, 0.0964,
        0.0966, 0.0958, 0.0939], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:35,974][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Sara] are: tensor([0.3896, 0.0134, 0.0307, 0.0249, 0.0351, 0.0238, 0.0926, 0.0460, 0.0231,
        0.0746, 0.0519, 0.1944], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:35,976][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Sara] are: tensor([0.0144, 0.1035, 0.0646, 0.0461, 0.0756, 0.0610, 0.0722, 0.1320, 0.1131,
        0.0816, 0.1372, 0.0987], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:35,979][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Sara] are: tensor([0.0714, 0.0638, 0.0816, 0.0830, 0.0644, 0.0752, 0.0638, 0.0840, 0.0861,
        0.0946, 0.1227, 0.1095], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:35,983][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Sara] are: tensor([0.2981, 0.0035, 0.0633, 0.1447, 0.1116, 0.0316, 0.0452, 0.0599, 0.0704,
        0.0786, 0.0640, 0.0291], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:35,987][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Sara] are: tensor([0.0013, 0.0962, 0.0934, 0.0847, 0.0875, 0.0942, 0.0986, 0.0857, 0.0917,
        0.0879, 0.0913, 0.0875], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:35,988][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Sara] are: tensor([0.0167, 0.0828, 0.0507, 0.0913, 0.0601, 0.0609, 0.1010, 0.0586, 0.0643,
        0.0845, 0.1107, 0.2185], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:35,989][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Sara] are: tensor([0.0910, 0.0013, 0.0107, 0.0049, 0.0252, 0.1334, 0.0064, 0.0227, 0.1422,
        0.0278, 0.5057, 0.0287], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:35,990][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([9.9922e-01, 6.7962e-05, 9.1661e-05, 3.7106e-05, 3.8503e-05, 2.1154e-05,
        5.6353e-06, 3.2389e-05, 8.6766e-05, 1.9407e-05, 1.7399e-04, 9.7813e-05,
        1.0367e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:35,992][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0761, 0.0333, 0.0599, 0.0171, 0.0085, 0.0102, 0.0763, 0.0192, 0.0825,
        0.5180, 0.0419, 0.0358, 0.0212], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:35,996][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0734, 0.0781, 0.0733, 0.0714, 0.0816, 0.0859, 0.0869, 0.0772, 0.0749,
        0.0724, 0.0761, 0.0722, 0.0767], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:35,998][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([9.9919e-01, 5.8186e-05, 3.5986e-05, 4.1582e-05, 7.8694e-05, 5.4604e-05,
        3.6647e-05, 1.1369e-04, 5.5526e-05, 4.2498e-05, 1.3738e-04, 9.6336e-05,
        5.7699e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:36,002][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.0027, 0.0687, 0.0768, 0.0830, 0.0751, 0.0832, 0.0947, 0.0895, 0.0893,
        0.0907, 0.0888, 0.0858, 0.0717], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:36,006][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.0831, 0.0303, 0.0427, 0.0370, 0.0279, 0.0271, 0.0828, 0.0652, 0.0335,
        0.1298, 0.1069, 0.3151, 0.0186], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:36,007][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0141, 0.0978, 0.0852, 0.0394, 0.0827, 0.0664, 0.0537, 0.1157, 0.0985,
        0.0523, 0.1263, 0.0739, 0.0937], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:36,007][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0803, 0.0577, 0.0967, 0.0727, 0.0550, 0.0628, 0.0594, 0.0916, 0.0677,
        0.0966, 0.1072, 0.0997, 0.0524], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:36,009][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.2024, 0.0134, 0.0634, 0.1113, 0.0806, 0.0221, 0.0501, 0.0520, 0.0705,
        0.0940, 0.0666, 0.1173, 0.0563], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:36,012][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0010, 0.0903, 0.0869, 0.0782, 0.0808, 0.0858, 0.0935, 0.0767, 0.0826,
        0.0829, 0.0838, 0.0832, 0.0743], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:36,016][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0184, 0.0712, 0.0411, 0.0673, 0.0587, 0.0733, 0.1076, 0.0517, 0.0669,
        0.0601, 0.1035, 0.1946, 0.0856], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:36,021][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0409, 0.0104, 0.1168, 0.0039, 0.0122, 0.1764, 0.0046, 0.0679, 0.0768,
        0.0142, 0.4151, 0.0555, 0.0052], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:36,022][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.9950e-01, 3.9772e-05, 4.8877e-05, 1.9490e-05, 2.2068e-05, 1.0628e-05,
        3.4530e-06, 1.5492e-05, 3.7582e-05, 1.0138e-05, 8.4741e-05, 5.4590e-05,
        5.7962e-05, 9.2754e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:36,023][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.3341, 0.0723, 0.0121, 0.0061, 0.0486, 0.0139, 0.0797, 0.0019, 0.0580,
        0.2937, 0.0122, 0.0358, 0.0291, 0.0023], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:36,023][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0695, 0.0735, 0.0688, 0.0679, 0.0764, 0.0806, 0.0812, 0.0714, 0.0695,
        0.0678, 0.0716, 0.0677, 0.0718, 0.0624], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:36,025][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([9.9966e-01, 2.4094e-05, 1.4748e-05, 1.6748e-05, 3.5453e-05, 2.2535e-05,
        1.6199e-05, 4.6629e-05, 2.0794e-05, 1.6153e-05, 5.2030e-05, 3.5758e-05,
        2.3383e-05, 1.1361e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:36,028][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0024, 0.0640, 0.0700, 0.0757, 0.0683, 0.0759, 0.0884, 0.0817, 0.0822,
        0.0824, 0.0820, 0.0793, 0.0660, 0.0817], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:36,032][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0915, 0.0137, 0.0283, 0.0556, 0.0512, 0.0446, 0.1992, 0.0356, 0.0300,
        0.1172, 0.0435, 0.2263, 0.0265, 0.0367], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:36,037][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0145, 0.0800, 0.0953, 0.0443, 0.0756, 0.0635, 0.0472, 0.1080, 0.0916,
        0.0487, 0.1144, 0.0631, 0.0706, 0.0832], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:36,037][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0672, 0.0642, 0.0809, 0.0779, 0.0456, 0.0606, 0.0616, 0.0589, 0.0612,
        0.1078, 0.0848, 0.1086, 0.0564, 0.0641], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:36,038][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1981, 0.0111, 0.0112, 0.0663, 0.0333, 0.0152, 0.1202, 0.0157, 0.0678,
        0.1199, 0.0126, 0.1133, 0.2014, 0.0139], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:36,040][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0009, 0.0818, 0.0819, 0.0732, 0.0730, 0.0791, 0.0869, 0.0696, 0.0776,
        0.0783, 0.0786, 0.0777, 0.0686, 0.0729], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:36,043][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0178, 0.0487, 0.0346, 0.0489, 0.0479, 0.0620, 0.0945, 0.0630, 0.0579,
        0.0530, 0.1152, 0.1704, 0.0934, 0.0925], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:36,047][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.2276, 0.0070, 0.0079, 0.0072, 0.0194, 0.0251, 0.0439, 0.0106, 0.0293,
        0.1393, 0.1934, 0.0504, 0.1676, 0.0712], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:36,050][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ give] are: tensor([9.9808e-01, 1.1061e-04, 1.5602e-04, 6.3351e-05, 6.2460e-05, 3.3761e-05,
        1.0504e-05, 5.3240e-05, 1.3855e-04, 3.4413e-05, 2.7769e-04, 1.6712e-04,
        2.1874e-04, 3.3745e-04, 2.6095e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:36,052][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.1529, 0.1260, 0.0873, 0.0346, 0.0365, 0.0317, 0.0810, 0.0241, 0.1285,
        0.0673, 0.0327, 0.0974, 0.0409, 0.0142, 0.0449], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:36,053][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0647, 0.0689, 0.0647, 0.0634, 0.0719, 0.0757, 0.0765, 0.0677, 0.0657,
        0.0638, 0.0665, 0.0634, 0.0675, 0.0586, 0.0608], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:36,054][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ give] are: tensor([9.9934e-01, 4.4269e-05, 2.8583e-05, 3.4342e-05, 6.4675e-05, 4.1114e-05,
        2.8701e-05, 7.9575e-05, 4.2606e-05, 3.2895e-05, 1.0006e-04, 6.9398e-05,
        4.6599e-05, 2.3488e-05, 2.7080e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:36,055][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0027, 0.0586, 0.0649, 0.0699, 0.0641, 0.0706, 0.0802, 0.0754, 0.0757,
        0.0753, 0.0751, 0.0728, 0.0618, 0.0740, 0.0789], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:36,057][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.2332, 0.0143, 0.0265, 0.0226, 0.0216, 0.0194, 0.0672, 0.0541, 0.0272,
        0.0766, 0.0635, 0.1988, 0.0259, 0.0678, 0.0813], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:36,060][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0119, 0.0827, 0.0822, 0.0402, 0.0710, 0.0589, 0.0466, 0.0948, 0.0823,
        0.0440, 0.0991, 0.0605, 0.0673, 0.0752, 0.0833], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:36,064][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0654, 0.0672, 0.0808, 0.0676, 0.0433, 0.0507, 0.0549, 0.0568, 0.0581,
        0.0875, 0.0831, 0.1019, 0.0544, 0.0671, 0.0612], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:36,068][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.2382, 0.0125, 0.0296, 0.0698, 0.0225, 0.0163, 0.0655, 0.0397, 0.0719,
        0.0657, 0.0305, 0.0957, 0.1253, 0.0750, 0.0418], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:36,069][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0008, 0.0773, 0.0740, 0.0684, 0.0684, 0.0747, 0.0821, 0.0668, 0.0727,
        0.0732, 0.0718, 0.0726, 0.0632, 0.0671, 0.0669], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:36,070][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0213, 0.0530, 0.0367, 0.0599, 0.0415, 0.0425, 0.0689, 0.0570, 0.0434,
        0.0514, 0.0969, 0.1456, 0.0791, 0.0812, 0.1216], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:36,072][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0594, 0.0145, 0.0599, 0.0034, 0.0179, 0.1416, 0.0067, 0.0420, 0.0661,
        0.0397, 0.2765, 0.0510, 0.0156, 0.1933, 0.0125], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:36,074][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ it] are: tensor([9.9702e-01, 1.3578e-04, 2.1702e-04, 7.4764e-05, 9.0704e-05, 5.1961e-05,
        1.5355e-05, 7.8098e-05, 1.9214e-04, 4.5382e-05, 3.9002e-04, 2.2746e-04,
        2.5174e-04, 4.5267e-04, 3.2071e-04, 4.3189e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:36,077][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ it] are: tensor([0.6825, 0.0191, 0.0103, 0.0060, 0.0061, 0.0138, 0.1212, 0.0063, 0.0189,
        0.0395, 0.0111, 0.0139, 0.0212, 0.0092, 0.0153, 0.0057],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:36,081][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.0610, 0.0650, 0.0605, 0.0596, 0.0671, 0.0714, 0.0730, 0.0639, 0.0614,
        0.0602, 0.0627, 0.0597, 0.0633, 0.0544, 0.0573, 0.0595],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:36,083][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ it] are: tensor([9.9956e-01, 2.7802e-05, 1.8668e-05, 2.0254e-05, 4.0835e-05, 2.6293e-05,
        1.8376e-05, 5.4801e-05, 2.6690e-05, 2.0815e-05, 6.6817e-05, 4.3271e-05,
        2.7807e-05, 1.4788e-05, 1.7451e-05, 1.6391e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:36,084][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.0026, 0.0543, 0.0605, 0.0646, 0.0594, 0.0650, 0.0734, 0.0699, 0.0699,
        0.0690, 0.0696, 0.0673, 0.0565, 0.0692, 0.0726, 0.0761],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:36,085][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ it] are: tensor([0.2545, 0.0106, 0.0210, 0.0246, 0.0370, 0.0288, 0.0995, 0.0390, 0.0236,
        0.0600, 0.0450, 0.1411, 0.0259, 0.0442, 0.0676, 0.0775],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:36,086][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.0087, 0.0692, 0.0776, 0.0326, 0.0673, 0.0548, 0.0415, 0.0856, 0.0815,
        0.0410, 0.0962, 0.0520, 0.0692, 0.0763, 0.0746, 0.0719],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:36,088][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.0582, 0.0548, 0.0623, 0.0606, 0.0470, 0.0567, 0.0629, 0.0627, 0.0521,
        0.0780, 0.0767, 0.0882, 0.0501, 0.0689, 0.0695, 0.0513],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:36,090][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.1467, 0.0073, 0.0260, 0.0765, 0.0241, 0.0072, 0.0418, 0.0456, 0.0275,
        0.0525, 0.0207, 0.0715, 0.1141, 0.1022, 0.1985, 0.0378],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:36,095][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ it] are: tensor([0.0008, 0.0712, 0.0704, 0.0646, 0.0642, 0.0705, 0.0767, 0.0624, 0.0688,
        0.0687, 0.0684, 0.0669, 0.0589, 0.0628, 0.0626, 0.0621],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:36,099][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.0373, 0.0643, 0.0428, 0.0594, 0.0428, 0.0358, 0.0554, 0.0516, 0.0390,
        0.0526, 0.0748, 0.1256, 0.0710, 0.0845, 0.0905, 0.0725],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:36,100][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ it] are: tensor([0.1546, 0.0043, 0.0123, 0.0043, 0.0105, 0.0222, 0.0371, 0.0362, 0.0136,
        0.1493, 0.1351, 0.0399, 0.0632, 0.1781, 0.0321, 0.1074],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:36,101][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.9889e-01, 5.2546e-05, 7.0993e-05, 2.7274e-05, 3.1211e-05, 1.4569e-05,
        4.5038e-06, 2.1151e-05, 5.3350e-05, 1.3807e-05, 1.2022e-04, 7.6376e-05,
        8.0769e-05, 1.3456e-04, 1.0248e-04, 1.4027e-04, 1.6193e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:36,103][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.3207, 0.0525, 0.0079, 0.0038, 0.0393, 0.0143, 0.0789, 0.0014, 0.0613,
        0.2437, 0.0115, 0.0247, 0.0224, 0.0019, 0.0297, 0.0835, 0.0025],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:36,106][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0575, 0.0605, 0.0570, 0.0565, 0.0635, 0.0672, 0.0682, 0.0600, 0.0579,
        0.0567, 0.0592, 0.0564, 0.0603, 0.0522, 0.0547, 0.0569, 0.0551],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:36,108][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([9.9975e-01, 1.5469e-05, 9.4701e-06, 1.0429e-05, 2.3704e-05, 1.4926e-05,
        1.0209e-05, 3.2516e-05, 1.4175e-05, 1.0397e-05, 3.6190e-05, 2.4101e-05,
        1.5659e-05, 7.7251e-06, 9.4482e-06, 9.3007e-06, 6.4044e-06],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:36,112][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0021, 0.0508, 0.0558, 0.0596, 0.0544, 0.0604, 0.0694, 0.0647, 0.0652,
        0.0650, 0.0649, 0.0629, 0.0526, 0.0648, 0.0681, 0.0715, 0.0679],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:36,114][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1266, 0.0112, 0.0184, 0.0338, 0.0403, 0.0363, 0.1325, 0.0340, 0.0241,
        0.0748, 0.0396, 0.1611, 0.0222, 0.0378, 0.0716, 0.0778, 0.0581],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:36,115][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0113, 0.0628, 0.0719, 0.0369, 0.0599, 0.0525, 0.0398, 0.0934, 0.0736,
        0.0396, 0.0943, 0.0510, 0.0577, 0.0712, 0.0624, 0.0561, 0.0658],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:36,116][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0558, 0.0499, 0.0701, 0.0610, 0.0364, 0.0494, 0.0508, 0.0474, 0.0505,
        0.0868, 0.0730, 0.0852, 0.0425, 0.0510, 0.0657, 0.0601, 0.0646],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:36,117][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1308, 0.0072, 0.0063, 0.0420, 0.0229, 0.0083, 0.0705, 0.0075, 0.0317,
        0.0676, 0.0072, 0.0669, 0.1423, 0.0091, 0.1563, 0.2124, 0.0112],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:36,119][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0008, 0.0660, 0.0664, 0.0599, 0.0594, 0.0648, 0.0713, 0.0572, 0.0639,
        0.0642, 0.0646, 0.0637, 0.0561, 0.0592, 0.0596, 0.0596, 0.0634],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:36,121][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0308, 0.0559, 0.0335, 0.0519, 0.0396, 0.0389, 0.0574, 0.0455, 0.0383,
        0.0410, 0.0832, 0.1290, 0.0643, 0.0745, 0.0856, 0.0690, 0.0617],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:36,125][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1406, 0.0046, 0.0031, 0.0060, 0.0079, 0.0088, 0.0392, 0.0052, 0.0105,
        0.1736, 0.0723, 0.0364, 0.1220, 0.0294, 0.0202, 0.2731, 0.0471],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:36,183][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:36,184][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:36,185][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:36,185][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:36,186][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:36,187][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:36,187][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:36,188][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:36,189][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:36,189][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:36,190][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:36,191][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:36,191][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:36,192][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Sara] are: tensor([0.9983, 0.0017], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:36,193][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Sara] are: tensor([0.8334, 0.1666], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:36,194][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Sara] are: tensor([0.4914, 0.5086], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:36,194][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Sara] are: tensor([0.9323, 0.0677], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:36,195][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Sara] are: tensor([0.9578, 0.0422], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:36,196][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Sara] are: tensor([0.1598, 0.8402], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:36,197][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Sara] are: tensor([0.9061, 0.0939], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:36,197][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Sara] are: tensor([0.4462, 0.5538], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:36,198][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Sara] are: tensor([9.9949e-01, 5.1324e-04], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:36,199][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Sara] are: tensor([0.0739, 0.9261], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:36,203][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Sara] are: tensor([0.5407, 0.4593], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:36,204][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Sara] are: tensor([0.1255, 0.8745], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:36,204][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([9.9881e-01, 1.1715e-03, 1.6056e-05], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:36,205][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1872, 0.7047, 0.1081], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:36,206][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3263, 0.3176, 0.3561], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:36,208][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.7954, 0.0872, 0.1174], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:36,210][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.9138, 0.0397, 0.0465], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:36,214][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1141, 0.4737, 0.4123], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:36,218][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.7357, 0.1258, 0.1386], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:36,219][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2451, 0.3599, 0.3950], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:36,220][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([9.9787e-01, 1.5246e-03, 6.0439e-04], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:36,221][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0352, 0.4383, 0.5265], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:36,221][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.3595, 0.3274, 0.3131], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:36,223][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0831, 0.5681, 0.3488], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:36,226][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Kenneth] are: tensor([0.9568, 0.0194, 0.0104, 0.0134], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:36,230][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Kenneth] are: tensor([0.4476, 0.1344, 0.1638, 0.2542], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:36,234][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Kenneth] are: tensor([0.2685, 0.2449, 0.2721, 0.2145], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:36,235][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Kenneth] are: tensor([0.7189, 0.0721, 0.0999, 0.1091], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:36,235][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Kenneth] are: tensor([0.8715, 0.0228, 0.0579, 0.0478], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:36,236][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Kenneth] are: tensor([0.0702, 0.3125, 0.3149, 0.3024], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:36,237][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Kenneth] are: tensor([0.6764, 0.0998, 0.1014, 0.1224], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:36,239][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Kenneth] are: tensor([0.1775, 0.2603, 0.2928, 0.2694], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:36,241][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Kenneth] are: tensor([0.9956, 0.0016, 0.0012, 0.0016], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:36,246][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Kenneth] are: tensor([0.0291, 0.3107, 0.4173, 0.2430], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:36,250][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Kenneth] are: tensor([0.2747, 0.2477, 0.2377, 0.2399], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:36,250][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Kenneth] are: tensor([0.0569, 0.4057, 0.2569, 0.2805], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:36,251][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.9488, 0.0163, 0.0058, 0.0281, 0.0011], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:36,252][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.3503, 0.0577, 0.1561, 0.3684, 0.0674], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:36,254][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.2444, 0.1823, 0.2109, 0.1657, 0.1967], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:36,257][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.6490, 0.0687, 0.0869, 0.1038, 0.0915], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:36,261][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.7914, 0.0262, 0.0450, 0.0472, 0.0902], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:36,265][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.0628, 0.2594, 0.2458, 0.2408, 0.1911], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:36,266][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.6272, 0.0889, 0.0975, 0.1101, 0.0763], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:36,266][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.1405, 0.2037, 0.2253, 0.2192, 0.2114], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:36,267][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([9.9224e-01, 2.0202e-03, 1.9128e-03, 3.4150e-03, 4.0951e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:36,268][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.0253, 0.2509, 0.3078, 0.1929, 0.2230], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:36,270][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.2335, 0.1959, 0.1887, 0.1874, 0.1944], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:36,273][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.0440, 0.3125, 0.2052, 0.2268, 0.2115], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:36,275][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([9.8970e-01, 3.4140e-03, 1.1997e-03, 3.7731e-03, 1.8331e-03, 7.5874e-05],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:36,279][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1118, 0.0579, 0.2051, 0.4709, 0.1191, 0.0353], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:36,281][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1911, 0.1468, 0.1764, 0.1450, 0.1649, 0.1757], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:36,282][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.5954, 0.0570, 0.0752, 0.0929, 0.0824, 0.0972], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:36,283][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.8306, 0.0151, 0.0300, 0.0282, 0.0736, 0.0225], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:36,284][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0500, 0.2207, 0.1908, 0.2140, 0.1579, 0.1665], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:36,286][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.5244, 0.0920, 0.0961, 0.1111, 0.0803, 0.0962], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:36,289][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1214, 0.1707, 0.1792, 0.1823, 0.1762, 0.1702], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:36,291][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([9.7640e-01, 4.5700e-03, 5.0998e-03, 1.1174e-02, 1.8221e-03, 9.3776e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:36,295][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0158, 0.2137, 0.2773, 0.1568, 0.1776, 0.1588], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:36,297][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1855, 0.1699, 0.1631, 0.1610, 0.1670, 0.1535], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:36,297][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0376, 0.2684, 0.1686, 0.1902, 0.1918, 0.1434], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:36,298][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.9222, 0.0071, 0.0285, 0.0067, 0.0138, 0.0173, 0.0044],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:36,299][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.2283, 0.0373, 0.1805, 0.2822, 0.1324, 0.0605, 0.0788],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:36,301][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.1846, 0.1201, 0.1424, 0.1110, 0.1359, 0.1598, 0.1463],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:36,304][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.5553, 0.0512, 0.0645, 0.0764, 0.0710, 0.0865, 0.0951],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:36,308][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.8335, 0.0100, 0.0347, 0.0185, 0.0519, 0.0277, 0.0238],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:36,312][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.0236, 0.1713, 0.1717, 0.1656, 0.1427, 0.1450, 0.1801],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:36,313][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.5238, 0.0791, 0.0804, 0.0953, 0.0604, 0.0720, 0.0890],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:36,314][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.1036, 0.1510, 0.1586, 0.1465, 0.1472, 0.1455, 0.1476],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:36,314][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([9.9059e-01, 2.1894e-03, 2.1147e-03, 2.5422e-03, 7.9845e-04, 9.0126e-04,
        8.6332e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:36,316][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.0123, 0.1839, 0.2482, 0.1461, 0.1555, 0.1351, 0.1188],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:36,319][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.1587, 0.1449, 0.1387, 0.1375, 0.1425, 0.1316, 0.1462],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:36,323][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.0279, 0.2155, 0.1525, 0.1560, 0.1565, 0.1340, 0.1576],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:36,326][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([9.8569e-01, 2.4039e-03, 7.3320e-04, 5.8205e-03, 1.2043e-03, 2.6720e-04,
        3.6666e-03, 2.1433e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:36,328][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.1993, 0.0511, 0.1183, 0.2058, 0.1484, 0.0498, 0.2008, 0.0265],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:36,329][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1480, 0.1029, 0.1234, 0.1003, 0.1167, 0.1363, 0.1264, 0.1460],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:36,330][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.5698, 0.0394, 0.0550, 0.0634, 0.0565, 0.0698, 0.0778, 0.0683],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:36,330][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.8544, 0.0115, 0.0199, 0.0171, 0.0536, 0.0199, 0.0164, 0.0071],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:36,332][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0313, 0.1593, 0.1506, 0.1547, 0.1196, 0.1163, 0.1492, 0.1189],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:36,335][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.4388, 0.0764, 0.0840, 0.0941, 0.0662, 0.0800, 0.0834, 0.0771],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:36,339][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0870, 0.1217, 0.1295, 0.1354, 0.1313, 0.1230, 0.1367, 0.1355],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:36,344][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.9631, 0.0068, 0.0068, 0.0102, 0.0023, 0.0025, 0.0057, 0.0026],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:36,344][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0121, 0.1573, 0.1995, 0.1218, 0.1462, 0.1289, 0.1129, 0.1211],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:36,345][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.1320, 0.1284, 0.1230, 0.1218, 0.1266, 0.1165, 0.1300, 0.1217],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:36,346][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0288, 0.1988, 0.1232, 0.1489, 0.1436, 0.1129, 0.1526, 0.0911],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:36,347][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([9.8693e-01, 1.3190e-03, 1.0760e-03, 2.8489e-03, 4.5243e-03, 4.1307e-04,
        1.9661e-03, 8.4716e-04, 7.4657e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:36,350][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1454, 0.0453, 0.0725, 0.2091, 0.0725, 0.0450, 0.3129, 0.0679, 0.0293],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:36,355][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1266, 0.0925, 0.1136, 0.0917, 0.1058, 0.1152, 0.1103, 0.1287, 0.1155],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:36,359][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.5120, 0.0400, 0.0506, 0.0626, 0.0537, 0.0655, 0.0815, 0.0654, 0.0687],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:36,360][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.8653, 0.0113, 0.0214, 0.0187, 0.0458, 0.0135, 0.0109, 0.0059, 0.0071],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:36,361][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0301, 0.1423, 0.1259, 0.1355, 0.1059, 0.1049, 0.1382, 0.1083, 0.1090],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:36,361][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.4198, 0.0674, 0.0737, 0.0822, 0.0576, 0.0721, 0.0730, 0.0652, 0.0892],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:36,363][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0758, 0.1089, 0.1149, 0.1169, 0.1158, 0.1090, 0.1201, 0.1194, 0.1191],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:36,366][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.9536, 0.0076, 0.0060, 0.0147, 0.0023, 0.0018, 0.0070, 0.0049, 0.0021],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:36,370][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0093, 0.1502, 0.1785, 0.1097, 0.1231, 0.1063, 0.0959, 0.1117, 0.1155],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:36,375][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1277, 0.1121, 0.1082, 0.1065, 0.1111, 0.1024, 0.1142, 0.1077, 0.1100],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:36,375][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0234, 0.1807, 0.1133, 0.1242, 0.1254, 0.0962, 0.1399, 0.0899, 0.1070],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:36,376][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ garden] are: tensor([0.9052, 0.0092, 0.0179, 0.0153, 0.0109, 0.0043, 0.0077, 0.0123, 0.0131,
        0.0041], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:36,377][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ garden] are: tensor([0.3093, 0.0312, 0.0966, 0.1691, 0.2076, 0.0347, 0.0189, 0.0908, 0.0356,
        0.0062], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:36,379][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ garden] are: tensor([0.1243, 0.0797, 0.0944, 0.0748, 0.0937, 0.1111, 0.0993, 0.1121, 0.1170,
        0.0936], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:36,382][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ garden] are: tensor([0.4638, 0.0394, 0.0487, 0.0563, 0.0517, 0.0651, 0.0708, 0.0643, 0.0694,
        0.0705], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:36,386][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ garden] are: tensor([0.7860, 0.0083, 0.0287, 0.0279, 0.0776, 0.0192, 0.0120, 0.0139, 0.0104,
        0.0161], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:36,390][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ garden] are: tensor([0.0173, 0.1198, 0.1215, 0.1111, 0.0937, 0.0956, 0.1257, 0.0994, 0.0985,
        0.1174], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:36,391][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ garden] are: tensor([0.3924, 0.0620, 0.0640, 0.0774, 0.0486, 0.0606, 0.0725, 0.0605, 0.0739,
        0.0881], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:36,392][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ garden] are: tensor([0.0636, 0.1038, 0.1091, 0.1053, 0.1068, 0.0988, 0.1031, 0.1091, 0.1077,
        0.0927], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:36,393][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ garden] are: tensor([0.9750, 0.0040, 0.0037, 0.0047, 0.0012, 0.0016, 0.0033, 0.0027, 0.0026,
        0.0012], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:36,395][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ garden] are: tensor([0.0073, 0.1292, 0.1755, 0.1001, 0.1102, 0.0970, 0.0848, 0.1046, 0.1054,
        0.0859], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:36,398][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ garden] are: tensor([0.1145, 0.1008, 0.0974, 0.0968, 0.1004, 0.0928, 0.1028, 0.0961, 0.0988,
        0.0996], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:36,402][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ garden] are: tensor([0.0211, 0.1538, 0.1046, 0.1135, 0.1086, 0.0907, 0.1152, 0.0836, 0.1013,
        0.1076], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:36,404][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([9.9686e-01, 3.3029e-04, 1.6343e-05, 6.7571e-04, 8.7292e-04, 4.6544e-05,
        2.3556e-04, 4.5327e-05, 4.6683e-05, 8.1571e-04, 5.3144e-05],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:36,406][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0502, 0.0474, 0.0439, 0.1865, 0.2008, 0.0653, 0.0946, 0.1001, 0.0984,
        0.0873, 0.0255], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:36,407][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0837, 0.0758, 0.0927, 0.0800, 0.0899, 0.0958, 0.0917, 0.1064, 0.0962,
        0.0863, 0.1015], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:36,408][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.4364, 0.0379, 0.0497, 0.0522, 0.0485, 0.0603, 0.0668, 0.0597, 0.0650,
        0.0699, 0.0535], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:36,410][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.8569, 0.0072, 0.0206, 0.0165, 0.0458, 0.0117, 0.0077, 0.0062, 0.0075,
        0.0098, 0.0101], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:36,413][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0313, 0.1093, 0.1024, 0.1022, 0.0861, 0.0852, 0.1015, 0.0880, 0.0859,
        0.0990, 0.1091], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:36,417][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3098, 0.0599, 0.0671, 0.0721, 0.0515, 0.0654, 0.0644, 0.0629, 0.0796,
        0.0783, 0.0890], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:36,421][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0613, 0.0919, 0.0947, 0.0960, 0.0955, 0.0882, 0.0951, 0.0979, 0.0968,
        0.0867, 0.0959], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:36,422][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([9.8821e-01, 2.4301e-03, 9.4676e-04, 2.8165e-03, 5.2895e-04, 6.8808e-04,
        1.3663e-03, 8.9867e-04, 8.6382e-04, 6.7227e-04, 5.8180e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:36,423][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0066, 0.1160, 0.1488, 0.0950, 0.1032, 0.0913, 0.0810, 0.0981, 0.1010,
        0.0845, 0.0747], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:36,424][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0970, 0.0930, 0.0902, 0.0885, 0.0927, 0.0852, 0.0947, 0.0893, 0.0918,
        0.0912, 0.0863], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:36,426][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0213, 0.1418, 0.0891, 0.0985, 0.1022, 0.0839, 0.1049, 0.0684, 0.0933,
        0.1046, 0.0920], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:36,429][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Sara] are: tensor([0.9204, 0.0026, 0.0054, 0.0100, 0.0151, 0.0081, 0.0038, 0.0016, 0.0042,
        0.0064, 0.0157, 0.0067], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:36,433][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Sara] are: tensor([0.1727, 0.0168, 0.1126, 0.1235, 0.0470, 0.0810, 0.1134, 0.0748, 0.0544,
        0.0761, 0.0798, 0.0478], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:36,437][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Sara] are: tensor([0.0938, 0.0643, 0.0842, 0.0655, 0.0805, 0.0915, 0.0802, 0.0970, 0.0938,
        0.0792, 0.0970, 0.0728], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:36,438][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Sara] are: tensor([0.3909, 0.0368, 0.0476, 0.0503, 0.0488, 0.0593, 0.0631, 0.0570, 0.0643,
        0.0653, 0.0531, 0.0636], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:36,439][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Sara] are: tensor([0.8378, 0.0109, 0.0267, 0.0147, 0.0356, 0.0142, 0.0152, 0.0059, 0.0080,
        0.0075, 0.0118, 0.0117], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:36,440][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Sara] are: tensor([0.0189, 0.0948, 0.0898, 0.0959, 0.0770, 0.0738, 0.0925, 0.0743, 0.0773,
        0.0960, 0.1009, 0.1089], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:36,443][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Sara] are: tensor([0.3046, 0.0552, 0.0575, 0.0691, 0.0452, 0.0543, 0.0608, 0.0534, 0.0668,
        0.0718, 0.0752, 0.0861], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:36,448][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Sara] are: tensor([0.0596, 0.0865, 0.0896, 0.0838, 0.0837, 0.0821, 0.0851, 0.0917, 0.0909,
        0.0771, 0.0927, 0.0771], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:36,450][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Sara] are: tensor([9.7740e-01, 1.1787e-03, 3.2846e-03, 6.2530e-03, 1.1646e-03, 1.0913e-03,
        1.2197e-03, 2.3486e-03, 1.2348e-03, 9.9606e-04, 3.1874e-03, 6.3988e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:36,453][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Sara] are: tensor([0.0063, 0.1171, 0.1575, 0.0937, 0.0984, 0.0823, 0.0725, 0.0864, 0.0873,
        0.0733, 0.0666, 0.0586], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:36,454][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Sara] are: tensor([0.0976, 0.0856, 0.0822, 0.0815, 0.0843, 0.0779, 0.0872, 0.0810, 0.0830,
        0.0833, 0.0781, 0.0783], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:36,454][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Sara] are: tensor([0.0174, 0.1185, 0.0831, 0.0897, 0.0869, 0.0741, 0.0901, 0.0644, 0.0819,
        0.0918, 0.0910, 0.1111], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:36,455][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.6383, 0.0229, 0.0441, 0.0403, 0.0054, 0.0182, 0.0063, 0.0900, 0.0162,
        0.0070, 0.0605, 0.0392, 0.0113], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:36,457][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.1016, 0.0189, 0.0905, 0.0608, 0.0750, 0.0368, 0.1110, 0.1450, 0.0783,
        0.1124, 0.0776, 0.0509, 0.0412], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:36,460][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0772, 0.0653, 0.0739, 0.0640, 0.0751, 0.0817, 0.0786, 0.0903, 0.0837,
        0.0703, 0.0874, 0.0729, 0.0796], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:36,464][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.4007, 0.0341, 0.0400, 0.0453, 0.0396, 0.0499, 0.0599, 0.0547, 0.0589,
        0.0598, 0.0495, 0.0624, 0.0450], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:36,468][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.8011, 0.0052, 0.0242, 0.0130, 0.0444, 0.0168, 0.0055, 0.0085, 0.0084,
        0.0094, 0.0095, 0.0077, 0.0463], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:36,469][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.0172, 0.0790, 0.0895, 0.0838, 0.0670, 0.0697, 0.0826, 0.0705, 0.0700,
        0.0823, 0.0959, 0.0906, 0.1017], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:36,470][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.3302, 0.0473, 0.0530, 0.0589, 0.0388, 0.0488, 0.0499, 0.0464, 0.0602,
        0.0597, 0.0691, 0.0724, 0.0653], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:36,472][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0470, 0.0771, 0.0865, 0.0813, 0.0806, 0.0756, 0.0792, 0.0871, 0.0843,
        0.0709, 0.0865, 0.0727, 0.0714], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:36,475][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.9646, 0.0037, 0.0045, 0.0062, 0.0016, 0.0017, 0.0025, 0.0035, 0.0016,
        0.0015, 0.0042, 0.0018, 0.0026], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:36,479][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0066, 0.1012, 0.1380, 0.0812, 0.0948, 0.0812, 0.0702, 0.0804, 0.0855,
        0.0720, 0.0641, 0.0563, 0.0684], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:36,482][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.0908, 0.0783, 0.0760, 0.0750, 0.0776, 0.0719, 0.0799, 0.0759, 0.0772,
        0.0771, 0.0734, 0.0729, 0.0740], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:36,486][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0147, 0.1139, 0.0799, 0.0798, 0.0754, 0.0679, 0.0817, 0.0618, 0.0725,
        0.0838, 0.0813, 0.1041, 0.0832], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:36,487][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.5334e-01, 3.0785e-03, 2.6945e-03, 3.7356e-03, 4.2759e-03, 9.9476e-04,
        1.4679e-03, 7.1135e-04, 3.5851e-04, 8.4663e-03, 7.9930e-03, 5.7054e-03,
        1.3391e-03, 5.8405e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:36,488][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0691, 0.0214, 0.0323, 0.1408, 0.1233, 0.0293, 0.1199, 0.0360, 0.0654,
        0.1428, 0.0516, 0.0647, 0.0852, 0.0182], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:36,489][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0570, 0.0546, 0.0693, 0.0596, 0.0664, 0.0777, 0.0725, 0.0883, 0.0792,
        0.0715, 0.0845, 0.0714, 0.0767, 0.0713], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:36,491][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.3651, 0.0336, 0.0420, 0.0452, 0.0415, 0.0512, 0.0533, 0.0507, 0.0588,
        0.0575, 0.0497, 0.0583, 0.0497, 0.0436], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:36,493][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.7571, 0.0135, 0.0316, 0.0171, 0.0396, 0.0150, 0.0110, 0.0075, 0.0081,
        0.0121, 0.0121, 0.0134, 0.0423, 0.0196], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:36,497][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0176, 0.0821, 0.0769, 0.0800, 0.0593, 0.0607, 0.0785, 0.0638, 0.0612,
        0.0758, 0.0826, 0.0922, 0.1036, 0.0658], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:36,502][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.2427, 0.0499, 0.0525, 0.0598, 0.0431, 0.0520, 0.0521, 0.0496, 0.0621,
        0.0620, 0.0644, 0.0713, 0.0617, 0.0768], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:36,503][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0479, 0.0718, 0.0777, 0.0772, 0.0765, 0.0694, 0.0749, 0.0780, 0.0765,
        0.0667, 0.0752, 0.0701, 0.0684, 0.0697], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:36,503][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([9.7411e-01, 3.8456e-03, 1.4129e-03, 4.4551e-03, 8.8232e-04, 1.2226e-03,
        3.1951e-03, 1.3490e-03, 1.1284e-03, 1.6685e-03, 1.3306e-03, 1.6957e-03,
        3.3256e-03, 3.8104e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:36,504][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0056, 0.0951, 0.1246, 0.0757, 0.0843, 0.0751, 0.0638, 0.0769, 0.0841,
        0.0675, 0.0595, 0.0534, 0.0637, 0.0706], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:36,506][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0739, 0.0744, 0.0717, 0.0708, 0.0743, 0.0682, 0.0757, 0.0708, 0.0727,
        0.0727, 0.0683, 0.0691, 0.0701, 0.0674], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:36,509][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0122, 0.1077, 0.0688, 0.0749, 0.0753, 0.0619, 0.0836, 0.0530, 0.0669,
        0.0785, 0.0703, 0.0962, 0.0894, 0.0613], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:36,513][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.6680, 0.0030, 0.0140, 0.0017, 0.0037, 0.0014, 0.0015, 0.0037, 0.0016,
        0.0025, 0.0267, 0.0050, 0.0133, 0.2501, 0.0037], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:36,518][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.1324, 0.0317, 0.0308, 0.1412, 0.0478, 0.0207, 0.1498, 0.0632, 0.0797,
        0.0314, 0.0455, 0.0936, 0.0556, 0.0181, 0.0584], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:36,519][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0758, 0.0525, 0.0654, 0.0529, 0.0615, 0.0704, 0.0674, 0.0777, 0.0745,
        0.0627, 0.0772, 0.0625, 0.0723, 0.0676, 0.0597], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:36,520][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.3759, 0.0311, 0.0376, 0.0425, 0.0386, 0.0488, 0.0520, 0.0462, 0.0531,
        0.0536, 0.0445, 0.0564, 0.0447, 0.0401, 0.0348], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:36,521][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.7516, 0.0212, 0.0212, 0.0170, 0.0303, 0.0143, 0.0100, 0.0061, 0.0076,
        0.0141, 0.0111, 0.0191, 0.0420, 0.0147, 0.0199], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:36,523][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0155, 0.0744, 0.0742, 0.0678, 0.0528, 0.0602, 0.0679, 0.0636, 0.0614,
        0.0674, 0.0810, 0.0811, 0.0889, 0.0677, 0.0760], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:36,526][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.2847, 0.0412, 0.0452, 0.0490, 0.0334, 0.0427, 0.0432, 0.0407, 0.0528,
        0.0526, 0.0582, 0.0620, 0.0538, 0.0691, 0.0713], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:36,530][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0441, 0.0680, 0.0759, 0.0713, 0.0711, 0.0660, 0.0693, 0.0732, 0.0720,
        0.0633, 0.0731, 0.0660, 0.0637, 0.0663, 0.0568], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:36,534][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.9422, 0.0063, 0.0056, 0.0079, 0.0014, 0.0028, 0.0046, 0.0053, 0.0032,
        0.0022, 0.0059, 0.0029, 0.0065, 0.0022, 0.0011], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:36,535][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0054, 0.0938, 0.1201, 0.0709, 0.0780, 0.0711, 0.0614, 0.0727, 0.0779,
        0.0633, 0.0594, 0.0492, 0.0589, 0.0658, 0.0522], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:36,536][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0743, 0.0694, 0.0668, 0.0658, 0.0685, 0.0633, 0.0702, 0.0655, 0.0675,
        0.0674, 0.0638, 0.0640, 0.0648, 0.0632, 0.0656], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:36,537][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0116, 0.1029, 0.0670, 0.0690, 0.0677, 0.0591, 0.0733, 0.0514, 0.0644,
        0.0748, 0.0683, 0.0937, 0.0776, 0.0611, 0.0580], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:36,539][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([0.6065, 0.0043, 0.0084, 0.0159, 0.0148, 0.0041, 0.0032, 0.0123, 0.0011,
        0.0028, 0.0141, 0.0058, 0.0087, 0.2778, 0.0190, 0.0011],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:36,542][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([0.0608, 0.0079, 0.0353, 0.1016, 0.0481, 0.0381, 0.1647, 0.1373, 0.0317,
        0.0620, 0.0447, 0.0302, 0.0855, 0.0551, 0.0649, 0.0322],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:36,545][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.0706, 0.0486, 0.0624, 0.0523, 0.0591, 0.0653, 0.0632, 0.0745, 0.0679,
        0.0611, 0.0732, 0.0574, 0.0651, 0.0664, 0.0551, 0.0577],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:36,550][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([0.3805, 0.0283, 0.0350, 0.0390, 0.0342, 0.0431, 0.0491, 0.0421, 0.0496,
        0.0495, 0.0410, 0.0511, 0.0426, 0.0366, 0.0351, 0.0431],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:36,550][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.6965, 0.0106, 0.0306, 0.0125, 0.0543, 0.0169, 0.0107, 0.0091, 0.0079,
        0.0163, 0.0101, 0.0126, 0.0474, 0.0149, 0.0329, 0.0167],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:36,551][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([0.0145, 0.0728, 0.0638, 0.0668, 0.0524, 0.0523, 0.0707, 0.0564, 0.0536,
        0.0664, 0.0716, 0.0821, 0.0873, 0.0609, 0.0732, 0.0550],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:36,552][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([0.2581, 0.0416, 0.0433, 0.0493, 0.0338, 0.0416, 0.0428, 0.0382, 0.0508,
        0.0495, 0.0538, 0.0586, 0.0510, 0.0634, 0.0650, 0.0593],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:36,555][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.0474, 0.0643, 0.0715, 0.0658, 0.0667, 0.0616, 0.0647, 0.0692, 0.0681,
        0.0592, 0.0695, 0.0610, 0.0607, 0.0620, 0.0548, 0.0535],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:36,557][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.9131, 0.0098, 0.0070, 0.0141, 0.0021, 0.0023, 0.0071, 0.0085, 0.0029,
        0.0041, 0.0069, 0.0051, 0.0084, 0.0034, 0.0037, 0.0015],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:36,561][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([0.0049, 0.0911, 0.1201, 0.0692, 0.0733, 0.0635, 0.0573, 0.0719, 0.0684,
        0.0589, 0.0539, 0.0457, 0.0579, 0.0629, 0.0499, 0.0510],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:36,565][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.0680, 0.0660, 0.0631, 0.0621, 0.0649, 0.0598, 0.0663, 0.0620, 0.0636,
        0.0634, 0.0601, 0.0606, 0.0611, 0.0593, 0.0614, 0.0583],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:36,566][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([0.0126, 0.0931, 0.0613, 0.0651, 0.0626, 0.0510, 0.0725, 0.0499, 0.0558,
        0.0707, 0.0630, 0.0840, 0.0782, 0.0575, 0.0566, 0.0660],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:36,567][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.5138e-01, 2.7278e-03, 2.0776e-03, 2.9333e-03, 2.5084e-03, 7.4098e-04,
        1.3144e-03, 7.2602e-04, 3.3781e-04, 6.7249e-03, 7.1271e-03, 4.5313e-03,
        1.6377e-03, 5.4003e-03, 1.8476e-03, 2.0848e-03, 5.8975e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:36,568][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0723, 0.0153, 0.0327, 0.1158, 0.0873, 0.0217, 0.0900, 0.0340, 0.0483,
        0.0980, 0.0461, 0.0432, 0.0680, 0.0143, 0.0707, 0.1230, 0.0193],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:36,570][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0436, 0.0442, 0.0581, 0.0498, 0.0552, 0.0655, 0.0615, 0.0738, 0.0667,
        0.0609, 0.0707, 0.0597, 0.0639, 0.0595, 0.0515, 0.0551, 0.0603],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:36,574][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.3141, 0.0320, 0.0389, 0.0411, 0.0373, 0.0460, 0.0464, 0.0452, 0.0531,
        0.0494, 0.0457, 0.0513, 0.0446, 0.0390, 0.0345, 0.0423, 0.0390],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:36,577][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.6867, 0.0115, 0.0353, 0.0144, 0.0395, 0.0163, 0.0111, 0.0107, 0.0095,
        0.0099, 0.0142, 0.0107, 0.0417, 0.0210, 0.0223, 0.0180, 0.0275],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:36,581][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0151, 0.0687, 0.0614, 0.0669, 0.0497, 0.0505, 0.0652, 0.0527, 0.0510,
        0.0635, 0.0671, 0.0771, 0.0843, 0.0539, 0.0675, 0.0552, 0.0503],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:36,582][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1982, 0.0393, 0.0420, 0.0476, 0.0353, 0.0436, 0.0429, 0.0399, 0.0516,
        0.0507, 0.0529, 0.0599, 0.0506, 0.0617, 0.0617, 0.0558, 0.0662],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:36,583][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0418, 0.0612, 0.0656, 0.0640, 0.0642, 0.0582, 0.0614, 0.0648, 0.0635,
        0.0554, 0.0629, 0.0587, 0.0579, 0.0582, 0.0512, 0.0513, 0.0597],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:36,584][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([9.6467e-01, 4.8817e-03, 1.7900e-03, 5.4892e-03, 1.0026e-03, 1.5010e-03,
        4.1420e-03, 1.8653e-03, 1.5241e-03, 2.0559e-03, 1.7271e-03, 2.1254e-03,
        4.0794e-03, 4.6913e-04, 1.0190e-03, 1.2326e-03, 4.2914e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:36,586][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0046, 0.0839, 0.1062, 0.0657, 0.0708, 0.0637, 0.0545, 0.0660, 0.0706,
        0.0575, 0.0512, 0.0459, 0.0549, 0.0593, 0.0480, 0.0506, 0.0466],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:36,590][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0600, 0.0618, 0.0596, 0.0588, 0.0617, 0.0569, 0.0627, 0.0590, 0.0607,
        0.0604, 0.0571, 0.0578, 0.0584, 0.0561, 0.0582, 0.0552, 0.0558],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:36,593][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0101, 0.0891, 0.0568, 0.0620, 0.0625, 0.0507, 0.0696, 0.0438, 0.0551,
        0.0659, 0.0576, 0.0789, 0.0746, 0.0509, 0.0532, 0.0682, 0.0510],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:36,596][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:36,599][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[14446],
        [32784],
        [ 6310],
        [20916],
        [20765],
        [15253],
        [10986],
        [12462],
        [ 9584],
        [11182],
        [10453],
        [25032],
        [ 6417],
        [ 7213],
        [ 9355],
        [ 4417],
        [ 5684]], device='cuda:0')
[2024-07-24 10:29:36,600][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[14539],
        [42012],
        [27766],
        [46062],
        [42920],
        [43866],
        [30766],
        [39750],
        [40645],
        [36971],
        [37935],
        [46152],
        [40919],
        [44098],
        [42195],
        [33597],
        [42821]], device='cuda:0')
[2024-07-24 10:29:36,602][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[22507],
        [22506],
        [22512],
        [22530],
        [22529],
        [22512],
        [22554],
        [22514],
        [22511],
        [22516],
        [22511],
        [22513],
        [22513],
        [22511],
        [22518],
        [22522],
        [22510]], device='cuda:0')
[2024-07-24 10:29:36,605][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[42887],
        [42571],
        [40093],
        [28175],
        [25996],
        [36866],
        [22152],
        [24550],
        [31086],
        [24290],
        [37401],
        [24060],
        [22936],
        [22744],
        [19129],
        [21873],
        [20495]], device='cuda:0')
[2024-07-24 10:29:36,608][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[31390],
        [28089],
        [25723],
        [24325],
        [24047],
        [23833],
        [22802],
        [22560],
        [22307],
        [21734],
        [21808],
        [21612],
        [21781],
        [21896],
        [21831],
        [21934],
        [22026]], device='cuda:0')
[2024-07-24 10:29:36,610][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[16315],
        [16328],
        [16321],
        [16329],
        [16356],
        [16341],
        [16353],
        [16357],
        [16338],
        [16357],
        [16349],
        [16368],
        [16353],
        [16329],
        [16347],
        [16334],
        [16323]], device='cuda:0')
[2024-07-24 10:29:36,613][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 5065],
        [17027],
        [16119],
        [16515],
        [14656],
        [14116],
        [15048],
        [15366],
        [14993],
        [14591],
        [14693],
        [15068],
        [14993],
        [14446],
        [14601],
        [14851],
        [14692]], device='cuda:0')
[2024-07-24 10:29:36,616][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[23530],
        [14837],
        [ 6485],
        [ 7010],
        [ 7361],
        [ 6333],
        [ 8844],
        [ 8686],
        [ 6820],
        [ 5948],
        [ 6070],
        [ 5431],
        [ 4542],
        [ 5510],
        [ 3869],
        [ 3994],
        [ 4222]], device='cuda:0')
[2024-07-24 10:29:36,617][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[21551],
        [10578],
        [19840],
        [19298],
        [18052],
        [18460],
        [17153],
        [18522],
        [18654],
        [19102],
        [19713],
        [18786],
        [18661],
        [18517],
        [18173],
        [18295],
        [18275]], device='cuda:0')
[2024-07-24 10:29:36,619][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[12185],
        [ 8039],
        [ 9237],
        [ 7697],
        [ 7568],
        [ 6663],
        [ 7542],
        [ 7322],
        [ 6992],
        [ 6478],
        [ 6320],
        [ 6467],
        [ 7147],
        [ 7510],
        [ 7693],
        [ 7618],
        [ 7667]], device='cuda:0')
[2024-07-24 10:29:36,620][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[11263],
        [ 9736],
        [ 5337],
        [11039],
        [12122],
        [10503],
        [ 8651],
        [ 7405],
        [ 7591],
        [ 7607],
        [ 6433],
        [ 7731],
        [ 5628],
        [ 3113],
        [ 4690],
        [ 5153],
        [ 3763]], device='cuda:0')
[2024-07-24 10:29:36,623][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[42853],
        [43360],
        [41927],
        [43278],
        [42215],
        [41462],
        [40573],
        [40658],
        [40651],
        [40421],
        [40230],
        [40087],
        [39784],
        [39567],
        [39270],
        [38960],
        [38724]], device='cuda:0')
[2024-07-24 10:29:36,626][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 3262],
        [ 3356],
        [ 6545],
        [ 6158],
        [10513],
        [12174],
        [12919],
        [19959],
        [21515],
        [20705],
        [23158],
        [22659],
        [24494],
        [27053],
        [25842],
        [24845],
        [24832]], device='cuda:0')
[2024-07-24 10:29:36,628][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[24561],
        [24259],
        [20816],
        [14356],
        [ 8585],
        [ 7517],
        [ 6582],
        [ 7426],
        [11370],
        [ 8123],
        [ 7921],
        [ 9412],
        [ 8955],
        [ 5244],
        [ 7246],
        [ 5685],
        [ 5114]], device='cuda:0')
[2024-07-24 10:29:36,631][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[18394],
        [20459],
        [10249],
        [ 5517],
        [12002],
        [14328],
        [20001],
        [12730],
        [ 9981],
        [13071],
        [15336],
        [18185],
        [ 7436],
        [ 7090],
        [10873],
        [11180],
        [ 8208]], device='cuda:0')
[2024-07-24 10:29:36,634][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[11030],
        [11024],
        [11029],
        [10104],
        [10138],
        [10831],
        [ 8058],
        [10739],
        [10572],
        [ 6653],
        [10891],
        [ 8300],
        [ 2946],
        [ 9243],
        [ 4564],
        [ 4559],
        [ 9117]], device='cuda:0')
[2024-07-24 10:29:36,635][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[34362],
        [25410],
        [ 6271],
        [19364],
        [20603],
        [20278],
        [19094],
        [12483],
        [10734],
        [25694],
        [15112],
        [14040],
        [12396],
        [ 8953],
        [ 9860],
        [14033],
        [11078]], device='cuda:0')
[2024-07-24 10:29:36,637][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[10506],
        [11427],
        [ 8796],
        [ 8010],
        [ 6163],
        [ 5084],
        [ 4374],
        [ 3701],
        [ 3584],
        [ 3330],
        [ 3282],
        [ 3015],
        [ 3069],
        [ 3167],
        [ 3070],
        [ 2980],
        [ 3129]], device='cuda:0')
[2024-07-24 10:29:36,638][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 6240],
        [ 8435],
        [12970],
        [15625],
        [16347],
        [16415],
        [16942],
        [16327],
        [16075],
        [16418],
        [16891],
        [17429],
        [17651],
        [18131],
        [17887],
        [17715],
        [17890]], device='cuda:0')
[2024-07-24 10:29:36,641][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[15067],
        [15875],
        [11353],
        [ 7207],
        [ 8594],
        [ 8784],
        [ 9425],
        [ 9611],
        [ 9193],
        [ 9247],
        [ 8495],
        [ 9109],
        [10936],
        [13534],
        [15529],
        [19048],
        [18733]], device='cuda:0')
[2024-07-24 10:29:36,644][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 5208],
        [16761],
        [13026],
        [11625],
        [11316],
        [ 9702],
        [ 9553],
        [ 9544],
        [ 9201],
        [ 9287],
        [ 9488],
        [10042],
        [10268],
        [ 9755],
        [ 8825],
        [ 8755],
        [ 8433]], device='cuda:0')
[2024-07-24 10:29:36,646][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[25798],
        [23516],
        [19115],
        [18797],
        [18723],
        [18906],
        [18645],
        [17456],
        [17734],
        [18847],
        [18010],
        [17278],
        [17369],
        [16560],
        [17008],
        [16258],
        [15626]], device='cuda:0')
[2024-07-24 10:29:36,649][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[24525],
        [16016],
        [12011],
        [12041],
        [10650],
        [ 9963],
        [ 9205],
        [ 9330],
        [ 9321],
        [ 9688],
        [ 9797],
        [10374],
        [10876],
        [10486],
        [10455],
        [10560],
        [10308]], device='cuda:0')
[2024-07-24 10:29:36,652][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[15064],
        [15070],
        [15093],
        [15131],
        [15185],
        [15405],
        [15218],
        [15550],
        [15618],
        [15401],
        [15234],
        [15332],
        [15425],
        [15354],
        [15538],
        [15758],
        [15415]], device='cuda:0')
[2024-07-24 10:29:36,653][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[24264],
        [21663],
        [16346],
        [16306],
        [14571],
        [13106],
        [12346],
        [11621],
        [11404],
        [11304],
        [10933],
        [11446],
        [11335],
        [11456],
        [11496],
        [11780],
        [11783]], device='cuda:0')
[2024-07-24 10:29:36,655][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[23436],
        [30418],
        [33623],
        [34998],
        [36045],
        [36710],
        [37104],
        [37322],
        [37544],
        [37501],
        [37640],
        [37438],
        [37646],
        [37978],
        [37944],
        [38090],
        [38216]], device='cuda:0')
[2024-07-24 10:29:36,656][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[39816],
        [30746],
        [34444],
        [35056],
        [37296],
        [36284],
        [33433],
        [34997],
        [34317],
        [32653],
        [33205],
        [32436],
        [33166],
        [33664],
        [33496],
        [33817],
        [34110]], device='cuda:0')
[2024-07-24 10:29:36,659][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[36679],
        [31414],
        [35460],
        [34930],
        [35069],
        [36128],
        [37062],
        [37485],
        [38113],
        [37147],
        [37592],
        [37889],
        [38579],
        [37421],
        [37883],
        [36550],
        [36446]], device='cuda:0')
[2024-07-24 10:29:36,662][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[31951],
        [38955],
        [40260],
        [36786],
        [36273],
        [31789],
        [36178],
        [39398],
        [39296],
        [42441],
        [39707],
        [41459],
        [43397],
        [41089],
        [41372],
        [40415],
        [40016]], device='cuda:0')
[2024-07-24 10:29:36,664][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940]], device='cuda:0')
[2024-07-24 10:29:36,748][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:36,749][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:36,750][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:36,750][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:36,751][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:36,752][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:36,752][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:36,753][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:36,754][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:36,754][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:36,755][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:36,756][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:36,756][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:36,757][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Sara] are: tensor([0.7853, 0.2147], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:36,758][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Sara] are: tensor([0.3340, 0.6660], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:36,759][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Sara] are: tensor([2.8742e-06, 1.0000e+00], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:36,759][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Sara] are: tensor([0.1456, 0.8544], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:36,760][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Sara] are: tensor([0.9779, 0.0221], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:36,761][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Sara] are: tensor([0.9918, 0.0082], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:36,762][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Sara] are: tensor([0.6403, 0.3597], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:36,762][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Sara] are: tensor([0.1735, 0.8265], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:36,765][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Sara] are: tensor([0.0571, 0.9429], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:36,766][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Sara] are: tensor([9.9954e-01, 4.6079e-04], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:36,766][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Sara] are: tensor([3.2470e-04, 9.9968e-01], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:36,767][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Sara] are: tensor([0.5241, 0.4759], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:36,768][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0243, 0.3669, 0.6087], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:36,769][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.5284, 0.3748, 0.0968], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:36,769][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([8.3145e-07, 8.0341e-01, 1.9658e-01], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:36,772][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0682, 0.4958, 0.4360], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:36,776][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.8651, 0.1285, 0.0065], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:36,779][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.9338, 0.0577, 0.0085], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:36,780][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3757, 0.2771, 0.3473], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:36,781][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1204, 0.5873, 0.2923], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:36,781][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0358, 0.5268, 0.4375], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:36,782][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([9.9881e-01, 5.5900e-04, 6.2634e-04], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:36,783][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([5.9431e-06, 7.3361e-01, 2.6639e-01], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:36,786][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.3239, 0.3964, 0.2797], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:36,790][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Kenneth] are: tensor([0.0220, 0.0490, 0.8556, 0.0734], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:36,793][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Kenneth] are: tensor([0.4504, 0.2361, 0.0812, 0.2323], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:36,795][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Kenneth] are: tensor([6.8763e-07, 5.9716e-01, 1.4915e-01, 2.5370e-01], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:36,796][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Kenneth] are: tensor([0.0499, 0.3463, 0.3066, 0.2972], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:36,797][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Kenneth] are: tensor([0.8770, 0.0777, 0.0212, 0.0241], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:36,797][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Kenneth] are: tensor([0.9685, 0.0169, 0.0078, 0.0068], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:36,799][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Kenneth] are: tensor([0.2588, 0.2145, 0.2755, 0.2511], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:36,802][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Kenneth] are: tensor([0.0459, 0.2980, 0.3742, 0.2820], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:36,802][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Kenneth] are: tensor([0.0197, 0.3721, 0.2885, 0.3197], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:36,803][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Kenneth] are: tensor([9.9892e-01, 2.8190e-04, 3.5899e-04, 4.3741e-04], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:36,806][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Kenneth] are: tensor([1.4270e-04, 4.1838e-01, 5.2650e-01, 5.4976e-02], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:36,810][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Kenneth] are: tensor([0.2651, 0.2863, 0.2219, 0.2267], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:36,812][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.0336, 0.0152, 0.0584, 0.0841, 0.8087], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:36,813][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.3451, 0.1918, 0.1179, 0.2241, 0.1211], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:36,814][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ got] are: tensor([1.9345e-06, 8.3945e-01, 5.3364e-02, 6.5341e-02, 4.1841e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:36,815][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.0363, 0.2692, 0.2370, 0.2289, 0.2286], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:36,816][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.5453, 0.2658, 0.1251, 0.0550, 0.0088], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:36,819][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.9612, 0.0169, 0.0073, 0.0106, 0.0040], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:36,823][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.1923, 0.1733, 0.2176, 0.2005, 0.2163], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:36,826][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.0962, 0.2717, 0.2187, 0.1960, 0.2174], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:36,828][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.0143, 0.3058, 0.2478, 0.2783, 0.1539], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:36,829][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ got] are: tensor([9.9720e-01, 5.5859e-04, 6.5487e-04, 8.6952e-04, 7.1515e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:36,830][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ got] are: tensor([7.2785e-05, 5.4004e-01, 3.9340e-01, 3.1181e-02, 3.5306e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:36,830][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.2627, 0.2340, 0.1699, 0.1764, 0.1570], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:36,832][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0216, 0.0026, 0.0064, 0.0116, 0.4982, 0.4597], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:36,835][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.4140, 0.1905, 0.0859, 0.1630, 0.0885, 0.0581], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:36,837][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([1.1137e-06, 5.6453e-01, 7.4574e-02, 1.0639e-01, 1.4097e-01, 1.1354e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:36,841][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0300, 0.2184, 0.1917, 0.1853, 0.1854, 0.1892], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:36,844][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2442, 0.3817, 0.2327, 0.0685, 0.0207, 0.0522], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:36,845][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.9838, 0.0064, 0.0022, 0.0027, 0.0018, 0.0031], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:36,846][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1786, 0.1389, 0.1726, 0.1677, 0.1798, 0.1624], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:36,846][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1465, 0.2208, 0.1990, 0.1475, 0.1978, 0.0883], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:36,848][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0140, 0.2908, 0.2018, 0.2791, 0.1484, 0.0658], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:36,850][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([9.9694e-01, 5.2445e-04, 5.7778e-04, 8.6458e-04, 6.9939e-04, 3.9593e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:36,852][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([1.3509e-05, 4.1624e-01, 4.1289e-01, 3.2694e-02, 6.9540e-02, 6.8620e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:36,856][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1913, 0.1982, 0.1387, 0.1490, 0.1357, 0.1871], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:36,860][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.0016, 0.0036, 0.0092, 0.0142, 0.4214, 0.5083, 0.0417],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:36,860][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.3151, 0.1395, 0.1163, 0.0998, 0.1453, 0.0704, 0.1136],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:36,861][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([9.7705e-08, 2.6206e-01, 6.7192e-02, 1.3397e-01, 5.8879e-02, 1.0700e-01,
        3.7090e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:36,862][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0262, 0.1838, 0.1620, 0.1577, 0.1561, 0.1596, 0.1545],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:36,864][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.7937, 0.0943, 0.0468, 0.0192, 0.0100, 0.0276, 0.0084],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:36,867][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.9429, 0.0131, 0.0049, 0.0062, 0.0070, 0.0112, 0.0147],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:36,871][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.1552, 0.1204, 0.1562, 0.1500, 0.1605, 0.1465, 0.1112],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:36,874][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.0815, 0.1522, 0.1884, 0.1639, 0.2072, 0.1133, 0.0934],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:36,876][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.0069, 0.2613, 0.2162, 0.2724, 0.1426, 0.0728, 0.0278],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:36,876][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([9.9617e-01, 5.8040e-04, 6.3238e-04, 9.9233e-04, 7.3431e-04, 4.3252e-04,
        4.5757e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:36,877][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([2.1068e-05, 4.6643e-01, 3.1318e-01, 5.5173e-02, 2.5130e-02, 8.3779e-02,
        5.6286e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:36,878][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.1918, 0.1593, 0.1233, 0.1221, 0.1098, 0.1560, 0.1376],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:36,880][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0211, 0.0009, 0.0039, 0.0091, 0.3567, 0.3539, 0.0805, 0.1740],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:36,883][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.3954, 0.1892, 0.0672, 0.1110, 0.0810, 0.0438, 0.0536, 0.0588],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:36,885][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ at] are: tensor([4.8345e-07, 3.2855e-01, 5.8041e-02, 9.4411e-02, 6.8468e-02, 1.2395e-01,
        2.6999e-01, 5.6580e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:36,889][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0231, 0.1568, 0.1384, 0.1352, 0.1339, 0.1370, 0.1326, 0.1429],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:36,891][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.2592, 0.4494, 0.0858, 0.0489, 0.0274, 0.0811, 0.0375, 0.0107],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:36,892][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.9502, 0.0130, 0.0031, 0.0060, 0.0034, 0.0052, 0.0128, 0.0063],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:36,893][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.1304, 0.1038, 0.1365, 0.1354, 0.1416, 0.1258, 0.0978, 0.1286],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:36,894][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.1214, 0.1855, 0.1541, 0.1197, 0.1822, 0.0683, 0.0805, 0.0883],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:36,896][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0107, 0.2543, 0.1767, 0.2339, 0.1264, 0.0612, 0.0221, 0.1146],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:36,898][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ at] are: tensor([9.9835e-01, 2.4059e-04, 2.4632e-04, 4.2837e-04, 3.0140e-04, 1.6338e-04,
        1.7052e-04, 9.6670e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:36,900][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ at] are: tensor([1.5528e-05, 4.0075e-01, 3.2017e-01, 3.1654e-02, 4.3121e-02, 1.1372e-01,
        5.2778e-02, 3.7794e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:36,905][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.1671, 0.1412, 0.1035, 0.1076, 0.0962, 0.1424, 0.1332, 0.1088],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:36,907][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ the] are: tensor([1.9172e-02, 3.9847e-04, 2.2808e-03, 2.6577e-03, 1.3236e-01, 1.5666e-01,
        4.2888e-02, 5.1266e-01, 1.3092e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:36,908][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.4350, 0.1259, 0.0628, 0.0991, 0.0544, 0.0308, 0.0702, 0.0731, 0.0487],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:36,909][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ the] are: tensor([8.9516e-08, 2.9736e-01, 2.1125e-02, 8.7140e-02, 4.0429e-02, 5.1085e-02,
        2.7901e-01, 4.8765e-02, 1.7508e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:36,909][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0199, 0.1384, 0.1215, 0.1182, 0.1174, 0.1201, 0.1167, 0.1258, 0.1221],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:36,912][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0770, 0.4139, 0.2259, 0.0584, 0.0288, 0.0877, 0.0348, 0.0466, 0.0269],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:36,914][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.9709, 0.0102, 0.0021, 0.0032, 0.0018, 0.0026, 0.0058, 0.0021, 0.0013],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:36,918][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1204, 0.0915, 0.1168, 0.1164, 0.1260, 0.1123, 0.0882, 0.1141, 0.1143],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:36,923][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1213, 0.1043, 0.1261, 0.0984, 0.1729, 0.0636, 0.1053, 0.1048, 0.1032],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:36,924][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0213, 0.2161, 0.1462, 0.1782, 0.1001, 0.0469, 0.0179, 0.0930, 0.1803],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:36,924][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ the] are: tensor([9.9821e-01, 2.3452e-04, 2.5829e-04, 3.9415e-04, 3.0984e-04, 1.7240e-04,
        1.8191e-04, 1.2291e-04, 1.1568e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:36,925][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ the] are: tensor([9.9504e-06, 5.1671e-01, 2.0639e-01, 5.2541e-02, 2.7068e-02, 3.6334e-02,
        3.3011e-02, 1.9230e-02, 1.0871e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:36,926][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1271, 0.1327, 0.0909, 0.0965, 0.0892, 0.1252, 0.1135, 0.1009, 0.1240],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:36,928][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ garden] are: tensor([0.0043, 0.0009, 0.0037, 0.0044, 0.1422, 0.1567, 0.0210, 0.3675, 0.2370,
        0.0624], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:36,932][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ garden] are: tensor([0.2382, 0.1318, 0.0915, 0.1463, 0.0844, 0.0348, 0.0418, 0.0807, 0.0764,
        0.0742], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:36,934][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ garden] are: tensor([1.7840e-08, 6.4204e-02, 3.3693e-02, 5.4488e-02, 2.8374e-02, 5.2313e-02,
        1.6552e-01, 4.3279e-02, 3.4735e-01, 2.1078e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:36,937][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ garden] are: tensor([0.0174, 0.1246, 0.1093, 0.1072, 0.1058, 0.1080, 0.1043, 0.1129, 0.1095,
        0.1011], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:36,939][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ garden] are: tensor([0.4426, 0.2883, 0.1099, 0.0246, 0.0163, 0.0392, 0.0169, 0.0229, 0.0283,
        0.0110], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:36,940][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ garden] are: tensor([9.8064e-01, 4.3226e-03, 1.8727e-03, 1.9827e-03, 1.1494e-03, 1.0622e-03,
        3.5136e-03, 1.4850e-03, 6.1545e-04, 3.3610e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:36,941][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ garden] are: tensor([0.0971, 0.0856, 0.1134, 0.1082, 0.1180, 0.1004, 0.0749, 0.1054, 0.0998,
        0.0973], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:36,942][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ garden] are: tensor([0.0162, 0.0690, 0.1068, 0.0821, 0.1264, 0.0510, 0.0568, 0.1376, 0.1322,
        0.2218], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:36,944][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ garden] are: tensor([0.0102, 0.1926, 0.1407, 0.1850, 0.0926, 0.0413, 0.0164, 0.0961, 0.1683,
        0.0567], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:36,946][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ garden] are: tensor([9.9774e-01, 2.6362e-04, 2.9401e-04, 4.4079e-04, 3.3177e-04, 1.8742e-04,
        2.0609e-04, 1.3817e-04, 1.3856e-04, 2.6423e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:36,948][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ garden] are: tensor([9.7292e-06, 2.4811e-01, 2.7924e-01, 3.3887e-02, 3.0243e-02, 7.0955e-02,
        5.2634e-02, 2.3308e-02, 2.3938e-01, 2.2230e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:36,952][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ garden] are: tensor([0.1249, 0.1137, 0.0836, 0.0862, 0.0781, 0.1116, 0.0981, 0.0901, 0.1051,
        0.1086], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:36,955][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0283, 0.0007, 0.0024, 0.0037, 0.1333, 0.2773, 0.0294, 0.2051, 0.1748,
        0.0856, 0.0594], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:36,956][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.5307, 0.0679, 0.0459, 0.0531, 0.0589, 0.0194, 0.0364, 0.0478, 0.0461,
        0.0532, 0.0406], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:36,956][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([4.5689e-08, 9.0810e-02, 2.0809e-02, 4.4272e-02, 2.1409e-02, 4.5850e-02,
        1.4517e-01, 3.5028e-02, 2.1860e-01, 1.6997e-01, 2.0809e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:36,957][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0159, 0.1116, 0.0979, 0.0965, 0.0957, 0.0975, 0.0948, 0.1022, 0.0988,
        0.0917, 0.0975], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:36,959][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.6540, 0.2001, 0.0219, 0.0224, 0.0179, 0.0299, 0.0118, 0.0100, 0.0176,
        0.0085, 0.0061], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:36,962][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9662, 0.0085, 0.0014, 0.0028, 0.0021, 0.0027, 0.0049, 0.0022, 0.0011,
        0.0070, 0.0011], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:36,966][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1031, 0.0718, 0.0941, 0.0981, 0.1006, 0.0899, 0.0720, 0.0944, 0.0918,
        0.0908, 0.0934], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:36,970][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0379, 0.0740, 0.0682, 0.0716, 0.1011, 0.0572, 0.0639, 0.0824, 0.1224,
        0.1796, 0.1418], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:36,971][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0173, 0.1638, 0.1068, 0.1401, 0.0722, 0.0367, 0.0135, 0.0666, 0.1376,
        0.0540, 0.1913], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:36,972][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([9.9841e-01, 1.7341e-04, 1.9052e-04, 2.9908e-04, 2.1534e-04, 1.2413e-04,
        1.3061e-04, 8.3689e-05, 8.6337e-05, 1.7408e-04, 1.1407e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:36,973][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([1.2459e-05, 4.1437e-01, 6.9460e-02, 4.1176e-02, 1.5251e-02, 5.9282e-02,
        2.6500e-02, 3.7126e-02, 2.4421e-01, 3.2809e-02, 5.9804e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:36,975][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1166, 0.1015, 0.0750, 0.0772, 0.0702, 0.1014, 0.0949, 0.0792, 0.0996,
        0.1013, 0.0832], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:36,979][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Sara] are: tensor([0.1533, 0.0008, 0.0077, 0.0073, 0.1163, 0.1705, 0.0176, 0.1909, 0.1408,
        0.0502, 0.0724, 0.0723], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:36,982][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Sara] are: tensor([0.1271, 0.1659, 0.0682, 0.1531, 0.0776, 0.0278, 0.0682, 0.0576, 0.0640,
        0.0774, 0.0470, 0.0661], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:36,984][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Sara] are: tensor([1.1646e-07, 2.3462e-01, 2.5864e-02, 7.4080e-02, 2.6557e-02, 3.2670e-02,
        9.2634e-02, 2.2006e-02, 1.1818e-01, 1.1924e-01, 2.4438e-01, 9.7617e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:36,988][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Sara] are: tensor([0.0161, 0.1012, 0.0889, 0.0881, 0.0865, 0.0879, 0.0863, 0.0923, 0.0895,
        0.0836, 0.0894, 0.0902], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:36,989][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Sara] are: tensor([0.8411, 0.0556, 0.0158, 0.0126, 0.0036, 0.0226, 0.0066, 0.0070, 0.0078,
        0.0071, 0.0064, 0.0138], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:36,990][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Sara] are: tensor([9.8113e-01, 2.6455e-03, 1.7131e-03, 2.0644e-03, 1.0172e-03, 1.4131e-03,
        2.5811e-03, 1.4135e-03, 7.9693e-04, 3.1855e-03, 8.2117e-04, 1.2163e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:36,991][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Sara] are: tensor([0.0866, 0.0723, 0.0935, 0.0892, 0.0964, 0.0850, 0.0648, 0.0846, 0.0849,
        0.0812, 0.0842, 0.0773], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:36,994][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Sara] are: tensor([0.0306, 0.0577, 0.0711, 0.0743, 0.0848, 0.0388, 0.0843, 0.0564, 0.1038,
        0.1913, 0.1422, 0.0647], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:36,999][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Sara] are: tensor([0.0139, 0.1484, 0.0956, 0.1309, 0.0537, 0.0249, 0.0096, 0.0482, 0.1036,
        0.0396, 0.1583, 0.1733], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,001][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Sara] are: tensor([9.9842e-01, 1.5099e-04, 1.7445e-04, 2.5687e-04, 2.0547e-04, 1.0645e-04,
        1.2449e-04, 7.7852e-05, 7.6618e-05, 1.5678e-04, 1.0657e-04, 1.4713e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,004][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Sara] are: tensor([5.8198e-05, 3.8511e-01, 1.3435e-01, 3.2888e-02, 2.2708e-02, 2.6603e-02,
        3.4127e-02, 2.0077e-02, 2.1075e-01, 3.3970e-02, 6.6350e-02, 3.3013e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,004][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Sara] are: tensor([0.1132, 0.0915, 0.0701, 0.0715, 0.0675, 0.0940, 0.0828, 0.0722, 0.0857,
        0.0878, 0.0733, 0.0904], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,005][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([3.9925e-02, 3.8336e-04, 8.4464e-04, 1.9977e-03, 4.0181e-02, 4.3862e-02,
        3.7083e-03, 3.2814e-02, 5.3505e-02, 1.1361e-02, 2.2732e-02, 5.2443e-02,
        6.9624e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,006][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.1863, 0.1104, 0.0654, 0.0658, 0.0675, 0.0457, 0.0351, 0.0791, 0.0698,
        0.0727, 0.0645, 0.0521, 0.0856], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,008][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([1.1443e-08, 1.0736e-01, 2.9509e-02, 4.5445e-02, 5.9136e-02, 5.6709e-02,
        1.6145e-01, 5.5592e-02, 9.2275e-02, 5.1259e-02, 3.0501e-01, 1.1887e-02,
        2.4361e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,010][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0134, 0.0935, 0.0826, 0.0811, 0.0801, 0.0815, 0.0793, 0.0851, 0.0823,
        0.0765, 0.0817, 0.0828, 0.0800], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,015][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.6995, 0.1323, 0.0337, 0.0095, 0.0055, 0.0180, 0.0116, 0.0137, 0.0153,
        0.0109, 0.0135, 0.0278, 0.0087], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,019][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.9508, 0.0062, 0.0040, 0.0041, 0.0020, 0.0029, 0.0048, 0.0046, 0.0019,
        0.0074, 0.0023, 0.0032, 0.0057], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,020][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0815, 0.0648, 0.0821, 0.0844, 0.0879, 0.0787, 0.0578, 0.0776, 0.0788,
        0.0772, 0.0776, 0.0704, 0.0812], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,021][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0209, 0.0607, 0.0669, 0.0358, 0.0902, 0.0533, 0.0545, 0.0723, 0.1016,
        0.1147, 0.1387, 0.0628, 0.1275], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,023][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0192, 0.1175, 0.0723, 0.0901, 0.0449, 0.0226, 0.0076, 0.0423, 0.0844,
        0.0270, 0.1205, 0.1368, 0.2148], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,025][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([9.9722e-01, 2.2437e-04, 2.6955e-04, 3.8122e-04, 3.0491e-04, 1.8534e-04,
        1.7669e-04, 1.2403e-04, 1.3520e-04, 2.4020e-04, 1.8137e-04, 2.4063e-04,
        3.1542e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,028][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([1.1232e-04, 1.2295e-01, 1.3780e-01, 9.7474e-03, 3.4369e-02, 8.7662e-02,
        2.7384e-02, 5.1028e-02, 1.6217e-01, 5.5662e-02, 9.2219e-02, 5.9395e-02,
        1.5950e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,032][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0872, 0.0820, 0.0666, 0.0657, 0.0612, 0.0868, 0.0799, 0.0704, 0.0847,
        0.0878, 0.0720, 0.0884, 0.0674], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,034][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([4.6460e-02, 1.8023e-04, 4.1477e-04, 5.2040e-04, 1.9413e-02, 6.4561e-02,
        3.9990e-03, 1.9163e-02, 4.3470e-02, 1.0088e-02, 1.5544e-02, 2.9983e-02,
        5.5972e-01, 1.8648e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,035][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.3682, 0.0743, 0.0410, 0.0608, 0.0765, 0.0301, 0.0248, 0.0726, 0.0479,
        0.0315, 0.0324, 0.0316, 0.0514, 0.0571], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,036][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([3.8758e-08, 4.9353e-02, 2.1537e-02, 3.5200e-02, 4.8691e-02, 3.6964e-02,
        1.4496e-01, 3.8809e-02, 1.8586e-01, 1.1211e-01, 2.6052e-01, 1.0499e-02,
        2.2553e-02, 3.2944e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,037][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0131, 0.0866, 0.0757, 0.0750, 0.0740, 0.0753, 0.0733, 0.0787, 0.0762,
        0.0710, 0.0753, 0.0767, 0.0742, 0.0750], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,039][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1670, 0.5396, 0.0456, 0.0205, 0.0124, 0.0467, 0.0414, 0.0069, 0.0195,
        0.0168, 0.0180, 0.0580, 0.0066, 0.0009], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,043][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.9007, 0.0163, 0.0035, 0.0041, 0.0043, 0.0059, 0.0105, 0.0046, 0.0027,
        0.0149, 0.0024, 0.0065, 0.0173, 0.0063], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,046][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0877, 0.0592, 0.0722, 0.0783, 0.0788, 0.0712, 0.0556, 0.0714, 0.0716,
        0.0706, 0.0704, 0.0653, 0.0751, 0.0725], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,050][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0351, 0.0804, 0.0583, 0.0493, 0.0614, 0.0418, 0.0518, 0.0619, 0.0952,
        0.1202, 0.0899, 0.0541, 0.1686, 0.0321], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,051][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0096, 0.0760, 0.0513, 0.0647, 0.0352, 0.0173, 0.0061, 0.0311, 0.0627,
        0.0237, 0.0877, 0.1072, 0.1701, 0.2572], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,052][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.9823e-01, 1.3965e-04, 1.5844e-04, 2.3272e-04, 1.8148e-04, 1.0575e-04,
        1.0746e-04, 7.0678e-05, 7.4646e-05, 1.3658e-04, 9.7451e-05, 1.3614e-04,
        1.8311e-04, 1.4667e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,053][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([4.9299e-06, 1.0605e-01, 1.0880e-01, 8.8942e-03, 2.6318e-02, 6.3215e-02,
        2.0923e-02, 2.7637e-02, 3.2410e-01, 3.4168e-02, 7.2231e-02, 6.0374e-02,
        9.4185e-02, 5.3101e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,056][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0835, 0.0802, 0.0613, 0.0620, 0.0546, 0.0802, 0.0721, 0.0620, 0.0798,
        0.0784, 0.0664, 0.0822, 0.0637, 0.0735], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,059][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ give] are: tensor([2.8185e-02, 1.5441e-05, 4.0951e-05, 2.6569e-05, 1.3257e-03, 2.4338e-03,
        1.1894e-04, 1.5354e-03, 2.6462e-03, 3.9827e-04, 1.2664e-03, 1.9338e-03,
        1.0201e-01, 9.2506e-02, 7.6556e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,063][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0820, 0.1229, 0.0364, 0.1036, 0.0689, 0.0277, 0.0859, 0.0881, 0.0566,
        0.0611, 0.0493, 0.0604, 0.0534, 0.0433, 0.0604], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,065][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ give] are: tensor([5.1092e-08, 2.0797e-01, 3.0217e-02, 6.9488e-02, 2.0330e-02, 5.8871e-02,
        1.5985e-01, 3.7198e-02, 9.4812e-02, 6.0856e-02, 2.1061e-01, 2.1426e-02,
        5.3317e-03, 1.7598e-02, 5.4306e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,066][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0116, 0.0807, 0.0703, 0.0695, 0.0684, 0.0700, 0.0678, 0.0733, 0.0710,
        0.0656, 0.0703, 0.0716, 0.0689, 0.0699, 0.0711], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,067][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.3247, 0.1837, 0.1842, 0.0326, 0.0145, 0.0702, 0.0207, 0.0208, 0.0256,
        0.0049, 0.0240, 0.0309, 0.0257, 0.0046, 0.0331], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,068][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.9300, 0.0104, 0.0034, 0.0023, 0.0025, 0.0049, 0.0050, 0.0039, 0.0022,
        0.0071, 0.0020, 0.0043, 0.0102, 0.0034, 0.0084], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,071][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0714, 0.0590, 0.0703, 0.0734, 0.0710, 0.0674, 0.0520, 0.0653, 0.0696,
        0.0669, 0.0687, 0.0637, 0.0684, 0.0718, 0.0610], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,074][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0802, 0.0540, 0.0490, 0.0378, 0.0524, 0.0567, 0.0562, 0.0683, 0.0745,
        0.0949, 0.0866, 0.0510, 0.1324, 0.0356, 0.0705], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,077][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0091, 0.0760, 0.0414, 0.0553, 0.0238, 0.0117, 0.0041, 0.0222, 0.0466,
        0.0159, 0.0680, 0.0788, 0.1161, 0.2127, 0.2182], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,080][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ give] are: tensor([9.9820e-01, 1.2626e-04, 1.5111e-04, 1.9737e-04, 1.5768e-04, 9.9545e-05,
        9.4520e-05, 6.2243e-05, 7.1063e-05, 1.1573e-04, 9.3406e-05, 1.2750e-04,
        1.6465e-04, 1.4972e-04, 1.8956e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,081][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ give] are: tensor([9.5236e-06, 1.5210e-01, 1.3032e-01, 1.0808e-02, 7.9605e-03, 5.3650e-02,
        3.0270e-02, 4.6685e-02, 1.8864e-01, 7.8244e-02, 1.1160e-01, 6.2816e-02,
        2.7718e-02, 5.0413e-02, 4.8767e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,082][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0843, 0.0776, 0.0571, 0.0564, 0.0514, 0.0734, 0.0651, 0.0607, 0.0721,
        0.0745, 0.0628, 0.0770, 0.0580, 0.0664, 0.0632], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,083][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ it] are: tensor([5.2544e-03, 4.8893e-06, 2.6638e-05, 1.7139e-05, 1.5539e-03, 2.9403e-03,
        6.1588e-05, 1.0091e-03, 2.6322e-03, 1.5736e-04, 7.9421e-04, 4.3409e-04,
        2.6296e-02, 2.1949e-02, 9.3093e-01, 5.9409e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,085][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ it] are: tensor([0.0710, 0.0497, 0.0484, 0.0649, 0.0638, 0.0334, 0.0750, 0.0872, 0.0646,
        0.0558, 0.0574, 0.0417, 0.0560, 0.0854, 0.0744, 0.0712],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,087][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ it] are: tensor([3.2418e-08, 1.6213e-01, 3.8996e-02, 4.7436e-02, 4.7126e-02, 3.8437e-02,
        2.1035e-01, 5.6298e-02, 6.4777e-02, 7.5921e-02, 1.8764e-01, 1.2322e-02,
        1.2484e-02, 3.2960e-02, 1.1984e-02, 1.1505e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,092][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ it] are: tensor([0.0113, 0.0752, 0.0655, 0.0650, 0.0641, 0.0652, 0.0638, 0.0683, 0.0663,
        0.0617, 0.0655, 0.0667, 0.0643, 0.0649, 0.0663, 0.0660],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,095][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.1076, 0.2042, 0.1924, 0.0166, 0.0257, 0.0954, 0.0266, 0.0520, 0.0567,
        0.0082, 0.0643, 0.0284, 0.0241, 0.0313, 0.0510, 0.0156],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,097][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ it] are: tensor([0.8794, 0.0135, 0.0061, 0.0048, 0.0036, 0.0072, 0.0061, 0.0066, 0.0038,
        0.0121, 0.0049, 0.0059, 0.0157, 0.0072, 0.0172, 0.0057],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,098][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.0718, 0.0524, 0.0631, 0.0653, 0.0682, 0.0648, 0.0494, 0.0606, 0.0667,
        0.0642, 0.0643, 0.0605, 0.0657, 0.0686, 0.0583, 0.0561],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,099][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.0788, 0.0858, 0.0665, 0.0634, 0.0977, 0.0423, 0.0501, 0.0574, 0.0505,
        0.0757, 0.0678, 0.0441, 0.0877, 0.0286, 0.0811, 0.0225],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,100][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.0051, 0.0449, 0.0324, 0.0349, 0.0202, 0.0103, 0.0036, 0.0193, 0.0440,
        0.0148, 0.0664, 0.0607, 0.1065, 0.1836, 0.2099, 0.1433],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,101][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ it] are: tensor([9.9745e-01, 1.6277e-04, 1.9409e-04, 2.5765e-04, 2.2027e-04, 1.2258e-04,
        1.1625e-04, 8.0674e-05, 8.9877e-05, 1.5511e-04, 1.1622e-04, 1.5620e-04,
        2.3555e-04, 1.9209e-04, 2.4251e-04, 2.0374e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,103][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ it] are: tensor([3.0286e-06, 1.2646e-01, 9.2015e-02, 1.6719e-02, 2.0050e-02, 5.2997e-02,
        2.2984e-02, 4.3518e-02, 1.2840e-01, 6.5830e-02, 6.1884e-02, 3.1249e-02,
        4.0017e-02, 1.3081e-01, 1.3008e-01, 3.6982e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,107][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ it] are: tensor([0.0620, 0.0734, 0.0561, 0.0552, 0.0496, 0.0685, 0.0604, 0.0592, 0.0671,
        0.0667, 0.0610, 0.0699, 0.0580, 0.0668, 0.0612, 0.0649],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,110][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([3.7464e-03, 1.2031e-05, 2.4358e-05, 2.2941e-05, 1.4886e-03, 4.6382e-03,
        1.8147e-04, 9.9923e-04, 3.9678e-03, 4.6441e-04, 8.7264e-04, 1.1791e-03,
        5.4070e-02, 1.6440e-02, 8.6918e-01, 2.7418e-02, 1.5296e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,112][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.2679, 0.0774, 0.0378, 0.0560, 0.0680, 0.0285, 0.0265, 0.0610, 0.0479,
        0.0316, 0.0334, 0.0302, 0.0455, 0.0445, 0.0477, 0.0541, 0.0421],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,113][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.7011e-08, 5.6117e-02, 1.2401e-02, 2.8060e-02, 2.7916e-02, 3.4621e-02,
        1.4337e-01, 2.6624e-02, 1.8465e-01, 1.3452e-01, 2.7868e-01, 1.1686e-02,
        1.4169e-02, 2.2045e-02, 8.1214e-03, 1.5991e-03, 1.5431e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,114][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0107, 0.0705, 0.0616, 0.0612, 0.0603, 0.0613, 0.0598, 0.0641, 0.0622,
        0.0580, 0.0613, 0.0626, 0.0605, 0.0611, 0.0624, 0.0618, 0.0606],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,117][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1304, 0.5527, 0.0463, 0.0170, 0.0102, 0.0497, 0.0429, 0.0059, 0.0221,
        0.0183, 0.0195, 0.0550, 0.0055, 0.0009, 0.0184, 0.0044, 0.0007],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,119][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.8205, 0.0220, 0.0051, 0.0056, 0.0063, 0.0089, 0.0147, 0.0070, 0.0043,
        0.0210, 0.0037, 0.0082, 0.0227, 0.0087, 0.0255, 0.0072, 0.0087],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,123][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0784, 0.0503, 0.0599, 0.0642, 0.0649, 0.0603, 0.0471, 0.0598, 0.0610,
        0.0599, 0.0589, 0.0552, 0.0623, 0.0601, 0.0543, 0.0508, 0.0525],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,128][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0228, 0.0802, 0.0466, 0.0447, 0.0565, 0.0382, 0.0460, 0.0556, 0.0840,
        0.1217, 0.0795, 0.0481, 0.1384, 0.0245, 0.0429, 0.0425, 0.0277],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,129][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0045, 0.0418, 0.0281, 0.0361, 0.0192, 0.0093, 0.0031, 0.0166, 0.0347,
        0.0126, 0.0496, 0.0591, 0.0895, 0.1419, 0.1685, 0.1231, 0.1620],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,129][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.9805e-01, 1.2435e-04, 1.3762e-04, 1.9901e-04, 1.5590e-04, 8.9962e-05,
        9.0479e-05, 5.7711e-05, 6.2872e-05, 1.1526e-04, 8.1249e-05, 1.1414e-04,
        1.6115e-04, 1.2492e-04, 1.5788e-04, 1.5311e-04, 1.2846e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,130][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([8.9435e-06, 9.3050e-02, 6.9914e-02, 6.1651e-03, 1.3798e-02, 4.7424e-02,
        1.7309e-02, 2.1342e-02, 2.4048e-01, 3.0283e-02, 6.7215e-02, 4.6463e-02,
        5.5783e-02, 3.1953e-02, 8.0614e-02, 1.2857e-01, 4.9623e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,133][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0632, 0.0648, 0.0497, 0.0511, 0.0452, 0.0665, 0.0591, 0.0511, 0.0644,
        0.0620, 0.0542, 0.0664, 0.0518, 0.0599, 0.0571, 0.0613, 0.0722],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,211][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:37,212][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,213][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,214][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,214][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,215][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,216][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,216][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,217][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,218][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,218][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,219][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,220][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,222][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Sara] are: tensor([0.7635, 0.2365], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,223][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Sara] are: tensor([0.3340, 0.6660], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,224][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Sara] are: tensor([1.7050e-04, 9.9983e-01], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,226][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Sara] are: tensor([0.5134, 0.4866], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,228][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Sara] are: tensor([0.8279, 0.1721], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,229][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Sara] are: tensor([0.7362, 0.2638], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,231][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Sara] are: tensor([0.7870, 0.2130], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,232][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Sara] are: tensor([0.1735, 0.8265], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,234][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Sara] are: tensor([0.6416, 0.3584], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,235][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Sara] are: tensor([0.2064, 0.7936], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,237][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Sara] are: tensor([4.1717e-04, 9.9958e-01], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,238][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Sara] are: tensor([0.7570, 0.2430], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,240][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1977, 0.2644, 0.5379], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,241][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.5284, 0.3748, 0.0968], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,242][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([1.3103e-04, 5.5669e-01, 4.4317e-01], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,243][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3736, 0.2133, 0.4131], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,243][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.7760, 0.0870, 0.1370], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,244][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.7783, 0.1392, 0.0825], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,246][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.5885, 0.2253, 0.1862], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,247][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1204, 0.5873, 0.2923], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,249][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2553, 0.1931, 0.5516], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,250][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0853, 0.3287, 0.5860], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,252][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([1.0285e-04, 7.4457e-01, 2.5533e-01], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,253][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2639, 0.4290, 0.3070], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,255][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Kenneth] are: tensor([0.1510, 0.0725, 0.5884, 0.1881], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,256][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Kenneth] are: tensor([0.4504, 0.2361, 0.0812, 0.2323], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,257][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Kenneth] are: tensor([5.0449e-05, 3.6776e-01, 3.9472e-01, 2.3747e-01], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,259][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Kenneth] are: tensor([0.3137, 0.1058, 0.2410, 0.3396], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,261][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Kenneth] are: tensor([0.5712, 0.1196, 0.2605, 0.0486], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,262][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Kenneth] are: tensor([0.6460, 0.1247, 0.1020, 0.1273], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,264][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Kenneth] are: tensor([0.4421, 0.1836, 0.1761, 0.1982], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,265][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Kenneth] are: tensor([0.0459, 0.2980, 0.3742, 0.2820], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,267][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Kenneth] are: tensor([0.3637, 0.1171, 0.2724, 0.2468], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,269][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Kenneth] are: tensor([0.0574, 0.1331, 0.3835, 0.4260], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,270][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Kenneth] are: tensor([2.9846e-04, 4.2076e-01, 3.3829e-01, 2.4065e-01], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,271][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Kenneth] are: tensor([0.2062, 0.1917, 0.2044, 0.3977], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,273][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.1436, 0.0449, 0.1799, 0.2550, 0.3766], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:37,274][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.3451, 0.1918, 0.1179, 0.2241, 0.1211], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:37,275][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([9.4918e-05, 4.8432e-01, 3.2889e-01, 1.0721e-01, 7.9492e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:37,276][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.2031, 0.0817, 0.1860, 0.2834, 0.2457], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:37,276][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.7560, 0.0433, 0.1078, 0.0222, 0.0708], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:37,277][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.5738, 0.0819, 0.0894, 0.1365, 0.1184], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:37,279][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.3836, 0.1457, 0.1567, 0.1362, 0.1777], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:37,280][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.0962, 0.2717, 0.2187, 0.1960, 0.2174], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:37,282][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.0732, 0.0631, 0.2375, 0.1677, 0.4585], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:37,284][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.0178, 0.1031, 0.2273, 0.3342, 0.3176], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:37,285][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([1.5763e-04, 4.6183e-01, 3.0881e-01, 1.5786e-01, 7.1346e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:37,286][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.2041, 0.2564, 0.1927, 0.1055, 0.2413], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:37,288][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0833, 0.0243, 0.0821, 0.1221, 0.5014, 0.1868], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:37,290][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.4140, 0.1905, 0.0859, 0.1630, 0.0885, 0.0581], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:37,291][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([4.8380e-05, 3.3783e-01, 2.9623e-01, 1.0292e-01, 1.5344e-01, 1.0953e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:37,293][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1379, 0.0601, 0.1386, 0.2681, 0.2433, 0.1520], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:37,294][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.6915, 0.0376, 0.1138, 0.0262, 0.0656, 0.0653], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:37,296][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.6421, 0.0575, 0.0463, 0.1131, 0.1083, 0.0327], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:37,298][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.4344, 0.1061, 0.1183, 0.0987, 0.1510, 0.0915], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:37,299][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1465, 0.2208, 0.1990, 0.1475, 0.1978, 0.0883], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:37,301][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0640, 0.0378, 0.0923, 0.1342, 0.5261, 0.1457], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:37,303][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0171, 0.0751, 0.1290, 0.3394, 0.3021, 0.1372], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:37,304][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([6.3178e-05, 3.3979e-01, 3.0487e-01, 1.4026e-01, 1.1510e-01, 9.9916e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:37,306][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1678, 0.1233, 0.1891, 0.1426, 0.2557, 0.1216], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:37,307][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.0194, 0.0293, 0.0837, 0.1201, 0.4143, 0.2535, 0.0797],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:37,308][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.3151, 0.1395, 0.1163, 0.0998, 0.1453, 0.0704, 0.1136],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:37,309][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([1.0720e-05, 2.0373e-01, 2.2271e-01, 1.0864e-01, 7.4103e-02, 8.9026e-02,
        3.0179e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:37,310][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.0693, 0.0622, 0.1440, 0.2234, 0.2146, 0.1548, 0.1318],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:37,310][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.0752, 0.0909, 0.2644, 0.0521, 0.1831, 0.3202, 0.0141],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:37,312][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.5112, 0.0657, 0.0600, 0.1227, 0.1392, 0.0431, 0.0582],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:37,314][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.3743, 0.0814, 0.1057, 0.0793, 0.1625, 0.1143, 0.0825],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:37,315][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.0815, 0.1522, 0.1884, 0.1639, 0.2072, 0.1133, 0.0934],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:37,317][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.0269, 0.0365, 0.0922, 0.1203, 0.4180, 0.2185, 0.0875],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:37,319][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.0073, 0.0756, 0.1177, 0.3837, 0.2328, 0.1270, 0.0559],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:37,320][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([5.5071e-05, 3.7278e-01, 2.2798e-01, 2.1368e-01, 5.3893e-02, 9.5182e-02,
        3.6427e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:37,321][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.0716, 0.1659, 0.2126, 0.1880, 0.1567, 0.1318, 0.0734],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:37,323][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.1523, 0.0072, 0.0395, 0.0612, 0.3705, 0.1724, 0.0790, 0.1179],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:37,325][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.3954, 0.1892, 0.0672, 0.1110, 0.0810, 0.0438, 0.0536, 0.0588],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:37,326][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([1.5063e-05, 2.5391e-01, 1.7253e-01, 6.9520e-02, 6.0928e-02, 7.7856e-02,
        2.7116e-01, 9.4075e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:37,328][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.1331, 0.0447, 0.0895, 0.2174, 0.1825, 0.1309, 0.0577, 0.1442],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:37,329][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.4368, 0.0459, 0.1254, 0.0378, 0.0946, 0.0834, 0.0082, 0.1679],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:37,331][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.6182, 0.0489, 0.0334, 0.0747, 0.1141, 0.0331, 0.0356, 0.0420],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:37,333][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.4055, 0.0684, 0.0916, 0.0846, 0.1274, 0.0728, 0.0650, 0.0847],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:37,334][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.1214, 0.1855, 0.1541, 0.1197, 0.1822, 0.0683, 0.0805, 0.0883],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:37,336][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0404, 0.0188, 0.0376, 0.0523, 0.5368, 0.1594, 0.0481, 0.1066],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:37,338][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0172, 0.0670, 0.0733, 0.4037, 0.2205, 0.0922, 0.0349, 0.0911],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:37,339][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([4.6714e-05, 3.1672e-01, 2.2144e-01, 1.0303e-01, 7.0295e-02, 1.2979e-01,
        3.4469e-02, 1.2422e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:37,341][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.1993, 0.1191, 0.1281, 0.0925, 0.1593, 0.1357, 0.0777, 0.0884],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:37,341][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.2516, 0.0049, 0.0296, 0.0259, 0.1434, 0.0688, 0.0444, 0.1691, 0.2624],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:37,342][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.4350, 0.1259, 0.0628, 0.0991, 0.0544, 0.0308, 0.0702, 0.0731, 0.0487],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:37,343][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([1.3157e-05, 2.9033e-01, 8.1756e-02, 7.5683e-02, 4.2754e-02, 3.4488e-02,
        2.1478e-01, 8.5140e-02, 1.7505e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:37,344][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.2369, 0.0302, 0.0691, 0.1226, 0.1242, 0.0834, 0.0520, 0.1157, 0.1659],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:37,345][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.7282, 0.0168, 0.0431, 0.0107, 0.0283, 0.0220, 0.0029, 0.0825, 0.0656],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:37,347][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.7467, 0.0308, 0.0215, 0.0535, 0.0556, 0.0156, 0.0205, 0.0391, 0.0167],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:37,349][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.4687, 0.0597, 0.0751, 0.0631, 0.1035, 0.0583, 0.0637, 0.0614, 0.0465],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:37,350][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1213, 0.1043, 0.1261, 0.0984, 0.1729, 0.0636, 0.1053, 0.1048, 0.1032],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:37,352][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1072, 0.0184, 0.0515, 0.0640, 0.2598, 0.0709, 0.0305, 0.1319, 0.2659],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:37,354][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0315, 0.0447, 0.0750, 0.1919, 0.1909, 0.0830, 0.0325, 0.1870, 0.1635],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:37,355][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([3.9063e-05, 3.4053e-01, 1.4740e-01, 1.7882e-01, 4.8404e-02, 5.0315e-02,
        2.2172e-02, 7.2386e-02, 1.3994e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:37,357][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1652, 0.1040, 0.0982, 0.1032, 0.1525, 0.0866, 0.0654, 0.0971, 0.1278],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:37,358][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ garden] are: tensor([0.0354, 0.0058, 0.0260, 0.0262, 0.1140, 0.0650, 0.0221, 0.1754, 0.4408,
        0.0894], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:37,360][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ garden] are: tensor([0.2382, 0.1318, 0.0915, 0.1463, 0.0844, 0.0348, 0.0418, 0.0807, 0.0764,
        0.0742], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:37,361][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ garden] are: tensor([1.8463e-06, 6.0158e-02, 6.8368e-02, 4.1111e-02, 2.4216e-02, 3.0291e-02,
        1.2057e-01, 9.3787e-02, 3.0449e-01, 2.5701e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:37,363][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ garden] are: tensor([0.0752, 0.0339, 0.0707, 0.1313, 0.1063, 0.0634, 0.0363, 0.1051, 0.2027,
        0.1751], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:37,365][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ garden] are: tensor([0.0810, 0.0385, 0.0884, 0.0203, 0.0550, 0.1093, 0.0072, 0.2182, 0.3780,
        0.0040], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:37,367][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ garden] are: tensor([0.5458, 0.0526, 0.0490, 0.1076, 0.0912, 0.0222, 0.0191, 0.0455, 0.0232,
        0.0438], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:37,368][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ garden] are: tensor([0.3207, 0.0685, 0.0760, 0.0775, 0.1295, 0.0777, 0.0568, 0.0859, 0.0490,
        0.0583], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:37,370][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ garden] are: tensor([0.0162, 0.0690, 0.1068, 0.0821, 0.1264, 0.0510, 0.0568, 0.1376, 0.1322,
        0.2218], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:37,372][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ garden] are: tensor([0.0230, 0.0147, 0.0307, 0.0560, 0.2430, 0.0601, 0.0218, 0.1816, 0.2948,
        0.0744], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:37,373][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ garden] are: tensor([0.0082, 0.0380, 0.0644, 0.1875, 0.1263, 0.0548, 0.0236, 0.1511, 0.1919,
        0.1541], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:37,374][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ garden] are: tensor([1.0786e-05, 1.5605e-01, 1.3820e-01, 1.0744e-01, 4.6271e-02, 7.0873e-02,
        3.3823e-02, 1.0411e-01, 2.9613e-01, 4.7102e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:37,375][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ garden] are: tensor([0.0548, 0.0797, 0.1148, 0.1020, 0.0938, 0.1017, 0.0598, 0.1242, 0.1552,
        0.1141], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:37,376][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4231, 0.0037, 0.0166, 0.0170, 0.0708, 0.0538, 0.0192, 0.0460, 0.1530,
        0.0587, 0.1382], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:37,377][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.5307, 0.0679, 0.0459, 0.0531, 0.0589, 0.0194, 0.0364, 0.0478, 0.0461,
        0.0532, 0.0406], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:37,378][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([5.8864e-06, 7.5576e-02, 5.3688e-02, 3.6763e-02, 2.3351e-02, 3.0690e-02,
        1.0701e-01, 6.1748e-02, 2.2476e-01, 1.9290e-01, 1.9352e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:37,380][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1782, 0.0156, 0.0442, 0.0735, 0.0806, 0.0610, 0.0266, 0.0795, 0.1332,
        0.0875, 0.2201], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:37,382][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.4176, 0.0190, 0.0471, 0.0142, 0.0395, 0.0400, 0.0032, 0.0953, 0.1410,
        0.0024, 0.1809], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:37,383][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.7990, 0.0189, 0.0137, 0.0385, 0.0412, 0.0095, 0.0120, 0.0208, 0.0093,
        0.0195, 0.0176], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:37,385][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3453, 0.0578, 0.0776, 0.0662, 0.1158, 0.0634, 0.0464, 0.0745, 0.0503,
        0.0546, 0.0481], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:37,387][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0379, 0.0740, 0.0682, 0.0716, 0.1011, 0.0572, 0.0639, 0.0824, 0.1224,
        0.1796, 0.1418], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:37,389][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0866, 0.0130, 0.0363, 0.0615, 0.1734, 0.0627, 0.0229, 0.0849, 0.2320,
        0.0532, 0.1736], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:37,390][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0244, 0.0292, 0.0394, 0.1466, 0.0852, 0.0445, 0.0157, 0.0760, 0.1234,
        0.1340, 0.2815], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:37,391][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([1.8653e-05, 2.0807e-01, 5.2772e-02, 1.2900e-01, 2.7849e-02, 5.7981e-02,
        1.4131e-02, 1.0948e-01, 2.2868e-01, 4.8655e-02, 1.2336e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:37,393][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0923, 0.0887, 0.0694, 0.1080, 0.1144, 0.0851, 0.0530, 0.0751, 0.1440,
        0.0691, 0.1010], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:37,395][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Sara] are: tensor([0.2498, 0.0022, 0.0228, 0.0195, 0.0545, 0.0403, 0.0108, 0.0572, 0.1594,
        0.0393, 0.2395, 0.1047], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,397][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Sara] are: tensor([0.1271, 0.1659, 0.0682, 0.1531, 0.0776, 0.0278, 0.0682, 0.0576, 0.0640,
        0.0774, 0.0470, 0.0661], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,398][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Sara] are: tensor([2.4372e-05, 1.8683e-01, 8.5566e-02, 7.4412e-02, 3.6585e-02, 2.3017e-02,
        7.6052e-02, 4.6972e-02, 1.3082e-01, 1.5530e-01, 1.6604e-01, 1.8386e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,400][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Sara] are: tensor([0.1338, 0.0159, 0.0315, 0.0715, 0.0480, 0.0336, 0.0209, 0.0426, 0.1045,
        0.0749, 0.2268, 0.1960], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,402][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Sara] are: tensor([0.3859, 0.0241, 0.0430, 0.0128, 0.0353, 0.0528, 0.0029, 0.0989, 0.1654,
        0.0016, 0.1590, 0.0182], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,403][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Sara] are: tensor([0.6554, 0.0281, 0.0221, 0.0396, 0.0419, 0.0149, 0.0233, 0.0418, 0.0180,
        0.0302, 0.0333, 0.0514], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,405][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Sara] are: tensor([0.3093, 0.0672, 0.0750, 0.0648, 0.0839, 0.0539, 0.0620, 0.0561, 0.0455,
        0.0688, 0.0469, 0.0666], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,407][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Sara] are: tensor([0.0306, 0.0577, 0.0711, 0.0743, 0.0848, 0.0388, 0.0843, 0.0564, 0.1038,
        0.1913, 0.1422, 0.0647], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,408][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Sara] are: tensor([0.1373, 0.0112, 0.0300, 0.0447, 0.0919, 0.0384, 0.0193, 0.0470, 0.1600,
        0.0480, 0.1721, 0.2001], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,409][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Sara] are: tensor([0.0188, 0.0164, 0.0322, 0.0833, 0.0871, 0.0259, 0.0161, 0.0700, 0.0818,
        0.0983, 0.2524, 0.2175], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,410][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Sara] are: tensor([6.3066e-05, 2.5376e-01, 9.1807e-02, 1.0469e-01, 3.3613e-02, 3.2600e-02,
        1.9742e-02, 5.5697e-02, 1.8651e-01, 4.6400e-02, 1.1831e-01, 5.6812e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,411][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Sara] are: tensor([0.1250, 0.0685, 0.0673, 0.0868, 0.1198, 0.0799, 0.0613, 0.0780, 0.0918,
        0.0950, 0.0721, 0.0545], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,412][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.1086, 0.0014, 0.0061, 0.0082, 0.0247, 0.0171, 0.0041, 0.0143, 0.0752,
        0.0136, 0.0818, 0.0652, 0.5799], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,414][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.1863, 0.1104, 0.0654, 0.0658, 0.0675, 0.0457, 0.0351, 0.0791, 0.0698,
        0.0727, 0.0645, 0.0521, 0.0856], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,415][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([7.5793e-06, 8.3002e-02, 8.2851e-02, 2.6639e-02, 4.2042e-02, 3.0459e-02,
        1.0372e-01, 7.8189e-02, 1.0285e-01, 9.9732e-02, 2.6417e-01, 2.5475e-02,
        6.0858e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,417][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.1457, 0.0085, 0.0253, 0.0346, 0.0359, 0.0232, 0.0124, 0.0373, 0.0696,
        0.0458, 0.1369, 0.1164, 0.3086], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,419][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.2161, 0.0235, 0.0610, 0.0177, 0.0450, 0.0541, 0.0040, 0.0985, 0.1629,
        0.0029, 0.2437, 0.0339, 0.0366], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,420][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.6120, 0.0140, 0.0175, 0.0288, 0.0375, 0.0118, 0.0079, 0.0276, 0.0174,
        0.0202, 0.0202, 0.0250, 0.1603], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,422][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.2113, 0.0568, 0.0673, 0.0477, 0.1066, 0.0724, 0.0470, 0.0611, 0.0619,
        0.0580, 0.0620, 0.0594, 0.0883], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,424][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0209, 0.0607, 0.0669, 0.0358, 0.0902, 0.0533, 0.0545, 0.0723, 0.1016,
        0.1147, 0.1387, 0.0628, 0.1275], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,426][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0333, 0.0031, 0.0109, 0.0092, 0.0440, 0.0250, 0.0049, 0.0246, 0.0946,
        0.0090, 0.0712, 0.0523, 0.6181], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,427][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0162, 0.0108, 0.0228, 0.0487, 0.0456, 0.0287, 0.0067, 0.0399, 0.0779,
        0.0499, 0.1891, 0.1437, 0.3200], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,429][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([7.3459e-05, 9.1838e-02, 8.0803e-02, 4.4255e-02, 4.4997e-02, 6.1663e-02,
        1.2748e-02, 1.0105e-01, 1.2073e-01, 5.1501e-02, 1.2311e-01, 7.5712e-02,
        1.9151e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,430][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0370, 0.0390, 0.1310, 0.0371, 0.0899, 0.0977, 0.0403, 0.0926, 0.1278,
        0.0419, 0.1406, 0.0508, 0.0743], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,432][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.3404, 0.0005, 0.0021, 0.0021, 0.0095, 0.0079, 0.0027, 0.0036, 0.0206,
        0.0065, 0.0232, 0.0196, 0.3118, 0.2496], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,434][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.3682, 0.0743, 0.0410, 0.0608, 0.0765, 0.0301, 0.0248, 0.0726, 0.0479,
        0.0315, 0.0324, 0.0316, 0.0514, 0.0571], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,435][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([3.0414e-06, 5.5568e-02, 4.8689e-02, 2.6816e-02, 3.6621e-02, 2.3844e-02,
        8.5576e-02, 5.6101e-02, 1.9042e-01, 1.2066e-01, 2.2903e-01, 2.2336e-02,
        4.3920e-02, 6.0417e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,437][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1997, 0.0073, 0.0165, 0.0305, 0.0274, 0.0174, 0.0062, 0.0212, 0.0376,
        0.0223, 0.0705, 0.0661, 0.1474, 0.3297], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,439][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.4574, 0.0146, 0.0241, 0.0091, 0.0122, 0.0114, 0.0018, 0.0281, 0.0351,
        0.0016, 0.0769, 0.0206, 0.0151, 0.2920], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,440][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.6940, 0.0113, 0.0117, 0.0261, 0.0212, 0.0082, 0.0079, 0.0141, 0.0088,
        0.0093, 0.0113, 0.0168, 0.1040, 0.0553], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,441][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.3008, 0.0568, 0.0569, 0.0473, 0.0865, 0.0552, 0.0410, 0.0538, 0.0479,
        0.0434, 0.0384, 0.0512, 0.0724, 0.0484], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,442][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0351, 0.0804, 0.0583, 0.0493, 0.0614, 0.0418, 0.0518, 0.0619, 0.0952,
        0.1202, 0.0899, 0.0541, 0.1686, 0.0321], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,443][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0363, 0.0023, 0.0052, 0.0064, 0.0344, 0.0113, 0.0028, 0.0103, 0.0396,
        0.0060, 0.0352, 0.0387, 0.5232, 0.2482], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,445][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0235, 0.0085, 0.0146, 0.0367, 0.0300, 0.0155, 0.0049, 0.0249, 0.0429,
        0.0291, 0.0922, 0.0929, 0.2296, 0.3549], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,446][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.8146e-05, 8.9127e-02, 6.1771e-02, 4.4907e-02, 4.1030e-02, 5.3018e-02,
        1.1027e-02, 6.9801e-02, 2.0997e-01, 3.6086e-02, 9.7698e-02, 8.4286e-02,
        1.2464e-01, 7.6622e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,448][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0546, 0.0672, 0.0968, 0.0686, 0.0733, 0.0692, 0.0318, 0.0591, 0.1264,
        0.0425, 0.0887, 0.0661, 0.1039, 0.0519], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,449][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([8.1836e-02, 1.6759e-04, 8.4101e-04, 6.1422e-04, 2.6807e-03, 1.9251e-03,
        4.9867e-04, 1.4391e-03, 8.1207e-03, 1.5452e-03, 1.0482e-02, 7.7943e-03,
        1.5626e-01, 3.1573e-01, 4.1006e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,450][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0820, 0.1229, 0.0364, 0.1036, 0.0689, 0.0277, 0.0859, 0.0881, 0.0566,
        0.0611, 0.0493, 0.0604, 0.0534, 0.0433, 0.0604], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,452][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([1.2191e-05, 1.4757e-01, 7.4394e-02, 3.5716e-02, 1.7638e-02, 2.4617e-02,
        1.0559e-01, 5.2886e-02, 1.1004e-01, 1.3173e-01, 1.9487e-01, 5.0283e-02,
        1.3377e-02, 2.9085e-02, 1.2191e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,454][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.1067, 0.0040, 0.0072, 0.0127, 0.0073, 0.0084, 0.0029, 0.0082, 0.0190,
        0.0100, 0.0360, 0.0389, 0.0675, 0.2672, 0.4040], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,455][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.4797, 0.0095, 0.0167, 0.0060, 0.0117, 0.0103, 0.0013, 0.0228, 0.0341,
        0.0009, 0.0508, 0.0101, 0.0107, 0.2956, 0.0398], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,457][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.6523, 0.0172, 0.0096, 0.0242, 0.0199, 0.0081, 0.0095, 0.0109, 0.0086,
        0.0152, 0.0121, 0.0263, 0.0797, 0.0713, 0.0350], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,459][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.2590, 0.0650, 0.0602, 0.0496, 0.0692, 0.0548, 0.0428, 0.0448, 0.0534,
        0.0464, 0.0427, 0.0497, 0.0559, 0.0605, 0.0457], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,461][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0802, 0.0540, 0.0490, 0.0378, 0.0524, 0.0567, 0.0562, 0.0683, 0.0745,
        0.0949, 0.0866, 0.0510, 0.1324, 0.0356, 0.0705], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,463][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0605, 0.0022, 0.0041, 0.0040, 0.0087, 0.0052, 0.0013, 0.0030, 0.0169,
        0.0022, 0.0178, 0.0220, 0.1545, 0.1530, 0.5447], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,464][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0158, 0.0061, 0.0103, 0.0145, 0.0131, 0.0093, 0.0024, 0.0110, 0.0248,
        0.0110, 0.0568, 0.0520, 0.0984, 0.2651, 0.4094], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,466][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([4.7447e-05, 1.4666e-01, 7.7541e-02, 6.3612e-02, 1.7257e-02, 4.4888e-02,
        1.4795e-02, 8.3672e-02, 1.3250e-01, 6.2162e-02, 1.2022e-01, 8.4543e-02,
        4.2493e-02, 6.3713e-02, 4.5909e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,468][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0668, 0.0987, 0.0838, 0.0430, 0.0579, 0.0763, 0.0249, 0.0610, 0.1103,
        0.0443, 0.0893, 0.0803, 0.0727, 0.0456, 0.0450], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,469][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([6.1921e-02, 9.9921e-05, 6.0257e-04, 4.8652e-04, 3.2825e-03, 1.8455e-03,
        2.8643e-04, 1.0092e-03, 7.1122e-03, 7.8837e-04, 7.8411e-03, 3.3840e-03,
        8.6180e-02, 1.3535e-01, 6.5045e-01, 3.9353e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,471][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([0.0710, 0.0497, 0.0484, 0.0649, 0.0638, 0.0334, 0.0750, 0.0872, 0.0646,
        0.0558, 0.0574, 0.0417, 0.0560, 0.0854, 0.0744, 0.0712],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,472][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([8.1942e-06, 1.0772e-01, 1.1559e-01, 2.8859e-02, 4.5872e-02, 1.9091e-02,
        1.2261e-01, 7.3730e-02, 6.7873e-02, 1.3677e-01, 1.5480e-01, 1.6225e-02,
        2.9989e-02, 5.2480e-02, 2.4958e-02, 3.4221e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,473][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([0.0742, 0.0026, 0.0072, 0.0082, 0.0106, 0.0081, 0.0033, 0.0091, 0.0227,
        0.0078, 0.0340, 0.0276, 0.0781, 0.2325, 0.3822, 0.0919],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,474][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.1526, 0.0124, 0.0251, 0.0076, 0.0158, 0.0121, 0.0013, 0.0444, 0.0490,
        0.0008, 0.0627, 0.0137, 0.0147, 0.4916, 0.0686, 0.0276],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,475][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([0.5870, 0.0126, 0.0106, 0.0181, 0.0244, 0.0091, 0.0087, 0.0140, 0.0075,
        0.0100, 0.0122, 0.0163, 0.0853, 0.0790, 0.0673, 0.0379],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,476][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([0.3038, 0.0459, 0.0575, 0.0371, 0.0665, 0.0487, 0.0424, 0.0389, 0.0406,
        0.0505, 0.0383, 0.0507, 0.0389, 0.0550, 0.0414, 0.0437],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,478][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.0788, 0.0858, 0.0665, 0.0634, 0.0977, 0.0423, 0.0501, 0.0574, 0.0505,
        0.0757, 0.0678, 0.0441, 0.0877, 0.0286, 0.0811, 0.0225],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,479][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([1.0508e-02, 2.5321e-04, 1.6112e-03, 4.0040e-04, 5.6511e-03, 2.9141e-03,
        7.7207e-04, 2.1028e-03, 1.5930e-02, 1.3537e-03, 1.8047e-02, 4.1067e-03,
        9.5656e-02, 1.0349e-01, 7.0281e-01, 3.4396e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,481][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([0.0063, 0.0042, 0.0086, 0.0124, 0.0168, 0.0066, 0.0015, 0.0102, 0.0198,
        0.0110, 0.0422, 0.0328, 0.1416, 0.2366, 0.3581, 0.0913],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,482][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([2.0602e-05, 1.3780e-01, 5.5396e-02, 6.8361e-02, 3.0901e-02, 3.9548e-02,
        1.1234e-02, 7.7744e-02, 8.2439e-02, 4.9653e-02, 6.2358e-02, 4.5813e-02,
        5.5162e-02, 1.2420e-01, 1.0832e-01, 5.1049e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,484][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([0.0278, 0.0652, 0.0848, 0.0645, 0.0530, 0.0478, 0.0291, 0.0892, 0.0771,
        0.0653, 0.1083, 0.0533, 0.0816, 0.0761, 0.0439, 0.0330],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,485][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.6702e-01, 1.2548e-04, 5.0102e-04, 4.4650e-04, 2.7492e-03, 2.0202e-03,
        5.7385e-04, 8.1406e-04, 6.2808e-03, 1.2886e-03, 6.1106e-03, 4.0482e-03,
        1.1578e-01, 8.3129e-02, 3.8768e-01, 7.2291e-02, 1.4914e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,487][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.2679, 0.0774, 0.0378, 0.0560, 0.0680, 0.0285, 0.0265, 0.0610, 0.0479,
        0.0316, 0.0334, 0.0302, 0.0455, 0.0445, 0.0477, 0.0541, 0.0421],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,488][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.8678e-06, 5.3878e-02, 3.4028e-02, 2.2677e-02, 2.5807e-02, 2.1277e-02,
        8.3826e-02, 4.0562e-02, 1.7871e-01, 1.2144e-01, 2.3496e-01, 2.3208e-02,
        3.2009e-02, 4.0166e-02, 2.0745e-02, 1.3236e-02, 5.3479e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,490][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0958, 0.0033, 0.0064, 0.0116, 0.0112, 0.0069, 0.0025, 0.0075, 0.0160,
        0.0088, 0.0272, 0.0260, 0.0716, 0.1412, 0.2920, 0.0641, 0.2078],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,492][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2892, 0.0127, 0.0179, 0.0072, 0.0098, 0.0074, 0.0013, 0.0217, 0.0240,
        0.0012, 0.0506, 0.0152, 0.0118, 0.2007, 0.0513, 0.0254, 0.2525],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,494][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.6108, 0.0104, 0.0086, 0.0191, 0.0195, 0.0065, 0.0064, 0.0113, 0.0072,
        0.0078, 0.0092, 0.0138, 0.0943, 0.0488, 0.0310, 0.0262, 0.0690],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,496][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.2655, 0.0571, 0.0494, 0.0400, 0.0757, 0.0503, 0.0347, 0.0447, 0.0416,
        0.0358, 0.0293, 0.0434, 0.0595, 0.0364, 0.0430, 0.0524, 0.0413],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,497][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0228, 0.0802, 0.0466, 0.0447, 0.0565, 0.0382, 0.0460, 0.0556, 0.0840,
        0.1217, 0.0795, 0.0481, 0.1384, 0.0245, 0.0429, 0.0425, 0.0277],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,499][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.1470e-02, 6.1154e-04, 1.1337e-03, 1.5670e-03, 8.1264e-03, 2.2744e-03,
        4.2722e-04, 1.4939e-03, 8.0777e-03, 1.0687e-03, 7.2325e-03, 7.4011e-03,
        1.0767e-01, 5.7554e-02, 6.1775e-01, 3.9100e-02, 1.2704e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,501][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0141, 0.0043, 0.0059, 0.0141, 0.0124, 0.0058, 0.0017, 0.0083, 0.0165,
        0.0108, 0.0334, 0.0352, 0.1058, 0.1445, 0.2320, 0.1241, 0.2312],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,502][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.3865e-05, 7.3973e-02, 3.7483e-02, 3.2495e-02, 2.4604e-02, 3.7174e-02,
        7.8831e-03, 4.4183e-02, 1.3992e-01, 2.5757e-02, 7.3617e-02, 6.5962e-02,
        7.5481e-02, 4.4660e-02, 7.7818e-02, 1.5667e-01, 8.2302e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,504][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0452, 0.0664, 0.0721, 0.0609, 0.0621, 0.0583, 0.0292, 0.0566, 0.1069,
        0.0430, 0.0760, 0.0572, 0.0813, 0.0397, 0.0377, 0.0706, 0.0371],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,507][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:37,509][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[12842],
        [28291],
        [ 4061],
        [23795],
        [15840],
        [12437],
        [ 8496],
        [ 5675],
        [ 6168],
        [ 3515],
        [ 4200],
        [14226],
        [ 2667],
        [ 1726],
        [ 3925],
        [ 2338],
        [ 1699]], device='cuda:0')
[2024-07-24 10:29:37,511][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[15262],
        [41136],
        [ 9716],
        [38986],
        [25380],
        [19374],
        [12032],
        [11959],
        [ 9032],
        [11652],
        [ 9564],
        [27280],
        [ 5415],
        [ 5929],
        [ 8195],
        [ 4418],
        [ 5963]], device='cuda:0')
[2024-07-24 10:29:37,512][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[30671],
        [20066],
        [22505],
        [29990],
        [22527],
        [15791],
        [14980],
        [16397],
        [17500],
        [14996],
        [13528],
        [14315],
        [14341],
        [16094],
        [18602],
        [18529],
        [18652]], device='cuda:0')
[2024-07-24 10:29:37,514][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 8108],
        [33677],
        [31027],
        [45677],
        [45117],
        [43177],
        [37941],
        [39172],
        [38077],
        [41376],
        [32711],
        [40424],
        [36837],
        [34890],
        [37025],
        [33612],
        [33892]], device='cuda:0')
[2024-07-24 10:29:37,516][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[35813],
        [19644],
        [18243],
        [39328],
        [24396],
        [29473],
        [31779],
        [29374],
        [30486],
        [36260],
        [35936],
        [36362],
        [32485],
        [33549],
        [33274],
        [31259],
        [33821]], device='cuda:0')
[2024-07-24 10:29:37,518][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 6092],
        [10842],
        [12521],
        [10905],
        [11877],
        [12853],
        [12942],
        [13353],
        [13624],
        [13734],
        [13976],
        [14336],
        [14747],
        [15016],
        [15000],
        [15543],
        [15789]], device='cuda:0')
[2024-07-24 10:29:37,519][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[16477],
        [16711],
        [19181],
        [17725],
        [21789],
        [21734],
        [16961],
        [21540],
        [20899],
        [20168],
        [18541],
        [15213],
        [17310],
        [21982],
        [17788],
        [16825],
        [21687]], device='cuda:0')
[2024-07-24 10:29:37,521][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[41356],
        [40686],
        [34288],
        [36969],
        [35150],
        [39141],
        [32989],
        [34350],
        [37708],
        [39117],
        [37258],
        [38981],
        [34683],
        [27199],
        [31518],
        [22917],
        [16133]], device='cuda:0')
[2024-07-24 10:29:37,523][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[1901],
        [1185],
        [1483],
        [1445],
        [1401],
        [1371],
        [1211],
        [1252],
        [1269],
        [1160],
        [1149],
        [1096],
        [1041],
        [1014],
        [ 972],
        [ 977],
        [ 958]], device='cuda:0')
[2024-07-24 10:29:37,525][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[12360],
        [36307],
        [33873],
        [35123],
        [28837],
        [24631],
        [20153],
        [18430],
        [13019],
        [ 4621],
        [ 4934],
        [ 5112],
        [ 5864],
        [ 6357],
        [ 5063],
        [ 7090],
        [ 5359]], device='cuda:0')
[2024-07-24 10:29:37,527][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 8382],
        [ 7457],
        [ 8350],
        [11996],
        [ 9363],
        [ 9013],
        [ 8545],
        [ 8097],
        [ 7601],
        [ 7230],
        [ 5846],
        [ 6273],
        [ 5179],
        [ 5662],
        [ 5811],
        [ 6813],
        [ 7395]], device='cuda:0')
[2024-07-24 10:29:37,529][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[48474],
        [48477],
        [48490],
        [48484],
        [48503],
        [48507],
        [48512],
        [48488],
        [48489],
        [48494],
        [48488],
        [48490],
        [48507],
        [48492],
        [48493],
        [48507],
        [48495]], device='cuda:0')
[2024-07-24 10:29:37,531][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[18036],
        [22229],
        [16678],
        [16362],
        [16052],
        [14677],
        [20926],
        [16811],
        [20423],
        [14961],
        [19087],
        [16894],
        [10934],
        [10334],
        [13544],
        [16047],
        [10990]], device='cuda:0')
[2024-07-24 10:29:37,533][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[10842],
        [22048],
        [17123],
        [19507],
        [17639],
        [16484],
        [15046],
        [14937],
        [15069],
        [14885],
        [14573],
        [15364],
        [14782],
        [14845],
        [14923],
        [14834],
        [14779]], device='cuda:0')
[2024-07-24 10:29:37,534][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[7325],
        [2178],
        [2943],
        [1913],
        [4613],
        [6519],
        [7195],
        [3409],
        [4203],
        [1436],
        [3905],
        [2725],
        [3056],
        [2027],
        [2563],
        [3212],
        [1985]], device='cuda:0')
[2024-07-24 10:29:37,536][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[44752],
        [45406],
        [20038],
        [14077],
        [ 8320],
        [ 9493],
        [10178],
        [ 9968],
        [14547],
        [16827],
        [16409],
        [14624],
        [14542],
        [17130],
        [20050],
        [16920],
        [17707]], device='cuda:0')
[2024-07-24 10:29:37,538][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[29458],
        [13296],
        [13879],
        [14733],
        [16974],
        [16146],
        [19039],
        [18874],
        [21042],
        [19583],
        [19622],
        [19537],
        [17043],
        [16215],
        [18714],
        [16521],
        [14602]], device='cuda:0')
[2024-07-24 10:29:37,540][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[26169],
        [ 4269],
        [ 8424],
        [15024],
        [ 9933],
        [17150],
        [18906],
        [18884],
        [22129],
        [27974],
        [27282],
        [22655],
        [29970],
        [30087],
        [23726],
        [25383],
        [29140]], device='cuda:0')
[2024-07-24 10:29:37,542][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[17076],
        [17138],
        [20164],
        [ 9195],
        [13752],
        [10790],
        [10727],
        [ 7688],
        [ 9230],
        [ 6914],
        [11750],
        [17284],
        [17453],
        [ 8558],
        [ 8911],
        [ 8212],
        [ 9542]], device='cuda:0')
[2024-07-24 10:29:37,543][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[41427],
        [17277],
        [13394],
        [ 7913],
        [11453],
        [ 8297],
        [ 4131],
        [ 5992],
        [10758],
        [ 5038],
        [ 6028],
        [ 5804],
        [ 5436],
        [10911],
        [11473],
        [ 9762],
        [ 8971]], device='cuda:0')
[2024-07-24 10:29:37,545][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[41802],
        [32692],
        [39111],
        [31899],
        [27115],
        [31611],
        [27904],
        [37652],
        [42059],
        [37088],
        [43098],
        [44161],
        [39487],
        [44882],
        [45597],
        [43736],
        [44463]], device='cuda:0')
[2024-07-24 10:29:37,547][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[43387],
        [45117],
        [40318],
        [33677],
        [38849],
        [37389],
        [31272],
        [29325],
        [28388],
        [25351],
        [25110],
        [23853],
        [26673],
        [25939],
        [26496],
        [25872],
        [27434]], device='cuda:0')
[2024-07-24 10:29:37,548][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[23971],
        [ 5240],
        [ 5606],
        [ 5981],
        [10008],
        [11389],
        [12018],
        [13193],
        [14778],
        [15354],
        [14484],
        [13610],
        [15019],
        [15075],
        [14708],
        [14289],
        [13901]], device='cuda:0')
[2024-07-24 10:29:37,550][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[43721],
        [30150],
        [23731],
        [17333],
        [13461],
        [13495],
        [17080],
        [18876],
        [30219],
        [31332],
        [34154],
        [37063],
        [39050],
        [45204],
        [44444],
        [41844],
        [43220]], device='cuda:0')
[2024-07-24 10:29:37,552][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[20670],
        [12929],
        [26287],
        [27207],
        [28096],
        [26291],
        [24662],
        [22088],
        [18183],
        [14385],
        [15788],
        [16555],
        [16448],
        [15022],
        [20894],
        [19511],
        [17291]], device='cuda:0')
[2024-07-24 10:29:37,554][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[39810],
        [24983],
        [29220],
        [32192],
        [31309],
        [31793],
        [34015],
        [36998],
        [36370],
        [36745],
        [36595],
        [35743],
        [31663],
        [32655],
        [35278],
        [36030],
        [34998]], device='cuda:0')
[2024-07-24 10:29:37,556][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[33896],
        [11102],
        [10108],
        [ 5652],
        [11895],
        [15043],
        [12127],
        [17019],
        [15833],
        [15074],
        [13178],
        [13164],
        [15039],
        [12227],
        [11317],
        [11212],
        [10960]], device='cuda:0')
[2024-07-24 10:29:37,557][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 3268],
        [24237],
        [30726],
        [38620],
        [36342],
        [35989],
        [35648],
        [33340],
        [25671],
        [28657],
        [28003],
        [25852],
        [25925],
        [23899],
        [19601],
        [24247],
        [23997]], device='cuda:0')
[2024-07-24 10:29:37,559][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[35136],
        [49003],
        [47839],
        [47160],
        [47616],
        [46483],
        [47686],
        [47786],
        [47912],
        [48769],
        [46504],
        [47884],
        [48319],
        [48197],
        [48380],
        [47868],
        [48161]], device='cuda:0')
[2024-07-24 10:29:37,561][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551]], device='cuda:0')
[2024-07-24 10:29:37,651][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:37,652][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,653][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,654][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,655][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,657][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,658][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,659][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,660][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,661][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,662][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,664][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,674][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,675][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Sara] are: tensor([0.2248, 0.7752], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,676][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Sara] are: tensor([0.0806, 0.9194], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,678][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Sara] are: tensor([0.3085, 0.6915], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,679][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Sara] are: tensor([0.0394, 0.9606], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,680][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Sara] are: tensor([0.0139, 0.9861], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,682][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Sara] are: tensor([0.9364, 0.0636], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,683][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Sara] are: tensor([0.0290, 0.9710], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,685][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Sara] are: tensor([0.9790, 0.0210], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,686][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Sara] are: tensor([0.2256, 0.7744], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,687][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Sara] are: tensor([0.5452, 0.4548], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,689][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Sara] are: tensor([0.9172, 0.0828], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,690][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Sara] are: tensor([0.0819, 0.9181], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,691][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1377, 0.5027, 0.3596], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,693][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0358, 0.5855, 0.3786], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,694][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1401, 0.4258, 0.4341], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,695][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0202, 0.4957, 0.4841], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,697][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0048, 0.4514, 0.5438], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,698][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.9882, 0.0085, 0.0033], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,700][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0105, 0.6201, 0.3694], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,700][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.8978, 0.0157, 0.0865], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,700][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0950, 0.3958, 0.5092], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,701][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.3240, 0.1216, 0.5544], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,701][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.8800, 0.0162, 0.1038], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,701][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0436, 0.1873, 0.7691], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,702][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Kenneth] are: tensor([0.0851, 0.3875, 0.2537, 0.2738], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,702][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Kenneth] are: tensor([0.0281, 0.3668, 0.2761, 0.3290], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,703][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Kenneth] are: tensor([0.0965, 0.2866, 0.2792, 0.3376], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,704][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Kenneth] are: tensor([0.0165, 0.3478, 0.3319, 0.3038], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,706][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Kenneth] are: tensor([0.0020, 0.4387, 0.4128, 0.1465], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,707][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Kenneth] are: tensor([0.8314, 0.0946, 0.0609, 0.0131], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,708][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Kenneth] are: tensor([0.0074, 0.4176, 0.3066, 0.2684], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,710][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Kenneth] are: tensor([0.9082, 0.0071, 0.0549, 0.0299], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,711][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Kenneth] are: tensor([0.0778, 0.2763, 0.3662, 0.2797], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,713][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Kenneth] are: tensor([0.1109, 0.1094, 0.4695, 0.3101], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,714][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Kenneth] are: tensor([0.8260, 0.0182, 0.0957, 0.0601], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,715][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Kenneth] are: tensor([0.0432, 0.1152, 0.5811, 0.2605], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,717][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.0675, 0.2800, 0.1956, 0.2108, 0.2461], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:37,718][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.0237, 0.3113, 0.2382, 0.2750, 0.1518], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:37,719][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.0677, 0.2452, 0.2347, 0.2874, 0.1651], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:37,721][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.0081, 0.2745, 0.2693, 0.2307, 0.2174], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:37,722][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.0026, 0.1969, 0.1959, 0.0984, 0.5062], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:37,724][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.8091, 0.1098, 0.0497, 0.0143, 0.0171], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:37,725][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.0039, 0.3963, 0.2463, 0.2290, 0.1245], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:37,726][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.9300, 0.0028, 0.0139, 0.0221, 0.0311], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:37,727][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.0466, 0.1690, 0.2854, 0.1688, 0.3302], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:37,729][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.0954, 0.1065, 0.3477, 0.2253, 0.2251], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:37,730][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.7533, 0.0134, 0.0672, 0.0404, 0.1257], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:37,732][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.0122, 0.0751, 0.3111, 0.1936, 0.4080], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:37,733][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0749, 0.2543, 0.1773, 0.1871, 0.2228, 0.0837], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:37,735][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0161, 0.2266, 0.2122, 0.2623, 0.1507, 0.1321], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:37,736][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0577, 0.1932, 0.1801, 0.2280, 0.1281, 0.2129], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:37,736][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0064, 0.2160, 0.2147, 0.1881, 0.1754, 0.1995], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:37,737][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0016, 0.1076, 0.1303, 0.0621, 0.4080, 0.2904], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:37,737][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.9179, 0.0383, 0.0152, 0.0060, 0.0084, 0.0141], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:37,737][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0085, 0.3131, 0.2164, 0.1938, 0.1300, 0.1381], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:37,738][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.7317, 0.0046, 0.0235, 0.0587, 0.1111, 0.0704], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:37,738][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0490, 0.1315, 0.2002, 0.1424, 0.2682, 0.2087], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:37,738][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.4094, 0.0319, 0.0904, 0.0931, 0.1204, 0.2548], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:37,739][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.7914, 0.0049, 0.0396, 0.0222, 0.1035, 0.0385], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:37,740][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0055, 0.0471, 0.2628, 0.3030, 0.2174, 0.1641], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:37,741][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.0523, 0.2114, 0.1426, 0.1570, 0.1762, 0.0675, 0.1930],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:37,742][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.0147, 0.2010, 0.1623, 0.2050, 0.1229, 0.1442, 0.1499],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:37,744][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.0548, 0.1562, 0.1523, 0.1901, 0.1133, 0.1732, 0.1601],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:37,745][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0059, 0.1882, 0.1832, 0.1616, 0.1482, 0.1618, 0.1511],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:37,746][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.0007, 0.0945, 0.1290, 0.0676, 0.3111, 0.2976, 0.0994],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:37,748][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.7559, 0.0885, 0.0512, 0.0157, 0.0238, 0.0474, 0.0175],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:37,749][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.0045, 0.2733, 0.1956, 0.1683, 0.1030, 0.1172, 0.1381],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:37,751][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.2136, 0.0121, 0.0479, 0.1292, 0.3696, 0.1936, 0.0340],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:37,752][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.0347, 0.1120, 0.1805, 0.1186, 0.2274, 0.1935, 0.1332],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:37,753][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.0546, 0.0463, 0.1548, 0.0822, 0.1986, 0.3200, 0.1435],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:37,755][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.2466, 0.0204, 0.1104, 0.0974, 0.3328, 0.1222, 0.0701],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:37,756][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0042, 0.0215, 0.3289, 0.0923, 0.1820, 0.3461, 0.0250],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:37,758][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0525, 0.1690, 0.1158, 0.1316, 0.1455, 0.0571, 0.1608, 0.1677],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:37,759][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0128, 0.1679, 0.1344, 0.1708, 0.1109, 0.1467, 0.1517, 0.1050],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:37,761][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0337, 0.1256, 0.1207, 0.1531, 0.0904, 0.1439, 0.1310, 0.2017],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:37,762][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0061, 0.1576, 0.1524, 0.1365, 0.1285, 0.1414, 0.1273, 0.1501],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:37,763][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0015, 0.1002, 0.0928, 0.0495, 0.2428, 0.1856, 0.0874, 0.2402],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:37,765][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.8588, 0.0482, 0.0222, 0.0103, 0.0125, 0.0212, 0.0167, 0.0101],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:37,766][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0037, 0.2444, 0.1663, 0.1529, 0.0980, 0.1115, 0.1280, 0.0951],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:37,768][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ at] are: tensor([9.2796e-01, 5.7964e-04, 3.6559e-03, 1.1111e-02, 2.4297e-02, 1.8361e-02,
        4.2044e-03, 9.8337e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:37,768][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0449, 0.1014, 0.1320, 0.0980, 0.2013, 0.1566, 0.1053, 0.1606],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:37,768][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.3845, 0.0177, 0.0408, 0.0503, 0.1105, 0.1420, 0.0207, 0.2335],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:37,769][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.8299, 0.0047, 0.0330, 0.0221, 0.0687, 0.0255, 0.0065, 0.0095],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:37,769][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0095, 0.0234, 0.1596, 0.2050, 0.1464, 0.1457, 0.0187, 0.2917],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:37,769][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0476, 0.1631, 0.1154, 0.1241, 0.1386, 0.0562, 0.1488, 0.1581, 0.0481],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:37,770][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0121, 0.1502, 0.1357, 0.1640, 0.0959, 0.0970, 0.1229, 0.1312, 0.0909],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:37,770][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0302, 0.1148, 0.1074, 0.1350, 0.0789, 0.1256, 0.1176, 0.1814, 0.1091],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:37,771][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0045, 0.1348, 0.1310, 0.1185, 0.1092, 0.1198, 0.1129, 0.1311, 0.1383],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:37,772][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0013, 0.0652, 0.0599, 0.0403, 0.1669, 0.1483, 0.0632, 0.2548, 0.2001],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:37,773][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.6556, 0.1016, 0.0523, 0.0200, 0.0299, 0.0500, 0.0379, 0.0261, 0.0265],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:37,775][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0062, 0.2142, 0.1514, 0.1332, 0.0864, 0.1003, 0.1223, 0.0864, 0.0995],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:37,776][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ the] are: tensor([9.0390e-01, 8.2992e-04, 4.0127e-03, 6.5117e-03, 2.0194e-02, 1.8520e-02,
        3.9622e-03, 1.9365e-02, 2.2709e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:37,777][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0425, 0.0995, 0.1157, 0.0914, 0.1644, 0.1230, 0.1030, 0.1345, 0.1261],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:37,779][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.3339, 0.0189, 0.0468, 0.0584, 0.0775, 0.1089, 0.0214, 0.2162, 0.1179],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:37,780][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.8787, 0.0025, 0.0204, 0.0120, 0.0437, 0.0139, 0.0062, 0.0062, 0.0165],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:37,781][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0051, 0.0164, 0.0812, 0.2393, 0.1226, 0.0849, 0.0252, 0.2643, 0.1610],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:37,783][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ garden] are: tensor([0.0352, 0.1464, 0.0964, 0.1034, 0.1236, 0.0451, 0.1368, 0.1371, 0.0376,
        0.1383], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:37,784][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ garden] are: tensor([0.0093, 0.1242, 0.1147, 0.1341, 0.0859, 0.1005, 0.0959, 0.1102, 0.1075,
        0.1176], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:37,786][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ garden] are: tensor([0.0309, 0.1015, 0.0962, 0.1247, 0.0699, 0.1111, 0.1038, 0.1652, 0.0973,
        0.0994], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:37,787][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ garden] are: tensor([0.0045, 0.1190, 0.1176, 0.1035, 0.0972, 0.1075, 0.0991, 0.1175, 0.1214,
        0.1126], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:37,789][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ garden] are: tensor([0.0006, 0.0582, 0.0650, 0.0329, 0.1456, 0.1520, 0.0488, 0.2310, 0.1917,
        0.0743], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:37,790][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ garden] are: tensor([0.5083, 0.1479, 0.0807, 0.0193, 0.0373, 0.0692, 0.0390, 0.0369, 0.0422,
        0.0191], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:37,792][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ garden] are: tensor([0.0029, 0.2197, 0.1397, 0.1291, 0.0756, 0.0863, 0.1012, 0.0736, 0.0869,
        0.0851], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:37,793][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ garden] are: tensor([0.5659, 0.0035, 0.0181, 0.0370, 0.0729, 0.0494, 0.0074, 0.0653, 0.1534,
        0.0272], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:37,795][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ garden] are: tensor([0.0226, 0.0771, 0.1080, 0.0810, 0.1576, 0.1238, 0.0885, 0.1267, 0.1085,
        0.1061], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:37,796][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ garden] are: tensor([0.0337, 0.0302, 0.0856, 0.0458, 0.1181, 0.1741, 0.0394, 0.2722, 0.1498,
        0.0509], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:37,798][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ garden] are: tensor([0.4116, 0.0117, 0.0769, 0.0515, 0.1992, 0.0660, 0.0260, 0.0336, 0.0728,
        0.0508], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:37,799][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ garden] are: tensor([0.0035, 0.0096, 0.1400, 0.0521, 0.0869, 0.0993, 0.0200, 0.2052, 0.3478,
        0.0357], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:37,800][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0401, 0.1281, 0.0903, 0.1003, 0.1106, 0.0433, 0.1207, 0.1273, 0.0377,
        0.1290, 0.0726], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:37,800][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0066, 0.1303, 0.0837, 0.1313, 0.0781, 0.0951, 0.0907, 0.0989, 0.0974,
        0.1158, 0.0721], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:37,800][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0260, 0.0905, 0.0907, 0.1133, 0.0694, 0.1061, 0.0973, 0.1497, 0.0912,
        0.0921, 0.0737], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:37,801][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0041, 0.1088, 0.1027, 0.0937, 0.0876, 0.0934, 0.0888, 0.1041, 0.1075,
        0.0978, 0.1114], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:37,801][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0020, 0.0361, 0.0516, 0.0273, 0.1033, 0.1238, 0.0450, 0.1893, 0.1761,
        0.0656, 0.1798], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:37,802][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.7753, 0.0564, 0.0245, 0.0152, 0.0225, 0.0308, 0.0211, 0.0162, 0.0157,
        0.0156, 0.0068], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:37,802][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0054, 0.2190, 0.1114, 0.1114, 0.0642, 0.0828, 0.1002, 0.0687, 0.0836,
        0.0816, 0.0715], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:37,803][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([9.6364e-01, 2.0632e-04, 1.2725e-03, 2.3810e-03, 4.8772e-03, 7.0762e-03,
        1.1849e-03, 2.4464e-03, 6.6789e-03, 2.6982e-03, 7.5349e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:37,804][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0395, 0.0754, 0.0823, 0.0739, 0.1262, 0.0966, 0.0766, 0.1104, 0.0992,
        0.1092, 0.1108], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:37,805][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1866, 0.0224, 0.0499, 0.0569, 0.0763, 0.1092, 0.0184, 0.2641, 0.1039,
        0.0275, 0.0849], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:37,807][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.8273, 0.0031, 0.0207, 0.0147, 0.0461, 0.0186, 0.0053, 0.0084, 0.0201,
        0.0087, 0.0269], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:37,808][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0030, 0.0154, 0.0588, 0.1083, 0.0850, 0.1091, 0.0047, 0.2090, 0.2444,
        0.0567, 0.1056], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:37,810][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Sara] are: tensor([0.0309, 0.1136, 0.0793, 0.0834, 0.0979, 0.0366, 0.1057, 0.1090, 0.0312,
        0.1088, 0.0661, 0.1376], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,811][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Sara] are: tensor([0.0064, 0.1072, 0.0967, 0.1118, 0.0668, 0.0801, 0.0852, 0.0825, 0.0886,
        0.1048, 0.0902, 0.0797], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,813][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Sara] are: tensor([0.0272, 0.0848, 0.0827, 0.1007, 0.0626, 0.0956, 0.0871, 0.1352, 0.0819,
        0.0837, 0.0684, 0.0903], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,814][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Sara] are: tensor([0.0038, 0.0951, 0.0917, 0.0848, 0.0826, 0.0868, 0.0809, 0.0935, 0.0946,
        0.0887, 0.0985, 0.0992], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,815][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Sara] are: tensor([0.0013, 0.0440, 0.0488, 0.0241, 0.0970, 0.1008, 0.0448, 0.1664, 0.1477,
        0.0614, 0.1534, 0.1103], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,817][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Sara] are: tensor([0.6585, 0.1052, 0.0441, 0.0181, 0.0197, 0.0346, 0.0285, 0.0217, 0.0229,
        0.0186, 0.0132, 0.0147], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,818][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Sara] are: tensor([0.0022, 0.1862, 0.1045, 0.1041, 0.0571, 0.0734, 0.0864, 0.0597, 0.0727,
        0.0707, 0.0607, 0.1222], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,819][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Sara] are: tensor([8.1183e-01, 7.2206e-04, 6.2569e-03, 1.0842e-02, 2.1142e-02, 1.4960e-02,
        3.2347e-03, 1.8515e-02, 3.7057e-02, 8.8140e-03, 4.6179e-02, 2.0445e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,821][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Sara] are: tensor([0.0235, 0.0681, 0.0874, 0.0685, 0.1193, 0.0980, 0.0770, 0.0962, 0.0877,
        0.0951, 0.0934, 0.0858], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,822][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Sara] are: tensor([0.1293, 0.0484, 0.0945, 0.0950, 0.0664, 0.1021, 0.0278, 0.1658, 0.1043,
        0.0420, 0.0884, 0.0360], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,824][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Sara] are: tensor([0.7339, 0.0055, 0.0269, 0.0154, 0.0795, 0.0206, 0.0117, 0.0065, 0.0213,
        0.0174, 0.0334, 0.0279], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,825][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Sara] are: tensor([0.0017, 0.0125, 0.1064, 0.0963, 0.0561, 0.0614, 0.0087, 0.0986, 0.2285,
        0.0912, 0.1924, 0.0462], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:37,827][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0281, 0.1124, 0.0698, 0.0778, 0.0901, 0.0305, 0.0981, 0.1023, 0.0261,
        0.0987, 0.0592, 0.1362, 0.0707], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,828][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0074, 0.1049, 0.0857, 0.0899, 0.0631, 0.0831, 0.0729, 0.0850, 0.0854,
        0.0959, 0.0821, 0.0898, 0.0546], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,830][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0183, 0.0774, 0.0760, 0.0989, 0.0581, 0.0936, 0.0826, 0.1308, 0.0787,
        0.0782, 0.0600, 0.0823, 0.0651], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,831][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0034, 0.0909, 0.0843, 0.0773, 0.0721, 0.0777, 0.0712, 0.0853, 0.0877,
        0.0813, 0.0924, 0.0929, 0.0834], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,831][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.0020, 0.0233, 0.0321, 0.0156, 0.0673, 0.1079, 0.0258, 0.1611, 0.1451,
        0.0403, 0.1364, 0.0743, 0.1687], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,832][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.6218, 0.1076, 0.0486, 0.0151, 0.0217, 0.0372, 0.0287, 0.0278, 0.0227,
        0.0199, 0.0150, 0.0156, 0.0182], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,832][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0017, 0.1907, 0.1010, 0.0987, 0.0544, 0.0672, 0.0818, 0.0553, 0.0687,
        0.0697, 0.0552, 0.1086, 0.0472], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,833][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([9.3916e-01, 1.7310e-04, 1.0282e-03, 1.1473e-03, 2.9478e-03, 5.0049e-03,
        5.9662e-04, 1.6124e-03, 6.8769e-03, 1.6718e-03, 8.8978e-03, 3.2918e-03,
        2.7593e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,833][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0316, 0.0592, 0.0726, 0.0505, 0.1073, 0.0861, 0.0521, 0.0945, 0.0821,
        0.0888, 0.0922, 0.0864, 0.0964], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,834][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0456, 0.0292, 0.0718, 0.0440, 0.0539, 0.1288, 0.0262, 0.2228, 0.1009,
        0.0270, 0.1087, 0.0267, 0.1144], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,834][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.8618, 0.0018, 0.0131, 0.0061, 0.0321, 0.0115, 0.0032, 0.0031, 0.0112,
        0.0038, 0.0161, 0.0069, 0.0293], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,835][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0040, 0.0192, 0.0537, 0.0436, 0.0578, 0.1278, 0.0130, 0.1929, 0.1768,
        0.0764, 0.1218, 0.0702, 0.0428], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:37,837][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0299, 0.0966, 0.0664, 0.0757, 0.0828, 0.0328, 0.0897, 0.0937, 0.0285,
        0.0943, 0.0563, 0.1190, 0.0672, 0.0671], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,838][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0074, 0.0991, 0.0737, 0.1097, 0.0619, 0.0815, 0.0763, 0.0674, 0.0829,
        0.0902, 0.0687, 0.0810, 0.0591, 0.0412], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,840][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0143, 0.0687, 0.0699, 0.0880, 0.0549, 0.0859, 0.0752, 0.1176, 0.0694,
        0.0687, 0.0550, 0.0688, 0.0622, 0.1015], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,841][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0033, 0.0813, 0.0779, 0.0692, 0.0663, 0.0731, 0.0665, 0.0800, 0.0818,
        0.0744, 0.0851, 0.0847, 0.0756, 0.0810], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,842][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0014, 0.0252, 0.0232, 0.0123, 0.0592, 0.0813, 0.0241, 0.1268, 0.1173,
        0.0364, 0.1075, 0.0820, 0.1301, 0.1732], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,844][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.4159, 0.1318, 0.0541, 0.0254, 0.0431, 0.0747, 0.0665, 0.0293, 0.0352,
        0.0378, 0.0157, 0.0248, 0.0395, 0.0061], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,845][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0038, 0.1673, 0.0866, 0.0953, 0.0526, 0.0665, 0.0821, 0.0519, 0.0674,
        0.0679, 0.0517, 0.1047, 0.0459, 0.0563], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,846][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([9.6375e-01, 4.6857e-05, 1.6804e-04, 3.9204e-04, 3.8539e-04, 1.2150e-03,
        1.7308e-04, 4.5631e-04, 1.2423e-03, 3.3664e-04, 1.6607e-03, 1.0547e-03,
        5.4963e-03, 2.3625e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,848][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0300, 0.0553, 0.0617, 0.0558, 0.0998, 0.0692, 0.0500, 0.0798, 0.0723,
        0.0741, 0.0811, 0.0778, 0.0862, 0.1070], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,849][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1256, 0.0144, 0.0262, 0.0287, 0.0565, 0.1317, 0.0158, 0.1632, 0.1020,
        0.0165, 0.0526, 0.0245, 0.1390, 0.1033], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,851][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.8285, 0.0016, 0.0118, 0.0067, 0.0301, 0.0108, 0.0030, 0.0037, 0.0096,
        0.0031, 0.0139, 0.0062, 0.0227, 0.0482], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,852][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0055, 0.0060, 0.0424, 0.0512, 0.0911, 0.0660, 0.0088, 0.1440, 0.1325,
        0.0452, 0.1228, 0.0349, 0.0558, 0.1939], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:37,853][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0272, 0.0945, 0.0612, 0.0664, 0.0763, 0.0262, 0.0829, 0.0872, 0.0227,
        0.0846, 0.0493, 0.1143, 0.0605, 0.0570, 0.0896], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,855][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0088, 0.0988, 0.0734, 0.0988, 0.0574, 0.0696, 0.0673, 0.0806, 0.0711,
        0.0832, 0.0680, 0.0814, 0.0465, 0.0459, 0.0492], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,856][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0155, 0.0635, 0.0656, 0.0802, 0.0514, 0.0778, 0.0672, 0.1043, 0.0633,
        0.0621, 0.0507, 0.0654, 0.0569, 0.0886, 0.0874], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,858][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0022, 0.0778, 0.0756, 0.0675, 0.0623, 0.0667, 0.0616, 0.0734, 0.0756,
        0.0686, 0.0795, 0.0789, 0.0695, 0.0758, 0.0651], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,859][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0021, 0.0216, 0.0232, 0.0115, 0.0524, 0.0571, 0.0190, 0.0865, 0.0944,
        0.0294, 0.0919, 0.0544, 0.1077, 0.1624, 0.1863], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,861][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.6814, 0.0717, 0.0352, 0.0123, 0.0220, 0.0393, 0.0251, 0.0173, 0.0190,
        0.0174, 0.0115, 0.0126, 0.0199, 0.0055, 0.0097], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,862][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0033, 0.1484, 0.0866, 0.0805, 0.0500, 0.0691, 0.0756, 0.0549, 0.0664,
        0.0605, 0.0530, 0.0991, 0.0453, 0.0587, 0.0487], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,863][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ give] are: tensor([8.4457e-01, 4.6578e-05, 1.9513e-04, 1.9147e-04, 4.7710e-04, 9.8567e-04,
        6.8823e-05, 4.3518e-04, 2.0492e-03, 1.9275e-04, 2.5997e-03, 1.1630e-03,
        1.0138e-02, 8.0075e-02, 5.6810e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,863][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0310, 0.0533, 0.0592, 0.0480, 0.0808, 0.0620, 0.0417, 0.0646, 0.0615,
        0.0667, 0.0713, 0.0684, 0.0755, 0.1007, 0.1152], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,864][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.1154, 0.0158, 0.0384, 0.0295, 0.0372, 0.0735, 0.0195, 0.0966, 0.0722,
        0.0193, 0.0455, 0.0120, 0.0718, 0.1025, 0.2509], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,864][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.7576, 0.0023, 0.0110, 0.0069, 0.0250, 0.0068, 0.0023, 0.0023, 0.0065,
        0.0034, 0.0095, 0.0076, 0.0162, 0.0355, 0.1071], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,865][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0032, 0.0147, 0.0373, 0.1037, 0.0959, 0.0392, 0.0152, 0.1390, 0.0779,
        0.0443, 0.1007, 0.0738, 0.0376, 0.1329, 0.0843], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:37,865][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.0234, 0.0886, 0.0577, 0.0638, 0.0736, 0.0271, 0.0814, 0.0817, 0.0234,
        0.0845, 0.0486, 0.1081, 0.0595, 0.0542, 0.0829, 0.0416],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,866][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ it] are: tensor([0.0070, 0.0817, 0.0749, 0.0950, 0.0573, 0.0622, 0.0629, 0.0809, 0.0590,
        0.0815, 0.0658, 0.0646, 0.0459, 0.0497, 0.0622, 0.0494],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,867][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.0163, 0.0584, 0.0582, 0.0749, 0.0453, 0.0693, 0.0634, 0.0938, 0.0577,
        0.0589, 0.0473, 0.0624, 0.0518, 0.0801, 0.0757, 0.0863],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,868][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ it] are: tensor([0.0028, 0.0733, 0.0699, 0.0629, 0.0586, 0.0626, 0.0580, 0.0690, 0.0709,
        0.0656, 0.0741, 0.0734, 0.0668, 0.0706, 0.0610, 0.0604],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,869][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.0011, 0.0150, 0.0198, 0.0089, 0.0560, 0.0469, 0.0143, 0.0698, 0.0752,
        0.0193, 0.0720, 0.0383, 0.1005, 0.1213, 0.1885, 0.1531],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,871][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ it] are: tensor([0.3350, 0.1599, 0.0773, 0.0304, 0.0381, 0.0545, 0.0641, 0.0379, 0.0379,
        0.0410, 0.0242, 0.0267, 0.0391, 0.0090, 0.0170, 0.0077],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,872][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.0030, 0.1224, 0.0778, 0.0710, 0.0478, 0.0597, 0.0684, 0.0487, 0.0633,
        0.0597, 0.0502, 0.0883, 0.0437, 0.0554, 0.0441, 0.0966],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,873][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ it] are: tensor([7.3433e-01, 7.5891e-05, 3.3435e-04, 1.6783e-04, 2.2476e-03, 2.4274e-03,
        1.4487e-04, 8.9642e-04, 5.1493e-03, 3.9427e-04, 4.0141e-03, 1.1336e-03,
        2.8618e-02, 9.3385e-02, 1.2146e-01, 5.2195e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,875][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.0304, 0.0392, 0.0524, 0.0392, 0.0823, 0.0558, 0.0384, 0.0640, 0.0606,
        0.0663, 0.0703, 0.0581, 0.0767, 0.0969, 0.1103, 0.0592],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,876][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ it] are: tensor([0.0241, 0.0091, 0.0264, 0.0190, 0.0320, 0.0695, 0.0139, 0.1303, 0.0975,
        0.0131, 0.0618, 0.0179, 0.0790, 0.0854, 0.2494, 0.0717],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,878][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.6122, 0.0014, 0.0092, 0.0042, 0.0294, 0.0091, 0.0021, 0.0027, 0.0118,
        0.0030, 0.0156, 0.0061, 0.0352, 0.0585, 0.0961, 0.1033],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,879][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ it] are: tensor([0.0031, 0.0029, 0.0241, 0.0202, 0.0546, 0.0340, 0.0029, 0.0666, 0.0731,
        0.0206, 0.0696, 0.0163, 0.0476, 0.3143, 0.1549, 0.0952],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:37,881][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0245, 0.0796, 0.0547, 0.0614, 0.0685, 0.0273, 0.0727, 0.0766, 0.0238,
        0.0773, 0.0467, 0.0972, 0.0554, 0.0548, 0.0789, 0.0415, 0.0590],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,882][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0057, 0.0858, 0.0619, 0.0934, 0.0520, 0.0678, 0.0647, 0.0565, 0.0694,
        0.0773, 0.0576, 0.0691, 0.0499, 0.0341, 0.0551, 0.0649, 0.0348],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,884][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0118, 0.0528, 0.0527, 0.0661, 0.0420, 0.0653, 0.0578, 0.0885, 0.0526,
        0.0529, 0.0421, 0.0525, 0.0481, 0.0757, 0.0713, 0.0817, 0.0862],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,885][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0028, 0.0677, 0.0654, 0.0586, 0.0551, 0.0600, 0.0541, 0.0650, 0.0668,
        0.0612, 0.0700, 0.0695, 0.0623, 0.0660, 0.0569, 0.0567, 0.0619],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,887][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0012, 0.0174, 0.0146, 0.0084, 0.0335, 0.0454, 0.0142, 0.0706, 0.0738,
        0.0233, 0.0618, 0.0482, 0.0771, 0.1002, 0.1289, 0.1712, 0.1103],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,888][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.2364, 0.1575, 0.0711, 0.0298, 0.0522, 0.0947, 0.0887, 0.0338, 0.0447,
        0.0491, 0.0198, 0.0315, 0.0448, 0.0066, 0.0244, 0.0103, 0.0045],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,890][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0032, 0.1295, 0.0720, 0.0700, 0.0436, 0.0550, 0.0647, 0.0426, 0.0569,
        0.0570, 0.0439, 0.0816, 0.0377, 0.0482, 0.0393, 0.0855, 0.0690],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,891][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([9.3264e-01, 4.2048e-05, 1.1218e-04, 2.5519e-04, 2.9818e-04, 8.8377e-04,
        9.3845e-05, 3.1188e-04, 1.0997e-03, 1.7861e-04, 1.1509e-03, 7.7140e-04,
        5.3794e-03, 1.8853e-02, 1.5466e-02, 2.5216e-03, 1.9945e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,892][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0223, 0.0438, 0.0472, 0.0420, 0.0776, 0.0522, 0.0371, 0.0603, 0.0546,
        0.0563, 0.0610, 0.0579, 0.0659, 0.0798, 0.0981, 0.0566, 0.0874],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,894][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0287, 0.0094, 0.0179, 0.0176, 0.0345, 0.0823, 0.0104, 0.1077, 0.0657,
        0.0102, 0.0362, 0.0133, 0.0921, 0.0595, 0.2601, 0.1117, 0.0427],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,894][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.6670, 0.0016, 0.0102, 0.0056, 0.0262, 0.0091, 0.0027, 0.0027, 0.0085,
        0.0028, 0.0115, 0.0050, 0.0209, 0.0387, 0.0759, 0.0682, 0.0435],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,895][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0037, 0.0042, 0.0276, 0.0299, 0.0513, 0.0410, 0.0049, 0.0881, 0.0908,
        0.0244, 0.0783, 0.0232, 0.0344, 0.1148, 0.0641, 0.1745, 0.1451],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:37,957][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:37,957][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,958][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,958][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,959][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,959][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,959][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,959][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,960][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,960][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,960][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,961][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,962][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:37,963][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Sara] are: tensor([0.6270, 0.3730], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,965][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Sara] are: tensor([0.0143, 0.9857], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,966][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Sara] are: tensor([0.5706, 0.4294], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,967][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Sara] are: tensor([0.0920, 0.9080], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,968][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Sara] are: tensor([0.7889, 0.2111], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,970][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Sara] are: tensor([0.8587, 0.1413], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,971][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Sara] are: tensor([0.9307, 0.0693], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,973][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Sara] are: tensor([0.5587, 0.4413], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,974][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Sara] are: tensor([0.8953, 0.1047], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,975][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Sara] are: tensor([0.8676, 0.1324], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,977][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Sara] are: tensor([0.7749, 0.2251], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,978][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Sara] are: tensor([0.2960, 0.7040], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:37,979][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.4739, 0.3135, 0.2126], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,981][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0021, 0.7290, 0.2688], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,982][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.6920, 0.1963, 0.1117], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,984][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3524, 0.2580, 0.3896], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,985][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2112, 0.0242, 0.7646], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,986][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.5911, 0.0866, 0.3223], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,988][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6492, 0.0971, 0.2537], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,989][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2918, 0.0456, 0.6625], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,989][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.7653, 0.0752, 0.1594], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,990][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.6881, 0.0599, 0.2520], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,990][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.5495, 0.0944, 0.3562], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,990][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0493, 0.1459, 0.8047], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:37,991][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Kenneth] are: tensor([0.3479, 0.2978, 0.1557, 0.1987], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,991][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Kenneth] are: tensor([0.0008, 0.2364, 0.0983, 0.6645], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,991][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Kenneth] are: tensor([0.6850, 0.1663, 0.0646, 0.0841], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,992][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Kenneth] are: tensor([0.1389, 0.3116, 0.1072, 0.4423], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,992][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Kenneth] are: tensor([0.2046, 0.0415, 0.5101, 0.2438], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,993][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Kenneth] are: tensor([0.4487, 0.0420, 0.3324, 0.1768], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,995][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Kenneth] are: tensor([0.5708, 0.0472, 0.2514, 0.1306], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,996][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Kenneth] are: tensor([0.1315, 0.0391, 0.6784, 0.1511], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,998][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Kenneth] are: tensor([0.6519, 0.0566, 0.1038, 0.1877], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:37,999][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Kenneth] are: tensor([0.5853, 0.0403, 0.1949, 0.1794], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,000][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Kenneth] are: tensor([0.4690, 0.0633, 0.2555, 0.2122], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,002][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Kenneth] are: tensor([0.0518, 0.0650, 0.5378, 0.3454], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,003][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.2872, 0.1984, 0.1211, 0.1598, 0.2335], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,004][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.0027, 0.3733, 0.1777, 0.3732, 0.0730], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,006][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.3851, 0.2176, 0.1070, 0.1412, 0.1492], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,007][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.1331, 0.2205, 0.3161, 0.1918, 0.1385], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,009][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.0245, 0.0047, 0.0822, 0.0939, 0.7947], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,010][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.2157, 0.0543, 0.1819, 0.2555, 0.2926], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,011][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.4383, 0.0549, 0.1498, 0.1517, 0.2053], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,013][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.2272, 0.0228, 0.3137, 0.1548, 0.2814], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,014][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.3359, 0.0431, 0.1944, 0.1964, 0.2302], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,016][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.3513, 0.0598, 0.2195, 0.2170, 0.1523], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,017][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.2725, 0.0657, 0.2272, 0.1972, 0.2374], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,019][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.0188, 0.0451, 0.3156, 0.2304, 0.3901], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,020][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.3417, 0.1926, 0.1131, 0.1375, 0.2032, 0.0119], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,021][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0012, 0.2480, 0.1493, 0.4453, 0.1024, 0.0537], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,021][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2839, 0.1541, 0.0947, 0.1306, 0.1430, 0.1935], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,021][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0362, 0.2968, 0.1546, 0.1513, 0.3240, 0.0371], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,022][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0390, 0.0020, 0.0481, 0.0573, 0.5973, 0.2564], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,022][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.3260, 0.0332, 0.1151, 0.2166, 0.2319, 0.0771], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,022][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.6882, 0.0233, 0.0705, 0.0572, 0.1308, 0.0300], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,023][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1393, 0.0110, 0.1739, 0.1350, 0.2805, 0.2603], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,023][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.3928, 0.0303, 0.1021, 0.1637, 0.1872, 0.1240], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,024][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.4883, 0.0272, 0.1162, 0.1391, 0.1014, 0.1278], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,025][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.3057, 0.0352, 0.1591, 0.1219, 0.2140, 0.1641], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,026][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0203, 0.0269, 0.2074, 0.1593, 0.2195, 0.3666], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,027][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.1969, 0.1809, 0.0847, 0.1175, 0.1500, 0.0085, 0.2617],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,028][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([2.3027e-04, 2.4203e-01, 1.0457e-01, 4.3550e-01, 4.3749e-02, 9.5024e-02,
        7.8902e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,030][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.1704, 0.0869, 0.0629, 0.0825, 0.0998, 0.1100, 0.3875],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,030][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.0041, 0.0368, 0.0463, 0.0714, 0.0254, 0.0101, 0.8060],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,032][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.0048, 0.0027, 0.0456, 0.0794, 0.4974, 0.3511, 0.0191],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,033][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.0450, 0.0359, 0.1871, 0.1863, 0.3337, 0.1741, 0.0378],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,035][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.3665, 0.0402, 0.1624, 0.0943, 0.2152, 0.0671, 0.0541],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,036][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.0061, 0.0114, 0.1370, 0.1166, 0.4013, 0.3095, 0.0182],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,037][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.2606, 0.0318, 0.1112, 0.1488, 0.2112, 0.1522, 0.0843],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,039][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.2687, 0.0338, 0.1466, 0.1030, 0.1515, 0.1463, 0.1501],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,040][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.0775, 0.0472, 0.1536, 0.1774, 0.2393, 0.1863, 0.1187],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,042][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.0072, 0.0237, 0.1904, 0.1394, 0.1885, 0.3982, 0.0526],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,043][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.1961, 0.1252, 0.0708, 0.1039, 0.1266, 0.0090, 0.2101, 0.1583],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,045][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0005, 0.2612, 0.0877, 0.3159, 0.0738, 0.1344, 0.0910, 0.0355],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,046][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1805, 0.0788, 0.0422, 0.0503, 0.0589, 0.0770, 0.2689, 0.2435],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,047][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.1352, 0.1160, 0.2168, 0.1554, 0.1337, 0.0951, 0.0745, 0.0733],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,049][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0270, 0.0020, 0.0194, 0.0434, 0.4193, 0.1305, 0.0141, 0.3443],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,050][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.2548, 0.0301, 0.0997, 0.1793, 0.2071, 0.0810, 0.0248, 0.1230],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,052][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.5976, 0.0177, 0.0703, 0.0441, 0.1748, 0.0393, 0.0275, 0.0287],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,052][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.2353, 0.0047, 0.0911, 0.0711, 0.1925, 0.1958, 0.0121, 0.1974],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,053][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.4953, 0.0183, 0.0600, 0.0988, 0.1592, 0.0886, 0.0370, 0.0429],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,053][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.5205, 0.0136, 0.0659, 0.0836, 0.0943, 0.0928, 0.0471, 0.0824],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,053][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.3256, 0.0269, 0.1282, 0.1252, 0.1485, 0.1173, 0.0311, 0.0971],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,054][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0222, 0.0172, 0.1351, 0.1139, 0.1775, 0.2664, 0.0278, 0.2399],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,054][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1823, 0.1375, 0.0801, 0.0987, 0.1297, 0.0100, 0.1987, 0.1556, 0.0073],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,055][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0005, 0.2117, 0.0967, 0.3975, 0.0490, 0.0347, 0.0507, 0.0641, 0.0951],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,055][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1616, 0.0618, 0.0367, 0.0489, 0.0554, 0.0730, 0.2478, 0.2280, 0.0869],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,056][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0278, 0.1106, 0.0995, 0.1345, 0.1467, 0.0307, 0.2400, 0.0846, 0.1255],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,057][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0360, 0.0008, 0.0098, 0.0248, 0.1393, 0.0689, 0.0065, 0.3426, 0.3712],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,059][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.5306, 0.0110, 0.0535, 0.0545, 0.0750, 0.0350, 0.0080, 0.0652, 0.1673],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,060][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.7109, 0.0164, 0.0587, 0.0368, 0.0882, 0.0233, 0.0232, 0.0208, 0.0218],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,061][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.2978, 0.0025, 0.0419, 0.0182, 0.0626, 0.0709, 0.0042, 0.1016, 0.4004],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,063][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.5716, 0.0203, 0.0463, 0.0910, 0.0979, 0.0494, 0.0390, 0.0308, 0.0538],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,064][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.5379, 0.0146, 0.0695, 0.0854, 0.0603, 0.0570, 0.0415, 0.0593, 0.0746],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,066][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.3975, 0.0212, 0.0961, 0.0779, 0.1079, 0.0786, 0.0336, 0.0662, 0.1211],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,067][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0135, 0.0111, 0.0706, 0.0760, 0.0853, 0.1421, 0.0199, 0.1529, 0.4286],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,069][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ garden] are: tensor([0.1249, 0.1233, 0.0566, 0.0810, 0.1221, 0.0058, 0.2157, 0.1362, 0.0036,
        0.1307], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,070][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ garden] are: tensor([1.1358e-05, 1.6919e-01, 6.0892e-02, 2.3509e-01, 2.1389e-02, 4.8434e-02,
        4.3406e-02, 6.6009e-02, 2.7378e-01, 8.1799e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,071][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ garden] are: tensor([0.1557, 0.0471, 0.0306, 0.0420, 0.0481, 0.0550, 0.1982, 0.2316, 0.0728,
        0.1189], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,073][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ garden] are: tensor([0.0223, 0.0266, 0.0850, 0.0295, 0.0666, 0.0411, 0.2687, 0.0537, 0.1316,
        0.2749], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,074][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ garden] are: tensor([0.0019, 0.0014, 0.0116, 0.0267, 0.1247, 0.0743, 0.0045, 0.2810, 0.4663,
        0.0077], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,075][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ garden] are: tensor([0.0595, 0.0132, 0.0847, 0.0670, 0.1139, 0.0557, 0.0107, 0.1133, 0.3788,
        0.1033], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,077][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ garden] are: tensor([0.1510, 0.0278, 0.1612, 0.1190, 0.2471, 0.0602, 0.0435, 0.0511, 0.0709,
        0.0682], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,079][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ garden] are: tensor([0.0096, 0.0023, 0.0350, 0.0228, 0.0539, 0.0444, 0.0023, 0.1051, 0.6933,
        0.0312], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,080][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ garden] are: tensor([0.3108, 0.0198, 0.0605, 0.1176, 0.1589, 0.0893, 0.0463, 0.0629, 0.0859,
        0.0481], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,081][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ garden] are: tensor([0.3079, 0.0201, 0.0851, 0.0658, 0.0924, 0.0812, 0.0576, 0.0951, 0.0998,
        0.0948], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,083][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ garden] are: tensor([0.1073, 0.0231, 0.1038, 0.1009, 0.1279, 0.1015, 0.0447, 0.1337, 0.1642,
        0.0931], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,084][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ garden] are: tensor([0.0029, 0.0060, 0.0541, 0.0296, 0.0726, 0.1327, 0.0195, 0.1808, 0.4584,
        0.0433], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,084][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1739, 0.0967, 0.0590, 0.0806, 0.1034, 0.0075, 0.1583, 0.1198, 0.0056,
        0.1323, 0.0629], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,085][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([1.5004e-04, 2.0336e-01, 2.9834e-02, 1.8947e-01, 2.0543e-02, 3.7111e-02,
        3.2574e-02, 4.2645e-02, 1.9705e-01, 9.2685e-02, 1.5457e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,085][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1081, 0.0519, 0.0437, 0.0357, 0.0475, 0.0568, 0.2100, 0.1982, 0.0695,
        0.1123, 0.0663], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,085][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0547, 0.0704, 0.0804, 0.0662, 0.0944, 0.0565, 0.1197, 0.1027, 0.1857,
        0.0951, 0.0743], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,086][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0596, 0.0006, 0.0105, 0.0208, 0.0870, 0.0647, 0.0053, 0.2398, 0.3895,
        0.0086, 0.1136], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,086][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4445, 0.0069, 0.0309, 0.0302, 0.0394, 0.0234, 0.0051, 0.0319, 0.1318,
        0.0518, 0.2043], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,087][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3581, 0.0279, 0.0643, 0.0777, 0.1920, 0.0430, 0.0326, 0.0341, 0.0548,
        0.0614, 0.0541], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,088][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4093, 0.0009, 0.0178, 0.0089, 0.0224, 0.0346, 0.0016, 0.0199, 0.1670,
        0.0147, 0.3030], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,089][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.6719, 0.0108, 0.0225, 0.0609, 0.0529, 0.0276, 0.0191, 0.0186, 0.0347,
        0.0318, 0.0492], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,091][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.4168, 0.0174, 0.0616, 0.0846, 0.0655, 0.0574, 0.0385, 0.0640, 0.0742,
        0.0613, 0.0588], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,092][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.3485, 0.0191, 0.0732, 0.0710, 0.0867, 0.0719, 0.0208, 0.0597, 0.0968,
        0.0400, 0.1121], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,093][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0118, 0.0079, 0.0446, 0.0443, 0.0631, 0.0838, 0.0099, 0.0996, 0.2777,
        0.0335, 0.3238], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,095][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Sara] are: tensor([0.1387, 0.0885, 0.0517, 0.0661, 0.0869, 0.0052, 0.1439, 0.1012, 0.0036,
        0.1021, 0.0626, 0.1494], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,096][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Sara] are: tensor([2.5728e-04, 1.4936e-01, 2.6972e-02, 3.7222e-01, 3.6251e-02, 3.0051e-02,
        3.5354e-02, 2.4568e-02, 9.8646e-02, 6.8064e-02, 6.8305e-02, 8.9951e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,097][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Sara] are: tensor([0.1947, 0.0415, 0.0298, 0.0285, 0.0361, 0.0451, 0.1804, 0.1733, 0.0609,
        0.0912, 0.0614, 0.0572], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,099][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Sara] are: tensor([0.0135, 0.0986, 0.0193, 0.1390, 0.0896, 0.0120, 0.2470, 0.0405, 0.0459,
        0.1576, 0.0370, 0.1002], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,100][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Sara] are: tensor([0.0281, 0.0013, 0.0102, 0.0153, 0.0661, 0.0566, 0.0045, 0.2003, 0.4277,
        0.0082, 0.1075, 0.0742], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,102][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Sara] are: tensor([0.2041, 0.0088, 0.0373, 0.0325, 0.0442, 0.0215, 0.0038, 0.0362, 0.1571,
        0.0407, 0.3123, 0.1015], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,103][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Sara] are: tensor([0.2281, 0.0258, 0.0973, 0.0835, 0.2390, 0.0603, 0.0399, 0.0351, 0.0590,
        0.0512, 0.0554, 0.0254], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,105][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Sara] are: tensor([0.0500, 0.0007, 0.0173, 0.0084, 0.0223, 0.0184, 0.0010, 0.0363, 0.2380,
        0.0114, 0.4831, 0.1131], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,106][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Sara] are: tensor([0.3987, 0.0174, 0.0347, 0.0747, 0.0831, 0.0563, 0.0454, 0.0313, 0.0506,
        0.0448, 0.0625, 0.1006], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,108][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Sara] are: tensor([0.4180, 0.0213, 0.0647, 0.0748, 0.0539, 0.0464, 0.0422, 0.0518, 0.0581,
        0.0654, 0.0487, 0.0549], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,109][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Sara] are: tensor([0.2353, 0.0170, 0.0685, 0.0498, 0.0950, 0.0634, 0.0301, 0.0527, 0.1019,
        0.0507, 0.1365, 0.0991], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,111][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Sara] are: tensor([0.0050, 0.0039, 0.0480, 0.0264, 0.0429, 0.1000, 0.0124, 0.0931, 0.2664,
        0.0310, 0.2760, 0.0950], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,112][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.1299, 0.0919, 0.0390, 0.0580, 0.0856, 0.0039, 0.1349, 0.1049, 0.0027,
        0.0837, 0.0555, 0.1704, 0.0397], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,113][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([1.1460e-04, 8.4493e-02, 3.8535e-02, 8.2940e-02, 3.1526e-02, 6.7140e-02,
        2.8481e-02, 3.8543e-02, 1.5184e-01, 7.6921e-02, 1.9729e-01, 1.4923e-01,
        5.2945e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,115][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0673, 0.0481, 0.0252, 0.0301, 0.0431, 0.0511, 0.2054, 0.1520, 0.0547,
        0.0887, 0.0556, 0.0583, 0.1202], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,115][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.0158, 0.0379, 0.0464, 0.0597, 0.0399, 0.0267, 0.1081, 0.0335, 0.1124,
        0.0419, 0.0778, 0.0256, 0.3742], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,116][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([2.4282e-02, 3.5013e-04, 5.7853e-03, 7.1589e-03, 3.6928e-02, 4.1501e-02,
        1.9087e-03, 1.2496e-01, 2.3455e-01, 3.0400e-03, 5.1224e-02, 2.4105e-02,
        4.4421e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,116][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.3521, 0.0033, 0.0195, 0.0149, 0.0218, 0.0129, 0.0017, 0.0159, 0.0657,
        0.0139, 0.1155, 0.0536, 0.3091], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,117][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.2809, 0.0237, 0.1076, 0.0815, 0.1434, 0.0396, 0.0354, 0.0259, 0.0463,
        0.0593, 0.0617, 0.0151, 0.0796], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,117][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([2.3449e-01, 3.0320e-04, 6.1089e-03, 1.8227e-03, 5.8913e-03, 1.1096e-02,
        3.6142e-04, 5.0926e-03, 6.1065e-02, 3.2815e-03, 1.2069e-01, 2.3107e-02,
        5.2669e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,117][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.4193, 0.0094, 0.0264, 0.0331, 0.0580, 0.0381, 0.0108, 0.0230, 0.0350,
        0.0290, 0.0475, 0.0688, 0.2016], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,118][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.4121, 0.0126, 0.0461, 0.0417, 0.0429, 0.0412, 0.0260, 0.0475, 0.0490,
        0.0409, 0.0442, 0.0336, 0.1621], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,118][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.2180, 0.0089, 0.0546, 0.0333, 0.0659, 0.0563, 0.0140, 0.0402, 0.0809,
        0.0218, 0.1045, 0.0442, 0.2574], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,120][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0157, 0.0042, 0.0339, 0.0180, 0.0347, 0.0984, 0.0078, 0.0853, 0.1994,
        0.0217, 0.1796, 0.0858, 0.2155], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,121][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1297, 0.0800, 0.0415, 0.0651, 0.0779, 0.0061, 0.1291, 0.0944, 0.0046,
        0.0975, 0.0540, 0.1465, 0.0424, 0.0312], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,122][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([9.1201e-05, 1.5961e-01, 3.9585e-02, 2.0027e-01, 2.3130e-02, 5.4180e-02,
        1.9196e-02, 2.3310e-02, 1.6226e-01, 3.3856e-02, 9.8870e-02, 1.3437e-01,
        3.0340e-02, 2.0930e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,124][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1031, 0.0443, 0.0190, 0.0242, 0.0304, 0.0401, 0.1870, 0.1548, 0.0465,
        0.0802, 0.0512, 0.0501, 0.1073, 0.0619], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,125][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0633, 0.0383, 0.0511, 0.0512, 0.0580, 0.0370, 0.0964, 0.0484, 0.0859,
        0.0439, 0.0596, 0.0493, 0.2131, 0.1046], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,126][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([4.2030e-02, 9.4856e-05, 8.8677e-04, 1.4528e-03, 7.1729e-03, 6.2948e-03,
        4.1643e-04, 1.9997e-02, 4.1373e-02, 7.5559e-04, 1.0445e-02, 9.0651e-03,
        1.0100e-01, 7.5901e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,127][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.4742, 0.0024, 0.0063, 0.0074, 0.0080, 0.0044, 0.0008, 0.0044, 0.0203,
        0.0058, 0.0430, 0.0176, 0.1491, 0.2564], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,129][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.4599, 0.0183, 0.0695, 0.0532, 0.1218, 0.0347, 0.0262, 0.0153, 0.0330,
        0.0478, 0.0389, 0.0126, 0.0475, 0.0212], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,130][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([3.1681e-01, 7.4831e-05, 9.2317e-04, 5.0707e-04, 7.4409e-04, 2.1060e-03,
        8.1671e-05, 1.0584e-03, 9.1295e-03, 5.6527e-04, 1.8006e-02, 5.1875e-03,
        9.0559e-02, 5.5425e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,131][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.5318, 0.0056, 0.0133, 0.0359, 0.0346, 0.0167, 0.0079, 0.0098, 0.0177,
        0.0118, 0.0202, 0.0303, 0.0956, 0.1688], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,133][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.3611, 0.0087, 0.0273, 0.0370, 0.0361, 0.0428, 0.0206, 0.0339, 0.0465,
        0.0270, 0.0307, 0.0280, 0.1287, 0.1717], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,134][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.2490, 0.0080, 0.0385, 0.0297, 0.0518, 0.0386, 0.0101, 0.0300, 0.0469,
        0.0143, 0.0593, 0.0314, 0.1119, 0.2803], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,136][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0144, 0.0031, 0.0211, 0.0148, 0.0290, 0.0452, 0.0073, 0.0361, 0.1206,
        0.0178, 0.1135, 0.0739, 0.1718, 0.3315], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,137][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.1332, 0.0786, 0.0351, 0.0535, 0.0730, 0.0035, 0.1097, 0.0860, 0.0025,
        0.0752, 0.0449, 0.1455, 0.0358, 0.0221, 0.1013], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,139][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0006, 0.1130, 0.0486, 0.1565, 0.0172, 0.0509, 0.0449, 0.0614, 0.1279,
        0.0703, 0.1263, 0.0888, 0.0161, 0.0293, 0.0483], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,140][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0730, 0.0481, 0.0209, 0.0235, 0.0392, 0.0502, 0.1530, 0.1261, 0.0487,
        0.0670, 0.0484, 0.0610, 0.1074, 0.0577, 0.0759], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,142][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0230, 0.0743, 0.0475, 0.0343, 0.0578, 0.0242, 0.1800, 0.0520, 0.0689,
        0.0604, 0.0370, 0.0692, 0.0557, 0.0995, 0.1162], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,143][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([2.5058e-02, 4.5494e-05, 3.3450e-04, 6.4937e-04, 2.6922e-03, 1.1870e-03,
        1.3314e-04, 4.2587e-03, 1.0590e-02, 2.2892e-04, 3.3625e-03, 2.1722e-03,
        3.2710e-02, 3.3698e-01, 5.7960e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,144][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([2.2076e-01, 7.4859e-04, 2.4314e-03, 2.1954e-03, 2.5021e-03, 1.9352e-03,
        1.6829e-04, 1.4391e-03, 1.2637e-02, 1.7337e-03, 1.7027e-02, 6.9035e-03,
        7.2111e-02, 2.3252e-01, 4.2489e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,145][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.6165, 0.0093, 0.0425, 0.0310, 0.0690, 0.0278, 0.0152, 0.0111, 0.0219,
        0.0213, 0.0238, 0.0071, 0.0256, 0.0213, 0.0565], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,147][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([9.2274e-02, 2.4243e-05, 3.6640e-04, 8.9303e-05, 2.6942e-04, 5.4507e-04,
        1.1558e-05, 2.9552e-04, 3.9617e-03, 9.6227e-05, 7.7609e-03, 1.7440e-03,
        4.4801e-02, 4.3146e-01, 4.1630e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,147][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.3991, 0.0059, 0.0133, 0.0232, 0.0213, 0.0133, 0.0048, 0.0054, 0.0114,
        0.0092, 0.0155, 0.0239, 0.0674, 0.1669, 0.2194], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,147][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.3846, 0.0067, 0.0213, 0.0230, 0.0182, 0.0192, 0.0159, 0.0150, 0.0254,
        0.0189, 0.0195, 0.0150, 0.0625, 0.1205, 0.2342], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,148][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.1406, 0.0065, 0.0274, 0.0191, 0.0277, 0.0211, 0.0055, 0.0169, 0.0304,
        0.0088, 0.0420, 0.0224, 0.0709, 0.2386, 0.3222], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,148][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0056, 0.0024, 0.0140, 0.0171, 0.0179, 0.0250, 0.0036, 0.0210, 0.0716,
        0.0101, 0.0845, 0.0465, 0.0905, 0.2977, 0.2924], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,149][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([0.0940, 0.0792, 0.0341, 0.0525, 0.0737, 0.0044, 0.1289, 0.0839, 0.0033,
        0.0866, 0.0459, 0.1479, 0.0384, 0.0220, 0.0946, 0.0106],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,149][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([9.9792e-05, 5.5709e-02, 3.8366e-02, 2.1085e-01, 2.7768e-02, 4.7703e-02,
        6.5884e-02, 5.1730e-02, 1.5320e-01, 7.9103e-02, 9.7080e-02, 4.1417e-02,
        3.3600e-02, 2.9929e-02, 5.6454e-02, 1.1108e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,150][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.1154, 0.0364, 0.0227, 0.0221, 0.0349, 0.0355, 0.1382, 0.1032, 0.0407,
        0.0601, 0.0440, 0.0466, 0.1065, 0.0592, 0.0555, 0.0791],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,151][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([0.0171, 0.0212, 0.0220, 0.0290, 0.0623, 0.0245, 0.0620, 0.0654, 0.0614,
        0.0421, 0.0544, 0.0284, 0.2064, 0.0677, 0.1700, 0.0660],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,152][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([1.7992e-03, 1.2900e-05, 1.5966e-04, 2.9485e-04, 3.1937e-03, 1.2236e-03,
        8.0679e-05, 4.1381e-03, 8.1638e-03, 1.1694e-04, 1.9932e-03, 9.4991e-04,
        2.9314e-02, 1.7384e-01, 7.6605e-01, 8.6677e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,153][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([1.0680e-01, 6.4147e-04, 2.1319e-03, 1.6749e-03, 2.5569e-03, 1.2780e-03,
        1.9947e-04, 1.6876e-03, 1.0807e-02, 1.6727e-03, 1.9320e-02, 5.3780e-03,
        6.4447e-02, 1.5711e-01, 5.6482e-01, 5.9486e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,154][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([0.3454, 0.0107, 0.0618, 0.0412, 0.1558, 0.0374, 0.0204, 0.0197, 0.0394,
        0.0309, 0.0394, 0.0099, 0.0614, 0.0324, 0.0702, 0.0239],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,155][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([3.8809e-02, 2.1666e-05, 3.3734e-04, 4.9874e-05, 6.6326e-04, 7.5683e-04,
        1.4242e-05, 3.6402e-04, 5.6462e-03, 1.1554e-04, 7.1457e-03, 1.0858e-03,
        7.2148e-02, 3.2295e-01, 5.3108e-01, 1.8812e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,156][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.3038, 0.0023, 0.0103, 0.0142, 0.0279, 0.0111, 0.0047, 0.0067, 0.0138,
        0.0122, 0.0164, 0.0139, 0.0873, 0.1762, 0.2379, 0.0612],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,158][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([0.1968, 0.0046, 0.0193, 0.0193, 0.0196, 0.0209, 0.0122, 0.0249, 0.0361,
        0.0152, 0.0259, 0.0201, 0.0880, 0.1157, 0.2781, 0.1031],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,159][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.1170, 0.0034, 0.0175, 0.0098, 0.0267, 0.0196, 0.0040, 0.0130, 0.0331,
        0.0070, 0.0378, 0.0148, 0.0951, 0.2044, 0.2123, 0.1844],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,161][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([0.0064, 0.0013, 0.0101, 0.0073, 0.0123, 0.0200, 0.0019, 0.0197, 0.0485,
        0.0077, 0.0610, 0.0265, 0.0815, 0.2989, 0.2767, 0.1202],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,162][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1020, 0.0704, 0.0362, 0.0571, 0.0677, 0.0057, 0.1129, 0.0802, 0.0043,
        0.0814, 0.0471, 0.1274, 0.0361, 0.0276, 0.0947, 0.0125, 0.0368],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,163][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([3.5360e-05, 1.4942e-01, 2.6800e-02, 1.6070e-01, 1.5584e-02, 4.0822e-02,
        1.7718e-02, 1.6530e-02, 1.4842e-01, 2.8605e-02, 7.3640e-02, 1.3184e-01,
        2.1044e-02, 1.2617e-02, 5.1121e-02, 7.8438e-02, 2.6668e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,164][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0835, 0.0323, 0.0142, 0.0196, 0.0279, 0.0317, 0.1566, 0.1251, 0.0361,
        0.0727, 0.0448, 0.0470, 0.0975, 0.0507, 0.0534, 0.0724, 0.0345],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,166][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0498, 0.0326, 0.0369, 0.0401, 0.0408, 0.0232, 0.0589, 0.0278, 0.0567,
        0.0290, 0.0383, 0.0348, 0.1601, 0.0605, 0.0553, 0.1906, 0.0645],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,167][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.2345e-02, 2.3486e-05, 1.8639e-04, 3.8821e-04, 1.5643e-03, 1.2488e-03,
        9.1358e-05, 4.1367e-03, 9.8721e-03, 1.9818e-04, 2.2097e-03, 2.1244e-03,
        2.6320e-02, 1.8765e-01, 4.4712e-01, 1.9228e-02, 2.8529e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,168][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.4724e-01, 8.8449e-04, 2.0451e-03, 2.1903e-03, 2.8595e-03, 1.4135e-03,
        2.3493e-04, 1.4290e-03, 7.5774e-03, 1.7639e-03, 1.4137e-02, 5.6498e-03,
        6.3917e-02, 9.9180e-02, 4.1602e-01, 9.7020e-02, 1.3644e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,170][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.3346, 0.0213, 0.0594, 0.0539, 0.1220, 0.0371, 0.0265, 0.0147, 0.0359,
        0.0474, 0.0381, 0.0120, 0.0471, 0.0187, 0.0673, 0.0360, 0.0279],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,171][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.5936e-01, 3.3784e-05, 3.1062e-04, 1.7358e-04, 3.0219e-04, 6.9894e-04,
        2.2961e-05, 3.3785e-04, 3.7453e-03, 1.5357e-04, 6.1858e-03, 1.8789e-03,
        4.7854e-02, 2.3635e-01, 2.7509e-01, 3.1630e-02, 2.3587e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,172][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.3179, 0.0040, 0.0082, 0.0208, 0.0259, 0.0105, 0.0048, 0.0065, 0.0116,
        0.0081, 0.0125, 0.0185, 0.0642, 0.1005, 0.1789, 0.0686, 0.1384],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,174][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1626, 0.0059, 0.0167, 0.0228, 0.0208, 0.0251, 0.0118, 0.0202, 0.0281,
        0.0153, 0.0181, 0.0159, 0.0848, 0.0922, 0.2230, 0.1318, 0.1048],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,175][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1354, 0.0041, 0.0193, 0.0143, 0.0265, 0.0194, 0.0049, 0.0138, 0.0250,
        0.0070, 0.0305, 0.0148, 0.0639, 0.1430, 0.1896, 0.1316, 0.1570],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,177][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0077, 0.0018, 0.0116, 0.0072, 0.0151, 0.0248, 0.0034, 0.0188, 0.0715,
        0.0079, 0.0608, 0.0344, 0.0862, 0.1749, 0.1622, 0.1441, 0.1676],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,178][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:38,180][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[14731],
        [13765],
        [ 1503],
        [12143],
        [ 5956],
        [10677],
        [ 1601],
        [ 1655],
        [ 2010],
        [  238],
        [ 1155],
        [ 2582],
        [  448],
        [  308],
        [  513],
        [  265],
        [  258]], device='cuda:0')
[2024-07-24 10:29:38,181][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[14911],
        [38030],
        [11482],
        [34353],
        [21813],
        [20315],
        [13626],
        [10216],
        [ 8502],
        [ 6666],
        [ 8106],
        [17880],
        [ 5706],
        [ 3751],
        [ 6955],
        [ 4154],
        [ 3970]], device='cuda:0')
[2024-07-24 10:29:38,182][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[18868],
        [23609],
        [24893],
        [25224],
        [26065],
        [26206],
        [24048],
        [22568],
        [22857],
        [22789],
        [23170],
        [22440],
        [22676],
        [22440],
        [22647],
        [22945],
        [22728]], device='cuda:0')
[2024-07-24 10:29:38,183][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[17469],
        [41757],
        [32049],
        [48265],
        [47284],
        [46124],
        [42516],
        [39719],
        [38841],
        [36593],
        [36222],
        [35390],
        [33697],
        [35288],
        [33681],
        [31260],
        [31105]], device='cuda:0')
[2024-07-24 10:29:38,184][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[2402],
        [1547],
        [1926],
        [1795],
        [1781],
        [1739],
        [1790],
        [1748],
        [1726],
        [1671],
        [1672],
        [1666],
        [1674],
        [1703],
        [1703],
        [1784],
        [1833]], device='cuda:0')
[2024-07-24 10:29:38,186][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[36934],
        [ 6737],
        [16473],
        [20077],
        [17887],
        [15300],
        [15653],
        [13603],
        [13445],
        [13131],
        [12997],
        [12283],
        [12248],
        [12302],
        [12760],
        [12450],
        [12491]], device='cuda:0')
[2024-07-24 10:29:38,187][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[40584],
        [34908],
        [33965],
        [36002],
        [32687],
        [32577],
        [33312],
        [33070],
        [33458],
        [33199],
        [33273],
        [33700],
        [32914],
        [33122],
        [33558],
        [33635],
        [33946]], device='cuda:0')
[2024-07-24 10:29:38,189][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[3108],
        [3484],
        [3106],
        [3798],
        [4023],
        [3051],
        [3800],
        [3068],
        [4116],
        [5134],
        [3282],
        [4263],
        [4622],
        [5938],
        [4010],
        [6344],
        [6634]], device='cuda:0')
[2024-07-24 10:29:38,190][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 7830],
        [34508],
        [31314],
        [33696],
        [33344],
        [32925],
        [29713],
        [29944],
        [28646],
        [27204],
        [26812],
        [28059],
        [27929],
        [26615],
        [25754],
        [24574],
        [23433]], device='cuda:0')
[2024-07-24 10:29:38,192][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[39402],
        [39123],
        [38912],
        [38928],
        [38106],
        [32265],
        [15830],
        [37735],
        [36931],
        [23959],
        [38692],
        [34768],
        [38295],
        [38438],
        [32735],
        [26907],
        [37516]], device='cuda:0')
[2024-07-24 10:29:38,194][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[24704],
        [27334],
        [15081],
        [24016],
        [19099],
        [17547],
        [15996],
        [15389],
        [15322],
        [13438],
        [13191],
        [12976],
        [11464],
        [11436],
        [11995],
        [11766],
        [11623]], device='cuda:0')
[2024-07-24 10:29:38,195][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[29768],
        [ 8796],
        [11176],
        [ 6403],
        [ 7944],
        [ 8830],
        [ 9058],
        [10692],
        [ 9560],
        [ 9564],
        [ 8447],
        [ 7438],
        [ 8948],
        [ 9987],
        [ 8631],
        [ 7836],
        [ 7671]], device='cuda:0')
[2024-07-24 10:29:38,196][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[26170],
        [16052],
        [11486],
        [ 5011],
        [ 4870],
        [ 6258],
        [ 3159],
        [ 7028],
        [ 9505],
        [ 3231],
        [ 6574],
        [ 4681],
        [ 7487],
        [ 5917],
        [ 3668],
        [ 2123],
        [ 2508]], device='cuda:0')
[2024-07-24 10:29:38,198][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[13776],
        [ 1242],
        [11769],
        [50226],
        [50096],
        [50246],
        [41747],
        [50059],
        [50166],
        [33641],
        [45903],
        [43384],
        [23381],
        [31422],
        [42679],
        [23022],
        [28317]], device='cuda:0')
[2024-07-24 10:29:38,199][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[10990],
        [ 4153],
        [ 5064],
        [ 2993],
        [ 3717],
        [ 3990],
        [ 5800],
        [ 3560],
        [ 5146],
        [ 3765],
        [ 5690],
        [ 4135],
        [ 5591],
        [ 5042],
        [ 3348],
        [ 4189],
        [ 4276]], device='cuda:0')
[2024-07-24 10:29:38,201][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[1533],
        [1292],
        [1289],
        [1189],
        [1259],
        [1202],
        [1115],
        [1033],
        [1066],
        [1168],
        [1153],
        [1218],
        [1216],
        [1212],
        [1092],
        [1134],
        [1119]], device='cuda:0')
[2024-07-24 10:29:38,202][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[15061],
        [ 8004],
        [10658],
        [ 7379],
        [ 8790],
        [ 7641],
        [ 6484],
        [ 6102],
        [ 7561],
        [ 6287],
        [ 4780],
        [ 5996],
        [ 5185],
        [ 6307],
        [ 5182],
        [ 4688],
        [ 4881]], device='cuda:0')
[2024-07-24 10:29:38,204][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[8512],
        [4745],
        [6067],
        [6210],
        [8056],
        [9161],
        [8889],
        [8596],
        [8680],
        [7925],
        [8004],
        [7980],
        [8005],
        [7812],
        [7548],
        [7138],
        [6963]], device='cuda:0')
[2024-07-24 10:29:38,205][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[43320],
        [30307],
        [22953],
        [14331],
        [15520],
        [18293],
        [16810],
        [14125],
        [10620],
        [21513],
        [18763],
        [19901],
        [ 7764],
        [13558],
        [22168],
        [19214],
        [16758]], device='cuda:0')
[2024-07-24 10:29:38,207][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[35090],
        [ 8483],
        [10860],
        [14201],
        [16209],
        [13799],
        [13383],
        [13047],
        [ 9880],
        [ 9620],
        [ 9385],
        [ 9370],
        [12096],
        [15667],
        [16790],
        [17757],
        [16004]], device='cuda:0')
[2024-07-24 10:29:38,208][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[45768],
        [41286],
        [31977],
        [25731],
        [26102],
        [28006],
        [23125],
        [25994],
        [28839],
        [14839],
        [19520],
        [14815],
        [30467],
        [27133],
        [24751],
        [25574],
        [24915]], device='cuda:0')
[2024-07-24 10:29:38,209][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[24116],
        [13746],
        [ 7216],
        [ 3634],
        [ 1722],
        [ 5691],
        [ 3487],
        [ 6038],
        [ 9653],
        [ 3487],
        [ 3908],
        [ 3503],
        [ 3363],
        [ 4374],
        [ 9445],
        [ 5731],
        [ 5504]], device='cuda:0')
[2024-07-24 10:29:38,211][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 8656],
        [23711],
        [10957],
        [10007],
        [16313],
        [18425],
        [22653],
        [24787],
        [29794],
        [27998],
        [22454],
        [20705],
        [19280],
        [21681],
        [26381],
        [27385],
        [22421]], device='cuda:0')
[2024-07-24 10:29:38,213][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[25514],
        [17852],
        [11876],
        [ 9271],
        [ 8750],
        [10322],
        [ 8386],
        [10174],
        [12334],
        [12307],
        [15979],
        [15634],
        [ 7696],
        [13631],
        [15255],
        [13692],
        [15640]], device='cuda:0')
[2024-07-24 10:29:38,214][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[14479],
        [ 4566],
        [ 5428],
        [ 3789],
        [ 3458],
        [ 4231],
        [ 5999],
        [ 5641],
        [ 6222],
        [ 6442],
        [ 6148],
        [ 5470],
        [ 6923],
        [ 5688],
        [ 6861],
        [ 7276],
        [ 6635]], device='cuda:0')
[2024-07-24 10:29:38,215][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 9271],
        [10205],
        [ 7690],
        [11151],
        [12798],
        [10841],
        [13898],
        [ 9841],
        [10220],
        [14178],
        [10568],
        [14490],
        [16773],
        [15276],
        [27752],
        [25996],
        [25508]], device='cuda:0')
[2024-07-24 10:29:38,216][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[15328],
        [24570],
        [14907],
        [12569],
        [ 8002],
        [16131],
        [20014],
        [33591],
        [25078],
        [30242],
        [32995],
        [37542],
        [36704],
        [40132],
        [46152],
        [45790],
        [44050]], device='cuda:0')
[2024-07-24 10:29:38,217][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[27734],
        [43148],
        [47808],
        [49251],
        [49151],
        [48219],
        [47831],
        [47404],
        [45952],
        [46699],
        [47445],
        [47080],
        [47576],
        [46812],
        [42360],
        [42403],
        [44241]], device='cuda:0')
[2024-07-24 10:29:38,218][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[41211],
        [48005],
        [48260],
        [48499],
        [48482],
        [48050],
        [46903],
        [47439],
        [46580],
        [47743],
        [47288],
        [48058],
        [47091],
        [47405],
        [46279],
        [47730],
        [47729]], device='cuda:0')
[2024-07-24 10:29:38,220][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535]], device='cuda:0')
[2024-07-24 10:29:38,275][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:38,276][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,277][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,277][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,277][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,278][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,278][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,278][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,279][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,279][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,279][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,280][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,280][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,282][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Sara] are: tensor([0.8105, 0.1895], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,283][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Sara] are: tensor([0.0443, 0.9557], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,284][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Sara] are: tensor([0.9632, 0.0368], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,286][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Sara] are: tensor([0.9577, 0.0423], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,287][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Sara] are: tensor([0.5662, 0.4338], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,297][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Sara] are: tensor([0.1766, 0.8234], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,298][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Sara] are: tensor([0.0143, 0.9857], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,300][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Sara] are: tensor([0.4751, 0.5249], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,301][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Sara] are: tensor([0.7755, 0.2245], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,303][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Sara] are: tensor([0.0356, 0.9644], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,304][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Sara] are: tensor([0.7293, 0.2707], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,305][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Sara] are: tensor([0.0215, 0.9785], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,307][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.8690, 0.0840, 0.0470], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,308][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0365, 0.7398, 0.2237], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,309][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.9592, 0.0260, 0.0148], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,309][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.6769, 0.0067, 0.3164], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,309][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2612, 0.2915, 0.4473], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,310][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0773, 0.3443, 0.5783], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,310][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0055, 0.4575, 0.5370], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,310][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.5678, 0.2203, 0.2119], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,311][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.8881, 0.0548, 0.0572], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,311][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0068, 0.7474, 0.2458], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,311][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2222, 0.0571, 0.7206], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,313][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0097, 0.5465, 0.4439], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,314][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Kenneth] are: tensor([0.8814, 0.0655, 0.0402, 0.0130], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,315][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Kenneth] are: tensor([0.0255, 0.5260, 0.1584, 0.2901], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,317][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Kenneth] are: tensor([0.8582, 0.0309, 0.0171, 0.0937], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,318][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Kenneth] are: tensor([0.1556, 0.0162, 0.7746, 0.0536], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,319][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Kenneth] are: tensor([0.1857, 0.2087, 0.3592, 0.2463], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,320][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Kenneth] are: tensor([0.0534, 0.2483, 0.4514, 0.2469], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,322][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Kenneth] are: tensor([0.0033, 0.3317, 0.4593, 0.2057], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,323][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Kenneth] are: tensor([0.2137, 0.2913, 0.3590, 0.1361], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,325][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Kenneth] are: tensor([0.4807, 0.1878, 0.2750, 0.0564], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,326][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Kenneth] are: tensor([0.0075, 0.5934, 0.2234, 0.1757], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,328][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Kenneth] are: tensor([0.0720, 0.0376, 0.7816, 0.1088], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,329][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Kenneth] are: tensor([0.0060, 0.3935, 0.3166, 0.2840], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,330][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.9276, 0.0392, 0.0207, 0.0070, 0.0056], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,332][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.0095, 0.5137, 0.0982, 0.2753, 0.1033], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,333][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.7789, 0.0359, 0.0416, 0.0517, 0.0919], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,335][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.3415, 0.0126, 0.3841, 0.0568, 0.2049], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,336][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.1462, 0.1710, 0.2363, 0.1911, 0.2554], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,337][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.0441, 0.1717, 0.3434, 0.1703, 0.2705], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,339][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.0018, 0.2684, 0.3414, 0.1611, 0.2273], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,340][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.1519, 0.2183, 0.3217, 0.1006, 0.2075], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,340][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.6742, 0.0956, 0.1097, 0.0529, 0.0676], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,341][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.0061, 0.5669, 0.1781, 0.1481, 0.1007], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,341][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.1452, 0.0330, 0.4929, 0.0850, 0.2440], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,341][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.0038, 0.2891, 0.2434, 0.2218, 0.2419], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,342][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.9141, 0.0480, 0.0185, 0.0074, 0.0058, 0.0062], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,342][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0172, 0.2755, 0.1611, 0.2688, 0.1448, 0.1325], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,343][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.9309, 0.0115, 0.0044, 0.0224, 0.0218, 0.0089], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,343][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.5090, 0.0037, 0.1501, 0.0317, 0.1698, 0.1358], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,344][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1657, 0.1291, 0.1919, 0.1418, 0.2055, 0.1660], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,345][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0378, 0.1521, 0.2396, 0.1438, 0.1904, 0.2364], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,346][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0013, 0.1821, 0.2302, 0.1110, 0.1598, 0.3156], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,348][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.2687, 0.1176, 0.1535, 0.0647, 0.1236, 0.2718], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,349][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.8080, 0.0674, 0.0471, 0.0289, 0.0354, 0.0131], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,350][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0053, 0.5346, 0.1442, 0.1143, 0.0841, 0.1175], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,351][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2093, 0.0154, 0.2556, 0.0653, 0.2017, 0.2527], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,353][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0032, 0.2333, 0.1955, 0.1835, 0.1929, 0.1917], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,354][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.9185, 0.0445, 0.0152, 0.0065, 0.0051, 0.0057, 0.0044],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,355][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.0066, 0.2714, 0.1336, 0.1517, 0.1384, 0.1569, 0.1413],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,357][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.4310, 0.1051, 0.1217, 0.1492, 0.1096, 0.0503, 0.0331],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,358][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0076, 0.0067, 0.3268, 0.0282, 0.2076, 0.4201, 0.0029],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,360][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.1325, 0.1062, 0.1786, 0.1275, 0.1738, 0.1491, 0.1323],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,361][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.0239, 0.1206, 0.2414, 0.1155, 0.1820, 0.2001, 0.1165],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,363][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.0012, 0.1505, 0.1818, 0.0907, 0.1356, 0.2645, 0.1756],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,364][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.0490, 0.1606, 0.2015, 0.0563, 0.1413, 0.3491, 0.0423],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,365][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.3103, 0.0923, 0.2270, 0.0552, 0.1064, 0.1800, 0.0288],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,367][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.0026, 0.5806, 0.1060, 0.1065, 0.0626, 0.0863, 0.0554],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,368][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.0044, 0.0218, 0.2131, 0.0674, 0.2659, 0.4205, 0.0070],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,370][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0029, 0.1799, 0.1622, 0.1383, 0.1568, 0.1719, 0.1880],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,371][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.8983, 0.0474, 0.0175, 0.0078, 0.0059, 0.0062, 0.0044, 0.0126],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,372][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0129, 0.3509, 0.0697, 0.1616, 0.0743, 0.0986, 0.0873, 0.1447],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,372][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.5346, 0.1005, 0.0548, 0.0952, 0.1174, 0.0633, 0.0071, 0.0271],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,373][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.4170, 0.0040, 0.1336, 0.0254, 0.1386, 0.1472, 0.0021, 0.1321],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,373][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.1703, 0.0869, 0.1558, 0.0898, 0.1592, 0.1373, 0.0934, 0.1074],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,373][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0216, 0.1071, 0.1965, 0.1010, 0.1552, 0.1801, 0.0999, 0.1385],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,374][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0011, 0.1320, 0.1440, 0.0735, 0.1035, 0.1982, 0.1291, 0.2184],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,374][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.1975, 0.1306, 0.1203, 0.0535, 0.1265, 0.2343, 0.0561, 0.0812],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,375][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.5322, 0.2199, 0.0882, 0.0573, 0.0526, 0.0354, 0.0071, 0.0073],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,375][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0041, 0.4661, 0.1035, 0.0976, 0.0603, 0.0889, 0.0550, 0.1245],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,377][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.1242, 0.0104, 0.1490, 0.0346, 0.1166, 0.1968, 0.0023, 0.3661],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,378][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0020, 0.1687, 0.1358, 0.1261, 0.1310, 0.1412, 0.1710, 0.1244],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,379][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.9009, 0.0464, 0.0139, 0.0068, 0.0050, 0.0052, 0.0038, 0.0107, 0.0074],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,381][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0110, 0.2348, 0.0790, 0.1662, 0.0590, 0.0644, 0.1244, 0.1504, 0.1109],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,382][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.7479, 0.0395, 0.0289, 0.0536, 0.0651, 0.0329, 0.0033, 0.0148, 0.0138],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,383][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ the] are: tensor([6.3810e-01, 1.0121e-03, 4.8997e-02, 4.3939e-03, 2.9553e-02, 6.1868e-02,
        3.2422e-04, 4.6732e-02, 1.6902e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,384][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1784, 0.0716, 0.1360, 0.0926, 0.1397, 0.1016, 0.0980, 0.0864, 0.0957],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,386][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0180, 0.0968, 0.1582, 0.0938, 0.1261, 0.1523, 0.0949, 0.1176, 0.1423],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,387][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0007, 0.1061, 0.1179, 0.0607, 0.0824, 0.1462, 0.1113, 0.1750, 0.1996],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,389][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1573, 0.0863, 0.1381, 0.0472, 0.1095, 0.2278, 0.0381, 0.1011, 0.0946],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,390][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.5164, 0.2451, 0.0878, 0.0527, 0.0551, 0.0216, 0.0082, 0.0085, 0.0047],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,392][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0029, 0.4357, 0.0918, 0.0901, 0.0507, 0.0717, 0.0477, 0.1066, 0.1029],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,393][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ the] are: tensor([3.1705e-01, 2.1647e-03, 4.1197e-02, 4.8015e-03, 2.8756e-02, 4.5399e-02,
        3.2496e-04, 1.1762e-01, 4.4269e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,394][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0020, 0.1425, 0.1234, 0.1090, 0.1179, 0.1246, 0.1501, 0.1099, 0.1205],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,396][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ garden] are: tensor([0.8941, 0.0484, 0.0151, 0.0070, 0.0050, 0.0053, 0.0041, 0.0108, 0.0075,
        0.0027], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,397][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ garden] are: tensor([0.0070, 0.1675, 0.0685, 0.0800, 0.0436, 0.0687, 0.1346, 0.1305, 0.1311,
        0.1683], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,399][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ garden] are: tensor([0.2490, 0.1698, 0.2018, 0.0678, 0.0696, 0.0744, 0.0218, 0.0556, 0.0777,
        0.0125], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,400][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ garden] are: tensor([1.6384e-02, 9.7547e-04, 5.8522e-02, 5.0939e-03, 5.3000e-02, 5.2184e-02,
        3.8584e-04, 7.3720e-02, 7.1592e-01, 2.3820e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,401][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ garden] are: tensor([0.1020, 0.0667, 0.1343, 0.0963, 0.1229, 0.0983, 0.0897, 0.0890, 0.1111,
        0.0897], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,403][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ garden] are: tensor([0.0169, 0.0847, 0.1603, 0.0815, 0.1265, 0.1363, 0.0797, 0.1071, 0.1205,
        0.0865], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,403][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ garden] are: tensor([0.0005, 0.0925, 0.1012, 0.0538, 0.0698, 0.1460, 0.0960, 0.1676, 0.1857,
        0.0869], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,404][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ garden] are: tensor([0.0497, 0.0936, 0.1774, 0.0325, 0.0998, 0.2623, 0.0337, 0.1070, 0.1071,
        0.0369], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,404][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ garden] are: tensor([0.3258, 0.2097, 0.1393, 0.0434, 0.0854, 0.0552, 0.0202, 0.0241, 0.0327,
        0.0641], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,405][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ garden] are: tensor([0.0013, 0.4655, 0.0807, 0.0854, 0.0412, 0.0635, 0.0352, 0.1065, 0.0859,
        0.0347], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,405][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ garden] are: tensor([2.9218e-03, 1.9094e-03, 2.2225e-02, 4.6477e-03, 1.8672e-02, 3.3693e-02,
        1.7700e-04, 8.4303e-02, 8.2048e-01, 1.0968e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,406][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ garden] are: tensor([0.0017, 0.1282, 0.1107, 0.0952, 0.1047, 0.1171, 0.1306, 0.0930, 0.1132,
        0.1057], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,406][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.8883, 0.0461, 0.0151, 0.0070, 0.0048, 0.0051, 0.0037, 0.0104, 0.0077,
        0.0026, 0.0092], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,406][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0031, 0.2037, 0.0499, 0.1052, 0.0566, 0.0852, 0.0625, 0.0952, 0.1177,
        0.1716, 0.0492], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,408][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2919, 0.0703, 0.0620, 0.1570, 0.1102, 0.1005, 0.0092, 0.0328, 0.1232,
        0.0066, 0.0365], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,409][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([5.9986e-01, 4.7018e-04, 2.4701e-02, 1.8706e-03, 8.8672e-03, 2.3798e-02,
        2.5729e-04, 1.8073e-02, 9.7556e-02, 6.6120e-03, 2.1794e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,410][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1170, 0.0572, 0.1126, 0.0713, 0.1105, 0.0895, 0.0756, 0.0758, 0.0993,
        0.0811, 0.1099], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,411][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0188, 0.0707, 0.1343, 0.0718, 0.1030, 0.1209, 0.0674, 0.0895, 0.1076,
        0.0746, 0.1414], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,413][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0007, 0.0831, 0.0876, 0.0468, 0.0618, 0.1199, 0.0811, 0.1409, 0.1618,
        0.0736, 0.1427], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,414][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1902, 0.0973, 0.1010, 0.0459, 0.1001, 0.1888, 0.0304, 0.0634, 0.0745,
        0.0558, 0.0525], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,416][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.5271, 0.2424, 0.0643, 0.0560, 0.0413, 0.0159, 0.0054, 0.0069, 0.0039,
        0.0207, 0.0161], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,417][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0032, 0.3893, 0.0748, 0.0775, 0.0448, 0.0707, 0.0356, 0.1006, 0.0953,
        0.0381, 0.0701], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,418][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([1.2744e-01, 2.1252e-03, 3.1814e-02, 5.5375e-03, 1.3595e-02, 3.6531e-02,
        3.3433e-04, 6.8234e-02, 4.3774e-01, 1.5881e-02, 2.6077e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,420][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0017, 0.1207, 0.0937, 0.0852, 0.0984, 0.1022, 0.1204, 0.0843, 0.0953,
        0.1002, 0.0979], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,421][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Sara] are: tensor([0.9114, 0.0359, 0.0123, 0.0055, 0.0038, 0.0040, 0.0030, 0.0075, 0.0057,
        0.0018, 0.0065, 0.0025], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,423][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Sara] are: tensor([0.0029, 0.1319, 0.0505, 0.0715, 0.0595, 0.0465, 0.0926, 0.0723, 0.0912,
        0.1265, 0.0603, 0.1943], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,424][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Sara] are: tensor([0.3763, 0.0313, 0.1532, 0.0839, 0.0560, 0.1255, 0.0078, 0.0268, 0.0521,
        0.0069, 0.0603, 0.0198], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,425][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Sara] are: tensor([5.0028e-02, 1.1117e-03, 5.5771e-02, 3.7175e-03, 2.5666e-02, 3.8639e-02,
        2.6763e-04, 3.5273e-02, 2.7727e-01, 1.3949e-02, 4.8089e-01, 1.7416e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,426][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Sara] are: tensor([0.1133, 0.0499, 0.1161, 0.0737, 0.1244, 0.0866, 0.0774, 0.0652, 0.0794,
        0.0803, 0.0882, 0.0455], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,428][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Sara] are: tensor([0.0154, 0.0717, 0.1252, 0.0679, 0.0968, 0.1030, 0.0663, 0.0782, 0.0918,
        0.0675, 0.1321, 0.0840], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,429][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Sara] are: tensor([0.0006, 0.0635, 0.0783, 0.0396, 0.0602, 0.1192, 0.0726, 0.1251, 0.1431,
        0.0661, 0.1212, 0.1103], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,431][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Sara] are: tensor([0.0894, 0.0675, 0.1391, 0.0358, 0.0841, 0.2152, 0.0295, 0.0730, 0.0788,
        0.0413, 0.0780, 0.0685], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,432][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Sara] are: tensor([0.2874, 0.1347, 0.1044, 0.0545, 0.0441, 0.1032, 0.0207, 0.0133, 0.0301,
        0.0412, 0.0432, 0.1232], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,434][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Sara] are: tensor([0.0027, 0.3976, 0.0836, 0.0658, 0.0484, 0.0547, 0.0331, 0.0852, 0.0832,
        0.0355, 0.0595, 0.0506], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,435][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Sara] are: tensor([2.2085e-02, 1.0451e-03, 2.8766e-02, 4.1685e-03, 1.4201e-02, 2.6717e-02,
        1.5818e-04, 4.3801e-02, 5.7053e-01, 9.5429e-03, 2.5829e-01, 2.0692e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,435][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Sara] are: tensor([0.0015, 0.1055, 0.0889, 0.0818, 0.0832, 0.0932, 0.1033, 0.0740, 0.0880,
        0.0855, 0.1006, 0.0945], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,436][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.9052, 0.0403, 0.0118, 0.0055, 0.0039, 0.0040, 0.0028, 0.0079, 0.0056,
        0.0018, 0.0067, 0.0026, 0.0017], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,436][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0037, 0.1320, 0.0419, 0.0812, 0.0352, 0.0525, 0.0731, 0.0874, 0.0870,
        0.1026, 0.0526, 0.1966, 0.0543], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,436][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0728, 0.0749, 0.0909, 0.0455, 0.1078, 0.0948, 0.0099, 0.0279, 0.0726,
        0.0043, 0.0295, 0.0228, 0.3462], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,437][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([2.9149e-01, 1.3902e-04, 6.9467e-03, 3.4628e-04, 3.2635e-03, 7.4826e-03,
        3.0095e-05, 3.1085e-03, 5.4726e-02, 1.1947e-03, 7.2668e-02, 2.7189e-03,
        5.5589e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,437][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.0798, 0.0616, 0.0996, 0.0628, 0.1183, 0.0880, 0.0644, 0.0686, 0.0909,
        0.0783, 0.0909, 0.0514, 0.0455], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,438][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.0147, 0.0528, 0.1276, 0.0532, 0.0909, 0.0938, 0.0515, 0.0752, 0.0852,
        0.0583, 0.1312, 0.0661, 0.0994], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,438][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0006, 0.0621, 0.0719, 0.0376, 0.0520, 0.1024, 0.0637, 0.1152, 0.1305,
        0.0601, 0.1137, 0.1090, 0.0810], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,440][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.1216, 0.0692, 0.1034, 0.0406, 0.0758, 0.1448, 0.0278, 0.0568, 0.0635,
        0.0403, 0.0529, 0.0704, 0.1329], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,441][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.6233, 0.0604, 0.0489, 0.0225, 0.0202, 0.0409, 0.0060, 0.0127, 0.0131,
        0.0282, 0.0225, 0.0496, 0.0518], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,442][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0018, 0.3167, 0.0795, 0.0719, 0.0431, 0.0663, 0.0341, 0.1095, 0.0914,
        0.0370, 0.0676, 0.0486, 0.0325], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,443][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([1.0244e-01, 6.2426e-04, 8.2717e-03, 9.4377e-04, 4.3329e-03, 1.0068e-02,
        3.2515e-05, 1.1113e-02, 1.2516e-01, 1.1438e-03, 7.0613e-02, 8.3968e-03,
        6.5686e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,445][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0014, 0.0943, 0.0771, 0.0712, 0.0763, 0.0812, 0.0978, 0.0669, 0.0798,
        0.0801, 0.0898, 0.0849, 0.0991], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,446][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.8887, 0.0483, 0.0131, 0.0064, 0.0042, 0.0043, 0.0031, 0.0089, 0.0062,
        0.0021, 0.0074, 0.0030, 0.0019, 0.0023], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,448][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0032, 0.1248, 0.0358, 0.0555, 0.0441, 0.0600, 0.0505, 0.0766, 0.0880,
        0.1174, 0.0441, 0.1827, 0.0602, 0.0570], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,449][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1672, 0.0651, 0.0674, 0.1350, 0.0970, 0.0941, 0.0084, 0.0216, 0.0668,
        0.0055, 0.0315, 0.0145, 0.1982, 0.0275], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,450][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([3.7737e-01, 4.0499e-05, 9.7843e-04, 1.0806e-04, 2.9131e-04, 7.4842e-04,
        8.0207e-06, 3.5092e-04, 3.7193e-03, 2.0341e-04, 9.1707e-03, 4.6383e-04,
        8.1141e-02, 5.2541e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,452][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0867, 0.0537, 0.0956, 0.0631, 0.1074, 0.0837, 0.0609, 0.0657, 0.0870,
        0.0591, 0.0865, 0.0513, 0.0400, 0.0592], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,453][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0126, 0.0565, 0.0961, 0.0552, 0.0767, 0.0908, 0.0544, 0.0686, 0.0809,
        0.0587, 0.1052, 0.0665, 0.0800, 0.0978], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,455][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0004, 0.0608, 0.0656, 0.0365, 0.0486, 0.0934, 0.0576, 0.1052, 0.1209,
        0.0551, 0.1035, 0.0983, 0.0757, 0.0783], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,456][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1145, 0.0710, 0.0723, 0.0324, 0.0690, 0.1378, 0.0237, 0.0505, 0.0564,
        0.0355, 0.0494, 0.0773, 0.1289, 0.0811], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,458][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.3653, 0.2311, 0.0764, 0.0383, 0.0204, 0.0272, 0.0098, 0.0078, 0.0086,
        0.0260, 0.0188, 0.0891, 0.0651, 0.0161], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,459][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0020, 0.2568, 0.0758, 0.0615, 0.0435, 0.0689, 0.0355, 0.1052, 0.1004,
        0.0386, 0.0703, 0.0491, 0.0339, 0.0585], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,460][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([3.6390e-01, 3.4022e-04, 2.1384e-03, 3.8663e-04, 1.0352e-03, 2.6048e-03,
        1.9381e-05, 2.1459e-03, 2.6988e-02, 5.6480e-04, 1.9032e-02, 2.7515e-03,
        1.6149e-01, 4.1660e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,462][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0014, 0.0832, 0.0732, 0.0643, 0.0695, 0.0752, 0.0893, 0.0642, 0.0737,
        0.0744, 0.0799, 0.0763, 0.0853, 0.0901], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,463][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.9210, 0.0353, 0.0090, 0.0042, 0.0029, 0.0029, 0.0021, 0.0058, 0.0042,
        0.0013, 0.0051, 0.0020, 0.0012, 0.0015, 0.0015], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,465][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0050, 0.1137, 0.0400, 0.0703, 0.0294, 0.0497, 0.0439, 0.0722, 0.0849,
        0.0932, 0.0453, 0.1612, 0.0298, 0.0590, 0.1024], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,466][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.1644, 0.0486, 0.0713, 0.0431, 0.0798, 0.0397, 0.0056, 0.0161, 0.0383,
        0.0038, 0.0223, 0.0108, 0.2900, 0.0198, 0.1463], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,467][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ give] are: tensor([1.3841e-01, 1.7581e-05, 3.8383e-04, 2.2368e-05, 1.4607e-04, 2.9113e-04,
        5.2981e-07, 1.3862e-04, 2.9495e-03, 3.4221e-05, 5.7722e-03, 1.8783e-04,
        5.2073e-02, 6.8552e-01, 1.1406e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,467][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.1237, 0.0605, 0.0919, 0.0617, 0.0975, 0.0777, 0.0501, 0.0555, 0.0719,
        0.0506, 0.0752, 0.0410, 0.0342, 0.0474, 0.0611], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,468][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0113, 0.0473, 0.0983, 0.0448, 0.0707, 0.0861, 0.0439, 0.0623, 0.0762,
        0.0503, 0.1029, 0.0570, 0.0738, 0.0901, 0.0850], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,468][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0004, 0.0625, 0.0626, 0.0339, 0.0404, 0.0829, 0.0549, 0.0935, 0.1102,
        0.0506, 0.0951, 0.0932, 0.0608, 0.0676, 0.0913], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,469][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0661, 0.0640, 0.0826, 0.0320, 0.0600, 0.1413, 0.0229, 0.0484, 0.0519,
        0.0373, 0.0470, 0.0716, 0.1236, 0.0737, 0.0778], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,469][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.2756, 0.1970, 0.0405, 0.0323, 0.0243, 0.0236, 0.0053, 0.0049, 0.0072,
        0.0238, 0.0136, 0.1016, 0.0840, 0.0097, 0.1566], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,469][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0024, 0.3547, 0.0706, 0.0674, 0.0368, 0.0546, 0.0304, 0.0737, 0.0768,
        0.0323, 0.0580, 0.0388, 0.0240, 0.0480, 0.0314], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,470][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ give] are: tensor([9.5031e-02, 5.4274e-05, 6.9768e-04, 1.1636e-04, 3.0728e-04, 7.0647e-04,
        2.5407e-06, 5.5346e-04, 9.2605e-03, 1.5690e-04, 5.0173e-03, 5.5455e-04,
        7.2160e-02, 4.3897e-01, 3.7641e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,472][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0010, 0.0758, 0.0691, 0.0600, 0.0650, 0.0700, 0.0799, 0.0594, 0.0693,
        0.0654, 0.0763, 0.0711, 0.0802, 0.0825, 0.0752], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,473][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.9134, 0.0386, 0.0106, 0.0048, 0.0032, 0.0030, 0.0021, 0.0063, 0.0044,
        0.0013, 0.0052, 0.0019, 0.0012, 0.0015, 0.0014, 0.0012],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,475][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ it] are: tensor([0.0029, 0.0747, 0.0390, 0.0496, 0.0374, 0.0413, 0.0432, 0.0803, 0.0713,
        0.0934, 0.0547, 0.1089, 0.0422, 0.0660, 0.1194, 0.0756],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,476][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.0527, 0.0222, 0.1631, 0.0293, 0.0786, 0.0967, 0.0025, 0.0397, 0.0436,
        0.0018, 0.0470, 0.0045, 0.1550, 0.0212, 0.1641, 0.0779],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,477][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ it] are: tensor([3.9282e-02, 1.3027e-05, 4.3326e-04, 2.8537e-05, 3.1141e-04, 6.1541e-04,
        1.5771e-06, 1.6287e-04, 4.5931e-03, 6.6428e-05, 5.7694e-03, 1.0573e-04,
        5.5706e-02, 5.4246e-01, 3.3614e-01, 1.4313e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,479][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.0945, 0.0512, 0.0830, 0.0608, 0.0884, 0.0705, 0.0456, 0.0521, 0.0712,
        0.0525, 0.0738, 0.0420, 0.0368, 0.0441, 0.0581, 0.0753],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,480][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ it] are: tensor([0.0103, 0.0444, 0.0871, 0.0442, 0.0719, 0.0767, 0.0472, 0.0582, 0.0687,
        0.0479, 0.0927, 0.0528, 0.0719, 0.0811, 0.0770, 0.0679],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,482][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.0003, 0.0448, 0.0535, 0.0282, 0.0412, 0.0776, 0.0525, 0.0854, 0.0997,
        0.0471, 0.0847, 0.0838, 0.0643, 0.0646, 0.0929, 0.0794],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,483][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.0672, 0.0548, 0.0845, 0.0287, 0.0675, 0.1373, 0.0240, 0.0492, 0.0486,
        0.0472, 0.0425, 0.0550, 0.1174, 0.0755, 0.0726, 0.0279],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,485][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.0589, 0.1269, 0.0648, 0.0284, 0.0203, 0.0320, 0.0102, 0.0117, 0.0081,
        0.0397, 0.0437, 0.1055, 0.1049, 0.0335, 0.1760, 0.1355],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,486][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ it] are: tensor([0.0022, 0.2778, 0.0659, 0.0555, 0.0361, 0.0569, 0.0335, 0.0904, 0.0820,
        0.0329, 0.0542, 0.0454, 0.0312, 0.0545, 0.0338, 0.0477],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,487][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ it] are: tensor([7.1480e-03, 4.0648e-05, 4.1214e-04, 5.6161e-05, 2.4005e-04, 6.5282e-04,
        2.5436e-06, 7.1711e-04, 1.7157e-02, 1.2729e-04, 7.1767e-03, 3.4636e-04,
        7.4783e-02, 3.0915e-01, 4.9150e-01, 9.0489e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,489][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ it] are: tensor([0.0012, 0.0714, 0.0650, 0.0565, 0.0607, 0.0661, 0.0772, 0.0566, 0.0641,
        0.0636, 0.0715, 0.0657, 0.0759, 0.0752, 0.0682, 0.0613],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,489][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.1511e-01, 3.8021e-02, 1.0217e-02, 4.5528e-03, 2.8627e-03, 2.9382e-03,
        2.0048e-03, 5.9533e-03, 4.1918e-03, 1.3278e-03, 5.0489e-03, 1.8405e-03,
        1.1791e-03, 1.5247e-03, 1.4225e-03, 1.1558e-03, 6.5352e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,491][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0017, 0.0996, 0.0242, 0.0431, 0.0295, 0.0407, 0.0372, 0.0522, 0.0589,
        0.0854, 0.0305, 0.1422, 0.0434, 0.0391, 0.1075, 0.1259, 0.0389],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,493][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0437, 0.0428, 0.0751, 0.0953, 0.0678, 0.0981, 0.0080, 0.0213, 0.0759,
        0.0046, 0.0323, 0.0109, 0.1399, 0.0256, 0.1337, 0.1027, 0.0223],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,493][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.8088e-01, 3.7169e-05, 6.1621e-04, 7.6090e-05, 2.0669e-04, 4.0130e-04,
        4.4371e-06, 2.0983e-04, 2.5999e-03, 1.0994e-04, 5.3120e-03, 3.8576e-04,
        5.8163e-02, 3.5189e-01, 1.1209e-01, 2.2058e-02, 2.6497e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,495][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0678, 0.0457, 0.0819, 0.0549, 0.0863, 0.0657, 0.0465, 0.0525, 0.0669,
        0.0466, 0.0692, 0.0393, 0.0329, 0.0456, 0.0608, 0.0750, 0.0626],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,497][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0099, 0.0446, 0.0771, 0.0445, 0.0611, 0.0723, 0.0437, 0.0544, 0.0641,
        0.0470, 0.0841, 0.0532, 0.0631, 0.0771, 0.0676, 0.0623, 0.0740],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,498][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0003, 0.0498, 0.0510, 0.0291, 0.0376, 0.0729, 0.0440, 0.0810, 0.0955,
        0.0424, 0.0797, 0.0792, 0.0589, 0.0589, 0.0859, 0.0739, 0.0598],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,499][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0759, 0.0638, 0.0643, 0.0297, 0.0609, 0.1212, 0.0231, 0.0431, 0.0481,
        0.0337, 0.0405, 0.0673, 0.1097, 0.0662, 0.0781, 0.0255, 0.0491],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,499][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1028, 0.2100, 0.0750, 0.0315, 0.0158, 0.0252, 0.0091, 0.0077, 0.0069,
        0.0260, 0.0205, 0.0897, 0.0652, 0.0161, 0.1438, 0.1333, 0.0212],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,500][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0015, 0.2558, 0.0661, 0.0548, 0.0352, 0.0589, 0.0284, 0.0877, 0.0832,
        0.0302, 0.0569, 0.0410, 0.0271, 0.0465, 0.0313, 0.0472, 0.0484],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,500][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([9.3681e-02, 1.2880e-04, 6.7829e-04, 1.4190e-04, 3.8380e-04, 7.9490e-04,
        6.0242e-06, 8.5708e-04, 1.0688e-02, 1.9625e-04, 6.5699e-03, 1.0645e-03,
        7.2664e-02, 1.8391e-01, 2.5308e-01, 1.8057e-01, 1.9459e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,500][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0012, 0.0648, 0.0579, 0.0515, 0.0552, 0.0611, 0.0727, 0.0517, 0.0604,
        0.0605, 0.0651, 0.0609, 0.0681, 0.0732, 0.0647, 0.0588, 0.0723],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,557][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:38,558][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,559][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,560][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,562][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,563][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,564][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,565][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,566][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,567][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,568][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,569][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,569][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,569][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Sara] are: tensor([0.9886, 0.0114], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,570][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Sara] are: tensor([0.3136, 0.6864], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,570][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Sara] are: tensor([0.2086, 0.7914], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,570][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Sara] are: tensor([0.9577, 0.0423], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,571][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Sara] are: tensor([0.0059, 0.9941], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,571][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Sara] are: tensor([0.9409, 0.0591], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,571][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Sara] are: tensor([0.0071, 0.9929], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,572][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Sara] are: tensor([0.3344, 0.6656], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,573][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Sara] are: tensor([0.6411, 0.3589], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,574][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Sara] are: tensor([4.4269e-04, 9.9956e-01], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,575][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Sara] are: tensor([0.7293, 0.2707], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,577][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Sara] are: tensor([0.1173, 0.8827], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,578][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9604, 0.0046, 0.0351], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,579][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0828, 0.4516, 0.4657], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,580][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0759, 0.5492, 0.3749], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,581][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.6769, 0.0067, 0.3164], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,582][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([3.9503e-04, 7.0451e-01, 2.9509e-01], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,584][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.8829, 0.0776, 0.0395], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,585][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0031, 0.8336, 0.1632], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,586][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1592, 0.1414, 0.6994], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,588][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.6093, 0.2132, 0.1775], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,589][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([1.4084e-04, 7.0488e-01, 2.9498e-01], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,590][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2222, 0.0571, 0.7206], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,591][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0132, 0.6056, 0.3812], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,593][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Kenneth] are: tensor([0.8933, 0.0120, 0.0560, 0.0387], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,594][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Kenneth] are: tensor([0.0355, 0.2707, 0.1665, 0.5273], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,596][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Kenneth] are: tensor([0.0608, 0.4021, 0.2085, 0.3286], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,597][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Kenneth] are: tensor([0.1556, 0.0162, 0.7746, 0.0536], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,598][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Kenneth] are: tensor([4.4094e-04, 5.9595e-01, 2.1706e-01, 1.8655e-01], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,599][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Kenneth] are: tensor([0.7813, 0.0869, 0.0517, 0.0800], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,600][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Kenneth] are: tensor([0.0017, 0.4496, 0.1824, 0.3662], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,600][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Kenneth] are: tensor([0.0620, 0.1056, 0.5150, 0.3175], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,601][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Kenneth] are: tensor([0.3218, 0.2898, 0.2767, 0.1117], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,601][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Kenneth] are: tensor([9.9012e-05, 4.0196e-01, 2.7562e-01, 3.2232e-01], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,601][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Kenneth] are: tensor([0.0720, 0.0376, 0.7816, 0.1088], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,602][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Kenneth] are: tensor([0.0052, 0.3681, 0.2968, 0.3300], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,602][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.6882, 0.0127, 0.1355, 0.0235, 0.1400], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,603][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.0732, 0.2464, 0.1381, 0.3937, 0.1486], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,603][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.0332, 0.3265, 0.2514, 0.2251, 0.1638], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,604][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.3415, 0.0126, 0.3841, 0.0568, 0.2049], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,605][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([4.1238e-04, 5.7020e-01, 1.6785e-01, 1.5141e-01, 1.1012e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,606][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.5749, 0.0544, 0.0428, 0.0332, 0.2948], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,607][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.0009, 0.5630, 0.0993, 0.2560, 0.0808], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,609][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.0295, 0.0509, 0.2959, 0.3043, 0.3194], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,610][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.3449, 0.1992, 0.1705, 0.1333, 0.1522], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,611][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([1.0354e-04, 3.9743e-01, 2.6043e-01, 2.6170e-01, 8.0338e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,612][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.1452, 0.0330, 0.4929, 0.0850, 0.2440], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,614][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.0065, 0.3130, 0.1795, 0.2590, 0.2420], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,615][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.7886, 0.0037, 0.0534, 0.0075, 0.0927, 0.0541], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,616][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0841, 0.0846, 0.1512, 0.2470, 0.1894, 0.2437], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,618][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0298, 0.2559, 0.1753, 0.2038, 0.1289, 0.2063], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,619][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.5090, 0.0037, 0.1501, 0.0317, 0.1698, 0.1358], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,621][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0004, 0.3156, 0.2127, 0.1050, 0.2082, 0.1581], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,622][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.7377, 0.0348, 0.0230, 0.0182, 0.1517, 0.0347], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,623][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0017, 0.3359, 0.0755, 0.1896, 0.0855, 0.3118], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,625][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0360, 0.0387, 0.2036, 0.2422, 0.3242, 0.1553], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,626][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.5574, 0.1572, 0.0921, 0.0797, 0.0841, 0.0295], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,627][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([4.7636e-05, 3.3949e-01, 1.5831e-01, 1.2056e-01, 9.4717e-02, 2.8688e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,628][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2093, 0.0154, 0.2556, 0.0653, 0.2017, 0.2527], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,630][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0086, 0.1678, 0.1608, 0.2164, 0.2518, 0.1946], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,631][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.6064, 0.0187, 0.0682, 0.0235, 0.1320, 0.1437, 0.0075],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,632][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.0126, 0.1416, 0.1188, 0.2944, 0.1471, 0.2404, 0.0450],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,632][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.0112, 0.2392, 0.1725, 0.1791, 0.0860, 0.1371, 0.1750],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,633][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.0076, 0.0067, 0.3268, 0.0282, 0.2076, 0.4201, 0.0029],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,633][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([1.6921e-04, 3.1420e-01, 1.8650e-01, 8.6467e-02, 8.9776e-02, 9.5400e-02,
        2.2749e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,633][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.3889, 0.0328, 0.0374, 0.0215, 0.1826, 0.0582, 0.2785],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,634][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.0007, 0.3602, 0.0492, 0.1700, 0.0899, 0.2416, 0.0884],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,634][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.0051, 0.0332, 0.1608, 0.1311, 0.4220, 0.1502, 0.0975],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,635][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.1904, 0.1980, 0.2275, 0.0932, 0.1348, 0.1112, 0.0448],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,635][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([1.0859e-05, 3.1209e-01, 8.2630e-02, 1.6008e-01, 5.2883e-02, 2.2281e-01,
        1.6949e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,636][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.0044, 0.0218, 0.2131, 0.0674, 0.2659, 0.4205, 0.0070],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,638][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.0019, 0.1138, 0.1281, 0.1589, 0.1738, 0.2466, 0.1769],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,639][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.3980, 0.0153, 0.1423, 0.0150, 0.2391, 0.1440, 0.0024, 0.0438],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,641][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0914, 0.1420, 0.0790, 0.1545, 0.0826, 0.2007, 0.0251, 0.2246],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,641][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0109, 0.2176, 0.1590, 0.1401, 0.0919, 0.1602, 0.0971, 0.1233],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,643][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.4170, 0.0040, 0.1336, 0.0254, 0.1386, 0.1472, 0.0021, 0.1321],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,644][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0007, 0.3465, 0.2129, 0.0400, 0.0949, 0.1392, 0.0977, 0.0680],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,645][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.6354, 0.0338, 0.0191, 0.0283, 0.1404, 0.0231, 0.0822, 0.0376],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,647][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0008, 0.3196, 0.0319, 0.1346, 0.0541, 0.1804, 0.0371, 0.2415],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,648][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0299, 0.0451, 0.1180, 0.2459, 0.2995, 0.1257, 0.0750, 0.0608],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,649][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.3757, 0.2866, 0.1024, 0.0985, 0.0720, 0.0362, 0.0112, 0.0173],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,650][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([2.3711e-05, 2.8667e-01, 6.5437e-02, 1.1942e-01, 3.0998e-02, 1.7230e-01,
        8.9797e-02, 2.3535e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,652][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.1242, 0.0104, 0.1490, 0.0346, 0.1166, 0.1968, 0.0023, 0.3661],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,653][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0041, 0.1378, 0.0893, 0.1491, 0.1170, 0.1374, 0.1759, 0.1894],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,655][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.6793, 0.0050, 0.0798, 0.0084, 0.1064, 0.0584, 0.0013, 0.0194, 0.0420],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,656][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0625, 0.0899, 0.0897, 0.1964, 0.0863, 0.1196, 0.0364, 0.1606, 0.1587],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,658][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0119, 0.1617, 0.1240, 0.1156, 0.0742, 0.1191, 0.0907, 0.1009, 0.2020],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,659][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([6.3810e-01, 1.0121e-03, 4.8997e-02, 4.3939e-03, 2.9553e-02, 6.1868e-02,
        3.2422e-04, 4.6732e-02, 1.6902e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,659][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([1.4660e-04, 2.0918e-01, 1.5556e-01, 7.9205e-02, 1.2851e-01, 7.1265e-02,
        2.0296e-01, 7.1805e-02, 8.1385e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,661][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.7048, 0.0185, 0.0131, 0.0150, 0.1077, 0.0154, 0.0891, 0.0231, 0.0133],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,662][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0008, 0.2930, 0.0255, 0.1057, 0.0453, 0.0913, 0.0551, 0.2021, 0.1813],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,664][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0662, 0.0257, 0.1555, 0.1251, 0.2432, 0.1023, 0.0545, 0.0476, 0.1797],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,665][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.5060, 0.2383, 0.0751, 0.0699, 0.0532, 0.0187, 0.0124, 0.0145, 0.0119],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,666][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([1.6437e-05, 1.3426e-01, 4.3908e-02, 6.0027e-02, 2.2008e-02, 9.3464e-02,
        7.5490e-02, 1.3444e-01, 4.3639e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,667][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([3.1705e-01, 2.1647e-03, 4.1197e-02, 4.8015e-03, 2.8756e-02, 4.5399e-02,
        3.2496e-04, 1.1762e-01, 4.4269e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,668][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0041, 0.0844, 0.0789, 0.1010, 0.1054, 0.0986, 0.1803, 0.1836, 0.1635],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,669][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ garden] are: tensor([0.3748, 0.0131, 0.1359, 0.0105, 0.2326, 0.0759, 0.0035, 0.0554, 0.0855,
        0.0129], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,669][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ garden] are: tensor([0.0048, 0.0914, 0.0734, 0.1820, 0.0862, 0.1346, 0.0495, 0.2075, 0.1516,
        0.0190], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,669][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ garden] are: tensor([0.0062, 0.1601, 0.1262, 0.0897, 0.0531, 0.1028, 0.0928, 0.0975, 0.2229,
        0.0486], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,670][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ garden] are: tensor([1.6384e-02, 9.7547e-04, 5.8522e-02, 5.0939e-03, 5.3000e-02, 5.2184e-02,
        3.8584e-04, 7.3720e-02, 7.1592e-01, 2.3820e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,670][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ garden] are: tensor([9.2460e-05, 3.1491e-01, 1.8922e-01, 9.3308e-02, 3.7424e-02, 3.8975e-02,
        9.1803e-02, 3.4054e-02, 1.1348e-01, 8.6734e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,671][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ garden] are: tensor([0.4524, 0.0234, 0.0206, 0.0248, 0.1101, 0.0315, 0.1983, 0.0442, 0.0257,
        0.0690], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,671][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ garden] are: tensor([4.4646e-05, 1.7967e-01, 1.4887e-02, 7.2993e-02, 2.2559e-02, 1.4911e-01,
        3.8465e-02, 2.7831e-01, 2.3450e-01, 9.4579e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,673][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ garden] are: tensor([0.0096, 0.0258, 0.1065, 0.1169, 0.2142, 0.1097, 0.0426, 0.0985, 0.2171,
        0.0590], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,674][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ garden] are: tensor([0.2570, 0.2401, 0.1426, 0.0642, 0.0872, 0.0401, 0.0231, 0.0493, 0.0645,
        0.0320], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,675][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ garden] are: tensor([9.7201e-07, 1.8064e-01, 3.2834e-02, 7.2702e-02, 1.4990e-02, 8.7904e-02,
        4.2780e-02, 1.7991e-01, 3.3140e-01, 5.6833e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,676][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ garden] are: tensor([2.9218e-03, 1.9094e-03, 2.2225e-02, 4.6477e-03, 1.8672e-02, 3.3693e-02,
        1.7700e-04, 8.4303e-02, 8.2048e-01, 1.0968e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,677][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ garden] are: tensor([0.0004, 0.0250, 0.0412, 0.0801, 0.0300, 0.0997, 0.1086, 0.2168, 0.2782,
        0.1200], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,679][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4841, 0.0064, 0.0828, 0.0087, 0.1922, 0.0770, 0.0013, 0.0251, 0.0638,
        0.0035, 0.0552], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,680][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0202, 0.0886, 0.0651, 0.1429, 0.0720, 0.1643, 0.0215, 0.1799, 0.1592,
        0.0110, 0.0753], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,682][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0062, 0.1177, 0.0983, 0.1035, 0.0574, 0.0989, 0.0663, 0.0796, 0.1997,
        0.0378, 0.1346], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,683][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([5.9986e-01, 4.7018e-04, 2.4701e-02, 1.8706e-03, 8.8672e-03, 2.3798e-02,
        2.5729e-04, 1.8073e-02, 9.7556e-02, 6.6120e-03, 2.1794e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,684][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0002, 0.1427, 0.1181, 0.0406, 0.0520, 0.0758, 0.0735, 0.0541, 0.1665,
        0.1054, 0.1710], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,685][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.7591, 0.0137, 0.0114, 0.0162, 0.0860, 0.0127, 0.0527, 0.0189, 0.0083,
        0.0173, 0.0037], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,687][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0003, 0.1590, 0.0136, 0.0802, 0.0266, 0.1036, 0.0318, 0.1924, 0.2274,
        0.0078, 0.1573], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,688][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0340, 0.0233, 0.0716, 0.1080, 0.1381, 0.0753, 0.0428, 0.0468, 0.1433,
        0.0491, 0.2677], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,690][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4726, 0.2285, 0.0696, 0.0825, 0.0499, 0.0148, 0.0077, 0.0132, 0.0101,
        0.0135, 0.0375], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,691][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([8.4411e-06, 1.1836e-01, 2.1276e-02, 4.6572e-02, 1.3621e-02, 8.1430e-02,
        3.5293e-02, 1.4126e-01, 3.4792e-01, 3.5748e-02, 1.5852e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,692][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([1.2744e-01, 2.1252e-03, 3.1814e-02, 5.5375e-03, 1.3595e-02, 3.6531e-02,
        3.3433e-04, 6.8234e-02, 4.3774e-01, 1.5881e-02, 2.6077e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,693][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0015, 0.0971, 0.0486, 0.0994, 0.0658, 0.0829, 0.1187, 0.1389, 0.1772,
        0.0591, 0.1109], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,695][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Sara] are: tensor([0.4788, 0.0134, 0.1095, 0.0231, 0.1370, 0.0802, 0.0026, 0.0179, 0.0466,
        0.0110, 0.0753, 0.0046], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,696][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Sara] are: tensor([0.0107, 0.0529, 0.0740, 0.1383, 0.1376, 0.0921, 0.0390, 0.1972, 0.1286,
        0.0161, 0.0580, 0.0554], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,698][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Sara] are: tensor([0.0043, 0.0992, 0.1029, 0.0875, 0.0404, 0.1000, 0.0690, 0.0666, 0.1514,
        0.0397, 0.1381, 0.1007], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,699][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Sara] are: tensor([5.0028e-02, 1.1117e-03, 5.5771e-02, 3.7175e-03, 2.5666e-02, 3.8639e-02,
        2.6763e-04, 3.5273e-02, 2.7727e-01, 1.3949e-02, 4.8089e-01, 1.7416e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,699][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Sara] are: tensor([1.2622e-04, 1.7114e-01, 1.1937e-01, 7.4692e-02, 7.9585e-02, 4.3197e-02,
        9.3683e-02, 3.2568e-02, 9.9152e-02, 1.2958e-01, 1.0629e-01, 5.0615e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,700][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Sara] are: tensor([0.4765, 0.0316, 0.0174, 0.0315, 0.1626, 0.0267, 0.1130, 0.0479, 0.0168,
        0.0338, 0.0067, 0.0357], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,700][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Sara] are: tensor([1.8885e-04, 8.3056e-02, 2.1405e-02, 4.5680e-02, 3.8736e-02, 1.3625e-01,
        3.1512e-02, 1.9151e-01, 1.8597e-01, 6.9002e-03, 1.2938e-01, 1.2942e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,700][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Sara] are: tensor([0.0071, 0.0184, 0.0434, 0.1021, 0.1901, 0.0690, 0.0597, 0.0508, 0.2015,
        0.0467, 0.1633, 0.0478], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,701][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Sara] are: tensor([0.1950, 0.1882, 0.1127, 0.0909, 0.0705, 0.0565, 0.0190, 0.0238, 0.0389,
        0.0191, 0.0687, 0.1167], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,701][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Sara] are: tensor([8.4226e-06, 1.4399e-01, 2.6691e-02, 2.5097e-02, 2.3233e-02, 3.7995e-02,
        2.2939e-02, 6.4696e-02, 2.3362e-01, 3.1862e-02, 8.1098e-02, 3.0877e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,702][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Sara] are: tensor([2.2085e-02, 1.0451e-03, 2.8766e-02, 4.1685e-03, 1.4201e-02, 2.6717e-02,
        1.5818e-04, 4.3801e-02, 5.7053e-01, 9.5429e-03, 2.5829e-01, 2.0692e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,702][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Sara] are: tensor([0.0013, 0.0367, 0.0363, 0.0586, 0.0834, 0.1224, 0.0926, 0.1572, 0.1738,
        0.0588, 0.0757, 0.1031], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:38,703][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.3774, 0.0052, 0.1100, 0.0108, 0.1111, 0.0414, 0.0020, 0.0215, 0.0495,
        0.0038, 0.0785, 0.0014, 0.1874], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,705][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.0182, 0.0697, 0.0600, 0.2093, 0.0613, 0.1052, 0.0361, 0.1199, 0.1306,
        0.0116, 0.0509, 0.0781, 0.0492], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,706][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0038, 0.1134, 0.0838, 0.0622, 0.0497, 0.0806, 0.0557, 0.0577, 0.1411,
        0.0290, 0.1040, 0.0934, 0.1255], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,707][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([2.9149e-01, 1.3902e-04, 6.9467e-03, 3.4628e-04, 3.2635e-03, 7.4826e-03,
        3.0095e-05, 3.1085e-03, 5.4726e-02, 1.1947e-03, 7.2668e-02, 2.7189e-03,
        5.5589e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,708][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([1.0570e-04, 1.9692e-01, 1.1780e-01, 3.6469e-02, 5.9531e-02, 6.1253e-02,
        3.9827e-02, 3.8387e-02, 1.5094e-01, 8.8029e-02, 1.2236e-01, 5.0216e-02,
        3.8173e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,710][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.5488, 0.0186, 0.0138, 0.0154, 0.0743, 0.0138, 0.0458, 0.0290, 0.0094,
        0.0331, 0.0040, 0.0202, 0.1739], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,710][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([1.3426e-04, 6.9326e-02, 1.1415e-02, 3.7191e-02, 2.1456e-02, 1.1158e-01,
        1.8468e-02, 1.7484e-01, 1.6985e-01, 5.4772e-03, 1.1075e-01, 2.0743e-01,
        6.2076e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,712][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0164, 0.0110, 0.0686, 0.0776, 0.0883, 0.0605, 0.0192, 0.0292, 0.1000,
        0.0236, 0.1393, 0.0313, 0.3349], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,714][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.4511, 0.0828, 0.0752, 0.0514, 0.0392, 0.0357, 0.0072, 0.0321, 0.0252,
        0.0195, 0.0532, 0.0596, 0.0681], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,715][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([4.6135e-06, 5.2778e-02, 1.9915e-02, 2.6610e-02, 9.4157e-03, 6.3116e-02,
        2.2749e-02, 1.4289e-01, 1.8518e-01, 2.3476e-02, 1.0326e-01, 2.5966e-01,
        9.0942e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,715][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([1.0244e-01, 6.2426e-04, 8.2717e-03, 9.4377e-04, 4.3329e-03, 1.0068e-02,
        3.2515e-05, 1.1113e-02, 1.2516e-01, 1.1438e-03, 7.0613e-02, 8.3968e-03,
        6.5686e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,717][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0008, 0.0489, 0.0329, 0.0610, 0.0326, 0.0839, 0.0745, 0.1444, 0.1343,
        0.0484, 0.0636, 0.0623, 0.2125], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:38,718][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2739, 0.0067, 0.1072, 0.0113, 0.1653, 0.0861, 0.0014, 0.0353, 0.0798,
        0.0025, 0.0620, 0.0012, 0.1043, 0.0630], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,720][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0174, 0.0651, 0.0457, 0.1231, 0.0708, 0.1461, 0.0219, 0.1350, 0.1275,
        0.0076, 0.0525, 0.0755, 0.0745, 0.0373], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,721][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0024, 0.0886, 0.0710, 0.0719, 0.0359, 0.0727, 0.0518, 0.0531, 0.1481,
        0.0266, 0.1037, 0.0803, 0.0863, 0.1077], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,722][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([3.7737e-01, 4.0499e-05, 9.7843e-04, 1.0806e-04, 2.9131e-04, 7.4842e-04,
        8.0207e-06, 3.5092e-04, 3.7193e-03, 2.0341e-04, 9.1707e-03, 4.6383e-04,
        8.1141e-02, 5.2541e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,724][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0002, 0.1450, 0.1485, 0.0385, 0.0585, 0.0644, 0.0424, 0.0463, 0.1341,
        0.0373, 0.1191, 0.0629, 0.0461, 0.0568], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,725][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.6788, 0.0129, 0.0071, 0.0095, 0.0544, 0.0083, 0.0375, 0.0146, 0.0053,
        0.0086, 0.0023, 0.0139, 0.1083, 0.0385], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,726][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.4652e-04, 9.4265e-02, 6.2366e-03, 4.7981e-02, 2.1496e-02, 9.6211e-02,
        1.4723e-02, 1.5906e-01, 1.7176e-01, 4.4786e-03, 8.5290e-02, 2.0198e-01,
        7.1452e-02, 2.4933e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,728][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0503, 0.0128, 0.0233, 0.0581, 0.0432, 0.0305, 0.0141, 0.0129, 0.0442,
        0.0116, 0.0750, 0.0226, 0.1534, 0.4479], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,730][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.5788, 0.1255, 0.0523, 0.0433, 0.0224, 0.0137, 0.0066, 0.0077, 0.0086,
        0.0106, 0.0204, 0.0441, 0.0350, 0.0309], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,730][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([3.0895e-06, 3.8735e-02, 1.4414e-02, 1.5732e-02, 1.2447e-02, 5.8149e-02,
        1.9113e-02, 9.4047e-02, 2.5210e-01, 2.1377e-02, 8.8960e-02, 2.4746e-01,
        9.6571e-02, 4.0894e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,731][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([3.6390e-01, 3.4022e-04, 2.1384e-03, 3.8663e-04, 1.0352e-03, 2.6048e-03,
        1.9381e-05, 2.1459e-03, 2.6988e-02, 5.6480e-04, 1.9032e-02, 2.7515e-03,
        1.6149e-01, 4.1660e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,731][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0018, 0.0598, 0.0374, 0.0749, 0.0304, 0.0569, 0.0757, 0.0882, 0.1146,
        0.0435, 0.0793, 0.0968, 0.1746, 0.0661], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:38,732][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.2972, 0.0067, 0.0980, 0.0097, 0.1136, 0.0650, 0.0020, 0.0256, 0.0789,
        0.0070, 0.0668, 0.0016, 0.1447, 0.0434, 0.0398], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,732][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0415, 0.0703, 0.0703, 0.1155, 0.0494, 0.1159, 0.0170, 0.1050, 0.1229,
        0.0070, 0.0563, 0.0703, 0.0298, 0.0258, 0.1033], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,733][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0036, 0.0783, 0.0736, 0.0563, 0.0388, 0.0587, 0.0417, 0.0487, 0.1186,
        0.0254, 0.0938, 0.0687, 0.1059, 0.0985, 0.0893], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,733][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([1.3841e-01, 1.7581e-05, 3.8383e-04, 2.2368e-05, 1.4607e-04, 2.9113e-04,
        5.2981e-07, 1.3862e-04, 2.9495e-03, 3.4221e-05, 5.7722e-03, 1.8783e-04,
        5.2073e-02, 6.8552e-01, 1.1406e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,734][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([1.6145e-04, 1.6311e-01, 9.6359e-02, 3.5284e-02, 6.0996e-02, 8.1980e-02,
        4.8572e-02, 4.4633e-02, 1.4277e-01, 5.7266e-02, 1.0827e-01, 4.0982e-02,
        4.5796e-02, 5.1263e-02, 2.2553e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,736][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.6132, 0.0151, 0.0092, 0.0104, 0.0368, 0.0088, 0.0311, 0.0128, 0.0064,
        0.0119, 0.0027, 0.0131, 0.0871, 0.0477, 0.0937], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,737][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([8.1042e-05, 2.0841e-01, 8.4885e-03, 5.3112e-02, 8.9695e-03, 6.5065e-02,
        1.6402e-02, 9.1745e-02, 1.2961e-01, 4.0514e-03, 9.3946e-02, 2.1909e-01,
        2.0258e-02, 1.6259e-02, 6.4504e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,738][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0147, 0.0022, 0.0112, 0.0151, 0.0175, 0.0110, 0.0054, 0.0044, 0.0210,
        0.0047, 0.0337, 0.0054, 0.0621, 0.2844, 0.5073], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,740][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.3468, 0.2138, 0.0412, 0.0492, 0.0283, 0.0168, 0.0060, 0.0080, 0.0147,
        0.0090, 0.0273, 0.0758, 0.0482, 0.0408, 0.0743], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,741][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([9.9313e-06, 6.2027e-02, 1.9967e-02, 3.4564e-02, 9.7443e-03, 5.8843e-02,
        2.6666e-02, 7.2750e-02, 2.4121e-01, 3.5874e-02, 1.2525e-01, 1.7794e-01,
        4.6935e-02, 3.9286e-02, 4.8930e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,742][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([9.5031e-02, 5.4274e-05, 6.9768e-04, 1.1636e-04, 3.0728e-04, 7.0647e-04,
        2.5407e-06, 5.5346e-04, 9.2605e-03, 1.5690e-04, 5.0173e-03, 5.5455e-04,
        7.2160e-02, 4.3897e-01, 3.7641e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,743][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0009, 0.0391, 0.0289, 0.0267, 0.0338, 0.0635, 0.0389, 0.0620, 0.1150,
        0.0211, 0.0580, 0.0739, 0.1289, 0.0671, 0.2422], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:38,745][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([0.3223, 0.0043, 0.1128, 0.0064, 0.1180, 0.0545, 0.0014, 0.0236, 0.0481,
        0.0027, 0.0878, 0.0009, 0.1053, 0.0427, 0.0277, 0.0416],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,746][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([0.0111, 0.0316, 0.0593, 0.1009, 0.0761, 0.0962, 0.0174, 0.1388, 0.1647,
        0.0063, 0.0485, 0.0433, 0.0431, 0.0346, 0.0995, 0.0286],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,748][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.0021, 0.0541, 0.0746, 0.0466, 0.0352, 0.0622, 0.0344, 0.0514, 0.1038,
        0.0210, 0.0953, 0.0516, 0.0790, 0.0869, 0.0801, 0.1215],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,749][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([3.9282e-02, 1.3027e-05, 4.3326e-04, 2.8537e-05, 3.1141e-04, 6.1541e-04,
        1.5771e-06, 1.6287e-04, 4.5931e-03, 6.6428e-05, 5.7694e-03, 1.0573e-04,
        5.5706e-02, 5.4246e-01, 3.3614e-01, 1.4313e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,750][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([8.7886e-05, 1.3819e-01, 1.0647e-01, 6.2760e-02, 5.4257e-02, 7.3956e-02,
        5.0090e-02, 3.0739e-02, 1.3398e-01, 5.5820e-02, 1.0188e-01, 6.0397e-02,
        5.5213e-02, 3.4693e-02, 1.8304e-02, 2.3169e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,751][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([0.3955, 0.0141, 0.0093, 0.0123, 0.0462, 0.0087, 0.0279, 0.0182, 0.0084,
        0.0176, 0.0037, 0.0162, 0.1128, 0.0565, 0.0685, 0.1840],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,752][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([1.2198e-04, 4.9634e-02, 6.2734e-03, 2.3850e-02, 1.9818e-02, 6.7168e-02,
        2.3047e-02, 1.0911e-01, 1.5977e-01, 5.4606e-03, 8.1778e-02, 1.7144e-01,
        7.3475e-02, 2.4001e-02, 1.1558e-01, 6.9467e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,754][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.0122, 0.0024, 0.0148, 0.0161, 0.0230, 0.0097, 0.0026, 0.0042, 0.0181,
        0.0043, 0.0395, 0.0075, 0.0776, 0.2001, 0.2871, 0.2808],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,755][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.1571, 0.1440, 0.0672, 0.0504, 0.0290, 0.0217, 0.0116, 0.0124, 0.0113,
        0.0180, 0.0584, 0.0853, 0.0756, 0.0749, 0.0776, 0.1054],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,756][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([4.9259e-06, 2.5106e-02, 1.0583e-02, 9.6803e-03, 8.3292e-03, 5.3650e-02,
        2.5233e-02, 9.9637e-02, 2.4323e-01, 2.2010e-02, 5.2686e-02, 2.0835e-01,
        7.7596e-02, 4.9634e-02, 4.0638e-02, 7.3637e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,757][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([7.1480e-03, 4.0648e-05, 4.1214e-04, 5.6161e-05, 2.4005e-04, 6.5282e-04,
        2.5436e-06, 7.1711e-04, 1.7157e-02, 1.2729e-04, 7.1767e-03, 3.4636e-04,
        7.4783e-02, 3.0915e-01, 4.9150e-01, 9.0489e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,759][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([0.0006, 0.0214, 0.0238, 0.0330, 0.0346, 0.0461, 0.0773, 0.0858, 0.0943,
        0.0391, 0.0710, 0.0581, 0.2055, 0.0574, 0.1226, 0.0293],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:38,760][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1809, 0.0060, 0.0984, 0.0099, 0.1314, 0.0779, 0.0014, 0.0313, 0.0785,
        0.0026, 0.0560, 0.0011, 0.0880, 0.0654, 0.0162, 0.0871, 0.0679],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,761][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0138, 0.0535, 0.0392, 0.1175, 0.0574, 0.1121, 0.0171, 0.1185, 0.0927,
        0.0064, 0.0436, 0.0648, 0.0607, 0.0263, 0.1018, 0.0470, 0.0276],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,762][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0012, 0.0626, 0.0606, 0.0561, 0.0261, 0.0564, 0.0383, 0.0408, 0.1137,
        0.0198, 0.0819, 0.0548, 0.0641, 0.0823, 0.0602, 0.1111, 0.0701],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,762][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.8088e-01, 3.7169e-05, 6.1621e-04, 7.6090e-05, 2.0669e-04, 4.0130e-04,
        4.4371e-06, 2.0983e-04, 2.5999e-03, 1.0994e-04, 5.3120e-03, 3.8576e-04,
        5.8163e-02, 3.5189e-01, 1.1209e-01, 2.2058e-02, 2.6497e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,763][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.4566e-05, 1.5991e-01, 1.1942e-01, 3.4305e-02, 4.4799e-02, 5.8988e-02,
        3.4819e-02, 3.5199e-02, 1.3422e-01, 3.6509e-02, 1.0731e-01, 5.9209e-02,
        5.1425e-02, 4.4578e-02, 2.4877e-02, 2.7858e-02, 2.6473e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,763][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.5781, 0.0090, 0.0056, 0.0073, 0.0472, 0.0066, 0.0299, 0.0133, 0.0042,
        0.0078, 0.0018, 0.0109, 0.0979, 0.0325, 0.0495, 0.0660, 0.0323],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,764][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.0467e-04, 9.6856e-02, 5.0600e-03, 3.9998e-02, 1.5108e-02, 7.9791e-02,
        1.0980e-02, 1.0722e-01, 1.4609e-01, 3.3779e-03, 6.1941e-02, 1.8447e-01,
        5.2887e-02, 1.6155e-02, 1.0664e-01, 5.8011e-02, 1.5318e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,764][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0165, 0.0048, 0.0091, 0.0206, 0.0158, 0.0098, 0.0048, 0.0038, 0.0143,
        0.0041, 0.0232, 0.0075, 0.0564, 0.1361, 0.2663, 0.3024, 0.1046],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,765][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.4551, 0.1260, 0.0518, 0.0390, 0.0192, 0.0120, 0.0061, 0.0073, 0.0069,
        0.0114, 0.0212, 0.0456, 0.0346, 0.0318, 0.0393, 0.0517, 0.0409],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,766][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.3816e-06, 4.6940e-02, 1.3071e-02, 1.5878e-02, 9.1007e-03, 5.6337e-02,
        1.3710e-02, 7.1897e-02, 2.1009e-01, 1.3709e-02, 6.9403e-02, 2.3701e-01,
        7.3789e-02, 2.6979e-02, 4.5542e-02, 7.2410e-02, 2.4129e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,767][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([9.3681e-02, 1.2880e-04, 6.7829e-04, 1.4190e-04, 3.8380e-04, 7.9490e-04,
        6.0242e-06, 8.5708e-04, 1.0688e-02, 1.9625e-04, 6.5699e-03, 1.0645e-03,
        7.2664e-02, 1.8391e-01, 2.5308e-01, 1.8057e-01, 1.9459e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,769][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0012, 0.0488, 0.0197, 0.0528, 0.0187, 0.0373, 0.0615, 0.0643, 0.0892,
        0.0411, 0.0601, 0.0914, 0.1320, 0.0457, 0.1420, 0.0511, 0.0429],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:38,770][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:38,772][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[15254],
        [10985],
        [ 1501],
        [12428],
        [ 4561],
        [ 6214],
        [  489],
        [  548],
        [  537],
        [   82],
        [  299],
        [ 1218],
        [  127],
        [   92],
        [  153],
        [   67],
        [   82]], device='cuda:0')
[2024-07-24 10:29:38,774][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[15239],
        [19319],
        [ 3438],
        [18975],
        [ 7678],
        [11637],
        [ 1916],
        [ 2054],
        [ 1843],
        [  248],
        [ 1483],
        [ 3017],
        [  513],
        [  368],
        [  540],
        [  265],
        [  313]], device='cuda:0')
[2024-07-24 10:29:38,775][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[25735],
        [20776],
        [22789],
        [23623],
        [24166],
        [23788],
        [23873],
        [23233],
        [23246],
        [23075],
        [22926],
        [23360],
        [23126],
        [22700],
        [23414],
        [23265],
        [23251]], device='cuda:0')
[2024-07-24 10:29:38,777][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[17192],
        [17692],
        [18474],
        [18760],
        [19447],
        [22527],
        [19574],
        [15771],
        [15361],
        [16963],
        [19463],
        [17608],
        [18606],
        [20736],
        [22545],
        [24332],
        [24538]], device='cuda:0')
[2024-07-24 10:29:38,778][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[8142],
        [7074],
        [6391],
        [ 942],
        [2236],
        [3157],
        [2087],
        [2592],
        [2508],
        [4748],
        [2551],
        [3255],
        [7601],
        [3950],
        [7003],
        [6620],
        [5199]], device='cuda:0')
[2024-07-24 10:29:38,779][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[23247],
        [24282],
        [32313],
        [39353],
        [36846],
        [33778],
        [38250],
        [31842],
        [28788],
        [31711],
        [29818],
        [33070],
        [40263],
        [36953],
        [38479],
        [39136],
        [39145]], device='cuda:0')
[2024-07-24 10:29:38,781][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 9458],
        [ 4851],
        [13206],
        [12421],
        [12635],
        [15236],
        [17359],
        [17019],
        [17927],
        [19014],
        [17589],
        [17109],
        [17039],
        [17772],
        [17409],
        [17103],
        [17797]], device='cuda:0')
[2024-07-24 10:29:38,783][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[37874],
        [ 8763],
        [19996],
        [30076],
        [27196],
        [23252],
        [22862],
        [20586],
        [19345],
        [17576],
        [16762],
        [15287],
        [14072],
        [12391],
        [11838],
        [12062],
        [11051]], device='cuda:0')
[2024-07-24 10:29:38,784][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[27070],
        [26903],
        [22808],
        [33800],
        [31385],
        [27134],
        [26271],
        [26924],
        [25616],
        [25777],
        [25631],
        [25019],
        [23281],
        [22113],
        [21424],
        [20156],
        [19647]], device='cuda:0')
[2024-07-24 10:29:38,785][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[9633],
        [6769],
        [7198],
        [8962],
        [9300],
        [7542],
        [7866],
        [7444],
        [7127],
        [7019],
        [7016],
        [7173],
        [8531],
        [8548],
        [8383],
        [8418],
        [8403]], device='cuda:0')
[2024-07-24 10:29:38,787][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 3173],
        [ 9416],
        [ 3520],
        [ 8941],
        [11050],
        [ 8123],
        [10103],
        [13087],
        [12868],
        [10022],
        [13228],
        [13213],
        [11390],
        [15842],
        [23334],
        [21104],
        [19544]], device='cuda:0')
[2024-07-24 10:29:38,788][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[9287],
        [1481],
        [1140],
        [9007],
        [5679],
        [4037],
        [4267],
        [4779],
        [4964],
        [4879],
        [5017],
        [3656],
        [4460],
        [4564],
        [3982],
        [3858],
        [4103]], device='cuda:0')
[2024-07-24 10:29:38,790][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[33061],
        [34059],
        [37388],
        [38780],
        [39240],
        [40951],
        [41132],
        [41305],
        [44758],
        [45428],
        [45003],
        [45226],
        [40459],
        [44841],
        [46606],
        [46705],
        [46193]], device='cuda:0')
[2024-07-24 10:29:38,791][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[13491],
        [10709],
        [ 6806],
        [ 3199],
        [ 3234],
        [ 2886],
        [ 2698],
        [ 2629],
        [ 2482],
        [ 2194],
        [ 2310],
        [ 2371],
        [ 2103],
        [ 2039],
        [ 2007],
        [ 1991],
        [ 1979]], device='cuda:0')
[2024-07-24 10:29:38,793][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[30736],
        [21126],
        [16369],
        [17902],
        [14789],
        [16152],
        [12529],
        [11634],
        [12007],
        [13882],
        [11870],
        [17472],
        [13028],
        [11295],
        [12722],
        [12639],
        [10431]], device='cuda:0')
[2024-07-24 10:29:38,794][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[25480],
        [24816],
        [22940],
        [28465],
        [25726],
        [24031],
        [18372],
        [19152],
        [20070],
        [20347],
        [19530],
        [17890],
        [23803],
        [20268],
        [20889],
        [19887],
        [19011]], device='cuda:0')
[2024-07-24 10:29:38,795][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[12836],
        [27262],
        [26298],
        [30375],
        [30806],
        [27367],
        [27783],
        [34028],
        [30824],
        [31978],
        [30861],
        [32552],
        [30850],
        [31885],
        [34117],
        [34565],
        [36068]], device='cuda:0')
[2024-07-24 10:29:38,796][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[28370],
        [ 6800],
        [ 7240],
        [19039],
        [19030],
        [21158],
        [18556],
        [19610],
        [17891],
        [17121],
        [20326],
        [19234],
        [19434],
        [20584],
        [20730],
        [20116],
        [20461]], device='cuda:0')
[2024-07-24 10:29:38,797][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[4064],
        [3505],
        [ 820],
        [ 106],
        [ 163],
        [ 417],
        [ 114],
        [ 370],
        [1812],
        [1025],
        [1910],
        [ 974],
        [ 443],
        [1039],
        [ 776],
        [ 492],
        [ 561]], device='cuda:0')
[2024-07-24 10:29:38,799][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[16204],
        [16284],
        [14908],
        [11124],
        [10302],
        [ 8865],
        [13712],
        [13837],
        [13375],
        [13872],
        [15973],
        [13877],
        [15365],
        [14955],
        [14642],
        [13627],
        [14443]], device='cuda:0')
[2024-07-24 10:29:38,800][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 8485],
        [ 8451],
        [ 7498],
        [10359],
        [ 9307],
        [ 5577],
        [ 7654],
        [ 6321],
        [ 4332],
        [ 6076],
        [ 3551],
        [ 7195],
        [ 4346],
        [ 3421],
        [ 4375],
        [ 6701],
        [ 4678]], device='cuda:0')
[2024-07-24 10:29:38,802][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[10429],
        [29755],
        [28070],
        [15322],
        [20797],
        [20914],
        [23217],
        [20163],
        [21421],
        [20772],
        [21483],
        [21590],
        [22597],
        [23179],
        [22759],
        [23624],
        [22935]], device='cuda:0')
[2024-07-24 10:29:38,803][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[11599],
        [ 4656],
        [ 2780],
        [ 3235],
        [ 3999],
        [ 4382],
        [ 6104],
        [ 4547],
        [ 3785],
        [ 3874],
        [ 3877],
        [ 3719],
        [10389],
        [ 9646],
        [ 7303],
        [ 4068],
        [ 3831]], device='cuda:0')
[2024-07-24 10:29:38,805][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[21296],
        [31201],
        [35365],
        [35822],
        [34060],
        [34318],
        [33874],
        [33028],
        [32798],
        [35123],
        [33616],
        [26683],
        [27668],
        [32777],
        [28111],
        [20952],
        [25669]], device='cuda:0')
[2024-07-24 10:29:38,806][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[16539],
        [23610],
        [15695],
        [31253],
        [26024],
        [17488],
        [25018],
        [22627],
        [17682],
        [21081],
        [18728],
        [15674],
        [13853],
        [13416],
        [16307],
        [15840],
        [16329]], device='cuda:0')
[2024-07-24 10:29:38,808][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 6500],
        [10938],
        [ 2600],
        [ 3013],
        [ 6908],
        [ 8691],
        [11516],
        [17308],
        [13281],
        [13937],
        [10717],
        [11537],
        [22636],
        [17317],
        [19529],
        [22104],
        [19767]], device='cuda:0')
[2024-07-24 10:29:38,810][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[3386],
        [1600],
        [1808],
        [1496],
        [1861],
        [2679],
        [2538],
        [2372],
        [3469],
        [5688],
        [4192],
        [4502],
        [6709],
        [6479],
        [9700],
        [9960],
        [9428]], device='cuda:0')
[2024-07-24 10:29:38,811][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[45932],
        [46105],
        [48584],
        [46775],
        [46010],
        [46662],
        [45782],
        [45140],
        [45208],
        [43521],
        [44758],
        [45021],
        [44501],
        [44228],
        [42710],
        [43387],
        [44444]], device='cuda:0')
[2024-07-24 10:29:38,812][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[18541],
        [27511],
        [35174],
        [35432],
        [41097],
        [38854],
        [40001],
        [38923],
        [39071],
        [36552],
        [38348],
        [35884],
        [36946],
        [37124],
        [36639],
        [38194],
        [38760]], device='cuda:0')
[2024-07-24 10:29:38,814][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205]], device='cuda:0')
[2024-07-24 10:29:38,863][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:38,864][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,866][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,867][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,868][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,869][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,870][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,871][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,872][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,873][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,874][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,875][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,876][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:38,878][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Sara] are: tensor([0.0470, 0.9530], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,879][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Sara] are: tensor([0.0123, 0.9877], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,881][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Sara] are: tensor([0.8648, 0.1352], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,882][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Sara] are: tensor([0.7566, 0.2434], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,884][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Sara] are: tensor([0.7627, 0.2373], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,885][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Sara] are: tensor([0.9722, 0.0278], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,886][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Sara] are: tensor([0.1122, 0.8878], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,888][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Sara] are: tensor([0.0340, 0.9660], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,889][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Sara] are: tensor([0.7771, 0.2229], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,890][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Sara] are: tensor([0.8017, 0.1983], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,890][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Sara] are: tensor([0.0672, 0.9328], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,890][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Sara] are: tensor([0.0175, 0.9825], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:38,891][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0133, 0.3624, 0.6243], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,891][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0045, 0.7565, 0.2390], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,891][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.9303, 0.0263, 0.0434], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,892][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.5680, 0.1179, 0.3142], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,892][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4047, 0.1057, 0.4896], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,892][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.6625, 0.0020, 0.3355], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,893][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0409, 0.1155, 0.8435], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,895][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0877, 0.3355, 0.5768], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,896][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1750, 0.4877, 0.3373], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,897][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0907, 0.0040, 0.9053], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,898][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([1.5330e-04, 1.9401e-03, 9.9791e-01], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,899][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0189, 0.6839, 0.2972], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:38,901][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Kenneth] are: tensor([0.0072, 0.2705, 0.5146, 0.2076], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,902][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Kenneth] are: tensor([0.0030, 0.4654, 0.1368, 0.3947], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,903][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Kenneth] are: tensor([0.3325, 0.0825, 0.1634, 0.4216], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,905][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Kenneth] are: tensor([0.2262, 0.0886, 0.4208, 0.2643], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,906][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Kenneth] are: tensor([0.2072, 0.1817, 0.5011, 0.1101], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,907][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Kenneth] are: tensor([0.1875, 0.0045, 0.7956, 0.0124], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,909][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Kenneth] are: tensor([0.0055, 0.0499, 0.8187, 0.1259], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,910][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Kenneth] are: tensor([0.1188, 0.1850, 0.4848, 0.2115], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,912][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Kenneth] are: tensor([0.2129, 0.2960, 0.1411, 0.3500], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,913][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Kenneth] are: tensor([0.0133, 0.0081, 0.9649, 0.0137], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,914][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Kenneth] are: tensor([3.9930e-04, 3.8751e-03, 9.9192e-01, 3.8020e-03], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,915][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Kenneth] are: tensor([0.0157, 0.3764, 0.2044, 0.4035], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:38,917][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.0054, 0.2242, 0.4019, 0.1568, 0.2117], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,918][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.0041, 0.3760, 0.0970, 0.4433, 0.0796], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,920][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.8059, 0.0329, 0.0220, 0.1009, 0.0384], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,921][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.2424, 0.1179, 0.2371, 0.2937, 0.1090], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,921][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.1364, 0.1492, 0.3420, 0.0764, 0.2961], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,922][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.8208, 0.0009, 0.1379, 0.0017, 0.0387], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,922][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.0036, 0.0260, 0.8060, 0.0830, 0.0814], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,922][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.0596, 0.2446, 0.3640, 0.0311, 0.3007], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,923][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.0970, 0.2577, 0.1417, 0.3088, 0.1948], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,923][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.1244, 0.0094, 0.7213, 0.0331, 0.1118], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,924][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ got] are: tensor([4.0748e-04, 1.9783e-03, 9.2106e-01, 2.1057e-03, 7.4444e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,925][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.0464, 0.1559, 0.1353, 0.5282, 0.1343], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:38,926][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0025, 0.1565, 0.2291, 0.1127, 0.1346, 0.3646], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,928][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0024, 0.3388, 0.0925, 0.3269, 0.0795, 0.1599], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,929][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.6630, 0.0299, 0.0554, 0.1510, 0.0573, 0.0434], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,930][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2324, 0.0740, 0.1957, 0.2021, 0.1111, 0.1846], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,932][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1951, 0.0318, 0.2983, 0.0355, 0.2035, 0.2359], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,932][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([8.7498e-01, 2.1728e-04, 6.8692e-02, 1.6694e-03, 2.4471e-02, 2.9975e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,934][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0514, 0.1207, 0.6379, 0.0839, 0.0714, 0.0348], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,935][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1319, 0.1758, 0.1747, 0.0310, 0.1240, 0.3627], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,937][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1983, 0.1467, 0.1354, 0.3005, 0.1375, 0.0815], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,938][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.3013, 0.0032, 0.3574, 0.0138, 0.0490, 0.2753], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,939][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([6.3343e-05, 4.7155e-04, 7.9061e-01, 1.0462e-03, 2.2796e-02, 1.8502e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,941][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0249, 0.2258, 0.1196, 0.3676, 0.1332, 0.1287], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:38,942][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.0020, 0.1256, 0.1906, 0.0950, 0.1271, 0.3244, 0.1353],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,943][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.0010, 0.3516, 0.0645, 0.2713, 0.0554, 0.1157, 0.1405],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,945][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.3332, 0.0515, 0.0345, 0.0731, 0.0598, 0.0563, 0.3915],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,946][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0539, 0.1197, 0.1877, 0.1402, 0.1622, 0.2772, 0.0592],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,948][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.0398, 0.0330, 0.2684, 0.0272, 0.2282, 0.3390, 0.0644],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,948][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([1.7462e-02, 1.5769e-03, 3.3194e-01, 6.8968e-03, 2.0944e-01, 4.3263e-01,
        5.2721e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,950][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.0019, 0.1258, 0.5503, 0.0910, 0.1049, 0.0863, 0.0397],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,951][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.0284, 0.0809, 0.2227, 0.0403, 0.1344, 0.2792, 0.2140],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,952][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.1060, 0.2336, 0.1240, 0.3398, 0.0878, 0.0790, 0.0299],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,952][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([1.8059e-04, 2.9841e-03, 4.2399e-01, 5.0860e-03, 1.1346e-01, 4.5401e-01,
        2.8919e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,953][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([1.0288e-04, 1.9049e-03, 5.6382e-01, 8.3709e-04, 6.4276e-02, 3.6901e-01,
        4.9846e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,953][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0044, 0.1300, 0.1907, 0.2475, 0.1265, 0.1572, 0.1437],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:38,954][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0021, 0.1043, 0.1452, 0.0740, 0.0891, 0.2335, 0.0873, 0.2646],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,954][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0016, 0.3190, 0.0656, 0.2140, 0.0409, 0.0861, 0.0661, 0.2067],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,954][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0982, 0.0228, 0.0495, 0.0951, 0.0658, 0.0338, 0.5586, 0.0762],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,955][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.2342, 0.0661, 0.1527, 0.1987, 0.0855, 0.1376, 0.0372, 0.0881],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,955][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.1407, 0.0239, 0.2374, 0.0306, 0.1054, 0.1276, 0.0303, 0.3041],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,956][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ at] are: tensor([8.5434e-01, 8.2526e-04, 8.4429e-02, 1.7512e-03, 2.4768e-02, 2.9463e-02,
        4.6910e-06, 4.4192e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,957][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0544, 0.1231, 0.5280, 0.0935, 0.0586, 0.0270, 0.0125, 0.1030],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,959][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0477, 0.1130, 0.1467, 0.0186, 0.1124, 0.3058, 0.0406, 0.2152],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,960][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.2765, 0.1438, 0.1427, 0.2683, 0.0705, 0.0570, 0.0119, 0.0294],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,961][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ at] are: tensor([1.1761e-01, 3.2430e-03, 4.1023e-01, 1.4186e-02, 3.2627e-02, 3.1908e-01,
        1.2987e-04, 1.0289e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,962][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ at] are: tensor([7.7016e-06, 4.3034e-04, 7.3233e-01, 2.8746e-04, 1.6591e-02, 2.1338e-01,
        1.9492e-05, 3.6952e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,963][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.1893, 0.2274, 0.1221, 0.2787, 0.0354, 0.0545, 0.0065, 0.0861],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:38,964][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0011, 0.0780, 0.1141, 0.0581, 0.0696, 0.1789, 0.0742, 0.2096, 0.2162],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,966][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0014, 0.3182, 0.0616, 0.1870, 0.0346, 0.0664, 0.0655, 0.1294, 0.1359],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,967][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.2563, 0.0065, 0.0367, 0.0474, 0.0319, 0.0200, 0.5243, 0.0475, 0.0293],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,969][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0806, 0.0860, 0.1441, 0.2280, 0.0685, 0.1324, 0.0461, 0.0842, 0.1302],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,970][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0677, 0.0157, 0.1470, 0.0127, 0.0720, 0.1025, 0.0275, 0.3467, 0.2082],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,971][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ the] are: tensor([9.6455e-01, 4.0844e-05, 1.2536e-02, 1.3953e-04, 4.1429e-03, 3.8453e-03,
        3.6691e-07, 4.7219e-04, 1.4271e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,972][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0207, 0.1863, 0.4905, 0.0976, 0.0450, 0.0312, 0.0337, 0.0606, 0.0344],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,974][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0277, 0.1238, 0.1441, 0.0190, 0.0694, 0.2264, 0.0380, 0.1608, 0.1909],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,975][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.1294, 0.1186, 0.1239, 0.3572, 0.0948, 0.0690, 0.0242, 0.0323, 0.0507],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,976][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ the] are: tensor([3.1230e-01, 3.8644e-04, 1.0230e-01, 1.6343e-03, 9.0924e-03, 8.7061e-02,
        1.6916e-05, 1.3973e-02, 4.7323e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,977][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ the] are: tensor([2.6874e-05, 4.5730e-04, 7.2369e-01, 6.4306e-04, 2.1169e-02, 1.4105e-01,
        3.2084e-05, 3.0963e-02, 8.1964e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,979][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0260, 0.1559, 0.0863, 0.2723, 0.0546, 0.0518, 0.0256, 0.1183, 0.2091],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:38,980][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ garden] are: tensor([0.0009, 0.0667, 0.1003, 0.0491, 0.0698, 0.1733, 0.0731, 0.1931, 0.1959,
        0.0780], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,981][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ garden] are: tensor([2.7555e-04, 3.2339e-01, 3.8218e-02, 1.3033e-01, 1.8982e-02, 6.4203e-02,
        5.1937e-02, 1.6966e-01, 1.4486e-01, 5.8139e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,982][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ garden] are: tensor([0.0277, 0.0174, 0.0348, 0.0362, 0.0300, 0.0612, 0.5329, 0.0458, 0.0649,
        0.1490], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,983][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ garden] are: tensor([0.0330, 0.1231, 0.0901, 0.1286, 0.0663, 0.1604, 0.0615, 0.1033, 0.1758,
        0.0580], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,984][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ garden] are: tensor([0.0305, 0.0111, 0.0974, 0.0103, 0.0581, 0.0742, 0.0262, 0.3077, 0.2536,
        0.1308], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,984][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ garden] are: tensor([7.7559e-02, 7.6987e-04, 8.0295e-02, 3.8256e-03, 4.9416e-02, 5.8432e-02,
        8.3076e-06, 2.0229e-02, 7.0779e-01, 1.6773e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,985][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ garden] are: tensor([0.0016, 0.3460, 0.2280, 0.0304, 0.0366, 0.0438, 0.0301, 0.1362, 0.1143,
        0.0332], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,985][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ garden] are: tensor([0.0191, 0.0534, 0.0712, 0.0155, 0.0611, 0.1522, 0.0437, 0.1294, 0.1185,
        0.3359], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,986][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ garden] are: tensor([0.0435, 0.2915, 0.0879, 0.2471, 0.0744, 0.0684, 0.0157, 0.0800, 0.0711,
        0.0203], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,986][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ garden] are: tensor([2.1876e-03, 8.9880e-04, 9.0066e-02, 1.1719e-03, 1.6585e-02, 4.0630e-02,
        1.2359e-05, 1.4321e-02, 8.3116e-01, 2.9696e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,987][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ garden] are: tensor([1.2313e-05, 8.4537e-04, 5.5661e-01, 4.8018e-04, 2.9971e-02, 2.1294e-01,
        4.9952e-05, 4.6881e-02, 1.5214e-01, 7.1789e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,988][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ garden] are: tensor([0.0099, 0.0443, 0.0658, 0.2612, 0.0368, 0.0848, 0.0270, 0.1763, 0.2313,
        0.0626], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:38,989][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0009, 0.0645, 0.0873, 0.0442, 0.0565, 0.1502, 0.0580, 0.1710, 0.1796,
        0.0654, 0.1224], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,991][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0009, 0.2746, 0.0360, 0.1427, 0.0260, 0.0557, 0.0542, 0.1445, 0.1168,
        0.0525, 0.0962], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,992][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1406, 0.0076, 0.0268, 0.0416, 0.0429, 0.0371, 0.2679, 0.0441, 0.0532,
        0.3346, 0.0034], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,994][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0979, 0.1017, 0.0819, 0.1763, 0.0504, 0.1354, 0.0412, 0.1077, 0.1137,
        0.0304, 0.0633], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,995][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0804, 0.0170, 0.1176, 0.0118, 0.0824, 0.0788, 0.0216, 0.2352, 0.1471,
        0.1138, 0.0943], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,996][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([7.3321e-01, 4.0849e-04, 5.1695e-02, 7.1950e-04, 1.7717e-02, 2.6801e-02,
        3.6142e-06, 4.1035e-03, 1.2251e-01, 2.6986e-04, 4.2559e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,998][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0161, 0.2110, 0.2637, 0.0758, 0.0397, 0.0212, 0.0203, 0.0840, 0.0376,
        0.0186, 0.2121], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:38,999][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0126, 0.0696, 0.0993, 0.0120, 0.0532, 0.1964, 0.0239, 0.1082, 0.1486,
        0.1336, 0.1425], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,000][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0688, 0.1825, 0.0862, 0.2484, 0.0568, 0.0743, 0.0267, 0.0602, 0.1001,
        0.0235, 0.0725], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,001][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([1.3453e-01, 7.5448e-04, 1.3370e-01, 1.1352e-03, 8.4368e-03, 7.5060e-02,
        1.8228e-05, 1.0238e-02, 4.1916e-01, 1.1751e-03, 2.1578e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,002][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([2.6881e-05, 6.6465e-04, 4.6833e-01, 6.8922e-04, 2.2527e-02, 1.5637e-01,
        6.0490e-05, 4.4356e-02, 9.1143e-02, 1.9595e-04, 2.1563e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,004][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0358, 0.2008, 0.0719, 0.2013, 0.0393, 0.0456, 0.0285, 0.0762, 0.1644,
        0.0632, 0.0730], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,005][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Sara] are: tensor([0.0007, 0.0518, 0.0899, 0.0353, 0.0551, 0.1449, 0.0618, 0.1481, 0.1587,
        0.0640, 0.1062, 0.0835], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,007][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Sara] are: tensor([0.0007, 0.2732, 0.0356, 0.1233, 0.0368, 0.0318, 0.0306, 0.1107, 0.0667,
        0.0214, 0.0445, 0.2248], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,008][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Sara] are: tensor([0.0514, 0.0245, 0.0429, 0.1131, 0.0404, 0.0469, 0.3269, 0.0405, 0.0670,
        0.1598, 0.0235, 0.0631], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,010][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Sara] are: tensor([0.0258, 0.0474, 0.1201, 0.1340, 0.0712, 0.2170, 0.0597, 0.1138, 0.1106,
        0.0229, 0.0523, 0.0253], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,011][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Sara] are: tensor([0.0454, 0.0220, 0.1392, 0.0130, 0.2162, 0.1002, 0.0377, 0.1413, 0.0950,
        0.1138, 0.0589, 0.0174], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,012][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Sara] are: tensor([8.7604e-02, 1.6465e-03, 1.7222e-01, 3.2878e-03, 5.4248e-02, 5.4025e-02,
        1.2862e-05, 1.0965e-02, 4.7944e-01, 9.7240e-04, 1.3514e-01, 4.4055e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,014][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Sara] are: tensor([0.0034, 0.1237, 0.3281, 0.0164, 0.0937, 0.0428, 0.0280, 0.1148, 0.0535,
        0.0335, 0.1255, 0.0366], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,015][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Sara] are: tensor([0.0107, 0.1021, 0.0577, 0.0123, 0.0373, 0.1133, 0.0243, 0.0658, 0.0883,
        0.0881, 0.0764, 0.3235], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,015][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Sara] are: tensor([0.2071, 0.0678, 0.0955, 0.2538, 0.0768, 0.0529, 0.0293, 0.0467, 0.0605,
        0.0223, 0.0533, 0.0339], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,016][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Sara] are: tensor([3.4366e-04, 3.7118e-04, 5.6816e-02, 5.8685e-04, 1.5801e-02, 3.1873e-02,
        2.1471e-05, 1.4227e-02, 6.7957e-01, 1.4442e-03, 1.9875e-01, 1.9183e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,016][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Sara] are: tensor([7.5512e-06, 2.2028e-04, 5.9398e-01, 3.0814e-04, 1.5531e-02, 9.0187e-02,
        8.1883e-06, 2.1584e-02, 8.1558e-02, 4.1874e-05, 1.9653e-01, 4.0502e-05],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,016][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Sara] are: tensor([0.0037, 0.1846, 0.0873, 0.1367, 0.0577, 0.0368, 0.0636, 0.0888, 0.1285,
        0.1447, 0.0474, 0.0204], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,017][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0009, 0.0533, 0.0831, 0.0383, 0.0524, 0.1359, 0.0529, 0.1395, 0.1432,
        0.0555, 0.0932, 0.0810, 0.0708], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,017][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0011, 0.1076, 0.0387, 0.1046, 0.0263, 0.0531, 0.0343, 0.1342, 0.0772,
        0.0274, 0.0664, 0.2434, 0.0857], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,018][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.1048, 0.0179, 0.0274, 0.0486, 0.0714, 0.0348, 0.3695, 0.0254, 0.0305,
        0.1183, 0.0043, 0.0694, 0.0778], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,019][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0575, 0.0585, 0.0996, 0.1206, 0.0398, 0.1377, 0.0324, 0.1182, 0.1368,
        0.0397, 0.0766, 0.0395, 0.0432], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,020][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.1098, 0.0237, 0.0923, 0.0105, 0.1152, 0.0833, 0.0120, 0.1593, 0.0969,
        0.0994, 0.0713, 0.0393, 0.0871], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,021][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([8.2520e-01, 2.0922e-04, 1.9666e-02, 1.4785e-04, 3.6773e-03, 5.9989e-03,
        4.7228e-07, 3.9990e-04, 3.4910e-02, 2.9148e-05, 1.1119e-02, 2.1089e-05,
        9.8622e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,023][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0011, 0.0359, 0.4204, 0.0385, 0.0613, 0.0501, 0.0298, 0.0703, 0.0365,
        0.0205, 0.1964, 0.0213, 0.0179], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,024][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0191, 0.0357, 0.0741, 0.0102, 0.0515, 0.0785, 0.0197, 0.0614, 0.0662,
        0.0668, 0.0748, 0.1001, 0.3417], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,026][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0433, 0.1276, 0.1586, 0.2570, 0.0523, 0.0654, 0.0205, 0.0601, 0.0779,
        0.0249, 0.0575, 0.0282, 0.0267], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,027][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([8.9526e-02, 3.5200e-04, 2.6378e-02, 3.6292e-04, 3.0796e-03, 2.4468e-02,
        3.0044e-06, 1.8195e-03, 2.2411e-01, 1.1184e-04, 6.7088e-02, 4.3067e-05,
        5.6266e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,028][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([1.1445e-05, 2.4304e-04, 5.2763e-01, 4.4756e-04, 2.2062e-02, 1.1429e-01,
        1.2420e-05, 2.2038e-02, 6.3706e-02, 3.6154e-05, 2.4879e-01, 3.5288e-05,
        7.0425e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,029][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0269, 0.1310, 0.0715, 0.1481, 0.0391, 0.0591, 0.0150, 0.0681, 0.1524,
        0.0653, 0.0395, 0.0392, 0.1448], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,031][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0006, 0.0496, 0.0697, 0.0361, 0.0476, 0.1156, 0.0474, 0.1254, 0.1295,
        0.0521, 0.0892, 0.0759, 0.0666, 0.0946], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,032][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0006, 0.1204, 0.0211, 0.0821, 0.0152, 0.0373, 0.0389, 0.0795, 0.0760,
        0.0266, 0.0474, 0.3139, 0.0752, 0.0657], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,034][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0403, 0.0108, 0.0452, 0.0339, 0.0719, 0.0636, 0.2392, 0.0655, 0.0738,
        0.1785, 0.0116, 0.0385, 0.0984, 0.0290], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,035][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0837, 0.0692, 0.0695, 0.1115, 0.0499, 0.1016, 0.0343, 0.1020, 0.1127,
        0.0350, 0.0671, 0.0429, 0.0601, 0.0605], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,036][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0914, 0.0084, 0.0642, 0.0062, 0.0371, 0.0440, 0.0110, 0.1137, 0.0810,
        0.0472, 0.0824, 0.0174, 0.0742, 0.3217], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,037][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([7.9045e-01, 2.8155e-05, 1.2537e-03, 1.8896e-05, 3.3107e-04, 4.8364e-04,
        7.8876e-08, 3.1175e-05, 2.7170e-03, 2.4397e-06, 1.2269e-03, 5.3469e-06,
        7.3210e-03, 1.9613e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,039][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0130, 0.1572, 0.1648, 0.0895, 0.0640, 0.0357, 0.0189, 0.0600, 0.0366,
        0.0163, 0.1284, 0.0807, 0.0483, 0.0866], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,040][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0022, 0.0412, 0.0811, 0.0082, 0.0384, 0.1083, 0.0120, 0.0686, 0.0786,
        0.0691, 0.0923, 0.1134, 0.1308, 0.1557], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,042][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0941, 0.1455, 0.1092, 0.2058, 0.0628, 0.0686, 0.0154, 0.0491, 0.0671,
        0.0125, 0.0392, 0.0483, 0.0365, 0.0458], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,043][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.6464e-01, 7.8672e-05, 2.7571e-03, 7.9954e-05, 2.5081e-04, 1.2993e-03,
        4.4194e-07, 1.0065e-04, 8.8737e-03, 1.1344e-05, 5.5545e-03, 1.8935e-05,
        2.7580e-02, 7.8875e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,044][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([3.9784e-06, 2.4923e-04, 4.6361e-01, 4.4147e-04, 1.2284e-02, 1.0147e-01,
        2.8448e-05, 2.1494e-02, 8.6917e-02, 8.2795e-05, 2.8555e-01, 3.9201e-05,
        9.6735e-04, 2.6866e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,045][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0366, 0.0933, 0.0649, 0.1394, 0.0322, 0.0520, 0.0115, 0.0579, 0.1386,
        0.0228, 0.0366, 0.0142, 0.1947, 0.1053], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,046][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0005, 0.0433, 0.0650, 0.0330, 0.0421, 0.1055, 0.0463, 0.1148, 0.1181,
        0.0495, 0.0795, 0.0691, 0.0555, 0.0891, 0.0884], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,047][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0008, 0.1576, 0.0300, 0.1168, 0.0180, 0.0451, 0.0237, 0.0689, 0.0794,
        0.0225, 0.0586, 0.1580, 0.0487, 0.0594, 0.1125], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,047][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0699, 0.0024, 0.0148, 0.0167, 0.0432, 0.0143, 0.4544, 0.0286, 0.0345,
        0.1035, 0.0025, 0.0143, 0.0987, 0.0152, 0.0870], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,048][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0332, 0.0832, 0.0608, 0.0983, 0.0180, 0.0959, 0.0307, 0.0673, 0.0905,
        0.0179, 0.0620, 0.0471, 0.0173, 0.0490, 0.2289], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,048][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0805, 0.0102, 0.0785, 0.0090, 0.0537, 0.0431, 0.0120, 0.0934, 0.0546,
        0.0418, 0.0518, 0.0203, 0.0215, 0.2582, 0.1715], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,049][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ give] are: tensor([3.5450e-01, 9.3022e-06, 1.1917e-03, 3.9908e-06, 1.8964e-04, 2.8044e-04,
        1.4988e-08, 1.1372e-05, 2.2612e-03, 1.4575e-06, 9.3723e-04, 2.0700e-06,
        1.7652e-02, 5.4458e-01, 7.8381e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,049][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0026, 0.1300, 0.2147, 0.0331, 0.0367, 0.0402, 0.0226, 0.0479, 0.0340,
        0.0159, 0.1484, 0.0436, 0.0205, 0.1227, 0.0872], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,051][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0093, 0.0416, 0.0636, 0.0053, 0.0386, 0.0734, 0.0136, 0.0571, 0.0678,
        0.0448, 0.0752, 0.0893, 0.1358, 0.1108, 0.1738], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,052][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0679, 0.1540, 0.0989, 0.2567, 0.0589, 0.0591, 0.0133, 0.0415, 0.0670,
        0.0199, 0.0436, 0.0419, 0.0246, 0.0309, 0.0216], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,053][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ give] are: tensor([3.5959e-03, 6.6547e-06, 6.0052e-04, 5.6837e-06, 4.8239e-05, 1.7813e-04,
        2.9472e-08, 1.7263e-05, 3.6810e-03, 1.1696e-06, 1.9957e-03, 2.0376e-06,
        2.6800e-02, 7.9917e-01, 1.6389e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,054][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ give] are: tensor([1.0812e-05, 2.3905e-04, 4.9519e-01, 3.2264e-04, 1.5934e-02, 1.1172e-01,
        8.5163e-06, 2.3327e-02, 8.9193e-02, 2.3147e-05, 2.2869e-01, 2.9037e-05,
        8.0507e-04, 3.3848e-02, 6.5479e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,056][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0192, 0.0926, 0.0591, 0.1343, 0.0355, 0.0448, 0.0060, 0.0605, 0.0817,
        0.0170, 0.0315, 0.0123, 0.0791, 0.1166, 0.2097], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,057][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.0005, 0.0403, 0.0599, 0.0306, 0.0419, 0.0989, 0.0442, 0.1034, 0.1117,
        0.0478, 0.0744, 0.0637, 0.0547, 0.0781, 0.0801, 0.0696],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,059][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ it] are: tensor([0.0003, 0.0603, 0.0211, 0.0376, 0.0142, 0.0362, 0.0325, 0.0948, 0.0794,
        0.0221, 0.0366, 0.1244, 0.0491, 0.0593, 0.1211, 0.2109],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,060][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.0814, 0.0083, 0.0171, 0.0151, 0.0595, 0.0212, 0.4523, 0.0271, 0.0257,
        0.0944, 0.0032, 0.0243, 0.0707, 0.0056, 0.0800, 0.0141],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,062][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ it] are: tensor([0.0331, 0.0163, 0.0662, 0.0548, 0.0232, 0.0686, 0.0305, 0.0741, 0.0887,
        0.0327, 0.0587, 0.0114, 0.0345, 0.0591, 0.2031, 0.1450],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,063][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.0921, 0.0094, 0.0645, 0.0083, 0.0373, 0.0463, 0.0078, 0.0536, 0.0676,
        0.0633, 0.0556, 0.0182, 0.0295, 0.2080, 0.1827, 0.0558],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,064][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ it] are: tensor([1.6269e-02, 1.1112e-05, 9.6693e-04, 6.6897e-06, 2.0582e-04, 3.1262e-04,
        4.1826e-08, 2.6260e-05, 4.9523e-03, 2.2234e-06, 1.7351e-03, 2.9494e-06,
        1.9041e-02, 6.1871e-01, 2.9127e-01, 4.6488e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,066][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.0008, 0.0875, 0.2567, 0.0268, 0.0274, 0.0409, 0.0249, 0.0674, 0.0644,
        0.0125, 0.1203, 0.0382, 0.0207, 0.0702, 0.0536, 0.0877],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,067][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.0091, 0.0429, 0.0537, 0.0047, 0.0520, 0.0731, 0.0153, 0.0546, 0.0538,
        0.0670, 0.0544, 0.0770, 0.1651, 0.0781, 0.1215, 0.0776],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,069][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.0578, 0.0842, 0.0981, 0.1433, 0.0694, 0.0601, 0.0232, 0.0577, 0.0898,
        0.0215, 0.0485, 0.0260, 0.0863, 0.0753, 0.0286, 0.0300],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,070][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ it] are: tensor([1.4830e-03, 1.9709e-06, 3.4550e-04, 3.5602e-06, 5.8224e-05, 2.5071e-04,
        3.1843e-08, 3.0274e-05, 6.7906e-03, 2.2775e-06, 2.5332e-03, 9.8153e-07,
        1.2020e-02, 5.6083e-01, 1.9142e-01, 2.2423e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,071][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ it] are: tensor([6.4652e-06, 1.7295e-04, 5.2080e-01, 2.4169e-04, 1.8045e-02, 1.2749e-01,
        9.8694e-06, 1.8641e-02, 6.3916e-02, 2.5501e-05, 2.0536e-01, 1.9251e-05,
        6.4105e-04, 1.8667e-02, 8.0160e-04, 2.5163e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,072][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ it] are: tensor([0.0016, 0.0271, 0.0121, 0.0249, 0.0391, 0.0321, 0.0071, 0.0719, 0.2061,
        0.0182, 0.0125, 0.0065, 0.1472, 0.0484, 0.1500, 0.1953],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,074][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0004, 0.0398, 0.0580, 0.0304, 0.0394, 0.0899, 0.0387, 0.1003, 0.0991,
        0.0419, 0.0706, 0.0608, 0.0533, 0.0731, 0.0781, 0.0644, 0.0618],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,075][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0003, 0.0855, 0.0153, 0.0522, 0.0091, 0.0262, 0.0256, 0.0516, 0.0564,
        0.0172, 0.0301, 0.2171, 0.0569, 0.0445, 0.0954, 0.1725, 0.0441],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,077][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0197, 0.0088, 0.0371, 0.0230, 0.0608, 0.0537, 0.2321, 0.0782, 0.0784,
        0.1119, 0.0140, 0.0298, 0.0879, 0.0276, 0.0466, 0.0562, 0.0341],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,077][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0341, 0.0690, 0.0454, 0.0765, 0.0303, 0.0707, 0.0199, 0.0788, 0.0846,
        0.0175, 0.0399, 0.0410, 0.0375, 0.0381, 0.2004, 0.0881, 0.0284],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,078][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0606, 0.0090, 0.0480, 0.0049, 0.0286, 0.0304, 0.0079, 0.0766, 0.0574,
        0.0372, 0.0476, 0.0151, 0.0389, 0.1835, 0.2003, 0.0438, 0.1101],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,078][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([4.7309e-01, 4.5407e-05, 1.5100e-03, 2.5527e-05, 6.1202e-04, 4.6476e-04,
        1.1388e-07, 3.1453e-05, 3.4213e-03, 3.3558e-06, 1.4633e-03, 8.0130e-06,
        1.4436e-02, 2.4800e-01, 8.6428e-02, 1.2205e-01, 4.8409e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,079][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0051, 0.1264, 0.1655, 0.0608, 0.0406, 0.0297, 0.0107, 0.0481, 0.0372,
        0.0102, 0.1044, 0.0585, 0.0393, 0.0958, 0.0900, 0.0493, 0.0283],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,079][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0013, 0.0330, 0.0784, 0.0068, 0.0344, 0.0927, 0.0108, 0.0572, 0.0672,
        0.0551, 0.0781, 0.0728, 0.0973, 0.1100, 0.0715, 0.0507, 0.0827],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,080][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0823, 0.1559, 0.0974, 0.1786, 0.0622, 0.0596, 0.0135, 0.0393, 0.0558,
        0.0102, 0.0323, 0.0565, 0.0377, 0.0412, 0.0174, 0.0230, 0.0371],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,081][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.4210e-02, 2.7452e-05, 8.9621e-04, 3.3245e-05, 1.1688e-04, 4.1892e-04,
        1.9046e-07, 4.1968e-05, 4.2247e-03, 5.1653e-06, 2.5041e-03, 9.4029e-06,
        1.8918e-02, 3.9629e-01, 7.5685e-02, 3.8028e-01, 1.0634e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,082][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([3.6426e-06, 2.6571e-04, 4.2534e-01, 3.8762e-04, 1.2506e-02, 8.8885e-02,
        4.3812e-05, 2.4325e-02, 8.8629e-02, 1.1207e-04, 2.8634e-01, 5.0041e-05,
        1.2080e-03, 3.1081e-02, 6.4154e-04, 1.9538e-02, 2.0639e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,083][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0086, 0.0686, 0.0367, 0.0779, 0.0174, 0.0359, 0.0091, 0.0488, 0.1139,
        0.0148, 0.0232, 0.0124, 0.1210, 0.0713, 0.1029, 0.1646, 0.0727],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,144][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:39,144][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,145][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,145][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,145][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,146][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,146][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,146][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,147][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,147][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,147][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,147][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,148][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,148][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Sara] are: tensor([0.4854, 0.5146], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,148][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Sara] are: tensor([0.0034, 0.9966], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,149][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Sara] are: tensor([0.6262, 0.3738], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,149][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Sara] are: tensor([0.7566, 0.2434], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,150][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Sara] are: tensor([0.7627, 0.2373], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,151][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Sara] are: tensor([0.9924, 0.0076], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,152][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Sara] are: tensor([0.3017, 0.6983], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,154][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Sara] are: tensor([0.8951, 0.1049], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,155][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Sara] are: tensor([0.7771, 0.2229], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,156][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Sara] are: tensor([0.8017, 0.1983], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,157][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Sara] are: tensor([0.1271, 0.8729], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,159][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Sara] are: tensor([0.0175, 0.9825], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,160][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2224, 0.2176, 0.5600], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,162][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0017, 0.7959, 0.2024], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,163][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1885, 0.2849, 0.5266], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,165][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.5680, 0.1179, 0.3142], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,166][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.4047, 0.1057, 0.4896], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,167][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.7690, 0.0019, 0.2291], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,168][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0672, 0.3945, 0.5383], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,170][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.6059, 0.2680, 0.1261], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,171][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1750, 0.4877, 0.3373], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,172][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0907, 0.0040, 0.9053], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,174][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0509, 0.9479, 0.0012], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,175][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0189, 0.6839, 0.2972], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,177][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Kenneth] are: tensor([0.1001, 0.1146, 0.4591, 0.3262], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,177][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Kenneth] are: tensor([0.0008, 0.5181, 0.1067, 0.3745], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,178][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Kenneth] are: tensor([0.1000, 0.0945, 0.3162, 0.4893], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,178][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Kenneth] are: tensor([0.2262, 0.0886, 0.4208, 0.2643], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,178][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Kenneth] are: tensor([0.2072, 0.1817, 0.5011, 0.1101], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,179][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Kenneth] are: tensor([0.2890, 0.0042, 0.6911, 0.0156], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,179][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Kenneth] are: tensor([0.0357, 0.1881, 0.4436, 0.3326], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,179][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Kenneth] are: tensor([0.5630, 0.0577, 0.0801, 0.2992], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,180][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Kenneth] are: tensor([0.2129, 0.2960, 0.1411, 0.3500], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,181][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Kenneth] are: tensor([0.0133, 0.0081, 0.9649, 0.0137], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,183][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Kenneth] are: tensor([0.0707, 0.4782, 0.0035, 0.4476], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,184][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Kenneth] are: tensor([0.0157, 0.3764, 0.2044, 0.4035], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,185][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.0459, 0.1362, 0.3323, 0.2094, 0.2763], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,186][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.0013, 0.4232, 0.0646, 0.4627, 0.0482], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,188][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.0547, 0.1108, 0.1865, 0.3215, 0.3266], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,189][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.2424, 0.1179, 0.2371, 0.2937, 0.1090], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,190][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.1364, 0.1492, 0.3420, 0.0764, 0.2961], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,192][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.8300, 0.0010, 0.1275, 0.0020, 0.0396], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,193][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.0158, 0.1053, 0.4084, 0.2431, 0.2274], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,194][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.3622, 0.1043, 0.0735, 0.3755, 0.0845], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,196][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.0970, 0.2577, 0.1417, 0.3088, 0.1948], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,197][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.1244, 0.0094, 0.7213, 0.0331, 0.1118], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,199][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.0316, 0.4897, 0.0021, 0.4401, 0.0364], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,200][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.0464, 0.1559, 0.1353, 0.5282, 0.1343], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,202][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0754, 0.1656, 0.2070, 0.1454, 0.1345, 0.2721], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,203][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0007, 0.4049, 0.0697, 0.3489, 0.0554, 0.1203], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,204][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0485, 0.1011, 0.1480, 0.2570, 0.2922, 0.1531], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,206][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.2324, 0.0740, 0.1957, 0.2021, 0.1111, 0.1846], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,207][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1951, 0.0318, 0.2983, 0.0355, 0.2035, 0.2359], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,208][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([8.9438e-01, 2.3929e-04, 5.5549e-02, 1.5985e-03, 2.2099e-02, 2.6133e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,208][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0523, 0.2018, 0.2213, 0.2293, 0.1821, 0.1131], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,209][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.4259, 0.1092, 0.0708, 0.3244, 0.0306, 0.0391], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,209][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1983, 0.1467, 0.1354, 0.3005, 0.1375, 0.0815], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,209][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.3013, 0.0032, 0.3574, 0.0138, 0.0490, 0.2753], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,210][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0506, 0.5924, 0.0008, 0.3218, 0.0314, 0.0030], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,210][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0249, 0.2258, 0.1196, 0.3676, 0.1332, 0.1287], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,211][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.0222, 0.1536, 0.1100, 0.1356, 0.1809, 0.3370, 0.0607],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,211][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([1.3217e-04, 4.2541e-01, 4.2215e-02, 2.9341e-01, 3.2773e-02, 9.4131e-02,
        1.1193e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,212][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.0208, 0.0551, 0.1646, 0.2354, 0.2731, 0.1907, 0.0603],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,213][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.0539, 0.1197, 0.1877, 0.1402, 0.1622, 0.2772, 0.0592],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,215][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.0398, 0.0330, 0.2684, 0.0272, 0.2282, 0.3390, 0.0644],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,216][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([2.4664e-02, 1.5510e-03, 3.1073e-01, 8.3316e-03, 2.0735e-01, 4.4722e-01,
        1.4109e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,217][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.0054, 0.2179, 0.1697, 0.2330, 0.1501, 0.1303, 0.0936],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,218][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.1072, 0.1390, 0.0418, 0.6392, 0.0153, 0.0259, 0.0315],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,220][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.1060, 0.2336, 0.1240, 0.3398, 0.0878, 0.0790, 0.0299],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,220][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([1.8059e-04, 2.9841e-03, 4.2399e-01, 5.0860e-03, 1.1346e-01, 4.5401e-01,
        2.8919e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,221][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([1.6131e-02, 6.4772e-01, 1.2858e-03, 2.9598e-01, 3.4032e-02, 4.2526e-03,
        5.9875e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,223][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.0044, 0.1300, 0.1907, 0.2475, 0.1265, 0.1572, 0.1437],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,224][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0845, 0.1707, 0.1389, 0.1303, 0.0843, 0.2014, 0.0149, 0.1750],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,226][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0005, 0.4247, 0.0503, 0.2227, 0.0230, 0.0599, 0.0408, 0.1781],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,227][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0386, 0.0635, 0.0793, 0.2195, 0.2210, 0.1488, 0.0427, 0.1866],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,229][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.2342, 0.0661, 0.1527, 0.1987, 0.0855, 0.1376, 0.0372, 0.0881],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,230][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.1407, 0.0239, 0.2374, 0.0306, 0.1054, 0.1276, 0.0303, 0.3041],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,231][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([8.7933e-01, 6.2574e-04, 6.4220e-02, 1.6439e-03, 2.2110e-02, 2.7419e-02,
        1.0983e-05, 4.6438e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,233][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0429, 0.2165, 0.1616, 0.2363, 0.1415, 0.0860, 0.0289, 0.0864],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,234][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.4054, 0.1506, 0.0555, 0.3143, 0.0176, 0.0286, 0.0116, 0.0163],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,235][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.2765, 0.1438, 0.1427, 0.2683, 0.0705, 0.0570, 0.0119, 0.0294],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,236][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([1.1761e-01, 3.2430e-03, 4.1023e-01, 1.4186e-02, 3.2627e-02, 3.1908e-01,
        1.2987e-04, 1.0289e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,237][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([5.7720e-02, 5.6452e-01, 7.0393e-04, 3.5233e-01, 2.1492e-02, 2.5134e-03,
        1.5528e-04, 5.7186e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,239][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.1893, 0.2274, 0.1221, 0.2787, 0.0354, 0.0545, 0.0065, 0.0861],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,239][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0327, 0.1335, 0.1111, 0.0730, 0.0542, 0.1426, 0.0258, 0.1525, 0.2747],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,240][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([3.9138e-04, 4.2139e-01, 4.1610e-02, 1.9535e-01, 1.9302e-02, 3.9592e-02,
        4.6727e-02, 8.3038e-02, 1.5260e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,240][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0243, 0.0501, 0.0748, 0.1971, 0.1202, 0.0913, 0.0704, 0.1372, 0.2346],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,240][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0806, 0.0860, 0.1441, 0.2280, 0.0685, 0.1324, 0.0461, 0.0842, 0.1302],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,241][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0677, 0.0157, 0.1470, 0.0127, 0.0720, 0.1025, 0.0275, 0.3467, 0.2082],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,241][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([9.7328e-01, 3.8706e-05, 9.3058e-03, 1.4101e-04, 3.4989e-03, 3.4363e-03,
        9.3439e-07, 4.7732e-04, 9.8255e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,242][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0243, 0.2625, 0.1393, 0.1957, 0.0919, 0.0771, 0.0662, 0.0559, 0.0872],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,243][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.3184, 0.1281, 0.0598, 0.3722, 0.0222, 0.0280, 0.0151, 0.0138, 0.0424],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,244][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1294, 0.1186, 0.1239, 0.3572, 0.0948, 0.0690, 0.0242, 0.0323, 0.0507],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,245][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([3.1230e-01, 3.8644e-04, 1.0230e-01, 1.6343e-03, 9.0924e-03, 8.7061e-02,
        1.6916e-05, 1.3973e-02, 4.7323e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,246][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([3.2515e-02, 7.1657e-01, 3.5141e-04, 2.3477e-01, 1.4164e-02, 1.0043e-03,
        9.1781e-05, 2.0449e-04, 3.2857e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,248][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0260, 0.1559, 0.0863, 0.2723, 0.0546, 0.0518, 0.0256, 0.1183, 0.2091],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,249][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ garden] are: tensor([0.0060, 0.1819, 0.0457, 0.0457, 0.0420, 0.0915, 0.0252, 0.2592, 0.2760,
        0.0267], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,250][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ garden] are: tensor([2.5744e-05, 4.2849e-01, 2.2323e-02, 1.2784e-01, 8.2601e-03, 4.3872e-02,
        3.3158e-02, 1.3202e-01, 1.6347e-01, 4.0541e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,251][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ garden] are: tensor([0.0045, 0.0285, 0.0494, 0.1339, 0.0943, 0.0965, 0.0498, 0.1938, 0.2345,
        0.1147], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,253][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ garden] are: tensor([0.0330, 0.1231, 0.0901, 0.1286, 0.0663, 0.1604, 0.0615, 0.1033, 0.1758,
        0.0580], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,254][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ garden] are: tensor([0.0305, 0.0111, 0.0974, 0.0103, 0.0581, 0.0742, 0.0262, 0.3077, 0.2536,
        0.1308], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,255][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ garden] are: tensor([9.2195e-02, 7.8456e-04, 7.5130e-02, 4.5101e-03, 6.2479e-02, 7.4860e-02,
        3.0046e-05, 3.3295e-02, 6.5301e-01, 3.7049e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,256][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ garden] are: tensor([0.0028, 0.3320, 0.0709, 0.1115, 0.0570, 0.0672, 0.0531, 0.1057, 0.1469,
        0.0529], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,258][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ garden] are: tensor([0.1683, 0.2103, 0.0517, 0.4208, 0.0104, 0.0241, 0.0156, 0.0162, 0.0488,
        0.0338], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,260][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ garden] are: tensor([0.0435, 0.2915, 0.0879, 0.2471, 0.0744, 0.0684, 0.0157, 0.0800, 0.0711,
        0.0203], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,260][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ garden] are: tensor([2.1876e-03, 8.9880e-04, 9.0066e-02, 1.1719e-03, 1.6585e-02, 4.0630e-02,
        1.2359e-05, 1.4321e-02, 8.3116e-01, 2.9696e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,261][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ garden] are: tensor([2.3592e-03, 8.3636e-01, 2.9433e-04, 1.4496e-01, 1.1626e-02, 1.9747e-03,
        1.5674e-04, 8.9821e-04, 1.0179e-03, 3.4917e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,263][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ garden] are: tensor([0.0099, 0.0443, 0.0658, 0.2612, 0.0368, 0.0848, 0.0270, 0.1763, 0.2313,
        0.0626], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,264][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0275, 0.1459, 0.0628, 0.0583, 0.0388, 0.1099, 0.0161, 0.1471, 0.2120,
        0.0239, 0.1578], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,265][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([1.9183e-04, 3.5765e-01, 2.1171e-02, 1.4809e-01, 1.3317e-02, 3.4458e-02,
        3.3501e-02, 1.1951e-01, 1.3265e-01, 4.3088e-02, 9.6373e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,267][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0116, 0.0428, 0.0366, 0.1329, 0.0982, 0.0927, 0.0501, 0.1637, 0.2151,
        0.0699, 0.0865], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,268][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0979, 0.1017, 0.0819, 0.1763, 0.0504, 0.1354, 0.0412, 0.1077, 0.1137,
        0.0304, 0.0633], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,270][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0804, 0.0170, 0.1176, 0.0118, 0.0824, 0.0788, 0.0216, 0.2352, 0.1471,
        0.1138, 0.0943], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,270][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([7.2417e-01, 4.1635e-04, 4.7618e-02, 9.5206e-04, 2.0298e-02, 3.1992e-02,
        1.1801e-05, 6.0628e-03, 1.1520e-01, 5.6033e-04, 5.2717e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,271][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0180, 0.2277, 0.0801, 0.1794, 0.0829, 0.0487, 0.0334, 0.0694, 0.0669,
        0.0415, 0.1520], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,271][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2133, 0.1756, 0.0543, 0.3947, 0.0166, 0.0233, 0.0119, 0.0144, 0.0378,
        0.0152, 0.0429], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,271][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0688, 0.1825, 0.0862, 0.2484, 0.0568, 0.0743, 0.0267, 0.0602, 0.1001,
        0.0235, 0.0725], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,272][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([1.3453e-01, 7.5448e-04, 1.3370e-01, 1.1352e-03, 8.4368e-03, 7.5060e-02,
        1.8228e-05, 1.0238e-02, 4.1916e-01, 1.1751e-03, 2.1578e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,272][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([2.8178e-02, 7.6077e-01, 2.9321e-04, 1.9905e-01, 9.4235e-03, 1.0890e-03,
        9.6805e-05, 3.6000e-04, 3.6629e-04, 1.8883e-04, 1.8735e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,273][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0358, 0.2008, 0.0719, 0.2013, 0.0393, 0.0456, 0.0285, 0.0762, 0.1644,
        0.0632, 0.0730], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,273][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Sara] are: tensor([0.0038, 0.0694, 0.0558, 0.0183, 0.0553, 0.1213, 0.0304, 0.1234, 0.2304,
        0.0239, 0.1158, 0.1523], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,274][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Sara] are: tensor([9.5056e-05, 3.3764e-01, 2.2249e-02, 1.1410e-01, 2.3255e-02, 2.0557e-02,
        2.0141e-02, 8.6424e-02, 7.5182e-02, 1.3390e-02, 3.9614e-02, 2.4735e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,275][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Sara] are: tensor([0.0065, 0.0219, 0.0584, 0.1142, 0.2004, 0.0895, 0.0300, 0.1731, 0.1277,
        0.0638, 0.0790, 0.0356], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,276][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Sara] are: tensor([0.0258, 0.0474, 0.1201, 0.1340, 0.0712, 0.2170, 0.0597, 0.1138, 0.1106,
        0.0229, 0.0523, 0.0253], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,278][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Sara] are: tensor([0.0454, 0.0220, 0.1392, 0.0130, 0.2162, 0.1002, 0.0377, 0.1413, 0.0950,
        0.1138, 0.0589, 0.0174], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,279][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Sara] are: tensor([1.0632e-01, 1.0525e-03, 1.4391e-01, 3.3752e-03, 5.7329e-02, 6.6953e-02,
        3.6316e-05, 1.7281e-02, 4.2439e-01, 2.0321e-03, 1.7658e-01, 7.4791e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,280][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Sara] are: tensor([0.0110, 0.1656, 0.1059, 0.0822, 0.1661, 0.0517, 0.0474, 0.0736, 0.0622,
        0.0575, 0.0818, 0.0950], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,281][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Sara] are: tensor([0.2424, 0.1346, 0.0542, 0.2632, 0.0206, 0.0242, 0.0358, 0.0116, 0.0417,
        0.0369, 0.0431, 0.0918], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,281][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Sara] are: tensor([0.2071, 0.0678, 0.0955, 0.2538, 0.0768, 0.0529, 0.0293, 0.0467, 0.0605,
        0.0223, 0.0533, 0.0339], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,282][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Sara] are: tensor([3.4366e-04, 3.7118e-04, 5.6816e-02, 5.8685e-04, 1.5801e-02, 3.1873e-02,
        2.1471e-05, 1.4227e-02, 6.7957e-01, 1.4442e-03, 1.9875e-01, 1.9183e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,282][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Sara] are: tensor([2.1083e-02, 7.1392e-01, 7.0538e-04, 2.1850e-01, 3.5243e-02, 3.4351e-03,
        3.1773e-04, 1.3115e-03, 9.9245e-04, 4.9552e-04, 3.5574e-04, 3.6394e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,282][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Sara] are: tensor([0.0037, 0.1846, 0.0873, 0.1367, 0.0577, 0.0368, 0.0636, 0.0888, 0.1285,
        0.1447, 0.0474, 0.0204], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,283][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.0257, 0.0592, 0.0444, 0.0327, 0.0412, 0.0877, 0.0136, 0.0879, 0.1076,
        0.0141, 0.0587, 0.2487, 0.1784], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,284][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([2.2984e-04, 1.1575e-01, 3.0115e-02, 1.0603e-01, 1.6316e-02, 4.5260e-02,
        2.1118e-02, 1.3269e-01, 8.9377e-02, 1.9720e-02, 6.9033e-02, 2.8723e-01,
        6.7133e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,285][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0135, 0.0347, 0.0365, 0.0993, 0.0741, 0.0849, 0.0316, 0.1351, 0.1466,
        0.0588, 0.0487, 0.1458, 0.0905], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,287][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.0575, 0.0585, 0.0996, 0.1206, 0.0398, 0.1377, 0.0324, 0.1182, 0.1368,
        0.0397, 0.0766, 0.0395, 0.0432], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,288][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.1098, 0.0237, 0.0923, 0.0105, 0.1152, 0.0833, 0.0120, 0.1593, 0.0969,
        0.0994, 0.0713, 0.0393, 0.0871], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,289][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([8.1282e-01, 1.5996e-04, 1.5598e-02, 1.8371e-04, 4.1088e-03, 6.5515e-03,
        1.6014e-06, 6.2246e-04, 2.9477e-02, 7.0616e-05, 1.3488e-02, 4.2799e-05,
        1.1688e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,291][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0105, 0.0561, 0.1272, 0.0841, 0.0891, 0.0815, 0.0502, 0.0446, 0.0639,
        0.0376, 0.1395, 0.1248, 0.0908], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,292][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.1645, 0.1423, 0.0432, 0.2813, 0.0227, 0.0270, 0.0131, 0.0142, 0.0405,
        0.0223, 0.0293, 0.0834, 0.1160], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,294][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0433, 0.1276, 0.1586, 0.2570, 0.0523, 0.0654, 0.0205, 0.0601, 0.0779,
        0.0249, 0.0575, 0.0282, 0.0267], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,295][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([8.9526e-02, 3.5200e-04, 2.6378e-02, 3.6292e-04, 3.0796e-03, 2.4468e-02,
        3.0044e-06, 1.8195e-03, 2.2411e-01, 1.1184e-04, 6.7088e-02, 4.3067e-05,
        5.6266e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,296][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([4.0337e-02, 6.3016e-01, 2.1439e-03, 2.6418e-01, 3.0179e-02, 6.7597e-03,
        4.1805e-04, 1.1489e-03, 1.6864e-03, 6.6572e-04, 1.0101e-03, 9.0333e-03,
        1.2271e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,297][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0269, 0.1310, 0.0715, 0.1481, 0.0391, 0.0591, 0.0150, 0.0681, 0.1524,
        0.0653, 0.0395, 0.0392, 0.1448], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,299][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0461, 0.0915, 0.0383, 0.0410, 0.0373, 0.0631, 0.0102, 0.0701, 0.0897,
        0.0161, 0.0659, 0.1477, 0.2220, 0.0610], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,300][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.0198e-04, 1.4379e-01, 1.3616e-02, 8.7365e-02, 8.5571e-03, 2.5121e-02,
        2.5335e-02, 6.2710e-02, 9.0587e-02, 1.9662e-02, 4.5189e-02, 3.6596e-01,
        6.6374e-02, 4.5638e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,301][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0218, 0.0260, 0.0223, 0.0880, 0.0930, 0.0664, 0.0268, 0.1041, 0.1094,
        0.0456, 0.0400, 0.1389, 0.1082, 0.1095], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,303][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0837, 0.0692, 0.0695, 0.1115, 0.0499, 0.1016, 0.0343, 0.1020, 0.1127,
        0.0350, 0.0671, 0.0429, 0.0601, 0.0605], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,304][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0914, 0.0084, 0.0642, 0.0062, 0.0371, 0.0440, 0.0110, 0.1137, 0.0810,
        0.0472, 0.0824, 0.0174, 0.0742, 0.3217], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,304][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([7.8540e-01, 2.9539e-05, 1.3750e-03, 3.0369e-05, 4.8515e-04, 6.8695e-04,
        3.0235e-07, 6.1929e-05, 3.0704e-03, 6.6849e-06, 1.8501e-03, 1.1857e-05,
        1.1588e-02, 1.9540e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,305][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0160, 0.0929, 0.0496, 0.0986, 0.0702, 0.0628, 0.0273, 0.0448, 0.0654,
        0.0242, 0.0975, 0.1506, 0.1142, 0.0858], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,305][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.2283, 0.1025, 0.0445, 0.2649, 0.0149, 0.0296, 0.0085, 0.0175, 0.0342,
        0.0146, 0.0394, 0.0935, 0.0335, 0.0742], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,306][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0941, 0.1455, 0.1092, 0.2058, 0.0628, 0.0686, 0.0154, 0.0491, 0.0671,
        0.0125, 0.0392, 0.0483, 0.0365, 0.0458], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,306][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.6464e-01, 7.8672e-05, 2.7571e-03, 7.9954e-05, 2.5081e-04, 1.2993e-03,
        4.4194e-07, 1.0065e-04, 8.8737e-03, 1.1344e-05, 5.5545e-03, 1.8935e-05,
        2.7580e-02, 7.8875e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,307][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([3.1965e-02, 7.0445e-01, 4.3002e-04, 2.3100e-01, 1.5071e-02, 1.9214e-03,
        1.5817e-04, 3.6185e-04, 5.2528e-04, 1.9111e-04, 2.2552e-04, 4.0508e-03,
        9.0116e-03, 6.4348e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,308][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0366, 0.0933, 0.0649, 0.1394, 0.0322, 0.0520, 0.0115, 0.0579, 0.1386,
        0.0228, 0.0366, 0.0142, 0.1947, 0.1053], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,309][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0045, 0.0572, 0.0312, 0.0296, 0.0171, 0.0410, 0.0077, 0.0327, 0.0594,
        0.0087, 0.0444, 0.1176, 0.0611, 0.0443, 0.4435], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,310][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([1.3317e-04, 2.3141e-01, 1.8699e-02, 1.2166e-01, 9.1227e-03, 3.2096e-02,
        1.4404e-02, 4.6367e-02, 9.6315e-02, 1.5932e-02, 6.4146e-02, 1.7842e-01,
        2.9235e-02, 3.9110e-02, 1.0294e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,312][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0050, 0.0258, 0.0150, 0.0632, 0.0409, 0.0380, 0.0186, 0.0630, 0.0665,
        0.0266, 0.0378, 0.0878, 0.0746, 0.0567, 0.3805], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,313][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0332, 0.0832, 0.0608, 0.0983, 0.0180, 0.0959, 0.0307, 0.0673, 0.0905,
        0.0179, 0.0620, 0.0471, 0.0173, 0.0490, 0.2289], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,315][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0805, 0.0102, 0.0785, 0.0090, 0.0537, 0.0431, 0.0120, 0.0934, 0.0546,
        0.0418, 0.0518, 0.0203, 0.0215, 0.2582, 0.1715], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,316][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([3.7184e-01, 1.0746e-05, 1.3947e-03, 6.7913e-06, 2.6350e-04, 4.3827e-04,
        6.2366e-08, 2.4430e-05, 2.8000e-03, 3.8378e-06, 1.5171e-03, 4.5195e-06,
        2.5794e-02, 5.1654e-01, 7.9359e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,317][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0091, 0.1862, 0.0592, 0.0807, 0.0400, 0.0561, 0.0226, 0.0262, 0.0477,
        0.0151, 0.1113, 0.1058, 0.0523, 0.0836, 0.1042], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,319][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.1536, 0.1480, 0.0354, 0.3593, 0.0113, 0.0217, 0.0094, 0.0121, 0.0262,
        0.0125, 0.0171, 0.0613, 0.0197, 0.0475, 0.0653], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,320][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0679, 0.1540, 0.0989, 0.2567, 0.0589, 0.0591, 0.0133, 0.0415, 0.0670,
        0.0199, 0.0436, 0.0419, 0.0246, 0.0309, 0.0216], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,321][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([3.5959e-03, 6.6547e-06, 6.0052e-04, 5.6837e-06, 4.8239e-05, 1.7813e-04,
        2.9472e-08, 1.7263e-05, 3.6810e-03, 1.1696e-06, 1.9957e-03, 2.0376e-06,
        2.6800e-02, 7.9917e-01, 1.6389e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,322][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([2.6378e-02, 7.2910e-01, 6.8666e-04, 2.0826e-01, 1.1523e-02, 2.1158e-03,
        2.8646e-04, 5.5867e-04, 1.0036e-03, 2.5142e-04, 3.6812e-04, 4.9660e-03,
        8.5511e-03, 9.3145e-04, 5.0250e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,324][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0192, 0.0926, 0.0591, 0.1343, 0.0355, 0.0448, 0.0060, 0.0605, 0.0817,
        0.0170, 0.0315, 0.0123, 0.0791, 0.1166, 0.2097], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,325][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([0.0116, 0.0295, 0.0232, 0.0157, 0.0167, 0.0379, 0.0069, 0.0286, 0.0801,
        0.0088, 0.0431, 0.0566, 0.0975, 0.0329, 0.2399, 0.2712],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,326][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([4.7451e-05, 4.9820e-02, 1.6107e-02, 2.7713e-02, 8.3067e-03, 2.7163e-02,
        2.2947e-02, 8.4007e-02, 1.0480e-01, 1.7466e-02, 3.6475e-02, 1.1643e-01,
        4.0113e-02, 5.9968e-02, 1.3473e-01, 2.5391e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,328][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.0055, 0.0080, 0.0313, 0.0366, 0.0452, 0.0304, 0.0256, 0.0678, 0.0710,
        0.0256, 0.0470, 0.0306, 0.1455, 0.0819, 0.2296, 0.1184],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,329][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([0.0331, 0.0163, 0.0662, 0.0548, 0.0232, 0.0686, 0.0305, 0.0741, 0.0887,
        0.0327, 0.0587, 0.0114, 0.0345, 0.0591, 0.2031, 0.1450],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,331][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.0921, 0.0094, 0.0645, 0.0083, 0.0373, 0.0463, 0.0078, 0.0536, 0.0676,
        0.0633, 0.0556, 0.0182, 0.0295, 0.2080, 0.1827, 0.0558],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,332][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([1.0775e-02, 1.1023e-05, 9.8226e-04, 1.2009e-05, 2.7975e-04, 4.9310e-04,
        1.7766e-07, 6.5985e-05, 6.3118e-03, 6.5193e-06, 2.6485e-03, 7.1839e-06,
        2.9811e-02, 6.0010e-01, 3.0233e-01, 4.6169e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,333][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([0.0026, 0.0471, 0.0387, 0.0505, 0.0363, 0.0511, 0.0266, 0.0323, 0.0731,
        0.0185, 0.0746, 0.0865, 0.0713, 0.0575, 0.0656, 0.2676],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,335][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.1425, 0.0661, 0.0339, 0.2053, 0.0113, 0.0373, 0.0147, 0.0180, 0.0441,
        0.0116, 0.0357, 0.0551, 0.0434, 0.0608, 0.0273, 0.1928],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,335][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.0578, 0.0842, 0.0981, 0.1433, 0.0694, 0.0601, 0.0232, 0.0577, 0.0898,
        0.0215, 0.0485, 0.0260, 0.0863, 0.0753, 0.0286, 0.0300],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,336][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([1.4830e-03, 1.9709e-06, 3.4550e-04, 3.5602e-06, 5.8224e-05, 2.5071e-04,
        3.1843e-08, 3.0274e-05, 6.7906e-03, 2.2775e-06, 2.5332e-03, 9.8153e-07,
        1.2020e-02, 5.6083e-01, 1.9142e-01, 2.2423e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,336][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.0212, 0.5059, 0.0020, 0.2514, 0.0390, 0.0072, 0.0010, 0.0021, 0.0039,
        0.0012, 0.0009, 0.0056, 0.0347, 0.0043, 0.0164, 0.1031],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,337][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([0.0016, 0.0271, 0.0121, 0.0249, 0.0391, 0.0321, 0.0071, 0.0719, 0.2061,
        0.0182, 0.0125, 0.0065, 0.1472, 0.0484, 0.1500, 0.1953],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,337][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0135, 0.0520, 0.0173, 0.0214, 0.0167, 0.0268, 0.0049, 0.0380, 0.0472,
        0.0068, 0.0323, 0.0878, 0.0989, 0.0250, 0.3067, 0.1846, 0.0201],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,338][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.6697e-05, 1.0368e-01, 9.0854e-03, 5.2652e-02, 4.7658e-03, 1.7513e-02,
        1.6603e-02, 3.7921e-02, 6.6395e-02, 1.2363e-02, 2.6531e-02, 2.5700e-01,
        5.0277e-02, 2.8440e-02, 9.4740e-02, 1.9462e-01, 2.7368e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,338][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0080, 0.0165, 0.0115, 0.0496, 0.0461, 0.0330, 0.0149, 0.0556, 0.0623,
        0.0218, 0.0205, 0.0867, 0.0613, 0.0499, 0.3020, 0.1058, 0.0544],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,340][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0341, 0.0690, 0.0454, 0.0765, 0.0303, 0.0707, 0.0199, 0.0788, 0.0846,
        0.0175, 0.0399, 0.0410, 0.0375, 0.0381, 0.2004, 0.0881, 0.0284],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,341][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0606, 0.0090, 0.0480, 0.0049, 0.0286, 0.0304, 0.0079, 0.0766, 0.0574,
        0.0372, 0.0476, 0.0151, 0.0389, 0.1835, 0.2003, 0.0438, 0.1101],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,342][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([4.4871e-01, 3.8229e-05, 1.5231e-03, 3.6649e-05, 7.6128e-04, 6.4055e-04,
        3.8159e-07, 6.3116e-05, 3.7100e-03, 8.1609e-06, 2.1572e-03, 1.6328e-05,
        2.1778e-02, 2.3978e-01, 7.8717e-02, 1.3237e-01, 6.9687e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,344][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0054, 0.0771, 0.0375, 0.0706, 0.0438, 0.0467, 0.0145, 0.0298, 0.0524,
        0.0140, 0.0676, 0.1203, 0.0776, 0.0620, 0.0902, 0.1530, 0.0376],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,345][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1387, 0.1179, 0.0317, 0.3153, 0.0106, 0.0244, 0.0095, 0.0156, 0.0296,
        0.0116, 0.0247, 0.0693, 0.0316, 0.0401, 0.0278, 0.0522, 0.0494],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,346][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0823, 0.1559, 0.0974, 0.1786, 0.0622, 0.0596, 0.0135, 0.0393, 0.0558,
        0.0102, 0.0323, 0.0565, 0.0377, 0.0412, 0.0174, 0.0230, 0.0371],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,347][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.4210e-02, 2.7452e-05, 8.9621e-04, 3.3245e-05, 1.1688e-04, 4.1892e-04,
        1.9046e-07, 4.1968e-05, 4.2247e-03, 5.1653e-06, 2.5041e-03, 9.4029e-06,
        1.8918e-02, 3.9629e-01, 7.5685e-02, 3.8028e-01, 1.0634e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,348][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([2.1799e-02, 7.3167e-01, 6.1506e-04, 1.9210e-01, 1.4091e-02, 2.0962e-03,
        1.8994e-04, 4.6755e-04, 7.1766e-04, 2.3699e-04, 3.0491e-04, 5.4617e-03,
        1.0087e-02, 8.1425e-04, 2.7030e-03, 1.5942e-02, 7.0245e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,350][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0086, 0.0686, 0.0367, 0.0779, 0.0174, 0.0359, 0.0091, 0.0488, 0.1139,
        0.0148, 0.0232, 0.0124, 0.1210, 0.0713, 0.1029, 0.1646, 0.0727],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,351][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:39,353][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[4418],
        [ 718],
        [ 471],
        [1179],
        [ 154],
        [ 118],
        [ 312],
        [  84],
        [  54],
        [  39],
        [ 100],
        [  44],
        [  40],
        [  15],
        [  16],
        [   7],
        [   2]], device='cuda:0')
[2024-07-24 10:29:39,355][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[3731],
        [1556],
        [1142],
        [3392],
        [ 447],
        [ 432],
        [ 731],
        [ 275],
        [ 213],
        [ 143],
        [ 412],
        [ 185],
        [ 154],
        [  98],
        [  58],
        [  45],
        [  49]], device='cuda:0')
[2024-07-24 10:29:39,356][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[20938],
        [18010],
        [ 9359],
        [16429],
        [10210],
        [11787],
        [13009],
        [14621],
        [15807],
        [15157],
        [15843],
        [14212],
        [12655],
        [12114],
        [11588],
        [11532],
        [11649]], device='cuda:0')
[2024-07-24 10:29:39,358][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[17568],
        [39440],
        [37996],
        [44091],
        [43499],
        [41196],
        [42056],
        [39457],
        [38434],
        [36594],
        [35139],
        [36567],
        [31738],
        [32665],
        [32125],
        [26372],
        [29053]], device='cuda:0')
[2024-07-24 10:29:39,359][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[20540],
        [12650],
        [21489],
        [    7],
        [   53],
        [   43],
        [  943],
        [ 1016],
        [ 1572],
        [ 1355],
        [  845],
        [  422],
        [  603],
        [  703],
        [  686],
        [  823],
        [  798]], device='cuda:0')
[2024-07-24 10:29:39,361][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[22570],
        [15631],
        [27191],
        [29187],
        [23937],
        [18909],
        [16565],
        [17170],
        [17290],
        [14092],
        [16161],
        [15207],
        [14612],
        [15237],
        [18705],
        [21895],
        [19076]], device='cuda:0')
[2024-07-24 10:29:39,362][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[38661],
        [39413],
        [42207],
        [41822],
        [41414],
        [37868],
        [35215],
        [34114],
        [31752],
        [31704],
        [33586],
        [35591],
        [36956],
        [40558],
        [41612],
        [41580],
        [41946]], device='cuda:0')
[2024-07-24 10:29:39,364][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[24781],
        [24127],
        [33907],
        [34461],
        [32137],
        [31105],
        [34592],
        [31728],
        [28028],
        [38792],
        [36966],
        [38333],
        [39563],
        [41696],
        [43757],
        [44278],
        [42247]], device='cuda:0')
[2024-07-24 10:29:39,365][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[7005],
        [2706],
        [1730],
        [3548],
        [2646],
        [2466],
        [2503],
        [3155],
        [3122],
        [2528],
        [2315],
        [1696],
        [1863],
        [2160],
        [2133],
        [2492],
        [2676]], device='cuda:0')
[2024-07-24 10:29:39,367][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[19670],
        [  256],
        [ 3013],
        [24294],
        [ 6013],
        [ 3702],
        [ 8169],
        [ 6455],
        [ 5917],
        [ 9987],
        [ 7387],
        [ 3627],
        [17552],
        [ 9235],
        [ 9643],
        [10551],
        [ 8774]], device='cuda:0')
[2024-07-24 10:29:39,368][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[21191],
        [29874],
        [31123],
        [19939],
        [18470],
        [15175],
        [16664],
        [15222],
        [11836],
        [15598],
        [13059],
        [10990],
        [12912],
        [12757],
        [12672],
        [11003],
        [13682]], device='cuda:0')
[2024-07-24 10:29:39,369][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[24305],
        [23337],
        [47868],
        [48044],
        [48131],
        [47548],
        [48605],
        [47990],
        [42981],
        [42775],
        [44831],
        [43469],
        [42722],
        [39673],
        [41102],
        [43581],
        [44696]], device='cuda:0')
[2024-07-24 10:29:39,370][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[29316],
        [39519],
        [ 4134],
        [ 4095],
        [ 4267],
        [ 4981],
        [ 6407],
        [ 5280],
        [ 5634],
        [ 7074],
        [ 7332],
        [ 6353],
        [ 6701],
        [ 7375],
        [ 7124],
        [ 6878],
        [ 7857]], device='cuda:0')
[2024-07-24 10:29:39,371][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[25450],
        [ 4366],
        [ 4584],
        [14080],
        [23228],
        [16742],
        [13877],
        [14696],
        [16188],
        [18729],
        [13338],
        [11775],
        [13152],
        [14501],
        [15555],
        [17617],
        [16715]], device='cuda:0')
[2024-07-24 10:29:39,373][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[15298],
        [ 9255],
        [10036],
        [ 1953],
        [ 7159],
        [ 7532],
        [ 6884],
        [ 6099],
        [ 7017],
        [ 8465],
        [ 6126],
        [ 7162],
        [ 6200],
        [ 8726],
        [10761],
        [ 6129],
        [ 7562]], device='cuda:0')
[2024-07-24 10:29:39,374][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[12488],
        [ 9493],
        [ 9813],
        [ 9678],
        [13344],
        [11762],
        [12496],
        [10424],
        [12645],
        [12302],
        [12329],
        [12599],
        [ 9424],
        [ 9049],
        [ 8800],
        [11752],
        [10303]], device='cuda:0')
[2024-07-24 10:29:39,376][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[48078],
        [22081],
        [24049],
        [36025],
        [38968],
        [37587],
        [33831],
        [30880],
        [29615],
        [26922],
        [27270],
        [21542],
        [21679],
        [18883],
        [23197],
        [16612],
        [17614]], device='cuda:0')
[2024-07-24 10:29:39,377][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[33356],
        [21386],
        [11069],
        [ 8772],
        [ 8750],
        [ 9883],
        [ 9258],
        [10565],
        [17054],
        [22120],
        [20174],
        [16372],
        [20274],
        [21010],
        [17561],
        [27548],
        [20006]], device='cuda:0')
[2024-07-24 10:29:39,379][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[26009],
        [28849],
        [16190],
        [12739],
        [16883],
        [19208],
        [20143],
        [22836],
        [24114],
        [26950],
        [26169],
        [26485],
        [26695],
        [26082],
        [35824],
        [37239],
        [36312]], device='cuda:0')
[2024-07-24 10:29:39,380][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[23798],
        [27503],
        [19320],
        [16753],
        [12141],
        [17634],
        [19850],
        [22103],
        [24561],
        [23688],
        [21737],
        [19253],
        [22315],
        [19966],
        [18692],
        [17837],
        [18717]], device='cuda:0')
[2024-07-24 10:29:39,382][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[22808],
        [23673],
        [20067],
        [13440],
        [21528],
        [24176],
        [14518],
        [24245],
        [24343],
        [24452],
        [26176],
        [23392],
        [24790],
        [22931],
        [18856],
        [17863],
        [20070]], device='cuda:0')
[2024-07-24 10:29:39,383][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[10805],
        [22834],
        [20751],
        [19223],
        [16857],
        [16785],
        [15624],
        [18061],
        [18153],
        [20515],
        [21018],
        [19797],
        [19648],
        [18927],
        [19779],
        [21135],
        [19734]], device='cuda:0')
[2024-07-24 10:29:39,385][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[16223],
        [15869],
        [15909],
        [13129],
        [13535],
        [12514],
        [12879],
        [13250],
        [12646],
        [13346],
        [12801],
        [11277],
        [11321],
        [10704],
        [12312],
        [ 9202],
        [10768]], device='cuda:0')
[2024-07-24 10:29:39,386][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[12275],
        [12236],
        [18411],
        [18379],
        [19628],
        [20524],
        [20103],
        [21230],
        [21749],
        [22561],
        [23989],
        [24124],
        [24873],
        [25514],
        [24947],
        [28156],
        [26410]], device='cuda:0')
[2024-07-24 10:29:39,388][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[16070],
        [16597],
        [23945],
        [25009],
        [23660],
        [23118],
        [28657],
        [25616],
        [21585],
        [25511],
        [22138],
        [23896],
        [23526],
        [20861],
        [21873],
        [23331],
        [25215]], device='cuda:0')
[2024-07-24 10:29:39,389][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[36860],
        [23517],
        [23376],
        [25015],
        [25759],
        [25632],
        [25363],
        [25514],
        [24959],
        [24212],
        [24652],
        [24856],
        [24830],
        [24765],
        [24635],
        [24999],
        [24439]], device='cuda:0')
[2024-07-24 10:29:39,391][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[19766],
        [35043],
        [39886],
        [45564],
        [45573],
        [46990],
        [46805],
        [46565],
        [47355],
        [46315],
        [46852],
        [45728],
        [47577],
        [47448],
        [46662],
        [41902],
        [44417]], device='cuda:0')
[2024-07-24 10:29:39,392][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[14400],
        [19118],
        [24594],
        [22547],
        [18878],
        [16154],
        [18808],
        [15613],
        [13488],
        [12836],
        [12666],
        [16333],
        [14858],
        [16282],
        [15359],
        [14845],
        [15140]], device='cuda:0')
[2024-07-24 10:29:39,394][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[33366],
        [38587],
        [35275],
        [47901],
        [37741],
        [40583],
        [41069],
        [43044],
        [41716],
        [37654],
        [41483],
        [40776],
        [40160],
        [37595],
        [34623],
        [42118],
        [40357]], device='cuda:0')
[2024-07-24 10:29:39,395][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597]], device='cuda:0')
[2024-07-24 10:29:39,450][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:39,451][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,452][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,454][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,455][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,456][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,457][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,457][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,459][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,460][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,461][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,462][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,464][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,465][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Sara] are: tensor([0.9718, 0.0282], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,467][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Sara] are: tensor([0.9968, 0.0032], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,468][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Sara] are: tensor([0.9737, 0.0263], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,470][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Sara] are: tensor([0.9965, 0.0035], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,472][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Sara] are: tensor([0.1682, 0.8318], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,473][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Sara] are: tensor([0.9650, 0.0350], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,475][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Sara] are: tensor([0.9724, 0.0276], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,476][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Sara] are: tensor([0.9909, 0.0091], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,478][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Sara] are: tensor([0.3843, 0.6157], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,478][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Sara] are: tensor([0.9976, 0.0024], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,479][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Sara] are: tensor([9.9997e-01, 3.0360e-05], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,480][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Sara] are: tensor([0.9933, 0.0067], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,480][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.8963, 0.0486, 0.0551], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,482][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.9905, 0.0037, 0.0057], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,483][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.8037, 0.1283, 0.0681], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,484][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([9.4962e-01, 6.9220e-04, 4.9690e-02], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,486][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1013, 0.5062, 0.3925], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,487][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.6327, 0.2411, 0.1262], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,488][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.9338, 0.0541, 0.0120], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,490][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.8725, 0.0473, 0.0802], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,492][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2373, 0.0029, 0.7597], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,493][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.9650, 0.0087, 0.0263], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,494][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([9.7488e-01, 3.7514e-05, 2.5081e-02], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,496][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([9.9889e-01, 5.1564e-04, 5.9351e-04], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,497][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Kenneth] are: tensor([0.8240, 0.0250, 0.0685, 0.0825], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,498][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Kenneth] are: tensor([9.9469e-01, 6.2035e-04, 1.3940e-03, 3.2996e-03], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,500][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Kenneth] are: tensor([0.8438, 0.0538, 0.0548, 0.0476], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,502][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Kenneth] are: tensor([0.5590, 0.0036, 0.4215, 0.0158], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,503][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Kenneth] are: tensor([0.0526, 0.4636, 0.2456, 0.2382], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,505][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Kenneth] are: tensor([0.7926, 0.0674, 0.0726, 0.0674], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,506][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Kenneth] are: tensor([0.9692, 0.0242, 0.0044, 0.0022], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,508][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Kenneth] are: tensor([0.9359, 0.0111, 0.0253, 0.0277], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,509][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Kenneth] are: tensor([9.8013e-04, 2.8271e-03, 9.9291e-01, 3.2836e-03], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,510][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Kenneth] are: tensor([0.9690, 0.0031, 0.0125, 0.0154], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,510][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Kenneth] are: tensor([9.8419e-01, 4.5742e-06, 1.5202e-02, 6.0541e-04], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,511][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Kenneth] are: tensor([0.9923, 0.0041, 0.0020, 0.0016], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,513][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.9358, 0.0048, 0.0115, 0.0194, 0.0286], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,514][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.9336, 0.0087, 0.0193, 0.0342, 0.0042], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,516][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.5162, 0.1323, 0.1501, 0.1682, 0.0331], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,517][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ got] are: tensor([8.5421e-01, 8.1347e-04, 1.2415e-01, 1.7251e-02, 3.5799e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,518][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.0106, 0.2620, 0.2905, 0.3399, 0.0970], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,519][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.4835, 0.1683, 0.0939, 0.2273, 0.0269], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,521][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.8971, 0.0374, 0.0189, 0.0180, 0.0287], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,523][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.5766, 0.0644, 0.1055, 0.1282, 0.1252], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,525][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.0818, 0.0056, 0.8313, 0.0451, 0.0362], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,526][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.9746, 0.0018, 0.0086, 0.0113, 0.0037], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,527][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ got] are: tensor([9.7411e-01, 2.9533e-05, 2.3028e-02, 1.2992e-03, 1.5304e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,529][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.9884, 0.0021, 0.0021, 0.0033, 0.0041], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,530][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.7465, 0.0170, 0.0866, 0.0408, 0.0806, 0.0285], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,532][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([9.7764e-01, 7.0976e-03, 3.9345e-03, 9.2419e-03, 1.6537e-03, 4.3381e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,533][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.6261, 0.1606, 0.0740, 0.1049, 0.0158, 0.0187], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,534][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([8.2626e-01, 5.8804e-04, 1.3928e-01, 7.1420e-03, 2.5704e-03, 2.4163e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,536][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0205, 0.3229, 0.2179, 0.2428, 0.0461, 0.1498], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,538][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.6980, 0.0721, 0.0450, 0.1238, 0.0497, 0.0114], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,539][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.9256, 0.0467, 0.0072, 0.0058, 0.0105, 0.0042], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,540][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.6333, 0.0903, 0.0819, 0.0860, 0.0998, 0.0089], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,541][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([9.2435e-01, 2.2922e-04, 5.9993e-02, 9.9907e-03, 9.4811e-04, 4.4923e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,542][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([9.6288e-01, 3.9531e-03, 8.7713e-03, 1.4626e-02, 9.0323e-03, 7.4034e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,542][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([9.7675e-01, 8.1801e-06, 1.9887e-02, 6.3973e-04, 6.2467e-04, 2.0916e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,543][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([9.9503e-01, 1.0024e-03, 1.8598e-03, 6.5160e-04, 8.8578e-04, 5.6550e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,545][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.2099, 0.0189, 0.1962, 0.1290, 0.3526, 0.0603, 0.0332],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,546][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([8.6888e-01, 3.5078e-02, 2.9901e-02, 4.0199e-02, 2.0243e-02, 5.4626e-03,
        2.3981e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,547][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.2048, 0.2166, 0.2975, 0.1637, 0.0646, 0.0510, 0.0019],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,549][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0153, 0.0007, 0.5717, 0.0112, 0.0247, 0.3735, 0.0028],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,551][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.0268, 0.2494, 0.1311, 0.2799, 0.0858, 0.1952, 0.0317],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,552][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.4814, 0.1200, 0.0768, 0.1560, 0.1374, 0.0248, 0.0036],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,553][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([8.6608e-01, 5.2649e-02, 2.1402e-02, 1.1729e-02, 3.6065e-02, 1.2042e-02,
        3.8069e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,555][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.3829, 0.1112, 0.1550, 0.1385, 0.1878, 0.0205, 0.0042],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,556][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([8.6357e-01, 4.9630e-04, 1.0519e-01, 1.5046e-02, 3.3141e-03, 6.8098e-03,
        5.5810e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,557][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([8.9008e-01, 9.6946e-03, 1.8960e-02, 3.3969e-02, 4.5972e-02, 1.2910e-03,
        3.2754e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,559][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([7.9051e-01, 1.9976e-04, 1.7001e-01, 1.0152e-02, 4.4259e-03, 2.2038e-02,
        2.6647e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,560][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.9201, 0.0114, 0.0281, 0.0104, 0.0153, 0.0136, 0.0011],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,562][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.6664, 0.0202, 0.0705, 0.0730, 0.1093, 0.0272, 0.0077, 0.0258],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,563][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ at] are: tensor([9.7869e-01, 6.3733e-03, 5.5750e-03, 7.1816e-03, 1.0416e-03, 2.7085e-04,
        1.4425e-05, 8.5109e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,565][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.6811, 0.0495, 0.0757, 0.0982, 0.0175, 0.0145, 0.0017, 0.0618],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,566][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ at] are: tensor([7.9971e-01, 4.3363e-04, 1.6497e-01, 6.8835e-03, 2.4118e-03, 2.1241e-02,
        1.8355e-04, 4.1674e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,567][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0316, 0.2565, 0.1262, 0.2509, 0.0194, 0.1072, 0.0158, 0.1925],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,569][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ at] are: tensor([7.7916e-01, 1.0305e-01, 2.7075e-02, 5.8096e-02, 1.7278e-02, 3.7956e-03,
        4.0700e-04, 1.1131e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,570][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ at] are: tensor([9.2255e-01, 5.6913e-02, 6.3670e-03, 5.0662e-03, 4.1091e-03, 2.9180e-03,
        1.8971e-05, 2.0560e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,571][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ at] are: tensor([7.4819e-01, 2.4596e-02, 7.5617e-02, 8.4408e-02, 5.9223e-02, 3.2904e-03,
        4.7773e-04, 4.1995e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,571][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0161, 0.0004, 0.3338, 0.0061, 0.0128, 0.3641, 0.0298, 0.2369],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,572][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ at] are: tensor([9.5547e-01, 7.1896e-03, 5.6912e-03, 2.7424e-02, 3.3147e-03, 2.0275e-04,
        3.2286e-05, 6.7533e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,573][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ at] are: tensor([9.8742e-01, 3.1392e-06, 1.0754e-02, 8.5812e-04, 2.2279e-04, 4.4785e-04,
        3.3190e-05, 2.5829e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,574][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ at] are: tensor([9.9886e-01, 2.2419e-04, 4.9993e-04, 1.9797e-04, 1.3897e-04, 6.1813e-05,
        2.4080e-06, 1.1352e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,576][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.6358, 0.0058, 0.0988, 0.0431, 0.0987, 0.0245, 0.0061, 0.0162, 0.0709],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,577][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ the] are: tensor([9.1967e-01, 3.2825e-02, 1.6775e-02, 2.0688e-02, 5.9711e-03, 6.8395e-04,
        7.7285e-05, 1.8296e-03, 1.4791e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,579][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.3933, 0.1706, 0.1228, 0.1472, 0.0147, 0.0184, 0.0019, 0.0494, 0.0817],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,580][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ the] are: tensor([8.4798e-01, 1.4060e-04, 8.0518e-02, 4.5311e-03, 1.9825e-03, 1.7470e-02,
        4.7139e-04, 1.7830e-03, 4.5122e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,581][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0121, 0.2393, 0.1592, 0.1728, 0.0302, 0.0831, 0.0265, 0.0956, 0.1813],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,583][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.5350, 0.1699, 0.0515, 0.1540, 0.0371, 0.0086, 0.0011, 0.0295, 0.0134],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,584][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ the] are: tensor([8.6319e-01, 9.5454e-02, 9.5320e-03, 7.5318e-03, 1.0884e-02, 4.0894e-03,
        2.1015e-05, 2.1361e-03, 7.1622e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,586][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.4644, 0.1358, 0.1137, 0.1494, 0.1085, 0.0059, 0.0020, 0.0046, 0.0156],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,587][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ the] are: tensor([9.3341e-01, 4.8171e-05, 2.2293e-02, 3.2294e-03, 4.3540e-04, 4.7266e-03,
        1.6091e-03, 8.6513e-03, 2.5596e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,588][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ the] are: tensor([9.7187e-01, 2.9457e-03, 7.6234e-03, 1.0810e-02, 5.4126e-03, 3.8256e-04,
        2.4795e-05, 6.8052e-04, 2.4920e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,589][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ the] are: tensor([9.8029e-01, 2.3049e-06, 1.6521e-02, 7.6257e-04, 4.0648e-04, 1.1768e-03,
        7.9627e-05, 1.3551e-04, 6.2254e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,590][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ the] are: tensor([9.9672e-01, 3.0963e-04, 1.4078e-03, 2.4967e-04, 6.2853e-04, 2.5408e-04,
        1.2752e-05, 1.6795e-05, 4.0554e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,592][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ garden] are: tensor([0.5167, 0.0058, 0.0830, 0.1342, 0.1324, 0.0161, 0.0087, 0.0267, 0.0573,
        0.0189], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,593][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ garden] are: tensor([8.6245e-01, 3.0602e-02, 3.4564e-02, 4.0011e-02, 1.1009e-02, 4.0020e-03,
        1.3192e-04, 6.6846e-03, 9.3455e-03, 1.2013e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,595][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ garden] are: tensor([0.0539, 0.2382, 0.1403, 0.1129, 0.0123, 0.0369, 0.0024, 0.1039, 0.2934,
        0.0059], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,596][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ garden] are: tensor([5.4797e-02, 5.6302e-04, 1.8770e-01, 5.0853e-03, 9.7777e-03, 9.8655e-02,
        1.1732e-03, 2.1665e-02, 5.6615e-01, 5.4437e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,598][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ garden] are: tensor([0.0171, 0.2677, 0.0720, 0.0853, 0.0729, 0.1229, 0.0095, 0.0623, 0.2066,
        0.0838], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,599][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ garden] are: tensor([0.4282, 0.0672, 0.0764, 0.1691, 0.0976, 0.0265, 0.0034, 0.0926, 0.0292,
        0.0098], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,601][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ garden] are: tensor([4.6955e-01, 3.5902e-01, 2.8679e-02, 1.4490e-02, 3.9349e-02, 1.8618e-02,
        4.1855e-05, 1.7163e-02, 5.2481e-02, 6.0502e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,602][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ garden] are: tensor([0.3837, 0.0328, 0.1196, 0.0753, 0.2552, 0.0173, 0.0040, 0.0169, 0.0648,
        0.0304], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,604][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ garden] are: tensor([2.6555e-01, 3.0293e-04, 9.9805e-02, 8.8152e-03, 3.6961e-03, 2.9389e-02,
        8.0571e-03, 2.6804e-02, 3.6439e-01, 1.9319e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,605][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ garden] are: tensor([8.0540e-01, 2.2856e-02, 5.0213e-02, 4.9577e-02, 3.8595e-02, 4.7396e-03,
        6.3932e-05, 1.7623e-02, 1.0198e-02, 7.3522e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,606][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ garden] are: tensor([9.2895e-01, 9.9029e-05, 5.3082e-02, 7.8158e-03, 2.0986e-03, 3.1917e-03,
        5.0065e-04, 9.4429e-04, 2.3863e-03, 9.3089e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,607][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ garden] are: tensor([9.8627e-01, 1.0591e-03, 3.0602e-03, 1.4695e-03, 2.3130e-03, 1.3854e-03,
        3.2642e-05, 1.8748e-04, 4.1011e-03, 1.1895e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,607][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.6442, 0.0101, 0.0767, 0.0584, 0.0722, 0.0258, 0.0051, 0.0180, 0.0543,
        0.0080, 0.0272], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,608][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([9.6323e-01, 1.2067e-02, 6.4871e-03, 1.0573e-02, 2.8811e-03, 6.2261e-04,
        6.2544e-05, 1.7782e-03, 1.1380e-03, 2.5758e-04, 9.0716e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,609][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4432, 0.1898, 0.0901, 0.1032, 0.0134, 0.0176, 0.0018, 0.0612, 0.0508,
        0.0050, 0.0240], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,610][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([6.6247e-01, 3.5942e-04, 1.5603e-01, 8.8425e-03, 2.6626e-03, 4.0516e-02,
        1.1648e-03, 6.2478e-03, 8.7890e-02, 2.2635e-02, 1.1188e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,612][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0144, 0.1778, 0.0954, 0.1088, 0.0216, 0.0898, 0.0160, 0.1188, 0.1784,
        0.0972, 0.0819], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,614][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.5846, 0.1030, 0.0675, 0.0696, 0.0460, 0.0181, 0.0013, 0.0548, 0.0233,
        0.0057, 0.0260], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,615][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([9.0943e-01, 3.6377e-02, 1.1659e-02, 5.1682e-03, 9.8121e-03, 6.9449e-03,
        2.4130e-05, 4.6147e-03, 1.1942e-02, 2.7543e-04, 3.7496e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,617][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.5220, 0.0650, 0.1742, 0.0834, 0.0715, 0.0095, 0.0023, 0.0098, 0.0305,
        0.0060, 0.0258], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,618][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([2.0271e-01, 8.4725e-05, 4.3554e-02, 1.7487e-03, 1.3979e-03, 2.9862e-02,
        8.2406e-03, 3.9238e-02, 8.3526e-02, 7.9511e-02, 5.1012e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,619][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([9.4555e-01, 5.4078e-03, 1.3469e-02, 1.8821e-02, 1.1850e-02, 7.2913e-04,
        4.1267e-05, 2.4735e-03, 5.5358e-04, 1.4873e-04, 9.5981e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,620][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([9.8268e-01, 3.1376e-06, 1.3927e-02, 1.1983e-03, 3.6342e-04, 6.2547e-04,
        7.2249e-05, 1.0275e-04, 2.4399e-04, 8.7108e-05, 6.9238e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,621][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([9.9128e-01, 5.6239e-04, 3.1951e-03, 9.1911e-04, 1.9943e-03, 6.0056e-04,
        6.1380e-05, 1.5830e-04, 8.5545e-04, 1.8682e-04, 1.8983e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,623][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Sara] are: tensor([0.1937, 0.0186, 0.1634, 0.1149, 0.1108, 0.0437, 0.0377, 0.0576, 0.1010,
        0.0542, 0.0957, 0.0087], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,624][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Sara] are: tensor([9.4518e-01, 8.5817e-03, 6.9515e-03, 2.1280e-02, 1.1285e-02, 1.3809e-03,
        7.5041e-05, 2.1413e-03, 1.7170e-03, 4.6896e-04, 8.5229e-04, 9.0928e-05],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,626][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Sara] are: tensor([0.2232, 0.0612, 0.2021, 0.0622, 0.1006, 0.0546, 0.0035, 0.0958, 0.1203,
        0.0152, 0.0585, 0.0029], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,627][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Sara] are: tensor([4.1017e-03, 7.9600e-05, 1.1939e-01, 8.4592e-03, 1.8181e-02, 1.0931e-01,
        7.7685e-03, 2.8666e-02, 5.5422e-01, 9.3950e-02, 5.5835e-02, 3.7251e-05],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,629][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Sara] are: tensor([0.0099, 0.1401, 0.0517, 0.0774, 0.0522, 0.0800, 0.0072, 0.1135, 0.1883,
        0.1366, 0.0432, 0.0999], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,630][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Sara] are: tensor([7.6118e-01, 4.1751e-02, 3.3570e-02, 5.4579e-02, 6.2818e-02, 7.1037e-03,
        7.5933e-04, 1.9256e-02, 6.0523e-03, 7.2673e-03, 5.1777e-03, 4.7997e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,631][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Sara] are: tensor([7.6638e-01, 7.9156e-02, 2.4245e-02, 5.4251e-03, 6.8597e-02, 1.6695e-02,
        1.1551e-04, 1.3566e-02, 1.9206e-02, 6.4526e-04, 5.8611e-03, 1.1132e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,633][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Sara] are: tensor([0.6069, 0.0780, 0.1018, 0.0600, 0.0945, 0.0079, 0.0011, 0.0159, 0.0113,
        0.0093, 0.0122, 0.0010], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,634][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Sara] are: tensor([7.5901e-02, 1.5203e-04, 5.2589e-02, 4.0155e-03, 3.8052e-03, 3.6083e-02,
        1.5701e-02, 5.4046e-02, 1.1661e-01, 6.4341e-02, 5.6983e-01, 6.9249e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,635][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Sara] are: tensor([9.5646e-01, 3.4351e-03, 7.0391e-03, 1.2458e-02, 1.7743e-02, 5.6056e-04,
        2.6320e-05, 1.5521e-03, 3.5136e-04, 6.5459e-05, 3.0101e-04, 9.0468e-06],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,637][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Sara] are: tensor([6.9614e-01, 3.5488e-05, 1.8057e-01, 1.1608e-02, 7.1576e-03, 1.8166e-02,
        1.0084e-02, 9.2908e-03, 1.0578e-02, 5.8594e-03, 5.0127e-02, 3.8591e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,637][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Sara] are: tensor([0.7634, 0.0112, 0.0600, 0.0143, 0.0382, 0.0205, 0.0033, 0.0091, 0.0513,
        0.0134, 0.0139, 0.0016], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:39,638][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([9.1306e-01, 2.8714e-03, 8.4603e-03, 2.2981e-02, 1.8311e-02, 2.2409e-03,
        4.3768e-04, 2.5240e-03, 2.8890e-03, 6.5017e-04, 3.2518e-03, 8.6786e-04,
        2.1459e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,639][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([9.4515e-01, 6.7040e-03, 1.6160e-02, 1.4965e-02, 4.9401e-03, 1.2058e-03,
        1.1060e-04, 2.3953e-03, 1.2003e-03, 4.4759e-04, 1.1433e-03, 1.7854e-04,
        5.4041e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,640][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.4431, 0.0543, 0.1221, 0.1268, 0.0504, 0.0398, 0.0044, 0.0665, 0.0485,
        0.0080, 0.0182, 0.0030, 0.0148], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,641][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([7.2099e-01, 2.7349e-04, 1.0339e-01, 4.6488e-03, 2.7922e-03, 3.1285e-02,
        8.6578e-04, 8.2655e-03, 8.7928e-02, 1.0126e-02, 1.8865e-02, 4.0706e-05,
        1.0538e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,643][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.0048, 0.1216, 0.0678, 0.0656, 0.0438, 0.0784, 0.0085, 0.2535, 0.1237,
        0.0458, 0.0448, 0.0790, 0.0628], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,644][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.3044, 0.1964, 0.0645, 0.1036, 0.0741, 0.0289, 0.0023, 0.1529, 0.0212,
        0.0070, 0.0144, 0.0046, 0.0256], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,645][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([8.3871e-01, 3.4421e-02, 3.1326e-02, 1.4641e-02, 2.1808e-02, 2.1549e-02,
        8.7037e-05, 7.9034e-03, 1.3193e-02, 7.7787e-04, 4.3599e-03, 3.7951e-04,
        1.0845e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,647][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.2377, 0.0450, 0.2179, 0.1495, 0.1844, 0.0130, 0.0031, 0.0222, 0.0191,
        0.0061, 0.0218, 0.0005, 0.0796], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,648][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([9.6257e-01, 6.0798e-05, 3.7270e-03, 2.9148e-03, 7.8660e-05, 1.0739e-04,
        1.6636e-04, 2.8321e-03, 2.5621e-03, 2.8969e-03, 2.1349e-02, 8.9106e-05,
        6.4886e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,649][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([9.5224e-01, 3.4933e-03, 1.5883e-02, 1.4907e-02, 8.9446e-03, 8.2522e-04,
        5.4662e-05, 1.9490e-03, 2.8220e-04, 2.4034e-04, 5.9996e-04, 5.4272e-05,
        5.2314e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,651][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([9.8450e-01, 1.3383e-05, 1.0943e-02, 5.7517e-04, 4.4323e-04, 1.1921e-03,
        4.6026e-05, 2.6073e-04, 6.8804e-04, 4.5061e-05, 8.6935e-04, 1.8048e-05,
        4.0375e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,652][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([9.9162e-01, 3.7129e-04, 2.6884e-03, 3.6810e-04, 1.7033e-03, 1.0468e-03,
        3.8891e-05, 1.0964e-04, 1.5049e-03, 1.2675e-04, 1.1838e-04, 1.2331e-05,
        2.8662e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:39,654][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.7553, 0.0052, 0.0168, 0.0277, 0.0220, 0.0049, 0.0011, 0.0045, 0.0112,
        0.0039, 0.0097, 0.0027, 0.0468, 0.0879], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,655][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([9.7128e-01, 6.2710e-03, 5.2768e-03, 5.3601e-03, 2.1185e-03, 7.7511e-04,
        2.5293e-05, 6.0799e-04, 9.7907e-04, 1.4077e-04, 6.1061e-04, 1.3170e-04,
        2.4184e-03, 4.0007e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,657][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.4972, 0.0744, 0.0680, 0.0916, 0.0160, 0.0331, 0.0032, 0.0674, 0.0475,
        0.0032, 0.0175, 0.0038, 0.0328, 0.0445], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,658][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([9.4026e-01, 1.5537e-04, 1.4775e-02, 1.0097e-03, 6.2728e-04, 2.9263e-03,
        8.3215e-05, 1.8402e-04, 4.9573e-03, 1.0773e-03, 1.3558e-03, 1.1634e-05,
        1.5205e-03, 3.1052e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,660][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0089, 0.0893, 0.0565, 0.0893, 0.0165, 0.0794, 0.0206, 0.1139, 0.0898,
        0.0485, 0.0455, 0.1976, 0.0294, 0.1149], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,661][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.3238, 0.1706, 0.0683, 0.1240, 0.0574, 0.0323, 0.0043, 0.0994, 0.0257,
        0.0078, 0.0223, 0.0037, 0.0312, 0.0292], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,663][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([8.6649e-01, 3.8570e-02, 1.4643e-02, 1.2063e-02, 1.3730e-02, 1.3956e-02,
        3.5695e-05, 4.5756e-03, 1.3176e-02, 4.7508e-04, 3.5547e-03, 3.6049e-04,
        9.8913e-03, 8.4758e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,664][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([4.9934e-01, 2.6515e-02, 1.4266e-01, 1.1956e-01, 6.3386e-02, 1.1751e-02,
        2.4612e-03, 8.7361e-03, 2.4253e-02, 4.4236e-03, 1.5612e-02, 3.6582e-04,
        4.8536e-02, 3.2401e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,665][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([5.3926e-03, 1.3106e-05, 5.7127e-03, 1.0313e-04, 3.6785e-04, 2.0279e-02,
        2.4365e-03, 3.5415e-03, 4.7203e-02, 1.8091e-02, 1.1439e-01, 5.5999e-03,
        1.6056e-01, 6.1631e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,666][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.2304e-01, 2.4193e-03, 1.3584e-02, 3.5087e-02, 1.9207e-02, 1.3229e-03,
        2.5435e-05, 1.6217e-03, 3.9798e-04, 9.0899e-05, 6.0672e-04, 8.8343e-06,
        9.3208e-04, 1.6597e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,668][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([9.8248e-01, 3.6671e-06, 1.1026e-02, 7.6145e-04, 2.2222e-04, 7.0457e-04,
        3.1366e-05, 1.3019e-04, 2.5289e-04, 3.2519e-05, 5.8843e-04, 1.5607e-05,
        1.6892e-04, 3.5870e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,669][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([9.9564e-01, 2.3334e-04, 1.4128e-03, 4.1286e-04, 8.1029e-04, 1.7178e-04,
        1.2277e-05, 1.8015e-05, 3.5301e-04, 2.9093e-05, 7.0406e-05, 8.3841e-06,
        2.1700e-04, 6.0735e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:39,670][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.4709, 0.0051, 0.0192, 0.0318, 0.0210, 0.0050, 0.0014, 0.0035, 0.0138,
        0.0033, 0.0108, 0.0023, 0.0449, 0.1004, 0.2667], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,671][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ give] are: tensor([8.8886e-01, 4.0116e-02, 1.5373e-02, 1.5208e-02, 1.6275e-02, 2.1352e-03,
        7.6581e-05, 1.2788e-03, 3.0619e-03, 3.9016e-04, 1.3143e-03, 6.3799e-04,
        3.5161e-03, 6.5623e-03, 5.1985e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,672][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0897, 0.1902, 0.1149, 0.2105, 0.0317, 0.0288, 0.0056, 0.0698, 0.0781,
        0.0045, 0.0381, 0.0110, 0.0156, 0.0516, 0.0600], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,673][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ give] are: tensor([4.8252e-01, 1.4438e-04, 8.4145e-02, 3.6961e-03, 1.4846e-03, 6.9985e-03,
        1.2452e-04, 7.2802e-04, 2.1374e-02, 1.2026e-03, 5.2686e-03, 9.1571e-06,
        7.0459e-03, 3.5062e-01, 3.4646e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,675][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0023, 0.1248, 0.0389, 0.0741, 0.0109, 0.0430, 0.0076, 0.0598, 0.1041,
        0.0385, 0.0417, 0.1564, 0.0292, 0.0441, 0.2246], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,676][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.3663, 0.1783, 0.0539, 0.1934, 0.0809, 0.0154, 0.0016, 0.0285, 0.0109,
        0.0043, 0.0093, 0.0020, 0.0135, 0.0184, 0.0232], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,678][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ give] are: tensor([7.6228e-01, 9.1051e-02, 2.7860e-02, 1.2984e-02, 2.7958e-02, 1.9455e-02,
        3.9219e-05, 4.8601e-03, 1.2626e-02, 2.5913e-04, 6.0886e-03, 4.3630e-04,
        1.1346e-02, 1.8120e-02, 4.6386e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,679][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.2853, 0.0403, 0.1607, 0.1086, 0.1088, 0.0093, 0.0046, 0.0136, 0.0301,
        0.0076, 0.0279, 0.0016, 0.0871, 0.0343, 0.0803], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,680][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ give] are: tensor([1.1871e-03, 9.6391e-06, 2.9233e-03, 5.2059e-05, 1.8955e-04, 3.7016e-03,
        1.3520e-03, 2.3659e-03, 1.6994e-02, 8.8664e-03, 6.7586e-02, 1.0346e-03,
        8.4787e-02, 6.4800e-01, 1.6095e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,681][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ give] are: tensor([9.6446e-01, 3.0429e-03, 6.5529e-03, 1.2671e-02, 1.0574e-02, 5.3269e-04,
        7.1480e-06, 3.0375e-04, 1.5476e-04, 4.0576e-05, 2.2373e-04, 9.8186e-06,
        2.7316e-04, 9.7615e-04, 1.7497e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,683][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ give] are: tensor([9.5314e-01, 2.5329e-05, 3.2411e-02, 2.1796e-03, 6.8915e-04, 1.5925e-03,
        6.5011e-05, 1.3941e-04, 8.0646e-04, 9.3245e-05, 1.3462e-03, 2.7259e-05,
        3.6247e-04, 6.7144e-03, 4.1057e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,684][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ give] are: tensor([9.8440e-01, 1.6165e-03, 5.4682e-03, 1.4551e-03, 1.1345e-03, 8.6199e-04,
        4.5521e-05, 4.8753e-05, 1.1370e-03, 1.6994e-04, 2.7642e-04, 5.1355e-05,
        1.6334e-04, 2.7940e-03, 3.7453e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:39,686][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.5781, 0.0019, 0.0173, 0.0195, 0.0200, 0.0032, 0.0009, 0.0031, 0.0095,
        0.0017, 0.0091, 0.0009, 0.0420, 0.0740, 0.1931, 0.0257],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,687][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ it] are: tensor([6.8761e-01, 1.2938e-02, 1.2967e-02, 6.5679e-03, 1.4890e-02, 2.1236e-03,
        3.0691e-04, 4.5964e-03, 3.3366e-03, 7.3420e-04, 1.0572e-03, 3.5841e-04,
        8.2768e-03, 1.0313e-02, 9.3316e-03, 2.2459e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,689][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.0971, 0.0277, 0.0784, 0.0558, 0.0371, 0.0399, 0.0068, 0.0726, 0.1021,
        0.0101, 0.0351, 0.0041, 0.0405, 0.0856, 0.1031, 0.2041],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,690][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ it] are: tensor([3.6523e-01, 7.9462e-05, 2.7962e-02, 4.8779e-04, 1.6186e-03, 1.2054e-02,
        7.8293e-05, 1.2323e-03, 3.4622e-02, 1.2897e-03, 6.5622e-03, 1.0927e-05,
        1.1876e-02, 3.6004e-01, 4.4550e-02, 1.3231e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,692][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.0010, 0.0141, 0.0211, 0.0199, 0.0071, 0.0488, 0.0113, 0.1566, 0.1436,
        0.0476, 0.0290, 0.0413, 0.0525, 0.0889, 0.2821, 0.0352],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,694][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ it] are: tensor([0.1705, 0.0574, 0.0494, 0.0739, 0.1157, 0.0433, 0.0034, 0.0916, 0.0489,
        0.0107, 0.0170, 0.0014, 0.0455, 0.0860, 0.0523, 0.1329],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,695][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ it] are: tensor([5.0130e-01, 3.8921e-02, 3.1040e-02, 1.1603e-02, 4.2411e-02, 5.4813e-02,
        2.4868e-04, 2.3879e-02, 6.5504e-02, 1.8122e-03, 9.6195e-03, 8.3279e-04,
        7.6427e-02, 3.8759e-02, 1.7950e-02, 8.4883e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,696][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.2467, 0.0162, 0.0660, 0.0323, 0.0958, 0.0112, 0.0034, 0.0108, 0.0118,
        0.0116, 0.0104, 0.0008, 0.0636, 0.0280, 0.0506, 0.3407],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,698][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ it] are: tensor([4.7149e-03, 1.7717e-05, 2.5825e-03, 1.9483e-04, 4.9475e-04, 3.2776e-03,
        1.1673e-03, 3.0439e-03, 1.5586e-02, 5.6924e-03, 6.6610e-02, 7.7942e-04,
        9.3539e-02, 4.1760e-01, 1.6011e-01, 2.2459e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,699][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ it] are: tensor([8.2331e-01, 5.3571e-03, 2.3046e-02, 2.7424e-02, 6.6326e-02, 5.7786e-03,
        2.8136e-04, 6.8474e-03, 2.6999e-03, 6.0254e-04, 1.7814e-03, 4.7213e-05,
        7.0180e-03, 1.6269e-02, 7.1472e-03, 6.0619e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,700][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ it] are: tensor([8.6805e-01, 2.0236e-05, 5.6422e-02, 1.6576e-03, 2.5929e-03, 9.2658e-03,
        3.1387e-04, 1.4954e-03, 7.8850e-03, 3.3796e-04, 7.4486e-03, 1.1983e-04,
        2.4566e-03, 3.9803e-02, 1.2255e-03, 9.0245e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,701][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ it] are: tensor([8.2334e-01, 2.1190e-03, 1.6649e-02, 2.1214e-03, 2.1322e-02, 4.6638e-03,
        2.2448e-04, 8.7086e-04, 2.4813e-02, 9.1601e-04, 5.8959e-03, 4.4347e-04,
        1.7399e-02, 2.9919e-02, 1.5326e-02, 3.3975e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:39,702][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.5698, 0.0034, 0.0107, 0.0244, 0.0150, 0.0025, 0.0006, 0.0029, 0.0064,
        0.0028, 0.0057, 0.0018, 0.0297, 0.0478, 0.1655, 0.0110, 0.1001],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,703][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([9.2898e-01, 9.3215e-03, 7.1655e-03, 6.8720e-03, 2.8950e-03, 7.2991e-04,
        3.0931e-05, 8.3476e-04, 1.0666e-03, 1.7065e-04, 7.3434e-04, 1.5332e-04,
        2.3728e-03, 3.6821e-03, 1.6558e-03, 3.0605e-02, 2.7313e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,705][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.3631, 0.0907, 0.0730, 0.0868, 0.0169, 0.0215, 0.0027, 0.0429, 0.0396,
        0.0031, 0.0176, 0.0042, 0.0252, 0.0376, 0.0538, 0.0790, 0.0424],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,706][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([6.7452e-01, 3.9199e-04, 2.9407e-02, 3.0214e-03, 1.4196e-03, 8.0667e-03,
        3.3998e-04, 6.8750e-04, 1.9920e-02, 2.8077e-03, 5.0490e-03, 5.6583e-05,
        5.4477e-03, 8.5263e-02, 2.2730e-02, 1.0671e-01, 3.4162e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,708][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0035, 0.0662, 0.0363, 0.0511, 0.0133, 0.0666, 0.0081, 0.1150, 0.0949,
        0.0261, 0.0362, 0.1145, 0.0193, 0.0665, 0.2130, 0.0160, 0.0535],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,710][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.2554, 0.1865, 0.0749, 0.1115, 0.0617, 0.0389, 0.0030, 0.0892, 0.0239,
        0.0062, 0.0185, 0.0051, 0.0256, 0.0276, 0.0250, 0.0233, 0.0237],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,711][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([7.2680e-01, 7.5094e-02, 3.1421e-02, 1.7222e-02, 1.7839e-02, 1.7933e-02,
        5.6574e-05, 8.2879e-03, 2.1405e-02, 8.3182e-04, 8.0635e-03, 7.7088e-04,
        1.5394e-02, 2.0899e-02, 3.7424e-03, 2.2551e-02, 1.1692e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,712][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([1.9284e-01, 1.1364e-02, 8.2248e-02, 5.8623e-02, 4.0163e-02, 6.0410e-03,
        1.5273e-03, 6.4530e-03, 1.2331e-02, 3.3188e-03, 8.6701e-03, 2.0268e-04,
        3.1882e-02, 1.9178e-02, 1.0996e-02, 5.0298e-01, 1.1180e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,713][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([5.9973e-04, 8.8709e-06, 2.1434e-03, 6.8575e-05, 2.3939e-04, 9.0768e-03,
        1.1196e-03, 2.9065e-03, 2.8695e-02, 8.6447e-03, 6.4919e-02, 3.6151e-03,
        1.4632e-01, 2.9570e-01, 9.0272e-02, 1.9302e-01, 1.5265e-01],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,715][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([8.8026e-01, 3.9864e-03, 2.2356e-02, 4.9302e-02, 3.0178e-02, 2.1343e-03,
        3.6191e-05, 2.2580e-03, 5.9294e-04, 1.6651e-04, 7.8000e-04, 2.4604e-05,
        1.3749e-03, 3.5370e-03, 1.8471e-03, 3.8799e-04, 7.8195e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,716][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([9.5000e-01, 1.4658e-05, 2.7327e-02, 3.9334e-03, 3.9517e-04, 1.8700e-03,
        9.3600e-05, 3.9337e-04, 8.2963e-04, 1.1972e-04, 1.7178e-03, 4.1683e-05,
        4.5695e-04, 7.0939e-03, 9.6862e-05, 9.7902e-05, 5.5205e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,717][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([9.7456e-01, 7.0789e-04, 4.4228e-03, 1.0522e-03, 2.7222e-03, 4.8847e-04,
        4.3663e-05, 5.9362e-05, 1.3212e-03, 9.1038e-05, 2.2841e-04, 3.1921e-05,
        6.7477e-04, 1.4768e-03, 7.1578e-04, 1.0306e-02, 1.0974e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:39,835][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:39,836][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,837][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,839][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,840][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,841][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,842][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,844][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,845][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,847][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,848][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,849][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,851][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:29:39,852][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Sara] are: tensor([0.9718, 0.0282], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,854][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Sara] are: tensor([0.9968, 0.0032], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,855][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Sara] are: tensor([0.9737, 0.0263], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,857][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Sara] are: tensor([0.9965, 0.0035], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,859][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Sara] are: tensor([0.1682, 0.8318], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,860][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Sara] are: tensor([0.9650, 0.0350], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,862][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Sara] are: tensor([0.9724, 0.0276], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,862][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Sara] are: tensor([0.9909, 0.0091], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,863][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Sara] are: tensor([9.9987e-01, 1.2847e-04], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,864][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Sara] are: tensor([0.9976, 0.0024], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,864][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Sara] are: tensor([9.9997e-01, 3.0360e-05], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,865][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Sara] are: tensor([0.9933, 0.0067], device='cuda:0') for source tokens [When Sara]
[2024-07-24 10:29:39,867][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.8963, 0.0486, 0.0551], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,868][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.9905, 0.0037, 0.0057], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,870][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.8037, 0.1283, 0.0681], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,871][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([9.4962e-01, 6.9220e-04, 4.9690e-02], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,873][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1013, 0.5062, 0.3925], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,874][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.6327, 0.2411, 0.1262], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,876][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.9338, 0.0541, 0.0120], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,877][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.8725, 0.0473, 0.0802], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,878][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([9.7698e-01, 2.1322e-04, 2.2803e-02], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,880][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.9650, 0.0087, 0.0263], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,881][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([9.7488e-01, 3.7514e-05, 2.5081e-02], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,882][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([9.9889e-01, 5.1564e-04, 5.9351e-04], device='cuda:0') for source tokens [When Sara and]
[2024-07-24 10:29:39,884][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Kenneth] are: tensor([0.8240, 0.0250, 0.0685, 0.0825], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,885][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Kenneth] are: tensor([9.9469e-01, 6.2035e-04, 1.3940e-03, 3.2996e-03], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,887][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Kenneth] are: tensor([0.8438, 0.0538, 0.0548, 0.0476], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,888][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Kenneth] are: tensor([0.5590, 0.0036, 0.4215, 0.0158], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,890][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Kenneth] are: tensor([0.0526, 0.4636, 0.2456, 0.2382], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,892][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Kenneth] are: tensor([0.7926, 0.0674, 0.0726, 0.0674], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,893][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Kenneth] are: tensor([0.9692, 0.0242, 0.0044, 0.0022], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,894][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Kenneth] are: tensor([0.9359, 0.0111, 0.0253, 0.0277], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,894][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Kenneth] are: tensor([0.8613, 0.0036, 0.1162, 0.0189], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,895][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Kenneth] are: tensor([0.9690, 0.0031, 0.0125, 0.0154], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,896][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Kenneth] are: tensor([9.8419e-01, 4.5742e-06, 1.5202e-02, 6.0541e-04], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,897][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Kenneth] are: tensor([0.9923, 0.0041, 0.0020, 0.0016], device='cuda:0') for source tokens [When Sara and Kenneth]
[2024-07-24 10:29:39,899][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.9358, 0.0048, 0.0115, 0.0194, 0.0286], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,901][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.9336, 0.0087, 0.0193, 0.0342, 0.0042], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,902][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.5162, 0.1323, 0.1501, 0.1682, 0.0331], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,904][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([8.5421e-01, 8.1347e-04, 1.2415e-01, 1.7251e-02, 3.5799e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,905][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.0106, 0.2620, 0.2905, 0.3399, 0.0970], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,907][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.4835, 0.1683, 0.0939, 0.2273, 0.0269], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,908][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.8971, 0.0374, 0.0189, 0.0180, 0.0287], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,910][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.5766, 0.0644, 0.1055, 0.1282, 0.1252], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,911][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([9.8705e-01, 8.5749e-05, 9.5074e-03, 2.3702e-03, 9.8890e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,913][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.9746, 0.0018, 0.0086, 0.0113, 0.0037], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,914][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([9.7411e-01, 2.9533e-05, 2.3028e-02, 1.2992e-03, 1.5304e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,915][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.9884, 0.0021, 0.0021, 0.0033, 0.0041], device='cuda:0') for source tokens [When Sara and Kenneth got]
[2024-07-24 10:29:39,917][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.7465, 0.0170, 0.0866, 0.0408, 0.0806, 0.0285], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,918][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([9.7764e-01, 7.0976e-03, 3.9345e-03, 9.2419e-03, 1.6537e-03, 4.3381e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,920][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.6261, 0.1606, 0.0740, 0.1049, 0.0158, 0.0187], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,921][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([8.2626e-01, 5.8804e-04, 1.3928e-01, 7.1420e-03, 2.5704e-03, 2.4163e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,923][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0205, 0.3229, 0.2179, 0.2428, 0.0461, 0.1498], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,925][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.6980, 0.0721, 0.0450, 0.1238, 0.0497, 0.0114], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,925][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.9256, 0.0467, 0.0072, 0.0058, 0.0105, 0.0042], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,926][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.6333, 0.0903, 0.0819, 0.0860, 0.0998, 0.0089], device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,927][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([9.9706e-01, 4.8221e-06, 1.8990e-03, 4.4627e-04, 2.2322e-04, 3.6268e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,927][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([9.6288e-01, 3.9531e-03, 8.7713e-03, 1.4626e-02, 9.0323e-03, 7.4034e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,929][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([9.7675e-01, 8.1801e-06, 1.9887e-02, 6.3973e-04, 6.2467e-04, 2.0916e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,930][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([9.9503e-01, 1.0024e-03, 1.8598e-03, 6.5160e-04, 8.8578e-04, 5.6550e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a]
[2024-07-24 10:29:39,931][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.2099, 0.0189, 0.1962, 0.1290, 0.3526, 0.0603, 0.0332],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,932][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([8.6888e-01, 3.5078e-02, 2.9901e-02, 4.0199e-02, 2.0243e-02, 5.4626e-03,
        2.3981e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,934][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.2048, 0.2166, 0.2975, 0.1637, 0.0646, 0.0510, 0.0019],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,935][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.0153, 0.0007, 0.5717, 0.0112, 0.0247, 0.3735, 0.0028],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,937][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.0268, 0.2494, 0.1311, 0.2799, 0.0858, 0.1952, 0.0317],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,939][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.4814, 0.1200, 0.0768, 0.1560, 0.1374, 0.0248, 0.0036],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,940][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([8.6608e-01, 5.2649e-02, 2.1402e-02, 1.1729e-02, 3.6065e-02, 1.2042e-02,
        3.8069e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,941][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.3829, 0.1112, 0.1550, 0.1385, 0.1878, 0.0205, 0.0042],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,943][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([9.9610e-01, 6.5414e-06, 2.2114e-03, 4.7015e-04, 3.9930e-04, 4.1145e-04,
        4.0123e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,944][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([8.9008e-01, 9.6946e-03, 1.8960e-02, 3.3969e-02, 4.5972e-02, 1.2910e-03,
        3.2754e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,945][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([7.9051e-01, 1.9976e-04, 1.7001e-01, 1.0152e-02, 4.4259e-03, 2.2038e-02,
        2.6647e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,946][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.9201, 0.0114, 0.0281, 0.0104, 0.0153, 0.0136, 0.0011],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace]
[2024-07-24 10:29:39,948][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.6664, 0.0202, 0.0705, 0.0730, 0.1093, 0.0272, 0.0077, 0.0258],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,949][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([9.7869e-01, 6.3733e-03, 5.5750e-03, 7.1816e-03, 1.0416e-03, 2.7085e-04,
        1.4425e-05, 8.5109e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,951][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.6811, 0.0495, 0.0757, 0.0982, 0.0175, 0.0145, 0.0017, 0.0618],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,952][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([7.9971e-01, 4.3363e-04, 1.6497e-01, 6.8835e-03, 2.4118e-03, 2.1241e-02,
        1.8355e-04, 4.1674e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,954][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0316, 0.2565, 0.1262, 0.2509, 0.0194, 0.1072, 0.0158, 0.1925],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,955][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([7.7916e-01, 1.0305e-01, 2.7075e-02, 5.8096e-02, 1.7278e-02, 3.7956e-03,
        4.0700e-04, 1.1131e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,956][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([9.2255e-01, 5.6913e-02, 6.3670e-03, 5.0662e-03, 4.1091e-03, 2.9180e-03,
        1.8971e-05, 2.0560e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,957][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([7.4819e-01, 2.4596e-02, 7.5617e-02, 8.4408e-02, 5.9223e-02, 3.2904e-03,
        4.7773e-04, 4.1995e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,958][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([9.6776e-01, 2.7844e-05, 1.0682e-02, 2.0736e-03, 1.1167e-03, 3.4464e-03,
        1.2935e-03, 1.3603e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,958][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([9.5547e-01, 7.1896e-03, 5.6912e-03, 2.7424e-02, 3.3147e-03, 2.0275e-04,
        3.2286e-05, 6.7533e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,959][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([9.8742e-01, 3.1392e-06, 1.0754e-02, 8.5812e-04, 2.2279e-04, 4.4785e-04,
        3.3190e-05, 2.5829e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,960][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([9.9886e-01, 2.2419e-04, 4.9993e-04, 1.9797e-04, 1.3897e-04, 6.1813e-05,
        2.4080e-06, 1.1352e-05], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at]
[2024-07-24 10:29:39,962][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.6358, 0.0058, 0.0988, 0.0431, 0.0987, 0.0245, 0.0061, 0.0162, 0.0709],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,963][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([9.1967e-01, 3.2825e-02, 1.6775e-02, 2.0688e-02, 5.9711e-03, 6.8395e-04,
        7.7285e-05, 1.8296e-03, 1.4791e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,965][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.3933, 0.1706, 0.1228, 0.1472, 0.0147, 0.0184, 0.0019, 0.0494, 0.0817],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,966][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([8.4798e-01, 1.4060e-04, 8.0518e-02, 4.5311e-03, 1.9825e-03, 1.7470e-02,
        4.7139e-04, 1.7830e-03, 4.5122e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,967][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0121, 0.2393, 0.1592, 0.1728, 0.0302, 0.0831, 0.0265, 0.0956, 0.1813],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,969][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.5350, 0.1699, 0.0515, 0.1540, 0.0371, 0.0086, 0.0011, 0.0295, 0.0134],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,970][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([8.6319e-01, 9.5454e-02, 9.5320e-03, 7.5318e-03, 1.0884e-02, 4.0894e-03,
        2.1015e-05, 2.1361e-03, 7.1622e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,972][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.4644, 0.1358, 0.1137, 0.1494, 0.1085, 0.0059, 0.0020, 0.0046, 0.0156],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,973][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([9.9580e-01, 1.6073e-06, 1.2088e-03, 3.3666e-04, 1.3167e-04, 3.1369e-04,
        1.8813e-04, 6.8855e-04, 1.3358e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,974][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([9.7187e-01, 2.9457e-03, 7.6234e-03, 1.0810e-02, 5.4126e-03, 3.8256e-04,
        2.4795e-05, 6.8052e-04, 2.4920e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,976][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([9.8029e-01, 2.3049e-06, 1.6521e-02, 7.6257e-04, 4.0648e-04, 1.1768e-03,
        7.9627e-05, 1.3551e-04, 6.2254e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,977][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([9.9672e-01, 3.0963e-04, 1.4078e-03, 2.4967e-04, 6.2853e-04, 2.5408e-04,
        1.2752e-05, 1.6795e-05, 4.0554e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the]
[2024-07-24 10:29:39,978][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ garden] are: tensor([0.5167, 0.0058, 0.0830, 0.1342, 0.1324, 0.0161, 0.0087, 0.0267, 0.0573,
        0.0189], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,980][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ garden] are: tensor([8.6245e-01, 3.0602e-02, 3.4564e-02, 4.0011e-02, 1.1009e-02, 4.0020e-03,
        1.3192e-04, 6.6846e-03, 9.3455e-03, 1.2013e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,981][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ garden] are: tensor([0.0539, 0.2382, 0.1403, 0.1129, 0.0123, 0.0369, 0.0024, 0.1039, 0.2934,
        0.0059], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,982][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ garden] are: tensor([5.4797e-02, 5.6302e-04, 1.8770e-01, 5.0853e-03, 9.7777e-03, 9.8655e-02,
        1.1732e-03, 2.1665e-02, 5.6615e-01, 5.4437e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,984][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ garden] are: tensor([0.0171, 0.2677, 0.0720, 0.0853, 0.0729, 0.1229, 0.0095, 0.0623, 0.2066,
        0.0838], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,986][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ garden] are: tensor([0.4282, 0.0672, 0.0764, 0.1691, 0.0976, 0.0265, 0.0034, 0.0926, 0.0292,
        0.0098], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,987][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ garden] are: tensor([4.6955e-01, 3.5902e-01, 2.8679e-02, 1.4490e-02, 3.9349e-02, 1.8618e-02,
        4.1855e-05, 1.7163e-02, 5.2481e-02, 6.0502e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,988][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ garden] are: tensor([0.3837, 0.0328, 0.1196, 0.0753, 0.2552, 0.0173, 0.0040, 0.0169, 0.0648,
        0.0304], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,989][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ garden] are: tensor([7.6431e-01, 1.1476e-04, 2.2746e-02, 3.9545e-03, 4.3001e-03, 1.2096e-02,
        2.9587e-03, 8.6477e-03, 8.0818e-02, 1.0005e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,990][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ garden] are: tensor([8.0540e-01, 2.2856e-02, 5.0213e-02, 4.9577e-02, 3.8595e-02, 4.7396e-03,
        6.3932e-05, 1.7623e-02, 1.0198e-02, 7.3522e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,990][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ garden] are: tensor([9.2895e-01, 9.9029e-05, 5.3082e-02, 7.8158e-03, 2.0986e-03, 3.1917e-03,
        5.0065e-04, 9.4429e-04, 2.3863e-03, 9.3089e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,992][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ garden] are: tensor([9.8627e-01, 1.0591e-03, 3.0602e-03, 1.4695e-03, 2.3130e-03, 1.3854e-03,
        3.2642e-05, 1.8748e-04, 4.1011e-03, 1.1895e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden]
[2024-07-24 10:29:39,993][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.6442, 0.0101, 0.0767, 0.0584, 0.0722, 0.0258, 0.0051, 0.0180, 0.0543,
        0.0080, 0.0272], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,994][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([9.6323e-01, 1.2067e-02, 6.4871e-03, 1.0573e-02, 2.8811e-03, 6.2261e-04,
        6.2544e-05, 1.7782e-03, 1.1380e-03, 2.5758e-04, 9.0716e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,996][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.4432, 0.1898, 0.0901, 0.1032, 0.0134, 0.0176, 0.0018, 0.0612, 0.0508,
        0.0050, 0.0240], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,997][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([6.6247e-01, 3.5942e-04, 1.5603e-01, 8.8425e-03, 2.6626e-03, 4.0516e-02,
        1.1648e-03, 6.2478e-03, 8.7890e-02, 2.2635e-02, 1.1188e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:39,999][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0144, 0.1778, 0.0954, 0.1088, 0.0216, 0.0898, 0.0160, 0.1188, 0.1784,
        0.0972, 0.0819], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:40,000][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.5846, 0.1030, 0.0675, 0.0696, 0.0460, 0.0181, 0.0013, 0.0548, 0.0233,
        0.0057, 0.0260], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:40,002][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([9.0943e-01, 3.6377e-02, 1.1659e-02, 5.1682e-03, 9.8121e-03, 6.9449e-03,
        2.4130e-05, 4.6147e-03, 1.1942e-02, 2.7543e-04, 3.7496e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:40,003][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.5220, 0.0650, 0.1742, 0.0834, 0.0715, 0.0095, 0.0023, 0.0098, 0.0305,
        0.0060, 0.0258], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:40,005][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([9.6540e-01, 5.3420e-06, 2.1335e-03, 4.2120e-04, 2.4054e-04, 5.9686e-04,
        5.0785e-04, 2.9768e-03, 2.1095e-03, 1.4223e-02, 1.1390e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:40,006][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([9.4555e-01, 5.4078e-03, 1.3469e-02, 1.8821e-02, 1.1850e-02, 7.2913e-04,
        4.1267e-05, 2.4735e-03, 5.5358e-04, 1.4873e-04, 9.5981e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:40,007][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([9.8268e-01, 3.1376e-06, 1.3927e-02, 1.1983e-03, 3.6342e-04, 6.2547e-04,
        7.2249e-05, 1.0275e-04, 2.4399e-04, 8.7108e-05, 6.9238e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:40,008][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([9.9128e-01, 5.6239e-04, 3.1951e-03, 9.1911e-04, 1.9943e-03, 6.0056e-04,
        6.1380e-05, 1.5830e-04, 8.5545e-04, 1.8682e-04, 1.8983e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden,]
[2024-07-24 10:29:40,010][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Sara] are: tensor([0.1937, 0.0186, 0.1634, 0.1149, 0.1108, 0.0437, 0.0377, 0.0576, 0.1010,
        0.0542, 0.0957, 0.0087], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:40,011][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Sara] are: tensor([9.4518e-01, 8.5817e-03, 6.9515e-03, 2.1280e-02, 1.1285e-02, 1.3809e-03,
        7.5041e-05, 2.1413e-03, 1.7170e-03, 4.6896e-04, 8.5229e-04, 9.0928e-05],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:40,013][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Sara] are: tensor([0.2232, 0.0612, 0.2021, 0.0622, 0.1006, 0.0546, 0.0035, 0.0958, 0.1203,
        0.0152, 0.0585, 0.0029], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:40,014][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Sara] are: tensor([4.1017e-03, 7.9600e-05, 1.1939e-01, 8.4592e-03, 1.8181e-02, 1.0931e-01,
        7.7685e-03, 2.8666e-02, 5.5422e-01, 9.3950e-02, 5.5835e-02, 3.7251e-05],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:40,016][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Sara] are: tensor([0.0099, 0.1401, 0.0517, 0.0774, 0.0522, 0.0800, 0.0072, 0.1135, 0.1883,
        0.1366, 0.0432, 0.0999], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:40,017][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Sara] are: tensor([7.6118e-01, 4.1751e-02, 3.3570e-02, 5.4579e-02, 6.2818e-02, 7.1037e-03,
        7.5933e-04, 1.9256e-02, 6.0523e-03, 7.2673e-03, 5.1777e-03, 4.7997e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:40,018][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Sara] are: tensor([7.6638e-01, 7.9156e-02, 2.4245e-02, 5.4251e-03, 6.8597e-02, 1.6695e-02,
        1.1551e-04, 1.3566e-02, 1.9206e-02, 6.4526e-04, 5.8611e-03, 1.1132e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:40,019][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Sara] are: tensor([0.6069, 0.0780, 0.1018, 0.0600, 0.0945, 0.0079, 0.0011, 0.0159, 0.0113,
        0.0093, 0.0122, 0.0010], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:40,020][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Sara] are: tensor([9.5361e-01, 1.2322e-05, 3.8326e-03, 1.0589e-03, 6.6013e-04, 9.3658e-04,
        9.7112e-04, 4.7121e-03, 3.8491e-03, 1.8743e-02, 1.1530e-02, 8.2672e-05],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:40,021][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Sara] are: tensor([9.5646e-01, 3.4351e-03, 7.0391e-03, 1.2458e-02, 1.7743e-02, 5.6056e-04,
        2.6320e-05, 1.5521e-03, 3.5136e-04, 6.5459e-05, 3.0101e-04, 9.0468e-06],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:40,022][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Sara] are: tensor([6.9614e-01, 3.5488e-05, 1.8057e-01, 1.1608e-02, 7.1576e-03, 1.8166e-02,
        1.0084e-02, 9.2908e-03, 1.0578e-02, 5.8594e-03, 5.0127e-02, 3.8591e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:40,023][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Sara] are: tensor([0.7634, 0.0112, 0.0600, 0.0143, 0.0382, 0.0205, 0.0033, 0.0091, 0.0513,
        0.0134, 0.0139, 0.0016], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara]
[2024-07-24 10:29:40,024][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([9.1306e-01, 2.8714e-03, 8.4603e-03, 2.2981e-02, 1.8311e-02, 2.2409e-03,
        4.3768e-04, 2.5240e-03, 2.8890e-03, 6.5017e-04, 3.2518e-03, 8.6786e-04,
        2.1459e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:40,026][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([9.4515e-01, 6.7040e-03, 1.6160e-02, 1.4965e-02, 4.9401e-03, 1.2058e-03,
        1.1060e-04, 2.3953e-03, 1.2003e-03, 4.4759e-04, 1.1433e-03, 1.7854e-04,
        5.4041e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:40,028][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.4431, 0.0543, 0.1221, 0.1268, 0.0504, 0.0398, 0.0044, 0.0665, 0.0485,
        0.0080, 0.0182, 0.0030, 0.0148], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:40,029][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([7.2099e-01, 2.7349e-04, 1.0339e-01, 4.6488e-03, 2.7922e-03, 3.1285e-02,
        8.6578e-04, 8.2655e-03, 8.7928e-02, 1.0126e-02, 1.8865e-02, 4.0706e-05,
        1.0538e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:40,030][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0048, 0.1216, 0.0678, 0.0656, 0.0438, 0.0784, 0.0085, 0.2535, 0.1237,
        0.0458, 0.0448, 0.0790, 0.0628], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:40,032][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.3044, 0.1964, 0.0645, 0.1036, 0.0741, 0.0289, 0.0023, 0.1529, 0.0212,
        0.0070, 0.0144, 0.0046, 0.0256], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:40,033][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([8.3871e-01, 3.4421e-02, 3.1326e-02, 1.4641e-02, 2.1808e-02, 2.1549e-02,
        8.7037e-05, 7.9034e-03, 1.3193e-02, 7.7787e-04, 4.3599e-03, 3.7951e-04,
        1.0845e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:40,035][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.2377, 0.0450, 0.2179, 0.1495, 0.1844, 0.0130, 0.0031, 0.0222, 0.0191,
        0.0061, 0.0218, 0.0005, 0.0796], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:40,036][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([9.6471e-01, 3.8458e-06, 1.4196e-03, 5.4423e-04, 2.5930e-04, 3.2178e-04,
        3.4010e-04, 2.3730e-03, 4.2164e-03, 1.2984e-02, 1.0386e-02, 3.7269e-05,
        2.4056e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:40,037][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([9.5224e-01, 3.4933e-03, 1.5883e-02, 1.4907e-02, 8.9446e-03, 8.2522e-04,
        5.4662e-05, 1.9490e-03, 2.8220e-04, 2.4034e-04, 5.9996e-04, 5.4272e-05,
        5.2314e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:40,039][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([9.8450e-01, 1.3383e-05, 1.0943e-02, 5.7517e-04, 4.4323e-04, 1.1921e-03,
        4.6026e-05, 2.6073e-04, 6.8804e-04, 4.5061e-05, 8.6935e-04, 1.8048e-05,
        4.0375e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:40,040][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([9.9162e-01, 3.7129e-04, 2.6884e-03, 3.6810e-04, 1.7033e-03, 1.0468e-03,
        3.8891e-05, 1.0964e-04, 1.5049e-03, 1.2675e-04, 1.1838e-04, 1.2331e-05,
        2.8662e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided]
[2024-07-24 10:29:40,042][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.7553, 0.0052, 0.0168, 0.0277, 0.0220, 0.0049, 0.0011, 0.0045, 0.0112,
        0.0039, 0.0097, 0.0027, 0.0468, 0.0879], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:40,043][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([9.7128e-01, 6.2710e-03, 5.2768e-03, 5.3601e-03, 2.1185e-03, 7.7511e-04,
        2.5293e-05, 6.0799e-04, 9.7907e-04, 1.4077e-04, 6.1061e-04, 1.3170e-04,
        2.4184e-03, 4.0007e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:40,045][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.4972, 0.0744, 0.0680, 0.0916, 0.0160, 0.0331, 0.0032, 0.0674, 0.0475,
        0.0032, 0.0175, 0.0038, 0.0328, 0.0445], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:40,046][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([9.4026e-01, 1.5537e-04, 1.4775e-02, 1.0097e-03, 6.2728e-04, 2.9263e-03,
        8.3215e-05, 1.8402e-04, 4.9573e-03, 1.0773e-03, 1.3558e-03, 1.1634e-05,
        1.5205e-03, 3.1052e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:40,047][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0089, 0.0893, 0.0565, 0.0893, 0.0165, 0.0794, 0.0206, 0.1139, 0.0898,
        0.0485, 0.0455, 0.1976, 0.0294, 0.1149], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:40,049][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.3238, 0.1706, 0.0683, 0.1240, 0.0574, 0.0323, 0.0043, 0.0994, 0.0257,
        0.0078, 0.0223, 0.0037, 0.0312, 0.0292], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:40,050][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([8.6649e-01, 3.8570e-02, 1.4643e-02, 1.2063e-02, 1.3730e-02, 1.3956e-02,
        3.5695e-05, 4.5756e-03, 1.3176e-02, 4.7508e-04, 3.5547e-03, 3.6049e-04,
        9.8913e-03, 8.4758e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:40,051][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([4.9934e-01, 2.6515e-02, 1.4266e-01, 1.1956e-01, 6.3386e-02, 1.1751e-02,
        2.4612e-03, 8.7361e-03, 2.4253e-02, 4.4236e-03, 1.5612e-02, 3.6582e-04,
        4.8536e-02, 3.2401e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:40,052][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([9.3292e-01, 4.6835e-06, 9.7240e-04, 3.2117e-04, 9.4112e-05, 2.9306e-04,
        2.5349e-04, 6.7462e-04, 1.6468e-03, 8.9321e-03, 5.0119e-03, 6.2486e-05,
        1.2965e-03, 4.7515e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:40,053][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([9.2304e-01, 2.4193e-03, 1.3584e-02, 3.5087e-02, 1.9207e-02, 1.3229e-03,
        2.5435e-05, 1.6217e-03, 3.9798e-04, 9.0899e-05, 6.0672e-04, 8.8343e-06,
        9.3208e-04, 1.6597e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:40,054][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([9.8248e-01, 3.6671e-06, 1.1026e-02, 7.6145e-04, 2.2222e-04, 7.0457e-04,
        3.1366e-05, 1.3019e-04, 2.5289e-04, 3.2519e-05, 5.8843e-04, 1.5607e-05,
        1.6892e-04, 3.5870e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:40,055][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([9.9564e-01, 2.3334e-04, 1.4128e-03, 4.1286e-04, 8.1029e-04, 1.7178e-04,
        1.2277e-05, 1.8015e-05, 3.5301e-04, 2.9093e-05, 7.0406e-05, 8.3841e-06,
        2.1700e-04, 6.0735e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to]
[2024-07-24 10:29:40,057][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.4709, 0.0051, 0.0192, 0.0318, 0.0210, 0.0050, 0.0014, 0.0035, 0.0138,
        0.0033, 0.0108, 0.0023, 0.0449, 0.1004, 0.2667], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:40,058][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([8.8886e-01, 4.0116e-02, 1.5373e-02, 1.5208e-02, 1.6275e-02, 2.1352e-03,
        7.6581e-05, 1.2788e-03, 3.0619e-03, 3.9016e-04, 1.3143e-03, 6.3799e-04,
        3.5161e-03, 6.5623e-03, 5.1985e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:40,060][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0897, 0.1902, 0.1149, 0.2105, 0.0317, 0.0288, 0.0056, 0.0698, 0.0781,
        0.0045, 0.0381, 0.0110, 0.0156, 0.0516, 0.0600], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:40,061][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([4.8252e-01, 1.4438e-04, 8.4145e-02, 3.6961e-03, 1.4846e-03, 6.9985e-03,
        1.2452e-04, 7.2802e-04, 2.1374e-02, 1.2026e-03, 5.2686e-03, 9.1571e-06,
        7.0459e-03, 3.5062e-01, 3.4646e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:40,063][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0023, 0.1248, 0.0389, 0.0741, 0.0109, 0.0430, 0.0076, 0.0598, 0.1041,
        0.0385, 0.0417, 0.1564, 0.0292, 0.0441, 0.2246], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:40,065][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.3663, 0.1783, 0.0539, 0.1934, 0.0809, 0.0154, 0.0016, 0.0285, 0.0109,
        0.0043, 0.0093, 0.0020, 0.0135, 0.0184, 0.0232], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:40,066][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([7.6228e-01, 9.1051e-02, 2.7860e-02, 1.2984e-02, 2.7958e-02, 1.9455e-02,
        3.9219e-05, 4.8601e-03, 1.2626e-02, 2.5913e-04, 6.0886e-03, 4.3630e-04,
        1.1346e-02, 1.8120e-02, 4.6386e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:40,067][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.2853, 0.0403, 0.1607, 0.1086, 0.1088, 0.0093, 0.0046, 0.0136, 0.0301,
        0.0076, 0.0279, 0.0016, 0.0871, 0.0343, 0.0803], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:40,069][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([5.6214e-01, 4.7965e-06, 1.2757e-03, 1.5722e-04, 1.3517e-04, 3.4370e-04,
        5.9949e-04, 1.6318e-03, 2.5168e-03, 1.9178e-02, 1.7047e-02, 6.6579e-05,
        6.8713e-03, 3.4762e-01, 4.0412e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:40,070][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([9.6446e-01, 3.0429e-03, 6.5529e-03, 1.2671e-02, 1.0574e-02, 5.3269e-04,
        7.1480e-06, 3.0375e-04, 1.5476e-04, 4.0576e-05, 2.2373e-04, 9.8186e-06,
        2.7316e-04, 9.7615e-04, 1.7497e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:40,071][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([9.5314e-01, 2.5329e-05, 3.2411e-02, 2.1796e-03, 6.8915e-04, 1.5925e-03,
        6.5011e-05, 1.3941e-04, 8.0646e-04, 9.3245e-05, 1.3462e-03, 2.7259e-05,
        3.6247e-04, 6.7144e-03, 4.1057e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:40,073][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([9.8440e-01, 1.6165e-03, 5.4682e-03, 1.4551e-03, 1.1345e-03, 8.6199e-04,
        4.5521e-05, 4.8753e-05, 1.1370e-03, 1.6994e-04, 2.7642e-04, 5.1355e-05,
        1.6334e-04, 2.7940e-03, 3.7453e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give]
[2024-07-24 10:29:40,075][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([0.5781, 0.0019, 0.0173, 0.0195, 0.0200, 0.0032, 0.0009, 0.0031, 0.0095,
        0.0017, 0.0091, 0.0009, 0.0420, 0.0740, 0.1931, 0.0257],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:40,076][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([6.8761e-01, 1.2938e-02, 1.2967e-02, 6.5679e-03, 1.4890e-02, 2.1236e-03,
        3.0691e-04, 4.5964e-03, 3.3366e-03, 7.3420e-04, 1.0572e-03, 3.5841e-04,
        8.2768e-03, 1.0313e-02, 9.3316e-03, 2.2459e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:40,077][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.0971, 0.0277, 0.0784, 0.0558, 0.0371, 0.0399, 0.0068, 0.0726, 0.1021,
        0.0101, 0.0351, 0.0041, 0.0405, 0.0856, 0.1031, 0.2041],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:40,079][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([3.6523e-01, 7.9462e-05, 2.7962e-02, 4.8779e-04, 1.6186e-03, 1.2054e-02,
        7.8293e-05, 1.2323e-03, 3.4622e-02, 1.2897e-03, 6.5622e-03, 1.0927e-05,
        1.1876e-02, 3.6004e-01, 4.4550e-02, 1.3231e-01], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:40,081][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.0010, 0.0141, 0.0211, 0.0199, 0.0071, 0.0488, 0.0113, 0.1566, 0.1436,
        0.0476, 0.0290, 0.0413, 0.0525, 0.0889, 0.2821, 0.0352],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:40,082][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([0.1705, 0.0574, 0.0494, 0.0739, 0.1157, 0.0433, 0.0034, 0.0916, 0.0489,
        0.0107, 0.0170, 0.0014, 0.0455, 0.0860, 0.0523, 0.1329],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:40,083][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([5.0130e-01, 3.8921e-02, 3.1040e-02, 1.1603e-02, 4.2411e-02, 5.4813e-02,
        2.4868e-04, 2.3879e-02, 6.5504e-02, 1.8122e-03, 9.6195e-03, 8.3279e-04,
        7.6427e-02, 3.8759e-02, 1.7950e-02, 8.4883e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:40,083][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.2467, 0.0162, 0.0660, 0.0323, 0.0958, 0.0112, 0.0034, 0.0108, 0.0118,
        0.0116, 0.0104, 0.0008, 0.0636, 0.0280, 0.0506, 0.3407],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:40,084][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([9.5676e-01, 7.0890e-07, 1.5703e-04, 9.9355e-05, 4.5052e-05, 3.7327e-05,
        7.5302e-05, 2.4781e-04, 3.1005e-04, 2.0337e-03, 2.6571e-03, 5.6472e-06,
        9.9346e-04, 2.8245e-02, 3.9542e-03, 4.3783e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:40,086][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([8.2331e-01, 5.3571e-03, 2.3046e-02, 2.7424e-02, 6.6326e-02, 5.7786e-03,
        2.8136e-04, 6.8474e-03, 2.6999e-03, 6.0254e-04, 1.7814e-03, 4.7213e-05,
        7.0180e-03, 1.6269e-02, 7.1472e-03, 6.0619e-03], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:40,087][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([8.6805e-01, 2.0236e-05, 5.6422e-02, 1.6576e-03, 2.5929e-03, 9.2658e-03,
        3.1387e-04, 1.4954e-03, 7.8850e-03, 3.3796e-04, 7.4486e-03, 1.1983e-04,
        2.4566e-03, 3.9803e-02, 1.2255e-03, 9.0245e-04], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:40,088][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([8.2334e-01, 2.1190e-03, 1.6649e-02, 2.1214e-03, 2.1322e-02, 4.6638e-03,
        2.2448e-04, 8.7086e-04, 2.4813e-02, 9.1601e-04, 5.8959e-03, 4.4347e-04,
        1.7399e-02, 2.9919e-02, 1.5326e-02, 3.3975e-02], device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it]
[2024-07-24 10:29:40,090][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.5698, 0.0034, 0.0107, 0.0244, 0.0150, 0.0025, 0.0006, 0.0029, 0.0064,
        0.0028, 0.0057, 0.0018, 0.0297, 0.0478, 0.1655, 0.0110, 0.1001],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:40,091][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([9.2898e-01, 9.3215e-03, 7.1655e-03, 6.8720e-03, 2.8950e-03, 7.2991e-04,
        3.0931e-05, 8.3476e-04, 1.0666e-03, 1.7065e-04, 7.3434e-04, 1.5332e-04,
        2.3728e-03, 3.6821e-03, 1.6558e-03, 3.0605e-02, 2.7313e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:40,093][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3631, 0.0907, 0.0730, 0.0868, 0.0169, 0.0215, 0.0027, 0.0429, 0.0396,
        0.0031, 0.0176, 0.0042, 0.0252, 0.0376, 0.0538, 0.0790, 0.0424],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:40,094][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([6.7452e-01, 3.9199e-04, 2.9407e-02, 3.0214e-03, 1.4196e-03, 8.0667e-03,
        3.3998e-04, 6.8750e-04, 1.9920e-02, 2.8077e-03, 5.0490e-03, 5.6583e-05,
        5.4477e-03, 8.5263e-02, 2.2730e-02, 1.0671e-01, 3.4162e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:40,096][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0035, 0.0662, 0.0363, 0.0511, 0.0133, 0.0666, 0.0081, 0.1150, 0.0949,
        0.0261, 0.0362, 0.1145, 0.0193, 0.0665, 0.2130, 0.0160, 0.0535],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:40,098][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.2554, 0.1865, 0.0749, 0.1115, 0.0617, 0.0389, 0.0030, 0.0892, 0.0239,
        0.0062, 0.0185, 0.0051, 0.0256, 0.0276, 0.0250, 0.0233, 0.0237],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:40,099][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([7.2680e-01, 7.5094e-02, 3.1421e-02, 1.7222e-02, 1.7839e-02, 1.7933e-02,
        5.6574e-05, 8.2879e-03, 2.1405e-02, 8.3182e-04, 8.0635e-03, 7.7088e-04,
        1.5394e-02, 2.0899e-02, 3.7424e-03, 2.2551e-02, 1.1692e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:40,100][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.9284e-01, 1.1364e-02, 8.2248e-02, 5.8623e-02, 4.0163e-02, 6.0410e-03,
        1.5273e-03, 6.4530e-03, 1.2331e-02, 3.3188e-03, 8.6701e-03, 2.0268e-04,
        3.1882e-02, 1.9178e-02, 1.0996e-02, 5.0298e-01, 1.1180e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:40,101][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([9.0512e-01, 4.7559e-06, 5.8147e-04, 4.2442e-04, 7.0970e-05, 1.5493e-04,
        1.7058e-04, 8.7503e-04, 1.3684e-03, 8.0074e-03, 4.1617e-03, 5.5394e-05,
        1.5408e-03, 4.0493e-02, 4.6496e-03, 7.3516e-03, 2.4969e-02],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:40,103][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([8.8026e-01, 3.9864e-03, 2.2356e-02, 4.9302e-02, 3.0178e-02, 2.1343e-03,
        3.6191e-05, 2.2580e-03, 5.9294e-04, 1.6651e-04, 7.8000e-04, 2.4604e-05,
        1.3749e-03, 3.5370e-03, 1.8471e-03, 3.8799e-04, 7.8195e-04],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:40,104][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([9.5000e-01, 1.4658e-05, 2.7327e-02, 3.9334e-03, 3.9517e-04, 1.8700e-03,
        9.3600e-05, 3.9337e-04, 8.2963e-04, 1.1972e-04, 1.7178e-03, 4.1683e-05,
        4.5695e-04, 7.0939e-03, 9.6862e-05, 9.7902e-05, 5.5205e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:40,105][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([9.7456e-01, 7.0789e-04, 4.4228e-03, 1.0522e-03, 2.7222e-03, 4.8847e-04,
        4.3663e-05, 5.9362e-05, 1.3212e-03, 9.1038e-05, 2.2841e-04, 3.1921e-05,
        6.7477e-04, 1.4768e-03, 7.1578e-04, 1.0306e-02, 1.0974e-03],
       device='cuda:0') for source tokens [When Sara and Kenneth got a necklace at the garden, Sara decided to give it to]
[2024-07-24 10:29:40,109][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:40,111][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[371],
        [  8],
        [  5],
        [ 16],
        [  2],
        [ 30],
        [ 93],
        [  1],
        [ 47],
        [  1],
        [  1],
        [  1],
        [ 23],
        [  1],
        [  1],
        [  1],
        [  1]], device='cuda:0')
[2024-07-24 10:29:40,113][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[592],
        [  9],
        [ 10],
        [ 21],
        [  6],
        [  1],
        [ 18],
        [  3],
        [  3],
        [  1],
        [  3],
        [  3],
        [  1],
        [  1],
        [  2],
        [  1],
        [  1]], device='cuda:0')
[2024-07-24 10:29:40,114][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[27847],
        [27362],
        [26383],
        [19764],
        [24328],
        [21635],
        [18663],
        [19815],
        [21404],
        [17585],
        [20637],
        [19154],
        [22714],
        [19057],
        [14541],
        [15430],
        [15448]], device='cuda:0')
[2024-07-24 10:29:40,115][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 555],
        [ 586],
        [ 592],
        [ 616],
        [1420],
        [ 768],
        [2347],
        [ 722],
        [1523],
        [2327],
        [ 891],
        [1066],
        [ 882],
        [ 694],
        [1378],
        [1072],
        [ 730]], device='cuda:0')
[2024-07-24 10:29:40,117][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 5852],
        [ 6601],
        [ 8029],
        [ 8725],
        [11915],
        [13766],
        [ 7770],
        [ 8374],
        [10787],
        [ 7669],
        [10790],
        [ 3415],
        [ 5837],
        [ 6595],
        [10168],
        [ 4152],
        [ 6238]], device='cuda:0')
[2024-07-24 10:29:40,119][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[7185],
        [7404],
        [4998],
        [7280],
        [6359],
        [5617],
        [7073],
        [5676],
        [4247],
        [4689],
        [4721],
        [4686],
        [4290],
        [4389],
        [6213],
        [6750],
        [5912]], device='cuda:0')
[2024-07-24 10:29:40,120][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[17756],
        [18451],
        [18596],
        [15912],
        [16098],
        [17382],
        [17791],
        [13328],
        [15819],
        [18401],
        [16004],
        [17178],
        [14189],
        [18137],
        [19227],
        [19577],
        [19488]], device='cuda:0')
[2024-07-24 10:29:40,122][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[31394],
        [33584],
        [35435],
        [29650],
        [25858],
        [25311],
        [23983],
        [30657],
        [27592],
        [23144],
        [28098],
        [26854],
        [27203],
        [27253],
        [26674],
        [29631],
        [29139]], device='cuda:0')
[2024-07-24 10:29:40,124][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[28907],
        [24155],
        [21185],
        [26284],
        [31042],
        [24585],
        [26123],
        [23256],
        [20413],
        [14278],
        [27282],
        [22233],
        [31733],
        [29729],
        [24128],
        [29069],
        [27522]], device='cuda:0')
[2024-07-24 10:29:40,125][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[49531],
        [49495],
        [49329],
        [49626],
        [48336],
        [48408],
        [46943],
        [49293],
        [46657],
        [47209],
        [47436],
        [48210],
        [45873],
        [47040],
        [44159],
        [43284],
        [42284]], device='cuda:0')
[2024-07-24 10:29:40,127][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[15296],
        [14962],
        [17792],
        [29204],
        [21244],
        [15358],
        [15411],
        [12372],
        [15308],
        [16447],
        [17338],
        [11614],
        [15306],
        [15194],
        [18629],
        [16718],
        [16460]], device='cuda:0')
[2024-07-24 10:29:40,129][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[38728],
        [38932],
        [41175],
        [41985],
        [41410],
        [42108],
        [44163],
        [43066],
        [41544],
        [45411],
        [43127],
        [42254],
        [42832],
        [44440],
        [42113],
        [46162],
        [45524]], device='cuda:0')
[2024-07-24 10:29:40,131][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[29103],
        [29103],
        [32885],
        [31241],
        [32280],
        [32216],
        [41399],
        [30569],
        [31719],
        [34653],
        [31165],
        [43160],
        [31252],
        [31450],
        [34633],
        [41270],
        [34091]], device='cuda:0')
[2024-07-24 10:29:40,132][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 7987],
        [ 7368],
        [ 7921],
        [ 7669],
        [ 7762],
        [ 7821],
        [ 7400],
        [ 7966],
        [ 7876],
        [ 7782],
        [ 7707],
        [ 9554],
        [ 7725],
        [ 7870],
        [ 7769],
        [13682],
        [ 8402]], device='cuda:0')
[2024-07-24 10:29:40,134][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[16934],
        [12445],
        [14550],
        [22433],
        [17184],
        [14760],
        [18654],
        [13340],
        [17263],
        [17685],
        [18958],
        [19714],
        [13416],
        [15592],
        [14008],
        [11197],
        [13939]], device='cuda:0')
[2024-07-24 10:29:40,136][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[20378],
        [19885],
        [18917],
        [18002],
        [18595],
        [16625],
        [14554],
        [15860],
        [15901],
        [15403],
        [16163],
        [15364],
        [17997],
        [16414],
        [14917],
        [15266],
        [15834]], device='cuda:0')
[2024-07-24 10:29:40,138][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[16303],
        [16437],
        [16587],
        [16330],
        [17128],
        [16693],
        [18766],
        [16742],
        [18481],
        [19249],
        [17131],
        [16942],
        [16885],
        [16747],
        [19230],
        [19388],
        [17050]], device='cuda:0')
[2024-07-24 10:29:40,140][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[28483],
        [28747],
        [28270],
        [25462],
        [24466],
        [25767],
        [25737],
        [24744],
        [26010],
        [27301],
        [26413],
        [26796],
        [25562],
        [25279],
        [25135],
        [26268],
        [25833]], device='cuda:0')
[2024-07-24 10:29:40,142][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[21529],
        [21018],
        [18378],
        [13542],
        [14836],
        [13853],
        [11505],
        [13725],
        [14325],
        [14500],
        [13814],
        [15008],
        [14268],
        [19866],
        [18659],
        [17687],
        [16564]], device='cuda:0')
[2024-07-24 10:29:40,144][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[26228],
        [40110],
        [43043],
        [36938],
        [35207],
        [36701],
        [35269],
        [37181],
        [37102],
        [39052],
        [38352],
        [37688],
        [41369],
        [38837],
        [36560],
        [34734],
        [37429]], device='cuda:0')
[2024-07-24 10:29:40,145][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[5432],
        [4000],
        [2715],
        [3469],
        [3658],
        [4131],
        [5050],
        [3232],
        [3592],
        [5648],
        [4874],
        [5340],
        [4906],
        [5156],
        [4794],
        [7952],
        [5636]], device='cuda:0')
[2024-07-24 10:29:40,147][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[15483],
        [11321],
        [10205],
        [11962],
        [13554],
        [11066],
        [14137],
        [10812],
        [13469],
        [27337],
        [13093],
        [17143],
        [16000],
        [14525],
        [18014],
        [13229],
        [17988]], device='cuda:0')
[2024-07-24 10:29:40,149][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[27208],
        [26210],
        [19175],
        [23756],
        [17179],
        [17362],
        [16715],
        [18791],
        [16132],
        [17659],
        [14390],
        [15887],
        [14745],
        [14374],
        [13402],
        [11750],
        [10756]], device='cuda:0')
[2024-07-24 10:29:40,150][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[21826],
        [21826],
        [21840],
        [21940],
        [21838],
        [21831],
        [21831],
        [21828],
        [21828],
        [21654],
        [21816],
        [21813],
        [21815],
        [21794],
        [21153],
        [21800],
        [21749]], device='cuda:0')
[2024-07-24 10:29:40,152][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[34293],
        [35410],
        [43756],
        [42534],
        [41326],
        [43375],
        [47606],
        [44406],
        [41877],
        [48638],
        [45446],
        [44076],
        [44792],
        [46525],
        [42970],
        [48089],
        [47691]], device='cuda:0')
[2024-07-24 10:29:40,154][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[13596],
        [13598],
        [15378],
        [14653],
        [15370],
        [15213],
        [26509],
        [14397],
        [14942],
        [18259],
        [14741],
        [32167],
        [14669],
        [14856],
        [17119],
        [25799],
        [17321]], device='cuda:0')
[2024-07-24 10:29:40,156][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 9233],
        [ 8738],
        [ 9164],
        [ 8800],
        [ 8865],
        [ 9075],
        [ 8739],
        [ 9180],
        [ 9160],
        [ 9155],
        [ 9076],
        [13395],
        [ 9124],
        [ 9134],
        [ 8957],
        [11819],
        [ 9058]], device='cuda:0')
[2024-07-24 10:29:40,157][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[27175],
        [27999],
        [28390],
        [30617],
        [31150],
        [31075],
        [26880],
        [31549],
        [30776],
        [23176],
        [30582],
        [23519],
        [29774],
        [27986],
        [28139],
        [23281],
        [27848]], device='cuda:0')
[2024-07-24 10:29:40,159][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[30849],
        [34522],
        [31576],
        [27419],
        [31059],
        [32385],
        [29551],
        [33997],
        [29769],
        [30436],
        [28833],
        [27797],
        [35232],
        [31693],
        [32943],
        [36980],
        [33229]], device='cuda:0')
[2024-07-24 10:29:40,160][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712]], device='cuda:0')
