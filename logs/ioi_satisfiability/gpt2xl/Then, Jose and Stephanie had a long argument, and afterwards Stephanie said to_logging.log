[2024-07-24 10:25:35,140][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isThen, Jose and Stephanie had a long argument, and afterwards Stephanie said to
[2024-07-24 10:25:35,140][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Jose
[2024-07-24 10:25:35,140][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:25:35,140][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:25:35,140][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:25:35,140][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,140][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:25:35,140][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,140][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:25:35,141][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,141][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:25:35,141][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:25:35,141][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:25:35,141][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,141][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:25:35,141][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,141][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:25:35,141][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,141][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:25:35,141][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit5', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,141][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:25:35,141][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,141][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:25:35,141][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,142][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:25:35,142][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,142][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:25:35,142][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit4', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,142][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:25:35,142][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,142][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:25:35,142][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit5', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,142][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:25:35,142][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,142][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:25:35,142][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit26']
[2024-07-24 10:25:35,142][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:25:35,142][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,143][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:25:35,143][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit19', 'circuit26']
[2024-07-24 10:25:35,143][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:25:35,143][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,143][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:25:35,143][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,143][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:25:35,143][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit22', 'circuit26']
[2024-07-24 10:25:35,143][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:25:35,143][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,143][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:25:35,143][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,143][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:25:35,143][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13']
[2024-07-24 10:25:35,143][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:25:35,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,144][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:25:35,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,144][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:25:35,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,144][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:25:35,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,144][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:25:35,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,144][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:25:35,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,144][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,144][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:25:35,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,145][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,145][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:25:35,145][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,145][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit11', 'circuit13', 'circuit20', 'circuit26']
[2024-07-24 10:25:35,145][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:25:35,145][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,145][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,145][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:25:35,145][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18', 'circuit21', 'circuit23']
[2024-07-24 10:25:35,145][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,145][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:25:35,145][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:25:35,145][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,145][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:25:35,145][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:25:35,146][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,146][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:25:35,146][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:25:35,146][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,146][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:25:35,146][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit26']
[2024-07-24 10:25:35,146][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit19']
[2024-07-24 10:25:35,146][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:25:35,146][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,146][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit23']
[2024-07-24 10:25:35,146][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:25:35,146][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,146][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:25:35,146][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:25:35,146][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,147][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,147][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:25:35,147][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,147][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,147][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:25:35,147][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,147][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,147][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:25:35,147][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,147][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,147][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:25:35,147][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,147][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,147][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:25:35,148][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit21', 'circuit24']
[2024-07-24 10:25:35,148][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,148][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:25:35,148][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:25:35,148][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:25:35,148][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:25:35,148][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit20', 'circuit24']
[2024-07-24 10:25:35,148][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,148][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:25:35,148][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:25:35,148][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,148][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:25:35,148][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:35,148][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:25:35,148][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:25:35,149][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,149][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,149][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:25:35,149][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:25:35,149][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:25:35,149][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:25:35,149][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:25:35,149][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,149][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:25:35,149][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,149][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,149][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:25:35,149][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,149][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:25:35,149][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:25:35,150][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,150][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,150][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:25:35,150][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,150][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,150][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:25:35,150][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,150][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,150][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:25:35,150][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,150][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,150][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,150][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:25:35,150][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,151][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit13', 'circuit15', 'circuit16', 'circuit19', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:25:35,151][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:25:35,151][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:25:35,151][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:25:35,151][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,151][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:25:35,151][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:25:35,151][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,151][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit17']
[2024-07-24 10:25:35,151][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,151][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:25:35,151][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit22']
[2024-07-24 10:25:35,151][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:25:35,151][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,151][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:25:35,152][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit19', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,152][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,152][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,152][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:25:35,152][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,152][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,152][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,152][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:25:35,152][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,152][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,152][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,152][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:25:35,152][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18']
[2024-07-24 10:25:35,152][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:25:35,153][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15']
[2024-07-24 10:25:35,153][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:25:35,153][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:25:35,153][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:25:35,153][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:25:35,153][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:25:35,153][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,153][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,153][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,153][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:25:35,153][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,153][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,153][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,153][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:25:35,153][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:25:35,154][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:25:35,154][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit19', 'circuit20']
[2024-07-24 10:25:35,154][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:25:35,154][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,154][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,154][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit7', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,154][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:25:35,154][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:25:35,154][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:25:35,154][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,154][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:25:35,154][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:25:35,154][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:25:35,154][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:25:35,154][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:25:35,155][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18', 'circuit21', 'circuit23']
[2024-07-24 10:25:35,155][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20']
[2024-07-24 10:25:35,155][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,155][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:25:35,155][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,155][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:25:35,155][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,155][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:25:35,155][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,155][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit26']
[2024-07-24 10:25:35,155][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:25:35,155][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:25:35,155][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:25:35,155][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit13', 'circuit17', 'circuit20', 'circuit24']
[2024-07-24 10:25:35,156][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,156][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:25:35,156][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,156][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,156][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,156][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:25:35,156][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit27']
[2024-07-24 10:25:35,156][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:25:35,156][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit23']
[2024-07-24 10:25:35,156][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:25:35,156][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22']
[2024-07-24 10:25:35,156][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,156][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,156][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:25:35,156][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,157][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,157][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,157][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:25:35,157][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,157][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,157][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit26']
[2024-07-24 10:25:35,157][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:25:35,157][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,157][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,157][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,157][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:25:35,157][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,157][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,157][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,158][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:25:35,158][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,158][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,158][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,158][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:25:35,158][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,158][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,158][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,158][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:25:35,158][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,158][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,158][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,158][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,158][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:25:35,159][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,159][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,159][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,159][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,159][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:25:35,159][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,159][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit19', 'circuit20', 'circuit25']
[2024-07-24 10:25:35,159][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit24']
[2024-07-24 10:25:35,159][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,159][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:25:35,159][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,159][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,159][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit24']
[2024-07-24 10:25:35,159][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit14', 'circuit15']
[2024-07-24 10:25:35,159][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:25:35,160][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,160][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,160][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit26']
[2024-07-24 10:25:35,160][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,160][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:25:35,160][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,160][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit8', 'circuit10', 'circuit19', 'circuit20', 'circuit26']
[2024-07-24 10:25:35,160][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,160][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,160][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:25:35,160][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,160][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,160][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit24']
[2024-07-24 10:25:35,160][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit17', 'circuit19']
[2024-07-24 10:25:35,160][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:25:35,161][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,161][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,161][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,161][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21']
[2024-07-24 10:25:35,161][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:25:35,161][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:25:35,161][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,161][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,161][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,161][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:25:35,161][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,161][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,161][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,161][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit19', 'circuit20', 'circuit23', 'circuit26']
[2024-07-24 10:25:35,162][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:25:35,162][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,162][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,162][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,162][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:25:35,162][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:25:35,162][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,162][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit8', 'circuit10', 'circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,162][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit7', 'circuit13', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit26']
[2024-07-24 10:25:35,162][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit26']
[2024-07-24 10:25:35,162][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:25:35,162][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,162][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,162][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,162][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16']
[2024-07-24 10:25:35,163][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:25:35,163][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,163][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,163][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,163][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,163][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:25:35,163][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,163][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,163][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,163][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,163][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:25:35,163][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,163][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,163][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,164][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:25:35,164][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:25:35,164][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit20', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,164][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:25:35,164][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:25:35,164][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,164][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:25:35,164][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:25:35,164][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19']
[2024-07-24 10:25:35,164][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,164][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:35,164][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:25:35,164][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,164][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:25:35,164][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17']
[2024-07-24 10:25:35,165][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,165][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:25:35,165][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,165][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,165][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,165][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,165][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:25:35,165][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,165][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit13']
[2024-07-24 10:25:35,165][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit5', 'circuit6', 'circuit11', 'circuit14']
[2024-07-24 10:25:35,165][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:25:35,165][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:25:35,165][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit18']
[2024-07-24 10:25:35,165][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,166][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,166][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,166][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:25:35,166][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit22', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,166][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:25:35,166][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:25:35,166][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,166][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:25:35,166][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit19', 'circuit24']
[2024-07-24 10:25:35,166][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,166][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,166][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,166][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:25:35,166][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit28']
[2024-07-24 10:25:35,166][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,167][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,167][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,167][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:25:35,167][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,167][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,167][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,167][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,167][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:25:35,167][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,167][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,167][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,167][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,167][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:25:35,167][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,167][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,168][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,168][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,168][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:25:35,168][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,168][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,168][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,168][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,168][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:25:35,168][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,168][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,168][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,168][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,168][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,168][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:25:35,169][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,169][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,169][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,169][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,169][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,169][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:25:35,169][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,169][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,169][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,169][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,169][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,169][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:25:35,169][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,169][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19']
[2024-07-24 10:25:35,170][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,170][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,170][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:25:35,170][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:25:35,170][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,170][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,170][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,170][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:25:35,170][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,170][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:25:35,170][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,170][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,170][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit26']
[2024-07-24 10:25:35,170][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,170][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:25:35,171][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:25:35,171][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,171][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,171][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,171][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,171][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,171][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:25:35,171][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,171][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,171][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,171][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,171][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,171][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:25:35,171][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,172][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,172][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:25:35,172][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit9', 'circuit13', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:25:35,172][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit24']
[2024-07-24 10:25:35,172][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:25:35,172][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,172][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,172][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,172][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,172][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,172][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:25:35,172][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,172][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,172][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,173][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,173][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,173][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:25:35,173][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,173][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:25:35,173][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:25:35,173][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,173][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:25:35,173][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:25:35,173][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,173][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit13', 'circuit14', 'circuit20', 'circuit21', 'circuit22', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,173][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit26']
[2024-07-24 10:25:35,173][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:25:35,173][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:25:35,173][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:25:35,174][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,174][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,174][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,174][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,174][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,174][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:25:35,174][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,174][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,174][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,174][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,174][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,174][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:25:35,174][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,174][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,175][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,175][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,175][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,175][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:25:35,175][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,175][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit4', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,175][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,175][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,175][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,175][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:25:35,175][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit18']
[2024-07-24 10:25:35,175][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:25:35,175][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,175][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25', 'circuit26']
[2024-07-24 10:25:35,176][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,176][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:25:35,176][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:25:35,176][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,176][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,176][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,176][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,176][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:25:35,176][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,176][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:25:35,176][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,176][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,176][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:25:35,176][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:25:35,176][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit26']
[2024-07-24 10:25:35,177][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,177][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,177][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit23']
[2024-07-24 10:25:35,177][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:25:35,177][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:25:35,177][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,177][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit28']
[2024-07-24 10:25:35,177][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:35,177][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:25:35,177][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,177][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:25:35,177][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,177][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,177][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,178][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit25']
[2024-07-24 10:25:35,178][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,178][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:25:35,178][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,178][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,178][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,178][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,178][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,178][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:25:35,178][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,178][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,178][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,178][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,178][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,178][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:25:35,179][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit27']
[2024-07-24 10:25:35,179][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,179][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,179][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,179][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24', 'circuit26']
[2024-07-24 10:25:35,179][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:25:35,179][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,179][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,179][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,179][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,179][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,179][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:25:35,179][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,179][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,180][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,180][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,180][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,180][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:25:35,180][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,180][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,180][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,180][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,180][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,180][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:25:35,180][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,180][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,180][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit7', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,180][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,181][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,181][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,181][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:25:35,181][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,181][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit22']
[2024-07-24 10:25:35,181][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,181][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:35,181][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,181][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,181][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:25:35,181][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,181][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,181][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit10', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,181][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit20', 'circuit23', 'circuit25']
[2024-07-24 10:25:35,181][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:25:35,182][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:35,182][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:25:35,182][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,182][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit10', 'circuit13', 'circuit17', 'circuit19', 'circuit20']
[2024-07-24 10:25:35,182][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:25:35,182][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit19', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,182][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,182][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,182][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:25:35,182][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,182][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:25:35,182][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,182][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit25']
[2024-07-24 10:25:35,182][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,183][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,183][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:25:35,183][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,183][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit11', 'circuit14', 'circuit15', 'circuit17', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,183][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,183][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit21']
[2024-07-24 10:25:35,183][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit20']
[2024-07-24 10:25:35,183][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,183][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:25:35,183][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,183][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,183][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,183][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,183][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,183][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,184][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:25:35,184][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,184][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit16', 'circuit26']
[2024-07-24 10:25:35,184][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit23']
[2024-07-24 10:25:35,184][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit23', 'circuit26']
[2024-07-24 10:25:35,184][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:25:35,184][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit15', 'circuit23', 'circuit25']
[2024-07-24 10:25:35,184][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:25:35,184][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,184][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,184][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,184][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,184][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,184][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,184][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:25:35,185][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:25:35,185][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,185][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,185][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,185][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,185][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,185][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:25:35,185][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,185][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,185][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,185][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,185][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit6', 'circuit14', 'circuit17', 'circuit18', 'circuit20', 'circuit26']
[2024-07-24 10:25:35,185][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,185][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:25:35,186][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,186][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit6', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit26']
[2024-07-24 10:25:35,186][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit6', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,186][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit1', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,186][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,186][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit4', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,186][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:25:35,186][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:35,186][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,186][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,186][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,186][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,186][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,186][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:25:35,186][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,187][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,187][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,187][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,187][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,187][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,187][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:25:35,187][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,187][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,187][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,187][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,187][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,187][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,187][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:25:35,187][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,188][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,188][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,188][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,188][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,188][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,188][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:25:35,188][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,188][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,188][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,188][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,188][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,188][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,188][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:25:35,188][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,188][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,189][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,189][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,189][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,189][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,189][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:25:35,189][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,189][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,189][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,189][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,189][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,189][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,189][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:25:35,189][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,189][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,189][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,190][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,190][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,190][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,190][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:25:35,190][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,190][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,190][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,190][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,190][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,190][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,190][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:25:35,190][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,190][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,190][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,190][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,191][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,191][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,191][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:25:35,191][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,191][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,191][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,191][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,191][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,191][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,191][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:25:35,191][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,191][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,191][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,191][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,191][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,192][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,192][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:25:35,192][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,192][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,192][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,192][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,192][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,192][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,192][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:25:35,192][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,192][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,192][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,192][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,192][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,193][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,193][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:25:35,193][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,193][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,193][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,193][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,193][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,193][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,193][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:25:35,193][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,193][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,193][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,193][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,193][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,194][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,194][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:25:35,194][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,194][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,194][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,194][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,194][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,194][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,194][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:25:35,194][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,194][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,194][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,194][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,194][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,194][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit6', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,195][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,195][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:25:35,195][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,195][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,195][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,195][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,195][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,195][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,195][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,195][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:25:35,195][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,195][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:25:35,195][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:25:35,195][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,196][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,196][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,196][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24']
[2024-07-24 10:25:35,196][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:25:35,196][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,196][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:25:35,196][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,196][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit2', 'circuit3', 'circuit10', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:25:35,196][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,196][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,196][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:25:35,196][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:25:35,196][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:25:35,196][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,196][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:25:35,197][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,197][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,197][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,197][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:25:35,197][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:25:35,197][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,197][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,197][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,197][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,197][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,197][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,197][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,197][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:25:35,197][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,198][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,198][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,198][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,198][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,198][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,198][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,198][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:25:35,198][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,198][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,198][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,198][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,198][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,198][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,198][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,198][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:25:35,199][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,199][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,199][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,199][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,199][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,199][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,199][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,199][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:25:35,199][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,199][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,199][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,199][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,199][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,199][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,199][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,200][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:25:35,200][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,200][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,200][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,200][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,200][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,200][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,200][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,200][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:25:35,200][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,200][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,200][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,200][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,200][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,201][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,201][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit14', 'circuit17', 'circuit19']
[2024-07-24 10:25:35,201][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:25:35,201][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit23']
[2024-07-24 10:25:35,201][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,201][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,201][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,201][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,201][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,201][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,201][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:25:35,201][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,201][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,201][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:25:35,201][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,202][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,202][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit21']
[2024-07-24 10:25:35,202][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit19', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,202][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:25:35,202][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,202][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,202][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,202][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,202][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,202][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,202][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,202][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:25:35,202][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,202][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,202][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,203][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,203][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,203][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,203][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,203][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:25:35,203][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,203][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,203][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,203][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,203][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,203][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,203][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,203][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:25:35,203][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,204][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,204][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,204][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,204][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,204][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,204][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,204][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:25:35,204][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,204][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,204][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,204][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,204][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,204][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,204][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,204][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:25:35,205][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,205][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,205][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,205][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,205][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,205][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,205][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,205][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:25:35,205][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,205][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,205][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,205][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,205][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,205][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,205][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,206][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:25:35,206][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,206][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,206][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,206][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,206][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,206][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,206][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,206][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:25:35,206][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,206][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,206][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,206][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,206][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,207][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,207][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,207][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:25:35,207][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,207][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,207][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,207][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,207][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,207][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,207][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,207][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:25:35,207][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,207][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,207][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,207][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,208][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,208][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,208][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,208][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:25:35,208][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,208][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,208][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,208][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,208][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,208][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,208][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,208][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:25:35,208][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,208][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,209][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,209][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,209][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,209][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,209][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,209][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:25:35,209][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,209][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,209][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,209][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,209][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,209][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,209][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,209][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:25:35,209][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,210][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,210][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,210][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,210][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,210][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,210][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,210][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:25:35,210][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,210][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,210][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,210][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,210][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,210][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,210][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,211][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit7', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,211][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:25:35,211][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,211][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,211][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit19', 'circuit25']
[2024-07-24 10:25:35,211][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:35,211][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,211][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,211][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,211][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,211][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:25:35,211][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,211][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,211][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,212][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16']
[2024-07-24 10:25:35,212][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,212][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,212][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,212][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,212][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:25:35,212][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,212][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,212][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-24 10:25:35,212][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit25']
[2024-07-24 10:25:35,212][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,212][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,212][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,212][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,212][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:25:35,213][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,213][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,213][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,213][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,213][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,213][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,213][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,213][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,213][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:25:35,213][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,213][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit4', 'circuit13']
[2024-07-24 10:25:35,213][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,213][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,213][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14']
[2024-07-24 10:25:35,213][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,214][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,214][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,214][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:25:35,214][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,214][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:25:35,214][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,214][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,214][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,214][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,214][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit27']
[2024-07-24 10:25:35,214][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,214][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:25:35,214][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22']
[2024-07-24 10:25:35,214][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,215][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,215][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,215][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,215][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,215][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,215][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,215][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:25:35,215][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,215][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,215][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,215][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,215][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,215][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,215][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,215][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,216][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:25:35,216][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,216][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit22', 'circuit25']
[2024-07-24 10:25:35,216][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,216][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:35,216][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,216][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,216][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,216][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit13', 'circuit25']
[2024-07-24 10:25:35,216][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:25:35,216][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit27']
[2024-07-24 10:25:35,216][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:25:35,216][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit22']
[2024-07-24 10:25:35,216][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,216][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,217][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,217][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,217][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,217][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:25:35,217][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,217][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,217][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,217][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,217][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,217][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,217][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,217][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,217][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:25:35,217][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:25:35,218][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,218][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,218][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,218][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,218][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,218][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit2', 'circuit6', 'circuit8', 'circuit13', 'circuit14', 'circuit16']
[2024-07-24 10:25:35,218][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:25:35,218][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:25:35,218][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit27']
[2024-07-24 10:25:35,218][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:25:35,218][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit24']
[2024-07-24 10:25:35,218][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,218][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,218][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,218][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,219][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,219][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:25:35,219][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,219][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,219][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,219][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,219][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,219][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,219][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,219][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,219][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:25:35,219][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,219][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,219][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,220][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,220][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,220][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,220][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,220][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,220][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:25:35,220][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,220][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,220][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,220][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,220][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,220][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,220][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,220][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,220][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:25:35,221][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,221][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,221][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,221][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,221][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,221][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,221][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,221][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,221][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:25:35,221][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,221][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,221][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,221][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,221][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,221][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,222][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,222][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,222][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:25:35,222][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,222][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,222][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,222][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,222][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,222][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,222][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,222][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,222][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:25:35,222][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,222][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,222][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,223][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,223][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,223][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,223][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,223][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,223][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:25:35,223][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,223][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,223][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,223][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,223][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,223][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,223][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,223][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,224][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:25:35,224][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,224][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,224][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,224][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,224][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,224][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,224][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,224][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,224][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:25:35,224][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,224][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,224][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,224][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,224][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,225][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,225][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,225][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,225][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:25:35,225][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,225][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,225][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,225][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,225][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,225][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,225][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,225][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,225][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:25:35,225][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,225][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,226][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,226][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,226][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,226][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,226][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,226][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,226][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:25:35,226][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,226][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,226][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,226][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,226][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,226][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,226][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,227][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,227][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:25:35,227][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,227][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,227][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,227][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,227][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,227][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,227][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,227][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,227][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:25:35,227][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,227][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,227][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,228][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,228][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,228][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,228][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,228][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,228][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:25:35,228][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,228][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,228][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,228][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit4', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,228][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,228][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,228][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,228][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,229][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,229][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:25:35,229][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,229][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,229][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,229][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,229][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,229][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,229][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,229][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,229][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,229][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:25:35,229][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,229][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,229][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,230][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,230][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,230][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,230][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,230][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,230][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,230][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:25:35,230][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24']
[2024-07-24 10:25:35,230][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,230][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:25:35,230][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:25:35,230][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,230][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:25:35,230][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:25:35,230][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit25']
[2024-07-24 10:25:35,231][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit12', 'circuit13', 'circuit14']
[2024-07-24 10:25:35,231][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:25:35,231][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,231][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,231][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,231][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,231][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,231][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,231][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,231][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,231][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,231][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:25:35,231][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,231][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:25:35,232][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,232][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,232][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,232][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,232][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,232][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,232][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,232][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:25:35,232][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,232][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,232][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,232][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:35,232][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,232][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,232][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,233][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,233][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,233][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:25:35,233][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20']
[2024-07-24 10:25:35,233][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:25:35,233][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:25:35,233][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,233][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17']
[2024-07-24 10:25:35,233][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,233][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,233][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,233][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit1', 'circuit13', 'circuit16', 'circuit17']
[2024-07-24 10:25:35,233][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:25:35,233][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,234][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,234][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,234][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,234][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,234][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,234][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,234][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,234][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,234][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:25:35,234][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,234][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit26']
[2024-07-24 10:25:35,234][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,234][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,234][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,234][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,235][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,235][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit13', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,235][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,235][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:25:35,235][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,235][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit22']
[2024-07-24 10:25:35,235][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,235][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:35,235][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:25:35,235][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:25:35,235][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit24']
[2024-07-24 10:25:35,235][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit17', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:25:35,235][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,235][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:25:35,235][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,236][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,236][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,236][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,236][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,236][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,236][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,236][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit15', 'circuit18', 'circuit21', 'circuit23']
[2024-07-24 10:25:35,236][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,236][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:25:35,236][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit24']
[2024-07-24 10:25:35,236][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,236][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:25:35,236][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,236][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,237][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,237][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,237][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,237][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,237][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:25:35,237][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:25:35,237][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,237][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,237][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,237][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit18']
[2024-07-24 10:25:35,237][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:35,237][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit17', 'circuit21', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,237][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit20']
[2024-07-24 10:25:35,237][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,237][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:25:35,238][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,238][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,238][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,238][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,238][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,238][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,238][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,238][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,238][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,238][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:25:35,238][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,238][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,238][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,238][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,239][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,239][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,239][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,239][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,239][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,239][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:25:35,239][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,239][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,239][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,239][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,239][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,239][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,239][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,239][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,239][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,240][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:25:35,240][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,240][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,240][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,240][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,240][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,240][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,240][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,240][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,240][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,240][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:25:35,240][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,240][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,240][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,240][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,241][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,241][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,241][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,241][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,241][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,241][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:25:35,241][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,241][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,241][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,241][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,241][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,241][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,241][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,241][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,242][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,242][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:25:35,242][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,242][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,242][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,242][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,242][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,242][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,242][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,242][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,242][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,242][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:25:35,242][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,242][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,242][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,243][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,243][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,243][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,243][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,243][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,243][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,243][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:25:35,243][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,243][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,243][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,243][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,243][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,243][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,243][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,243][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,244][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,244][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:25:35,244][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,244][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,244][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,244][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,244][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,244][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,244][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,244][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,244][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,244][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:25:35,244][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,244][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,244][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,245][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,245][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,245][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,245][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,245][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,245][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,245][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:25:35,245][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,245][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,245][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,245][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,245][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,245][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,245][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,246][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,246][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,246][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:25:35,246][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,246][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,246][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,246][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,246][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,246][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,246][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,246][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,246][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,246][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:25:35,246][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,247][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,247][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,247][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,247][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,247][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,247][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,247][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,247][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,247][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:25:35,247][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,247][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,247][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,247][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,247][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,247][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,248][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,248][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,248][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,248][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:25:35,248][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,248][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,248][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,248][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,248][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,248][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,248][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,248][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,248][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit4', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,248][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,249][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:25:35,249][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit21', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,249][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,249][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,249][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,249][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:25:35,249][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16']
[2024-07-24 10:25:35,249][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,249][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit21', 'circuit24']
[2024-07-24 10:25:35,249][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13']
[2024-07-24 10:25:35,249][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit7', 'circuit9', 'circuit19', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:25:35,249][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:25:35,249][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,249][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,250][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,250][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,250][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,250][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,250][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:25:35,250][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,250][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:25:35,250][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit8', 'circuit9']
[2024-07-24 10:25:35,250][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:25:35,250][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit20', 'circuit23', 'circuit27']
[2024-07-24 10:25:35,250][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,250][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,250][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,250][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,250][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,251][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,251][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit13', 'circuit21']
[2024-07-24 10:25:35,251][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,251][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,251][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:25:35,251][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,251][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,251][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,251][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22']
[2024-07-24 10:25:35,251][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,251][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,251][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,251][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:25:35,251][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,252][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:25:35,252][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:25:35,252][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit20', 'circuit23']
[2024-07-24 10:25:35,252][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,252][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,252][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,252][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,252][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:25:35,252][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,252][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21']
[2024-07-24 10:25:35,252][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:25:35,252][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,252][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:25:35,252][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:35,252][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:25:35,253][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit23']
[2024-07-24 10:25:35,253][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,253][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:25:35,253][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,253][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:25:35,253][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,253][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,253][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,253][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:25:35,253][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,253][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,253][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,253][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,253][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,254][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,254][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,254][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,254][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,254][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit22']
[2024-07-24 10:25:35,254][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:25:35,254][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,254][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,254][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,254][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,254][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,254][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,254][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,254][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,254][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,255][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,255][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:25:35,255][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,255][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,255][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,255][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,255][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,255][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,255][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,255][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,255][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,255][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,255][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:25:35,255][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,255][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,256][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,256][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,256][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,256][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,256][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,256][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,256][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,256][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,256][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:25:35,256][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:25:35,256][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,256][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,256][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,256][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,256][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,257][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,257][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,257][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,257][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,257][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:25:35,257][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,257][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,257][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,257][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,257][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,257][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,257][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,257][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,257][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,258][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,258][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:25:35,258][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:25:35,258][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,258][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22']
[2024-07-24 10:25:35,258][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23']
[2024-07-24 10:25:35,258][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:35,258][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,258][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,258][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,258][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,258][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,258][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:25:35,258][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,258][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,259][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,259][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,259][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,259][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,259][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,259][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,259][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,259][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,259][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:25:35,259][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,259][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,259][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,259][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,259][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,259][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,260][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,260][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,260][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,260][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,260][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:25:35,260][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,260][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,260][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,260][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,260][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,260][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,260][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,260][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,260][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,261][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,261][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:25:35,261][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,261][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,261][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,261][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,261][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,261][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,261][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,261][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,261][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,261][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,261][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:25:35,261][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,261][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,262][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,262][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,262][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,262][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,262][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,262][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,262][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,262][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,262][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:25:35,262][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,262][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,262][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,262][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,262][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,262][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,263][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,263][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,263][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,263][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,263][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:25:35,263][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,263][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,263][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,263][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,263][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,263][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,263][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,263][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,263][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,264][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,264][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:25:35,264][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,264][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,264][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,264][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,264][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,264][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,264][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,264][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,264][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,264][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,264][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:25:35,264][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,264][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,265][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,265][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,265][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,265][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,265][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,265][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,265][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,265][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,265][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:25:35,265][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,265][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,265][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,265][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,265][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,265][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,266][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,266][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,266][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,266][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,266][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:25:35,266][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,266][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,266][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,266][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,266][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,266][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,266][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,266][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,266][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,267][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,267][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:25:35,267][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,267][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,267][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,267][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,267][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,267][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,267][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,267][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,267][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,267][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,267][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:25:35,267][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,267][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,268][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,268][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,268][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,268][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,268][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,268][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,268][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,268][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,268][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:25:35,268][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,268][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,268][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,268][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,268][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,269][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,269][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,269][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,269][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,269][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,269][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:25:35,269][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,269][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,269][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,269][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,269][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,269][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,269][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,269][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,270][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,270][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,270][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:25:35,270][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,270][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,270][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,270][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,270][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,270][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit5', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,270][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,270][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:25:35,270][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,270][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,270][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,271][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:25:35,271][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,271][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,271][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,271][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,271][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,271][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,271][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,271][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,271][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,271][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,271][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:35,271][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:25:35,271][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:25:35,271][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,272][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,272][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,272][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,272][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,272][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,272][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,272][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,272][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,272][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:35,272][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:25:35,272][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,272][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,272][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,272][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,273][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,273][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,273][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,273][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:25:35,273][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,273][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,273][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:25:35,273][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:25:35,273][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,273][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,273][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,273][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,273][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,273][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,273][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,274][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit8']
[2024-07-24 10:25:35,274][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit2', 'circuit12', 'circuit27']
[2024-07-24 10:25:35,274][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,274][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit3']
[2024-07-24 10:25:35,274][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:25:35,274][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,274][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,274][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,274][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,274][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,274][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,274][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,274][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,274][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,274][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,275][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:35,275][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:25:35,275][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,275][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,275][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,275][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,275][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,275][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,275][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,275][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,275][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,275][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,275][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:35,275][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:25:35,276][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit25']
[2024-07-24 10:25:35,276][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,276][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,276][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,276][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,276][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,276][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,276][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,276][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,276][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:25:35,276][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:35,276][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:25:35,276][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit21', 'circuit25']
[2024-07-24 10:25:35,276][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,276][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,277][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,277][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,277][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,277][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,277][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,277][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,277][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit13', 'circuit24', 'circuit25']
[2024-07-24 10:25:35,277][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:35,277][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:25:35,277][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,277][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,277][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,277][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,277][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23']
[2024-07-24 10:25:35,277][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,278][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,278][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,278][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,278][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,278][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:35,278][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:25:35,278][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,278][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,278][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,278][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,278][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,278][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,278][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,278][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,279][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,279][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,279][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:35,279][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:25:35,279][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,279][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,279][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,279][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,279][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,279][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,279][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,279][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,279][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,279][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,279][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:35,280][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:25:35,280][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,280][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,280][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,280][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,280][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,280][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,280][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,280][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,280][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,280][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,280][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:35,280][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:25:35,280][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit17', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,280][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,281][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,281][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,281][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,281][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit6', 'circuit11', 'circuit13', 'circuit16', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:35,281][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit10', 'circuit11', 'circuit12', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:25:35,281][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit21', 'circuit22', 'circuit26', 'circuit27']
[2024-07-24 10:25:35,281][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit21', 'circuit24']
[2024-07-24 10:25:35,281][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit13', 'circuit22', 'circuit25']
[2024-07-24 10:25:35,281][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:35,281][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:25:35,281][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,281][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,281][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,281][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,282][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,282][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,282][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,282][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,282][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,282][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,282][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:35,282][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:25:35,282][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,282][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,282][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,282][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,282][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,282][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,282][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,283][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,283][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,283][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,283][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:35,283][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:25:35,283][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,283][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,283][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,283][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,283][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,283][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,283][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,283][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,283][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,284][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,284][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:35,284][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:25:35,284][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,284][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,284][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,284][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,284][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,284][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,284][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,284][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,284][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,284][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,284][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:35,284][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:25:35,285][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,285][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,285][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,285][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,285][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,285][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,285][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,285][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,285][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,285][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,285][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:35,285][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:25:35,285][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,285][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,285][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,286][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,286][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,286][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,286][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,286][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,286][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,286][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,286][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:35,286][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:25:35,286][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,286][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,286][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,286][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,286][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,287][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,287][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,287][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,287][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,287][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,287][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:35,287][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:25:35,287][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,287][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,287][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,287][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,287][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,287][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,287][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,287][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,288][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,288][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,288][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:35,288][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:25:35,288][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:25:35,288][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,288][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,288][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,288][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,288][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,288][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,288][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,288][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,288][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,288][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:35,289][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:25:35,289][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,289][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,289][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,289][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,289][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,289][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,289][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,289][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,289][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,289][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,289][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:35,289][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:25:35,289][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,290][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,290][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,290][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,290][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,290][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,290][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,290][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,290][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,290][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,290][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:35,290][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:25:35,290][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:35,290][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:35,290][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:35,290][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:35,291][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:35,291][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:35,291][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:35,291][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:35,291][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:35,291][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:35,291][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:35,291][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:25:35,291][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,291][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,291][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,291][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,291][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,291][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,291][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,292][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,292][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,292][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,292][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,292][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:25:35,292][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,292][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,292][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,292][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,292][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,292][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,292][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,292][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,292][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,293][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,293][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,293][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:25:35,293][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,293][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,293][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,293][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,293][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,293][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,293][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,293][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,293][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,293][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:35,293][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:36,465][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:36,466][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,467][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,467][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,467][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,472][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,472][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,472][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,473][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,473][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,473][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,474][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,474][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,474][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,475][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,475][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,475][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,477][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,478][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,479][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,480][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,481][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,483][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,484][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,485][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,486][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Jose] are: tensor([0.3363, 0.3533, 0.3105], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,487][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Jose] are: tensor([7.0421e-04, 2.0440e-04, 9.9909e-01], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,489][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Jose] are: tensor([0.5729, 0.2639, 0.1632], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,489][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Jose] are: tensor([2.9888e-02, 8.4627e-04, 9.6927e-01], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,491][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Jose] are: tensor([0.1361, 0.0217, 0.8422], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,492][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Jose] are: tensor([3.7819e-02, 7.4038e-06, 9.6217e-01], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,493][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Jose] are: tensor([0.4179, 0.2759, 0.3062], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,494][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Jose] are: tensor([0.5963, 0.2997, 0.1040], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,496][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Jose] are: tensor([0.5719, 0.3034, 0.1247], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,497][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Jose] are: tensor([0.6294, 0.3301, 0.0405], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,498][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Jose] are: tensor([0.4661, 0.2294, 0.3045], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,500][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Jose] are: tensor([0.5261, 0.2829, 0.1909], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,501][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.7090, 0.0803, 0.1481, 0.0626], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,502][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.3023e-03, 3.9245e-02, 5.5679e-04, 9.5790e-01], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,504][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2390, 0.1790, 0.0313, 0.5507], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,505][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1134, 0.3875, 0.0250, 0.4741], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,506][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3327, 0.1507, 0.2437, 0.2729], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,508][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1235, 0.1977, 0.0035, 0.6753], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,509][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6787, 0.0325, 0.2642, 0.0246], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,511][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2400, 0.1825, 0.3026, 0.2748], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,512][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0677, 0.4739, 0.0140, 0.4444], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,513][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4316, 0.2410, 0.1034, 0.2239], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,515][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4129, 0.3075, 0.0768, 0.2029], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,516][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4537, 0.1982, 0.0891, 0.2589], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,518][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Stephanie] are: tensor([0.2517, 0.2311, 0.2466, 0.2150, 0.0556], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,518][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Stephanie] are: tensor([8.8065e-04, 4.4198e-04, 1.7549e-03, 1.2047e-03, 9.9572e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,519][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Stephanie] are: tensor([0.4454, 0.2312, 0.0870, 0.1319, 0.1045], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,519][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Stephanie] are: tensor([1.6807e-02, 1.2756e-04, 2.5106e-03, 3.3964e-04, 9.8022e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,519][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Stephanie] are: tensor([5.9050e-03, 7.9046e-04, 1.6101e-03, 6.3901e-04, 9.9106e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,520][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Stephanie] are: tensor([2.1608e-02, 3.7303e-06, 2.9441e-05, 1.2729e-06, 9.7836e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,520][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Stephanie] are: tensor([0.2135, 0.2799, 0.1045, 0.2133, 0.1888], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,520][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Stephanie] are: tensor([0.2080, 0.1748, 0.1144, 0.3368, 0.1660], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,521][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Stephanie] are: tensor([0.3747, 0.1951, 0.1286, 0.1914, 0.1102], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,521][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Stephanie] are: tensor([0.4121, 0.2245, 0.1429, 0.1899, 0.0305], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,521][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Stephanie] are: tensor([0.2995, 0.2176, 0.0785, 0.1480, 0.2564], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,522][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Stephanie] are: tensor([0.2419, 0.2349, 0.1003, 0.2396, 0.1833], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,523][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.4241, 0.0373, 0.0261, 0.0371, 0.1488, 0.3267], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,524][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ had] are: tensor([3.2202e-04, 1.6747e-03, 7.8620e-04, 2.8605e-03, 1.0412e-04, 9.9425e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,525][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.4719, 0.1204, 0.0810, 0.1424, 0.0433, 0.1410], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,526][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0049, 0.0054, 0.0013, 0.0115, 0.0032, 0.9737], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,528][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2006, 0.0571, 0.1250, 0.1033, 0.0880, 0.4260], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,529][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ had] are: tensor([3.9829e-02, 1.8586e-03, 8.5266e-05, 1.2922e-03, 9.5623e-05, 9.5684e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,530][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.3000, 0.0224, 0.2437, 0.0210, 0.3829, 0.0301], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,531][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1050, 0.0818, 0.0776, 0.1899, 0.3096, 0.2361], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,533][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0972, 0.2730, 0.0199, 0.3586, 0.0295, 0.2219], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,534][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.3076, 0.1854, 0.0956, 0.1911, 0.0912, 0.1291], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,536][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.2481, 0.1914, 0.0788, 0.1401, 0.0373, 0.3043], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,537][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.4154, 0.1388, 0.0673, 0.1730, 0.1180, 0.0875], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,539][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.4639, 0.0534, 0.0900, 0.0404, 0.2499, 0.0666, 0.0358],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,540][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([8.5686e-04, 4.3062e-03, 3.2137e-04, 4.3042e-03, 1.6026e-04, 4.6898e-04,
        9.8958e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,541][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.3029, 0.1879, 0.0692, 0.2215, 0.0462, 0.1254, 0.0468],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,542][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0290, 0.0178, 0.0049, 0.0328, 0.0286, 0.1771, 0.7098],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,544][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1394, 0.0307, 0.0601, 0.0432, 0.0801, 0.4358, 0.2108],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,545][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0560, 0.1298, 0.0033, 0.0971, 0.0018, 0.0448, 0.6672],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,546][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3540, 0.0118, 0.2279, 0.0100, 0.3328, 0.0521, 0.0115],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,548][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0969, 0.0582, 0.0713, 0.1301, 0.1248, 0.2183, 0.3005],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,549][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0241, 0.1313, 0.0059, 0.1950, 0.0085, 0.1425, 0.4927],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,551][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2636, 0.1688, 0.0812, 0.1713, 0.0737, 0.1062, 0.1351],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,552][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2259, 0.1926, 0.0588, 0.1633, 0.0501, 0.0836, 0.2258],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,553][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.3270, 0.1311, 0.0753, 0.1408, 0.1329, 0.0845, 0.1084],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,555][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.2753, 0.0659, 0.0544, 0.0610, 0.2633, 0.1134, 0.0865, 0.0802],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:36,556][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ long] are: tensor([2.8429e-04, 9.8813e-04, 1.3066e-03, 1.4096e-03, 9.2369e-04, 3.2487e-03,
        9.3745e-04, 9.9090e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:36,557][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.2899, 0.1494, 0.1194, 0.1511, 0.0716, 0.1055, 0.0755, 0.0376],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:36,558][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ long] are: tensor([6.5084e-03, 4.5928e-04, 1.1735e-03, 8.0222e-04, 9.9842e-04, 9.0916e-03,
        7.2427e-03, 9.7372e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:36,559][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0955, 0.0218, 0.0470, 0.0285, 0.0732, 0.1425, 0.0755, 0.5161],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:36,560][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ long] are: tensor([5.4041e-03, 1.8790e-04, 1.0017e-04, 1.0305e-04, 7.6591e-05, 1.9183e-04,
        8.2370e-05, 9.9385e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:36,561][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.2907, 0.0313, 0.2470, 0.0218, 0.2545, 0.0481, 0.0225, 0.0842],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:36,562][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0976, 0.0424, 0.0124, 0.0890, 0.1432, 0.1789, 0.3303, 0.1061],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:36,562][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.1243, 0.1244, 0.0139, 0.1581, 0.0693, 0.1530, 0.3110, 0.0460],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:36,563][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.2387, 0.1561, 0.0890, 0.1511, 0.0756, 0.0922, 0.1324, 0.0650],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:36,563][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.2226, 0.1577, 0.0499, 0.1104, 0.0400, 0.0766, 0.0866, 0.2562],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:36,564][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.3787, 0.1019, 0.0640, 0.1268, 0.0914, 0.0628, 0.0642, 0.1101],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:36,564][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.3647, 0.0872, 0.0929, 0.0688, 0.1191, 0.0744, 0.0585, 0.0743, 0.0600],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:36,564][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([1.8571e-03, 3.0773e-04, 1.2904e-03, 2.0916e-04, 6.4047e-04, 3.4886e-04,
        1.9523e-04, 3.4344e-05, 9.9512e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:36,565][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.3327, 0.1131, 0.0300, 0.0829, 0.0375, 0.1089, 0.1276, 0.1055, 0.0617],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:36,565][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([3.3803e-03, 4.0824e-05, 3.3419e-04, 9.1137e-05, 2.4809e-03, 2.4657e-04,
        6.2866e-04, 4.2993e-03, 9.8850e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:36,566][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.1285, 0.0058, 0.0153, 0.0050, 0.0362, 0.0156, 0.0131, 0.1723, 0.6082],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:36,567][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([1.2028e-02, 1.5134e-05, 1.8228e-05, 4.1251e-06, 1.6978e-05, 2.0255e-06,
        1.5990e-06, 6.3679e-07, 9.8791e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:36,568][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.1923, 0.0500, 0.1101, 0.0437, 0.2642, 0.0330, 0.0354, 0.0794, 0.1920],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:36,569][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0907, 0.0520, 0.0232, 0.0968, 0.0300, 0.1335, 0.2130, 0.2564, 0.1043],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:36,571][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.2550, 0.0985, 0.0415, 0.1153, 0.0518, 0.2405, 0.1231, 0.0665, 0.0077],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:36,572][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.2277, 0.1326, 0.0759, 0.1242, 0.0999, 0.1079, 0.1111, 0.0801, 0.0407],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:36,573][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.2160, 0.1345, 0.0485, 0.1137, 0.0404, 0.0776, 0.0750, 0.0393, 0.2550],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:36,574][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.3179, 0.1410, 0.0573, 0.1021, 0.1042, 0.0404, 0.0390, 0.0861, 0.1122],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:36,575][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4467, 0.0153, 0.0718, 0.0178, 0.1369, 0.0791, 0.0342, 0.0635, 0.1216,
        0.0130], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:36,576][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([1.8447e-03, 4.4362e-01, 3.6093e-05, 1.1172e-02, 3.8957e-05, 3.9676e-04,
        1.7964e-04, 5.1712e-05, 7.8259e-06, 5.4265e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:36,578][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2015, 0.3172, 0.0090, 0.0776, 0.0178, 0.0370, 0.0076, 0.0103, 0.0102,
        0.3119], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:36,579][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([3.3169e-02, 7.7042e-03, 6.7586e-04, 7.7492e-03, 4.8699e-03, 6.0611e-02,
        4.9757e-02, 5.5137e-02, 8.6443e-02, 6.9388e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:36,580][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2773, 0.0269, 0.0276, 0.0232, 0.0378, 0.1339, 0.0327, 0.1145, 0.0480,
        0.2782], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:36,581][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0965, 0.3408, 0.0123, 0.1229, 0.0158, 0.0684, 0.1012, 0.0298, 0.0100,
        0.2024], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:36,583][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2805, 0.0083, 0.1483, 0.0080, 0.3144, 0.0263, 0.0102, 0.0677, 0.1308,
        0.0055], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:36,584][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0369, 0.0139, 0.0300, 0.0379, 0.0634, 0.0692, 0.1103, 0.1446, 0.1382,
        0.3556], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:36,586][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0192, 0.1650, 0.0067, 0.1852, 0.0049, 0.0643, 0.1661, 0.0292, 0.0076,
        0.3519], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:36,587][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2150, 0.1230, 0.0690, 0.1278, 0.0537, 0.0862, 0.0939, 0.0702, 0.0567,
        0.1046], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:36,588][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1741, 0.1603, 0.0630, 0.1472, 0.0555, 0.0953, 0.0923, 0.0592, 0.0422,
        0.1111], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:36,590][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2425, 0.0938, 0.0536, 0.1064, 0.1083, 0.0676, 0.0645, 0.0787, 0.0732,
        0.1115], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:36,591][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3463, 0.0282, 0.0922, 0.0243, 0.1264, 0.0681, 0.0411, 0.0905, 0.1257,
        0.0277, 0.0295], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:36,592][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([1.0614e-03, 1.2476e-02, 1.1586e-04, 5.1184e-01, 9.8722e-05, 6.9041e-04,
        2.3419e-04, 1.8326e-04, 8.4966e-06, 7.4675e-03, 4.6582e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:36,593][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0838, 0.0626, 0.0167, 0.3137, 0.0157, 0.0436, 0.0175, 0.0150, 0.0234,
        0.0557, 0.3523], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:36,594][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([1.0819e-02, 6.0637e-03, 1.3528e-04, 3.9876e-03, 7.4284e-04, 7.8456e-03,
        1.3922e-02, 1.5636e-02, 7.4081e-03, 4.9295e-01, 4.4049e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:36,596][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0351, 0.0129, 0.0146, 0.0244, 0.0193, 0.1605, 0.0651, 0.1188, 0.1761,
        0.1205, 0.2527], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:36,597][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0326, 0.0872, 0.0024, 0.3878, 0.0044, 0.0543, 0.1211, 0.0254, 0.0037,
        0.0306, 0.2505], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:36,599][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2524, 0.0102, 0.1506, 0.0097, 0.2547, 0.0320, 0.0118, 0.0892, 0.1708,
        0.0078, 0.0107], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:36,600][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0327, 0.0118, 0.0200, 0.0197, 0.0449, 0.0418, 0.0627, 0.0785, 0.0967,
        0.2417, 0.3495], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:36,602][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0115, 0.1004, 0.0035, 0.1178, 0.0042, 0.0611, 0.2004, 0.0256, 0.0109,
        0.2632, 0.2014], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:36,603][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1767, 0.1102, 0.0557, 0.1112, 0.0525, 0.0770, 0.0884, 0.0594, 0.0581,
        0.0974, 0.1133], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:36,604][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1433, 0.1297, 0.0525, 0.1379, 0.0505, 0.0969, 0.0979, 0.0520, 0.0350,
        0.0941, 0.1102], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:36,606][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2146, 0.0875, 0.0468, 0.1008, 0.0906, 0.0523, 0.0464, 0.0602, 0.0768,
        0.1106, 0.1136], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:36,607][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.2598, 0.0473, 0.0265, 0.0524, 0.0953, 0.1379, 0.0538, 0.0377, 0.1658,
        0.0410, 0.0626, 0.0200], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:36,608][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([1.7394e-03, 4.1719e-04, 4.8425e-04, 1.5585e-04, 2.6035e-03, 1.7361e-04,
        9.0114e-05, 1.4330e-04, 6.0548e-04, 9.2274e-05, 7.0706e-05, 9.9342e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:36,608][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.2618, 0.0856, 0.0554, 0.0812, 0.0494, 0.1652, 0.0678, 0.0598, 0.0345,
        0.0543, 0.0653, 0.0196], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:36,609][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([1.2695e-02, 5.1813e-05, 1.9164e-05, 7.2030e-05, 2.1100e-04, 1.1422e-03,
        2.1228e-04, 3.4372e-03, 1.4253e-03, 2.2502e-03, 4.8174e-03, 9.7367e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:36,609][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0421, 0.0034, 0.0018, 0.0070, 0.0061, 0.0114, 0.0109, 0.0295, 0.0154,
        0.0128, 0.0439, 0.8159], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:36,609][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([9.2441e-02, 4.3735e-06, 2.9304e-05, 1.6931e-06, 3.3628e-04, 4.4300e-06,
        4.7544e-07, 4.6477e-06, 5.0041e-06, 9.8421e-08, 2.7239e-07, 9.0717e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:36,610][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.1416, 0.0593, 0.0867, 0.0441, 0.1899, 0.0369, 0.0628, 0.0552, 0.1273,
        0.0523, 0.0485, 0.0953], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:36,610][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0532, 0.0191, 0.0041, 0.0294, 0.0147, 0.0338, 0.0718, 0.0493, 0.0278,
        0.1937, 0.3943, 0.1088], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:36,611][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0989, 0.1118, 0.0145, 0.1415, 0.0166, 0.0400, 0.1236, 0.0371, 0.1013,
        0.1318, 0.1698, 0.0131], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:36,612][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.1742, 0.0985, 0.0731, 0.0905, 0.0665, 0.0750, 0.0660, 0.0565, 0.0855,
        0.0835, 0.0908, 0.0400], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:36,614][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.1895, 0.0921, 0.0461, 0.0881, 0.0544, 0.0825, 0.0548, 0.0512, 0.0384,
        0.0656, 0.0682, 0.1690], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:36,615][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.1682, 0.1333, 0.0541, 0.0884, 0.1187, 0.0304, 0.0389, 0.0392, 0.0358,
        0.1524, 0.0949, 0.0458], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:36,617][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Stephanie] are: tensor([0.1559, 0.1100, 0.1627, 0.1097, 0.0359, 0.0196, 0.0467, 0.0264, 0.0629,
        0.0878, 0.1082, 0.0394, 0.0347], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:36,618][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Stephanie] are: tensor([4.1207e-04, 1.0298e-04, 4.4886e-04, 3.5260e-04, 5.6029e-01, 4.9268e-05,
        5.9914e-05, 2.1346e-04, 2.3513e-04, 1.8496e-05, 1.4946e-04, 7.8462e-04,
        4.3689e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:36,619][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Stephanie] are: tensor([0.1963, 0.0888, 0.0519, 0.0648, 0.0660, 0.0876, 0.0761, 0.0348, 0.0806,
        0.0671, 0.0595, 0.0593, 0.0671], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:36,620][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Stephanie] are: tensor([1.6303e-03, 1.3650e-06, 1.5646e-05, 1.5815e-06, 5.9795e-03, 1.0669e-05,
        1.4833e-05, 4.2050e-05, 3.4633e-04, 8.1700e-05, 1.2566e-04, 6.2705e-03,
        9.8548e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:36,621][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Stephanie] are: tensor([7.4923e-04, 6.1508e-05, 7.8008e-05, 4.0147e-05, 5.5394e-02, 4.2724e-05,
        5.1225e-05, 3.1611e-04, 2.5800e-04, 2.9168e-04, 3.4740e-04, 8.4291e-04,
        9.4153e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:36,622][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Stephanie] are: tensor([5.7601e-03, 7.8687e-07, 1.3143e-05, 2.9059e-07, 6.2892e-01, 1.7745e-07,
        2.2133e-08, 8.3275e-07, 2.7335e-07, 1.8927e-08, 4.5416e-08, 4.0501e-06,
        3.6530e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:36,624][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Stephanie] are: tensor([0.1000, 0.1211, 0.0572, 0.1066, 0.1290, 0.0254, 0.0468, 0.0284, 0.0388,
        0.1061, 0.0955, 0.0177, 0.1274], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:36,625][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Stephanie] are: tensor([0.0496, 0.0155, 0.0080, 0.0243, 0.0122, 0.0381, 0.0542, 0.0245, 0.0276,
        0.1475, 0.2498, 0.1960, 0.1525], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:36,627][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Stephanie] are: tensor([0.1725, 0.0801, 0.0753, 0.0923, 0.0570, 0.0282, 0.0593, 0.0364, 0.1673,
        0.0626, 0.0855, 0.0241, 0.0593], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:36,628][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Stephanie] are: tensor([0.1990, 0.1104, 0.0846, 0.0985, 0.0174, 0.0642, 0.0704, 0.0506, 0.0519,
        0.0871, 0.0935, 0.0554, 0.0170], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:36,629][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Stephanie] are: tensor([0.1034, 0.0780, 0.0424, 0.0762, 0.2373, 0.0429, 0.0557, 0.0269, 0.0175,
        0.0518, 0.0544, 0.0227, 0.1908], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:36,631][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Stephanie] are: tensor([0.0942, 0.0909, 0.0450, 0.0797, 0.0776, 0.0527, 0.0423, 0.0607, 0.0847,
        0.0872, 0.0967, 0.0835, 0.1048], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:36,632][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.3538, 0.0306, 0.1019, 0.0177, 0.0379, 0.0645, 0.0189, 0.0468, 0.0451,
        0.0301, 0.0188, 0.1025, 0.0526, 0.0787], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:36,633][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ said] are: tensor([1.4464e-03, 3.5555e-03, 1.8741e-04, 1.2023e-03, 4.0476e-04, 8.5005e-03,
        1.4063e-03, 4.5836e-05, 1.5938e-03, 1.5526e-03, 7.2306e-04, 1.1251e-04,
        2.7584e-04, 9.7899e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:36,635][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.2206, 0.0493, 0.0518, 0.0425, 0.0237, 0.1015, 0.0335, 0.0245, 0.0483,
        0.0407, 0.0397, 0.0399, 0.0239, 0.2600], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:36,636][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ said] are: tensor([2.0004e-03, 7.3988e-05, 2.1718e-05, 5.5077e-05, 3.6635e-05, 3.1005e-04,
        4.3076e-04, 4.8966e-04, 1.2623e-03, 2.5561e-03, 3.5732e-03, 1.3259e-03,
        3.4997e-03, 9.8436e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:36,637][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0844, 0.0129, 0.0102, 0.0184, 0.0059, 0.0262, 0.0213, 0.0247, 0.0420,
        0.0553, 0.1176, 0.0237, 0.0456, 0.5117], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:36,638][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ said] are: tensor([1.2078e-02, 2.4348e-03, 1.5054e-04, 8.9075e-04, 5.9015e-05, 8.6993e-03,
        2.0766e-04, 2.9483e-05, 6.7262e-04, 2.4889e-04, 2.8127e-04, 6.2028e-06,
        2.0164e-05, 9.7422e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:36,640][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.1669, 0.0081, 0.0934, 0.0082, 0.1939, 0.0110, 0.0066, 0.0298, 0.0787,
        0.0062, 0.0081, 0.1143, 0.2585, 0.0162], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:36,641][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0314, 0.0060, 0.0059, 0.0100, 0.0121, 0.0135, 0.0285, 0.0123, 0.0195,
        0.1036, 0.1619, 0.1669, 0.2645, 0.1638], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:36,643][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0512, 0.1060, 0.0181, 0.1040, 0.0210, 0.1013, 0.1371, 0.0312, 0.0277,
        0.1754, 0.1373, 0.0248, 0.0277, 0.0372], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:36,644][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.1477, 0.0794, 0.0587, 0.0816, 0.0460, 0.0653, 0.0621, 0.0461, 0.0542,
        0.0739, 0.0845, 0.0548, 0.0511, 0.0945], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:36,646][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.1018, 0.0734, 0.0418, 0.0774, 0.0366, 0.0798, 0.0598, 0.0250, 0.0479,
        0.0621, 0.0668, 0.0285, 0.0311, 0.2679], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:36,647][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.2405, 0.0572, 0.0406, 0.0765, 0.0677, 0.0366, 0.0307, 0.0552, 0.0656,
        0.0607, 0.0776, 0.0805, 0.0723, 0.0385], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:36,648][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2500, 0.0242, 0.0560, 0.0203, 0.0844, 0.0652, 0.0218, 0.0352, 0.0696,
        0.0242, 0.0248, 0.0806, 0.1239, 0.1038, 0.0160], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:36,649][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([4.1210e-03, 1.1778e-02, 2.3022e-04, 3.4314e-02, 9.7204e-05, 3.0532e-04,
        1.4491e-03, 1.7846e-04, 5.7929e-05, 8.2840e-03, 3.0205e-02, 2.4504e-04,
        6.5134e-05, 1.4514e-04, 9.0852e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:36,649][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1600, 0.0704, 0.0430, 0.0966, 0.0179, 0.0587, 0.0252, 0.0377, 0.0307,
        0.0601, 0.0951, 0.0391, 0.0179, 0.0747, 0.1729], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:36,650][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([2.9514e-03, 2.6644e-04, 2.4667e-05, 1.8258e-04, 1.5992e-05, 7.3080e-04,
        1.2087e-03, 2.4306e-04, 1.1507e-03, 7.2166e-03, 1.1966e-02, 1.6612e-02,
        1.4766e-03, 2.9406e-01, 6.6190e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:36,650][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0359, 0.0023, 0.0023, 0.0038, 0.0014, 0.0339, 0.0104, 0.0263, 0.0573,
        0.0123, 0.0316, 0.0733, 0.0149, 0.4163, 0.2780], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:36,650][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0433, 0.0611, 0.0033, 0.0783, 0.0016, 0.0312, 0.2263, 0.0343, 0.0048,
        0.0212, 0.0412, 0.0007, 0.0007, 0.0326, 0.4193], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:36,651][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1222, 0.0059, 0.0269, 0.0051, 0.0944, 0.0171, 0.0048, 0.0316, 0.0545,
        0.0044, 0.0064, 0.1112, 0.1581, 0.0328, 0.3244], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:36,651][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0218, 0.0041, 0.0039, 0.0068, 0.0075, 0.0088, 0.0118, 0.0181, 0.0265,
        0.0486, 0.0786, 0.0922, 0.1466, 0.2549, 0.2698], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:36,653][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0081, 0.0597, 0.0031, 0.1040, 0.0030, 0.0468, 0.1317, 0.0198, 0.0090,
        0.1514, 0.1822, 0.0048, 0.0045, 0.0339, 0.2379], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:36,654][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1198, 0.0743, 0.0403, 0.0817, 0.0402, 0.0545, 0.0695, 0.0477, 0.0429,
        0.0701, 0.0857, 0.0460, 0.0450, 0.0833, 0.0988], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:36,656][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1001, 0.0823, 0.0388, 0.0985, 0.0390, 0.0730, 0.0839, 0.0493, 0.0327,
        0.0747, 0.0910, 0.0270, 0.0353, 0.0630, 0.1113], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:36,657][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1734, 0.0685, 0.0402, 0.0704, 0.0659, 0.0488, 0.0444, 0.0520, 0.0522,
        0.0705, 0.0669, 0.0720, 0.0683, 0.0358, 0.0707], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:36,659][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:36,659][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,659][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,660][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,660][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,660][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,661][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,661][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,661][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,661][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,662][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,662][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,662][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,663][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,663][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,663][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,664][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,664][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,664][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,665][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,665][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,665][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,666][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,666][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,666][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,667][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Jose] are: tensor([0.3363, 0.3533, 0.3105], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,667][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Jose] are: tensor([7.0421e-04, 2.0440e-04, 9.9909e-01], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,667][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Jose] are: tensor([0.5729, 0.2639, 0.1632], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,668][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Jose] are: tensor([2.9888e-02, 8.4627e-04, 9.6927e-01], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,668][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Jose] are: tensor([0.1361, 0.0217, 0.8422], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,668][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Jose] are: tensor([3.7819e-02, 7.4038e-06, 9.6217e-01], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,669][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Jose] are: tensor([0.4179, 0.2759, 0.3062], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,669][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Jose] are: tensor([0.5963, 0.2997, 0.1040], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,669][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Jose] are: tensor([0.5719, 0.3034, 0.1247], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,670][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Jose] are: tensor([0.6294, 0.3301, 0.0405], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,671][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Jose] are: tensor([0.4661, 0.2294, 0.3045], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,672][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Jose] are: tensor([0.5261, 0.2829, 0.1909], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,674][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.7090, 0.0803, 0.1481, 0.0626], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,675][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.3023e-03, 3.9245e-02, 5.5679e-04, 9.5790e-01], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,676][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2390, 0.1790, 0.0313, 0.5507], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,677][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1134, 0.3875, 0.0250, 0.4741], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,679][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3327, 0.1507, 0.2437, 0.2729], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,680][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1235, 0.1977, 0.0035, 0.6753], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,681][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6787, 0.0325, 0.2642, 0.0246], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,683][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2400, 0.1825, 0.3026, 0.2748], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,684][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0677, 0.4739, 0.0140, 0.4444], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,685][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4316, 0.2410, 0.1034, 0.2239], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,687][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4129, 0.3075, 0.0768, 0.2029], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,688][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4537, 0.1982, 0.0891, 0.2589], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,690][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Stephanie] are: tensor([0.2517, 0.2311, 0.2466, 0.2150, 0.0556], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,691][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Stephanie] are: tensor([8.8065e-04, 4.4198e-04, 1.7549e-03, 1.2047e-03, 9.9572e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,692][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Stephanie] are: tensor([0.4454, 0.2312, 0.0870, 0.1319, 0.1045], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,693][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Stephanie] are: tensor([1.6807e-02, 1.2756e-04, 2.5106e-03, 3.3964e-04, 9.8022e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,694][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Stephanie] are: tensor([5.9050e-03, 7.9046e-04, 1.6101e-03, 6.3901e-04, 9.9106e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,695][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Stephanie] are: tensor([2.1608e-02, 3.7303e-06, 2.9441e-05, 1.2729e-06, 9.7836e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,696][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Stephanie] are: tensor([0.2135, 0.2799, 0.1045, 0.2133, 0.1888], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,697][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Stephanie] are: tensor([0.2080, 0.1748, 0.1144, 0.3368, 0.1660], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,699][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Stephanie] are: tensor([0.3747, 0.1951, 0.1286, 0.1914, 0.1102], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,700][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Stephanie] are: tensor([0.4121, 0.2245, 0.1429, 0.1899, 0.0305], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,702][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Stephanie] are: tensor([0.2995, 0.2176, 0.0785, 0.1480, 0.2564], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,702][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Stephanie] are: tensor([0.2419, 0.2349, 0.1003, 0.2396, 0.1833], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,702][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.4241, 0.0373, 0.0261, 0.0371, 0.1488, 0.3267], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,703][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([3.2202e-04, 1.6747e-03, 7.8620e-04, 2.8605e-03, 1.0412e-04, 9.9425e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,703][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.4719, 0.1204, 0.0810, 0.1424, 0.0433, 0.1410], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,704][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0049, 0.0054, 0.0013, 0.0115, 0.0032, 0.9737], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,704][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.2006, 0.0571, 0.1250, 0.1033, 0.0880, 0.4260], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,704][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([3.9829e-02, 1.8586e-03, 8.5266e-05, 1.2922e-03, 9.5623e-05, 9.5684e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,705][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.3000, 0.0224, 0.2437, 0.0210, 0.3829, 0.0301], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,705][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1050, 0.0818, 0.0776, 0.1899, 0.3096, 0.2361], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,707][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0972, 0.2730, 0.0199, 0.3586, 0.0295, 0.2219], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,708][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.3076, 0.1854, 0.0956, 0.1911, 0.0912, 0.1291], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,709][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.2481, 0.1914, 0.0788, 0.1401, 0.0373, 0.3043], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,711][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.4154, 0.1388, 0.0673, 0.1730, 0.1180, 0.0875], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,712][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4639, 0.0534, 0.0900, 0.0404, 0.2499, 0.0666, 0.0358],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,713][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([8.5686e-04, 4.3062e-03, 3.2137e-04, 4.3042e-03, 1.6026e-04, 4.6898e-04,
        9.8958e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,714][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.3029, 0.1879, 0.0692, 0.2215, 0.0462, 0.1254, 0.0468],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,715][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0290, 0.0178, 0.0049, 0.0328, 0.0286, 0.1771, 0.7098],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,717][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1394, 0.0307, 0.0601, 0.0432, 0.0801, 0.4358, 0.2108],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,718][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0560, 0.1298, 0.0033, 0.0971, 0.0018, 0.0448, 0.6672],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,720][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.3540, 0.0118, 0.2279, 0.0100, 0.3328, 0.0521, 0.0115],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,721][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0969, 0.0582, 0.0713, 0.1301, 0.1248, 0.2183, 0.3005],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,723][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0241, 0.1313, 0.0059, 0.1950, 0.0085, 0.1425, 0.4927],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,724][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2636, 0.1688, 0.0812, 0.1713, 0.0737, 0.1062, 0.1351],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,725][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2259, 0.1926, 0.0588, 0.1633, 0.0501, 0.0836, 0.2258],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,727][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3270, 0.1311, 0.0753, 0.1408, 0.1329, 0.0845, 0.1084],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,728][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.2753, 0.0659, 0.0544, 0.0610, 0.2633, 0.1134, 0.0865, 0.0802],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:36,729][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([2.8429e-04, 9.8813e-04, 1.3066e-03, 1.4096e-03, 9.2369e-04, 3.2487e-03,
        9.3745e-04, 9.9090e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:36,730][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.2899, 0.1494, 0.1194, 0.1511, 0.0716, 0.1055, 0.0755, 0.0376],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:36,731][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([6.5084e-03, 4.5928e-04, 1.1735e-03, 8.0222e-04, 9.9842e-04, 9.0916e-03,
        7.2427e-03, 9.7372e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:36,733][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0955, 0.0218, 0.0470, 0.0285, 0.0732, 0.1425, 0.0755, 0.5161],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:36,733][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([5.4041e-03, 1.8790e-04, 1.0017e-04, 1.0305e-04, 7.6591e-05, 1.9183e-04,
        8.2370e-05, 9.9385e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:36,735][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.2907, 0.0313, 0.2470, 0.0218, 0.2545, 0.0481, 0.0225, 0.0842],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:36,736][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0976, 0.0424, 0.0124, 0.0890, 0.1432, 0.1789, 0.3303, 0.1061],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:36,738][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.1243, 0.1244, 0.0139, 0.1581, 0.0693, 0.1530, 0.3110, 0.0460],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:36,739][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.2387, 0.1561, 0.0890, 0.1511, 0.0756, 0.0922, 0.1324, 0.0650],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:36,741][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.2226, 0.1577, 0.0499, 0.1104, 0.0400, 0.0766, 0.0866, 0.2562],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:36,742][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.3787, 0.1019, 0.0640, 0.1268, 0.0914, 0.0628, 0.0642, 0.1101],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:36,744][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.3647, 0.0872, 0.0929, 0.0688, 0.1191, 0.0744, 0.0585, 0.0743, 0.0600],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:36,744][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([1.8571e-03, 3.0773e-04, 1.2904e-03, 2.0916e-04, 6.4047e-04, 3.4886e-04,
        1.9523e-04, 3.4344e-05, 9.9512e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:36,745][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.3327, 0.1131, 0.0300, 0.0829, 0.0375, 0.1089, 0.1276, 0.1055, 0.0617],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:36,745][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([3.3803e-03, 4.0824e-05, 3.3419e-04, 9.1137e-05, 2.4809e-03, 2.4657e-04,
        6.2866e-04, 4.2993e-03, 9.8850e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:36,745][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.1285, 0.0058, 0.0153, 0.0050, 0.0362, 0.0156, 0.0131, 0.1723, 0.6082],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:36,746][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([1.2028e-02, 1.5134e-05, 1.8228e-05, 4.1251e-06, 1.6978e-05, 2.0255e-06,
        1.5990e-06, 6.3679e-07, 9.8791e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:36,746][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.1923, 0.0500, 0.1101, 0.0437, 0.2642, 0.0330, 0.0354, 0.0794, 0.1920],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:36,747][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0907, 0.0520, 0.0232, 0.0968, 0.0300, 0.1335, 0.2130, 0.2564, 0.1043],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:36,747][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.2550, 0.0985, 0.0415, 0.1153, 0.0518, 0.2405, 0.1231, 0.0665, 0.0077],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:36,747][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.2277, 0.1326, 0.0759, 0.1242, 0.0999, 0.1079, 0.1111, 0.0801, 0.0407],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:36,749][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.2160, 0.1345, 0.0485, 0.1137, 0.0404, 0.0776, 0.0750, 0.0393, 0.2550],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:36,750][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.3179, 0.1410, 0.0573, 0.1021, 0.1042, 0.0404, 0.0390, 0.0861, 0.1122],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:36,751][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4467, 0.0153, 0.0718, 0.0178, 0.1369, 0.0791, 0.0342, 0.0635, 0.1216,
        0.0130], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:36,752][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([1.8447e-03, 4.4362e-01, 3.6093e-05, 1.1172e-02, 3.8957e-05, 3.9676e-04,
        1.7964e-04, 5.1712e-05, 7.8259e-06, 5.4265e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:36,754][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2015, 0.3172, 0.0090, 0.0776, 0.0178, 0.0370, 0.0076, 0.0103, 0.0102,
        0.3119], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:36,755][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([3.3169e-02, 7.7042e-03, 6.7586e-04, 7.7492e-03, 4.8699e-03, 6.0611e-02,
        4.9757e-02, 5.5137e-02, 8.6443e-02, 6.9388e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:36,756][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2773, 0.0269, 0.0276, 0.0232, 0.0378, 0.1339, 0.0327, 0.1145, 0.0480,
        0.2782], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:36,758][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0965, 0.3408, 0.0123, 0.1229, 0.0158, 0.0684, 0.1012, 0.0298, 0.0100,
        0.2024], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:36,759][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2805, 0.0083, 0.1483, 0.0080, 0.3144, 0.0263, 0.0102, 0.0677, 0.1308,
        0.0055], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:36,760][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0369, 0.0139, 0.0300, 0.0379, 0.0634, 0.0692, 0.1103, 0.1446, 0.1382,
        0.3556], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:36,762][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0192, 0.1650, 0.0067, 0.1852, 0.0049, 0.0643, 0.1661, 0.0292, 0.0076,
        0.3519], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:36,763][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2150, 0.1230, 0.0690, 0.1278, 0.0537, 0.0862, 0.0939, 0.0702, 0.0567,
        0.1046], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:36,765][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1741, 0.1603, 0.0630, 0.1472, 0.0555, 0.0953, 0.0923, 0.0592, 0.0422,
        0.1111], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:36,766][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2425, 0.0938, 0.0536, 0.1064, 0.1083, 0.0676, 0.0645, 0.0787, 0.0732,
        0.1115], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:36,768][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3463, 0.0282, 0.0922, 0.0243, 0.1264, 0.0681, 0.0411, 0.0905, 0.1257,
        0.0277, 0.0295], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:36,769][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([1.0614e-03, 1.2476e-02, 1.1586e-04, 5.1184e-01, 9.8722e-05, 6.9041e-04,
        2.3419e-04, 1.8326e-04, 8.4966e-06, 7.4675e-03, 4.6582e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:36,770][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0838, 0.0626, 0.0167, 0.3137, 0.0157, 0.0436, 0.0175, 0.0150, 0.0234,
        0.0557, 0.3523], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:36,771][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([1.0819e-02, 6.0637e-03, 1.3528e-04, 3.9876e-03, 7.4284e-04, 7.8456e-03,
        1.3922e-02, 1.5636e-02, 7.4081e-03, 4.9295e-01, 4.4049e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:36,772][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0351, 0.0129, 0.0146, 0.0244, 0.0193, 0.1605, 0.0651, 0.1188, 0.1761,
        0.1205, 0.2527], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:36,774][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0326, 0.0872, 0.0024, 0.3878, 0.0044, 0.0543, 0.1211, 0.0254, 0.0037,
        0.0306, 0.2505], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:36,775][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2524, 0.0102, 0.1506, 0.0097, 0.2547, 0.0320, 0.0118, 0.0892, 0.1708,
        0.0078, 0.0107], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:36,777][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0327, 0.0118, 0.0200, 0.0197, 0.0449, 0.0418, 0.0627, 0.0785, 0.0967,
        0.2417, 0.3495], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:36,778][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0115, 0.1004, 0.0035, 0.1178, 0.0042, 0.0611, 0.2004, 0.0256, 0.0109,
        0.2632, 0.2014], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:36,780][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1767, 0.1102, 0.0557, 0.1112, 0.0525, 0.0770, 0.0884, 0.0594, 0.0581,
        0.0974, 0.1133], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:36,781][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1433, 0.1297, 0.0525, 0.1379, 0.0505, 0.0969, 0.0979, 0.0520, 0.0350,
        0.0941, 0.1102], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:36,783][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2146, 0.0875, 0.0468, 0.1008, 0.0906, 0.0523, 0.0464, 0.0602, 0.0768,
        0.1106, 0.1136], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:36,784][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.2598, 0.0473, 0.0265, 0.0524, 0.0953, 0.1379, 0.0538, 0.0377, 0.1658,
        0.0410, 0.0626, 0.0200], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:36,785][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([1.7394e-03, 4.1719e-04, 4.8425e-04, 1.5585e-04, 2.6035e-03, 1.7361e-04,
        9.0114e-05, 1.4330e-04, 6.0548e-04, 9.2274e-05, 7.0706e-05, 9.9342e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:36,787][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.2618, 0.0856, 0.0554, 0.0812, 0.0494, 0.1652, 0.0678, 0.0598, 0.0345,
        0.0543, 0.0653, 0.0196], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:36,787][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([1.2695e-02, 5.1813e-05, 1.9164e-05, 7.2030e-05, 2.1100e-04, 1.1422e-03,
        2.1228e-04, 3.4372e-03, 1.4253e-03, 2.2502e-03, 4.8174e-03, 9.7367e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:36,787][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0421, 0.0034, 0.0018, 0.0070, 0.0061, 0.0114, 0.0109, 0.0295, 0.0154,
        0.0128, 0.0439, 0.8159], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:36,788][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([9.2441e-02, 4.3735e-06, 2.9304e-05, 1.6931e-06, 3.3628e-04, 4.4300e-06,
        4.7544e-07, 4.6477e-06, 5.0041e-06, 9.8421e-08, 2.7239e-07, 9.0717e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:36,788][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.1416, 0.0593, 0.0867, 0.0441, 0.1899, 0.0369, 0.0628, 0.0552, 0.1273,
        0.0523, 0.0485, 0.0953], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:36,789][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0532, 0.0191, 0.0041, 0.0294, 0.0147, 0.0338, 0.0718, 0.0493, 0.0278,
        0.1937, 0.3943, 0.1088], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:36,789][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0989, 0.1118, 0.0145, 0.1415, 0.0166, 0.0400, 0.1236, 0.0371, 0.1013,
        0.1318, 0.1698, 0.0131], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:36,790][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.1742, 0.0985, 0.0731, 0.0905, 0.0665, 0.0750, 0.0660, 0.0565, 0.0855,
        0.0835, 0.0908, 0.0400], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:36,790][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.1895, 0.0921, 0.0461, 0.0881, 0.0544, 0.0825, 0.0548, 0.0512, 0.0384,
        0.0656, 0.0682, 0.1690], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:36,791][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.1682, 0.1333, 0.0541, 0.0884, 0.1187, 0.0304, 0.0389, 0.0392, 0.0358,
        0.1524, 0.0949, 0.0458], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:36,793][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Stephanie] are: tensor([0.1559, 0.1100, 0.1627, 0.1097, 0.0359, 0.0196, 0.0467, 0.0264, 0.0629,
        0.0878, 0.1082, 0.0394, 0.0347], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:36,794][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Stephanie] are: tensor([4.1207e-04, 1.0298e-04, 4.4886e-04, 3.5260e-04, 5.6029e-01, 4.9268e-05,
        5.9914e-05, 2.1346e-04, 2.3513e-04, 1.8496e-05, 1.4946e-04, 7.8462e-04,
        4.3689e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:36,795][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Stephanie] are: tensor([0.1963, 0.0888, 0.0519, 0.0648, 0.0660, 0.0876, 0.0761, 0.0348, 0.0806,
        0.0671, 0.0595, 0.0593, 0.0671], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:36,796][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Stephanie] are: tensor([1.6303e-03, 1.3650e-06, 1.5646e-05, 1.5815e-06, 5.9795e-03, 1.0669e-05,
        1.4833e-05, 4.2050e-05, 3.4633e-04, 8.1700e-05, 1.2566e-04, 6.2705e-03,
        9.8548e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:36,797][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Stephanie] are: tensor([7.4923e-04, 6.1508e-05, 7.8008e-05, 4.0147e-05, 5.5394e-02, 4.2724e-05,
        5.1225e-05, 3.1611e-04, 2.5800e-04, 2.9168e-04, 3.4740e-04, 8.4291e-04,
        9.4153e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:36,798][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Stephanie] are: tensor([5.7601e-03, 7.8687e-07, 1.3143e-05, 2.9059e-07, 6.2892e-01, 1.7745e-07,
        2.2133e-08, 8.3275e-07, 2.7335e-07, 1.8927e-08, 4.5416e-08, 4.0501e-06,
        3.6530e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:36,799][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Stephanie] are: tensor([0.1000, 0.1211, 0.0572, 0.1066, 0.1290, 0.0254, 0.0468, 0.0284, 0.0388,
        0.1061, 0.0955, 0.0177, 0.1274], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:36,801][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Stephanie] are: tensor([0.0496, 0.0155, 0.0080, 0.0243, 0.0122, 0.0381, 0.0542, 0.0245, 0.0276,
        0.1475, 0.2498, 0.1960, 0.1525], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:36,802][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Stephanie] are: tensor([0.1725, 0.0801, 0.0753, 0.0923, 0.0570, 0.0282, 0.0593, 0.0364, 0.1673,
        0.0626, 0.0855, 0.0241, 0.0593], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:36,803][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Stephanie] are: tensor([0.1990, 0.1104, 0.0846, 0.0985, 0.0174, 0.0642, 0.0704, 0.0506, 0.0519,
        0.0871, 0.0935, 0.0554, 0.0170], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:36,805][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Stephanie] are: tensor([0.1034, 0.0780, 0.0424, 0.0762, 0.2373, 0.0429, 0.0557, 0.0269, 0.0175,
        0.0518, 0.0544, 0.0227, 0.1908], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:36,806][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Stephanie] are: tensor([0.0942, 0.0909, 0.0450, 0.0797, 0.0776, 0.0527, 0.0423, 0.0607, 0.0847,
        0.0872, 0.0967, 0.0835, 0.1048], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:36,808][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.3538, 0.0306, 0.1019, 0.0177, 0.0379, 0.0645, 0.0189, 0.0468, 0.0451,
        0.0301, 0.0188, 0.1025, 0.0526, 0.0787], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:36,809][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([1.4464e-03, 3.5555e-03, 1.8741e-04, 1.2023e-03, 4.0476e-04, 8.5005e-03,
        1.4063e-03, 4.5836e-05, 1.5938e-03, 1.5526e-03, 7.2306e-04, 1.1251e-04,
        2.7584e-04, 9.7899e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:36,810][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.2206, 0.0493, 0.0518, 0.0425, 0.0237, 0.1015, 0.0335, 0.0245, 0.0483,
        0.0407, 0.0397, 0.0399, 0.0239, 0.2600], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:36,811][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([2.0004e-03, 7.3988e-05, 2.1718e-05, 5.5077e-05, 3.6635e-05, 3.1005e-04,
        4.3076e-04, 4.8966e-04, 1.2623e-03, 2.5561e-03, 3.5732e-03, 1.3259e-03,
        3.4997e-03, 9.8436e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:36,813][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0844, 0.0129, 0.0102, 0.0184, 0.0059, 0.0262, 0.0213, 0.0247, 0.0420,
        0.0553, 0.1176, 0.0237, 0.0456, 0.5117], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:36,814][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([1.2078e-02, 2.4348e-03, 1.5054e-04, 8.9075e-04, 5.9015e-05, 8.6993e-03,
        2.0766e-04, 2.9483e-05, 6.7262e-04, 2.4889e-04, 2.8127e-04, 6.2028e-06,
        2.0164e-05, 9.7422e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:36,815][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.1669, 0.0081, 0.0934, 0.0082, 0.1939, 0.0110, 0.0066, 0.0298, 0.0787,
        0.0062, 0.0081, 0.1143, 0.2585, 0.0162], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:36,817][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0314, 0.0060, 0.0059, 0.0100, 0.0121, 0.0135, 0.0285, 0.0123, 0.0195,
        0.1036, 0.1619, 0.1669, 0.2645, 0.1638], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:36,818][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0512, 0.1060, 0.0181, 0.1040, 0.0210, 0.1013, 0.1371, 0.0312, 0.0277,
        0.1754, 0.1373, 0.0248, 0.0277, 0.0372], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:36,819][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.1477, 0.0794, 0.0587, 0.0816, 0.0460, 0.0653, 0.0621, 0.0461, 0.0542,
        0.0739, 0.0845, 0.0548, 0.0511, 0.0945], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:36,821][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.1018, 0.0734, 0.0418, 0.0774, 0.0366, 0.0798, 0.0598, 0.0250, 0.0479,
        0.0621, 0.0668, 0.0285, 0.0311, 0.2679], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:36,823][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.2405, 0.0572, 0.0406, 0.0765, 0.0677, 0.0366, 0.0307, 0.0552, 0.0656,
        0.0607, 0.0776, 0.0805, 0.0723, 0.0385], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:36,824][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2500, 0.0242, 0.0560, 0.0203, 0.0844, 0.0652, 0.0218, 0.0352, 0.0696,
        0.0242, 0.0248, 0.0806, 0.1239, 0.1038, 0.0160], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:36,825][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.1210e-03, 1.1778e-02, 2.3022e-04, 3.4314e-02, 9.7204e-05, 3.0532e-04,
        1.4491e-03, 1.7846e-04, 5.7929e-05, 8.2840e-03, 3.0205e-02, 2.4504e-04,
        6.5134e-05, 1.4514e-04, 9.0852e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:36,826][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1600, 0.0704, 0.0430, 0.0966, 0.0179, 0.0587, 0.0252, 0.0377, 0.0307,
        0.0601, 0.0951, 0.0391, 0.0179, 0.0747, 0.1729], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:36,828][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.9514e-03, 2.6644e-04, 2.4667e-05, 1.8258e-04, 1.5992e-05, 7.3080e-04,
        1.2087e-03, 2.4306e-04, 1.1507e-03, 7.2166e-03, 1.1966e-02, 1.6612e-02,
        1.4766e-03, 2.9406e-01, 6.6190e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:36,829][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0359, 0.0023, 0.0023, 0.0038, 0.0014, 0.0339, 0.0104, 0.0263, 0.0573,
        0.0123, 0.0316, 0.0733, 0.0149, 0.4163, 0.2780], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:36,830][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0433, 0.0611, 0.0033, 0.0783, 0.0016, 0.0312, 0.2263, 0.0343, 0.0048,
        0.0212, 0.0412, 0.0007, 0.0007, 0.0326, 0.4193], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:36,830][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1222, 0.0059, 0.0269, 0.0051, 0.0944, 0.0171, 0.0048, 0.0316, 0.0545,
        0.0044, 0.0064, 0.1112, 0.1581, 0.0328, 0.3244], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:36,830][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0218, 0.0041, 0.0039, 0.0068, 0.0075, 0.0088, 0.0118, 0.0181, 0.0265,
        0.0486, 0.0786, 0.0922, 0.1466, 0.2549, 0.2698], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:36,831][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0081, 0.0597, 0.0031, 0.1040, 0.0030, 0.0468, 0.1317, 0.0198, 0.0090,
        0.1514, 0.1822, 0.0048, 0.0045, 0.0339, 0.2379], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:36,831][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1198, 0.0743, 0.0403, 0.0817, 0.0402, 0.0545, 0.0695, 0.0477, 0.0429,
        0.0701, 0.0857, 0.0460, 0.0450, 0.0833, 0.0988], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:36,832][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1001, 0.0823, 0.0388, 0.0985, 0.0390, 0.0730, 0.0839, 0.0493, 0.0327,
        0.0747, 0.0910, 0.0270, 0.0353, 0.0630, 0.1113], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:36,832][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1734, 0.0685, 0.0402, 0.0704, 0.0659, 0.0488, 0.0444, 0.0520, 0.0522,
        0.0705, 0.0669, 0.0720, 0.0683, 0.0358, 0.0707], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:36,834][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:25:36,835][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[14643],
        [ 6986],
        [    1],
        [17797],
        [ 1276],
        [32920],
        [27286],
        [16930],
        [18952],
        [11409],
        [22422],
        [28880],
        [ 1347],
        [ 8566],
        [15335]], device='cuda:0')
[2024-07-24 10:25:36,837][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[46206],
        [34435],
        [    1],
        [43438],
        [14421],
        [46665],
        [41474],
        [46956],
        [47104],
        [45297],
        [44549],
        [48044],
        [10456],
        [43077],
        [43196]], device='cuda:0')
[2024-07-24 10:25:36,838][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[3840],
        [3374],
        [ 223],
        [ 904],
        [ 178],
        [4808],
        [ 618],
        [ 631],
        [ 615],
        [1435],
        [ 806],
        [1392],
        [ 357],
        [ 905],
        [1035]], device='cuda:0')
[2024-07-24 10:25:36,840][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 8300],
        [20164],
        [21192],
        [37672],
        [ 9126],
        [46680],
        [47260],
        [38320],
        [24174],
        [19178],
        [36533],
        [44944],
        [ 8138],
        [27071],
        [33322]], device='cuda:0')
[2024-07-24 10:25:36,841][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[21642],
        [11463],
        [13677],
        [28640],
        [17180],
        [29866],
        [27174],
        [25862],
        [22998],
        [ 7976],
        [33648],
        [28558],
        [22094],
        [35562],
        [31147]], device='cuda:0')
[2024-07-24 10:25:36,842][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[43232],
        [38785],
        [ 3891],
        [17304],
        [12208],
        [ 8854],
        [ 3763],
        [ 2111],
        [ 1522],
        [ 9507],
        [13775],
        [27788],
        [11594],
        [ 5706],
        [ 3493]], device='cuda:0')
[2024-07-24 10:25:36,844][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[39976],
        [40404],
        [   57],
        [26810],
        [ 1037],
        [23318],
        [29929],
        [28367],
        [16563],
        [38029],
        [35535],
        [18690],
        [  920],
        [36206],
        [40249]], device='cuda:0')
[2024-07-24 10:25:36,845][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[46203],
        [42454],
        [31202],
        [44387],
        [32747],
        [46574],
        [35687],
        [27593],
        [14476],
        [41019],
        [42844],
        [41910],
        [32261],
        [39146],
        [38652]], device='cuda:0')
[2024-07-24 10:25:36,846][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[2861],
        [2772],
        [ 132],
        [ 133],
        [2120],
        [ 720],
        [ 551],
        [ 207],
        [1863],
        [1720],
        [1436],
        [1745],
        [2903],
        [4346],
        [7716]], device='cuda:0')
[2024-07-24 10:25:36,848][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 1888],
        [ 1527],
        [  720],
        [ 1224],
        [ 1298],
        [ 2563],
        [11200],
        [17675],
        [20527],
        [ 3813],
        [ 3379],
        [ 3630],
        [ 1742],
        [ 1090],
        [ 1410]], device='cuda:0')
[2024-07-24 10:25:36,849][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 3740],
        [20921],
        [ 4141],
        [28231],
        [ 2399],
        [22328],
        [26272],
        [15492],
        [ 7693],
        [30838],
        [29030],
        [16672],
        [ 1104],
        [18144],
        [26372]], device='cuda:0')
[2024-07-24 10:25:36,851][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[29184],
        [32412],
        [31537],
        [28870],
        [25954],
        [25344],
        [24379],
        [23014],
        [20978],
        [23895],
        [24839],
        [22668],
        [24520],
        [23424],
        [25790]], device='cuda:0')
[2024-07-24 10:25:36,852][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 1746],
        [  975],
        [ 5455],
        [ 1634],
        [ 4710],
        [ 2299],
        [ 4170],
        [ 4390],
        [ 3069],
        [ 3131],
        [ 3382],
        [ 2432],
        [16910],
        [ 2476],
        [ 2339]], device='cuda:0')
[2024-07-24 10:25:36,853][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[44310],
        [45307],
        [44217],
        [43011],
        [37130],
        [40711],
        [40182],
        [41952],
        [37386],
        [36414],
        [34139],
        [34179],
        [23871],
        [29201],
        [26180]], device='cuda:0')
[2024-07-24 10:25:36,855][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[34701],
        [ 9088],
        [   21],
        [24903],
        [ 9595],
        [47409],
        [44564],
        [31356],
        [29104],
        [11328],
        [23859],
        [33943],
        [ 9630],
        [23917],
        [11375]], device='cuda:0')
[2024-07-24 10:25:36,856][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[38808],
        [38683],
        [16538],
        [34221],
        [17823],
        [35894],
        [29348],
        [27687],
        [27345],
        [30129],
        [26390],
        [27588],
        [19148],
        [27724],
        [25943]], device='cuda:0')
[2024-07-24 10:25:36,858][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 7828],
        [ 2243],
        [10607],
        [  467],
        [ 4319],
        [  174],
        [   62],
        [  532],
        [ 3092],
        [  721],
        [  138],
        [  135],
        [ 4218],
        [ 1254],
        [   19]], device='cuda:0')
[2024-07-24 10:25:36,859][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[22898],
        [29497],
        [28727],
        [31359],
        [35922],
        [29529],
        [32205],
        [34930],
        [36531],
        [31064],
        [30530],
        [34180],
        [39860],
        [25634],
        [30203]], device='cuda:0')
[2024-07-24 10:25:36,861][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 1516],
        [ 1207],
        [13544],
        [ 3092],
        [11384],
        [ 3366],
        [ 4021],
        [10760],
        [13348],
        [ 3110],
        [ 3562],
        [ 5099],
        [11118],
        [ 6214],
        [ 3788]], device='cuda:0')
[2024-07-24 10:25:36,862][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[10472],
        [10154],
        [13655],
        [ 9666],
        [30166],
        [ 7879],
        [ 8871],
        [ 6855],
        [ 6833],
        [ 6712],
        [ 5125],
        [43375],
        [28914],
        [ 7481],
        [ 8521]], device='cuda:0')
[2024-07-24 10:25:36,863][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[11165],
        [ 8656],
        [ 2907],
        [ 5696],
        [18089],
        [ 4441],
        [ 3433],
        [ 6133],
        [25969],
        [ 6182],
        [ 6257],
        [11175],
        [20035],
        [ 5618],
        [ 5844]], device='cuda:0')
[2024-07-24 10:25:36,865][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[32668],
        [33056],
        [15588],
        [17027],
        [26398],
        [ 7408],
        [ 9926],
        [12614],
        [32948],
        [14348],
        [20795],
        [39190],
        [32166],
        [10111],
        [35254]], device='cuda:0')
[2024-07-24 10:25:36,866][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[30315],
        [30988],
        [30603],
        [23140],
        [27274],
        [32982],
        [17054],
        [18767],
        [23276],
        [30840],
        [28520],
        [29316],
        [33368],
        [32848],
        [25155]], device='cuda:0')
[2024-07-24 10:25:36,868][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[43290],
        [31028],
        [39246],
        [29369],
        [39500],
        [30324],
        [16303],
        [23775],
        [32140],
        [18753],
        [19520],
        [30282],
        [36807],
        [25359],
        [21194]], device='cuda:0')
[2024-07-24 10:25:36,869][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[11336],
        [ 7251],
        [ 7007],
        [ 8450],
        [ 9508],
        [11136],
        [10920],
        [12089],
        [13617],
        [10304],
        [ 9903],
        [10889],
        [10034],
        [12780],
        [11648]], device='cuda:0')
[2024-07-24 10:25:36,870][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[31205],
        [42708],
        [41051],
        [46415],
        [44254],
        [43129],
        [46111],
        [42116],
        [40115],
        [46017],
        [46133],
        [43938],
        [43556],
        [43034],
        [46331]], device='cuda:0')
[2024-07-24 10:25:36,872][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 3731],
        [ 7116],
        [20022],
        [24714],
        [34319],
        [29945],
        [37040],
        [34818],
        [38193],
        [40399],
        [38345],
        [39791],
        [35722],
        [35769],
        [38377]], device='cuda:0')
[2024-07-24 10:25:36,873][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[11216],
        [ 8186],
        [10250],
        [10894],
        [ 6033],
        [14309],
        [15999],
        [12560],
        [ 7621],
        [11179],
        [13314],
        [ 7205],
        [ 6336],
        [13052],
        [11685]], device='cuda:0')
[2024-07-24 10:25:36,875][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 7566],
        [30601],
        [50065],
        [15205],
        [31255],
        [ 1356],
        [ 2296],
        [10955],
        [13358],
        [28705],
        [16159],
        [ 9896],
        [31272],
        [16209],
        [29543]], device='cuda:0')
[2024-07-24 10:25:36,876][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[25786],
        [25786],
        [25786],
        [25786],
        [25786],
        [25786],
        [25786],
        [25786],
        [25786],
        [25786],
        [25786],
        [25786],
        [25786],
        [25786],
        [25786]], device='cuda:0')
[2024-07-24 10:25:36,890][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:36,891][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,892][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,893][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,894][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,895][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,897][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,898][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,898][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,899][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,900][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,900][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,901][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:36,902][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9818, 0.0182], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,902][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.9962, 0.0038], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,903][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.5767, 0.4233], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,904][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5815, 0.4185], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,905][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2890, 0.7110], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,906][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4108, 0.5892], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,908][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9365, 0.0635], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,909][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9750, 0.0250], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,911][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.7865, 0.2135], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,912][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0013, 0.9987], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,914][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([5.2726e-04, 9.9947e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,915][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.8281, 0.1719], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:36,916][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Jose] are: tensor([9.9693e-01, 6.5241e-04, 2.4161e-03], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,918][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Jose] are: tensor([0.7165, 0.2398, 0.0437], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,919][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Jose] are: tensor([0.4097, 0.2947, 0.2956], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,921][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Jose] are: tensor([0.5756, 0.2364, 0.1880], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,923][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Jose] are: tensor([0.0785, 0.4298, 0.4917], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,924][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Jose] are: tensor([0.2092, 0.6741, 0.1167], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,926][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Jose] are: tensor([0.5362, 0.1117, 0.3521], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,927][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Jose] are: tensor([0.7297, 0.0843, 0.1860], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,929][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Jose] are: tensor([0.7221, 0.1934, 0.0845], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,931][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Jose] are: tensor([0.0018, 0.0532, 0.9450], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,932][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Jose] are: tensor([0.0010, 0.5772, 0.4217], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,934][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Jose] are: tensor([0.0280, 0.0058, 0.9662], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:36,936][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.9751, 0.0055, 0.0153, 0.0041], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,936][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.7395, 0.1045, 0.1019, 0.0540], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,937][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3146, 0.2278, 0.2316, 0.2261], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,938][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.5248, 0.1699, 0.1361, 0.1692], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,939][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0646, 0.2044, 0.5297, 0.2013], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,939][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1041, 0.7687, 0.0556, 0.0717], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,941][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.5446, 0.1706, 0.1625, 0.1222], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,942][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.5696, 0.0643, 0.2641, 0.1020], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,944][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7207, 0.1492, 0.0733, 0.0569], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,945][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([2.2206e-04, 1.5433e-01, 8.3531e-01, 1.0138e-02], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,947][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0023, 0.3399, 0.3127, 0.3451], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,948][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4649, 0.1039, 0.0406, 0.3906], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:36,949][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Stephanie] are: tensor([9.9940e-01, 9.7859e-05, 3.5554e-04, 1.3119e-04, 1.3347e-05],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,951][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Stephanie] are: tensor([0.5157, 0.1176, 0.0719, 0.2128, 0.0820], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,953][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Stephanie] are: tensor([0.2680, 0.1821, 0.1820, 0.1795, 0.1882], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,954][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Stephanie] are: tensor([0.4594, 0.1361, 0.1168, 0.1600, 0.1278], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,956][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Stephanie] are: tensor([0.0501, 0.2627, 0.2815, 0.2263, 0.1793], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,958][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Stephanie] are: tensor([0.1453, 0.2195, 0.2573, 0.0764, 0.3015], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,959][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Stephanie] are: tensor([0.5790, 0.1154, 0.0963, 0.0649, 0.1444], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,961][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Stephanie] are: tensor([0.4420, 0.1467, 0.1732, 0.2049, 0.0333], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,963][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Stephanie] are: tensor([0.5146, 0.2092, 0.0887, 0.1126, 0.0748], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,964][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Stephanie] are: tensor([0.0076, 0.0942, 0.7117, 0.0226, 0.1639], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,966][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Stephanie] are: tensor([0.0011, 0.2538, 0.2134, 0.2571, 0.2745], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,968][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Stephanie] are: tensor([0.0188, 0.0059, 0.0059, 0.0035, 0.9660], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:36,969][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ had] are: tensor([9.9817e-01, 3.0143e-04, 1.1817e-03, 2.4745e-04, 2.5248e-05, 7.6221e-05],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,970][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.6535, 0.0593, 0.0426, 0.1284, 0.0604, 0.0559], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,972][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.2205, 0.1562, 0.1582, 0.1541, 0.1627, 0.1483], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,974][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.4425, 0.1007, 0.0840, 0.1097, 0.0970, 0.1662], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,975][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0438, 0.1814, 0.2620, 0.1296, 0.2059, 0.1773], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,977][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0589, 0.7136, 0.0483, 0.0100, 0.0478, 0.1214], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,978][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.3490, 0.1058, 0.2210, 0.1519, 0.0877, 0.0846], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,979][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.4327, 0.0515, 0.1402, 0.0702, 0.1759, 0.1295], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,980][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.5862, 0.1509, 0.0502, 0.0547, 0.0549, 0.1032], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,981][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ had] are: tensor([6.6720e-04, 1.6417e-01, 8.0511e-01, 1.1535e-02, 1.8235e-02, 2.8607e-04],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,982][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0017, 0.1407, 0.1510, 0.1604, 0.2264, 0.3198], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,983][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0223, 0.0170, 0.0020, 0.0144, 0.0026, 0.9415], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:36,984][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([9.9526e-01, 7.2071e-04, 1.9909e-03, 6.9329e-04, 5.3139e-05, 2.5481e-04,
        1.0228e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,986][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.3890, 0.0459, 0.0585, 0.1350, 0.0934, 0.2068, 0.0714],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,988][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1942, 0.1357, 0.1375, 0.1338, 0.1417, 0.1287, 0.1285],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,989][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.4295, 0.0871, 0.0706, 0.0913, 0.0804, 0.1359, 0.1051],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,991][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0448, 0.1457, 0.2424, 0.1250, 0.1727, 0.1469, 0.1225],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,993][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1708, 0.5192, 0.0534, 0.0224, 0.0992, 0.0934, 0.0416],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,994][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2860, 0.1448, 0.1254, 0.1534, 0.1420, 0.0495, 0.0990],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,996][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.4401, 0.0555, 0.1170, 0.0718, 0.1209, 0.1147, 0.0799],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,998][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.5577, 0.1413, 0.0465, 0.0490, 0.0514, 0.0949, 0.0591],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:36,999][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([4.9550e-04, 2.3205e-01, 7.4457e-01, 1.1159e-02, 8.3783e-03, 2.1449e-04,
        3.1240e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,000][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0024, 0.1059, 0.1208, 0.1251, 0.1909, 0.2505, 0.2044],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,002][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.4916e-02, 3.9085e-03, 7.9263e-04, 3.8552e-03, 8.4717e-04, 2.1338e-03,
        9.7355e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,003][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ long] are: tensor([9.9375e-01, 8.9763e-04, 2.6184e-03, 8.2889e-04, 6.9382e-05, 2.8906e-04,
        1.1495e-03, 3.9512e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,004][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.2259, 0.0468, 0.0662, 0.1045, 0.1309, 0.1530, 0.2179, 0.0547],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,006][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.1748, 0.1183, 0.1178, 0.1163, 0.1215, 0.1109, 0.1107, 0.1298],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,008][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.4478, 0.0682, 0.0604, 0.0832, 0.0700, 0.1217, 0.1010, 0.0477],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,009][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0345, 0.1618, 0.1961, 0.1110, 0.1397, 0.1364, 0.0954, 0.1251],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,011][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.1042, 0.6441, 0.0049, 0.0184, 0.0036, 0.0258, 0.1067, 0.0923],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,013][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.1982, 0.2486, 0.0470, 0.1458, 0.0678, 0.0839, 0.1157, 0.0930],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,014][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.4442, 0.0671, 0.0741, 0.0687, 0.0540, 0.1697, 0.0818, 0.0404],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,016][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.5085, 0.1338, 0.0497, 0.0608, 0.0515, 0.1066, 0.0676, 0.0214],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,017][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ long] are: tensor([7.0365e-04, 2.4033e-01, 7.2872e-01, 1.4331e-02, 1.1449e-02, 3.6577e-04,
        3.8122e-03, 2.9217e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,019][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0018, 0.0885, 0.0974, 0.1053, 0.1632, 0.1942, 0.1611, 0.1885],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,020][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ long] are: tensor([2.6804e-02, 1.0184e-02, 4.5630e-04, 6.6311e-03, 1.5783e-03, 5.6590e-03,
        4.2598e-03, 9.4443e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,021][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([9.9915e-01, 8.5923e-05, 3.4683e-04, 1.1965e-04, 1.3106e-05, 3.8855e-05,
        1.6666e-04, 6.5263e-05, 1.7366e-05], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,022][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.3580, 0.0290, 0.0352, 0.0812, 0.0683, 0.1388, 0.0840, 0.0793, 0.1262],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,023][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.1593, 0.1036, 0.1032, 0.1015, 0.1069, 0.0968, 0.0969, 0.1141, 0.1176],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,024][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.4161, 0.0611, 0.0537, 0.0768, 0.0662, 0.1093, 0.0952, 0.0475, 0.0740],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,025][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0268, 0.1136, 0.1734, 0.0747, 0.1351, 0.1146, 0.0634, 0.0823, 0.2162],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,027][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0960, 0.1302, 0.0514, 0.0133, 0.4997, 0.0217, 0.1156, 0.0124, 0.0596],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,028][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.3501, 0.1405, 0.0644, 0.1027, 0.0155, 0.0609, 0.0699, 0.0337, 0.1622],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,030][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.2738, 0.0313, 0.1393, 0.0621, 0.0883, 0.1909, 0.0580, 0.0794, 0.0771],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,032][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.4846, 0.1245, 0.0487, 0.0479, 0.0498, 0.1010, 0.0521, 0.0161, 0.0753],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,033][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([5.1768e-04, 1.7281e-01, 8.0116e-01, 8.3394e-03, 1.3294e-02, 3.0829e-04,
        2.6845e-03, 4.3530e-04, 4.4096e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,034][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0022, 0.0652, 0.0807, 0.0816, 0.1248, 0.1571, 0.1203, 0.1387, 0.2294],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,036][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0430, 0.0121, 0.0064, 0.0098, 0.0036, 0.0020, 0.0147, 0.0025, 0.9058],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,037][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([9.8630e-01, 1.5313e-03, 3.6534e-03, 1.7580e-03, 1.3539e-04, 6.8985e-04,
        3.3329e-03, 1.0767e-03, 3.1579e-04, 1.2041e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,039][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.2710, 0.0042, 0.0639, 0.0913, 0.0939, 0.1066, 0.0973, 0.0642, 0.1181,
        0.0895], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,041][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1372, 0.0930, 0.0943, 0.0915, 0.0974, 0.0878, 0.0879, 0.1040, 0.1071,
        0.0999], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,042][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3933, 0.0666, 0.0533, 0.0699, 0.0579, 0.0998, 0.0720, 0.0363, 0.0671,
        0.0838], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,044][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0261, 0.0947, 0.1772, 0.0805, 0.1209, 0.1083, 0.0670, 0.0849, 0.1762,
        0.0642], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,046][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0199, 0.4597, 0.0527, 0.0008, 0.0134, 0.0137, 0.0218, 0.0032, 0.0195,
        0.3954], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,047][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1858, 0.0977, 0.0777, 0.1071, 0.0439, 0.0597, 0.1072, 0.0937, 0.1190,
        0.1083], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,049][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.3142, 0.0347, 0.1097, 0.0456, 0.0985, 0.0698, 0.0463, 0.0354, 0.1460,
        0.0997], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,051][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4263, 0.1018, 0.0352, 0.0351, 0.0379, 0.0650, 0.0370, 0.0115, 0.0648,
        0.1852], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,052][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([1.3534e-04, 1.8581e-01, 7.8393e-01, 6.5457e-03, 1.3903e-02, 5.5428e-05,
        1.2114e-03, 1.8442e-04, 4.6247e-04, 7.7561e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,054][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0035, 0.0443, 0.0572, 0.0598, 0.0939, 0.1285, 0.0914, 0.1101, 0.1941,
        0.2172], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,056][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0722, 0.0428, 0.0373, 0.0422, 0.0717, 0.0599, 0.0899, 0.0749, 0.0932,
        0.4160], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,057][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([9.8759e-01, 1.3738e-03, 3.2226e-03, 1.3941e-03, 1.4400e-04, 6.1005e-04,
        2.6696e-03, 1.0057e-03, 3.1233e-04, 1.0754e-03, 6.0482e-04],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,058][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1251, 0.0136, 0.0305, 0.0116, 0.0460, 0.1081, 0.0813, 0.0404, 0.1139,
        0.3516, 0.0779], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,060][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1223, 0.0846, 0.0862, 0.0834, 0.0892, 0.0803, 0.0805, 0.0954, 0.0982,
        0.0915, 0.0885], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,062][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3994, 0.0569, 0.0455, 0.0613, 0.0490, 0.0871, 0.0630, 0.0318, 0.0580,
        0.0765, 0.0716], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,063][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0241, 0.0780, 0.1870, 0.0765, 0.1260, 0.0857, 0.0590, 0.0731, 0.1737,
        0.0556, 0.0612], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,064][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0299, 0.3147, 0.0528, 0.0177, 0.0056, 0.0102, 0.0349, 0.0109, 0.0399,
        0.4588, 0.0246], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,064][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2034, 0.1043, 0.0599, 0.0571, 0.0687, 0.0501, 0.1379, 0.0548, 0.0618,
        0.1540, 0.0479], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,065][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2670, 0.0323, 0.0954, 0.0434, 0.0617, 0.1029, 0.0516, 0.0386, 0.1327,
        0.1061, 0.0684], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,067][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.3806, 0.0908, 0.0349, 0.0317, 0.0396, 0.0597, 0.0324, 0.0105, 0.0615,
        0.1631, 0.0953], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,068][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([2.0696e-04, 2.0887e-01, 7.6015e-01, 6.6792e-03, 6.8627e-03, 8.7978e-05,
        2.7437e-03, 2.5699e-04, 5.1042e-04, 1.2464e-02, 1.1758e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,070][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0031, 0.0365, 0.0482, 0.0509, 0.0763, 0.1077, 0.0739, 0.0887, 0.1575,
        0.1757, 0.1815], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,072][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0594, 0.0220, 0.0082, 0.0698, 0.0142, 0.0488, 0.0127, 0.0134, 0.0262,
        0.3266, 0.3988], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,073][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([9.9314e-01, 7.2922e-04, 1.7513e-03, 8.2625e-04, 8.7969e-05, 3.3675e-04,
        1.3180e-03, 5.7399e-04, 1.6511e-04, 6.2192e-04, 3.7322e-04, 7.3733e-05],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,075][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0704, 0.0103, 0.0226, 0.0410, 0.0248, 0.0236, 0.0329, 0.0340, 0.0695,
        0.2981, 0.3621, 0.0108], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,076][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.1169, 0.0774, 0.0776, 0.0760, 0.0805, 0.0724, 0.0728, 0.0857, 0.0883,
        0.0828, 0.0802, 0.0894], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,078][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.3303, 0.0493, 0.0401, 0.0611, 0.0431, 0.0829, 0.0761, 0.0343, 0.0589,
        0.0929, 0.0876, 0.0434], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,080][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0222, 0.1109, 0.1149, 0.0816, 0.0869, 0.0780, 0.0643, 0.0737, 0.1548,
        0.0685, 0.0578, 0.0864], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,082][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.1153, 0.0835, 0.0158, 0.0170, 0.0039, 0.1563, 0.0339, 0.1243, 0.0278,
        0.0393, 0.0160, 0.3668], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,083][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.1164, 0.0439, 0.0359, 0.0354, 0.1432, 0.1422, 0.0278, 0.2733, 0.0364,
        0.0729, 0.0348, 0.0378], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,085][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.2909, 0.0295, 0.1067, 0.0301, 0.0440, 0.1166, 0.0438, 0.0409, 0.1256,
        0.0738, 0.0430, 0.0551], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,087][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.1535, 0.0497, 0.0266, 0.0274, 0.0197, 0.0756, 0.0375, 0.0130, 0.0399,
        0.1690, 0.0869, 0.3012], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,088][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([1.9411e-04, 2.2392e-01, 4.5044e-01, 1.9169e-02, 2.7862e-01, 1.6582e-04,
        9.1401e-04, 1.5249e-03, 1.4608e-02, 2.3406e-03, 7.9628e-03, 1.4510e-04],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,090][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0024, 0.0347, 0.0455, 0.0456, 0.0687, 0.0850, 0.0652, 0.0796, 0.1307,
        0.1353, 0.1388, 0.1683], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,091][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([7.5208e-03, 1.8205e-03, 7.7670e-04, 1.7914e-03, 2.1212e-03, 5.9610e-04,
        2.7389e-04, 4.9805e-03, 3.1615e-03, 7.2182e-03, 3.7740e-03, 9.6597e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,092][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Stephanie] are: tensor([9.9865e-01, 1.1175e-04, 2.7201e-04, 1.5831e-04, 1.8815e-05, 6.5684e-05,
        2.9531e-04, 1.1890e-04, 3.6491e-05, 1.4637e-04, 9.8199e-05, 1.7742e-05,
        1.1467e-05], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,094][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Stephanie] are: tensor([0.0481, 0.0081, 0.0074, 0.0177, 0.0079, 0.0529, 0.0285, 0.0293, 0.0846,
        0.3574, 0.2091, 0.1053, 0.0438], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,096][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Stephanie] are: tensor([0.1090, 0.0712, 0.0713, 0.0701, 0.0739, 0.0664, 0.0668, 0.0784, 0.0811,
        0.0764, 0.0745, 0.0823, 0.0786], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,098][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Stephanie] are: tensor([0.3125, 0.0452, 0.0403, 0.0587, 0.0409, 0.0875, 0.0678, 0.0293, 0.0607,
        0.0849, 0.0831, 0.0404, 0.0487], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,099][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Stephanie] are: tensor([0.0169, 0.1053, 0.1078, 0.0881, 0.0687, 0.0829, 0.0566, 0.0637, 0.1374,
        0.0636, 0.0633, 0.0807, 0.0650], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,101][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Stephanie] are: tensor([0.0064, 0.0524, 0.0539, 0.0138, 0.0798, 0.0042, 0.0116, 0.0092, 0.0630,
        0.1490, 0.0675, 0.0315, 0.4577], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,103][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Stephanie] are: tensor([0.0995, 0.0779, 0.0396, 0.0374, 0.1529, 0.0259, 0.0462, 0.0232, 0.0823,
        0.1328, 0.0336, 0.1250, 0.1237], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,104][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Stephanie] are: tensor([0.0813, 0.0425, 0.0416, 0.0526, 0.0069, 0.2170, 0.0754, 0.0205, 0.1678,
        0.1553, 0.0944, 0.0364, 0.0082], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,105][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Stephanie] are: tensor([0.1289, 0.0650, 0.0230, 0.0331, 0.0165, 0.0872, 0.0543, 0.0156, 0.0450,
        0.1839, 0.0899, 0.2409, 0.0167], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,106][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Stephanie] are: tensor([0.0017, 0.1003, 0.7520, 0.0160, 0.0641, 0.0016, 0.0039, 0.0015, 0.0059,
        0.0144, 0.0068, 0.0022, 0.0296], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,107][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Stephanie] are: tensor([0.0012, 0.0339, 0.0391, 0.0424, 0.0536, 0.0824, 0.0570, 0.0686, 0.1062,
        0.1159, 0.1221, 0.1518, 0.1257], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,108][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Stephanie] are: tensor([1.4021e-05, 4.0026e-05, 3.1681e-05, 1.4643e-05, 3.9986e-02, 3.5255e-05,
        8.4964e-05, 6.6706e-05, 1.2400e-04, 8.6916e-03, 4.2078e-04, 2.1024e-04,
        9.5028e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,109][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ said] are: tensor([9.9394e-01, 6.4507e-04, 1.8610e-03, 6.7954e-04, 7.0334e-05, 2.6635e-04,
        1.0943e-03, 4.3649e-04, 1.2523e-04, 4.5368e-04, 2.5585e-04, 5.5157e-05,
        3.0724e-05, 8.6679e-05], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,111][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0655, 0.0078, 0.0072, 0.0138, 0.0107, 0.0355, 0.0222, 0.0216, 0.0232,
        0.2827, 0.1788, 0.2541, 0.0543, 0.0227], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,113][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0987, 0.0658, 0.0664, 0.0648, 0.0689, 0.0622, 0.0623, 0.0736, 0.0759,
        0.0710, 0.0686, 0.0765, 0.0723, 0.0730], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,114][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.3627, 0.0403, 0.0323, 0.0470, 0.0333, 0.0676, 0.0531, 0.0237, 0.0450,
        0.0686, 0.0635, 0.0341, 0.0377, 0.0911], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,116][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0141, 0.0738, 0.1232, 0.0511, 0.0821, 0.0689, 0.0468, 0.0462, 0.1209,
        0.0524, 0.0400, 0.0885, 0.0808, 0.1110], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,118][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0265, 0.2032, 0.0261, 0.0059, 0.0222, 0.0859, 0.0693, 0.0249, 0.1179,
        0.0977, 0.0053, 0.0166, 0.0110, 0.2875], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,119][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.2046, 0.0526, 0.0272, 0.0604, 0.0053, 0.0938, 0.0396, 0.0519, 0.2505,
        0.0716, 0.0525, 0.0568, 0.0016, 0.0315], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,121][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.2329, 0.0258, 0.0747, 0.0397, 0.0659, 0.0532, 0.0318, 0.0548, 0.1080,
        0.0826, 0.0706, 0.0662, 0.0572, 0.0366], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,123][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.1999, 0.0609, 0.0200, 0.0220, 0.0206, 0.0444, 0.0268, 0.0076, 0.0385,
        0.1328, 0.0665, 0.2900, 0.0272, 0.0429], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,124][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ said] are: tensor([1.0936e-04, 8.6474e-02, 8.7035e-01, 5.2034e-03, 2.2800e-02, 4.4476e-05,
        8.3916e-04, 2.8959e-04, 5.9621e-04, 4.5447e-03, 1.1641e-03, 1.4712e-03,
        6.0666e-03, 4.2167e-05], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,126][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0024, 0.0198, 0.0279, 0.0276, 0.0441, 0.0560, 0.0396, 0.0472, 0.0800,
        0.0907, 0.0940, 0.1259, 0.1140, 0.2309], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,127][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ said] are: tensor([4.5247e-03, 2.5389e-03, 4.5429e-04, 2.6676e-03, 7.0463e-04, 8.1326e-04,
        5.5276e-03, 7.0640e-04, 9.5322e-03, 4.9700e-02, 9.4997e-03, 1.7607e-03,
        9.7394e-04, 9.1060e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,129][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.8099e-01, 2.3082e-03, 4.3504e-03, 2.0964e-03, 1.7947e-04, 8.8409e-04,
        3.7298e-03, 1.2930e-03, 3.9812e-04, 1.6840e-03, 8.9148e-04, 1.7160e-04,
        1.0104e-04, 3.4846e-04, 5.7372e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,130][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0530, 0.0037, 0.0117, 0.0186, 0.0184, 0.0357, 0.0416, 0.0132, 0.0517,
        0.1498, 0.1881, 0.0627, 0.0635, 0.1709, 0.1175], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,132][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0912, 0.0614, 0.0624, 0.0605, 0.0645, 0.0581, 0.0582, 0.0688, 0.0710,
        0.0662, 0.0641, 0.0713, 0.0677, 0.0681, 0.0666], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,134][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.3796, 0.0397, 0.0308, 0.0422, 0.0307, 0.0617, 0.0464, 0.0203, 0.0391,
        0.0569, 0.0513, 0.0299, 0.0321, 0.0747, 0.0647], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,136][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0213, 0.0585, 0.1240, 0.0482, 0.0929, 0.0628, 0.0525, 0.0598, 0.1062,
        0.0441, 0.0388, 0.0889, 0.0914, 0.0715, 0.0393], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,137][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([2.5182e-04, 8.6154e-05, 1.9578e-04, 3.4227e-05, 1.1073e-03, 1.8967e-04,
        5.9256e-04, 1.0916e-04, 3.3015e-04, 8.6705e-05, 1.5688e-05, 1.6060e-04,
        3.8774e-04, 4.7989e-04, 9.9597e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,139][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1205, 0.0680, 0.0616, 0.1187, 0.0182, 0.0279, 0.0773, 0.0507, 0.0493,
        0.0990, 0.0879, 0.1088, 0.0095, 0.0362, 0.0662], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,141][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.2212, 0.0381, 0.0639, 0.0397, 0.0437, 0.0477, 0.0385, 0.0276, 0.1104,
        0.0809, 0.0488, 0.0527, 0.0334, 0.0715, 0.0820], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,142][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0656, 0.0207, 0.0165, 0.0098, 0.0207, 0.0375, 0.0206, 0.0063, 0.0198,
        0.0585, 0.0309, 0.1158, 0.0262, 0.0257, 0.5253], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,144][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([7.8322e-05, 1.7778e-01, 7.8660e-01, 6.2997e-03, 1.7397e-02, 4.1453e-05,
        1.1330e-03, 2.7731e-04, 7.2587e-04, 4.5502e-03, 1.1331e-03, 8.2997e-04,
        3.0098e-03, 3.8169e-05, 9.7618e-05], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,145][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0033, 0.0135, 0.0194, 0.0192, 0.0314, 0.0431, 0.0304, 0.0342, 0.0642,
        0.0741, 0.0744, 0.1057, 0.0921, 0.2108, 0.1840], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,146][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0260, 0.0085, 0.0014, 0.0138, 0.0036, 0.0036, 0.0157, 0.0025, 0.0063,
        0.1624, 0.0511, 0.0067, 0.0068, 0.0220, 0.6696], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,171][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:37,172][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,174][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,175][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,176][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,176][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,177][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,178][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,178][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,179][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,180][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,180][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,181][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,182][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2581, 0.7419], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,183][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9990, 0.0010], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,184][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.8365, 0.1635], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,186][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6608, 0.3392], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,187][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3153, 0.6847], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,189][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1658, 0.8342], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,191][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1281, 0.8719], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,192][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3866, 0.6134], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,194][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1982, 0.8018], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,195][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0136, 0.9864], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,197][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0010, 0.9990], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,199][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1845, 0.8155], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,200][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Jose] are: tensor([0.0250, 0.3424, 0.6326], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,202][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Jose] are: tensor([0.5658, 0.2116, 0.2227], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,203][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Jose] are: tensor([0.5298, 0.2658, 0.2045], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,204][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Jose] are: tensor([0.3998, 0.1984, 0.4018], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,205][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Jose] are: tensor([0.1595, 0.4248, 0.4156], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,206][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Jose] are: tensor([0.0681, 0.7876, 0.1442], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,206][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Jose] are: tensor([0.0045, 0.7932, 0.2024], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,207][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Jose] are: tensor([0.1609, 0.4236, 0.4154], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,209][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Jose] are: tensor([0.2783, 0.5876, 0.1341], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,210][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Jose] are: tensor([0.0044, 0.9701, 0.0255], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,212][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Jose] are: tensor([0.0018, 0.5799, 0.4183], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,213][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Jose] are: tensor([0.2251, 0.7555, 0.0194], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,215][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0285, 0.2050, 0.5472, 0.2193], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,216][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.4907, 0.0210, 0.4872, 0.0010], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,218][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4248, 0.1441, 0.1622, 0.2689], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,220][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2751, 0.1103, 0.4208, 0.1939], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,221][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1238, 0.2711, 0.3547, 0.2504], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,222][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([5.5274e-03, 9.6509e-01, 2.8991e-02, 3.9375e-04], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,223][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([4.3840e-04, 1.3746e-03, 9.9614e-01, 2.0441e-03], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,225][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1420, 0.2589, 0.3811, 0.2180], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,226][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0743, 0.3885, 0.0101, 0.5271], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,228][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0053, 0.9005, 0.0558, 0.0384], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,230][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0043, 0.3311, 0.3050, 0.3596], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,231][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([6.3894e-02, 1.7040e-01, 7.2380e-04, 7.6498e-01], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,232][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Stephanie] are: tensor([0.0134, 0.1501, 0.4421, 0.1827, 0.2117], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,234][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Stephanie] are: tensor([0.7728, 0.0920, 0.0813, 0.0426, 0.0113], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,236][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Stephanie] are: tensor([0.3293, 0.1838, 0.1364, 0.2666, 0.0840], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,237][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Stephanie] are: tensor([0.2269, 0.1177, 0.2784, 0.1729, 0.2042], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,239][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Stephanie] are: tensor([0.0947, 0.2473, 0.2411, 0.2127, 0.2042], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,240][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Stephanie] are: tensor([2.8768e-02, 7.9088e-01, 1.7935e-01, 1.5422e-04, 8.4369e-04],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,242][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Stephanie] are: tensor([0.0016, 0.2388, 0.0799, 0.3831, 0.2967], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,243][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Stephanie] are: tensor([0.0855, 0.2622, 0.2579, 0.1756, 0.2189], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,245][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Stephanie] are: tensor([0.0375, 0.5983, 0.0375, 0.2938, 0.0329], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,246][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Stephanie] are: tensor([0.0090, 0.9147, 0.0374, 0.0286, 0.0104], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,247][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Stephanie] are: tensor([0.0021, 0.2552, 0.2185, 0.2789, 0.2454], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,248][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Stephanie] are: tensor([0.0961, 0.2480, 0.0011, 0.6403, 0.0146], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,249][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0267, 0.0912, 0.2606, 0.1363, 0.1273, 0.3578], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,250][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.4363, 0.1207, 0.1764, 0.0742, 0.1802, 0.0122], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,251][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.2662, 0.1632, 0.1335, 0.1961, 0.0905, 0.1504], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,253][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1739, 0.0814, 0.2363, 0.1275, 0.1842, 0.1966], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,254][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0777, 0.1798, 0.2073, 0.1535, 0.1884, 0.1933], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,255][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([1.3952e-03, 9.6315e-01, 3.6671e-03, 2.1468e-03, 9.5586e-04, 2.8682e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,257][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0054, 0.0250, 0.0403, 0.2406, 0.1755, 0.5131], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,258][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0851, 0.1507, 0.2102, 0.1412, 0.2391, 0.1736], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,260][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0106, 0.3869, 0.0094, 0.1926, 0.0122, 0.3884], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,262][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0023, 0.7438, 0.0370, 0.0071, 0.0089, 0.2009], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,263][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0030, 0.1486, 0.1581, 0.1844, 0.2004, 0.3054], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,264][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([3.9076e-02, 2.3598e-01, 7.0425e-04, 5.6462e-01, 5.2400e-04, 1.5910e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,266][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0066, 0.0511, 0.1154, 0.0748, 0.1021, 0.4183, 0.2317],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,268][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.4579, 0.0644, 0.1889, 0.0361, 0.1750, 0.0737, 0.0041],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,269][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2756, 0.1221, 0.1034, 0.1767, 0.0796, 0.1023, 0.1403],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,271][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1580, 0.0665, 0.2073, 0.1026, 0.1625, 0.1548, 0.1483],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,272][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0717, 0.1538, 0.1785, 0.1370, 0.1561, 0.1631, 0.1398],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,274][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([2.7489e-03, 9.8185e-01, 1.1375e-02, 1.2113e-04, 2.3005e-04, 3.3324e-03,
        3.4690e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,275][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([2.5891e-04, 2.2154e-03, 5.1907e-01, 1.1883e-02, 4.0658e-01, 5.9988e-02,
        1.9768e-06], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,276][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0750, 0.1141, 0.1615, 0.1025, 0.2050, 0.1504, 0.1915],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,278][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0215, 0.1144, 0.0022, 0.1252, 0.0023, 0.0601, 0.6743],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,280][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0033, 0.6379, 0.0298, 0.0108, 0.0059, 0.0825, 0.2299],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,281][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0037, 0.1080, 0.1247, 0.1416, 0.1623, 0.2334, 0.2264],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,283][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([4.1682e-02, 1.6303e-01, 4.1417e-04, 4.6314e-01, 9.8493e-04, 1.2143e-02,
        3.1861e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,284][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0027, 0.0249, 0.1020, 0.0439, 0.0488, 0.3074, 0.3359, 0.1346],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,285][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([7.1138e-01, 1.5561e-02, 1.3893e-01, 2.3886e-02, 3.7963e-02, 2.6440e-02,
        4.5449e-02, 3.9110e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,287][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.2569, 0.1206, 0.1022, 0.1491, 0.0696, 0.0991, 0.1053, 0.0972],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,289][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.1403, 0.0616, 0.2092, 0.0986, 0.1494, 0.1478, 0.1168, 0.0761],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,289][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0562, 0.1405, 0.1480, 0.1183, 0.1299, 0.1440, 0.1176, 0.1454],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,290][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([4.1176e-03, 9.3790e-01, 1.3302e-02, 6.7335e-04, 7.0186e-04, 8.9570e-03,
        4.0102e-03, 3.0338e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,291][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0007, 0.0212, 0.4658, 0.0549, 0.0161, 0.4334, 0.0007, 0.0073],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,292][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0589, 0.0979, 0.1302, 0.0846, 0.1523, 0.1675, 0.2027, 0.1058],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,293][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([1.1775e-03, 1.4998e-01, 1.5324e-03, 8.0109e-02, 9.9658e-04, 5.2066e-02,
        7.1396e-01, 1.7619e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,295][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0012, 0.7347, 0.0438, 0.0162, 0.0096, 0.0384, 0.1549, 0.0012],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,296][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0031, 0.0856, 0.0990, 0.1189, 0.1439, 0.1920, 0.1900, 0.1676],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,298][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([5.9783e-02, 1.8605e-01, 3.4351e-04, 6.4750e-01, 6.2154e-04, 3.0689e-02,
        2.5354e-02, 4.9659e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,299][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0016, 0.0266, 0.0694, 0.0439, 0.0572, 0.2367, 0.2608, 0.2409, 0.0630],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,300][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([9.4378e-01, 5.8704e-03, 2.3370e-02, 8.2881e-03, 3.1265e-03, 7.3102e-03,
        7.6423e-03, 2.0332e-04, 4.0747e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,302][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.2105, 0.1092, 0.0967, 0.1410, 0.0629, 0.0943, 0.0976, 0.0798, 0.1078],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,304][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.1306, 0.0559, 0.1956, 0.0956, 0.1437, 0.1389, 0.1076, 0.0700, 0.0621],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,305][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0460, 0.1150, 0.1244, 0.0936, 0.1113, 0.1200, 0.0937, 0.1179, 0.1782],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,307][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([1.7091e-03, 9.6159e-01, 3.0150e-02, 5.6371e-05, 1.3723e-04, 1.9105e-03,
        2.5520e-04, 4.1162e-03, 7.3778e-05], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,308][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([4.2274e-04, 1.2647e-02, 6.9428e-02, 3.0605e-01, 1.1391e-03, 1.5288e-02,
        4.6761e-04, 4.0012e-04, 5.9415e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,309][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0458, 0.0809, 0.1338, 0.0618, 0.1416, 0.1432, 0.1129, 0.1370, 0.1430],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,311][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([2.6681e-03, 4.0536e-02, 9.9039e-04, 1.8673e-02, 1.7575e-03, 1.1925e-01,
        8.1532e-01, 5.3402e-04, 2.6685e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,312][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0011, 0.5386, 0.0407, 0.0071, 0.0128, 0.0775, 0.3192, 0.0018, 0.0012],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,314][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0032, 0.0695, 0.0856, 0.0970, 0.1136, 0.1591, 0.1462, 0.1297, 0.1960],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,315][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([8.5454e-02, 2.0776e-01, 5.0885e-04, 6.5113e-01, 1.0599e-03, 9.9454e-03,
        2.2142e-02, 2.1232e-03, 1.9870e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,317][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0078, 0.0263, 0.0999, 0.0439, 0.0899, 0.1260, 0.2077, 0.1522, 0.1572,
        0.0891], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,319][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.5368, 0.0018, 0.1710, 0.0164, 0.1542, 0.0595, 0.0067, 0.0101, 0.0419,
        0.0015], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,320][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1817, 0.0738, 0.0822, 0.1070, 0.0610, 0.0810, 0.0832, 0.0780, 0.1065,
        0.1457], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,322][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1168, 0.0481, 0.1697, 0.0852, 0.1288, 0.1266, 0.1049, 0.0759, 0.0686,
        0.0754], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,324][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0435, 0.0960, 0.1193, 0.0865, 0.1043, 0.1054, 0.0858, 0.1086, 0.1532,
        0.0975], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,325][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([1.1236e-03, 9.8717e-01, 7.4955e-03, 2.7398e-05, 4.3111e-05, 1.9100e-03,
        9.5139e-05, 2.0808e-03, 3.9995e-05, 1.4748e-05], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,326][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([1.8314e-04, 7.2030e-04, 2.8703e-01, 1.0882e-03, 1.0230e-01, 5.5529e-02,
        3.2818e-07, 5.2314e-05, 5.5301e-01, 8.1293e-05], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,328][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0382, 0.0721, 0.1107, 0.0677, 0.1253, 0.0918, 0.1267, 0.1085, 0.1534,
        0.1057], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,329][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([7.6391e-03, 3.6767e-02, 1.6754e-03, 1.9535e-02, 2.9267e-03, 6.9762e-02,
        5.6243e-01, 9.8860e-04, 2.2209e-04, 2.9805e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,330][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0028, 0.4704, 0.0166, 0.0150, 0.0059, 0.0315, 0.1746, 0.0028, 0.0007,
        0.2797], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,331][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0058, 0.0481, 0.0642, 0.0736, 0.0889, 0.1315, 0.1121, 0.0996, 0.1552,
        0.2210], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,332][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0404, 0.1038, 0.0009, 0.3211, 0.0011, 0.0144, 0.0197, 0.0043, 0.0027,
        0.4916], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,333][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0039, 0.0292, 0.0720, 0.0314, 0.0733, 0.1238, 0.2306, 0.1773, 0.1300,
        0.0987, 0.0298], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,334][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.8061e-01, 1.6513e-02, 3.8178e-01, 7.2051e-04, 1.8817e-01, 5.8793e-02,
        1.6868e-02, 1.1829e-02, 3.4910e-02, 9.4308e-03, 3.7455e-04],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,336][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1526, 0.0602, 0.0710, 0.1069, 0.0543, 0.0682, 0.0701, 0.0595, 0.0938,
        0.1219, 0.1416], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,337][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1117, 0.0451, 0.1528, 0.0826, 0.1180, 0.1131, 0.0935, 0.0700, 0.0649,
        0.0707, 0.0777], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,339][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0401, 0.0858, 0.1134, 0.0792, 0.0975, 0.0938, 0.0778, 0.0977, 0.1424,
        0.0879, 0.0843], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,340][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([1.9469e-03, 9.8501e-01, 1.0362e-02, 2.0776e-05, 3.0622e-05, 1.1599e-03,
        5.2847e-05, 1.3932e-03, 1.5745e-05, 6.7560e-06, 1.2268e-06],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,341][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([1.0382e-04, 1.4690e-04, 1.7991e-01, 3.5978e-04, 3.5043e-02, 7.8001e-02,
        7.0834e-07, 3.2028e-05, 7.0607e-01, 5.1630e-05, 2.7830e-04],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,343][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0414, 0.0719, 0.0948, 0.0628, 0.1044, 0.0927, 0.1295, 0.0954, 0.1312,
        0.1140, 0.0621], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,344][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([6.0515e-03, 5.4091e-02, 8.4845e-04, 5.5653e-02, 9.1269e-04, 4.0523e-02,
        3.1843e-01, 3.5261e-04, 6.5526e-05, 4.9631e-01, 2.6762e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,346][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0026, 0.4270, 0.0292, 0.0192, 0.0087, 0.0260, 0.2393, 0.0033, 0.0011,
        0.2299, 0.0136], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,347][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0044, 0.0398, 0.0544, 0.0627, 0.0722, 0.1103, 0.0926, 0.0806, 0.1260,
        0.1771, 0.1801], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,348][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([1.9564e-02, 4.3278e-02, 2.2615e-04, 2.2258e-01, 2.7838e-04, 7.0762e-03,
        5.8588e-03, 1.2631e-03, 7.4846e-04, 2.2822e-01, 4.7090e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,350][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0021, 0.0227, 0.0564, 0.0391, 0.0317, 0.2163, 0.1309, 0.2357, 0.0770,
        0.1049, 0.0367, 0.0465], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,352][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.6231, 0.0210, 0.1500, 0.0626, 0.0111, 0.0164, 0.0106, 0.0028, 0.0077,
        0.0377, 0.0553, 0.0017], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,354][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.1683, 0.0751, 0.0668, 0.0953, 0.0485, 0.0579, 0.0668, 0.0589, 0.0739,
        0.1186, 0.1135, 0.0565], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,355][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.1051, 0.0451, 0.1309, 0.0738, 0.0951, 0.1014, 0.0866, 0.0588, 0.0536,
        0.0685, 0.0679, 0.1133], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,357][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0365, 0.0894, 0.0879, 0.0741, 0.0785, 0.0869, 0.0738, 0.0871, 0.1267,
        0.0861, 0.0789, 0.0943], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,358][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([5.8727e-03, 9.4874e-01, 4.3509e-02, 1.0620e-05, 2.3859e-05, 4.2675e-04,
        2.3363e-05, 1.3817e-03, 7.2079e-06, 2.9658e-06, 4.8680e-07, 1.1861e-06],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,360][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([1.2988e-03, 9.6181e-02, 2.1604e-02, 1.6303e-01, 3.7659e-02, 2.2070e-02,
        1.5912e-04, 7.8411e-03, 3.2891e-01, 5.0403e-02, 1.7101e-01, 9.9830e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,361][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0329, 0.0648, 0.0838, 0.0499, 0.0946, 0.1126, 0.1046, 0.0924, 0.1663,
        0.0855, 0.0433, 0.0693], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,363][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0028, 0.0436, 0.0043, 0.0159, 0.0040, 0.0538, 0.6375, 0.0048, 0.0017,
        0.2188, 0.0074, 0.0053], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,365][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0020, 0.2552, 0.0165, 0.0060, 0.0054, 0.2484, 0.2738, 0.0014, 0.0007,
        0.1815, 0.0038, 0.0052], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,366][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0028, 0.0363, 0.0493, 0.0549, 0.0636, 0.0905, 0.0832, 0.0754, 0.1136,
        0.1509, 0.1513, 0.1281], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,368][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([3.8151e-02, 5.6639e-02, 1.4589e-04, 1.6706e-01, 4.4341e-04, 3.3089e-03,
        2.8023e-03, 2.0158e-03, 6.6510e-04, 3.2679e-01, 3.9581e-01, 6.1673e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,369][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Stephanie] are: tensor([0.0027, 0.0320, 0.0954, 0.0385, 0.0443, 0.1312, 0.2209, 0.1099, 0.0727,
        0.1360, 0.0386, 0.0437, 0.0341], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,371][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Stephanie] are: tensor([0.5810, 0.0683, 0.0675, 0.0360, 0.0081, 0.0466, 0.0159, 0.0048, 0.0112,
        0.1018, 0.0279, 0.0210, 0.0098], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,373][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Stephanie] are: tensor([0.1249, 0.0773, 0.0571, 0.1051, 0.0370, 0.0654, 0.0590, 0.0545, 0.0808,
        0.1146, 0.1227, 0.0616, 0.0400], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,375][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Stephanie] are: tensor([0.0977, 0.0469, 0.1095, 0.0732, 0.0832, 0.0954, 0.0744, 0.0509, 0.0519,
        0.0637, 0.0648, 0.1037, 0.0847], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,376][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Stephanie] are: tensor([0.0310, 0.0839, 0.0818, 0.0712, 0.0690, 0.0833, 0.0672, 0.0790, 0.1161,
        0.0788, 0.0755, 0.0858, 0.0773], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,377][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Stephanie] are: tensor([4.5928e-03, 9.6929e-01, 2.1621e-02, 5.9934e-05, 1.3920e-04, 1.6530e-03,
        1.2403e-04, 2.3666e-03, 6.8045e-05, 2.8444e-05, 7.2259e-06, 5.7330e-06,
        4.8839e-05], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,378][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Stephanie] are: tensor([6.0653e-04, 1.0764e-01, 2.7989e-02, 1.9816e-01, 1.4010e-01, 3.2538e-02,
        6.8549e-04, 1.7775e-04, 9.9235e-02, 8.1756e-02, 1.6601e-01, 5.1004e-02,
        9.4092e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,379][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Stephanie] are: tensor([0.0242, 0.0813, 0.0802, 0.0537, 0.0668, 0.1215, 0.1101, 0.0646, 0.1522,
        0.0901, 0.0458, 0.0614, 0.0479], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,380][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Stephanie] are: tensor([0.0040, 0.0677, 0.0034, 0.0263, 0.0027, 0.0497, 0.4902, 0.0039, 0.0012,
        0.3307, 0.0134, 0.0055, 0.0014], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,382][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Stephanie] are: tensor([0.0030, 0.2793, 0.0132, 0.0087, 0.0038, 0.1540, 0.2950, 0.0024, 0.0023,
        0.2249, 0.0060, 0.0041, 0.0033], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,383][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Stephanie] are: tensor([0.0025, 0.0327, 0.0428, 0.0502, 0.0510, 0.0879, 0.0743, 0.0676, 0.0992,
        0.1354, 0.1375, 0.1214, 0.0975], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,385][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Stephanie] are: tensor([1.8834e-02, 5.8409e-02, 2.4132e-04, 1.4577e-01, 3.0493e-03, 1.4508e-03,
        5.2360e-03, 5.5112e-04, 7.5902e-04, 3.6094e-01, 4.0201e-01, 9.9082e-04,
        1.7613e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,386][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0042, 0.0275, 0.0663, 0.0400, 0.0507, 0.1795, 0.1454, 0.1428, 0.0543,
        0.0934, 0.0388, 0.0517, 0.0383, 0.0671], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,388][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.7493, 0.0429, 0.0658, 0.0208, 0.0099, 0.0081, 0.0060, 0.0027, 0.0021,
        0.0536, 0.0147, 0.0113, 0.0103, 0.0025], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,390][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.1269, 0.0613, 0.0579, 0.0741, 0.0450, 0.0569, 0.0595, 0.0480, 0.0753,
        0.1088, 0.0939, 0.0524, 0.0499, 0.0902], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,391][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0896, 0.0347, 0.1159, 0.0617, 0.0888, 0.0908, 0.0701, 0.0478, 0.0445,
        0.0538, 0.0555, 0.1030, 0.0906, 0.0532], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,393][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0275, 0.0681, 0.0795, 0.0576, 0.0694, 0.0715, 0.0584, 0.0706, 0.1046,
        0.0684, 0.0612, 0.0844, 0.0768, 0.1021], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,394][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([1.1752e-03, 9.7223e-01, 1.4565e-02, 5.5723e-05, 6.4866e-05, 4.4176e-03,
        1.8588e-04, 6.8633e-03, 1.4632e-04, 4.9855e-05, 7.3574e-06, 8.4905e-06,
        5.5732e-05, 1.7648e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,396][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([1.2210e-05, 3.7140e-04, 4.9874e-04, 5.7211e-03, 3.2040e-04, 5.1398e-03,
        3.7650e-08, 3.1638e-06, 9.6480e-01, 1.9922e-04, 5.1565e-03, 3.6367e-03,
        2.6304e-04, 1.3882e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,397][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0299, 0.0551, 0.0764, 0.0433, 0.1028, 0.0733, 0.0725, 0.0851, 0.1044,
        0.0689, 0.0398, 0.0679, 0.0754, 0.1051], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,399][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([5.8219e-03, 3.5895e-02, 1.0843e-03, 1.5655e-02, 8.2795e-04, 7.1766e-02,
        5.7471e-01, 1.6751e-04, 1.5359e-04, 2.8469e-01, 7.8374e-03, 7.0121e-04,
        3.8363e-04, 3.0719e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,400][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0041, 0.2348, 0.0385, 0.0032, 0.0045, 0.1166, 0.2380, 0.0033, 0.0064,
        0.1098, 0.0020, 0.0052, 0.0041, 0.2295], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,402][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0039, 0.0223, 0.0335, 0.0376, 0.0452, 0.0655, 0.0572, 0.0486, 0.0749,
        0.1091, 0.1127, 0.1008, 0.0860, 0.2025], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,403][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([1.9668e-02, 6.7572e-02, 1.8790e-04, 1.4828e-01, 4.9605e-04, 6.1635e-03,
        1.5039e-02, 9.8782e-04, 3.0198e-03, 3.4923e-01, 3.4447e-01, 1.4010e-03,
        3.1442e-04, 4.3167e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,405][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0032, 0.0227, 0.0502, 0.0295, 0.0322, 0.1980, 0.1410, 0.1239, 0.0858,
        0.0817, 0.0259, 0.0499, 0.0229, 0.1191, 0.0142], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,406][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([5.6347e-01, 6.0715e-03, 1.2030e-01, 1.4810e-02, 6.3448e-02, 2.6124e-02,
        1.5036e-02, 3.3942e-03, 1.0508e-02, 6.1913e-03, 1.0126e-02, 2.3869e-02,
        8.2427e-02, 5.4142e-02, 9.0135e-05], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,408][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1156, 0.0489, 0.0550, 0.0653, 0.0430, 0.0515, 0.0570, 0.0542, 0.0691,
        0.0966, 0.0843, 0.0598, 0.0488, 0.0746, 0.0764], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,410][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0839, 0.0318, 0.1160, 0.0541, 0.0850, 0.0858, 0.0679, 0.0469, 0.0455,
        0.0501, 0.0497, 0.0998, 0.0891, 0.0513, 0.0431], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,412][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0293, 0.0613, 0.0774, 0.0546, 0.0675, 0.0667, 0.0574, 0.0699, 0.0961,
        0.0632, 0.0581, 0.0800, 0.0745, 0.0874, 0.0569], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,413][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.8172e-03, 9.7894e-01, 1.0928e-02, 6.0340e-05, 1.1021e-04, 2.7675e-03,
        1.3076e-04, 3.8995e-03, 7.8199e-05, 3.6013e-05, 7.1467e-06, 1.1260e-05,
        6.6651e-05, 9.0347e-05, 6.0207e-05], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,414][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([2.5043e-03, 9.0561e-04, 4.5865e-02, 1.5252e-02, 2.6190e-03, 5.8142e-02,
        3.1352e-05, 1.8534e-04, 6.0866e-01, 6.6325e-04, 2.3415e-02, 2.3259e-02,
        3.0259e-03, 2.0109e-01, 1.4383e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,416][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0305, 0.0540, 0.0646, 0.0472, 0.0767, 0.0651, 0.0846, 0.0687, 0.1117,
        0.0803, 0.0442, 0.0592, 0.0578, 0.0935, 0.0619], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,417][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([5.0267e-03, 4.8803e-02, 1.2519e-03, 1.8794e-02, 8.6171e-04, 5.4967e-02,
        4.7051e-01, 4.8435e-04, 6.1856e-05, 3.7033e-01, 8.0471e-03, 2.9959e-03,
        3.6792e-04, 1.4824e-04, 1.7349e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,419][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0022, 0.2648, 0.0166, 0.0073, 0.0045, 0.0334, 0.3424, 0.0033, 0.0005,
        0.1770, 0.0047, 0.0047, 0.0040, 0.0292, 0.1054], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,420][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0049, 0.0167, 0.0264, 0.0287, 0.0349, 0.0546, 0.0476, 0.0370, 0.0628,
        0.0919, 0.0910, 0.0836, 0.0685, 0.1831, 0.1682], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,421][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.3684e-02, 5.2185e-02, 1.4876e-04, 1.6737e-01, 3.1269e-04, 3.9537e-03,
        8.9605e-03, 9.2342e-04, 8.4642e-04, 2.6334e-01, 3.3741e-01, 9.6886e-04,
        1.9884e-04, 2.0232e-03, 1.4767e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,424][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:25:37,426][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 7853],
        [ 4191],
        [   36],
        [12874],
        [ 4597],
        [21908],
        [22586],
        [16848],
        [19247],
        [12403],
        [15098],
        [20264],
        [ 7996],
        [12228],
        [11497]], device='cuda:0')
[2024-07-24 10:25:37,428][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[11785],
        [ 2298],
        [    4],
        [12107],
        [ 4323],
        [29413],
        [24443],
        [19606],
        [29174],
        [ 9331],
        [12079],
        [25756],
        [ 5544],
        [ 6378],
        [ 9849]], device='cuda:0')
[2024-07-24 10:25:37,429][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[9207],
        [9463],
        [9228],
        [9488],
        [9211],
        [9225],
        [9271],
        [9299],
        [9216],
        [9440],
        [9417],
        [9326],
        [9228],
        [9313],
        [9525]], device='cuda:0')
[2024-07-24 10:25:37,431][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[17768],
        [17644],
        [ 7725],
        [ 8554],
        [10449],
        [16560],
        [27614],
        [20437],
        [19229],
        [12035],
        [11031],
        [17501],
        [12963],
        [13853],
        [11432]], device='cuda:0')
[2024-07-24 10:25:37,432][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[28849],
        [30243],
        [31365],
        [31489],
        [32344],
        [31973],
        [31960],
        [32208],
        [32704],
        [32784],
        [32744],
        [32863],
        [33148],
        [33269],
        [33264]], device='cuda:0')
[2024-07-24 10:25:37,434][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[2529],
        [1042],
        [1095],
        [1510],
        [2361],
        [2228],
        [2366],
        [2499],
        [2855],
        [2937],
        [2870],
        [3302],
        [3560],
        [2983],
        [2866]], device='cuda:0')
[2024-07-24 10:25:37,436][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 8506],
        [ 8642],
        [10962],
        [ 9257],
        [ 8783],
        [ 8458],
        [ 8606],
        [10595],
        [12948],
        [11924],
        [11140],
        [11126],
        [10751],
        [10669],
        [11478]], device='cuda:0')
[2024-07-24 10:25:37,438][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 4826],
        [13454],
        [25309],
        [21726],
        [21553],
        [20395],
        [15717],
        [16897],
        [ 4185],
        [15727],
        [14111],
        [13474],
        [  950],
        [21723],
        [ 6264]], device='cuda:0')
[2024-07-24 10:25:37,439][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[27363],
        [27377],
        [  492],
        [ 7167],
        [ 7102],
        [ 2227],
        [ 5418],
        [18388],
        [29767],
        [26217],
        [21253],
        [23603],
        [11649],
        [38083],
        [17662]], device='cuda:0')
[2024-07-24 10:25:37,441][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[12387],
        [11705],
        [  744],
        [  694],
        [ 3102],
        [ 3551],
        [ 4330],
        [ 5926],
        [ 3346],
        [ 3653],
        [ 5274],
        [ 3317],
        [ 9854],
        [ 6402],
        [ 7425]], device='cuda:0')
[2024-07-24 10:25:37,443][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[34156],
        [34701],
        [33098],
        [31470],
        [27767],
        [28413],
        [27591],
        [26124],
        [25294],
        [24491],
        [23223],
        [15413],
        [15723],
        [16453],
        [23237]], device='cuda:0')
[2024-07-24 10:25:37,445][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[29438],
        [28375],
        [36004],
        [37108],
        [41218],
        [37751],
        [37945],
        [38145],
        [37650],
        [37828],
        [37882],
        [45173],
        [39934],
        [37343],
        [37948]], device='cuda:0')
[2024-07-24 10:25:37,446][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 4754],
        [ 8982],
        [ 8097],
        [10359],
        [ 8854],
        [11362],
        [10159],
        [10167],
        [11896],
        [12209],
        [13067],
        [12205],
        [11835],
        [11853],
        [12959]], device='cuda:0')
[2024-07-24 10:25:37,448][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[15448],
        [17723],
        [46848],
        [20623],
        [32561],
        [33933],
        [35441],
        [ 9120],
        [14885],
        [29932],
        [29214],
        [38448],
        [47259],
        [42676],
        [38251]], device='cuda:0')
[2024-07-24 10:25:37,450][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 6619],
        [ 3880],
        [  378],
        [ 9411],
        [21514],
        [30311],
        [18734],
        [34447],
        [24382],
        [ 9784],
        [23086],
        [45745],
        [40197],
        [ 9988],
        [21888]], device='cuda:0')
[2024-07-24 10:25:37,451][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[11480],
        [ 7443],
        [11819],
        [11721],
        [12491],
        [23066],
        [19725],
        [15570],
        [17926],
        [16814],
        [15696],
        [20236],
        [14528],
        [18575],
        [21128]], device='cuda:0')
[2024-07-24 10:25:37,453][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[10755],
        [10786],
        [14838],
        [12091],
        [13158],
        [12713],
        [12067],
        [11869],
        [10805],
        [11193],
        [12596],
        [12512],
        [14753],
        [12756],
        [10634]], device='cuda:0')
[2024-07-24 10:25:37,455][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[17365],
        [16682],
        [14449],
        [13584],
        [12525],
        [12394],
        [12247],
        [12570],
        [12572],
        [12319],
        [11994],
        [12222],
        [11805],
        [11370],
        [11227]], device='cuda:0')
[2024-07-24 10:25:37,456][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[16489],
        [14096],
        [15636],
        [14268],
        [13462],
        [14376],
        [12878],
        [12737],
        [12901],
        [12540],
        [12447],
        [14120],
        [14116],
        [14378],
        [14039]], device='cuda:0')
[2024-07-24 10:25:37,458][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[24659],
        [27680],
        [25037],
        [26574],
        [25593],
        [27499],
        [28648],
        [28988],
        [28459],
        [28674],
        [28977],
        [28812],
        [28277],
        [28419],
        [28621]], device='cuda:0')
[2024-07-24 10:25:37,460][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[29767],
        [29180],
        [28246],
        [29736],
        [28229],
        [30724],
        [30002],
        [30039],
        [29776],
        [29973],
        [29917],
        [29587],
        [29820],
        [29956],
        [29968]], device='cuda:0')
[2024-07-24 10:25:37,462][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[40239],
        [37366],
        [38584],
        [29603],
        [26497],
        [24516],
        [36551],
        [31510],
        [26796],
        [18442],
        [14089],
        [24827],
        [24567],
        [11026],
        [13711]], device='cuda:0')
[2024-07-24 10:25:37,463][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[21603],
        [18329],
        [24812],
        [21116],
        [22406],
        [22916],
        [21388],
        [20305],
        [22485],
        [21287],
        [19877],
        [20758],
        [20711],
        [22031],
        [20301]], device='cuda:0')
[2024-07-24 10:25:37,465][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[32357],
        [29538],
        [25070],
        [27242],
        [27333],
        [38207],
        [12585],
        [11745],
        [ 9224],
        [17073],
        [24730],
        [13952],
        [19667],
        [16729],
        [19858]], device='cuda:0')
[2024-07-24 10:25:37,466][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 7135],
        [ 6656],
        [ 6666],
        [ 7108],
        [ 7105],
        [11450],
        [12964],
        [11989],
        [12500],
        [12151],
        [12415],
        [12617],
        [12423],
        [ 9995],
        [11547]], device='cuda:0')
[2024-07-24 10:25:37,468][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[5966],
        [4015],
        [3489],
        [2955],
        [2823],
        [2147],
        [2299],
        [2463],
        [2692],
        [3100],
        [3212],
        [3371],
        [3418],
        [3290],
        [3158]], device='cuda:0')
[2024-07-24 10:25:37,470][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 9908],
        [20021],
        [18727],
        [17254],
        [16964],
        [12969],
        [ 9995],
        [14534],
        [15893],
        [20036],
        [19347],
        [19908],
        [20411],
        [18834],
        [17508]], device='cuda:0')
[2024-07-24 10:25:37,471][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 7928],
        [15124],
        [14364],
        [25575],
        [21459],
        [20763],
        [23185],
        [26389],
        [23133],
        [27212],
        [26653],
        [19594],
        [20104],
        [24792],
        [24621]], device='cuda:0')
[2024-07-24 10:25:37,473][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 6159],
        [30410],
        [44866],
        [18938],
        [ 4203],
        [ 2966],
        [ 8935],
        [ 2929],
        [ 7305],
        [18877],
        [ 7330],
        [  449],
        [  912],
        [24295],
        [ 7814]], device='cuda:0')
[2024-07-24 10:25:37,474][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[26776],
        [26776],
        [26776],
        [26776],
        [26776],
        [26776],
        [26776],
        [26776],
        [26776],
        [26776],
        [26776],
        [26776],
        [26776],
        [26776],
        [26776]], device='cuda:0')
[2024-07-24 10:25:37,515][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:37,515][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,516][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,517][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,517][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,518][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,519][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,519][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,520][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,521][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,521][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,522][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,523][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,523][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9977, 0.0023], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,524][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1935, 0.8065], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,525][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0030, 0.9970], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,526][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9414, 0.0586], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,527][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9350, 0.0650], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,529][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2083, 0.7917], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,530][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3684, 0.6316], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,531][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.7540, 0.2460], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,532][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3423, 0.6577], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,532][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3291, 0.6709], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,533][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.3931, 0.6069], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,534][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2655, 0.7345], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,535][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Jose] are: tensor([0.9635, 0.0051, 0.0314], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,537][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Jose] are: tensor([0.1621, 0.6283, 0.2096], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,538][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Jose] are: tensor([9.8543e-06, 7.2352e-01, 2.7647e-01], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,540][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Jose] are: tensor([0.8579, 0.0465, 0.0956], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,541][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Jose] are: tensor([0.0239, 0.9670, 0.0091], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,543][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Jose] are: tensor([0.0996, 0.3967, 0.5038], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,544][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Jose] are: tensor([0.1582, 0.3896, 0.4522], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,546][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Jose] are: tensor([0.4246, 0.3832, 0.1922], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,547][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Jose] are: tensor([0.0915, 0.3632, 0.5453], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,549][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Jose] are: tensor([0.0347, 0.3381, 0.6272], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,551][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Jose] are: tensor([0.0844, 0.2724, 0.6432], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,552][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Jose] are: tensor([0.1366, 0.3608, 0.5027], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,554][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.9361, 0.0019, 0.0249, 0.0371], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,556][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1324, 0.4294, 0.1580, 0.2801], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,557][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([1.7833e-06, 1.8475e-02, 1.3442e-01, 8.4710e-01], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,558][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.8984, 0.0251, 0.0542, 0.0223], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,560][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0836, 0.8916, 0.0103, 0.0145], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,562][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0643, 0.2566, 0.3836, 0.2955], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,563][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1768, 0.3217, 0.3299, 0.1716], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,565][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.5408, 0.1365, 0.2628, 0.0600], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,566][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0845, 0.2062, 0.3176, 0.3917], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,568][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0181, 0.1379, 0.7441, 0.0999], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,570][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1118, 0.1962, 0.5558, 0.1362], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,571][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1024, 0.2701, 0.3576, 0.2698], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,573][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Stephanie] are: tensor([0.7031, 0.0036, 0.0239, 0.0542, 0.2153], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,574][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Stephanie] are: tensor([0.1177, 0.3699, 0.1356, 0.2388, 0.1380], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,574][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Stephanie] are: tensor([7.1704e-08, 3.9022e-04, 2.4937e-03, 8.9192e-02, 9.0792e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,575][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Stephanie] are: tensor([0.8472, 0.0214, 0.0449, 0.0195, 0.0670], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,576][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Stephanie] are: tensor([0.0453, 0.6675, 0.1341, 0.1219, 0.0312], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,578][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Stephanie] are: tensor([0.0377, 0.1524, 0.2013, 0.2068, 0.4019], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,579][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Stephanie] are: tensor([0.0927, 0.2105, 0.2808, 0.1027, 0.3134], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,581][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Stephanie] are: tensor([0.3120, 0.2657, 0.2119, 0.0718, 0.1386], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,582][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Stephanie] are: tensor([0.0399, 0.1348, 0.1933, 0.2836, 0.3484], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,584][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Stephanie] are: tensor([0.0123, 0.1270, 0.5258, 0.1367, 0.1982], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,585][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Stephanie] are: tensor([0.0539, 0.1678, 0.3507, 0.1076, 0.3200], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,587][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Stephanie] are: tensor([0.0765, 0.1951, 0.2660, 0.1951, 0.2673], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,589][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.3726, 0.0025, 0.0339, 0.0906, 0.4237, 0.0767], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,590][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0499, 0.4270, 0.1211, 0.2313, 0.1251, 0.0457], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,591][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ had] are: tensor([3.6306e-09, 3.3066e-05, 1.2008e-04, 1.2825e-02, 9.5062e-01, 3.6406e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,593][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.8477, 0.0141, 0.0312, 0.0140, 0.0567, 0.0364], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,595][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.7010, 0.1528, 0.0050, 0.1260, 0.0022, 0.0130], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,596][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0199, 0.0938, 0.1529, 0.1172, 0.3227, 0.2934], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,598][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0978, 0.1965, 0.1964, 0.0895, 0.2642, 0.1557], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,600][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.2674, 0.2048, 0.1609, 0.0718, 0.1789, 0.1162], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,601][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0400, 0.1085, 0.1651, 0.2199, 0.2826, 0.1839], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,603][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0161, 0.1029, 0.3519, 0.0939, 0.3746, 0.0605], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,604][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0438, 0.1300, 0.3211, 0.0666, 0.3058, 0.1328], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,606][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0571, 0.1586, 0.2177, 0.1588, 0.2269, 0.1810], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,608][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.4155, 0.0036, 0.0395, 0.0544, 0.2328, 0.0789, 0.1754],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,609][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0687, 0.3235, 0.1194, 0.2090, 0.1319, 0.0581, 0.0894],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,611][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([9.8220e-09, 2.2029e-05, 1.3123e-04, 1.3386e-02, 3.9280e-01, 4.0215e-01,
        1.9152e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,612][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.6468, 0.0196, 0.0377, 0.0226, 0.0722, 0.0566, 0.1445],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,614][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.3860, 0.1573, 0.1483, 0.1670, 0.0453, 0.0863, 0.0098],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,615][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0177, 0.0767, 0.1227, 0.0951, 0.2624, 0.2603, 0.1650],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,616][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0993, 0.1755, 0.1532, 0.0963, 0.2263, 0.1546, 0.0948],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,616][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.3037, 0.1523, 0.1600, 0.0593, 0.1586, 0.0963, 0.0697],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,617][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0384, 0.0778, 0.1174, 0.1629, 0.2150, 0.1528, 0.2357],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,618][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0188, 0.0995, 0.3259, 0.0900, 0.2872, 0.1162, 0.0624],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,620][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0640, 0.1062, 0.2715, 0.0864, 0.2348, 0.1283, 0.1087],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,621][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0498, 0.1357, 0.1831, 0.1356, 0.1908, 0.1572, 0.1478],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,623][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.3564, 0.0077, 0.0471, 0.0578, 0.1890, 0.0524, 0.1369, 0.1527],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,624][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0521, 0.3187, 0.1135, 0.1905, 0.1270, 0.0480, 0.0769, 0.0734],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,625][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ long] are: tensor([7.5361e-10, 7.2397e-07, 1.0372e-05, 2.5433e-04, 4.7558e-02, 2.7937e-02,
        1.4622e-01, 7.7802e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,627][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.6216, 0.0118, 0.0244, 0.0137, 0.0470, 0.0356, 0.0953, 0.1507],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,629][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.1909, 0.1877, 0.0055, 0.2151, 0.0527, 0.1178, 0.2286, 0.0016],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,631][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0161, 0.0584, 0.0821, 0.0760, 0.1643, 0.1917, 0.1271, 0.2842],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,632][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0671, 0.1441, 0.1665, 0.0770, 0.1773, 0.1706, 0.0848, 0.1125],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,634][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.2573, 0.1977, 0.1345, 0.0503, 0.0980, 0.0765, 0.0415, 0.1441],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,636][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0169, 0.0614, 0.0830, 0.1212, 0.1639, 0.1104, 0.1656, 0.2776],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,637][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0160, 0.0817, 0.2809, 0.1041, 0.2132, 0.1214, 0.0911, 0.0914],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,639][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0445, 0.1146, 0.1884, 0.0712, 0.1771, 0.1174, 0.0780, 0.2088],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,641][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0427, 0.1132, 0.1448, 0.1122, 0.1461, 0.1301, 0.1232, 0.1877],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,642][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.2658, 0.0043, 0.0325, 0.0389, 0.1386, 0.0400, 0.1066, 0.1338, 0.2395],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,644][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0469, 0.2954, 0.0986, 0.1736, 0.1068, 0.0439, 0.0779, 0.0710, 0.0858],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,645][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([9.8275e-11, 1.1819e-07, 2.7757e-07, 4.1527e-05, 2.2524e-03, 1.7978e-03,
        1.2854e-02, 4.4934e-01, 5.3371e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,647][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.4208, 0.0104, 0.0187, 0.0113, 0.0331, 0.0268, 0.0759, 0.1114, 0.2916],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,648][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0300, 0.1700, 0.0083, 0.1453, 0.0384, 0.4539, 0.1356, 0.0169, 0.0017],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,650][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0122, 0.0452, 0.0622, 0.0618, 0.1259, 0.1553, 0.1061, 0.2435, 0.1878],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,652][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0556, 0.1093, 0.1405, 0.0563, 0.1797, 0.1181, 0.0778, 0.1076, 0.1550],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,653][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.1730, 0.1376, 0.1248, 0.0434, 0.0917, 0.0822, 0.0461, 0.1340, 0.1671],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,655][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0102, 0.0445, 0.0586, 0.0923, 0.1234, 0.0867, 0.1298, 0.2286, 0.2259],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,657][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0073, 0.0897, 0.2238, 0.0861, 0.1908, 0.1128, 0.0931, 0.1439, 0.0525],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,658][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0419, 0.0950, 0.1609, 0.0514, 0.1611, 0.1062, 0.0703, 0.1639, 0.1493],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,658][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0371, 0.0930, 0.1265, 0.0909, 0.1262, 0.1065, 0.1003, 0.1561, 0.1632],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,659][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4104, 0.0005, 0.0072, 0.0101, 0.0692, 0.0149, 0.0422, 0.0637, 0.1514,
        0.2303], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,661][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0680, 0.2253, 0.0898, 0.1506, 0.0968, 0.0470, 0.0670, 0.0661, 0.0703,
        0.1191], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,662][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([8.9229e-11, 3.9677e-09, 2.5452e-07, 1.4766e-05, 7.2655e-04, 3.6459e-04,
        2.2949e-03, 9.1291e-02, 2.4371e-01, 6.6160e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,664][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4508, 0.0067, 0.0136, 0.0073, 0.0245, 0.0178, 0.0529, 0.0765, 0.2422,
        0.1075], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,665][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3265, 0.0190, 0.1517, 0.0327, 0.2586, 0.0128, 0.1723, 0.0067, 0.0091,
        0.0105], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,667][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0094, 0.0388, 0.0595, 0.0485, 0.1238, 0.1222, 0.0833, 0.2182, 0.1992,
        0.0972], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,669][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0632, 0.1016, 0.1142, 0.0670, 0.1453, 0.1046, 0.0708, 0.0873, 0.1247,
        0.1212], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,671][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2305, 0.0619, 0.1228, 0.0432, 0.1019, 0.0794, 0.0463, 0.1191, 0.1663,
        0.0285], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,672][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0145, 0.0348, 0.0528, 0.0725, 0.1010, 0.0679, 0.1108, 0.1985, 0.2347,
        0.1125], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,674][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0126, 0.0472, 0.2248, 0.0622, 0.1926, 0.0849, 0.0815, 0.1257, 0.1063,
        0.0621], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,676][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0309, 0.0677, 0.1602, 0.0584, 0.1433, 0.1022, 0.0648, 0.1835, 0.1526,
        0.0364], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,677][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0323, 0.0838, 0.1104, 0.0829, 0.1148, 0.0939, 0.0887, 0.1438, 0.1499,
        0.0996], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,679][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([1.8215e-01, 2.8133e-04, 3.3888e-03, 3.2549e-03, 3.2147e-02, 5.5598e-03,
        1.5406e-02, 2.7760e-02, 6.2680e-02, 1.1298e-01, 5.5439e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,680][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0660, 0.1915, 0.0748, 0.1287, 0.0777, 0.0433, 0.0600, 0.0576, 0.0577,
        0.1058, 0.1369], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,682][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([2.8564e-11, 1.1846e-09, 1.9851e-08, 7.1606e-08, 4.0680e-05, 1.1254e-05,
        1.2071e-04, 2.8256e-03, 1.1184e-02, 1.8004e-01, 8.0577e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,683][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.4704, 0.0066, 0.0133, 0.0067, 0.0214, 0.0148, 0.0450, 0.0570, 0.1915,
        0.0856, 0.0877], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,684][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([2.5251e-02, 4.7880e-01, 3.0690e-03, 6.8529e-03, 1.3169e-03, 6.5995e-03,
        1.3599e-01, 7.8340e-04, 1.7004e-04, 3.3657e-01, 4.5964e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,686][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0084, 0.0354, 0.0554, 0.0423, 0.1200, 0.1175, 0.0749, 0.2081, 0.1928,
        0.0906, 0.0545], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,688][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0578, 0.1091, 0.1100, 0.0612, 0.1329, 0.0998, 0.0678, 0.0807, 0.1058,
        0.1234, 0.0516], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,690][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2084, 0.0629, 0.1280, 0.0374, 0.1102, 0.0796, 0.0451, 0.1057, 0.1740,
        0.0253, 0.0235], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,691][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0153, 0.0338, 0.0525, 0.0686, 0.0977, 0.0641, 0.1013, 0.1813, 0.2114,
        0.1039, 0.0701], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,693][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0076, 0.0493, 0.2213, 0.0328, 0.1927, 0.0894, 0.0630, 0.1465, 0.1027,
        0.0694, 0.0252], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,695][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0338, 0.0650, 0.1643, 0.0475, 0.1246, 0.1083, 0.0712, 0.1544, 0.1679,
        0.0354, 0.0277], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,697][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0294, 0.0779, 0.1021, 0.0769, 0.1061, 0.0867, 0.0814, 0.1322, 0.1386,
        0.0923, 0.0763], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,698][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.1060, 0.0011, 0.0077, 0.0095, 0.0365, 0.0086, 0.0229, 0.0325, 0.0608,
        0.1049, 0.3585, 0.2511], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,699][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0507, 0.1827, 0.0642, 0.1113, 0.0637, 0.0356, 0.0575, 0.0526, 0.0556,
        0.1098, 0.1334, 0.0830], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,700][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([7.4604e-12, 2.0432e-10, 1.0154e-09, 6.8752e-08, 2.1595e-06, 1.2320e-06,
        1.7262e-05, 1.0929e-04, 1.2803e-03, 2.2570e-02, 6.9501e-01, 2.8101e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,701][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.1828, 0.0079, 0.0135, 0.0090, 0.0210, 0.0182, 0.0461, 0.0625, 0.1454,
        0.0898, 0.0892, 0.3147], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,702][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([1.3909e-03, 2.3854e-02, 1.5900e-04, 1.5018e-02, 3.1371e-04, 4.7871e-02,
        7.3737e-04, 8.7800e-01, 3.0930e-05, 2.2134e-02, 1.0083e-02, 4.0266e-04],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,703][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0100, 0.0334, 0.0442, 0.0445, 0.0892, 0.1088, 0.0737, 0.1717, 0.1443,
        0.0872, 0.0595, 0.1334], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,705][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0408, 0.0827, 0.1111, 0.0417, 0.1289, 0.1079, 0.0477, 0.0818, 0.1249,
        0.0919, 0.0370, 0.1034], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,707][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.1529, 0.1264, 0.0943, 0.0369, 0.0908, 0.0759, 0.0359, 0.1215, 0.1475,
        0.0334, 0.0214, 0.0630], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,708][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0141, 0.0360, 0.0498, 0.0675, 0.0914, 0.0655, 0.0873, 0.1504, 0.1573,
        0.0937, 0.0667, 0.1203], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,710][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0085, 0.0652, 0.1904, 0.0688, 0.1498, 0.0924, 0.0819, 0.1009, 0.0681,
        0.0764, 0.0570, 0.0406], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,712][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0144, 0.0836, 0.1330, 0.0429, 0.1168, 0.0889, 0.0548, 0.1291, 0.1725,
        0.0441, 0.0230, 0.0970], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,713][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0273, 0.0702, 0.0939, 0.0694, 0.0947, 0.0782, 0.0741, 0.1185, 0.1226,
        0.0814, 0.0680, 0.1018], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,715][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Stephanie] are: tensor([0.2541, 0.0012, 0.0058, 0.0061, 0.0330, 0.0070, 0.0183, 0.0312, 0.0488,
        0.0478, 0.1353, 0.1632, 0.2481], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,717][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Stephanie] are: tensor([0.0575, 0.1626, 0.0603, 0.1040, 0.0613, 0.0364, 0.0550, 0.0519, 0.0523,
        0.0990, 0.1172, 0.0740, 0.0683], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,718][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Stephanie] are: tensor([1.6842e-12, 3.4925e-11, 2.9420e-10, 6.4442e-09, 9.9612e-08, 2.6553e-07,
        1.3417e-06, 4.1671e-05, 1.5601e-04, 2.1695e-03, 4.4983e-02, 1.4884e-01,
        8.0381e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,720][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Stephanie] are: tensor([0.1761, 0.0046, 0.0082, 0.0051, 0.0126, 0.0104, 0.0287, 0.0369, 0.1011,
        0.0545, 0.0573, 0.2628, 0.2416], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,721][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Stephanie] are: tensor([0.0200, 0.2578, 0.0472, 0.0523, 0.0103, 0.1262, 0.1364, 0.0008, 0.0015,
        0.2235, 0.0328, 0.0832, 0.0078], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,723][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Stephanie] are: tensor([0.0063, 0.0247, 0.0324, 0.0370, 0.0719, 0.1095, 0.0682, 0.1657, 0.1291,
        0.0812, 0.0540, 0.1233, 0.0966], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,725][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Stephanie] are: tensor([0.0315, 0.0741, 0.1006, 0.0368, 0.1121, 0.0939, 0.0378, 0.0693, 0.1097,
        0.0813, 0.0332, 0.1116, 0.1082], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,727][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Stephanie] are: tensor([0.1389, 0.1410, 0.1030, 0.0409, 0.0683, 0.0759, 0.0384, 0.1041, 0.1305,
        0.0269, 0.0216, 0.0552, 0.0553], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,728][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Stephanie] are: tensor([0.0088, 0.0297, 0.0392, 0.0623, 0.0771, 0.0570, 0.0820, 0.1365, 0.1486,
        0.0929, 0.0645, 0.1097, 0.0918], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,730][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Stephanie] are: tensor([0.0052, 0.0579, 0.2062, 0.0620, 0.0710, 0.1041, 0.0801, 0.1196, 0.0807,
        0.0740, 0.0490, 0.0529, 0.0372], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,732][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Stephanie] are: tensor([0.0165, 0.0592, 0.1200, 0.0374, 0.1059, 0.0858, 0.0479, 0.1248, 0.1315,
        0.0320, 0.0227, 0.1143, 0.1019], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,734][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Stephanie] are: tensor([0.0242, 0.0623, 0.0871, 0.0623, 0.0872, 0.0732, 0.0678, 0.1085, 0.1142,
        0.0727, 0.0609, 0.0942, 0.0855], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:37,735][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.1047, 0.0004, 0.0031, 0.0032, 0.0302, 0.0031, 0.0094, 0.0146, 0.0299,
        0.0500, 0.1763, 0.1701, 0.2661, 0.1389], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,737][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0465, 0.1496, 0.0533, 0.0945, 0.0556, 0.0323, 0.0499, 0.0452, 0.0476,
        0.0906, 0.1090, 0.0697, 0.0651, 0.0910], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,738][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ said] are: tensor([1.9754e-13, 3.7968e-12, 1.2908e-11, 1.0417e-09, 4.3550e-08, 4.5146e-08,
        1.3399e-07, 1.3202e-06, 1.9181e-05, 5.8460e-04, 1.6481e-02, 6.9007e-02,
        7.8686e-01, 1.2705e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,740][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.1468, 0.0050, 0.0084, 0.0053, 0.0126, 0.0099, 0.0264, 0.0331, 0.0818,
        0.0450, 0.0464, 0.1954, 0.1872, 0.1966], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,741][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ said] are: tensor([7.4527e-01, 5.6472e-02, 1.1947e-02, 1.9537e-02, 6.0622e-04, 3.8991e-02,
        9.1687e-03, 3.2559e-02, 5.0852e-05, 2.2741e-02, 1.7115e-02, 4.5111e-02,
        3.5948e-04, 7.3529e-05], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,742][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0060, 0.0239, 0.0370, 0.0316, 0.0769, 0.0737, 0.0508, 0.1390, 0.1252,
        0.0615, 0.0409, 0.1210, 0.1160, 0.0966], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,743][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0324, 0.0607, 0.0790, 0.0328, 0.1230, 0.0688, 0.0425, 0.0602, 0.0798,
        0.0703, 0.0311, 0.0978, 0.1202, 0.1014], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,744][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.1141, 0.0572, 0.1068, 0.0281, 0.0784, 0.0592, 0.0340, 0.1007, 0.1362,
        0.0283, 0.0218, 0.0793, 0.0732, 0.0828], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,746][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0091, 0.0260, 0.0341, 0.0528, 0.0738, 0.0498, 0.0737, 0.1276, 0.1314,
        0.0799, 0.0568, 0.1153, 0.1033, 0.0664], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,747][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0079, 0.0601, 0.1589, 0.0639, 0.1098, 0.0647, 0.0618, 0.0978, 0.0716,
        0.0871, 0.0637, 0.0598, 0.0672, 0.0256], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,749][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0188, 0.0479, 0.1245, 0.0253, 0.1085, 0.0525, 0.0505, 0.1392, 0.1079,
        0.0319, 0.0187, 0.1007, 0.1068, 0.0668], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,751][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0217, 0.0580, 0.0786, 0.0578, 0.0801, 0.0658, 0.0621, 0.1007, 0.1037,
        0.0689, 0.0577, 0.0883, 0.0790, 0.0775], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:37,752][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.2744e-02, 1.3630e-04, 1.3539e-03, 1.0284e-03, 1.3202e-02, 1.3680e-03,
        3.4232e-03, 7.4057e-03, 1.4614e-02, 2.0960e-02, 1.0470e-01, 1.1093e-01,
        1.8068e-01, 1.1260e-01, 3.3485e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,754][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0546, 0.1380, 0.0539, 0.0899, 0.0545, 0.0322, 0.0459, 0.0437, 0.0422,
        0.0788, 0.0963, 0.0614, 0.0566, 0.0756, 0.0765], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,755][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([3.3083e-13, 7.9777e-13, 3.3303e-12, 1.6845e-10, 6.0512e-09, 8.6932e-09,
        3.3024e-08, 6.1576e-07, 6.3218e-06, 5.9791e-05, 1.7606e-03, 6.2586e-03,
        8.3348e-02, 2.5664e-01, 6.5192e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,757][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1387, 0.0038, 0.0065, 0.0043, 0.0102, 0.0082, 0.0208, 0.0260, 0.0679,
        0.0353, 0.0362, 0.1589, 0.1438, 0.1673, 0.1720], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,759][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0851, 0.0300, 0.1223, 0.0229, 0.0170, 0.2163, 0.0165, 0.0255, 0.3237,
        0.0290, 0.0248, 0.0129, 0.0178, 0.0529, 0.0033], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,760][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0056, 0.0226, 0.0343, 0.0289, 0.0732, 0.0698, 0.0467, 0.1333, 0.1209,
        0.0585, 0.0360, 0.1102, 0.1117, 0.0939, 0.0543], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,762][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0465, 0.0685, 0.0715, 0.0459, 0.0852, 0.0666, 0.0466, 0.0476, 0.0794,
        0.0880, 0.0402, 0.0810, 0.0801, 0.1281, 0.0247], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,764][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1604, 0.0529, 0.0851, 0.0287, 0.0691, 0.0591, 0.0327, 0.0790, 0.0981,
        0.0243, 0.0194, 0.0847, 0.0629, 0.1082, 0.0354], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,766][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0120, 0.0240, 0.0341, 0.0486, 0.0646, 0.0454, 0.0706, 0.1136, 0.1319,
        0.0710, 0.0514, 0.1083, 0.0965, 0.0697, 0.0581], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,767][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0135, 0.0475, 0.1559, 0.0403, 0.1359, 0.0496, 0.0585, 0.1106, 0.0754,
        0.0562, 0.0345, 0.0671, 0.0869, 0.0572, 0.0110], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,769][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0222, 0.0585, 0.0999, 0.0466, 0.0902, 0.0670, 0.0478, 0.1056, 0.0977,
        0.0412, 0.0301, 0.0803, 0.0864, 0.0949, 0.0316], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,771][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0216, 0.0560, 0.0734, 0.0555, 0.0751, 0.0616, 0.0583, 0.0939, 0.0970,
        0.0653, 0.0543, 0.0817, 0.0725, 0.0713, 0.0626], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:37,798][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:37,799][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,800][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,802][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,803][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,804][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,805][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,807][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,808][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,809][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,811][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,812][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,813][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:37,815][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4079, 0.5921], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,816][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([9.9987e-01, 1.3149e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,818][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6832, 0.3168], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,819][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1290, 0.8710], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,821][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.6169, 0.3831], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,823][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1521, 0.8479], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,824][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3681, 0.6319], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,826][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.6198, 0.3802], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,827][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.7158, 0.2842], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,829][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.5244, 0.4756], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,831][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0182, 0.9818], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,832][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6247, 0.3753], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:37,834][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Jose] are: tensor([0.1542, 0.3085, 0.5374], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,835][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Jose] are: tensor([9.9616e-01, 6.4381e-04, 3.1944e-03], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,837][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Jose] are: tensor([0.0831, 0.2730, 0.6440], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,838][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Jose] are: tensor([0.0807, 0.5665, 0.3528], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,839][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Jose] are: tensor([0.0880, 0.8218, 0.0902], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,839][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Jose] are: tensor([0.0564, 0.7104, 0.2332], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,840][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Jose] are: tensor([0.1596, 0.3582, 0.4822], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,841][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Jose] are: tensor([0.5215, 0.3142, 0.1644], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,843][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Jose] are: tensor([0.0697, 0.9245, 0.0057], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,844][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Jose] are: tensor([0.1118, 0.3575, 0.5307], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,846][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Jose] are: tensor([0.0016, 0.2966, 0.7018], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,847][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Jose] are: tensor([0.4072, 0.2281, 0.3647], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:37,849][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1197, 0.2160, 0.4617, 0.2026], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,850][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.7995, 0.0085, 0.0246, 0.1674], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,852][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0211, 0.0237, 0.9034, 0.0518], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,854][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0813, 0.4403, 0.2929, 0.1854], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,855][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1172, 0.5708, 0.1059, 0.2061], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,857][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0549, 0.3648, 0.3893, 0.1909], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,858][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1624, 0.2785, 0.3344, 0.2247], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,860][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4286, 0.2548, 0.1893, 0.1273], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,862][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1334, 0.8075, 0.0530, 0.0061], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,863][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0601, 0.1836, 0.6211, 0.1352], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,865][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0044, 0.2363, 0.6119, 0.1474], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,867][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.3101, 0.1936, 0.3254, 0.1709], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:37,868][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Stephanie] are: tensor([0.0938, 0.1850, 0.3563, 0.2413, 0.1237], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,869][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Stephanie] are: tensor([9.7124e-01, 3.0119e-04, 1.6529e-03, 2.5712e-02, 1.0954e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,871][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Stephanie] are: tensor([0.0211, 0.0213, 0.8235, 0.1152, 0.0189], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,872][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Stephanie] are: tensor([0.0416, 0.3646, 0.2594, 0.2133, 0.1211], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,874][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Stephanie] are: tensor([0.0881, 0.3779, 0.2179, 0.2289, 0.0872], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,876][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Stephanie] are: tensor([0.0321, 0.3631, 0.2059, 0.2578, 0.1411], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,877][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Stephanie] are: tensor([0.0863, 0.1716, 0.2651, 0.1308, 0.3462], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,879][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Stephanie] are: tensor([0.3496, 0.2436, 0.1487, 0.1148, 0.1434], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,881][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Stephanie] are: tensor([0.0528, 0.7779, 0.0517, 0.1143, 0.0034], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,882][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Stephanie] are: tensor([0.0516, 0.1674, 0.3926, 0.1734, 0.2149], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,883][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Stephanie] are: tensor([0.0033, 0.2184, 0.4110, 0.0994, 0.2678], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,884][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Stephanie] are: tensor([0.2504, 0.1513, 0.2468, 0.1362, 0.2153], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:37,885][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0864, 0.1661, 0.2909, 0.1742, 0.2057, 0.0768], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,885][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([9.2580e-01, 9.0847e-04, 4.0025e-03, 6.1492e-02, 2.5006e-03, 5.2969e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,886][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0163, 0.0490, 0.2945, 0.2957, 0.3101, 0.0344], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,888][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0630, 0.3609, 0.2236, 0.1612, 0.1016, 0.0897], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,889][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1696, 0.2355, 0.0581, 0.3782, 0.0641, 0.0945], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,891][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0367, 0.2443, 0.1993, 0.1838, 0.2269, 0.1090], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,893][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0862, 0.1579, 0.1868, 0.1135, 0.2786, 0.1770], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,894][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.3165, 0.2185, 0.1126, 0.0932, 0.1310, 0.1281], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,896][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([3.1318e-01, 6.5817e-01, 1.1781e-02, 1.0227e-02, 6.0101e-03, 6.2857e-04],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,897][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0511, 0.1145, 0.2879, 0.1179, 0.3379, 0.0908], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,899][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0031, 0.1800, 0.3901, 0.0662, 0.2626, 0.0979], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,901][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.2204, 0.1328, 0.2133, 0.1062, 0.2042, 0.1231], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:37,902][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0696, 0.1215, 0.2561, 0.1826, 0.1836, 0.0831, 0.1035],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,904][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.6772, 0.0054, 0.0154, 0.1162, 0.0100, 0.0192, 0.1567],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,906][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0330, 0.0207, 0.2759, 0.2303, 0.0625, 0.3723, 0.0054],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,907][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0642, 0.3054, 0.2107, 0.1445, 0.0952, 0.0974, 0.0826],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,909][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1221, 0.1832, 0.1453, 0.2446, 0.1260, 0.1161, 0.0627],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,911][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0299, 0.2062, 0.1903, 0.1495, 0.1662, 0.2286, 0.0293],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,912][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0873, 0.1396, 0.1412, 0.1096, 0.2389, 0.1674, 0.1159],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,914][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.2670, 0.1668, 0.1226, 0.0877, 0.1411, 0.1170, 0.0977],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,916][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0300, 0.2678, 0.0927, 0.2087, 0.1314, 0.2669, 0.0025],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,917][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0482, 0.1124, 0.2658, 0.0992, 0.2584, 0.1436, 0.0725],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,919][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0026, 0.1589, 0.3137, 0.1052, 0.1949, 0.1032, 0.1215],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,921][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1924, 0.1146, 0.1891, 0.1076, 0.1752, 0.1211, 0.1000],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:37,922][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0826, 0.1225, 0.1956, 0.1472, 0.1324, 0.0671, 0.1204, 0.1323],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,924][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.5646, 0.0068, 0.0174, 0.1259, 0.0115, 0.0205, 0.1554, 0.0979],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,925][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0090, 0.0066, 0.3887, 0.0549, 0.0782, 0.3227, 0.1031, 0.0369],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,927][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0608, 0.2973, 0.1889, 0.1342, 0.0921, 0.0948, 0.0880, 0.0437],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,929][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0962, 0.1688, 0.0293, 0.2461, 0.0728, 0.1251, 0.2026, 0.0592],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,930][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0254, 0.1904, 0.1717, 0.1595, 0.1323, 0.1692, 0.0815, 0.0700],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,930][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0581, 0.1123, 0.1470, 0.0882, 0.1866, 0.1723, 0.1021, 0.1335],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,931][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.2417, 0.1724, 0.1077, 0.0860, 0.1164, 0.1014, 0.0821, 0.0923],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,933][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0682, 0.4285, 0.2008, 0.0428, 0.0996, 0.0952, 0.0603, 0.0046],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,934][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0347, 0.0902, 0.2308, 0.1040, 0.1977, 0.1412, 0.0975, 0.1039],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,936][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0036, 0.1912, 0.2335, 0.0909, 0.1570, 0.0979, 0.0869, 0.1391],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,937][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.1800, 0.1008, 0.1583, 0.0884, 0.1422, 0.1036, 0.0857, 0.1409],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:37,939][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0645, 0.1149, 0.1724, 0.1223, 0.1226, 0.0747, 0.0845, 0.1670, 0.0771],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,941][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.6573, 0.0030, 0.0090, 0.0764, 0.0065, 0.0094, 0.1102, 0.0767, 0.0515],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,943][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0086, 0.0121, 0.1488, 0.0809, 0.0746, 0.3725, 0.0834, 0.1952, 0.0240],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,944][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0435, 0.2454, 0.1739, 0.1394, 0.0912, 0.1018, 0.0990, 0.0574, 0.0485],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,946][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0405, 0.1401, 0.0377, 0.2038, 0.0620, 0.1890, 0.1833, 0.1016, 0.0419],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,948][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0189, 0.1793, 0.1011, 0.1326, 0.1092, 0.1511, 0.0622, 0.1173, 0.1282],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,949][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0460, 0.0825, 0.1226, 0.0620, 0.1764, 0.1210, 0.0889, 0.1238, 0.1768],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,951][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.2216, 0.1369, 0.1023, 0.0831, 0.1132, 0.1026, 0.0833, 0.0860, 0.0709],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,953][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0420, 0.3464, 0.0142, 0.0818, 0.0316, 0.0867, 0.3640, 0.0232, 0.0100],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,954][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0226, 0.0980, 0.1729, 0.0888, 0.1728, 0.1380, 0.0983, 0.1444, 0.0643],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,956][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0046, 0.1619, 0.2027, 0.0684, 0.1428, 0.0999, 0.0831, 0.1229, 0.1136],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,958][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.1423, 0.0805, 0.1369, 0.0718, 0.1253, 0.0886, 0.0746, 0.1340, 0.1460],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:37,960][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0500, 0.0719, 0.1778, 0.1042, 0.1286, 0.0592, 0.0832, 0.1262, 0.0914,
        0.1075], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,961][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.3779, 0.0065, 0.0152, 0.0964, 0.0106, 0.0185, 0.1129, 0.0768, 0.0530,
        0.2322], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,963][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0086, 0.0027, 0.2351, 0.0798, 0.0662, 0.2881, 0.0659, 0.1793, 0.0721,
        0.0021], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,965][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0609, 0.2532, 0.1771, 0.1319, 0.0874, 0.0876, 0.0767, 0.0458, 0.0401,
        0.0393], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,966][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0843, 0.0708, 0.1025, 0.1081, 0.1745, 0.0484, 0.1888, 0.0725, 0.0560,
        0.0941], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,968][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0182, 0.0967, 0.1184, 0.1110, 0.0998, 0.1296, 0.0379, 0.1110, 0.1911,
        0.0862], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,970][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0500, 0.0734, 0.0949, 0.0696, 0.1392, 0.1049, 0.0789, 0.0980, 0.1421,
        0.1490], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,971][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2145, 0.1275, 0.1034, 0.0728, 0.1088, 0.0973, 0.0754, 0.0762, 0.0738,
        0.0502], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,973][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1235, 0.0286, 0.0234, 0.0875, 0.0229, 0.1890, 0.3153, 0.0316, 0.1613,
        0.0169], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,974][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0314, 0.0590, 0.1851, 0.0664, 0.1783, 0.1005, 0.0815, 0.1257, 0.1175,
        0.0545], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,975][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0011, 0.1281, 0.1885, 0.0719, 0.1253, 0.0953, 0.0740, 0.1340, 0.1201,
        0.0619], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,976][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1345, 0.0752, 0.1248, 0.0704, 0.1169, 0.0784, 0.0676, 0.1142, 0.1331,
        0.0850], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:37,977][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0443, 0.0793, 0.1618, 0.0736, 0.1271, 0.0469, 0.0774, 0.1136, 0.0820,
        0.1162, 0.0778], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,978][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.2644, 0.0050, 0.0119, 0.0750, 0.0084, 0.0160, 0.0901, 0.0617, 0.0413,
        0.1924, 0.2338], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,980][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0096, 0.0095, 0.3395, 0.0158, 0.1021, 0.2237, 0.0790, 0.1521, 0.0550,
        0.0075, 0.0063], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,981][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0486, 0.2530, 0.1782, 0.1179, 0.0829, 0.0773, 0.0699, 0.0395, 0.0354,
        0.0331, 0.0642], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,983][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0307, 0.2387, 0.0217, 0.0701, 0.0244, 0.0358, 0.1695, 0.0254, 0.0166,
        0.3149, 0.0521], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,985][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0169, 0.1067, 0.1091, 0.0513, 0.1019, 0.1340, 0.0355, 0.1071, 0.2096,
        0.0927, 0.0352], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,986][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0445, 0.0758, 0.0910, 0.0637, 0.1266, 0.0997, 0.0750, 0.0914, 0.1190,
        0.1463, 0.0671], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,988][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1848, 0.1151, 0.1071, 0.0772, 0.1122, 0.0969, 0.0748, 0.0670, 0.0712,
        0.0503, 0.0434], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,990][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1098, 0.2522, 0.0318, 0.0059, 0.0269, 0.1220, 0.1578, 0.0600, 0.0979,
        0.1305, 0.0052], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,992][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0240, 0.0592, 0.1781, 0.0403, 0.1739, 0.1042, 0.0652, 0.1420, 0.1181,
        0.0609, 0.0340], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,993][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0015, 0.1047, 0.1829, 0.0530, 0.1058, 0.1038, 0.0851, 0.1170, 0.1322,
        0.0525, 0.0615], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,995][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1227, 0.0731, 0.1192, 0.0626, 0.1090, 0.0774, 0.0647, 0.1042, 0.1277,
        0.0813, 0.0581], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:37,997][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0343, 0.0687, 0.1286, 0.0921, 0.0773, 0.0421, 0.0565, 0.0966, 0.0735,
        0.1181, 0.1080, 0.1041], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:37,999][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.4838, 0.0007, 0.0027, 0.0282, 0.0020, 0.0029, 0.0489, 0.0316, 0.0198,
        0.1511, 0.2140, 0.0142], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,000][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0075, 0.0130, 0.2200, 0.1640, 0.0375, 0.2353, 0.0888, 0.0597, 0.0469,
        0.0118, 0.0931, 0.0224], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,002][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0304, 0.1847, 0.1475, 0.1099, 0.0814, 0.0747, 0.0837, 0.0500, 0.0479,
        0.0488, 0.0865, 0.0546], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,004][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0214, 0.1011, 0.0124, 0.1006, 0.0123, 0.0763, 0.0202, 0.4631, 0.0062,
        0.1080, 0.0605, 0.0178], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,006][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0154, 0.1043, 0.1032, 0.0847, 0.0892, 0.1108, 0.0338, 0.0716, 0.1654,
        0.0933, 0.0667, 0.0614], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,007][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0317, 0.0586, 0.0923, 0.0434, 0.1211, 0.0995, 0.0542, 0.0904, 0.1305,
        0.1103, 0.0502, 0.1179], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,009][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.1534, 0.1132, 0.0814, 0.0741, 0.0983, 0.0948, 0.0708, 0.0736, 0.0630,
        0.0677, 0.0528, 0.0570], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,011][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0447, 0.2489, 0.0112, 0.0648, 0.0025, 0.0953, 0.0412, 0.0406, 0.1299,
        0.2064, 0.1127, 0.0020], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,013][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0275, 0.0677, 0.1354, 0.0729, 0.1351, 0.1011, 0.0815, 0.0977, 0.0777,
        0.0704, 0.0718, 0.0610], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,014][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0007, 0.1986, 0.1644, 0.0568, 0.0967, 0.0660, 0.0560, 0.0816, 0.1012,
        0.0749, 0.0513, 0.0518], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,016][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.1073, 0.0603, 0.1030, 0.0505, 0.0977, 0.0664, 0.0539, 0.0971, 0.1123,
        0.0714, 0.0489, 0.1312], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,018][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Stephanie] are: tensor([0.0317, 0.0645, 0.1329, 0.0851, 0.0451, 0.0432, 0.0607, 0.0799, 0.0717,
        0.1175, 0.1031, 0.1125, 0.0520], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,019][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Stephanie] are: tensor([5.6503e-01, 2.6340e-04, 1.2571e-03, 1.8223e-02, 8.5845e-04, 1.3119e-03,
        3.4209e-02, 2.1681e-02, 1.3211e-02, 1.2970e-01, 2.0038e-01, 8.7546e-03,
        5.1201e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,020][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Stephanie] are: tensor([0.0073, 0.0070, 0.3143, 0.0400, 0.0062, 0.2995, 0.0541, 0.0674, 0.0587,
        0.0067, 0.0175, 0.1180, 0.0033], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,020][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Stephanie] are: tensor([0.0148, 0.1522, 0.1196, 0.1073, 0.0635, 0.0702, 0.0914, 0.0490, 0.0485,
        0.0611, 0.1052, 0.0649, 0.0523], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,022][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Stephanie] are: tensor([0.0320, 0.1433, 0.0813, 0.0841, 0.0287, 0.1025, 0.1243, 0.0246, 0.0159,
        0.1809, 0.0580, 0.1039, 0.0206], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,024][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Stephanie] are: tensor([0.0099, 0.1172, 0.0643, 0.0826, 0.0439, 0.1044, 0.0360, 0.0721, 0.1655,
        0.0943, 0.0586, 0.1200, 0.0312], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,026][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Stephanie] are: tensor([0.0252, 0.0509, 0.0799, 0.0397, 0.1054, 0.0862, 0.0452, 0.0779, 0.1110,
        0.0958, 0.0440, 0.1223, 0.1164], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,027][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Stephanie] are: tensor([0.1614, 0.1122, 0.0854, 0.0668, 0.0831, 0.0867, 0.0662, 0.0617, 0.0591,
        0.0511, 0.0438, 0.0539, 0.0687], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,029][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Stephanie] are: tensor([0.0439, 0.2440, 0.0298, 0.0749, 0.0053, 0.0384, 0.0285, 0.0319, 0.1710,
        0.2271, 0.0808, 0.0165, 0.0077], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,031][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Stephanie] are: tensor([0.0205, 0.0643, 0.1384, 0.0665, 0.0719, 0.1104, 0.0833, 0.1089, 0.0859,
        0.0660, 0.0622, 0.0741, 0.0475], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,032][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Stephanie] are: tensor([0.0011, 0.1157, 0.1764, 0.0483, 0.1052, 0.0757, 0.0524, 0.0921, 0.0995,
        0.0481, 0.0424, 0.0757, 0.0672], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,034][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Stephanie] are: tensor([0.0940, 0.0563, 0.0920, 0.0506, 0.0803, 0.0664, 0.0499, 0.0865, 0.1015,
        0.0677, 0.0484, 0.1211, 0.0853], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,036][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0318, 0.0586, 0.1211, 0.0659, 0.0751, 0.0439, 0.0446, 0.0781, 0.0698,
        0.0809, 0.0725, 0.1162, 0.0832, 0.0582], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,038][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.1743, 0.0057, 0.0120, 0.0569, 0.0092, 0.0131, 0.0700, 0.0542, 0.0364,
        0.1293, 0.1458, 0.0269, 0.0185, 0.2474], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,040][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0052, 0.0131, 0.1636, 0.1159, 0.0326, 0.3475, 0.0280, 0.0734, 0.0292,
        0.0107, 0.0929, 0.0588, 0.0169, 0.0121], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,041][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0462, 0.1920, 0.1278, 0.0984, 0.0698, 0.0691, 0.0690, 0.0417, 0.0396,
        0.0371, 0.0681, 0.0477, 0.0539, 0.0395], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,043][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.1546, 0.1104, 0.0356, 0.0943, 0.0103, 0.0820, 0.0569, 0.1335, 0.0084,
        0.1183, 0.0777, 0.1029, 0.0073, 0.0078], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,045][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0132, 0.1061, 0.0662, 0.0899, 0.0725, 0.0673, 0.0344, 0.0987, 0.1018,
        0.1000, 0.0725, 0.0934, 0.0533, 0.0307], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,047][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0258, 0.0438, 0.0644, 0.0334, 0.1116, 0.0667, 0.0446, 0.0636, 0.0862,
        0.0803, 0.0389, 0.1037, 0.1224, 0.1146], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,048][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.1384, 0.0811, 0.0867, 0.0596, 0.0891, 0.0781, 0.0615, 0.0613, 0.0574,
        0.0542, 0.0441, 0.0588, 0.0775, 0.0524], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,050][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0653, 0.3268, 0.0076, 0.0314, 0.0115, 0.0124, 0.0247, 0.0232, 0.0351,
        0.3586, 0.0612, 0.0213, 0.0177, 0.0031], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,052][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0193, 0.0618, 0.1288, 0.0634, 0.1081, 0.0757, 0.0598, 0.0934, 0.0750,
        0.0687, 0.0639, 0.0730, 0.0766, 0.0325], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,054][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0026, 0.0889, 0.1544, 0.0330, 0.1005, 0.0518, 0.0597, 0.1132, 0.0886,
        0.0555, 0.0416, 0.0707, 0.0762, 0.0632], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,055][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0885, 0.0504, 0.0867, 0.0413, 0.0813, 0.0545, 0.0477, 0.0860, 0.0942,
        0.0607, 0.0417, 0.1201, 0.0890, 0.0580], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,057][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0314, 0.0510, 0.1111, 0.0648, 0.0667, 0.0357, 0.0429, 0.0715, 0.0610,
        0.0756, 0.0740, 0.1148, 0.0748, 0.0552, 0.0695], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,059][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1531, 0.0033, 0.0074, 0.0422, 0.0055, 0.0091, 0.0523, 0.0383, 0.0257,
        0.1080, 0.1273, 0.0179, 0.0118, 0.2166, 0.1817], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,061][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0079, 0.0077, 0.1452, 0.0634, 0.0330, 0.2626, 0.0511, 0.1710, 0.0675,
        0.0068, 0.0388, 0.0888, 0.0177, 0.0373, 0.0011], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,062][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0554, 0.1981, 0.1343, 0.1035, 0.0670, 0.0699, 0.0622, 0.0350, 0.0328,
        0.0323, 0.0625, 0.0397, 0.0487, 0.0373, 0.0213], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,063][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0323, 0.0643, 0.0742, 0.0978, 0.0389, 0.1072, 0.0623, 0.0924, 0.0975,
        0.1057, 0.0778, 0.0421, 0.0327, 0.0448, 0.0300], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,064][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0121, 0.0732, 0.0950, 0.0753, 0.0770, 0.1057, 0.0246, 0.0629, 0.1184,
        0.0680, 0.0669, 0.0766, 0.0646, 0.0569, 0.0227], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,065][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0322, 0.0435, 0.0546, 0.0444, 0.0756, 0.0616, 0.0489, 0.0514, 0.0846,
        0.1012, 0.0503, 0.0857, 0.0823, 0.1492, 0.0346], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,067][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1253, 0.0839, 0.0796, 0.0667, 0.0844, 0.0767, 0.0606, 0.0569, 0.0516,
        0.0513, 0.0433, 0.0546, 0.0681, 0.0555, 0.0415], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,068][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0418, 0.1076, 0.0372, 0.0348, 0.0039, 0.2848, 0.0610, 0.0080, 0.0535,
        0.0802, 0.0479, 0.0096, 0.0059, 0.2235, 0.0004], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,070][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0282, 0.0483, 0.1159, 0.0411, 0.1256, 0.0587, 0.0553, 0.0994, 0.0802,
        0.0482, 0.0413, 0.0837, 0.0952, 0.0649, 0.0142], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,072][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0014, 0.1109, 0.1041, 0.0537, 0.0717, 0.0629, 0.0536, 0.0782, 0.0728,
        0.0665, 0.0650, 0.0506, 0.0520, 0.1030, 0.0536], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,073][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0836, 0.0526, 0.0808, 0.0475, 0.0780, 0.0545, 0.0460, 0.0749, 0.0860,
        0.0607, 0.0449, 0.1025, 0.0837, 0.0593, 0.0449], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,077][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:25:38,079][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[6097],
        [6536],
        [ 277],
        [1575],
        [2309],
        [2435],
        [1073],
        [3491],
        [3496],
        [3118],
        [6331],
        [3738],
        [2059],
        [7227],
        [2861]], device='cuda:0')
[2024-07-24 10:25:38,081][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 7582],
        [ 4717],
        [ 1917],
        [10916],
        [ 8071],
        [17439],
        [17570],
        [15842],
        [20725],
        [16661],
        [12743],
        [14935],
        [13617],
        [12816],
        [12191]], device='cuda:0')
[2024-07-24 10:25:38,083][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[25615],
        [25594],
        [25061],
        [24533],
        [24329],
        [20195],
        [16587],
        [15317],
        [14162],
        [13528],
        [10794],
        [11757],
        [16025],
        [14659],
        [13299]], device='cuda:0')
[2024-07-24 10:25:38,084][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[2211],
        [3121],
        [3872],
        [3871],
        [3898],
        [4098],
        [3958],
        [3840],
        [3488],
        [3133],
        [2989],
        [2889],
        [2837],
        [2877],
        [2933]], device='cuda:0')
[2024-07-24 10:25:38,086][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[29720],
        [34293],
        [32614],
        [14346],
        [24807],
        [24926],
        [14854],
        [ 8307],
        [ 7576],
        [22824],
        [17683],
        [15530],
        [30179],
        [32517],
        [27802]], device='cuda:0')
[2024-07-24 10:25:38,087][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[30301],
        [30166],
        [30008],
        [30091],
        [29718],
        [29760],
        [29213],
        [29085],
        [29681],
        [29756],
        [29512],
        [27638],
        [27169],
        [27652],
        [28056]], device='cuda:0')
[2024-07-24 10:25:38,089][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[15126],
        [15084],
        [16104],
        [15866],
        [14748],
        [15871],
        [16369],
        [23277],
        [34248],
        [14150],
        [17885],
        [28508],
        [17069],
        [14740],
        [13172]], device='cuda:0')
[2024-07-24 10:25:38,091][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[25392],
        [36123],
        [38868],
        [37937],
        [41421],
        [40919],
        [39642],
        [39501],
        [40962],
        [41354],
        [41175],
        [41358],
        [42032],
        [42928],
        [42813]], device='cuda:0')
[2024-07-24 10:25:38,092][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[12235],
        [16248],
        [18647],
        [17978],
        [16882],
        [19565],
        [19452],
        [20763],
        [20489],
        [20535],
        [20461],
        [21737],
        [20996],
        [19466],
        [19316]], device='cuda:0')
[2024-07-24 10:25:38,094][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[23450],
        [19094],
        [20526],
        [26112],
        [20255],
        [17785],
        [19463],
        [17012],
        [14005],
        [15092],
        [14763],
        [12902],
        [12944],
        [11152],
        [11406]], device='cuda:0')
[2024-07-24 10:25:38,096][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[3300],
        [3418],
        [3683],
        [3725],
        [3066],
        [3096],
        [3124],
        [3583],
        [3444],
        [3520],
        [3624],
        [3618],
        [3478],
        [3533],
        [3521]], device='cuda:0')
[2024-07-24 10:25:38,097][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[37964],
        [36601],
        [31532],
        [31675],
        [32793],
        [32256],
        [32922],
        [33576],
        [33548],
        [33719],
        [33687],
        [35310],
        [35017],
        [35436],
        [34086]], device='cuda:0')
[2024-07-24 10:25:38,099][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 8287],
        [21888],
        [ 4255],
        [ 4046],
        [ 1947],
        [ 1467],
        [ 1622],
        [ 1963],
        [ 1860],
        [ 2132],
        [ 2252],
        [ 2534],
        [ 1711],
        [ 1359],
        [ 2159]], device='cuda:0')
[2024-07-24 10:25:38,100][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[28229],
        [21770],
        [19974],
        [19979],
        [20018],
        [20034],
        [20128],
        [20542],
        [20374],
        [20372],
        [20478],
        [20873],
        [21035],
        [20974],
        [21059]], device='cuda:0')
[2024-07-24 10:25:38,102][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 5555],
        [14281],
        [ 5334],
        [ 6747],
        [ 5065],
        [ 2019],
        [ 3845],
        [11427],
        [ 3511],
        [ 6921],
        [13209],
        [26867],
        [ 3246],
        [ 5781],
        [ 2160]], device='cuda:0')
[2024-07-24 10:25:38,104][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[35197],
        [38479],
        [38803],
        [39110],
        [39727],
        [40080],
        [39827],
        [40691],
        [41229],
        [40955],
        [40780],
        [41002],
        [41017],
        [41687],
        [41650]], device='cuda:0')
[2024-07-24 10:25:38,105][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[629],
        [629],
        [643],
        [699],
        [613],
        [612],
        [413],
        [275],
        [295],
        [ 80],
        [ 54],
        [ 56],
        [ 71],
        [ 24],
        [ 29]], device='cuda:0')
[2024-07-24 10:25:38,107][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[19332],
        [21104],
        [29919],
        [33551],
        [33104],
        [31094],
        [29991],
        [29343],
        [30490],
        [28408],
        [27661],
        [28258],
        [28624],
        [30032],
        [28293]], device='cuda:0')
[2024-07-24 10:25:38,109][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[8390],
        [5539],
        [5866],
        [6001],
        [6411],
        [6191],
        [6212],
        [6248],
        [6444],
        [6422],
        [6422],
        [6505],
        [6647],
        [6713],
        [6685]], device='cuda:0')
[2024-07-24 10:25:38,110][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[14925],
        [15106],
        [17054],
        [14734],
        [12565],
        [13376],
        [12498],
        [13846],
        [13160],
        [12094],
        [15664],
        [ 7466],
        [12747],
        [11537],
        [11035]], device='cuda:0')
[2024-07-24 10:25:38,112][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[2603],
        [1795],
        [1887],
        [1727],
        [1568],
        [1733],
        [1797],
        [1777],
        [1753],
        [1760],
        [1796],
        [1677],
        [1684],
        [1633],
        [1672]], device='cuda:0')
[2024-07-24 10:25:38,113][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[9374],
        [5909],
        [5549],
        [5522],
        [5345],
        [5103],
        [4787],
        [4653],
        [5024],
        [4765],
        [4720],
        [4823],
        [4853],
        [4819],
        [4679]], device='cuda:0')
[2024-07-24 10:25:38,115][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[3983],
        [3812],
        [3145],
        [3190],
        [3208],
        [3595],
        [3438],
        [3791],
        [3910],
        [3846],
        [3877],
        [4026],
        [3941],
        [4026],
        [4024]], device='cuda:0')
[2024-07-24 10:25:38,117][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[10518],
        [10658],
        [ 9402],
        [ 9947],
        [10514],
        [10078],
        [ 9523],
        [12565],
        [18517],
        [12845],
        [12775],
        [12178],
        [11712],
        [11833],
        [ 6545]], device='cuda:0')
[2024-07-24 10:25:38,118][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[16029],
        [14771],
        [13094],
        [12754],
        [13015],
        [13018],
        [12719],
        [12561],
        [12580],
        [12582],
        [12509],
        [12573],
        [12557],
        [12788],
        [13020]], device='cuda:0')
[2024-07-24 10:25:38,120][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 9571],
        [19608],
        [13251],
        [13366],
        [12866],
        [11917],
        [10104],
        [12472],
        [14114],
        [15876],
        [13629],
        [16179],
        [14645],
        [13365],
        [12312]], device='cuda:0')
[2024-07-24 10:25:38,122][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[4866],
        [6750],
        [5289],
        [5765],
        [4587],
        [4830],
        [5287],
        [5350],
        [5653],
        [6056],
        [6283],
        [5713],
        [5217],
        [5123],
        [5346]], device='cuda:0')
[2024-07-24 10:25:38,123][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[17203],
        [20398],
        [19444],
        [19157],
        [19256],
        [18686],
        [20218],
        [20115],
        [17544],
        [22265],
        [23317],
        [24038],
        [22966],
        [24388],
        [26785]], device='cuda:0')
[2024-07-24 10:25:38,125][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[33822],
        [ 5110],
        [21724],
        [23869],
        [28522],
        [33561],
        [25042],
        [26136],
        [31056],
        [27787],
        [25398],
        [ 8084],
        [20625],
        [37093],
        [34152]], device='cuda:0')
[2024-07-24 10:25:38,127][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[7554],
        [7554],
        [7554],
        [7554],
        [7554],
        [7554],
        [7554],
        [7554],
        [7554],
        [7554],
        [7554],
        [7554],
        [7554],
        [7554],
        [7554]], device='cuda:0')
[2024-07-24 10:25:38,175][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:38,176][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,177][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,179][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,180][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,181][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,183][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,184][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,185][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,187][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,188][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,189][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,191][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,192][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.6263, 0.3737], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,194][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.2591, 0.7409], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,195][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([1.7198e-04, 9.9983e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,197][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1366, 0.8634], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,198][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.6606, 0.3394], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,199][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.6370, 0.3630], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,199][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4046, 0.5954], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,200][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0962, 0.9038], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,201][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1360, 0.8640], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,202][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1801, 0.8199], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,203][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9174, 0.0826], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,204][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.7317, 0.2683], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,205][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Jose] are: tensor([0.4710, 0.2671, 0.2619], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,207][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Jose] are: tensor([0.1801, 0.5530, 0.2669], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,208][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Jose] are: tensor([7.9724e-05, 9.7556e-01, 2.4358e-02], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,209][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Jose] are: tensor([0.0299, 0.4575, 0.5126], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,211][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Jose] are: tensor([0.4683, 0.2271, 0.3046], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,212][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Jose] are: tensor([0.4491, 0.2815, 0.2694], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,214][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Jose] are: tensor([0.2694, 0.3939, 0.3367], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,216][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Jose] are: tensor([0.0381, 0.5511, 0.4108], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,217][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Jose] are: tensor([0.0836, 0.6410, 0.2754], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,219][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Jose] are: tensor([0.0788, 0.7561, 0.1651], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,221][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Jose] are: tensor([0.9357, 0.0319, 0.0323], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,222][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Jose] are: tensor([0.6005, 0.2578, 0.1417], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,224][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3811, 0.2138, 0.2102, 0.1948], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,225][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1254, 0.3930, 0.2326, 0.2490], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,226][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([1.3498e-06, 9.8138e-01, 1.8395e-02, 2.2712e-04], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,228][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0117, 0.3282, 0.5776, 0.0825], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,230][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3724, 0.1863, 0.2408, 0.2005], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,231][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3798, 0.2155, 0.2167, 0.1879], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,233][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1945, 0.2884, 0.2487, 0.2685], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,235][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0289, 0.3071, 0.3365, 0.3276], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,236][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0522, 0.4500, 0.2442, 0.2536], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,238][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0563, 0.3557, 0.0882, 0.4997], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,239][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.8627, 0.0561, 0.0496, 0.0316], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,241][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.5234, 0.2012, 0.1279, 0.1475], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,243][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Stephanie] are: tensor([0.3187, 0.1780, 0.1752, 0.1627, 0.1654], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,244][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Stephanie] are: tensor([0.0923, 0.2968, 0.1449, 0.2223, 0.2437], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,245][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Stephanie] are: tensor([2.1230e-04, 8.2439e-01, 1.3025e-02, 5.9009e-04, 1.6178e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,246][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Stephanie] are: tensor([0.0069, 0.2726, 0.3254, 0.0889, 0.3062], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,247][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Stephanie] are: tensor([0.2922, 0.1468, 0.1953, 0.1640, 0.2017], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,247][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Stephanie] are: tensor([0.2784, 0.1836, 0.1794, 0.1605, 0.1981], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,248][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Stephanie] are: tensor([0.1566, 0.2296, 0.1953, 0.2140, 0.2045], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,250][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Stephanie] are: tensor([0.0195, 0.2407, 0.2110, 0.2232, 0.3056], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,251][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Stephanie] are: tensor([0.0393, 0.3616, 0.1807, 0.2651, 0.1532], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,253][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Stephanie] are: tensor([0.0288, 0.2845, 0.0929, 0.3605, 0.2334], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,255][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Stephanie] are: tensor([0.7884, 0.0426, 0.0488, 0.0294, 0.0908], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,256][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Stephanie] are: tensor([0.3548, 0.1826, 0.1299, 0.1355, 0.1973], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,258][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.2721, 0.1547, 0.1513, 0.1410, 0.1422, 0.1387], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,259][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0923, 0.2185, 0.1223, 0.1811, 0.2064, 0.1794], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,261][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ had] are: tensor([2.3395e-04, 5.2342e-01, 3.7381e-02, 9.1609e-04, 3.9913e-01, 3.8918e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,262][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0066, 0.1418, 0.1406, 0.0636, 0.6235, 0.0238], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,264][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2527, 0.1262, 0.1636, 0.1389, 0.1690, 0.1496], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,266][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.2376, 0.1476, 0.1563, 0.1305, 0.1690, 0.1590], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,267][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.1268, 0.1853, 0.1601, 0.1730, 0.1684, 0.1864], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,269][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0136, 0.1627, 0.1667, 0.1627, 0.2708, 0.2234], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,270][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0368, 0.3002, 0.1411, 0.1920, 0.1390, 0.1910], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,272][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0221, 0.2081, 0.0342, 0.2189, 0.0880, 0.4286], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,274][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.7735, 0.0445, 0.0504, 0.0258, 0.0729, 0.0330], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,275][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.3459, 0.1345, 0.0915, 0.1126, 0.1972, 0.1183], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,277][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2302, 0.1351, 0.1340, 0.1238, 0.1258, 0.1215, 0.1297],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,279][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0665, 0.1965, 0.1120, 0.1420, 0.1774, 0.1609, 0.1447],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,280][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([2.2168e-05, 4.9775e-01, 1.6711e-02, 7.1757e-04, 4.1057e-01, 6.4142e-02,
        1.0087e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,281][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0066, 0.1396, 0.1415, 0.0225, 0.5189, 0.1141, 0.0567],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,283][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2234, 0.1138, 0.1430, 0.1209, 0.1460, 0.1325, 0.1204],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,285][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.2102, 0.1288, 0.1317, 0.1136, 0.1451, 0.1391, 0.1315],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,286][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1052, 0.1559, 0.1344, 0.1456, 0.1418, 0.1574, 0.1597],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,288][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0102, 0.1189, 0.1227, 0.1201, 0.2240, 0.1716, 0.2324],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,290][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0324, 0.2474, 0.1254, 0.1818, 0.1356, 0.2011, 0.0763],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,290][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0250, 0.1411, 0.0403, 0.2062, 0.0841, 0.4446, 0.0587],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,291][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.7115, 0.0486, 0.0497, 0.0332, 0.0828, 0.0413, 0.0328],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,292][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.2899, 0.1384, 0.0790, 0.1008, 0.1645, 0.1194, 0.1080],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,293][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.2051, 0.1202, 0.1186, 0.1105, 0.1116, 0.1084, 0.1165, 0.1091],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,295][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0542, 0.1776, 0.0832, 0.1344, 0.1419, 0.1412, 0.1454, 0.1220],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,296][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ long] are: tensor([3.8903e-05, 5.2029e-01, 9.4185e-03, 8.2746e-04, 2.3346e-01, 1.0123e-01,
        3.6891e-02, 9.7842e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,297][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0034, 0.0953, 0.0886, 0.0378, 0.5064, 0.0211, 0.1986, 0.0488],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,299][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.1909, 0.1000, 0.1286, 0.1090, 0.1319, 0.1178, 0.1070, 0.1148],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,301][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.1970, 0.1145, 0.1144, 0.1029, 0.1321, 0.1284, 0.1224, 0.0883],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,302][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0924, 0.1362, 0.1158, 0.1264, 0.1219, 0.1366, 0.1389, 0.1318],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,304][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0065, 0.1068, 0.0913, 0.1028, 0.1720, 0.1403, 0.2048, 0.1756],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,306][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0263, 0.2240, 0.0982, 0.1584, 0.1106, 0.1814, 0.0775, 0.1237],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,307][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0135, 0.1506, 0.0466, 0.2294, 0.0600, 0.2346, 0.1092, 0.1560],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,309][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.6878, 0.0505, 0.0513, 0.0376, 0.0778, 0.0424, 0.0385, 0.0140],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,311][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.2560, 0.0935, 0.0530, 0.0789, 0.1329, 0.0856, 0.1281, 0.1719],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,312][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.1851, 0.1078, 0.1075, 0.1006, 0.1017, 0.0989, 0.1069, 0.0992, 0.0923],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:38,314][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0410, 0.1485, 0.0717, 0.1172, 0.1251, 0.1320, 0.1333, 0.1239, 0.1071],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:38,315][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([5.9145e-05, 2.3131e-01, 7.6216e-03, 5.8974e-04, 1.9504e-01, 1.3914e-01,
        3.7703e-02, 1.9608e-01, 1.9245e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:38,317][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0018, 0.0688, 0.0297, 0.0265, 0.3054, 0.1023, 0.1068, 0.3275, 0.0312],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:38,319][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.1743, 0.0898, 0.1160, 0.0968, 0.1190, 0.1039, 0.0943, 0.1016, 0.1044],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:38,320][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.1762, 0.1042, 0.1019, 0.0950, 0.1208, 0.1171, 0.1109, 0.0806, 0.0932],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:38,322][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0815, 0.1206, 0.1013, 0.1118, 0.1060, 0.1207, 0.1237, 0.1165, 0.1179],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:38,324][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0068, 0.0840, 0.0700, 0.0774, 0.1304, 0.1086, 0.1547, 0.1425, 0.2256],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:38,326][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0219, 0.1794, 0.0961, 0.1364, 0.1055, 0.1646, 0.0643, 0.1493, 0.0824],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:38,328][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0088, 0.0970, 0.0394, 0.1218, 0.0837, 0.2715, 0.0502, 0.2250, 0.1025],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:38,329][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.7125, 0.0470, 0.0434, 0.0307, 0.0654, 0.0352, 0.0277, 0.0120, 0.0262],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:38,331][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.1847, 0.0836, 0.0567, 0.0663, 0.1132, 0.0890, 0.1071, 0.1843, 0.1153],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:38,333][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1657, 0.0988, 0.0991, 0.0918, 0.0936, 0.0901, 0.0967, 0.0907, 0.0844,
        0.0890], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:38,334][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0372, 0.1245, 0.0688, 0.0989, 0.1121, 0.1178, 0.1042, 0.1033, 0.0992,
        0.1340], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:38,335][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([5.8275e-05, 1.8959e-01, 2.2068e-02, 9.9712e-04, 2.7920e-01, 6.4342e-02,
        2.6813e-02, 1.3694e-01, 2.6916e-01, 1.0832e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:38,336][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0024, 0.0197, 0.0496, 0.0064, 0.3119, 0.0481, 0.1339, 0.3286, 0.0498,
        0.0496], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:38,337][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1604, 0.0844, 0.1047, 0.0884, 0.1065, 0.0967, 0.0886, 0.0934, 0.0973,
        0.0795], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:38,338][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1682, 0.0955, 0.0955, 0.0850, 0.1105, 0.1057, 0.1016, 0.0750, 0.0866,
        0.0765], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:38,339][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0708, 0.1060, 0.0916, 0.0995, 0.0965, 0.1082, 0.1099, 0.1045, 0.1063,
        0.1068], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:38,341][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0043, 0.0603, 0.0584, 0.0632, 0.1117, 0.0974, 0.1467, 0.1284, 0.2477,
        0.0817], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:38,343][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0211, 0.1533, 0.0840, 0.1084, 0.0992, 0.1402, 0.0677, 0.1055, 0.0937,
        0.1269], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:38,344][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0124, 0.0678, 0.0235, 0.1338, 0.0812, 0.1654, 0.0709, 0.2500, 0.1170,
        0.0782], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:38,346][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.6213, 0.0631, 0.0543, 0.0365, 0.0828, 0.0345, 0.0304, 0.0119, 0.0244,
        0.0409], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:38,348][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1851, 0.0774, 0.0470, 0.0669, 0.0953, 0.0762, 0.0974, 0.1374, 0.1393,
        0.0779], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:38,350][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1572, 0.0915, 0.0908, 0.0845, 0.0855, 0.0825, 0.0889, 0.0830, 0.0772,
        0.0817, 0.0772], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:38,351][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0347, 0.1176, 0.0677, 0.0740, 0.1049, 0.1075, 0.0939, 0.1006, 0.0975,
        0.1343, 0.0674], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:38,353][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0006, 0.1136, 0.0274, 0.0010, 0.2802, 0.0748, 0.0305, 0.1175, 0.2535,
        0.0296, 0.0715], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:38,355][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0028, 0.0434, 0.0449, 0.0068, 0.1112, 0.0720, 0.2380, 0.2135, 0.1110,
        0.1090, 0.0475], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:38,356][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1514, 0.0764, 0.0985, 0.0808, 0.1019, 0.0886, 0.0801, 0.0859, 0.0903,
        0.0711, 0.0750], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:38,358][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1678, 0.0886, 0.0886, 0.0770, 0.0999, 0.0974, 0.0958, 0.0694, 0.0796,
        0.0715, 0.0644], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:38,360][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0635, 0.0960, 0.0838, 0.0904, 0.0887, 0.0984, 0.1002, 0.0950, 0.0973,
        0.0974, 0.0892], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:38,362][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0060, 0.0573, 0.0619, 0.0576, 0.1017, 0.0881, 0.1220, 0.1091, 0.2132,
        0.0724, 0.1108], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:38,363][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0189, 0.1439, 0.0797, 0.0847, 0.1049, 0.1247, 0.0611, 0.0905, 0.0898,
        0.1229, 0.0790], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:38,365][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0113, 0.0845, 0.0207, 0.1233, 0.0690, 0.1537, 0.0767, 0.1644, 0.0978,
        0.0953, 0.1032], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:38,367][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.6394, 0.0560, 0.0421, 0.0307, 0.0657, 0.0284, 0.0277, 0.0114, 0.0215,
        0.0357, 0.0413], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:38,369][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1854, 0.0752, 0.0476, 0.0537, 0.0876, 0.0649, 0.0893, 0.1302, 0.1308,
        0.0773, 0.0582], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:38,370][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.1478, 0.0848, 0.0840, 0.0775, 0.0792, 0.0761, 0.0826, 0.0765, 0.0704,
        0.0750, 0.0711, 0.0751], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,372][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0291, 0.1047, 0.0553, 0.0785, 0.0873, 0.0911, 0.0844, 0.1033, 0.0808,
        0.1352, 0.0776, 0.0726], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,373][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([2.2484e-04, 2.9394e-02, 3.5173e-03, 6.6637e-04, 6.4505e-02, 3.6878e-02,
        1.5899e-02, 1.1778e-01, 1.8125e-01, 1.4274e-02, 5.3467e-02, 4.8214e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,375][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0007, 0.0286, 0.0257, 0.0162, 0.0751, 0.0161, 0.0887, 0.4189, 0.0104,
        0.0861, 0.1151, 0.1183], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,377][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.1388, 0.0687, 0.0906, 0.0751, 0.0931, 0.0808, 0.0737, 0.0786, 0.0817,
        0.0646, 0.0694, 0.0851], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,379][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.1411, 0.0831, 0.0833, 0.0760, 0.0959, 0.0945, 0.0893, 0.0631, 0.0725,
        0.0686, 0.0637, 0.0688], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,380][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0609, 0.0889, 0.0753, 0.0826, 0.0787, 0.0896, 0.0914, 0.0857, 0.0867,
        0.0895, 0.0825, 0.0881], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,381][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0048, 0.0669, 0.0494, 0.0606, 0.0910, 0.0708, 0.1008, 0.0887, 0.1348,
        0.0622, 0.0896, 0.1805], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,382][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0142, 0.1338, 0.0659, 0.1058, 0.0726, 0.1146, 0.0473, 0.0984, 0.0739,
        0.1251, 0.0999, 0.0486], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,382][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0062, 0.0880, 0.0252, 0.1285, 0.0463, 0.1926, 0.0532, 0.1121, 0.0561,
        0.1306, 0.1231, 0.0383], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,384][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.6642, 0.0386, 0.0344, 0.0228, 0.0470, 0.0267, 0.0238, 0.0104, 0.0231,
        0.0267, 0.0328, 0.0494], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,386][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.1310, 0.0586, 0.0406, 0.0533, 0.0775, 0.0720, 0.0902, 0.1352, 0.1017,
        0.0686, 0.0577, 0.1136], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,387][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Stephanie] are: tensor([0.1362, 0.0786, 0.0784, 0.0719, 0.0742, 0.0710, 0.0767, 0.0712, 0.0660,
        0.0699, 0.0662, 0.0697, 0.0700], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,389][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Stephanie] are: tensor([0.0260, 0.0970, 0.0462, 0.0694, 0.0792, 0.0794, 0.0820, 0.0838, 0.0816,
        0.1261, 0.0701, 0.0845, 0.0745], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,390][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Stephanie] are: tensor([2.0732e-04, 3.4653e-04, 9.1161e-05, 1.6895e-05, 1.0322e-03, 4.8398e-03,
        1.3104e-03, 4.4819e-03, 5.2891e-03, 1.2786e-03, 6.5496e-03, 7.7662e-02,
        8.9689e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,392][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Stephanie] are: tensor([0.0019, 0.0465, 0.0446, 0.0107, 0.0320, 0.0221, 0.1404, 0.0909, 0.0159,
        0.0835, 0.0463, 0.2426, 0.2227], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,394][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Stephanie] are: tensor([0.1259, 0.0622, 0.0837, 0.0695, 0.0856, 0.0743, 0.0681, 0.0728, 0.0750,
        0.0595, 0.0637, 0.0763, 0.0834], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,396][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Stephanie] are: tensor([0.1272, 0.0793, 0.0764, 0.0684, 0.0859, 0.0923, 0.0808, 0.0598, 0.0696,
        0.0632, 0.0573, 0.0686, 0.0712], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,397][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Stephanie] are: tensor([0.0539, 0.0814, 0.0697, 0.0768, 0.0732, 0.0831, 0.0852, 0.0802, 0.0815,
        0.0838, 0.0772, 0.0830, 0.0711], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,399][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Stephanie] are: tensor([0.0041, 0.0606, 0.0440, 0.0511, 0.0695, 0.0599, 0.0869, 0.0783, 0.1229,
        0.0501, 0.0787, 0.1946, 0.0991], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,401][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Stephanie] are: tensor([0.0141, 0.1277, 0.0655, 0.1004, 0.0555, 0.1036, 0.0486, 0.0954, 0.0705,
        0.1194, 0.0952, 0.0605, 0.0435], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,402][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Stephanie] are: tensor([0.0071, 0.0744, 0.0246, 0.0962, 0.0667, 0.1190, 0.0478, 0.1978, 0.0638,
        0.1032, 0.0872, 0.0570, 0.0552], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,404][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Stephanie] are: tensor([0.4036, 0.0435, 0.0477, 0.0307, 0.0714, 0.0334, 0.0368, 0.0223, 0.0380,
        0.0405, 0.0431, 0.0581, 0.1309], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,406][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Stephanie] are: tensor([0.1290, 0.0653, 0.0441, 0.0462, 0.0688, 0.0682, 0.0679, 0.0955, 0.0934,
        0.0582, 0.0470, 0.1260, 0.0903], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,408][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.1288, 0.0740, 0.0733, 0.0682, 0.0693, 0.0663, 0.0725, 0.0670, 0.0614,
        0.0659, 0.0627, 0.0655, 0.0662, 0.0589], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,410][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0261, 0.0864, 0.0414, 0.0736, 0.0722, 0.0687, 0.0801, 0.0827, 0.0554,
        0.1179, 0.0713, 0.0771, 0.0695, 0.0778], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,411][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ said] are: tensor([5.9510e-04, 2.2114e-03, 7.3828e-04, 1.3074e-04, 4.6825e-03, 7.4843e-03,
        2.7568e-03, 9.3590e-03, 6.9641e-03, 3.5594e-03, 1.6844e-02, 3.8149e-02,
        8.4544e-01, 6.1088e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,413][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0014, 0.0113, 0.0130, 0.0038, 0.0399, 0.0065, 0.0176, 0.1047, 0.0015,
        0.0419, 0.0328, 0.2444, 0.4747, 0.0066], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,414][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.1107, 0.0583, 0.0763, 0.0643, 0.0776, 0.0696, 0.0638, 0.0683, 0.0706,
        0.0566, 0.0604, 0.0724, 0.0768, 0.0743], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,416][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.1262, 0.0728, 0.0729, 0.0626, 0.0817, 0.0795, 0.0755, 0.0547, 0.0643,
        0.0576, 0.0527, 0.0621, 0.0679, 0.0695], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,418][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0506, 0.0759, 0.0650, 0.0710, 0.0685, 0.0769, 0.0788, 0.0742, 0.0755,
        0.0772, 0.0710, 0.0764, 0.0665, 0.0725], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,419][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0038, 0.0434, 0.0391, 0.0419, 0.0663, 0.0483, 0.0779, 0.0675, 0.1167,
        0.0441, 0.0644, 0.1918, 0.1068, 0.0881], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,421][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0134, 0.1145, 0.0631, 0.0907, 0.0742, 0.0977, 0.0454, 0.0943, 0.0642,
        0.1056, 0.0850, 0.0530, 0.0592, 0.0397], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,423][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0073, 0.0645, 0.0161, 0.0810, 0.0474, 0.1189, 0.0368, 0.1860, 0.0647,
        0.0771, 0.0775, 0.0981, 0.0429, 0.0818], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,424][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.5426, 0.0405, 0.0354, 0.0224, 0.0557, 0.0233, 0.0206, 0.0092, 0.0198,
        0.0274, 0.0302, 0.0381, 0.1033, 0.0315], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,425][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.1116, 0.0535, 0.0318, 0.0397, 0.0689, 0.0626, 0.0596, 0.0920, 0.0975,
        0.0550, 0.0443, 0.1496, 0.0922, 0.0418], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,426][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1116, 0.0684, 0.0678, 0.0634, 0.0643, 0.0620, 0.0669, 0.0627, 0.0582,
        0.0617, 0.0584, 0.0609, 0.0609, 0.0551, 0.0778], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,427][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0274, 0.0786, 0.0494, 0.0624, 0.0707, 0.0762, 0.0671, 0.0686, 0.0669,
        0.0923, 0.0612, 0.0648, 0.0666, 0.0930, 0.0548], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,428][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([1.8646e-03, 7.5074e-06, 1.8472e-05, 3.4376e-06, 7.4263e-05, 2.1620e-04,
        1.4033e-04, 4.8303e-04, 2.3270e-04, 1.9276e-04, 1.0045e-03, 6.1117e-03,
        3.5514e-02, 1.5696e-02, 9.3844e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,430][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0014, 0.0128, 0.0177, 0.0018, 0.0380, 0.0155, 0.0258, 0.0690, 0.0499,
        0.0247, 0.0146, 0.1040, 0.5442, 0.0671, 0.0134], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,431][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1056, 0.0560, 0.0701, 0.0609, 0.0716, 0.0648, 0.0599, 0.0630, 0.0650,
        0.0534, 0.0568, 0.0670, 0.0700, 0.0687, 0.0671], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,433][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1254, 0.0682, 0.0665, 0.0597, 0.0759, 0.0752, 0.0723, 0.0521, 0.0614,
        0.0556, 0.0500, 0.0560, 0.0636, 0.0633, 0.0548], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,435][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0492, 0.0706, 0.0613, 0.0662, 0.0639, 0.0714, 0.0726, 0.0686, 0.0696,
        0.0707, 0.0654, 0.0695, 0.0616, 0.0664, 0.0729], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,437][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0047, 0.0377, 0.0345, 0.0379, 0.0601, 0.0440, 0.0659, 0.0626, 0.1043,
        0.0304, 0.0397, 0.1887, 0.1034, 0.0862, 0.0998], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,438][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0129, 0.1187, 0.0600, 0.0828, 0.0610, 0.1030, 0.0411, 0.0726, 0.0589,
        0.1014, 0.0796, 0.0464, 0.0483, 0.0459, 0.0673], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,440][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0071, 0.0561, 0.0204, 0.0952, 0.0413, 0.1328, 0.0463, 0.1369, 0.1230,
        0.0633, 0.0859, 0.0533, 0.0348, 0.0712, 0.0324], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,442][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.5274, 0.0410, 0.0340, 0.0206, 0.0522, 0.0224, 0.0163, 0.0076, 0.0172,
        0.0226, 0.0256, 0.0334, 0.0951, 0.0254, 0.0590], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,444][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1154, 0.0536, 0.0298, 0.0446, 0.0624, 0.0456, 0.0579, 0.0898, 0.1066,
        0.0573, 0.0495, 0.1072, 0.0891, 0.0453, 0.0459], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,489][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:38,491][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,492][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,493][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,495][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,496][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,497][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,498][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,498][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,499][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,500][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,501][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,503][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,504][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9039, 0.0961], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,506][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2701, 0.7299], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,507][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0425, 0.9575], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,509][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9259, 0.0741], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,510][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5051, 0.4949], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,512][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9978, 0.0022], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,514][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.5788, 0.4212], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,515][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.5510, 0.4490], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,517][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3265, 0.6735], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,518][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2027, 0.7973], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,520][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.4368, 0.5632], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,521][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.3040, 0.6960], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,522][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Jose] are: tensor([0.8772, 0.0710, 0.0517], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,523][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Jose] are: tensor([0.1802, 0.5478, 0.2720], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,524][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Jose] are: tensor([0.0186, 0.6176, 0.3639], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,524][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Jose] are: tensor([0.7224, 0.2450, 0.0326], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,526][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Jose] are: tensor([0.3336, 0.3227, 0.3437], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,527][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Jose] are: tensor([0.9782, 0.0136, 0.0082], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,529][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Jose] are: tensor([0.2257, 0.4286, 0.3457], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,531][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Jose] are: tensor([0.4411, 0.2733, 0.2856], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,532][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Jose] are: tensor([0.2063, 0.4188, 0.3749], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,533][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Jose] are: tensor([0.0822, 0.7669, 0.1509], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,535][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Jose] are: tensor([0.2750, 0.3539, 0.3711], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,536][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Jose] are: tensor([0.1066, 0.8079, 0.0856], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,538][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.8237, 0.0698, 0.0514, 0.0551], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,539][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1277, 0.3810, 0.2399, 0.2515], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,541][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0092, 0.5543, 0.3163, 0.1201], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,543][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.6728, 0.1928, 0.0372, 0.0971], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,544][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2471, 0.2390, 0.2536, 0.2602], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,546][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9842, 0.0053, 0.0035, 0.0070], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,548][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0302, 0.1941, 0.2316, 0.5441], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,549][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2725, 0.1816, 0.3078, 0.2381], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,551][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1482, 0.3258, 0.2865, 0.2394], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,552][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0673, 0.3969, 0.0806, 0.4551], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,554][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2015, 0.2569, 0.2701, 0.2716], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,556][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0294, 0.7057, 0.0392, 0.2258], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,557][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Stephanie] are: tensor([0.7612, 0.0666, 0.0488, 0.0535, 0.0700], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,559][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Stephanie] are: tensor([0.0974, 0.2844, 0.1454, 0.2361, 0.2367], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,561][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Stephanie] are: tensor([0.0176, 0.3278, 0.1982, 0.0905, 0.3659], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,562][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Stephanie] are: tensor([0.6067, 0.2364, 0.0250, 0.0742, 0.0577], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,564][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Stephanie] are: tensor([0.2017, 0.1948, 0.2053, 0.2099, 0.1884], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,565][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Stephanie] are: tensor([0.9553, 0.0095, 0.0059, 0.0139, 0.0154], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,567][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Stephanie] are: tensor([0.2755, 0.1627, 0.2754, 0.2638, 0.0225], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,568][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Stephanie] are: tensor([0.2328, 0.1609, 0.2290, 0.2657, 0.1116], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,568][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Stephanie] are: tensor([0.1171, 0.2496, 0.2214, 0.1921, 0.2199], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,569][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Stephanie] are: tensor([0.0295, 0.3085, 0.0824, 0.3317, 0.2480], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,570][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Stephanie] are: tensor([0.1611, 0.2076, 0.2190, 0.2210, 0.1914], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,572][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Stephanie] are: tensor([0.1536, 0.4734, 0.0284, 0.2200, 0.1247], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,573][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.6977, 0.0636, 0.0475, 0.0501, 0.0670, 0.0741], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,575][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0934, 0.2096, 0.1259, 0.1945, 0.2097, 0.1669], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,577][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0087, 0.2129, 0.1323, 0.0669, 0.3757, 0.2035], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,578][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.8404, 0.0724, 0.0108, 0.0395, 0.0258, 0.0110], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,580][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1656, 0.1609, 0.1695, 0.1736, 0.1571, 0.1733], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,582][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.9741, 0.0041, 0.0029, 0.0055, 0.0069, 0.0066], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,583][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.1213, 0.0894, 0.2567, 0.3253, 0.0380, 0.1694], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,585][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1763, 0.1330, 0.1902, 0.1899, 0.1627, 0.1478], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,587][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0986, 0.2025, 0.1783, 0.1545, 0.1751, 0.1911], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,588][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0317, 0.2325, 0.0313, 0.2078, 0.0960, 0.4007], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,590][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.1337, 0.1700, 0.1783, 0.1783, 0.1589, 0.1808], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,591][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0543, 0.3025, 0.0077, 0.1010, 0.0561, 0.4783], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,593][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.6680, 0.0593, 0.0431, 0.0459, 0.0606, 0.0691, 0.0540],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,595][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0690, 0.1914, 0.1113, 0.1526, 0.1885, 0.1519, 0.1351],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,596][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0034, 0.1572, 0.0841, 0.0426, 0.3763, 0.1893, 0.1472],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,598][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1311, 0.0206, 0.0026, 0.0213, 0.0297, 0.0018, 0.7929],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,600][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1434, 0.1369, 0.1443, 0.1484, 0.1339, 0.1485, 0.1446],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,601][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.9763, 0.0026, 0.0017, 0.0038, 0.0052, 0.0043, 0.0062],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,603][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0208, 0.0612, 0.1112, 0.2188, 0.0679, 0.4725, 0.0476],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,605][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1426, 0.0992, 0.1427, 0.1398, 0.1307, 0.1866, 0.1584],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,606][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0808, 0.1706, 0.1460, 0.1268, 0.1448, 0.1575, 0.1735],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,608][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0322, 0.1644, 0.0385, 0.1907, 0.0940, 0.4048, 0.0754],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,610][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1122, 0.1412, 0.1467, 0.1472, 0.1310, 0.1488, 0.1729],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,611][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0095, 0.3489, 0.0015, 0.0793, 0.0223, 0.4412, 0.0974],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,612][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.7042, 0.0489, 0.0337, 0.0368, 0.0488, 0.0569, 0.0435, 0.0273],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,613][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0530, 0.1741, 0.0854, 0.1485, 0.1551, 0.1355, 0.1302, 0.1182],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,614][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0028, 0.1186, 0.0586, 0.0317, 0.2612, 0.1445, 0.1254, 0.2571],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,615][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([3.2151e-02, 3.2402e-03, 2.2511e-04, 3.8278e-03, 3.2913e-03, 2.2130e-04,
        3.2679e-01, 6.3025e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,616][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.1253, 0.1210, 0.1276, 0.1311, 0.1178, 0.1309, 0.1269, 0.1193],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,617][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.9302, 0.0063, 0.0036, 0.0073, 0.0094, 0.0077, 0.0132, 0.0223],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,619][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0194, 0.0464, 0.0644, 0.2684, 0.0350, 0.4052, 0.0681, 0.0932],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,621][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.1034, 0.0764, 0.1004, 0.1436, 0.0960, 0.1882, 0.1556, 0.1364],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,622][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0674, 0.1434, 0.1262, 0.1101, 0.1246, 0.1359, 0.1503, 0.1422],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,624][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0170, 0.1645, 0.0373, 0.2029, 0.0725, 0.2259, 0.1239, 0.1560],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,626][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0946, 0.1203, 0.1246, 0.1265, 0.1106, 0.1272, 0.1488, 0.1475],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,628][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0070, 0.2110, 0.0011, 0.0394, 0.0173, 0.2008, 0.3554, 0.1680],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,629][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.7125, 0.0443, 0.0298, 0.0335, 0.0425, 0.0521, 0.0401, 0.0236, 0.0216],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:38,631][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0392, 0.1430, 0.0728, 0.1307, 0.1338, 0.1277, 0.1177, 0.1230, 0.1120],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:38,633][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0022, 0.0876, 0.0415, 0.0241, 0.1592, 0.1053, 0.0952, 0.2099, 0.2750],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:38,634][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0335, 0.0073, 0.0007, 0.0078, 0.0057, 0.0010, 0.3159, 0.5208, 0.1073],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:38,636][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.1129, 0.1081, 0.1137, 0.1170, 0.1048, 0.1170, 0.1143, 0.1073, 0.1051],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:38,638][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.9130, 0.0052, 0.0028, 0.0066, 0.0080, 0.0076, 0.0122, 0.0203, 0.0243],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:38,640][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0373, 0.0600, 0.1120, 0.2262, 0.0537, 0.2046, 0.1085, 0.1723, 0.0253],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:38,641][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0900, 0.0669, 0.0957, 0.1011, 0.0907, 0.1686, 0.1277, 0.1878, 0.0715],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:38,643][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0592, 0.1251, 0.1100, 0.0963, 0.1087, 0.1188, 0.1322, 0.1254, 0.1242],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:38,645][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0099, 0.1147, 0.0331, 0.1211, 0.0889, 0.2471, 0.0641, 0.2141, 0.1068],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:38,646][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0826, 0.1045, 0.1083, 0.1104, 0.0954, 0.1109, 0.1294, 0.1277, 0.1307],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:38,647][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([5.7745e-03, 8.6343e-02, 3.2020e-04, 2.9157e-02, 3.7190e-03, 8.6659e-02,
        1.2249e-01, 6.0993e-01, 5.5606e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:38,649][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.6046, 0.0513, 0.0375, 0.0405, 0.0527, 0.0601, 0.0467, 0.0310, 0.0285,
        0.0471], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:38,651][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0351, 0.1198, 0.0679, 0.1054, 0.1201, 0.1118, 0.0967, 0.1026, 0.1093,
        0.1314], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:38,652][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0014, 0.0692, 0.0360, 0.0206, 0.1967, 0.0970, 0.0779, 0.1783, 0.2512,
        0.0716], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:38,654][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0779, 0.0056, 0.0007, 0.0046, 0.0064, 0.0006, 0.1676, 0.3339, 0.0633,
        0.3394], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:38,656][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1031, 0.0984, 0.1034, 0.1059, 0.0951, 0.1062, 0.1036, 0.0972, 0.0948,
        0.0924], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:38,657][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9160, 0.0036, 0.0020, 0.0045, 0.0059, 0.0053, 0.0084, 0.0167, 0.0205,
        0.0171], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:38,658][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0083, 0.0276, 0.0452, 0.1645, 0.0435, 0.4751, 0.0374, 0.0638, 0.0045,
        0.1301], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:38,659][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0743, 0.0466, 0.0893, 0.0804, 0.0883, 0.1088, 0.1538, 0.1818, 0.1294,
        0.0474], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:38,659][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0515, 0.1118, 0.0992, 0.0854, 0.0968, 0.1087, 0.1189, 0.1126, 0.1102,
        0.1049], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:38,661][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0159, 0.0823, 0.0220, 0.1168, 0.0869, 0.1651, 0.0842, 0.2197, 0.1132,
        0.0938], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:38,663][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0732, 0.0925, 0.0960, 0.0963, 0.0854, 0.0971, 0.1123, 0.1119, 0.1141,
        0.1212], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:38,664][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0059, 0.0285, 0.0007, 0.0236, 0.0071, 0.1037, 0.1321, 0.3256, 0.0959,
        0.2769], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:38,666][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.5858, 0.0483, 0.0352, 0.0385, 0.0508, 0.0571, 0.0448, 0.0296, 0.0276,
        0.0453, 0.0369], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:38,667][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0326, 0.1144, 0.0715, 0.0741, 0.1145, 0.1034, 0.0824, 0.0989, 0.1131,
        0.1318, 0.0634], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:38,669][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0019, 0.0756, 0.0430, 0.0200, 0.1859, 0.0935, 0.0761, 0.1618, 0.2282,
        0.0727, 0.0413], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:38,671][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0491, 0.0079, 0.0011, 0.0038, 0.0052, 0.0016, 0.1340, 0.5278, 0.0515,
        0.2085, 0.0094], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:38,673][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0945, 0.0907, 0.0954, 0.0979, 0.0875, 0.0979, 0.0951, 0.0894, 0.0868,
        0.0846, 0.0802], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:38,674][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9195, 0.0027, 0.0017, 0.0040, 0.0048, 0.0047, 0.0071, 0.0149, 0.0196,
        0.0156, 0.0055], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:38,676][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0085, 0.0433, 0.0479, 0.1064, 0.0534, 0.5083, 0.0435, 0.0784, 0.0107,
        0.0793, 0.0203], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:38,678][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0780, 0.0497, 0.0885, 0.0645, 0.0836, 0.1129, 0.1059, 0.1698, 0.1269,
        0.0472, 0.0729], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:38,679][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0482, 0.1003, 0.0904, 0.0769, 0.0882, 0.0986, 0.1093, 0.1030, 0.1019,
        0.0961, 0.0870], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:38,681][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0125, 0.0928, 0.0180, 0.1077, 0.0708, 0.1407, 0.0819, 0.1372, 0.0954,
        0.1102, 0.1328], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:38,683][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0653, 0.0833, 0.0871, 0.0874, 0.0774, 0.0885, 0.1021, 0.1020, 0.1038,
        0.1100, 0.0932], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:38,684][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([1.9048e-02, 2.7416e-03, 1.0455e-04, 4.9075e-04, 6.5139e-04, 1.2307e-02,
        5.8463e-03, 1.1015e-02, 6.1561e-03, 2.0036e-02, 9.2160e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:38,686][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.5266, 0.0492, 0.0355, 0.0397, 0.0505, 0.0568, 0.0460, 0.0295, 0.0275,
        0.0468, 0.0392, 0.0528], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,688][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0296, 0.1007, 0.0563, 0.0868, 0.0877, 0.0871, 0.0746, 0.1007, 0.0869,
        0.1299, 0.0810, 0.0787], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,689][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0058, 0.0807, 0.0425, 0.0252, 0.1247, 0.0798, 0.0712, 0.1382, 0.1834,
        0.0713, 0.0441, 0.1333], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,691][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0275, 0.0083, 0.0008, 0.0080, 0.0072, 0.0010, 0.1476, 0.2068, 0.0646,
        0.3738, 0.0270, 0.1273], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,693][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0891, 0.0847, 0.0890, 0.0911, 0.0811, 0.0915, 0.0890, 0.0830, 0.0806,
        0.0785, 0.0741, 0.0684], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,695][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.8671, 0.0042, 0.0027, 0.0063, 0.0069, 0.0069, 0.0102, 0.0203, 0.0263,
        0.0274, 0.0101, 0.0115], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,696][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0671, 0.0464, 0.0427, 0.0810, 0.0232, 0.0809, 0.0839, 0.1226, 0.0484,
        0.1556, 0.1812, 0.0671], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,698][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0684, 0.0458, 0.0604, 0.0797, 0.0556, 0.1150, 0.1064, 0.1343, 0.0854,
        0.0553, 0.0954, 0.0982], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,700][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0452, 0.0913, 0.0813, 0.0706, 0.0799, 0.0874, 0.0970, 0.0918, 0.0926,
        0.0871, 0.0792, 0.0965], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,702][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0064, 0.0913, 0.0204, 0.1034, 0.0509, 0.1740, 0.0567, 0.1008, 0.0611,
        0.1278, 0.1376, 0.0696], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,703][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0602, 0.0759, 0.0794, 0.0809, 0.0697, 0.0812, 0.0947, 0.0931, 0.0947,
        0.1024, 0.0866, 0.0812], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,705][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([9.0721e-03, 1.2309e-02, 1.3087e-04, 1.8537e-03, 1.0703e-03, 4.7724e-03,
        4.7644e-03, 1.8606e-02, 9.5319e-03, 1.6204e-02, 5.5175e-01, 3.6994e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:38,706][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Stephanie] are: tensor([0.5089, 0.0469, 0.0335, 0.0371, 0.0477, 0.0533, 0.0415, 0.0264, 0.0250,
        0.0425, 0.0356, 0.0479, 0.0536], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,707][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Stephanie] are: tensor([0.0282, 0.0959, 0.0469, 0.0771, 0.0795, 0.0779, 0.0724, 0.0792, 0.0863,
        0.1170, 0.0712, 0.0932, 0.0751], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,708][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Stephanie] are: tensor([0.0057, 0.0719, 0.0414, 0.0216, 0.0892, 0.0700, 0.0577, 0.1092, 0.1439,
        0.0586, 0.0358, 0.1211, 0.1740], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,709][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Stephanie] are: tensor([0.0374, 0.0102, 0.0011, 0.0062, 0.0052, 0.0012, 0.1326, 0.2673, 0.0601,
        0.3098, 0.0221, 0.0730, 0.0738], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,710][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Stephanie] are: tensor([0.0854, 0.0810, 0.0840, 0.0858, 0.0760, 0.0863, 0.0840, 0.0782, 0.0758,
        0.0741, 0.0695, 0.0640, 0.0559], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,712][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Stephanie] are: tensor([0.8004, 0.0058, 0.0035, 0.0089, 0.0096, 0.0093, 0.0143, 0.0263, 0.0360,
        0.0432, 0.0151, 0.0161, 0.0116], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,713][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Stephanie] are: tensor([0.0341, 0.0334, 0.0359, 0.0713, 0.0100, 0.0766, 0.0829, 0.1695, 0.0290,
        0.2196, 0.1743, 0.0363, 0.0271], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,715][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Stephanie] are: tensor([0.0593, 0.0365, 0.0569, 0.0689, 0.0296, 0.1140, 0.0873, 0.1317, 0.0964,
        0.0443, 0.0856, 0.1464, 0.0432], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,717][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Stephanie] are: tensor([0.0384, 0.0830, 0.0740, 0.0643, 0.0726, 0.0803, 0.0898, 0.0854, 0.0858,
        0.0806, 0.0738, 0.0905, 0.0817], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,718][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Stephanie] are: tensor([0.0062, 0.0758, 0.0206, 0.0838, 0.0670, 0.1056, 0.0530, 0.1520, 0.0643,
        0.1107, 0.1069, 0.0809, 0.0732], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,720][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Stephanie] are: tensor([0.0554, 0.0711, 0.0741, 0.0751, 0.0643, 0.0762, 0.0888, 0.0877, 0.0891,
        0.0969, 0.0813, 0.0753, 0.0646], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,721][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Stephanie] are: tensor([3.5593e-02, 3.1164e-03, 9.5523e-05, 1.0062e-03, 5.2263e-04, 6.4757e-03,
        5.3026e-03, 3.1144e-03, 8.0089e-03, 9.6851e-03, 2.9022e-01, 6.0099e-01,
        3.5875e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:38,723][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.5087, 0.0423, 0.0303, 0.0333, 0.0433, 0.0507, 0.0395, 0.0255, 0.0233,
        0.0390, 0.0321, 0.0431, 0.0488, 0.0400], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,725][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0250, 0.0798, 0.0408, 0.0773, 0.0748, 0.0646, 0.0671, 0.0797, 0.0576,
        0.1071, 0.0694, 0.0821, 0.0730, 0.1017], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,726][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0022, 0.0549, 0.0242, 0.0122, 0.1123, 0.0595, 0.0419, 0.0921, 0.1230,
        0.0388, 0.0235, 0.1250, 0.2140, 0.0764], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,728][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0104, 0.0083, 0.0013, 0.0068, 0.0056, 0.0024, 0.1247, 0.3944, 0.0573,
        0.2594, 0.0174, 0.0575, 0.0487, 0.0059], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,730][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0791, 0.0753, 0.0791, 0.0811, 0.0722, 0.0814, 0.0789, 0.0737, 0.0715,
        0.0696, 0.0657, 0.0609, 0.0533, 0.0580], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,732][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.8135, 0.0057, 0.0030, 0.0070, 0.0079, 0.0072, 0.0127, 0.0217, 0.0253,
        0.0283, 0.0107, 0.0140, 0.0104, 0.0326], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,734][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0208, 0.0611, 0.0682, 0.0918, 0.0461, 0.1416, 0.0809, 0.1465, 0.0474,
        0.1040, 0.0666, 0.0433, 0.0480, 0.0335], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,735][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0506, 0.0435, 0.0562, 0.0739, 0.0497, 0.0843, 0.1175, 0.0916, 0.0672,
        0.0507, 0.0892, 0.1084, 0.0640, 0.0532], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,737][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0366, 0.0775, 0.0684, 0.0596, 0.0672, 0.0746, 0.0836, 0.0791, 0.0794,
        0.0749, 0.0683, 0.0831, 0.0751, 0.0726], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,739][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0088, 0.0674, 0.0132, 0.0707, 0.0511, 0.1168, 0.0409, 0.1488, 0.0595,
        0.0757, 0.0906, 0.1112, 0.0620, 0.0834], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,741][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0523, 0.0661, 0.0690, 0.0701, 0.0608, 0.0708, 0.0816, 0.0809, 0.0820,
        0.0881, 0.0750, 0.0704, 0.0613, 0.0715], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,742][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([2.3556e-02, 1.8567e-03, 1.0548e-05, 4.3260e-04, 7.1995e-05, 1.3889e-03,
        5.4405e-04, 1.7758e-03, 1.0973e-03, 2.5098e-03, 1.0581e-01, 5.3066e-01,
        2.5176e-03, 3.2777e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:38,744][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.4242, 0.0436, 0.0322, 0.0351, 0.0457, 0.0508, 0.0397, 0.0277, 0.0257,
        0.0401, 0.0328, 0.0447, 0.0492, 0.0399, 0.0685], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,746][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0242, 0.0725, 0.0468, 0.0642, 0.0711, 0.0696, 0.0591, 0.0665, 0.0751,
        0.0879, 0.0598, 0.0681, 0.0671, 0.1243, 0.0439], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,748][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0027, 0.0474, 0.0231, 0.0141, 0.0995, 0.0556, 0.0455, 0.0919, 0.1220,
        0.0465, 0.0268, 0.1164, 0.1793, 0.0932, 0.0359], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,750][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0155, 0.0101, 0.0010, 0.0056, 0.0066, 0.0020, 0.1105, 0.3394, 0.0537,
        0.2902, 0.0191, 0.0632, 0.0615, 0.0058, 0.0158], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,751][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0738, 0.0704, 0.0734, 0.0752, 0.0677, 0.0755, 0.0734, 0.0692, 0.0669,
        0.0655, 0.0622, 0.0579, 0.0515, 0.0554, 0.0621], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,752][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.8685, 0.0033, 0.0019, 0.0043, 0.0050, 0.0046, 0.0075, 0.0151, 0.0179,
        0.0163, 0.0058, 0.0091, 0.0062, 0.0203, 0.0142], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,753][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0057, 0.0389, 0.0726, 0.1269, 0.0583, 0.3306, 0.0541, 0.1079, 0.0140,
        0.1063, 0.0388, 0.0119, 0.0198, 0.0064, 0.0079], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,754][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0504, 0.0362, 0.0624, 0.0518, 0.0611, 0.0736, 0.0794, 0.0861, 0.0766,
        0.0367, 0.0598, 0.0873, 0.0741, 0.0831, 0.0814], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,756][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0389, 0.0722, 0.0637, 0.0557, 0.0619, 0.0684, 0.0759, 0.0715, 0.0717,
        0.0684, 0.0624, 0.0762, 0.0679, 0.0656, 0.0797], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,757][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0090, 0.0614, 0.0163, 0.0817, 0.0410, 0.1132, 0.0483, 0.1117, 0.0958,
        0.0682, 0.1049, 0.0720, 0.0483, 0.0723, 0.0558], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,759][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0491, 0.0616, 0.0648, 0.0645, 0.0577, 0.0652, 0.0745, 0.0751, 0.0760,
        0.0806, 0.0690, 0.0654, 0.0583, 0.0661, 0.0722], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,761][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.9045e-01, 2.6676e-05, 1.1900e-06, 5.6672e-06, 8.3460e-06, 1.1250e-05,
        3.2073e-05, 5.1594e-05, 1.1669e-04, 4.7294e-05, 7.8080e-04, 2.8111e-02,
        7.7101e-04, 1.2950e-01, 6.5009e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:38,764][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:25:38,766][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[5937],
        [2738],
        [  22],
        [ 327],
        [ 851],
        [ 722],
        [ 489],
        [1035],
        [2473],
        [ 628],
        [1134],
        [1453],
        [1212],
        [ 920],
        [ 831]], device='cuda:0')
[2024-07-24 10:25:38,768][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[6116],
        [6188],
        [ 107],
        [1141],
        [1845],
        [1811],
        [ 784],
        [3618],
        [3703],
        [2624],
        [5311],
        [3403],
        [2025],
        [4788],
        [2076]], device='cuda:0')
[2024-07-24 10:25:38,770][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[1800],
        [1973],
        [2112],
        [2178],
        [2212],
        [2276],
        [2144],
        [2104],
        [2144],
        [2154],
        [2170],
        [2128],
        [2078],
        [2072],
        [1966]], device='cuda:0')
[2024-07-24 10:25:38,772][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[48685],
        [45751],
        [44948],
        [44965],
        [44738],
        [44677],
        [44667],
        [45009],
        [44899],
        [44896],
        [45032],
        [45526],
        [45496],
        [45314],
        [45000]], device='cuda:0')
[2024-07-24 10:25:38,773][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[46597],
        [16400],
        [16762],
        [16660],
        [19612],
        [25726],
        [25052],
        [17665],
        [11312],
        [14625],
        [13896],
        [ 6222],
        [38679],
        [37924],
        [ 7957]], device='cuda:0')
[2024-07-24 10:25:38,775][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[4807],
        [1129],
        [3618],
        [4608],
        [4253],
        [6226],
        [5732],
        [7103],
        [6883],
        [7512],
        [5540],
        [5620],
        [3200],
        [4468],
        [4938]], device='cuda:0')
[2024-07-24 10:25:38,776][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[41697],
        [37505],
        [34185],
        [32009],
        [30049],
        [28933],
        [28460],
        [28004],
        [28148],
        [27935],
        [27677],
        [27433],
        [27426],
        [27546],
        [27606]], device='cuda:0')
[2024-07-24 10:25:38,778][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[23731],
        [19316],
        [13808],
        [13424],
        [11517],
        [12078],
        [12743],
        [13333],
        [14245],
        [14460],
        [14317],
        [14184],
        [13538],
        [13361],
        [13619]], device='cuda:0')
[2024-07-24 10:25:38,780][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[22198],
        [22697],
        [22460],
        [22584],
        [22272],
        [22544],
        [22639],
        [22708],
        [22619],
        [22641],
        [22597],
        [22793],
        [22608],
        [22674],
        [22611]], device='cuda:0')
[2024-07-24 10:25:38,781][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[45405],
        [44634],
        [45761],
        [45301],
        [45239],
        [44954],
        [45041],
        [44632],
        [44561],
        [44445],
        [43757],
        [43982],
        [43624],
        [43199],
        [42367]], device='cuda:0')
[2024-07-24 10:25:38,783][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 8651],
        [12452],
        [12464],
        [13755],
        [14140],
        [14330],
        [13946],
        [13519],
        [12775],
        [12515],
        [12894],
        [13194],
        [13127],
        [13190],
        [13142]], device='cuda:0')
[2024-07-24 10:25:38,785][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[  886],
        [ 7472],
        [ 7432],
        [ 8069],
        [ 7415],
        [12792],
        [12514],
        [10044],
        [10961],
        [ 9985],
        [10030],
        [10392],
        [ 9077],
        [ 8604],
        [ 9214]], device='cuda:0')
[2024-07-24 10:25:38,787][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 3030],
        [ 2211],
        [ 2554],
        [ 2647],
        [ 4002],
        [ 4871],
        [ 6981],
        [ 7745],
        [ 7325],
        [ 9082],
        [ 8425],
        [ 8787],
        [13764],
        [10760],
        [ 9973]], device='cuda:0')
[2024-07-24 10:25:38,788][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[9426],
        [7136],
        [5080],
        [5220],
        [4591],
        [4826],
        [5433],
        [5810],
        [5451],
        [5694],
        [5743],
        [5819],
        [5419],
        [5581],
        [5567]], device='cuda:0')
[2024-07-24 10:25:38,790][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[22322],
        [14632],
        [ 5445],
        [21280],
        [16822],
        [ 8894],
        [11886],
        [ 2135],
        [ 1630],
        [13025],
        [ 5117],
        [ 8105],
        [ 8824],
        [ 1543],
        [ 9528]], device='cuda:0')
[2024-07-24 10:25:38,791][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[11869],
        [12037],
        [12177],
        [11834],
        [12197],
        [11964],
        [12047],
        [12010],
        [11994],
        [11993],
        [11840],
        [12000],
        [12383],
        [12294],
        [12475]], device='cuda:0')
[2024-07-24 10:25:38,793][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[35533],
        [35071],
        [35648],
        [33685],
        [36488],
        [37256],
        [37191],
        [36710],
        [36754],
        [36708],
        [36028],
        [34188],
        [34973],
        [34418],
        [34976]], device='cuda:0')
[2024-07-24 10:25:38,795][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[47896],
        [45653],
        [45517],
        [45983],
        [47537],
        [48008],
        [48029],
        [48061],
        [47861],
        [48027],
        [48030],
        [47963],
        [48005],
        [48143],
        [48130]], device='cuda:0')
[2024-07-24 10:25:38,796][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 8546],
        [ 9036],
        [10716],
        [11978],
        [12533],
        [ 9824],
        [38069],
        [35094],
        [35083],
        [35808],
        [35282],
        [35361],
        [35342],
        [35248],
        [35368]], device='cuda:0')
[2024-07-24 10:25:38,798][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[5637],
        [5853],
        [6283],
        [6471],
        [6547],
        [6539],
        [6355],
        [6289],
        [6402],
        [6208],
        [6106],
        [6102],
        [6047],
        [5976],
        [5807]], device='cuda:0')
[2024-07-24 10:25:38,800][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[12818],
        [12772],
        [12443],
        [12526],
        [12181],
        [12541],
        [12651],
        [11930],
        [11562],
        [11722],
        [11740],
        [11088],
        [10383],
        [10159],
        [10849]], device='cuda:0')
[2024-07-24 10:25:38,801][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 1268],
        [10092],
        [32368],
        [36169],
        [30913],
        [36466],
        [37065],
        [36898],
        [37100],
        [34704],
        [35373],
        [29298],
        [26186],
        [36173],
        [35509]], device='cuda:0')
[2024-07-24 10:25:38,802][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[5559],
        [4029],
        [3581],
        [3963],
        [3910],
        [3763],
        [4151],
        [4400],
        [4129],
        [3855],
        [3884],
        [4409],
        [4474],
        [4194],
        [4061]], device='cuda:0')
[2024-07-24 10:25:38,804][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[16565],
        [16967],
        [16114],
        [16082],
        [15709],
        [15445],
        [15327],
        [15461],
        [15702],
        [15712],
        [15809],
        [15922],
        [15966],
        [15962],
        [16018]], device='cuda:0')
[2024-07-24 10:25:38,805][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[43239],
        [25235],
        [24303],
        [23028],
        [23560],
        [21636],
        [20797],
        [21292],
        [22863],
        [22710],
        [21752],
        [21923],
        [22988],
        [23703],
        [23493]], device='cuda:0')
[2024-07-24 10:25:38,807][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[4038],
        [4537],
        [7010],
        [7626],
        [8710],
        [8126],
        [8025],
        [8233],
        [8158],
        [7958],
        [7752],
        [7841],
        [8088],
        [8252],
        [8368]], device='cuda:0')
[2024-07-24 10:25:38,809][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[1675],
        [1652],
        [1566],
        [1445],
        [1408],
        [1553],
        [1293],
        [2171],
        [1921],
        [1473],
        [ 843],
        [1391],
        [3025],
        [3003],
        [7384]], device='cuda:0')
[2024-07-24 10:25:38,810][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[27250],
        [23530],
        [20999],
        [18652],
        [18386],
        [19016],
        [15778],
        [14821],
        [14414],
        [16832],
        [15834],
        [16350],
        [14889],
        [13674],
        [11369]], device='cuda:0')
[2024-07-24 10:25:38,812][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[17799],
        [36856],
        [41334],
        [30616],
        [37817],
        [39118],
        [39199],
        [44123],
        [46523],
        [29366],
        [40775],
        [41996],
        [40242],
        [45369],
        [41156]], device='cuda:0')
[2024-07-24 10:25:38,814][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[4920],
        [4920],
        [4920],
        [4920],
        [4920],
        [4920],
        [4920],
        [4920],
        [4920],
        [4920],
        [4920],
        [4920],
        [4920],
        [4920],
        [4920]], device='cuda:0')
[2024-07-24 10:25:38,867][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:38,868][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,870][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,871][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,872][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,873][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,875][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,876][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,877][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,879][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,880][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,881][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,883][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:38,884][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.6945, 0.3055], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,886][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.6955, 0.3045], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,888][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.5588, 0.4412], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,889][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4265, 0.5735], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,889][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9634, 0.0366], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,890][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1856, 0.8144], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,891][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4618, 0.5382], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,891][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2834, 0.7166], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,893][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.5518, 0.4482], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,894][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3868, 0.6132], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,896][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.3649, 0.6351], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,897][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([8.7961e-11, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:38,899][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Jose] are: tensor([0.0840, 0.6488, 0.2672], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,900][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Jose] are: tensor([0.3768, 0.3460, 0.2772], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,902][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Jose] are: tensor([0.3545, 0.2761, 0.3694], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,903][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Jose] are: tensor([0.2804, 0.3637, 0.3560], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,905][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Jose] are: tensor([0.9384, 0.0275, 0.0341], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,906][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Jose] are: tensor([0.0926, 0.4039, 0.5035], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,908][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Jose] are: tensor([0.3036, 0.3550, 0.3414], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,910][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Jose] are: tensor([0.0754, 0.6075, 0.3171], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,911][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Jose] are: tensor([0.3769, 0.3058, 0.3173], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,913][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Jose] are: tensor([0.2331, 0.3763, 0.3906], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,914][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Jose] are: tensor([0.2149, 0.3762, 0.4089], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,916][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Jose] are: tensor([1.7532e-11, 8.4409e-01, 1.5591e-01], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:38,917][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2828, 0.3039, 0.3097, 0.1035], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,919][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1668, 0.4051, 0.2438, 0.1844], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,920][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2333, 0.2702, 0.2831, 0.2134], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,922][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2015, 0.2647, 0.2624, 0.2715], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,923][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.9059, 0.0268, 0.0341, 0.0332], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,925][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0543, 0.3105, 0.3860, 0.2492], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,927][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2318, 0.2721, 0.2609, 0.2353], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,928][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1234, 0.4308, 0.1858, 0.2600], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,930][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2810, 0.2280, 0.2356, 0.2554], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,932][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1633, 0.2734, 0.2859, 0.2773], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,933][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1561, 0.2678, 0.2913, 0.2848], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,934][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([2.4354e-12, 8.3458e-01, 1.5928e-01, 6.1421e-03], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:38,935][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Stephanie] are: tensor([0.0536, 0.3821, 0.2036, 0.1769, 0.1839], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,935][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Stephanie] are: tensor([0.1546, 0.4226, 0.1545, 0.2292, 0.0391], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,936][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Stephanie] are: tensor([0.2443, 0.1752, 0.1991, 0.1526, 0.2288], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,937][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Stephanie] are: tensor([0.1587, 0.2080, 0.2035, 0.2113, 0.2186], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,939][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Stephanie] are: tensor([0.8775, 0.0257, 0.0333, 0.0317, 0.0318], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,940][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Stephanie] are: tensor([0.0439, 0.2235, 0.2615, 0.1869, 0.2841], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,942][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Stephanie] are: tensor([0.1857, 0.2172, 0.2070, 0.1870, 0.2031], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,943][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Stephanie] are: tensor([0.0401, 0.3584, 0.2306, 0.1799, 0.1911], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,945][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Stephanie] are: tensor([0.2281, 0.1824, 0.1897, 0.2048, 0.1950], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,947][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Stephanie] are: tensor([0.1312, 0.2095, 0.2144, 0.2111, 0.2338], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,948][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Stephanie] are: tensor([0.1216, 0.2065, 0.2241, 0.2203, 0.2275], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,949][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Stephanie] are: tensor([2.8351e-11, 3.4692e-01, 1.9941e-01, 1.3930e-02, 4.3974e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:38,951][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0395, 0.2876, 0.1872, 0.1589, 0.2078, 0.1191], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,952][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.1837, 0.1645, 0.0952, 0.3755, 0.0546, 0.1265], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,954][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.1338, 0.1713, 0.1678, 0.1207, 0.1794, 0.2270], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,955][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1266, 0.1705, 0.1687, 0.1749, 0.1813, 0.1778], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,957][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.9178, 0.0164, 0.0197, 0.0197, 0.0185, 0.0080], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,959][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0438, 0.1746, 0.2123, 0.1454, 0.2372, 0.1866], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,960][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.1534, 0.1817, 0.1740, 0.1583, 0.1719, 0.1607], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,962][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0397, 0.2797, 0.1441, 0.1695, 0.1491, 0.2179], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,963][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1859, 0.1510, 0.1560, 0.1688, 0.1602, 0.1781], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,965][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.1065, 0.1702, 0.1766, 0.1714, 0.1922, 0.1831], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,967][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.1021, 0.1675, 0.1819, 0.1777, 0.1841, 0.1866], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,968][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ had] are: tensor([9.4541e-12, 1.0816e-02, 3.7066e-03, 1.0335e-04, 1.1115e-02, 9.7426e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:38,970][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1125, 0.2195, 0.1262, 0.0711, 0.2014, 0.1783, 0.0909],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,971][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.2191, 0.2297, 0.1226, 0.1204, 0.0752, 0.1952, 0.0378],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,973][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0999, 0.1218, 0.1052, 0.1005, 0.1649, 0.2003, 0.2074],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,974][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1057, 0.1461, 0.1438, 0.1502, 0.1549, 0.1519, 0.1475],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,976][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.8583, 0.0242, 0.0291, 0.0300, 0.0283, 0.0124, 0.0177],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,978][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0303, 0.1614, 0.1716, 0.1299, 0.2110, 0.1690, 0.1267],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,979][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1319, 0.1556, 0.1492, 0.1354, 0.1470, 0.1378, 0.1431],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,980][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0565, 0.2402, 0.1144, 0.1148, 0.1461, 0.1521, 0.1760],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,981][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1615, 0.1307, 0.1333, 0.1430, 0.1372, 0.1509, 0.1434],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,982][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0895, 0.1447, 0.1479, 0.1428, 0.1618, 0.1527, 0.1606],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,982][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0854, 0.1429, 0.1547, 0.1519, 0.1567, 0.1591, 0.1494],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,984][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([8.2270e-12, 1.1559e-02, 3.3353e-03, 1.2681e-04, 2.1509e-02, 9.5325e-01,
        1.0219e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:38,985][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0748, 0.1551, 0.1356, 0.0865, 0.0778, 0.0888, 0.1133, 0.2682],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,987][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0527, 0.3051, 0.0235, 0.2297, 0.0319, 0.0872, 0.1283, 0.1417],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,988][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.1059, 0.1127, 0.0923, 0.0832, 0.1473, 0.1665, 0.1893, 0.1027],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,990][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0938, 0.1266, 0.1250, 0.1303, 0.1343, 0.1323, 0.1284, 0.1293],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,991][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.8722, 0.0203, 0.0246, 0.0252, 0.0234, 0.0100, 0.0147, 0.0096],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,993][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0228, 0.1535, 0.1508, 0.1165, 0.1867, 0.1525, 0.1155, 0.1017],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,995][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.1166, 0.1370, 0.1304, 0.1182, 0.1285, 0.1207, 0.1261, 0.1224],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,996][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0364, 0.2504, 0.0752, 0.1203, 0.1052, 0.1809, 0.1406, 0.0910],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:38,998][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.1413, 0.1150, 0.1175, 0.1261, 0.1208, 0.1326, 0.1276, 0.1191],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,000][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0770, 0.1257, 0.1291, 0.1239, 0.1418, 0.1326, 0.1396, 0.1303],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,001][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0722, 0.1245, 0.1351, 0.1332, 0.1371, 0.1393, 0.1310, 0.1275],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,003][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ long] are: tensor([1.5242e-12, 1.2747e-02, 2.3968e-03, 6.8922e-05, 1.5078e-02, 8.9097e-01,
        7.6177e-03, 7.1122e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,004][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0335, 0.1170, 0.0555, 0.0432, 0.0686, 0.0961, 0.0758, 0.4075, 0.1028],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,006][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0191, 0.0643, 0.0754, 0.1468, 0.0245, 0.1077, 0.0962, 0.4105, 0.0555],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,008][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0679, 0.1021, 0.0767, 0.0795, 0.1385, 0.1387, 0.2034, 0.1104, 0.0828],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,009][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0843, 0.1128, 0.1103, 0.1148, 0.1189, 0.1165, 0.1131, 0.1136, 0.1156],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,011][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.7876, 0.0296, 0.0353, 0.0353, 0.0340, 0.0150, 0.0217, 0.0145, 0.0269],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,013][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0189, 0.1438, 0.1463, 0.1099, 0.1720, 0.1405, 0.1001, 0.0942, 0.0744],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,014][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.1043, 0.1218, 0.1166, 0.1059, 0.1150, 0.1075, 0.1122, 0.1095, 0.1071],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,016][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0527, 0.2000, 0.0834, 0.0913, 0.0991, 0.1345, 0.0850, 0.0693, 0.1848],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,018][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.1261, 0.1033, 0.1062, 0.1126, 0.1087, 0.1188, 0.1127, 0.1055, 0.1062],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,020][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0697, 0.1109, 0.1138, 0.1089, 0.1253, 0.1167, 0.1232, 0.1159, 0.1156],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,021][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0667, 0.1100, 0.1192, 0.1172, 0.1208, 0.1226, 0.1150, 0.1123, 0.1163],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,022][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([2.5251e-11, 8.3922e-03, 3.6748e-03, 1.8059e-04, 2.0574e-02, 8.8211e-01,
        1.0435e-02, 6.8366e-02, 6.2650e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,024][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0880, 0.0579, 0.0735, 0.0239, 0.1031, 0.0601, 0.0769, 0.3392, 0.1322,
        0.0453], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,025][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0494, 0.0176, 0.0320, 0.0234, 0.0670, 0.0909, 0.0485, 0.1747, 0.4819,
        0.0146], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,026][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0528, 0.0726, 0.0690, 0.0629, 0.1270, 0.1666, 0.2081, 0.1107, 0.0836,
        0.0466], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,027][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0756, 0.1005, 0.0993, 0.1030, 0.1063, 0.1046, 0.1011, 0.1021, 0.1038,
        0.1038], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,027][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.7908, 0.0262, 0.0323, 0.0323, 0.0307, 0.0137, 0.0193, 0.0128, 0.0237,
        0.0183], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,029][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0150, 0.1164, 0.1416, 0.1010, 0.1684, 0.1306, 0.0966, 0.0936, 0.0772,
        0.0596], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,031][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0943, 0.1104, 0.1058, 0.0956, 0.1040, 0.0973, 0.1016, 0.0990, 0.0970,
        0.0950], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,033][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0459, 0.1695, 0.0783, 0.1080, 0.0935, 0.0801, 0.0922, 0.0575, 0.1306,
        0.1445], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,034][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1137, 0.0921, 0.0945, 0.1008, 0.0973, 0.1067, 0.1019, 0.0950, 0.0953,
        0.1025], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,036][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0621, 0.0985, 0.1019, 0.0976, 0.1118, 0.1047, 0.1117, 0.1055, 0.1055,
        0.1006], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,038][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0571, 0.0992, 0.1078, 0.1059, 0.1094, 0.1110, 0.1042, 0.1011, 0.1048,
        0.0995], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,039][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([5.0123e-12, 9.9937e-03, 1.7088e-03, 4.1560e-05, 9.5125e-03, 8.2611e-01,
        1.2418e-02, 1.1003e-01, 1.1937e-02, 1.8241e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,041][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0505, 0.0721, 0.0609, 0.0205, 0.0866, 0.0659, 0.0837, 0.3351, 0.1384,
        0.0632, 0.0231], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,042][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0137, 0.0622, 0.0344, 0.0233, 0.0856, 0.0544, 0.0829, 0.1296, 0.4060,
        0.0892, 0.0187], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,044][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0622, 0.0719, 0.0710, 0.0602, 0.1134, 0.1494, 0.1749, 0.0960, 0.0811,
        0.0467, 0.0732], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,046][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0686, 0.0901, 0.0892, 0.0926, 0.0954, 0.0944, 0.0918, 0.0925, 0.0936,
        0.0943, 0.0975], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,047][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.7539, 0.0274, 0.0326, 0.0341, 0.0319, 0.0145, 0.0203, 0.0136, 0.0244,
        0.0194, 0.0279], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,049][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0145, 0.1069, 0.1331, 0.0868, 0.1582, 0.1238, 0.0928, 0.0888, 0.0724,
        0.0591, 0.0635], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,051][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0860, 0.1011, 0.0965, 0.0872, 0.0952, 0.0891, 0.0934, 0.0904, 0.0890,
        0.0871, 0.0851], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,053][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0424, 0.1507, 0.0751, 0.0892, 0.0868, 0.0680, 0.0928, 0.0644, 0.1120,
        0.1235, 0.0950], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,054][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1030, 0.0838, 0.0857, 0.0918, 0.0882, 0.0966, 0.0929, 0.0866, 0.0869,
        0.0934, 0.0910], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,056][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0553, 0.0892, 0.0933, 0.0892, 0.1021, 0.0961, 0.1019, 0.0954, 0.0950,
        0.0912, 0.0914], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,058][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0515, 0.0903, 0.0987, 0.0971, 0.0998, 0.1012, 0.0953, 0.0926, 0.0952,
        0.0909, 0.0875], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,059][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([3.2513e-11, 9.7905e-03, 2.6802e-03, 1.0613e-04, 1.2355e-02, 8.4880e-01,
        1.0960e-02, 8.3689e-02, 8.2187e-03, 1.9553e-02, 3.8518e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,061][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0199, 0.1282, 0.0413, 0.0509, 0.0386, 0.0874, 0.0771, 0.2222, 0.0743,
        0.1105, 0.0555, 0.0941], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,063][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0350, 0.0716, 0.0491, 0.1098, 0.0327, 0.1202, 0.0935, 0.2728, 0.0698,
        0.0615, 0.0595, 0.0244], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,064][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0770, 0.0889, 0.0769, 0.0700, 0.1333, 0.1057, 0.1390, 0.0730, 0.0581,
        0.0347, 0.0530, 0.0905], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,066][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0609, 0.0822, 0.0810, 0.0843, 0.0870, 0.0853, 0.0835, 0.0843, 0.0856,
        0.0857, 0.0887, 0.0915], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,068][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.6124, 0.0377, 0.0436, 0.0453, 0.0438, 0.0210, 0.0290, 0.0208, 0.0337,
        0.0266, 0.0357, 0.0503], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,069][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0161, 0.1178, 0.1150, 0.0894, 0.1345, 0.1096, 0.0809, 0.0766, 0.0636,
        0.0566, 0.0637, 0.0762], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,070][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0796, 0.0928, 0.0884, 0.0798, 0.0868, 0.0815, 0.0858, 0.0831, 0.0817,
        0.0800, 0.0783, 0.0823], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,071][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0236, 0.1588, 0.0630, 0.0891, 0.0565, 0.1150, 0.0845, 0.0430, 0.0796,
        0.1228, 0.0871, 0.0769], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,072][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0954, 0.0773, 0.0785, 0.0840, 0.0801, 0.0879, 0.0844, 0.0797, 0.0795,
        0.0849, 0.0833, 0.0850], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,073][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0517, 0.0828, 0.0845, 0.0824, 0.0924, 0.0882, 0.0931, 0.0871, 0.0858,
        0.0832, 0.0840, 0.0849], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,074][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0487, 0.0829, 0.0901, 0.0887, 0.0915, 0.0929, 0.0868, 0.0848, 0.0876,
        0.0831, 0.0796, 0.0833], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,076][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([5.1114e-09, 6.7188e-03, 7.4875e-03, 5.4231e-04, 2.0255e-02, 8.2145e-01,
        2.1925e-02, 7.4013e-02, 1.5585e-02, 1.6177e-02, 7.4984e-03, 8.3469e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,077][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Stephanie] are: tensor([0.0148, 0.0969, 0.0481, 0.0418, 0.0423, 0.0553, 0.0632, 0.2637, 0.0751,
        0.0720, 0.0430, 0.1217, 0.0619], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,079][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Stephanie] are: tensor([0.0513, 0.1454, 0.0360, 0.0797, 0.0075, 0.1176, 0.0886, 0.2552, 0.0359,
        0.0929, 0.0441, 0.0404, 0.0053], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,081][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Stephanie] are: tensor([0.0759, 0.0558, 0.0656, 0.0556, 0.1057, 0.1041, 0.1246, 0.0750, 0.0741,
        0.0326, 0.0537, 0.0921, 0.0852], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,082][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Stephanie] are: tensor([0.0591, 0.0750, 0.0734, 0.0766, 0.0787, 0.0783, 0.0765, 0.0767, 0.0785,
        0.0784, 0.0809, 0.0837, 0.0842], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,084][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Stephanie] are: tensor([0.6152, 0.0331, 0.0396, 0.0405, 0.0398, 0.0182, 0.0252, 0.0177, 0.0299,
        0.0231, 0.0314, 0.0435, 0.0428], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,086][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Stephanie] are: tensor([0.0142, 0.0940, 0.1058, 0.0809, 0.1098, 0.1002, 0.0793, 0.0703, 0.0583,
        0.0499, 0.0581, 0.0841, 0.0950], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,088][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Stephanie] are: tensor([0.0741, 0.0866, 0.0819, 0.0733, 0.0800, 0.0753, 0.0796, 0.0768, 0.0756,
        0.0741, 0.0720, 0.0761, 0.0746], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,089][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Stephanie] are: tensor([0.0170, 0.1291, 0.0872, 0.0643, 0.0747, 0.1037, 0.0911, 0.0422, 0.0955,
        0.0710, 0.0583, 0.0904, 0.0757], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,091][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Stephanie] are: tensor([0.0917, 0.0717, 0.0734, 0.0788, 0.0750, 0.0822, 0.0783, 0.0732, 0.0733,
        0.0790, 0.0774, 0.0779, 0.0679], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,093][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Stephanie] are: tensor([0.0492, 0.0762, 0.0771, 0.0754, 0.0842, 0.0808, 0.0851, 0.0794, 0.0777,
        0.0768, 0.0777, 0.0777, 0.0825], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,095][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Stephanie] are: tensor([0.0434, 0.0769, 0.0839, 0.0823, 0.0850, 0.0864, 0.0807, 0.0785, 0.0813,
        0.0770, 0.0737, 0.0769, 0.0739], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,096][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Stephanie] are: tensor([7.5621e-09, 5.5661e-03, 7.5547e-03, 8.1426e-04, 1.3938e-02, 7.7477e-01,
        1.6031e-02, 6.6923e-02, 9.5471e-03, 1.7203e-02, 9.2300e-03, 4.2533e-03,
        7.4172e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,098][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0125, 0.0594, 0.0469, 0.0236, 0.0624, 0.0414, 0.0512, 0.2936, 0.0586,
        0.0477, 0.0256, 0.1080, 0.0996, 0.0694], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,099][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0390, 0.0296, 0.0349, 0.0470, 0.0099, 0.1015, 0.0239, 0.4419, 0.0617,
        0.0797, 0.0541, 0.0470, 0.0103, 0.0196], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,101][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0679, 0.0555, 0.0661, 0.0499, 0.0957, 0.0876, 0.1291, 0.0690, 0.0630,
        0.0315, 0.0472, 0.0796, 0.0809, 0.0770], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,103][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0516, 0.0691, 0.0684, 0.0711, 0.0734, 0.0718, 0.0702, 0.0706, 0.0715,
        0.0719, 0.0744, 0.0769, 0.0781, 0.0810], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,105][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.4984, 0.0389, 0.0456, 0.0465, 0.0460, 0.0227, 0.0294, 0.0211, 0.0347,
        0.0269, 0.0349, 0.0473, 0.0469, 0.0608], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,106][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0145, 0.0911, 0.1029, 0.0763, 0.1112, 0.0923, 0.0683, 0.0680, 0.0542,
        0.0450, 0.0517, 0.0699, 0.0856, 0.0690], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,108][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0686, 0.0799, 0.0762, 0.0686, 0.0750, 0.0703, 0.0736, 0.0714, 0.0703,
        0.0687, 0.0671, 0.0712, 0.0703, 0.0689], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,110][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0259, 0.1021, 0.0540, 0.0478, 0.0767, 0.0992, 0.0689, 0.0303, 0.0881,
        0.0813, 0.0473, 0.0822, 0.0795, 0.1167], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,112][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0840, 0.0669, 0.0682, 0.0730, 0.0698, 0.0768, 0.0729, 0.0685, 0.0688,
        0.0732, 0.0720, 0.0734, 0.0639, 0.0686], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,113][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0441, 0.0704, 0.0725, 0.0698, 0.0790, 0.0750, 0.0790, 0.0737, 0.0723,
        0.0704, 0.0711, 0.0717, 0.0767, 0.0744], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,114][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0418, 0.0714, 0.0777, 0.0761, 0.0788, 0.0800, 0.0747, 0.0728, 0.0753,
        0.0713, 0.0685, 0.0713, 0.0687, 0.0716], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,115][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ said] are: tensor([5.5257e-08, 1.2243e-02, 1.0471e-02, 9.3194e-04, 3.8211e-02, 6.2170e-01,
        2.0276e-02, 6.6516e-02, 1.7249e-02, 1.8204e-02, 8.9511e-03, 1.1084e-02,
        1.7023e-01, 3.9283e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,116][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0388, 0.0351, 0.0386, 0.0129, 0.0481, 0.0343, 0.0477, 0.2466, 0.1062,
        0.0290, 0.0163, 0.0986, 0.0863, 0.1443, 0.0175], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,117][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0251, 0.0172, 0.0228, 0.0160, 0.0249, 0.0151, 0.0313, 0.1223, 0.5210,
        0.0264, 0.0154, 0.0388, 0.0488, 0.0688, 0.0059], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,119][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0354, 0.0435, 0.0476, 0.0456, 0.0762, 0.1047, 0.1519, 0.0888, 0.0649,
        0.0316, 0.0458, 0.0929, 0.0631, 0.0642, 0.0440], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,120][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0487, 0.0638, 0.0625, 0.0652, 0.0669, 0.0663, 0.0647, 0.0653, 0.0668,
        0.0666, 0.0690, 0.0714, 0.0719, 0.0760, 0.0751], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,122][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.5846, 0.0286, 0.0337, 0.0347, 0.0336, 0.0155, 0.0215, 0.0147, 0.0257,
        0.0198, 0.0273, 0.0379, 0.0374, 0.0487, 0.0362], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,124][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0192, 0.0666, 0.1007, 0.0686, 0.1095, 0.0920, 0.0659, 0.0594, 0.0502,
        0.0380, 0.0427, 0.0655, 0.0829, 0.0780, 0.0608], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,126][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0624, 0.0741, 0.0707, 0.0640, 0.0696, 0.0650, 0.0675, 0.0661, 0.0652,
        0.0637, 0.0628, 0.0665, 0.0664, 0.0646, 0.0715], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,127][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0330, 0.1113, 0.0503, 0.0594, 0.0581, 0.0558, 0.0497, 0.0434, 0.0873,
        0.0672, 0.0573, 0.0871, 0.0642, 0.0758, 0.1000], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,129][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0776, 0.0623, 0.0638, 0.0680, 0.0657, 0.0715, 0.0684, 0.0640, 0.0641,
        0.0689, 0.0672, 0.0683, 0.0597, 0.0639, 0.0666], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,131][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0426, 0.0648, 0.0662, 0.0640, 0.0716, 0.0688, 0.0729, 0.0687, 0.0683,
        0.0663, 0.0657, 0.0664, 0.0709, 0.0692, 0.0735], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,133][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0414, 0.0665, 0.0716, 0.0708, 0.0727, 0.0739, 0.0693, 0.0677, 0.0698,
        0.0664, 0.0640, 0.0663, 0.0640, 0.0664, 0.0694], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,134][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.1862e-07, 7.8665e-04, 8.2436e-04, 5.9895e-05, 1.7093e-03, 4.3767e-02,
        1.8376e-03, 4.9454e-03, 1.6885e-03, 9.9597e-04, 6.8450e-04, 1.2519e-03,
        2.2477e-02, 1.1943e-03, 9.1778e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,191][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:39,192][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,194][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,195][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,196][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,197][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,199][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,200][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,201][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,202][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,202][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,203][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,204][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,205][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4995, 0.5005], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,206][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1235, 0.8765], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,208][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6932, 0.3068], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,209][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.8128, 0.1872], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,211][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5648, 0.4352], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,213][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2036, 0.7964], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,214][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.5124, 0.4876], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,216][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.8541, 0.1459], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,217][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.7654, 0.2346], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,219][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.8825, 0.1175], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,220][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9718, 0.0282], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,222][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9731, 0.0269], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,224][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Jose] are: tensor([0.0480, 0.6844, 0.2677], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,225][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Jose] are: tensor([0.0969, 0.4680, 0.4351], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,227][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Jose] are: tensor([0.5888, 0.2086, 0.2026], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,228][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Jose] are: tensor([0.4851, 0.2284, 0.2865], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,230][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Jose] are: tensor([0.5603, 0.2585, 0.1812], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,232][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Jose] are: tensor([0.1517, 0.8209, 0.0275], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,233][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Jose] are: tensor([0.3602, 0.3320, 0.3079], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,235][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Jose] are: tensor([0.6866, 0.1680, 0.1453], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,236][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Jose] are: tensor([0.6547, 0.2364, 0.1089], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,238][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Jose] are: tensor([0.7756, 0.1036, 0.1207], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,240][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Jose] are: tensor([0.9564, 0.0266, 0.0171], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,241][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Jose] are: tensor([9.5364e-02, 9.0464e-01, 1.7645e-09], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,242][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2095, 0.3257, 0.3392, 0.1255], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,244][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0462, 0.3205, 0.3074, 0.3259], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,246][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4041, 0.2833, 0.1644, 0.1482], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,246][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2814, 0.0484, 0.5926, 0.0776], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,247][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2999, 0.2075, 0.0672, 0.4254], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,248][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0370, 0.8702, 0.0338, 0.0589], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,249][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2671, 0.2545, 0.2347, 0.2437], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,249][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.6527, 0.1293, 0.1078, 0.1103], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,251][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.6622, 0.1806, 0.0827, 0.0745], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,253][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.5447, 0.0358, 0.0452, 0.3743], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,254][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9000, 0.0373, 0.0103, 0.0524], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,255][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([7.7905e-02, 9.2208e-01, 1.1055e-05, 9.0603e-06], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,257][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Stephanie] are: tensor([0.0291, 0.3039, 0.2018, 0.2205, 0.2447], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,258][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Stephanie] are: tensor([0.0544, 0.2529, 0.2275, 0.2561, 0.2091], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,260][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Stephanie] are: tensor([0.6334, 0.1112, 0.1036, 0.0548, 0.0970], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,261][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Stephanie] are: tensor([0.1253, 0.1805, 0.1727, 0.4572, 0.0644], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,263][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Stephanie] are: tensor([0.2250, 0.0784, 0.0972, 0.0981, 0.5014], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,264][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Stephanie] are: tensor([0.1237, 0.7219, 0.0183, 0.1035, 0.0326], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,266][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Stephanie] are: tensor([0.2158, 0.2042, 0.1885, 0.1961, 0.1954], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,268][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Stephanie] are: tensor([0.5219, 0.1161, 0.1066, 0.1020, 0.1533], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,270][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Stephanie] are: tensor([0.5986, 0.1698, 0.0950, 0.0651, 0.0715], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,271][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Stephanie] are: tensor([0.2828, 0.0392, 0.0494, 0.4149, 0.2138], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,273][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Stephanie] are: tensor([0.7367, 0.1054, 0.0077, 0.1082, 0.0420], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,274][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Stephanie] are: tensor([8.9352e-04, 9.9909e-01, 8.9298e-09, 1.5152e-05, 1.9257e-07],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,276][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0215, 0.2373, 0.1606, 0.1877, 0.2777, 0.1152], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,277][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0416, 0.1975, 0.1794, 0.2103, 0.1746, 0.1965], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,279][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.3865, 0.1999, 0.0864, 0.1050, 0.1548, 0.0674], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,281][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0360, 0.0372, 0.4017, 0.1334, 0.3858, 0.0059], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,282][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0346, 0.0264, 0.0178, 0.0248, 0.0223, 0.8742], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,284][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.1728, 0.5015, 0.0118, 0.0332, 0.0359, 0.2448], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,286][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.1809, 0.1691, 0.1552, 0.1621, 0.1624, 0.1703], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,287][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.5815, 0.0955, 0.0781, 0.0733, 0.0996, 0.0719], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,289][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.5985, 0.1329, 0.0678, 0.0545, 0.0556, 0.0906], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,290][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.3469, 0.0220, 0.0249, 0.1970, 0.1594, 0.2498], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,292][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.8345, 0.0332, 0.0131, 0.0354, 0.0116, 0.0722], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,293][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([9.3385e-01, 3.8198e-02, 5.3643e-08, 2.5700e-07, 1.2856e-05, 2.7942e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,293][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0937, 0.1833, 0.1127, 0.0781, 0.2604, 0.1850, 0.0868],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,294][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0297, 0.1637, 0.1537, 0.1654, 0.1482, 0.1723, 0.1670],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,295][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.3429, 0.1458, 0.1381, 0.0947, 0.1053, 0.0872, 0.0861],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,297][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1253, 0.0446, 0.1838, 0.2895, 0.3143, 0.0218, 0.0207],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,298][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0627, 0.0479, 0.0310, 0.0681, 0.0721, 0.4583, 0.2599],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,300][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0323, 0.6302, 0.0031, 0.0232, 0.0321, 0.1981, 0.0810],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,302][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1528, 0.1462, 0.1341, 0.1395, 0.1402, 0.1477, 0.1395],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,303][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.5993, 0.0744, 0.0657, 0.0596, 0.0873, 0.0580, 0.0558],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,305][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.5050, 0.1357, 0.0727, 0.0672, 0.0556, 0.1007, 0.0630],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,307][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1381, 0.0072, 0.0084, 0.0859, 0.0638, 0.1225, 0.5742],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,308][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.8323, 0.0286, 0.0129, 0.0303, 0.0185, 0.0357, 0.0418],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,309][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([2.5178e-02, 7.9598e-01, 2.5410e-10, 3.0652e-07, 2.2006e-07, 1.7884e-01,
        1.4135e-07], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,311][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0494, 0.1327, 0.1221, 0.1149, 0.1032, 0.1043, 0.1314, 0.2422],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,313][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0291, 0.1405, 0.1184, 0.1437, 0.1202, 0.1395, 0.1481, 0.1606],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,314][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.5098, 0.0975, 0.0572, 0.0788, 0.0609, 0.0925, 0.0682, 0.0350],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,316][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.1267, 0.0345, 0.1326, 0.1433, 0.0866, 0.0240, 0.1197, 0.3325],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,318][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0657, 0.0313, 0.0265, 0.0408, 0.0328, 0.4073, 0.0603, 0.3354],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,319][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0253, 0.4973, 0.0016, 0.0232, 0.0188, 0.2157, 0.1669, 0.0512],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,321][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.1353, 0.1294, 0.1185, 0.1228, 0.1229, 0.1298, 0.1228, 0.1185],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,322][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.4923, 0.0800, 0.0711, 0.0698, 0.0966, 0.0642, 0.0626, 0.0635],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,324][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.4689, 0.1251, 0.0603, 0.0679, 0.0464, 0.1021, 0.0720, 0.0574],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,326][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0892, 0.0066, 0.0102, 0.0640, 0.0588, 0.0638, 0.3866, 0.3208],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,328][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.8205, 0.0313, 0.0203, 0.0217, 0.0318, 0.0364, 0.0300, 0.0081],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,329][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([5.1171e-03, 8.5966e-01, 1.5314e-10, 4.8535e-07, 1.2473e-07, 1.3521e-01,
        1.0024e-05, 3.4416e-08], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,331][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0197, 0.0933, 0.0480, 0.0586, 0.0818, 0.1139, 0.0817, 0.4169, 0.0861],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,332][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0238, 0.1167, 0.1062, 0.1214, 0.1010, 0.1217, 0.1286, 0.1406, 0.1400],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,334][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.4054, 0.1229, 0.0727, 0.0691, 0.0819, 0.0825, 0.0706, 0.0610, 0.0339],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,336][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0548, 0.0291, 0.0903, 0.0829, 0.1518, 0.0227, 0.1131, 0.3452, 0.1101],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,337][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0961, 0.0306, 0.0390, 0.0381, 0.0795, 0.4102, 0.1330, 0.0708, 0.1027],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,338][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0203, 0.5423, 0.0021, 0.0256, 0.0119, 0.1604, 0.1053, 0.0835, 0.0487],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,339][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.1211, 0.1158, 0.1057, 0.1095, 0.1098, 0.1157, 0.1093, 0.1062, 0.1068],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,339][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.5643, 0.0663, 0.0546, 0.0508, 0.0736, 0.0487, 0.0439, 0.0452, 0.0526],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,341][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.4238, 0.1332, 0.0671, 0.0558, 0.0545, 0.0927, 0.0551, 0.0499, 0.0681],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,342][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.2930, 0.0032, 0.0036, 0.0261, 0.0196, 0.0434, 0.2450, 0.2276, 0.1384],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,344][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.6292, 0.0437, 0.0201, 0.0506, 0.0438, 0.0254, 0.0960, 0.0126, 0.0785],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,345][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([6.6186e-02, 9.2695e-01, 3.8513e-11, 2.3651e-07, 1.9794e-07, 6.8630e-03,
        1.4139e-06, 6.7826e-07, 6.7995e-09], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,347][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0799, 0.0488, 0.0730, 0.0272, 0.1363, 0.0627, 0.0775, 0.3380, 0.1099,
        0.0466], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,348][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0155, 0.0995, 0.0940, 0.1020, 0.0962, 0.1117, 0.1110, 0.1225, 0.1319,
        0.1158], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,350][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2294, 0.1343, 0.0989, 0.0830, 0.0852, 0.0656, 0.0766, 0.0519, 0.0627,
        0.1125], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,352][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0185, 0.0019, 0.1788, 0.0125, 0.1352, 0.0041, 0.0401, 0.1956, 0.4128,
        0.0005], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,353][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0598, 0.0510, 0.0195, 0.0956, 0.0411, 0.4229, 0.0686, 0.1284, 0.0491,
        0.0639], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,355][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0611, 0.2355, 0.0045, 0.0274, 0.0173, 0.1510, 0.1312, 0.1192, 0.1030,
        0.1498], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,357][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1092, 0.1046, 0.0955, 0.0991, 0.0994, 0.1048, 0.0991, 0.0959, 0.0973,
        0.0950], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,358][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4946, 0.0607, 0.0559, 0.0535, 0.0830, 0.0509, 0.0504, 0.0502, 0.0537,
        0.0471], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,360][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4384, 0.1193, 0.0585, 0.0550, 0.0494, 0.0727, 0.0501, 0.0470, 0.0592,
        0.0504], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,362][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0500, 0.0024, 0.0037, 0.0294, 0.0226, 0.0458, 0.2294, 0.2096, 0.3159,
        0.0912], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,364][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.6452, 0.0334, 0.0220, 0.0270, 0.0305, 0.0377, 0.0353, 0.0150, 0.0493,
        0.1047], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,365][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([9.8241e-01, 7.4034e-03, 8.2433e-09, 5.4105e-09, 2.6853e-06, 8.5582e-03,
        1.6257e-06, 3.1498e-06, 1.4345e-05, 1.6105e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,367][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0462, 0.0591, 0.0622, 0.0214, 0.1183, 0.0645, 0.0838, 0.3472, 0.1196,
        0.0585, 0.0192], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,368][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0130, 0.0903, 0.0848, 0.0904, 0.0883, 0.0962, 0.1033, 0.1101, 0.1169,
        0.1094, 0.0973], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,370][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1964, 0.1384, 0.0740, 0.0687, 0.0625, 0.0509, 0.0728, 0.0658, 0.0593,
        0.1360, 0.0753], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,372][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0430, 0.0044, 0.1062, 0.0082, 0.1407, 0.0070, 0.0262, 0.2866, 0.3695,
        0.0020, 0.0063], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,373][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0496, 0.0503, 0.0184, 0.1053, 0.0357, 0.3086, 0.0795, 0.1299, 0.0424,
        0.0660, 0.1144], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,375][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1205, 0.1590, 0.0037, 0.0060, 0.0130, 0.1103, 0.0844, 0.0581, 0.0445,
        0.1334, 0.2670], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,377][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0995, 0.0947, 0.0872, 0.0902, 0.0902, 0.0953, 0.0896, 0.0868, 0.0880,
        0.0862, 0.0924], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,379][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4753, 0.0617, 0.0527, 0.0528, 0.0729, 0.0474, 0.0451, 0.0463, 0.0480,
        0.0406, 0.0572], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,381][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.4091, 0.1047, 0.0597, 0.0502, 0.0540, 0.0763, 0.0463, 0.0449, 0.0612,
        0.0469, 0.0467], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,382][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0541, 0.0021, 0.0027, 0.0240, 0.0183, 0.0437, 0.2146, 0.2336, 0.2497,
        0.0888, 0.0683], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,383][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.6056, 0.0342, 0.0216, 0.0291, 0.0307, 0.0275, 0.0301, 0.0141, 0.0607,
        0.0929, 0.0535], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,383][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([9.5351e-01, 2.5253e-05, 2.0842e-10, 2.0576e-11, 1.8276e-08, 2.7531e-05,
        5.3058e-09, 5.8785e-09, 1.0336e-07, 6.6750e-05, 4.6367e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,384][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0082, 0.0932, 0.0332, 0.0694, 0.0492, 0.0969, 0.0831, 0.2099, 0.0613,
        0.1360, 0.0704, 0.0891], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,386][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0160, 0.0838, 0.0777, 0.0878, 0.0757, 0.0890, 0.0928, 0.1018, 0.1026,
        0.0983, 0.0946, 0.0800], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,387][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.2829, 0.0954, 0.0913, 0.0422, 0.0608, 0.0562, 0.0404, 0.0424, 0.0470,
        0.0971, 0.0432, 0.1013], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,389][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0284, 0.0119, 0.0614, 0.0445, 0.0642, 0.0078, 0.0900, 0.3911, 0.1109,
        0.0148, 0.0436, 0.1314], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,390][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0813, 0.0723, 0.0123, 0.0788, 0.0765, 0.3476, 0.0320, 0.0912, 0.0214,
        0.0737, 0.0806, 0.0322], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,392][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0289, 0.3283, 0.0005, 0.0099, 0.0026, 0.0394, 0.0499, 0.0311, 0.0233,
        0.0844, 0.2864, 0.1153], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,394][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0907, 0.0888, 0.0806, 0.0834, 0.0834, 0.0871, 0.0819, 0.0796, 0.0800,
        0.0780, 0.0836, 0.0828], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,395][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.5939, 0.0475, 0.0361, 0.0307, 0.0475, 0.0307, 0.0289, 0.0288, 0.0313,
        0.0243, 0.0352, 0.0652], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,397][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.3430, 0.1165, 0.0623, 0.0470, 0.0567, 0.0896, 0.0460, 0.0427, 0.0516,
        0.0441, 0.0416, 0.0589], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,399][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0515, 0.0028, 0.0043, 0.0280, 0.0214, 0.0387, 0.2379, 0.1682, 0.2315,
        0.0891, 0.0734, 0.0533], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,400][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.5233, 0.0344, 0.0086, 0.0240, 0.0180, 0.0446, 0.0437, 0.0126, 0.0598,
        0.1121, 0.0649, 0.0540], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,402][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([2.8474e-04, 8.3069e-02, 1.1023e-12, 1.2532e-07, 3.1206e-10, 2.2125e-04,
        1.4024e-07, 3.1626e-09, 1.0797e-09, 1.4778e-04, 9.1627e-01, 6.2486e-06],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,403][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Stephanie] are: tensor([0.0082, 0.0679, 0.0447, 0.0476, 0.0572, 0.0584, 0.0667, 0.2651, 0.0711,
        0.0846, 0.0476, 0.1219, 0.0590], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,405][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Stephanie] are: tensor([0.0169, 0.0802, 0.0707, 0.0810, 0.0661, 0.0816, 0.0871, 0.0956, 0.0978,
        0.0943, 0.0866, 0.0784, 0.0638], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,407][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Stephanie] are: tensor([0.3913, 0.0618, 0.0597, 0.0305, 0.0551, 0.0317, 0.0363, 0.0322, 0.0437,
        0.0717, 0.0406, 0.0830, 0.0624], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,409][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Stephanie] are: tensor([0.0395, 0.0282, 0.0385, 0.0866, 0.0168, 0.0118, 0.0970, 0.1770, 0.1357,
        0.0414, 0.0868, 0.2134, 0.0273], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,411][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Stephanie] are: tensor([0.0667, 0.0247, 0.0295, 0.0301, 0.1667, 0.1848, 0.0468, 0.0805, 0.0422,
        0.0412, 0.0308, 0.0124, 0.2436], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,412][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Stephanie] are: tensor([0.1099, 0.0613, 0.0006, 0.0062, 0.0009, 0.0376, 0.0838, 0.0170, 0.0203,
        0.0516, 0.1746, 0.3995, 0.0367], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,414][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Stephanie] are: tensor([0.0835, 0.0813, 0.0748, 0.0770, 0.0770, 0.0809, 0.0765, 0.0742, 0.0747,
        0.0729, 0.0779, 0.0770, 0.0723], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,416][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Stephanie] are: tensor([0.4203, 0.0476, 0.0430, 0.0390, 0.0645, 0.0382, 0.0374, 0.0363, 0.0388,
        0.0319, 0.0445, 0.0693, 0.0891], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,417][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Stephanie] are: tensor([0.3301, 0.1068, 0.0739, 0.0487, 0.0472, 0.0857, 0.0538, 0.0381, 0.0429,
        0.0526, 0.0448, 0.0443, 0.0311], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,419][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Stephanie] are: tensor([0.0202, 0.0017, 0.0019, 0.0203, 0.0092, 0.0593, 0.3254, 0.1603, 0.1378,
        0.0965, 0.0956, 0.0545, 0.0172], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,421][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Stephanie] are: tensor([0.3432, 0.0445, 0.0063, 0.0341, 0.0265, 0.0889, 0.0623, 0.0135, 0.1216,
        0.1084, 0.0646, 0.0442, 0.0420], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,422][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Stephanie] are: tensor([1.4695e-01, 1.6693e-02, 2.6946e-12, 2.5250e-08, 8.8379e-11, 7.1271e-04,
        6.7247e-06, 2.1432e-07, 3.7716e-08, 2.6167e-03, 7.0394e-01, 1.2850e-01,
        5.9226e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,424][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0083, 0.0431, 0.0439, 0.0270, 0.0799, 0.0441, 0.0533, 0.2956, 0.0497,
        0.0572, 0.0284, 0.1080, 0.0939, 0.0675], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,426][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0134, 0.0715, 0.0681, 0.0762, 0.0635, 0.0773, 0.0778, 0.0911, 0.0879,
        0.0855, 0.0807, 0.0716, 0.0610, 0.0744], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,427][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.1820, 0.0481, 0.0685, 0.0391, 0.0567, 0.0445, 0.0241, 0.0232, 0.0301,
        0.0459, 0.0498, 0.0708, 0.0655, 0.2516], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,428][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0155, 0.0057, 0.0746, 0.0233, 0.1262, 0.0018, 0.0273, 0.1593, 0.1447,
        0.0045, 0.0287, 0.1278, 0.2588, 0.0018], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,429][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0352, 0.0131, 0.0143, 0.0126, 0.0263, 0.1941, 0.0288, 0.0271, 0.0439,
        0.0161, 0.0116, 0.0055, 0.0305, 0.5408], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,430][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.1180, 0.2353, 0.0018, 0.0135, 0.0031, 0.0361, 0.0422, 0.0256, 0.0165,
        0.0518, 0.1655, 0.1723, 0.0406, 0.0777], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,431][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0799, 0.0749, 0.0688, 0.0712, 0.0713, 0.0746, 0.0705, 0.0683, 0.0689,
        0.0673, 0.0720, 0.0717, 0.0673, 0.0732], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,433][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.5693, 0.0361, 0.0284, 0.0246, 0.0371, 0.0248, 0.0239, 0.0237, 0.0265,
        0.0194, 0.0274, 0.0489, 0.0512, 0.0587], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,435][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.3721, 0.0756, 0.0426, 0.0504, 0.0382, 0.0764, 0.0471, 0.0391, 0.0514,
        0.0476, 0.0419, 0.0453, 0.0271, 0.0452], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,437][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0776, 0.0034, 0.0042, 0.0223, 0.0205, 0.0294, 0.1719, 0.1706, 0.2264,
        0.0664, 0.0424, 0.0780, 0.0366, 0.0503], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,438][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.4075, 0.0205, 0.0258, 0.0241, 0.0105, 0.0459, 0.0344, 0.0123, 0.0611,
        0.1259, 0.0644, 0.0291, 0.0116, 0.1269], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,440][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([9.8586e-01, 1.9932e-03, 3.2106e-11, 6.7290e-09, 2.0587e-09, 5.8523e-06,
        5.5556e-09, 3.7083e-09, 1.2989e-09, 4.6231e-06, 9.7164e-03, 2.3035e-04,
        9.8642e-04, 1.2034e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,442][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0394, 0.0310, 0.0436, 0.0163, 0.0703, 0.0409, 0.0569, 0.2202, 0.0879,
        0.0337, 0.0158, 0.1010, 0.0840, 0.1401, 0.0190], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,443][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0114, 0.0655, 0.0619, 0.0667, 0.0616, 0.0687, 0.0714, 0.0794, 0.0845,
        0.0775, 0.0717, 0.0654, 0.0599, 0.0714, 0.0830], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,445][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1493, 0.0712, 0.0486, 0.0384, 0.0412, 0.0371, 0.0375, 0.0291, 0.0367,
        0.0625, 0.0412, 0.1017, 0.0410, 0.2212, 0.0430], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,447][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0347, 0.0043, 0.0502, 0.0154, 0.0470, 0.0024, 0.0194, 0.1478, 0.2495,
        0.0041, 0.0144, 0.2960, 0.0781, 0.0074, 0.0293], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,448][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0509, 0.0411, 0.0248, 0.0590, 0.0479, 0.1954, 0.0785, 0.0915, 0.0625,
        0.0539, 0.0590, 0.0134, 0.0469, 0.1667, 0.0086], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,450][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([3.7046e-01, 3.1452e-03, 9.1136e-05, 3.0201e-04, 1.3216e-04, 9.0583e-04,
        1.4560e-03, 6.7942e-04, 1.1326e-03, 2.4463e-03, 6.3611e-03, 2.2487e-02,
        5.9968e-03, 2.8638e-02, 5.5577e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,451][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0763, 0.0692, 0.0639, 0.0661, 0.0664, 0.0686, 0.0645, 0.0631, 0.0633,
        0.0614, 0.0656, 0.0677, 0.0634, 0.0687, 0.0719], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,453][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.4357, 0.0426, 0.0356, 0.0318, 0.0472, 0.0318, 0.0284, 0.0286, 0.0311,
        0.0228, 0.0333, 0.0563, 0.0615, 0.0682, 0.0449], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,455][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.3114, 0.0869, 0.0541, 0.0519, 0.0440, 0.0696, 0.0465, 0.0430, 0.0505,
        0.0453, 0.0421, 0.0508, 0.0310, 0.0384, 0.0346], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,457][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1297, 0.0011, 0.0027, 0.0163, 0.0174, 0.0142, 0.1112, 0.1498, 0.1943,
        0.0538, 0.0345, 0.0519, 0.0375, 0.0522, 0.1334], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,459][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.8016, 0.0130, 0.0111, 0.0106, 0.0123, 0.0080, 0.0129, 0.0046, 0.0203,
        0.0248, 0.0127, 0.0087, 0.0115, 0.0166, 0.0315], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,460][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.1549e-01, 3.9841e-14, 3.5037e-20, 3.9937e-20, 2.6951e-19, 9.0834e-17,
        6.0008e-19, 1.3121e-19, 1.1713e-17, 2.9033e-15, 2.5555e-13, 1.4703e-11,
        2.2999e-11, 1.0881e-08, 8.8451e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,464][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:25:39,466][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[5868],
        [5416],
        [4174],
        [1916],
        [6758],
        [3093],
        [1858],
        [3284],
        [7245],
        [1997],
        [2570],
        [3257],
        [8477],
        [2889],
        [2970]], device='cuda:0')
[2024-07-24 10:25:39,467][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[5793],
        [4805],
        [2615],
        [1416],
        [3475],
        [2092],
        [1385],
        [2417],
        [6222],
        [1587],
        [2549],
        [3985],
        [2885],
        [1721],
        [2284]], device='cuda:0')
[2024-07-24 10:25:39,469][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 8479],
        [15613],
        [17623],
        [15195],
        [19315],
        [22143],
        [23926],
        [22282],
        [24668],
        [23087],
        [24260],
        [26739],
        [24900],
        [22654],
        [22627]], device='cuda:0')
[2024-07-24 10:25:39,471][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[24994],
        [40168],
        [36572],
        [41681],
        [43529],
        [44233],
        [43196],
        [47296],
        [46725],
        [47342],
        [48348],
        [47530],
        [47517],
        [46895],
        [47417]], device='cuda:0')
[2024-07-24 10:25:39,472][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[19755],
        [20598],
        [22048],
        [24568],
        [26771],
        [27913],
        [29247],
        [28544],
        [27831],
        [27676],
        [27566],
        [27896],
        [28069],
        [28217],
        [27812]], device='cuda:0')
[2024-07-24 10:25:39,474][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[5315],
        [7711],
        [8991],
        [8382],
        [8321],
        [8345],
        [8218],
        [7701],
        [7703],
        [7418],
        [7183],
        [7140],
        [7165],
        [7184],
        [7175]], device='cuda:0')
[2024-07-24 10:25:39,475][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 5567],
        [ 6947],
        [ 7113],
        [ 8385],
        [ 8533],
        [ 7548],
        [ 9041],
        [ 8646],
        [10488],
        [10426],
        [11578],
        [13876],
        [13157],
        [14971],
        [13568]], device='cuda:0')
[2024-07-24 10:25:39,477][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[26381],
        [29014],
        [31218],
        [30140],
        [31770],
        [30965],
        [30478],
        [30965],
        [31134],
        [30647],
        [30288],
        [29808],
        [30738],
        [30744],
        [30172]], device='cuda:0')
[2024-07-24 10:25:39,478][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[21960],
        [23186],
        [23649],
        [23808],
        [24208],
        [24591],
        [24462],
        [24467],
        [24437],
        [24322],
        [24089],
        [24092],
        [23904],
        [23936],
        [23851]], device='cuda:0')
[2024-07-24 10:25:39,480][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[17121],
        [ 5324],
        [ 6578],
        [ 5631],
        [ 6590],
        [ 7071],
        [ 7400],
        [ 6886],
        [ 6859],
        [ 6075],
        [ 5844],
        [ 5954],
        [ 6723],
        [ 6207],
        [ 6187]], device='cuda:0')
[2024-07-24 10:25:39,481][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[30466],
        [31868],
        [32970],
        [32583],
        [32470],
        [32008],
        [31424],
        [31055],
        [30834],
        [30302],
        [30025],
        [30119],
        [30563],
        [30696],
        [30602]], device='cuda:0')
[2024-07-24 10:25:39,483][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[32849],
        [27826],
        [28045],
        [25922],
        [27268],
        [26908],
        [26535],
        [26263],
        [26230],
        [25857],
        [25538],
        [26198],
        [26889],
        [26758],
        [26581]], device='cuda:0')
[2024-07-24 10:25:39,485][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[33889],
        [34731],
        [35964],
        [36337],
        [36929],
        [37337],
        [37588],
        [37569],
        [37649],
        [37862],
        [37960],
        [37975],
        [38046],
        [37969],
        [37853]], device='cuda:0')
[2024-07-24 10:25:39,486][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[22535],
        [20430],
        [19420],
        [19339],
        [13999],
        [10318],
        [10335],
        [10552],
        [10526],
        [10771],
        [10693],
        [10738],
        [10815],
        [11178],
        [17256]], device='cuda:0')
[2024-07-24 10:25:39,488][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 4969],
        [ 8935],
        [29786],
        [20546],
        [44160],
        [38460],
        [35235],
        [30138],
        [23999],
        [37741],
        [29082],
        [23977],
        [46715],
        [31946],
        [38154]], device='cuda:0')
[2024-07-24 10:25:39,490][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[3126],
        [2130],
        [1960],
        [2059],
        [1548],
        [1637],
        [1808],
        [1596],
        [1555],
        [1547],
        [1537],
        [1442],
        [1377],
        [1416],
        [1510]], device='cuda:0')
[2024-07-24 10:25:39,491][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[11474],
        [ 7009],
        [11533],
        [ 9587],
        [ 8949],
        [ 8164],
        [ 8015],
        [ 7381],
        [ 7037],
        [ 6835],
        [ 6720],
        [ 6769],
        [ 6773],
        [ 6610],
        [ 6660]], device='cuda:0')
[2024-07-24 10:25:39,493][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 450],
        [ 781],
        [ 793],
        [1009],
        [ 586],
        [ 762],
        [ 823],
        [ 678],
        [ 908],
        [1157],
        [1249],
        [1010],
        [ 857],
        [1196],
        [1252]], device='cuda:0')
[2024-07-24 10:25:39,495][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[12752],
        [18400],
        [20221],
        [12759],
        [17490],
        [12541],
        [16201],
        [14924],
        [12807],
        [11065],
        [10965],
        [11065],
        [12737],
        [11114],
        [ 9590]], device='cuda:0')
[2024-07-24 10:25:39,497][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[19243],
        [ 6209],
        [ 9248],
        [ 2229],
        [14559],
        [ 1945],
        [ 2801],
        [ 2411],
        [ 2954],
        [ 2157],
        [ 1815],
        [ 2724],
        [10985],
        [ 7663],
        [ 4338]], device='cuda:0')
[2024-07-24 10:25:39,498][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 8213],
        [17598],
        [17560],
        [18063],
        [19646],
        [22224],
        [21380],
        [22739],
        [20646],
        [24353],
        [31435],
        [29055],
        [17476],
        [23454],
        [12096]], device='cuda:0')
[2024-07-24 10:25:39,500][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[2708],
        [2631],
        [2384],
        [2296],
        [2208],
        [2158],
        [2207],
        [2175],
        [2112],
        [2089],
        [2088],
        [2053],
        [2000],
        [1986],
        [1968]], device='cuda:0')
[2024-07-24 10:25:39,501][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 354],
        [1058],
        [1405],
        [1447],
        [1653],
        [1537],
        [1584],
        [1750],
        [1671],
        [1886],
        [1931],
        [1705],
        [2214],
        [1910],
        [2260]], device='cuda:0')
[2024-07-24 10:25:39,503][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[27615],
        [29673],
        [29676],
        [30302],
        [29025],
        [29476],
        [29396],
        [29019],
        [27853],
        [28021],
        [27951],
        [27606],
        [27425],
        [27229],
        [26792]], device='cuda:0')
[2024-07-24 10:25:39,505][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[26472],
        [32682],
        [20360],
        [14628],
        [11243],
        [11653],
        [10402],
        [ 9249],
        [ 8739],
        [ 7584],
        [ 7901],
        [ 8030],
        [ 8549],
        [ 7714],
        [ 7822]], device='cuda:0')
[2024-07-24 10:25:39,506][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[20074],
        [21352],
        [20783],
        [22296],
        [24822],
        [19551],
        [22740],
        [21645],
        [24766],
        [28257],
        [29497],
        [32649],
        [31098],
        [33721],
        [24714]], device='cuda:0')
[2024-07-24 10:25:39,508][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[34905],
        [35251],
        [42979],
        [42961],
        [42730],
        [36078],
        [43561],
        [43262],
        [42978],
        [35222],
        [35646],
        [ 7221],
        [21714],
        [35077],
        [16943]], device='cuda:0')
[2024-07-24 10:25:39,510][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[36235],
        [31037],
        [26609],
        [29229],
        [28247],
        [33424],
        [29775],
        [31079],
        [32185],
        [33999],
        [33766],
        [36162],
        [34614],
        [34070],
        [35717]], device='cuda:0')
[2024-07-24 10:25:39,511][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[36983],
        [45207],
        [32880],
        [43332],
        [13819],
        [30249],
        [32554],
        [35435],
        [37928],
        [32408],
        [38391],
        [31928],
        [ 7541],
        [34917],
        [23031]], device='cuda:0')
[2024-07-24 10:25:39,513][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[8423],
        [8423],
        [8423],
        [8423],
        [8423],
        [8423],
        [8423],
        [8423],
        [8423],
        [8423],
        [8423],
        [8423],
        [8423],
        [8423],
        [8423]], device='cuda:0')
[2024-07-24 10:25:39,566][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:39,566][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,567][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,568][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,569][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,571][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,572][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,573][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,574][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,576][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,577][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,578][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,578][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,579][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1313, 0.8687], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,580][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([6.2168e-08, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,581][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.5384, 0.4616], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,581][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.8109, 0.1891], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,582][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.6370, 0.3630], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,583][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.6066, 0.3934], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,583][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3981, 0.6019], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,584][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0996, 0.9004], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,585][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.5689, 0.4311], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,585][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9915, 0.0085], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,586][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0097, 0.9903], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,587][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.4604, 0.5396], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,588][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Jose] are: tensor([0.0217, 0.4497, 0.5287], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,590][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Jose] are: tensor([7.9324e-06, 6.5664e-01, 3.4335e-01], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,591][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Jose] are: tensor([0.4732, 0.3254, 0.2015], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,592][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Jose] are: tensor([0.6885, 0.1617, 0.1498], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,594][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Jose] are: tensor([0.4994, 0.2239, 0.2767], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,596][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Jose] are: tensor([0.3985, 0.3641, 0.2374], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,597][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Jose] are: tensor([0.3396, 0.2675, 0.3929], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,599][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Jose] are: tensor([0.0548, 0.4829, 0.4623], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,600][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Jose] are: tensor([0.3751, 0.3177, 0.3073], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,602][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Jose] are: tensor([0.9746, 0.0089, 0.0164], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,604][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Jose] are: tensor([0.0071, 0.4983, 0.4946], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,605][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Jose] are: tensor([0.3062, 0.3427, 0.3511], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,607][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0132, 0.2612, 0.3385, 0.3871], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,608][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([1.7259e-07, 2.1061e-01, 1.4554e-02, 7.7484e-01], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,610][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4036, 0.2492, 0.1615, 0.1857], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,611][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.5924, 0.1577, 0.1402, 0.1097], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,613][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4788, 0.1885, 0.2144, 0.1184], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,614][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3492, 0.2089, 0.2739, 0.1680], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,616][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2949, 0.2307, 0.2490, 0.2254], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,618][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0352, 0.3341, 0.3197, 0.3111], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,619][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.3052, 0.2336, 0.2496, 0.2116], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,620][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.9677, 0.0063, 0.0114, 0.0146], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,621][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0050, 0.3345, 0.3154, 0.3451], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,622][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2110, 0.2575, 0.2647, 0.2668], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,622][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Stephanie] are: tensor([0.0106, 0.1454, 0.2277, 0.2510, 0.3652], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,623][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Stephanie] are: tensor([2.8876e-07, 3.2133e-01, 3.9004e-02, 5.4123e-01, 9.8430e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,625][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Stephanie] are: tensor([0.3312, 0.2124, 0.1429, 0.1699, 0.1436], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,626][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Stephanie] are: tensor([0.4922, 0.1529, 0.1328, 0.1053, 0.1167], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,628][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Stephanie] are: tensor([0.3629, 0.1660, 0.2054, 0.1307, 0.1351], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,630][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Stephanie] are: tensor([0.2967, 0.2073, 0.1367, 0.2127, 0.1467], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,631][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Stephanie] are: tensor([0.3446, 0.1349, 0.1836, 0.1278, 0.2090], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,632][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Stephanie] are: tensor([0.0297, 0.2509, 0.2417, 0.2354, 0.2423], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,634][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Stephanie] are: tensor([0.2068, 0.1957, 0.1946, 0.1792, 0.2238], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,636][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Stephanie] are: tensor([0.9714, 0.0040, 0.0081, 0.0121, 0.0044], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,637][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Stephanie] are: tensor([0.0045, 0.2384, 0.2135, 0.2430, 0.3006], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,639][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Stephanie] are: tensor([0.1762, 0.2102, 0.2103, 0.2211, 0.1822], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,641][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0035, 0.0862, 0.1452, 0.1655, 0.3704, 0.2292], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,642][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ had] are: tensor([1.8825e-06, 2.4031e-01, 6.6762e-02, 5.2547e-01, 7.3930e-02, 9.3520e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,643][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.2826, 0.1808, 0.1183, 0.1390, 0.1228, 0.1565], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,645][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.5241, 0.1154, 0.1051, 0.0832, 0.0964, 0.0758], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,647][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.3857, 0.1589, 0.1703, 0.0936, 0.1034, 0.0880], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,648][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.1565, 0.2364, 0.1458, 0.1483, 0.1944, 0.1187], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,650][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2537, 0.1170, 0.1473, 0.1169, 0.1728, 0.1922], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,652][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0236, 0.2011, 0.1920, 0.1875, 0.1930, 0.2029], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,653][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1887, 0.1567, 0.1605, 0.1402, 0.1929, 0.1611], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,655][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.9716, 0.0050, 0.0072, 0.0108, 0.0032, 0.0023], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,656][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0033, 0.1991, 0.1818, 0.2014, 0.2184, 0.1960], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,658][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.1463, 0.1768, 0.1794, 0.1904, 0.1521, 0.1551], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,660][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0077, 0.1012, 0.1789, 0.1486, 0.2178, 0.2015, 0.1442],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,661][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([6.8789e-06, 2.8118e-01, 4.2299e-02, 5.3201e-01, 7.1439e-02, 5.0051e-02,
        2.3016e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,663][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2198, 0.1702, 0.1077, 0.1362, 0.1086, 0.1494, 0.1080],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,664][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.4287, 0.1250, 0.1077, 0.0892, 0.1031, 0.0807, 0.0656],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,665][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2955, 0.1611, 0.1791, 0.0950, 0.1090, 0.0898, 0.0705],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,666][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1675, 0.1605, 0.1462, 0.1351, 0.1883, 0.1185, 0.0838],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,667][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0602, 0.1600, 0.0867, 0.1307, 0.1258, 0.2212, 0.2155],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,668][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0200, 0.1664, 0.1603, 0.1563, 0.1608, 0.1690, 0.1673],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,669][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1578, 0.1379, 0.1414, 0.1280, 0.1678, 0.1466, 0.1205],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,670][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.9003, 0.0132, 0.0187, 0.0311, 0.0108, 0.0081, 0.0178],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,672][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0033, 0.1598, 0.1522, 0.1617, 0.1832, 0.1559, 0.1839],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,673][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1201, 0.1543, 0.1555, 0.1624, 0.1330, 0.1326, 0.1421],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,675][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0027, 0.0764, 0.1115, 0.1280, 0.2588, 0.1498, 0.1522, 0.1206],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,676][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ long] are: tensor([3.7188e-07, 1.1277e-01, 2.5923e-02, 4.2793e-01, 7.1697e-02, 5.9510e-02,
        1.2881e-02, 2.8929e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,678][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.1934, 0.1508, 0.1020, 0.1247, 0.0942, 0.1271, 0.0966, 0.1111],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,679][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.3857, 0.1244, 0.1036, 0.0875, 0.0980, 0.0768, 0.0605, 0.0635],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,681][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.2755, 0.1342, 0.1558, 0.0866, 0.0963, 0.0818, 0.0710, 0.0988],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,683][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0892, 0.1337, 0.1392, 0.1139, 0.2280, 0.0964, 0.0697, 0.1300],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,684][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0693, 0.1648, 0.0453, 0.0825, 0.0563, 0.1668, 0.1165, 0.2985],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,686][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0162, 0.1436, 0.1380, 0.1346, 0.1384, 0.1459, 0.1451, 0.1382],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,688][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.1398, 0.1223, 0.1303, 0.1174, 0.1576, 0.1324, 0.1080, 0.0921],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,690][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.9153, 0.0101, 0.0170, 0.0217, 0.0091, 0.0054, 0.0122, 0.0091],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,691][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0022, 0.1400, 0.1296, 0.1421, 0.1578, 0.1284, 0.1481, 0.1519],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,693][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.1053, 0.1351, 0.1338, 0.1388, 0.1159, 0.1150, 0.1188, 0.1374],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,694][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0093, 0.0950, 0.1825, 0.1237, 0.1488, 0.1570, 0.1016, 0.1061, 0.0759],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,696][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([1.1097e-05, 1.7360e-01, 4.6738e-02, 3.9229e-01, 5.5211e-02, 8.1440e-02,
        2.5887e-02, 1.6713e-01, 5.7693e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,697][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.1726, 0.1277, 0.0893, 0.1055, 0.0828, 0.1082, 0.0873, 0.0945, 0.1321],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,699][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.3578, 0.1091, 0.0921, 0.0799, 0.0892, 0.0699, 0.0583, 0.0614, 0.0823],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,701][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.1993, 0.1137, 0.1376, 0.0860, 0.0923, 0.0828, 0.0768, 0.1045, 0.1070],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,703][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.1551, 0.1842, 0.1053, 0.1731, 0.1483, 0.0619, 0.0515, 0.0927, 0.0279],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,704][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0253, 0.1359, 0.0413, 0.0838, 0.0593, 0.1728, 0.1166, 0.2890, 0.0761],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,706][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0155, 0.1250, 0.1205, 0.1178, 0.1212, 0.1273, 0.1268, 0.1211, 0.1249],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,708][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.1241, 0.1104, 0.1127, 0.1050, 0.1343, 0.1218, 0.1014, 0.0864, 0.1038],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,709][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.8980, 0.0100, 0.0151, 0.0261, 0.0095, 0.0062, 0.0141, 0.0111, 0.0100],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,710][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0020, 0.1185, 0.1070, 0.1199, 0.1375, 0.1155, 0.1284, 0.1207, 0.1504],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,711][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0925, 0.1146, 0.1147, 0.1255, 0.1033, 0.1029, 0.1096, 0.1235, 0.1134],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:39,712][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0061, 0.0677, 0.1289, 0.1260, 0.1695, 0.1161, 0.1112, 0.0898, 0.0671,
        0.1176], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,713][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([1.2012e-06, 1.4913e-01, 3.2093e-02, 4.9441e-01, 5.1258e-02, 3.1556e-02,
        1.7198e-02, 1.6640e-01, 3.6669e-02, 2.1282e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,714][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1884, 0.1065, 0.0709, 0.0828, 0.0703, 0.0951, 0.0709, 0.0823, 0.1287,
        0.1043], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,715][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3571, 0.0936, 0.0844, 0.0689, 0.0830, 0.0647, 0.0546, 0.0592, 0.0812,
        0.0532], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,717][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2028, 0.1125, 0.1282, 0.0786, 0.0801, 0.0737, 0.0656, 0.0934, 0.0957,
        0.0694], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,719][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0661, 0.1421, 0.1324, 0.1255, 0.1577, 0.0658, 0.0497, 0.1055, 0.0420,
        0.1131], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,720][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0304, 0.1340, 0.0360, 0.0607, 0.0467, 0.1079, 0.1038, 0.2832, 0.0815,
        0.1157], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,722][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0130, 0.1115, 0.1077, 0.1050, 0.1083, 0.1137, 0.1130, 0.1080, 0.1112,
        0.1085], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,724][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1217, 0.1005, 0.1089, 0.0915, 0.1268, 0.1059, 0.0859, 0.0727, 0.0901,
        0.0961], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,725][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.8895, 0.0089, 0.0145, 0.0216, 0.0085, 0.0054, 0.0145, 0.0123, 0.0112,
        0.0135], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,727][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0018, 0.1067, 0.0943, 0.1081, 0.1162, 0.1044, 0.1184, 0.1097, 0.1113,
        0.1291], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,729][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0917, 0.1051, 0.1053, 0.1116, 0.0911, 0.0898, 0.0985, 0.1100, 0.1019,
        0.0948], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:39,731][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0041, 0.0512, 0.1025, 0.1004, 0.1549, 0.1016, 0.1049, 0.0817, 0.0712,
        0.1303, 0.0972], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,732][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([1.7791e-06, 8.3537e-02, 3.3666e-02, 5.6842e-01, 5.6356e-02, 3.4348e-02,
        1.8842e-02, 1.0983e-01, 4.2455e-02, 2.0344e-02, 3.2196e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,734][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1505, 0.0897, 0.0669, 0.0757, 0.0675, 0.0848, 0.0667, 0.0715, 0.1031,
        0.0938, 0.1299], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,735][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3351, 0.0885, 0.0807, 0.0643, 0.0772, 0.0613, 0.0516, 0.0557, 0.0771,
        0.0506, 0.0578], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,737][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1841, 0.0941, 0.1130, 0.0707, 0.0729, 0.0689, 0.0635, 0.0850, 0.0950,
        0.0696, 0.0833], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,739][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0925, 0.1377, 0.1389, 0.0786, 0.1279, 0.0584, 0.0475, 0.0931, 0.0400,
        0.0976, 0.0879], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,741][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0265, 0.0769, 0.0216, 0.0357, 0.0293, 0.0611, 0.0928, 0.3121, 0.0937,
        0.1220, 0.1283], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,742][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0104, 0.1011, 0.0967, 0.0945, 0.0977, 0.1030, 0.1023, 0.0973, 0.1005,
        0.0980, 0.0984], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,744][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1163, 0.0892, 0.0991, 0.0819, 0.1166, 0.0968, 0.0780, 0.0654, 0.0843,
        0.0879, 0.0845], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,746][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.8906, 0.0080, 0.0141, 0.0196, 0.0072, 0.0044, 0.0127, 0.0095, 0.0088,
        0.0115, 0.0137], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,748][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0013, 0.0952, 0.0861, 0.0995, 0.1053, 0.0908, 0.1052, 0.0983, 0.0990,
        0.1173, 0.1020], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,749][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0869, 0.0956, 0.0950, 0.1027, 0.0824, 0.0830, 0.0911, 0.1006, 0.0909,
        0.0871, 0.0847], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:39,751][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0433, 0.0615, 0.1607, 0.0897, 0.0901, 0.1181, 0.0718, 0.0847, 0.0521,
        0.0920, 0.0995, 0.0365], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,752][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([1.5976e-06, 9.2627e-02, 2.8069e-02, 4.1268e-01, 4.9393e-02, 5.2997e-02,
        1.5606e-02, 1.0986e-01, 3.7178e-02, 3.0422e-02, 2.7318e-02, 1.4385e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,754][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.1236, 0.0856, 0.0611, 0.0718, 0.0591, 0.0757, 0.0629, 0.0708, 0.1018,
        0.0888, 0.1292, 0.0697], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,755][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.2571, 0.0933, 0.0810, 0.0695, 0.0803, 0.0616, 0.0535, 0.0572, 0.0756,
        0.0497, 0.0566, 0.0646], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,756][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.1441, 0.0808, 0.1033, 0.0673, 0.0703, 0.0678, 0.0615, 0.0816, 0.0839,
        0.0635, 0.0743, 0.1015], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,757][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.1813, 0.1007, 0.0696, 0.0601, 0.1089, 0.0678, 0.0336, 0.0785, 0.0237,
        0.0917, 0.1007, 0.0834], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,758][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0210, 0.0885, 0.0262, 0.0481, 0.0349, 0.0877, 0.0818, 0.2637, 0.0724,
        0.0947, 0.1012, 0.0798], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,759][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0103, 0.0922, 0.0884, 0.0864, 0.0892, 0.0939, 0.0931, 0.0887, 0.0913,
        0.0891, 0.0897, 0.0877], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,761][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0855, 0.0831, 0.0866, 0.0834, 0.0984, 0.0904, 0.0776, 0.0651, 0.0747,
        0.0886, 0.0876, 0.0790], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,762][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.8713, 0.0103, 0.0150, 0.0248, 0.0084, 0.0049, 0.0117, 0.0097, 0.0095,
        0.0130, 0.0169, 0.0046], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,764][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0009, 0.0867, 0.0759, 0.0934, 0.0976, 0.0790, 0.0989, 0.0894, 0.0886,
        0.1114, 0.0975, 0.0806], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,766][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0614, 0.0855, 0.0836, 0.0974, 0.0727, 0.0738, 0.0834, 0.0962, 0.0835,
        0.0784, 0.0778, 0.1063], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:39,767][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Stephanie] are: tensor([0.0141, 0.0515, 0.1266, 0.0994, 0.1071, 0.0955, 0.0818, 0.0769, 0.0587,
        0.0943, 0.0931, 0.0446, 0.0566], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,768][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Stephanie] are: tensor([1.2799e-06, 2.2248e-01, 3.4210e-02, 3.5999e-01, 1.0315e-01, 2.9824e-02,
        8.2009e-03, 8.2991e-02, 1.5323e-02, 1.9318e-02, 1.0002e-02, 5.2597e-02,
        6.1903e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,770][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Stephanie] are: tensor([0.1086, 0.0765, 0.0569, 0.0667, 0.0553, 0.0708, 0.0589, 0.0651, 0.0906,
        0.0864, 0.1181, 0.0658, 0.0802], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,772][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Stephanie] are: tensor([0.2700, 0.0843, 0.0735, 0.0624, 0.0708, 0.0555, 0.0465, 0.0503, 0.0690,
        0.0448, 0.0508, 0.0580, 0.0643], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,774][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Stephanie] are: tensor([0.1521, 0.0758, 0.0976, 0.0605, 0.0569, 0.0601, 0.0518, 0.0721, 0.0761,
        0.0573, 0.0699, 0.0974, 0.0724], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,776][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Stephanie] are: tensor([0.0703, 0.1431, 0.0687, 0.0778, 0.0741, 0.0506, 0.0300, 0.0681, 0.0192,
        0.0919, 0.1258, 0.0888, 0.0915], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,777][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Stephanie] are: tensor([0.0918, 0.1106, 0.0337, 0.0529, 0.0356, 0.1372, 0.0808, 0.1713, 0.0396,
        0.0713, 0.0824, 0.0487, 0.0440], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,779][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Stephanie] are: tensor([0.0098, 0.0848, 0.0810, 0.0792, 0.0815, 0.0861, 0.0856, 0.0813, 0.0837,
        0.0818, 0.0821, 0.0801, 0.0829], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,781][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Stephanie] are: tensor([0.0833, 0.0808, 0.0815, 0.0770, 0.0882, 0.0830, 0.0687, 0.0596, 0.0657,
        0.0776, 0.0769, 0.0701, 0.0877], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,782][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Stephanie] are: tensor([0.8984, 0.0058, 0.0119, 0.0183, 0.0068, 0.0036, 0.0087, 0.0092, 0.0068,
        0.0102, 0.0127, 0.0045, 0.0030], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,784][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Stephanie] are: tensor([0.0014, 0.0782, 0.0683, 0.0802, 0.0967, 0.0757, 0.0877, 0.0843, 0.0841,
        0.0956, 0.0825, 0.0727, 0.0926], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,786][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Stephanie] are: tensor([0.0620, 0.0796, 0.0774, 0.0887, 0.0695, 0.0680, 0.0767, 0.0868, 0.0756,
        0.0721, 0.0699, 0.0971, 0.0764], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:39,788][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0241, 0.0693, 0.1361, 0.0881, 0.0809, 0.1088, 0.0749, 0.0785, 0.0484,
        0.0916, 0.0862, 0.0324, 0.0440, 0.0366], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,789][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ said] are: tensor([1.9445e-07, 1.8118e-01, 5.0373e-02, 1.7557e-01, 6.9551e-02, 2.6810e-02,
        7.8370e-03, 2.0000e-01, 3.6966e-02, 9.6013e-03, 4.8197e-03, 3.9183e-02,
        2.8516e-02, 1.6958e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,791][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.1033, 0.0714, 0.0529, 0.0639, 0.0524, 0.0673, 0.0552, 0.0598, 0.0846,
        0.0782, 0.1108, 0.0583, 0.0737, 0.0681], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,793][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.2284, 0.0845, 0.0717, 0.0603, 0.0689, 0.0517, 0.0451, 0.0491, 0.0658,
        0.0424, 0.0482, 0.0563, 0.0642, 0.0633], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,794][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.1387, 0.0679, 0.0808, 0.0506, 0.0519, 0.0513, 0.0448, 0.0586, 0.0704,
        0.0498, 0.0633, 0.0925, 0.0739, 0.1056], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,796][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0821, 0.1296, 0.0607, 0.0624, 0.0844, 0.0604, 0.0354, 0.0602, 0.0285,
        0.0839, 0.0862, 0.0912, 0.0996, 0.0355], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,798][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0647, 0.1012, 0.0232, 0.0430, 0.0292, 0.0925, 0.0529, 0.1439, 0.0335,
        0.0675, 0.0753, 0.0335, 0.0410, 0.1988], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,799][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0084, 0.0784, 0.0751, 0.0733, 0.0758, 0.0799, 0.0786, 0.0747, 0.0769,
        0.0750, 0.0757, 0.0739, 0.0765, 0.0780], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,800][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0795, 0.0657, 0.0733, 0.0680, 0.0856, 0.0714, 0.0616, 0.0531, 0.0633,
        0.0671, 0.0674, 0.0669, 0.0857, 0.0913], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,801][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.8788, 0.0085, 0.0140, 0.0199, 0.0081, 0.0040, 0.0108, 0.0083, 0.0076,
        0.0118, 0.0154, 0.0044, 0.0039, 0.0045], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,802][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0012, 0.0703, 0.0653, 0.0694, 0.0810, 0.0710, 0.0770, 0.0742, 0.0852,
        0.0852, 0.0703, 0.0681, 0.0768, 0.1051], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,803][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0592, 0.0734, 0.0728, 0.0815, 0.0641, 0.0647, 0.0708, 0.0788, 0.0714,
        0.0664, 0.0668, 0.0888, 0.0702, 0.0710], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:39,805][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0168, 0.0534, 0.1226, 0.0778, 0.0938, 0.0958, 0.0746, 0.0693, 0.0492,
        0.0917, 0.0850, 0.0368, 0.0490, 0.0386, 0.0456], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,806][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([7.7515e-07, 1.1129e-01, 2.1515e-02, 3.0907e-01, 5.1897e-02, 2.8279e-02,
        1.2108e-02, 1.9348e-01, 3.8974e-02, 2.1700e-02, 1.3568e-02, 3.7661e-02,
        3.3246e-02, 9.0184e-02, 3.7028e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,808][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0963, 0.0676, 0.0460, 0.0540, 0.0462, 0.0619, 0.0458, 0.0533, 0.0809,
        0.0681, 0.0999, 0.0534, 0.0626, 0.0642, 0.0997], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,809][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.2640, 0.0662, 0.0611, 0.0507, 0.0600, 0.0462, 0.0423, 0.0467, 0.0644,
        0.0390, 0.0433, 0.0553, 0.0592, 0.0636, 0.0381], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,811][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1447, 0.0802, 0.0897, 0.0463, 0.0511, 0.0440, 0.0348, 0.0545, 0.0622,
        0.0430, 0.0547, 0.0707, 0.0598, 0.0939, 0.0704], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,813][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0755, 0.1018, 0.0711, 0.0676, 0.1057, 0.0599, 0.0365, 0.0765, 0.0301,
        0.0807, 0.0806, 0.0665, 0.0864, 0.0371, 0.0240], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,815][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0292, 0.0872, 0.0279, 0.0395, 0.0335, 0.0709, 0.0586, 0.1375, 0.0448,
        0.0625, 0.0775, 0.0480, 0.0558, 0.1461, 0.0810], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,816][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0080, 0.0718, 0.0694, 0.0677, 0.0700, 0.0735, 0.0728, 0.0693, 0.0715,
        0.0694, 0.0699, 0.0682, 0.0710, 0.0722, 0.0753], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,818][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0749, 0.0643, 0.0688, 0.0622, 0.0750, 0.0678, 0.0587, 0.0497, 0.0573,
        0.0637, 0.0604, 0.0589, 0.0726, 0.0806, 0.0850], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,820][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.8411, 0.0098, 0.0175, 0.0222, 0.0098, 0.0054, 0.0120, 0.0101, 0.0100,
        0.0123, 0.0159, 0.0052, 0.0045, 0.0053, 0.0190], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,822][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0011, 0.0661, 0.0618, 0.0673, 0.0735, 0.0644, 0.0742, 0.0697, 0.0741,
        0.0814, 0.0698, 0.0650, 0.0714, 0.0873, 0.0728], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,823][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0532, 0.0691, 0.0673, 0.0722, 0.0582, 0.0611, 0.0637, 0.0706, 0.0671,
        0.0602, 0.0631, 0.0851, 0.0653, 0.0679, 0.0759], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:39,883][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:39,884][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,886][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,887][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,888][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,888][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,889][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,890][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,890][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,891][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,892][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,893][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,894][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:39,895][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0132, 0.9868], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,895][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([1.9685e-05, 9.9998e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,896][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.7703, 0.2297], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,897][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9575, 0.0425], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,897][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9086, 0.0914], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,898][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.5727, 0.4273], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,899][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.5738, 0.4262], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,899][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.6185, 0.3815], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,900][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.5059, 0.4941], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,901][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,902][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9946, 0.0054], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,902][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9406, 0.0594], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:39,903][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Jose] are: tensor([0.0163, 0.5880, 0.3957], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,905][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Jose] are: tensor([0.0024, 0.6902, 0.3075], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,906][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Jose] are: tensor([0.5778, 0.1970, 0.2253], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,908][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Jose] are: tensor([0.8656, 0.0679, 0.0665], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,910][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Jose] are: tensor([0.5808, 0.1826, 0.2367], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,911][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Jose] are: tensor([0.3057, 0.3429, 0.3514], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,913][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Jose] are: tensor([0.5534, 0.3564, 0.0902], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,914][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Jose] are: tensor([0.4638, 0.2854, 0.2508], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,915][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Jose] are: tensor([0.3153, 0.2749, 0.4099], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,915][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Jose] are: tensor([0.9552, 0.0187, 0.0261], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,916][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Jose] are: tensor([0.9957, 0.0030, 0.0013], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,918][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Jose] are: tensor([0.8964, 0.0445, 0.0591], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:39,919][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0037, 0.2207, 0.2673, 0.5083], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,920][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([1.9510e-06, 3.4522e-02, 3.6103e-03, 9.6187e-01], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,922][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4516, 0.1612, 0.1835, 0.2038], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,924][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.8905, 0.0441, 0.0515, 0.0138], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,925][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3293, 0.0305, 0.5950, 0.0452], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,926][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2075, 0.2126, 0.2877, 0.2922], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,928][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.3821, 0.1627, 0.3740, 0.0812], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,930][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.3718, 0.2304, 0.2004, 0.1975], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,931][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3351, 0.1347, 0.2629, 0.2673], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,933][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.8713, 0.0267, 0.0385, 0.0635], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,935][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9943, 0.0023, 0.0023, 0.0011], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,936][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.8504, 0.0432, 0.0284, 0.0780], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:39,938][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Stephanie] are: tensor([0.0054, 0.2564, 0.1425, 0.3412, 0.2545], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,939][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Stephanie] are: tensor([4.6078e-04, 7.1497e-02, 2.4765e-02, 8.9450e-01, 8.7819e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,940][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Stephanie] are: tensor([0.3597, 0.1365, 0.1569, 0.1878, 0.1592], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,942][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Stephanie] are: tensor([0.7608, 0.0659, 0.0874, 0.0344, 0.0515], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,944][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Stephanie] are: tensor([0.1994, 0.0657, 0.2536, 0.4662, 0.0150], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,945][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Stephanie] are: tensor([0.1650, 0.1911, 0.2161, 0.2399, 0.1879], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,947][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Stephanie] are: tensor([0.2505, 0.2350, 0.0822, 0.3848, 0.0474], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,948][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Stephanie] are: tensor([0.3138, 0.1966, 0.1727, 0.1728, 0.1442], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,950][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Stephanie] are: tensor([0.2822, 0.1159, 0.1641, 0.1956, 0.2423], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,952][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Stephanie] are: tensor([0.8754, 0.0187, 0.0270, 0.0604, 0.0184], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,953][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Stephanie] are: tensor([0.9785, 0.0093, 0.0014, 0.0040, 0.0068], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,955][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Stephanie] are: tensor([0.7892, 0.0482, 0.0573, 0.0546, 0.0507], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:39,957][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0008, 0.1153, 0.1290, 0.2807, 0.2173, 0.2570], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,958][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([7.4773e-05, 4.0036e-02, 5.4957e-02, 6.4410e-01, 2.8646e-03, 2.5797e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,959][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.3466, 0.1206, 0.1368, 0.1546, 0.1389, 0.1024], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,959][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.8293, 0.0385, 0.0496, 0.0147, 0.0354, 0.0325], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,960][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.2196, 0.0310, 0.3088, 0.2331, 0.1965, 0.0110], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,961][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.1251, 0.1289, 0.1705, 0.1845, 0.1745, 0.2166], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,962][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.3301, 0.0663, 0.1275, 0.1067, 0.3550, 0.0144], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,963][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.2780, 0.1729, 0.1495, 0.1477, 0.1230, 0.1289], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,965][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.2190, 0.0760, 0.1562, 0.1541, 0.2357, 0.1591], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,967][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.6954, 0.0308, 0.0403, 0.0738, 0.0344, 0.1254], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,968][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([9.9115e-01, 2.8227e-03, 1.8716e-03, 1.2968e-03, 8.2175e-04, 2.0334e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,969][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.7013, 0.0510, 0.0440, 0.0728, 0.0394, 0.0915], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:39,971][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0007, 0.0681, 0.0970, 0.2489, 0.2738, 0.2380, 0.0735],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,972][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([3.0410e-05, 6.8441e-02, 1.2491e-02, 7.6581e-01, 1.2033e-03, 4.9732e-02,
        1.0229e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,974][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.3230, 0.1055, 0.1191, 0.1341, 0.1174, 0.0899, 0.1110],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,975][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.8307, 0.0327, 0.0301, 0.0124, 0.0224, 0.0368, 0.0349],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,977][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0704, 0.0272, 0.3969, 0.1875, 0.2651, 0.0494, 0.0036],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,979][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1389, 0.1035, 0.1434, 0.1439, 0.1375, 0.1794, 0.1534],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,980][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.3705, 0.0511, 0.1178, 0.1241, 0.3192, 0.0167, 0.0006],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,982][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.2433, 0.1493, 0.1293, 0.1276, 0.1073, 0.1123, 0.1308],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,983][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.2160, 0.0652, 0.1291, 0.1315, 0.2051, 0.1326, 0.1205],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,985][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.7321, 0.0256, 0.0294, 0.0518, 0.0221, 0.0928, 0.0461],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,986][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([9.9304e-01, 1.9318e-03, 1.5244e-03, 7.5343e-04, 8.2104e-04, 1.2190e-03,
        7.0721e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,988][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.7542, 0.0280, 0.0320, 0.0381, 0.0348, 0.0304, 0.0824],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:39,989][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0007, 0.1073, 0.0803, 0.2495, 0.2011, 0.1482, 0.0722, 0.1406],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,991][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([6.3444e-06, 1.4466e-02, 1.0753e-02, 7.1153e-01, 4.9766e-04, 2.4413e-02,
        5.6792e-02, 1.8154e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,992][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.2911, 0.0907, 0.1052, 0.1178, 0.1034, 0.0789, 0.0977, 0.1151],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,994][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.6937, 0.0490, 0.0493, 0.0210, 0.0398, 0.0391, 0.0579, 0.0502],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,996][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0780, 0.0473, 0.1730, 0.3279, 0.2489, 0.0538, 0.0586, 0.0124],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,997][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.1027, 0.0915, 0.1291, 0.1295, 0.1219, 0.1557, 0.1410, 0.1286],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:39,999][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.1063, 0.1777, 0.1871, 0.2330, 0.1302, 0.1495, 0.0077, 0.0086],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,001][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.2156, 0.1335, 0.1159, 0.1145, 0.0957, 0.1007, 0.1177, 0.1065],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,003][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.1626, 0.0510, 0.1022, 0.1112, 0.1684, 0.1255, 0.1137, 0.1653],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,004][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.7266, 0.0255, 0.0264, 0.0506, 0.0200, 0.0845, 0.0426, 0.0237],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,004][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([9.9171e-01, 1.6270e-03, 7.8110e-04, 1.3266e-03, 7.5656e-04, 1.6863e-03,
        1.0660e-03, 1.0431e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,005][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.7697, 0.0260, 0.0209, 0.0373, 0.0190, 0.0239, 0.0496, 0.0536],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,006][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0005, 0.0859, 0.1023, 0.1719, 0.2477, 0.1564, 0.0548, 0.1390, 0.0414],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,007][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0006, 0.0353, 0.0254, 0.5815, 0.0017, 0.0247, 0.0235, 0.0316, 0.2756],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,009][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.2515, 0.0822, 0.0914, 0.1045, 0.0898, 0.0710, 0.0856, 0.0980, 0.1259],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,010][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.5466, 0.0543, 0.0654, 0.0283, 0.0398, 0.0460, 0.0840, 0.0823, 0.0534],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,012][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0367, 0.0311, 0.2965, 0.2744, 0.0837, 0.0611, 0.0944, 0.1144, 0.0077],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,014][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0987, 0.0786, 0.1104, 0.1114, 0.1072, 0.1353, 0.1189, 0.1195, 0.1203],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,015][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0900, 0.1535, 0.1748, 0.2116, 0.1659, 0.0418, 0.0162, 0.0429, 0.1034],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,017][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.1907, 0.1172, 0.1027, 0.1021, 0.0859, 0.0904, 0.1051, 0.0953, 0.1106],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,019][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.1767, 0.0416, 0.0895, 0.0946, 0.1545, 0.1099, 0.0932, 0.1439, 0.0962],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,020][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.6397, 0.0318, 0.0325, 0.0537, 0.0223, 0.0922, 0.0487, 0.0310, 0.0481],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,021][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([9.8440e-01, 4.0586e-03, 1.2253e-03, 1.5391e-03, 5.6646e-04, 3.1905e-03,
        1.3617e-03, 4.5382e-04, 3.2023e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,023][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.6742, 0.0356, 0.0371, 0.0410, 0.0310, 0.0354, 0.0649, 0.0359, 0.0449],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,024][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([2.7245e-04, 3.3620e-02, 1.3905e-01, 1.6964e-01, 3.2066e-01, 1.4723e-01,
        3.8384e-02, 8.8915e-02, 2.1542e-02, 4.0679e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,025][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([7.4669e-06, 4.9340e-02, 4.0255e-03, 6.2950e-01, 3.8088e-04, 8.1230e-03,
        4.0449e-02, 3.5295e-02, 1.1613e-01, 1.1676e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,027][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2126, 0.0743, 0.0859, 0.0940, 0.0834, 0.0646, 0.0792, 0.0922, 0.1228,
        0.0910], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,029][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.7250, 0.0260, 0.0367, 0.0101, 0.0251, 0.0317, 0.0420, 0.0401, 0.0518,
        0.0113], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,031][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0591, 0.0042, 0.1786, 0.0438, 0.2175, 0.0396, 0.0988, 0.2181, 0.1376,
        0.0026], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,032][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0966, 0.0681, 0.0930, 0.0978, 0.0883, 0.1237, 0.1037, 0.1023, 0.1080,
        0.1185], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,034][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0448, 0.0010, 0.0138, 0.0028, 0.1956, 0.0063, 0.0018, 0.0075, 0.7100,
        0.0162], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,036][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1769, 0.1072, 0.0930, 0.0913, 0.0775, 0.0807, 0.0930, 0.0843, 0.0979,
        0.0981], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,037][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1995, 0.0400, 0.0943, 0.0841, 0.1273, 0.0801, 0.0713, 0.1190, 0.0806,
        0.1038], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,039][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.6764, 0.0251, 0.0267, 0.0434, 0.0178, 0.0798, 0.0375, 0.0246, 0.0410,
        0.0276], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,041][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9676, 0.0068, 0.0038, 0.0028, 0.0021, 0.0026, 0.0019, 0.0013, 0.0026,
        0.0085], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,043][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6174, 0.0408, 0.0294, 0.0572, 0.0293, 0.0353, 0.0662, 0.0299, 0.0312,
        0.0633], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,044][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0005, 0.0369, 0.1501, 0.1575, 0.3321, 0.1029, 0.0343, 0.0745, 0.0204,
        0.0325, 0.0582], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,046][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([1.4849e-05, 4.1593e-02, 5.2214e-03, 3.9154e-01, 5.3857e-04, 7.1037e-03,
        3.5480e-02, 3.9560e-02, 7.4720e-02, 1.0143e-01, 3.0280e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,047][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1923, 0.0669, 0.0786, 0.0864, 0.0751, 0.0576, 0.0721, 0.0832, 0.1136,
        0.0829, 0.0912], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,049][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.6403, 0.0436, 0.0413, 0.0131, 0.0307, 0.0367, 0.0567, 0.0466, 0.0532,
        0.0204, 0.0173], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,051][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0855, 0.0090, 0.1650, 0.0135, 0.1781, 0.0400, 0.0852, 0.2480, 0.1528,
        0.0081, 0.0149], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,052][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0763, 0.0702, 0.0853, 0.0863, 0.0831, 0.1053, 0.0934, 0.0930, 0.0984,
        0.1064, 0.1022], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,053][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0307, 0.0044, 0.0148, 0.0021, 0.1711, 0.0224, 0.0008, 0.0080, 0.7022,
        0.0365, 0.0071], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,054][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1605, 0.0972, 0.0840, 0.0827, 0.0701, 0.0728, 0.0837, 0.0760, 0.0883,
        0.0886, 0.0961], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,055][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1574, 0.0359, 0.0830, 0.0753, 0.1160, 0.0777, 0.0694, 0.1139, 0.0706,
        0.0979, 0.1030], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,056][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.7029, 0.0195, 0.0255, 0.0378, 0.0151, 0.0722, 0.0324, 0.0211, 0.0353,
        0.0231, 0.0151], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,058][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9291, 0.0178, 0.0045, 0.0064, 0.0027, 0.0047, 0.0039, 0.0024, 0.0025,
        0.0180, 0.0080], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,059][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.6005, 0.0346, 0.0238, 0.0589, 0.0252, 0.0287, 0.0561, 0.0258, 0.0288,
        0.0533, 0.0642], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,061][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0003, 0.0632, 0.0490, 0.2655, 0.1569, 0.1536, 0.0331, 0.0713, 0.0121,
        0.0689, 0.1077, 0.0182], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,063][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0006, 0.0108, 0.0031, 0.1438, 0.0007, 0.0058, 0.0126, 0.0172, 0.0253,
        0.1151, 0.5620, 0.1029], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,064][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.1881, 0.0622, 0.0712, 0.0820, 0.0674, 0.0548, 0.0679, 0.0793, 0.1017,
        0.0773, 0.0867, 0.0615], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,066][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.5526, 0.0487, 0.0450, 0.0164, 0.0318, 0.0407, 0.0685, 0.0588, 0.0676,
        0.0253, 0.0219, 0.0226], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,068][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0379, 0.0406, 0.0313, 0.2780, 0.0229, 0.0899, 0.0463, 0.0189, 0.0077,
        0.0787, 0.2985, 0.0494], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,069][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.1046, 0.0671, 0.0745, 0.0779, 0.0685, 0.0978, 0.0814, 0.0772, 0.0820,
        0.0977, 0.0926, 0.0789], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,071][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0643, 0.1012, 0.0456, 0.0700, 0.0763, 0.0885, 0.0106, 0.0119, 0.0719,
        0.2777, 0.1660, 0.0161], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,073][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.1416, 0.0884, 0.0770, 0.0763, 0.0643, 0.0676, 0.0781, 0.0711, 0.0826,
        0.0828, 0.0894, 0.0809], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,074][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0912, 0.0269, 0.0657, 0.0646, 0.1066, 0.0711, 0.0633, 0.1041, 0.0694,
        0.1043, 0.1139, 0.1190], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,076][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.6807, 0.0190, 0.0199, 0.0366, 0.0151, 0.0694, 0.0361, 0.0198, 0.0330,
        0.0309, 0.0228, 0.0166], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,078][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.9456, 0.0089, 0.0030, 0.0041, 0.0023, 0.0075, 0.0033, 0.0020, 0.0027,
        0.0090, 0.0061, 0.0056], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,080][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.5863, 0.0312, 0.0288, 0.0399, 0.0299, 0.0277, 0.0548, 0.0319, 0.0244,
        0.0490, 0.0435, 0.0527], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,081][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Stephanie] are: tensor([0.0007, 0.0437, 0.0448, 0.2282, 0.1828, 0.1211, 0.0489, 0.0723, 0.0188,
        0.0539, 0.1033, 0.0213, 0.0601], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,083][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Stephanie] are: tensor([0.0024, 0.0181, 0.0044, 0.2595, 0.0026, 0.0029, 0.0069, 0.0057, 0.0125,
        0.1362, 0.4857, 0.0528, 0.0104], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,085][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Stephanie] are: tensor([0.1596, 0.0581, 0.0664, 0.0780, 0.0651, 0.0526, 0.0659, 0.0756, 0.0985,
        0.0759, 0.0836, 0.0594, 0.0613], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,087][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Stephanie] are: tensor([0.4658, 0.0407, 0.0499, 0.0205, 0.0283, 0.0537, 0.0732, 0.0702, 0.0640,
        0.0276, 0.0286, 0.0399, 0.0374], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,088][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Stephanie] are: tensor([0.0886, 0.0121, 0.0804, 0.0994, 0.0046, 0.0608, 0.0315, 0.0557, 0.0126,
        0.0181, 0.1301, 0.3951, 0.0110], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,090][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Stephanie] are: tensor([0.1014, 0.0689, 0.0706, 0.0755, 0.0586, 0.0895, 0.0780, 0.0714, 0.0765,
        0.0857, 0.0832, 0.0744, 0.0663], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,092][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Stephanie] are: tensor([0.0387, 0.0864, 0.0214, 0.1080, 0.0113, 0.0433, 0.0097, 0.0068, 0.0446,
        0.3342, 0.2511, 0.0365, 0.0080], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,094][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Stephanie] are: tensor([0.1339, 0.0818, 0.0712, 0.0715, 0.0596, 0.0626, 0.0727, 0.0660, 0.0762,
        0.0770, 0.0830, 0.0744, 0.0700], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,096][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Stephanie] are: tensor([0.0813, 0.0258, 0.0465, 0.0552, 0.0765, 0.0654, 0.0637, 0.0960, 0.0696,
        0.1099, 0.1014, 0.1118, 0.0970], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,097][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Stephanie] are: tensor([0.7062, 0.0137, 0.0160, 0.0359, 0.0119, 0.0755, 0.0297, 0.0151, 0.0287,
        0.0305, 0.0213, 0.0121, 0.0036], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,098][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Stephanie] are: tensor([9.7077e-01, 4.3949e-03, 8.9958e-04, 1.7573e-03, 3.7968e-03, 3.0718e-03,
        1.0705e-03, 1.5897e-03, 1.6300e-03, 1.9559e-03, 1.4576e-03, 1.3286e-03,
        6.2786e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,099][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Stephanie] are: tensor([0.5048, 0.0307, 0.0377, 0.0330, 0.0341, 0.0340, 0.0649, 0.0433, 0.0338,
        0.0564, 0.0413, 0.0383, 0.0478], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,100][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([1.2556e-04, 4.1183e-02, 7.3884e-02, 1.2639e-01, 1.7634e-01, 2.0339e-01,
        4.5744e-02, 9.2980e-02, 2.5990e-02, 5.0009e-02, 6.0512e-02, 1.6504e-02,
        4.9601e-02, 3.7354e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,101][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([4.2287e-05, 2.8404e-02, 8.1132e-03, 1.7422e-01, 1.6082e-03, 1.7372e-02,
        3.7307e-02, 8.0254e-02, 1.4336e-01, 1.3763e-01, 2.7062e-01, 6.0764e-02,
        4.3063e-03, 3.6000e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,103][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.1729, 0.0552, 0.0621, 0.0698, 0.0596, 0.0463, 0.0584, 0.0675, 0.0883,
        0.0668, 0.0747, 0.0549, 0.0584, 0.0650], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,104][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.5468, 0.0312, 0.0396, 0.0147, 0.0292, 0.0362, 0.0558, 0.0522, 0.0510,
        0.0205, 0.0234, 0.0264, 0.0383, 0.0348], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,106][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0247, 0.0166, 0.0607, 0.2146, 0.0174, 0.0103, 0.0121, 0.0404, 0.0138,
        0.0174, 0.2003, 0.3399, 0.0268, 0.0048], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,108][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0730, 0.0534, 0.0678, 0.0678, 0.0654, 0.0824, 0.0720, 0.0701, 0.0742,
        0.0855, 0.0753, 0.0745, 0.0699, 0.0686], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,109][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0216, 0.0324, 0.0318, 0.0386, 0.0666, 0.0071, 0.0006, 0.0089, 0.1849,
        0.2250, 0.1318, 0.1332, 0.0871, 0.0302], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,111][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.1268, 0.0770, 0.0660, 0.0650, 0.0552, 0.0574, 0.0658, 0.0596, 0.0691,
        0.0692, 0.0752, 0.0690, 0.0647, 0.0798], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,113][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.1114, 0.0257, 0.0607, 0.0555, 0.0927, 0.0605, 0.0479, 0.0771, 0.0472,
        0.0795, 0.0852, 0.0878, 0.1068, 0.0620], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,115][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.6715, 0.0157, 0.0199, 0.0380, 0.0140, 0.0665, 0.0314, 0.0195, 0.0325,
        0.0284, 0.0212, 0.0181, 0.0051, 0.0183], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,117][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.9294, 0.0151, 0.0038, 0.0055, 0.0026, 0.0072, 0.0044, 0.0015, 0.0031,
        0.0104, 0.0050, 0.0049, 0.0032, 0.0038], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,118][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.4807, 0.0301, 0.0296, 0.0420, 0.0296, 0.0325, 0.0595, 0.0252, 0.0383,
        0.0487, 0.0472, 0.0355, 0.0420, 0.0592], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,120][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0008, 0.0354, 0.0404, 0.1736, 0.1634, 0.1016, 0.0482, 0.1131, 0.0224,
        0.0772, 0.0768, 0.0179, 0.0486, 0.0325, 0.0480], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,122][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([5.9628e-05, 2.6064e-02, 2.0685e-03, 1.5624e-01, 4.6992e-04, 6.8204e-03,
        2.0184e-02, 5.1772e-02, 8.8134e-02, 1.4116e-01, 3.6074e-01, 5.1290e-02,
        2.1060e-03, 8.1191e-03, 8.4772e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,124][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1750, 0.0503, 0.0573, 0.0639, 0.0565, 0.0441, 0.0529, 0.0611, 0.0827,
        0.0618, 0.0672, 0.0534, 0.0537, 0.0621, 0.0582], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,125][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.5924, 0.0334, 0.0295, 0.0125, 0.0222, 0.0283, 0.0413, 0.0395, 0.0430,
        0.0173, 0.0173, 0.0195, 0.0293, 0.0310, 0.0435], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,127][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0298, 0.0043, 0.0962, 0.0331, 0.0853, 0.0208, 0.0361, 0.0534, 0.0402,
        0.0079, 0.0388, 0.3170, 0.1760, 0.0434, 0.0175], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,129][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0805, 0.0537, 0.0636, 0.0638, 0.0590, 0.0792, 0.0655, 0.0654, 0.0654,
        0.0742, 0.0705, 0.0646, 0.0617, 0.0656, 0.0674], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,131][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1233, 0.0053, 0.0147, 0.0061, 0.0868, 0.0072, 0.0017, 0.0079, 0.2865,
        0.0449, 0.0242, 0.1549, 0.1860, 0.0502, 0.0004], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,132][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1145, 0.0710, 0.0613, 0.0603, 0.0516, 0.0540, 0.0609, 0.0557, 0.0639,
        0.0640, 0.0695, 0.0634, 0.0596, 0.0732, 0.0769], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,134][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2114, 0.0188, 0.0538, 0.0429, 0.0767, 0.0462, 0.0386, 0.0732, 0.0417,
        0.0587, 0.0647, 0.0699, 0.0887, 0.0500, 0.0647], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,136][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.6269, 0.0195, 0.0241, 0.0403, 0.0165, 0.0717, 0.0345, 0.0198, 0.0330,
        0.0272, 0.0188, 0.0170, 0.0055, 0.0189, 0.0262], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,137][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([9.8444e-01, 3.6558e-03, 7.8886e-04, 1.1915e-03, 3.9077e-04, 1.1664e-03,
        6.0738e-04, 2.5354e-04, 4.0437e-04, 2.9639e-03, 1.5137e-03, 6.5423e-04,
        4.2331e-04, 5.1660e-04, 1.0273e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,139][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.5119, 0.0315, 0.0269, 0.0432, 0.0232, 0.0277, 0.0597, 0.0260, 0.0240,
        0.0509, 0.0467, 0.0315, 0.0279, 0.0289, 0.0398], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,143][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:25:40,144][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 5890],
        [22613],
        [12528],
        [ 6020],
        [ 9193],
        [ 7575],
        [ 7021],
        [ 4547],
        [11303],
        [ 6215],
        [ 6420],
        [ 5414],
        [13061],
        [ 6222],
        [ 7752]], device='cuda:0')
[2024-07-24 10:25:40,146][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 6056],
        [11751],
        [24680],
        [ 5241],
        [14210],
        [ 7665],
        [ 4902],
        [ 6522],
        [13052],
        [ 6041],
        [ 6313],
        [ 6645],
        [16122],
        [ 6576],
        [ 7115]], device='cuda:0')
[2024-07-24 10:25:40,148][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 3322],
        [ 5351],
        [ 4612],
        [ 4942],
        [ 8307],
        [ 9918],
        [ 8927],
        [ 9734],
        [ 9104],
        [11359],
        [12695],
        [11017],
        [12636],
        [12170],
        [13233]], device='cuda:0')
[2024-07-24 10:25:40,149][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 2992],
        [13975],
        [ 9778],
        [11554],
        [10667],
        [10221],
        [10602],
        [ 9804],
        [ 9937],
        [10139],
        [10201],
        [11028],
        [10800],
        [10722],
        [11123]], device='cuda:0')
[2024-07-24 10:25:40,151][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[17567],
        [18352],
        [19133],
        [17788],
        [16920],
        [15512],
        [15170],
        [15285],
        [15211],
        [14747],
        [14438],
        [14197],
        [14224],
        [14235],
        [13825]], device='cuda:0')
[2024-07-24 10:25:40,153][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[18552],
        [20011],
        [20516],
        [20904],
        [21085],
        [20816],
        [20684],
        [20732],
        [20677],
        [20605],
        [20751],
        [20790],
        [21134],
        [21215],
        [21152]], device='cuda:0')
[2024-07-24 10:25:40,154][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[4327],
        [3330],
        [3923],
        [4000],
        [4615],
        [4372],
        [4477],
        [4567],
        [4745],
        [4745],
        [4756],
        [4942],
        [5109],
        [5284],
        [5213]], device='cuda:0')
[2024-07-24 10:25:40,156][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 8270],
        [10378],
        [12003],
        [14514],
        [15476],
        [15042],
        [14901],
        [15197],
        [16033],
        [16796],
        [17197],
        [16410],
        [18733],
        [18190],
        [18072]], device='cuda:0')
[2024-07-24 10:25:40,158][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[24259],
        [47052],
        [48230],
        [48368],
        [48843],
        [49001],
        [48764],
        [48139],
        [48196],
        [47648],
        [46904],
        [46865],
        [47244],
        [46585],
        [46305]], device='cuda:0')
[2024-07-24 10:25:40,159][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[32212],
        [31296],
        [31031],
        [30733],
        [31221],
        [31001],
        [31339],
        [31425],
        [31658],
        [31948],
        [32204],
        [32353],
        [32761],
        [32918],
        [33129]], device='cuda:0')
[2024-07-24 10:25:40,161][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[44028],
        [44682],
        [44028],
        [43733],
        [42670],
        [42147],
        [41888],
        [42194],
        [42518],
        [42209],
        [42362],
        [42426],
        [42414],
        [42392],
        [42203]], device='cuda:0')
[2024-07-24 10:25:40,163][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[36660],
        [36241],
        [35492],
        [35051],
        [35239],
        [35261],
        [31208],
        [32106],
        [30923],
        [30505],
        [30509],
        [29159],
        [31046],
        [29796],
        [27480]], device='cuda:0')
[2024-07-24 10:25:40,164][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 5634],
        [ 9947],
        [ 7182],
        [ 9018],
        [ 8924],
        [ 8309],
        [ 9070],
        [ 9283],
        [ 9873],
        [10336],
        [10894],
        [11240],
        [10968],
        [11048],
        [11179]], device='cuda:0')
[2024-07-24 10:25:40,166][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[14662],
        [11949],
        [11419],
        [ 9431],
        [ 8589],
        [ 8417],
        [ 8067],
        [ 7604],
        [ 6854],
        [ 6667],
        [ 6153],
        [ 5808],
        [ 5714],
        [ 5467],
        [ 5291]], device='cuda:0')
[2024-07-24 10:25:40,167][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[38610],
        [31740],
        [ 3841],
        [31209],
        [10639],
        [ 5899],
        [18860],
        [18802],
        [24136],
        [27107],
        [12095],
        [21017],
        [ 6990],
        [13668],
        [17985]], device='cuda:0')
[2024-07-24 10:25:40,169][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[22871],
        [22632],
        [25311],
        [27172],
        [29120],
        [28743],
        [29498],
        [28769],
        [29807],
        [30922],
        [31788],
        [30266],
        [31316],
        [31341],
        [32407]], device='cuda:0')
[2024-07-24 10:25:40,171][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[30469],
        [ 6125],
        [ 7134],
        [10097],
        [ 9787],
        [10674],
        [ 9986],
        [ 8867],
        [ 9476],
        [ 9787],
        [ 9513],
        [ 8624],
        [ 9137],
        [ 8221],
        [ 7581]], device='cuda:0')
[2024-07-24 10:25:40,172][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[3619],
        [2330],
        [1791],
        [1515],
        [1330],
        [1352],
        [1315],
        [1263],
        [1165],
        [1084],
        [ 999],
        [ 996],
        [ 968],
        [ 986],
        [1000]], device='cuda:0')
[2024-07-24 10:25:40,174][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[29024],
        [28875],
        [28267],
        [28563],
        [29566],
        [29160],
        [28857],
        [28584],
        [28003],
        [29290],
        [28684],
        [28390],
        [28774],
        [29276],
        [28977]], device='cuda:0')
[2024-07-24 10:25:40,176][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[19400],
        [13050],
        [ 4210],
        [ 3558],
        [ 2076],
        [ 2598],
        [ 2933],
        [ 2258],
        [ 1596],
        [ 6288],
        [ 6913],
        [ 2762],
        [ 1651],
        [ 1385],
        [ 2124]], device='cuda:0')
[2024-07-24 10:25:40,178][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[13369],
        [15055],
        [11087],
        [11979],
        [10178],
        [10401],
        [10723],
        [11563],
        [11359],
        [11626],
        [12091],
        [12452],
        [11975],
        [12051],
        [12113]], device='cuda:0')
[2024-07-24 10:25:40,179][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[31156],
        [33361],
        [33016],
        [30710],
        [31374],
        [28608],
        [29094],
        [29997],
        [29531],
        [23143],
        [24078],
        [31320],
        [31189],
        [29154],
        [25377]], device='cuda:0')
[2024-07-24 10:25:40,181][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[35107],
        [35211],
        [34643],
        [33976],
        [34241],
        [34275],
        [33468],
        [33133],
        [32752],
        [32039],
        [31438],
        [31375],
        [31351],
        [30993],
        [30586]], device='cuda:0')
[2024-07-24 10:25:40,182][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[27211],
        [33051],
        [33933],
        [32851],
        [34106],
        [33106],
        [31837],
        [29726],
        [29218],
        [27678],
        [25785],
        [25385],
        [25821],
        [26712],
        [26737]], device='cuda:0')
[2024-07-24 10:25:40,184][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[25376],
        [25043],
        [23695],
        [21500],
        [21396],
        [21240],
        [20782],
        [20682],
        [20276],
        [20984],
        [21595],
        [22070],
        [22493],
        [22200],
        [21945]], device='cuda:0')
[2024-07-24 10:25:40,186][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[28495],
        [28516],
        [28563],
        [28654],
        [28965],
        [28677],
        [28605],
        [28598],
        [28573],
        [28792],
        [28557],
        [29166],
        [28947],
        [29098],
        [28738]], device='cuda:0')
[2024-07-24 10:25:40,187][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 4806],
        [ 5915],
        [ 6777],
        [ 7254],
        [ 9414],
        [11860],
        [10753],
        [10603],
        [14894],
        [16076],
        [15247],
        [15795],
        [18014],
        [18586],
        [17350]], device='cuda:0')
[2024-07-24 10:25:40,189][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[10510],
        [12194],
        [15647],
        [15278],
        [16759],
        [15766],
        [15932],
        [17744],
        [18442],
        [15087],
        [15215],
        [16972],
        [16366],
        [17333],
        [16465]], device='cuda:0')
[2024-07-24 10:25:40,191][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 7335],
        [28229],
        [33868],
        [29179],
        [33158],
        [47692],
        [43896],
        [33771],
        [32626],
        [28186],
        [39541],
        [27369],
        [38534],
        [36581],
        [36728]], device='cuda:0')
[2024-07-24 10:25:40,192][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[26695],
        [26695],
        [26695],
        [26695],
        [26695],
        [26695],
        [26695],
        [26695],
        [26695],
        [26695],
        [26695],
        [26695],
        [26695],
        [26695],
        [26695]], device='cuda:0')
[2024-07-24 10:25:40,250][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:40,252][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,253][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,254][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,256][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,257][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,257][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,258][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,259][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,259][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,260][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,261][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,261][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,262][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0514, 0.9486], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:40,263][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0419, 0.9581], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:40,264][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.5208, 0.4792], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:40,264][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6037, 0.3963], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:40,265][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9079, 0.0921], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:40,266][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.5437, 0.4563], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:40,266][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([9.9926e-01, 7.4029e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:40,268][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.4067, 0.5933], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:40,270][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2598, 0.7402], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:40,271][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.6739, 0.3261], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:40,272][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7166, 0.2834], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:40,274][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.9964, 0.0036], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:40,276][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Jose] are: tensor([0.0354, 0.4929, 0.4717], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:40,277][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Jose] are: tensor([0.0224, 0.5387, 0.4389], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:40,279][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Jose] are: tensor([0.3273, 0.2849, 0.3879], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:40,281][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Jose] are: tensor([0.4025, 0.2636, 0.3339], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:40,282][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Jose] are: tensor([0.9358, 0.0491, 0.0152], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:40,284][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Jose] are: tensor([0.3147, 0.3525, 0.3328], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:40,285][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Jose] are: tensor([0.9930, 0.0015, 0.0055], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:40,287][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Jose] are: tensor([0.2252, 0.6219, 0.1529], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:40,289][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Jose] are: tensor([0.1976, 0.4591, 0.3433], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:40,290][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Jose] are: tensor([0.7376, 0.2453, 0.0171], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:40,292][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Jose] are: tensor([0.7004, 0.1593, 0.1403], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:40,293][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Jose] are: tensor([0.8803, 0.0517, 0.0681], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:40,295][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0223, 0.3730, 0.3422, 0.2625], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:40,296][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0115, 0.3332, 0.2702, 0.3852], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:40,298][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2610, 0.1872, 0.2760, 0.2758], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:40,300][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3251, 0.2030, 0.2500, 0.2219], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:40,300][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.9379, 0.0395, 0.0111, 0.0115], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:40,301][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2060, 0.2438, 0.2868, 0.2635], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:40,302][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([9.9502e-01, 7.9226e-04, 3.8206e-03, 3.6732e-04], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:40,303][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3193, 0.4190, 0.1011, 0.1606], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:40,304][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1268, 0.3383, 0.2526, 0.2822], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:40,306][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4646, 0.1327, 0.3980, 0.0047], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:40,307][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.6984, 0.1128, 0.0893, 0.0995], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:40,309][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.9404, 0.0078, 0.0483, 0.0035], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:40,310][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Stephanie] are: tensor([0.0154, 0.2587, 0.2512, 0.2084, 0.2664], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:40,312][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Stephanie] are: tensor([0.0092, 0.2643, 0.2138, 0.3133, 0.1995], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:40,314][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Stephanie] are: tensor([0.1830, 0.1598, 0.2183, 0.2366, 0.2022], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:40,315][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Stephanie] are: tensor([0.2460, 0.1555, 0.2189, 0.2029, 0.1767], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:40,317][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Stephanie] are: tensor([0.9023, 0.0553, 0.0164, 0.0166, 0.0095], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:40,319][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Stephanie] are: tensor([0.1145, 0.1544, 0.2256, 0.2436, 0.2619], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:40,320][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Stephanie] are: tensor([9.8827e-01, 1.3567e-03, 5.1720e-03, 6.2333e-04, 4.5775e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:40,321][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Stephanie] are: tensor([0.1729, 0.3641, 0.0912, 0.1852, 0.1866], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:40,323][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Stephanie] are: tensor([0.1034, 0.2615, 0.2027, 0.2407, 0.1917], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:40,324][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Stephanie] are: tensor([0.5496, 0.3812, 0.0458, 0.0206, 0.0027], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:40,326][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Stephanie] are: tensor([0.6194, 0.1089, 0.0887, 0.1036, 0.0795], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:40,328][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Stephanie] are: tensor([0.7354, 0.0485, 0.1173, 0.0298, 0.0690], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:40,329][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0135, 0.2073, 0.1951, 0.1541, 0.2114, 0.2186], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:40,331][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0081, 0.2038, 0.1660, 0.2379, 0.1528, 0.2314], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:40,333][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.1492, 0.1369, 0.1652, 0.1873, 0.1599, 0.2015], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:40,334][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1807, 0.1385, 0.1997, 0.1682, 0.1822, 0.1307], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:40,336][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.9286, 0.0383, 0.0108, 0.0110, 0.0060, 0.0053], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:40,338][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0876, 0.1409, 0.1756, 0.2254, 0.2383, 0.1322], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:40,339][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ had] are: tensor([9.9764e-01, 2.8861e-04, 1.2152e-03, 5.6183e-05, 6.1637e-04, 1.8550e-04],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:40,340][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.3598, 0.2354, 0.0569, 0.1220, 0.1318, 0.0941], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:40,342][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0932, 0.2056, 0.1591, 0.1837, 0.1597, 0.1986], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:40,344][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.7688, 0.0744, 0.0243, 0.0061, 0.1251, 0.0013], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:40,345][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.5317, 0.1125, 0.0886, 0.0982, 0.0761, 0.0928], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:40,345][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.6815, 0.0158, 0.0474, 0.0137, 0.0579, 0.1836], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:40,346][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0118, 0.1816, 0.1652, 0.1345, 0.1789, 0.1893, 0.1386],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:40,347][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0058, 0.1709, 0.1359, 0.1996, 0.1259, 0.1905, 0.1713],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:40,348][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1166, 0.1077, 0.1525, 0.1588, 0.1544, 0.1939, 0.1162],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:40,350][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1779, 0.1170, 0.1706, 0.1466, 0.1466, 0.1275, 0.1138],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:40,352][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.9253, 0.0372, 0.0096, 0.0104, 0.0055, 0.0048, 0.0073],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:40,353][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0643, 0.1379, 0.1791, 0.1770, 0.2483, 0.1267, 0.0668],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:40,354][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([9.9141e-01, 9.2134e-04, 3.5893e-03, 2.5327e-04, 2.3522e-03, 3.4713e-04,
        1.1219e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:40,356][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.2628, 0.2857, 0.0698, 0.1127, 0.1057, 0.0999, 0.0633],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:40,358][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0658, 0.1769, 0.1334, 0.1545, 0.1341, 0.1787, 0.1566],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:40,359][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.4784, 0.2866, 0.0698, 0.0383, 0.0960, 0.0290, 0.0019],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:40,361][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.5400, 0.0953, 0.0728, 0.0803, 0.0604, 0.0775, 0.0738],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:40,363][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.8504, 0.0056, 0.0164, 0.0030, 0.0164, 0.0949, 0.0133],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:40,364][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0093, 0.1562, 0.1385, 0.1156, 0.1527, 0.1695, 0.1329, 0.1252],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,366][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0049, 0.1500, 0.1190, 0.1782, 0.1098, 0.1681, 0.1533, 0.1167],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,368][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.1062, 0.0917, 0.1235, 0.1322, 0.1050, 0.1673, 0.0815, 0.1927],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,369][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.1573, 0.1021, 0.1453, 0.1256, 0.1255, 0.1086, 0.1065, 0.1291],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,371][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.8941, 0.0491, 0.0139, 0.0137, 0.0076, 0.0065, 0.0091, 0.0061],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,373][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0501, 0.1342, 0.1354, 0.2271, 0.1761, 0.1302, 0.0648, 0.0821],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,374][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ long] are: tensor([9.9456e-01, 4.8863e-04, 2.2044e-03, 1.6836e-04, 1.0410e-03, 1.5596e-04,
        1.9665e-04, 1.1816e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,376][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.1848, 0.2051, 0.0590, 0.1066, 0.1049, 0.1004, 0.0948, 0.1444],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,377][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0691, 0.1529, 0.1110, 0.1292, 0.1126, 0.1435, 0.1440, 0.1378],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,378][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ long] are: tensor([7.6386e-01, 1.1019e-01, 3.5933e-02, 6.1220e-03, 7.4004e-02, 3.8859e-03,
        5.5347e-03, 4.6490e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,380][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.4320, 0.0950, 0.0741, 0.0844, 0.0638, 0.0796, 0.0766, 0.0946],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,382][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.8258, 0.0058, 0.0215, 0.0033, 0.0151, 0.0840, 0.0279, 0.0165],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,384][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0083, 0.1322, 0.1233, 0.1040, 0.1307, 0.1420, 0.1156, 0.1118, 0.1322],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,385][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0044, 0.1329, 0.1060, 0.1613, 0.0974, 0.1500, 0.1375, 0.1041, 0.1066],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,387][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.1020, 0.0760, 0.1023, 0.1101, 0.1065, 0.1495, 0.0754, 0.1671, 0.1110],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,389][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.1464, 0.0939, 0.1210, 0.1121, 0.1096, 0.0942, 0.0959, 0.1125, 0.1145],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,389][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.8067, 0.0699, 0.0227, 0.0246, 0.0141, 0.0124, 0.0174, 0.0119, 0.0203],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,390][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0447, 0.1279, 0.1223, 0.2013, 0.1580, 0.0974, 0.0681, 0.1149, 0.0653],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,391][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([9.9065e-01, 6.9437e-04, 2.9723e-03, 1.9099e-04, 1.5911e-03, 1.9186e-04,
        2.5455e-04, 7.4741e-04, 2.7122e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,392][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.1806, 0.1658, 0.0465, 0.1044, 0.0814, 0.1114, 0.0876, 0.1504, 0.0719],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,393][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0559, 0.1333, 0.0986, 0.1194, 0.0973, 0.1283, 0.1264, 0.1242, 0.1167],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,395][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.4451, 0.3558, 0.0969, 0.0084, 0.0491, 0.0224, 0.0066, 0.0123, 0.0033],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,397][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.3974, 0.0825, 0.0656, 0.0741, 0.0570, 0.0687, 0.0689, 0.0866, 0.0992],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,398][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.6919, 0.0091, 0.0296, 0.0050, 0.0205, 0.0782, 0.0389, 0.0590, 0.0679],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,400][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0063, 0.1195, 0.1093, 0.0858, 0.1221, 0.1311, 0.0995, 0.1006, 0.1340,
        0.0917], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,402][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0032, 0.1184, 0.0948, 0.1401, 0.0862, 0.1353, 0.1221, 0.0936, 0.0959,
        0.1103], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,404][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0840, 0.0717, 0.0997, 0.1101, 0.0881, 0.1218, 0.0781, 0.1585, 0.0976,
        0.0904], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,405][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1243, 0.0832, 0.1134, 0.0973, 0.0988, 0.0909, 0.0885, 0.1085, 0.1078,
        0.0873], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,407][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.8301, 0.0605, 0.0188, 0.0197, 0.0108, 0.0096, 0.0132, 0.0089, 0.0160,
        0.0123], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,409][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0657, 0.0814, 0.1143, 0.1267, 0.1842, 0.1148, 0.0553, 0.0890, 0.0956,
        0.0731], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,410][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([9.9313e-01, 5.5167e-04, 3.6043e-03, 1.9005e-04, 1.2225e-03, 1.0170e-04,
        1.9161e-04, 3.1555e-04, 6.1904e-04, 7.4470e-05], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,412][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.4707, 0.1572, 0.0489, 0.0632, 0.0706, 0.0456, 0.0309, 0.0551, 0.0224,
        0.0354], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,413][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0428, 0.1154, 0.0864, 0.0995, 0.0898, 0.1213, 0.1156, 0.1139, 0.1156,
        0.0996], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,415][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1275, 0.0576, 0.2211, 0.0042, 0.0957, 0.0694, 0.0284, 0.0209, 0.3644,
        0.0108], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,417][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.3831, 0.0766, 0.0590, 0.0654, 0.0502, 0.0646, 0.0614, 0.0755, 0.0838,
        0.0804], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,418][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.5597, 0.0026, 0.0255, 0.0018, 0.0259, 0.1079, 0.0242, 0.0410, 0.2086,
        0.0028], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,420][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0052, 0.1102, 0.1024, 0.0777, 0.1160, 0.1243, 0.0906, 0.0940, 0.1259,
        0.0852, 0.0685], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,422][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0030, 0.1059, 0.0852, 0.1252, 0.0775, 0.1227, 0.1097, 0.0840, 0.0859,
        0.1004, 0.1004], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,423][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0900, 0.0665, 0.0963, 0.0931, 0.0885, 0.1022, 0.0667, 0.1490, 0.0908,
        0.0726, 0.0842], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,425][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1185, 0.0821, 0.0959, 0.0899, 0.0861, 0.0809, 0.0817, 0.0967, 0.0893,
        0.0851, 0.0937], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,427][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.8167, 0.0606, 0.0185, 0.0192, 0.0107, 0.0095, 0.0132, 0.0094, 0.0164,
        0.0126, 0.0132], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,429][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0600, 0.0903, 0.1107, 0.0956, 0.1695, 0.1008, 0.0483, 0.0802, 0.0820,
        0.0751, 0.0875], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,430][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([9.8450e-01, 1.2568e-03, 6.7053e-03, 6.6830e-04, 2.8406e-03, 2.4979e-04,
        4.4197e-04, 8.2806e-04, 1.8525e-03, 1.4526e-04, 5.1005e-04],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,432][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3984, 0.1370, 0.0432, 0.0672, 0.0884, 0.0432, 0.0293, 0.0554, 0.0232,
        0.0442, 0.0704], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,433][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0301, 0.1041, 0.0778, 0.0877, 0.0831, 0.1105, 0.1066, 0.1092, 0.1095,
        0.0960, 0.0853], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,434][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2060, 0.0721, 0.2022, 0.0012, 0.0777, 0.0816, 0.0147, 0.0129, 0.3169,
        0.0136, 0.0011], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,435][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4140, 0.0639, 0.0474, 0.0529, 0.0404, 0.0526, 0.0501, 0.0630, 0.0709,
        0.0675, 0.0772], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,436][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.5441, 0.0035, 0.0277, 0.0016, 0.0337, 0.1248, 0.0270, 0.0312, 0.2009,
        0.0040, 0.0015], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,438][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0062, 0.0951, 0.0902, 0.0770, 0.0980, 0.1051, 0.0908, 0.0852, 0.1064,
        0.0798, 0.0714, 0.0948], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,439][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0027, 0.0993, 0.0797, 0.1215, 0.0727, 0.1134, 0.1036, 0.0779, 0.0804,
        0.0931, 0.0939, 0.0617], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,441][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0664, 0.0568, 0.0697, 0.0966, 0.0670, 0.1114, 0.0547, 0.1313, 0.0864,
        0.0770, 0.0918, 0.0908], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,443][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0985, 0.0668, 0.0885, 0.0823, 0.0793, 0.0739, 0.0717, 0.0871, 0.0884,
        0.0790, 0.0884, 0.0962], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,444][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.7501, 0.0710, 0.0203, 0.0226, 0.0133, 0.0113, 0.0173, 0.0120, 0.0183,
        0.0169, 0.0167, 0.0304], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,446][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0337, 0.0909, 0.0874, 0.1299, 0.1022, 0.0859, 0.0431, 0.0797, 0.0517,
        0.0849, 0.1095, 0.1011], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,447][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([8.8351e-01, 5.5889e-03, 1.2394e-02, 2.0434e-03, 1.2317e-02, 1.4598e-03,
        2.1033e-03, 8.3976e-03, 1.1409e-02, 6.5984e-04, 1.2847e-03, 5.8832e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,449][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.2037, 0.1939, 0.0590, 0.0713, 0.0701, 0.0608, 0.0434, 0.0879, 0.0291,
        0.0600, 0.0924, 0.0284], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,451][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0292, 0.0985, 0.0735, 0.0886, 0.0757, 0.0984, 0.0970, 0.0967, 0.0953,
        0.0907, 0.0857, 0.0708], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,452][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.5641, 0.1623, 0.0539, 0.0111, 0.0533, 0.0209, 0.0088, 0.0027, 0.0774,
        0.0296, 0.0119, 0.0039], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,454][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.2904, 0.0699, 0.0553, 0.0636, 0.0484, 0.0562, 0.0567, 0.0682, 0.0765,
        0.0694, 0.0809, 0.0645], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,456][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.3464, 0.0152, 0.0259, 0.0057, 0.0294, 0.1361, 0.0690, 0.0714, 0.2096,
        0.0157, 0.0054, 0.0700], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,458][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Stephanie] are: tensor([0.0057, 0.0892, 0.0853, 0.0721, 0.0899, 0.0958, 0.0757, 0.0766, 0.0969,
        0.0732, 0.0663, 0.0916, 0.0817], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,459][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Stephanie] are: tensor([0.0028, 0.0938, 0.0758, 0.1117, 0.0696, 0.1070, 0.0967, 0.0735, 0.0759,
        0.0874, 0.0877, 0.0591, 0.0589], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,461][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Stephanie] are: tensor([0.0575, 0.0540, 0.0725, 0.0779, 0.0587, 0.0991, 0.0499, 0.1322, 0.0834,
        0.0690, 0.0744, 0.1123, 0.0591], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,463][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Stephanie] are: tensor([0.0908, 0.0585, 0.0822, 0.0757, 0.0680, 0.0760, 0.0615, 0.0794, 0.0795,
        0.0713, 0.0806, 0.1016, 0.0750], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,465][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Stephanie] are: tensor([0.7901, 0.0527, 0.0161, 0.0170, 0.0106, 0.0087, 0.0133, 0.0093, 0.0152,
        0.0125, 0.0131, 0.0291, 0.0124], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,466][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Stephanie] are: tensor([0.0426, 0.0549, 0.0939, 0.0875, 0.1040, 0.0767, 0.0288, 0.0563, 0.0598,
        0.0524, 0.0800, 0.1584, 0.1047], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,468][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Stephanie] are: tensor([9.1288e-01, 3.1752e-03, 1.1261e-02, 1.4087e-03, 1.2262e-02, 1.0525e-03,
        1.9736e-03, 5.5033e-03, 7.1139e-03, 6.7146e-04, 1.3021e-03, 2.3802e-02,
        1.7598e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,470][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Stephanie] are: tensor([0.0613, 0.0821, 0.0329, 0.0996, 0.0795, 0.0643, 0.0474, 0.0714, 0.0354,
        0.1054, 0.1654, 0.0519, 0.1033], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,471][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Stephanie] are: tensor([0.0336, 0.0911, 0.0686, 0.0836, 0.0641, 0.0939, 0.0861, 0.0915, 0.0870,
        0.0868, 0.0827, 0.0679, 0.0631], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,473][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Stephanie] are: tensor([0.2219, 0.4980, 0.0363, 0.0173, 0.0023, 0.0725, 0.0102, 0.0136, 0.0728,
        0.0311, 0.0094, 0.0123, 0.0023], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,475][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Stephanie] are: tensor([0.4850, 0.0480, 0.0370, 0.0445, 0.0311, 0.0386, 0.0371, 0.0484, 0.0553,
        0.0481, 0.0595, 0.0437, 0.0237], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,476][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Stephanie] are: tensor([0.3955, 0.0129, 0.0343, 0.0082, 0.0210, 0.1170, 0.0417, 0.0995, 0.1391,
        0.0136, 0.0078, 0.0769, 0.0323], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,477][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0038, 0.0814, 0.0796, 0.0624, 0.0885, 0.0885, 0.0677, 0.0695, 0.0904,
        0.0648, 0.0582, 0.0855, 0.0814, 0.0784], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,478][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0030, 0.0881, 0.0701, 0.1063, 0.0640, 0.0995, 0.0910, 0.0686, 0.0698,
        0.0826, 0.0836, 0.0541, 0.0538, 0.0656], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,479][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0513, 0.0494, 0.0695, 0.0823, 0.0572, 0.1014, 0.0573, 0.1163, 0.0738,
        0.0675, 0.0790, 0.0821, 0.0545, 0.0583], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,480][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0810, 0.0576, 0.0742, 0.0663, 0.0707, 0.0638, 0.0598, 0.0712, 0.0845,
        0.0661, 0.0706, 0.0918, 0.0767, 0.0656], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,482][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.6644, 0.0719, 0.0227, 0.0241, 0.0148, 0.0128, 0.0193, 0.0139, 0.0211,
        0.0188, 0.0185, 0.0312, 0.0151, 0.0514], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,483][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0237, 0.0674, 0.0809, 0.0964, 0.1093, 0.0646, 0.0366, 0.0569, 0.0500,
        0.0568, 0.0852, 0.1422, 0.1034, 0.0266], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,485][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ said] are: tensor([8.6092e-01, 3.6388e-03, 1.5463e-02, 8.7712e-04, 1.1637e-02, 1.1208e-03,
        1.5183e-03, 2.4356e-03, 8.6972e-03, 4.2038e-04, 7.1742e-04, 2.2757e-02,
        1.3645e-02, 5.6148e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,486][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.3276, 0.1307, 0.0419, 0.0592, 0.0686, 0.0361, 0.0283, 0.0513, 0.0187,
        0.0349, 0.0609, 0.0353, 0.0575, 0.0491], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,488][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0269, 0.0834, 0.0652, 0.0751, 0.0655, 0.0862, 0.0809, 0.0845, 0.0819,
        0.0769, 0.0730, 0.0644, 0.0645, 0.0716], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,490][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.2112, 0.2248, 0.0878, 0.0077, 0.1782, 0.0127, 0.0044, 0.0096, 0.0104,
        0.0232, 0.0094, 0.0525, 0.1644, 0.0038], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,492][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.2886, 0.0616, 0.0486, 0.0527, 0.0414, 0.0509, 0.0469, 0.0574, 0.0644,
        0.0626, 0.0726, 0.0560, 0.0364, 0.0598], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,494][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.3644, 0.0074, 0.0553, 0.0085, 0.0232, 0.1238, 0.0398, 0.0604, 0.1314,
        0.0121, 0.0097, 0.0645, 0.0376, 0.0620], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,495][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0036, 0.0785, 0.0725, 0.0579, 0.0818, 0.0850, 0.0658, 0.0665, 0.0863,
        0.0617, 0.0524, 0.0780, 0.0756, 0.0764, 0.0582], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,497][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0026, 0.0823, 0.0670, 0.0982, 0.0613, 0.0945, 0.0855, 0.0650, 0.0669,
        0.0767, 0.0763, 0.0518, 0.0513, 0.0616, 0.0588], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,499][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0556, 0.0485, 0.0650, 0.0698, 0.0563, 0.0718, 0.0478, 0.1091, 0.0579,
        0.0570, 0.0658, 0.0903, 0.0546, 0.0521, 0.0983], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,500][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0845, 0.0535, 0.0746, 0.0628, 0.0637, 0.0608, 0.0563, 0.0694, 0.0691,
        0.0610, 0.0656, 0.0833, 0.0675, 0.0634, 0.0643], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,502][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.6176, 0.0659, 0.0219, 0.0235, 0.0144, 0.0124, 0.0186, 0.0136, 0.0203,
        0.0185, 0.0177, 0.0290, 0.0146, 0.0471, 0.0649], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,504][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0467, 0.0525, 0.0778, 0.0723, 0.1146, 0.0612, 0.0346, 0.0553, 0.0479,
        0.0536, 0.0707, 0.1141, 0.1148, 0.0351, 0.0489], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,505][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([9.4265e-01, 1.9034e-03, 1.1762e-02, 5.9128e-04, 5.5323e-03, 4.8974e-04,
        7.9207e-04, 7.5706e-04, 3.1350e-03, 2.0558e-04, 4.2605e-04, 1.4364e-02,
        7.0151e-03, 6.8176e-03, 3.5547e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,507][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.3424, 0.1337, 0.0354, 0.0538, 0.0591, 0.0261, 0.0206, 0.0353, 0.0150,
        0.0299, 0.0507, 0.0173, 0.0507, 0.0510, 0.0790], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,509][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0273, 0.0768, 0.0591, 0.0679, 0.0609, 0.0791, 0.0781, 0.0783, 0.0779,
        0.0708, 0.0665, 0.0608, 0.0605, 0.0712, 0.0649], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,511][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.4330, 0.1084, 0.0594, 0.0028, 0.0481, 0.0200, 0.0061, 0.0086, 0.1416,
        0.0200, 0.0040, 0.0123, 0.0489, 0.0836, 0.0030], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,512][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.3522, 0.0525, 0.0396, 0.0444, 0.0345, 0.0434, 0.0415, 0.0518, 0.0574,
        0.0545, 0.0620, 0.0483, 0.0284, 0.0490, 0.0404], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,514][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.4975, 0.0029, 0.0206, 0.0021, 0.0205, 0.0739, 0.0233, 0.0313, 0.1744,
        0.0036, 0.0023, 0.0409, 0.0370, 0.0614, 0.0082], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,593][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:40,594][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,595][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,596][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,596][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,597][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,598][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,598][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,599][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,600][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,600][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,601][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,602][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,602][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.6752, 0.3248], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:40,604][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2526, 0.7474], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:40,605][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6450, 0.3550], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:40,607][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.8380, 0.1620], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:40,609][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9985, 0.0015], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:40,610][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.6159, 0.3841], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:40,612][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9826, 0.0174], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:40,613][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4991, 0.5009], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:40,615][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.6852, 0.3148], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:40,616][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0227, 0.9773], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:40,618][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2903, 0.7097], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:40,619][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2937, 0.7063], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:40,620][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Jose] are: tensor([0.8948, 0.0708, 0.0344], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:40,621][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Jose] are: tensor([0.4897, 0.4774, 0.0329], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:40,622][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Jose] are: tensor([0.6265, 0.2431, 0.1304], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:40,623][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Jose] are: tensor([0.9162, 0.0646, 0.0192], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:40,624][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Jose] are: tensor([0.9958, 0.0024, 0.0018], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:40,625][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Jose] are: tensor([0.6435, 0.2604, 0.0961], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:40,627][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Jose] are: tensor([9.9588e-01, 3.1626e-03, 9.5972e-04], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:40,628][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Jose] are: tensor([0.6863, 0.1624, 0.1514], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:40,630][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Jose] are: tensor([0.8921, 0.0908, 0.0171], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:40,631][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Jose] are: tensor([0.0892, 0.7089, 0.2020], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:40,633][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Jose] are: tensor([0.6688, 0.2067, 0.1245], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:40,634][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Jose] are: tensor([0.6309, 0.2613, 0.1077], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:40,636][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.4449, 0.4132, 0.0986, 0.0433], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:40,638][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0462, 0.8275, 0.0614, 0.0650], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:40,639][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4142, 0.2043, 0.1533, 0.2282], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:40,641][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.7270, 0.1522, 0.0901, 0.0306], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:40,642][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.9933, 0.0026, 0.0029, 0.0013], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:40,644][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2218, 0.5066, 0.1322, 0.1395], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:40,646][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.9857, 0.0082, 0.0018, 0.0044], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:40,647][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2954, 0.3946, 0.1906, 0.1195], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:40,649][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.4596, 0.3237, 0.1573, 0.0593], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:40,651][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0108, 0.1841, 0.3301, 0.4750], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:40,652][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4508, 0.2621, 0.1003, 0.1868], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:40,654][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1592, 0.6897, 0.0880, 0.0631], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:40,655][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Stephanie] are: tensor([0.5223, 0.2129, 0.0638, 0.0597, 0.1413], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:40,657][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Stephanie] are: tensor([0.2932, 0.5617, 0.0329, 0.0753, 0.0369], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:40,659][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Stephanie] are: tensor([0.3150, 0.1655, 0.1174, 0.2495, 0.1526], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:40,660][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Stephanie] are: tensor([0.6496, 0.1631, 0.0590, 0.0609, 0.0674], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:40,662][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Stephanie] are: tensor([0.9585, 0.0264, 0.0046, 0.0051, 0.0054], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:40,664][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Stephanie] are: tensor([0.2691, 0.3334, 0.0881, 0.1054, 0.2041], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:40,664][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Stephanie] are: tensor([0.9657, 0.0127, 0.0036, 0.0057, 0.0123], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:40,665][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Stephanie] are: tensor([0.2444, 0.3333, 0.1201, 0.1645, 0.1377], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:40,666][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Stephanie] are: tensor([0.6510, 0.2063, 0.0450, 0.0422, 0.0555], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:40,667][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Stephanie] are: tensor([0.0258, 0.1462, 0.0850, 0.7101, 0.0329], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:40,668][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Stephanie] are: tensor([0.2997, 0.1818, 0.1324, 0.2989, 0.0872], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:40,670][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Stephanie] are: tensor([0.2732, 0.4429, 0.0556, 0.1111, 0.1173], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:40,672][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.6307, 0.1956, 0.0382, 0.0240, 0.0684, 0.0432], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:40,673][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0845, 0.6674, 0.0226, 0.0583, 0.0179, 0.1492], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:40,675][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.3632, 0.1236, 0.0896, 0.1687, 0.1688, 0.0862], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:40,676][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.7573, 0.0785, 0.0421, 0.0186, 0.0641, 0.0393], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:40,678][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([9.9462e-01, 1.7424e-03, 1.5166e-03, 7.0971e-04, 1.0356e-03, 3.7604e-04],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:40,679][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.3679, 0.2214, 0.0702, 0.0811, 0.1251, 0.1343], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:40,681][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.9827, 0.0071, 0.0012, 0.0027, 0.0023, 0.0040], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:40,683][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.2268, 0.3008, 0.0902, 0.0892, 0.1009, 0.1920], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:40,684][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.5805, 0.1964, 0.0469, 0.0396, 0.0659, 0.0707], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:40,686][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0021, 0.0823, 0.4501, 0.2644, 0.1152, 0.0858], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:40,687][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.2802, 0.2040, 0.1594, 0.2165, 0.0362, 0.1037], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:40,689][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.4415, 0.3090, 0.0534, 0.0319, 0.0948, 0.0694], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:40,691][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.3148, 0.3897, 0.0291, 0.0481, 0.0503, 0.1015, 0.0665],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:40,692][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0454, 0.7551, 0.0088, 0.0412, 0.0079, 0.0987, 0.0429],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:40,694][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2726, 0.1312, 0.0756, 0.1370, 0.1109, 0.0982, 0.1745],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:40,696][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.6858, 0.1062, 0.0314, 0.0215, 0.0530, 0.0638, 0.0383],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:40,697][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([9.9370e-01, 2.4636e-03, 1.3713e-03, 7.8174e-04, 8.4989e-04, 3.8390e-04,
        4.4597e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:40,698][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1473, 0.3797, 0.0482, 0.0869, 0.0917, 0.1720, 0.0743],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:40,700][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.9839, 0.0054, 0.0013, 0.0023, 0.0028, 0.0023, 0.0020],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:40,702][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1242, 0.3394, 0.0441, 0.0862, 0.0537, 0.1859, 0.1664],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:40,703][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.2997, 0.4650, 0.0221, 0.0551, 0.0396, 0.0882, 0.0304],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:40,705][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0032, 0.0859, 0.2521, 0.3718, 0.0614, 0.1304, 0.0953],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:40,707][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.4651, 0.1534, 0.1044, 0.1428, 0.0334, 0.0598, 0.0411],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:40,708][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1081, 0.5327, 0.0362, 0.0614, 0.0631, 0.1456, 0.0530],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:40,709][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.2132, 0.4018, 0.0242, 0.0543, 0.0538, 0.0879, 0.1203, 0.0445],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,710][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0744, 0.6634, 0.0056, 0.0401, 0.0090, 0.0900, 0.1049, 0.0126],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,711][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.1836, 0.1257, 0.0801, 0.1485, 0.1379, 0.1090, 0.1769, 0.0384],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,712][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.5963, 0.1269, 0.0274, 0.0332, 0.0567, 0.0838, 0.0587, 0.0170],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,713][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([9.8803e-01, 3.6292e-03, 2.7440e-03, 1.3115e-03, 1.9012e-03, 1.1130e-03,
        8.7535e-04, 3.9145e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,714][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.1394, 0.3951, 0.0258, 0.0709, 0.0758, 0.1641, 0.0935, 0.0354],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,716][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.9841, 0.0052, 0.0010, 0.0022, 0.0023, 0.0023, 0.0018, 0.0011],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,718][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0586, 0.2755, 0.0280, 0.0737, 0.0432, 0.1787, 0.2475, 0.0947],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,719][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.3163, 0.3878, 0.0247, 0.0349, 0.0413, 0.1099, 0.0664, 0.0186],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,721][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0053, 0.0165, 0.3063, 0.2623, 0.0630, 0.1483, 0.1325, 0.0657],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,723][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.3441, 0.1732, 0.1055, 0.1797, 0.0323, 0.0692, 0.0674, 0.0285],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,724][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0925, 0.4811, 0.0321, 0.0558, 0.0684, 0.1439, 0.1038, 0.0223],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:40,726][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.3327, 0.2554, 0.0132, 0.0544, 0.0315, 0.1051, 0.1063, 0.0570, 0.0444],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,728][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0816, 0.7055, 0.0058, 0.0416, 0.0064, 0.0855, 0.0534, 0.0101, 0.0102],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,729][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.2164, 0.1261, 0.0628, 0.1391, 0.0807, 0.0929, 0.1654, 0.0321, 0.0844],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,731][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.6675, 0.1010, 0.0159, 0.0250, 0.0319, 0.0522, 0.0405, 0.0107, 0.0554],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,732][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([9.8985e-01, 3.9088e-03, 1.6879e-03, 1.1940e-03, 1.3622e-03, 5.8865e-04,
        6.9418e-04, 2.9576e-04, 4.2030e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,734][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.1759, 0.3504, 0.0206, 0.0815, 0.0494, 0.1336, 0.0920, 0.0389, 0.0577],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,735][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([9.7273e-01, 6.3935e-03, 2.4633e-03, 3.7489e-03, 5.2374e-03, 4.2502e-03,
        2.5305e-03, 8.1625e-04, 1.8309e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,737][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0988, 0.2320, 0.0155, 0.0774, 0.0202, 0.1831, 0.2424, 0.0766, 0.0540],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,739][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.3146, 0.4365, 0.0080, 0.0412, 0.0210, 0.0829, 0.0545, 0.0235, 0.0179],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,740][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0091, 0.0279, 0.2468, 0.3568, 0.0344, 0.1059, 0.0574, 0.0680, 0.0938],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,742][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.6533, 0.0636, 0.0634, 0.0740, 0.0296, 0.0320, 0.0241, 0.0203, 0.0397],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,744][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.1257, 0.4459, 0.0187, 0.0589, 0.0367, 0.1341, 0.1069, 0.0312, 0.0419],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:40,746][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2328, 0.2430, 0.0353, 0.0315, 0.0636, 0.0924, 0.0937, 0.0805, 0.0507,
        0.0765], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,747][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0345, 0.4826, 0.0181, 0.0419, 0.0175, 0.1596, 0.1198, 0.0438, 0.0319,
        0.0503], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,749][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1070, 0.1040, 0.0899, 0.0988, 0.1344, 0.0910, 0.1374, 0.0451, 0.1140,
        0.0784], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,751][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3731, 0.1393, 0.0439, 0.0278, 0.0717, 0.0938, 0.0712, 0.0319, 0.0882,
        0.0592], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,752][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([9.7535e-01, 5.2143e-03, 4.4747e-03, 2.2704e-03, 1.9045e-03, 1.3682e-03,
        1.3354e-03, 7.1180e-04, 6.1960e-04, 6.7472e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,753][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1031, 0.1966, 0.0502, 0.0758, 0.1044, 0.1683, 0.0922, 0.0494, 0.0902,
        0.0699], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,754][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9214, 0.0163, 0.0038, 0.0073, 0.0064, 0.0076, 0.0050, 0.0017, 0.0027,
        0.0278], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,755][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0592, 0.1854, 0.0403, 0.0632, 0.0521, 0.1350, 0.1727, 0.0902, 0.0923,
        0.1096], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,756][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1641, 0.2106, 0.0701, 0.0527, 0.1042, 0.1036, 0.0845, 0.0593, 0.0881,
        0.0630], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,757][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0003, 0.0644, 0.0941, 0.2238, 0.0167, 0.1298, 0.1115, 0.1501, 0.1565,
        0.0529], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,758][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1569, 0.2233, 0.0960, 0.1537, 0.0384, 0.0721, 0.0512, 0.0293, 0.0324,
        0.1467], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,760][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1135, 0.3063, 0.0537, 0.0435, 0.1013, 0.1259, 0.0968, 0.0363, 0.0713,
        0.0515], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:40,762][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1980, 0.2155, 0.0349, 0.0294, 0.0500, 0.0823, 0.0889, 0.0998, 0.0381,
        0.0779, 0.0852], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,763][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0236, 0.4248, 0.0171, 0.0382, 0.0139, 0.1299, 0.1489, 0.0611, 0.0320,
        0.0562, 0.0543], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,765][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0783, 0.0918, 0.0718, 0.0901, 0.1162, 0.0752, 0.1436, 0.0543, 0.1245,
        0.0756, 0.0785], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,767][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3536, 0.1439, 0.0392, 0.0277, 0.0628, 0.0718, 0.0742, 0.0313, 0.0670,
        0.0727, 0.0555], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,768][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([9.3690e-01, 1.1169e-02, 6.4620e-03, 4.4739e-03, 2.6327e-03, 2.2459e-03,
        2.4021e-03, 1.6009e-03, 8.8956e-04, 1.3187e-02, 1.8041e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,770][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0890, 0.1930, 0.0548, 0.0619, 0.0931, 0.1493, 0.0784, 0.0510, 0.0834,
        0.0674, 0.0787], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,771][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.8449, 0.0221, 0.0053, 0.0122, 0.0087, 0.0133, 0.0088, 0.0030, 0.0043,
        0.0413, 0.0362], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,773][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0503, 0.1952, 0.0319, 0.0528, 0.0352, 0.1119, 0.1494, 0.0824, 0.0722,
        0.1028, 0.1159], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,775][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1246, 0.1579, 0.0805, 0.0375, 0.0955, 0.0925, 0.0876, 0.0572, 0.1027,
        0.0639, 0.0999], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,776][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([1.5655e-04, 4.8306e-02, 8.1533e-02, 1.7991e-01, 1.6708e-02, 1.4136e-01,
        1.1677e-01, 2.1017e-01, 1.4231e-01, 3.8424e-02, 2.4360e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,778][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1080, 0.1858, 0.0720, 0.1214, 0.0415, 0.0878, 0.0627, 0.0354, 0.0386,
        0.1330, 0.1138], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,780][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1235, 0.3109, 0.0454, 0.0344, 0.0879, 0.1116, 0.0927, 0.0329, 0.0486,
        0.0545, 0.0577], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:40,781][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.1480, 0.2476, 0.0118, 0.0525, 0.0255, 0.0740, 0.1367, 0.0462, 0.0461,
        0.0688, 0.0978, 0.0450], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,783][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0283, 0.3985, 0.0098, 0.0501, 0.0101, 0.1375, 0.1156, 0.0201, 0.0536,
        0.0540, 0.0797, 0.0427], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,785][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.1257, 0.0837, 0.0458, 0.0885, 0.0642, 0.0626, 0.1145, 0.0342, 0.0818,
        0.1009, 0.1003, 0.0978], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,787][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.2635, 0.1275, 0.0344, 0.0445, 0.0547, 0.1067, 0.0795, 0.0242, 0.0745,
        0.0641, 0.0765, 0.0498], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,788][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([9.5435e-01, 9.9733e-03, 1.9911e-03, 2.3210e-03, 1.1812e-03, 1.4670e-03,
        1.4142e-03, 5.1567e-04, 4.2365e-04, 8.8856e-03, 1.5242e-02, 2.2336e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,789][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0729, 0.2528, 0.0235, 0.0644, 0.0540, 0.1274, 0.0935, 0.0514, 0.0665,
        0.0555, 0.0636, 0.0745], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,791][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.8987, 0.0146, 0.0027, 0.0077, 0.0056, 0.0075, 0.0062, 0.0019, 0.0037,
        0.0250, 0.0200, 0.0064], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,793][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0360, 0.1424, 0.0233, 0.0719, 0.0285, 0.1262, 0.1715, 0.0742, 0.0955,
        0.0901, 0.1030, 0.0373], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,795][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.1184, 0.2341, 0.0076, 0.0862, 0.0209, 0.1342, 0.0831, 0.0496, 0.0362,
        0.0613, 0.1427, 0.0256], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,796][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0022, 0.0425, 0.0876, 0.2549, 0.0223, 0.1051, 0.0839, 0.0581, 0.1207,
        0.0741, 0.1261, 0.0227], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,798][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.1059, 0.0981, 0.0563, 0.1353, 0.0276, 0.0682, 0.0702, 0.0311, 0.0347,
        0.1199, 0.2041, 0.0486], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,799][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0468, 0.2778, 0.0113, 0.0607, 0.0359, 0.1600, 0.1358, 0.0228, 0.0443,
        0.0667, 0.0858, 0.0520], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:40,800][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Stephanie] are: tensor([0.2635, 0.0952, 0.0151, 0.0218, 0.0331, 0.0392, 0.0734, 0.0400, 0.0478,
        0.0597, 0.0768, 0.0838, 0.1507], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,801][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Stephanie] are: tensor([0.1656, 0.2764, 0.0083, 0.0306, 0.0100, 0.0777, 0.0777, 0.0192, 0.0319,
        0.0655, 0.0943, 0.1084, 0.0345], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,802][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Stephanie] are: tensor([0.1013, 0.0681, 0.0457, 0.0788, 0.0558, 0.0676, 0.1041, 0.0345, 0.0608,
        0.0910, 0.1094, 0.1074, 0.0756], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,804][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Stephanie] are: tensor([0.3053, 0.1139, 0.0221, 0.0296, 0.0281, 0.0866, 0.0500, 0.0157, 0.0755,
        0.0525, 0.0655, 0.0832, 0.0719], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,805][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Stephanie] are: tensor([9.4639e-01, 1.3576e-02, 2.7659e-03, 2.8879e-03, 3.0713e-03, 2.1859e-03,
        1.4342e-03, 8.2906e-04, 1.2184e-03, 7.5841e-03, 9.2262e-03, 5.4310e-03,
        3.3961e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,807][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Stephanie] are: tensor([0.1239, 0.1172, 0.0279, 0.0377, 0.0558, 0.0774, 0.0664, 0.0379, 0.0944,
        0.0550, 0.0705, 0.1141, 0.1218], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,809][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Stephanie] are: tensor([0.8655, 0.0139, 0.0045, 0.0064, 0.0132, 0.0062, 0.0047, 0.0019, 0.0028,
        0.0198, 0.0226, 0.0055, 0.0330], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,811][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Stephanie] are: tensor([0.0694, 0.1248, 0.0224, 0.0459, 0.0273, 0.0881, 0.1325, 0.0637, 0.0957,
        0.0779, 0.0822, 0.0928, 0.0773], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,812][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Stephanie] are: tensor([0.3695, 0.1127, 0.0119, 0.0226, 0.0167, 0.0688, 0.0586, 0.0218, 0.0393,
        0.0577, 0.1020, 0.0500, 0.0684], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,814][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Stephanie] are: tensor([0.0014, 0.0238, 0.0270, 0.1501, 0.0080, 0.1324, 0.0967, 0.0936, 0.1603,
        0.1395, 0.1186, 0.0363, 0.0123], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,816][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Stephanie] are: tensor([0.2009, 0.0703, 0.0541, 0.1201, 0.0371, 0.0552, 0.0549, 0.0392, 0.0568,
        0.0983, 0.1308, 0.0408, 0.0415], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,818][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Stephanie] are: tensor([0.1037, 0.1393, 0.0127, 0.0291, 0.0228, 0.1320, 0.1102, 0.0205, 0.0641,
        0.0744, 0.0835, 0.1172, 0.0904], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:40,819][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.1926, 0.2681, 0.0291, 0.0439, 0.0405, 0.0526, 0.0517, 0.0413, 0.0193,
        0.0457, 0.0587, 0.0231, 0.0900, 0.0434], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,821][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0282, 0.6010, 0.0056, 0.0512, 0.0056, 0.0636, 0.0564, 0.0131, 0.0073,
        0.0411, 0.0490, 0.0280, 0.0085, 0.0414], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,823][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0638, 0.0640, 0.0532, 0.0764, 0.0838, 0.0629, 0.0899, 0.0243, 0.0803,
        0.0560, 0.0612, 0.1098, 0.0871, 0.0874], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,825][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.1730, 0.1465, 0.0362, 0.0350, 0.0502, 0.0834, 0.0653, 0.0213, 0.0612,
        0.0545, 0.0537, 0.0408, 0.0725, 0.1063], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,826][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([9.4955e-01, 1.0355e-02, 4.1012e-03, 2.8157e-03, 1.6692e-03, 1.7769e-03,
        1.5458e-03, 6.7202e-04, 6.5214e-04, 7.5486e-03, 1.0820e-02, 2.3423e-03,
        1.5734e-03, 4.5749e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,828][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0791, 0.2459, 0.0278, 0.0606, 0.0539, 0.0893, 0.0512, 0.0273, 0.0322,
        0.0454, 0.0588, 0.0569, 0.0757, 0.0959], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,830][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.8347, 0.0131, 0.0045, 0.0056, 0.0094, 0.0080, 0.0048, 0.0019, 0.0034,
        0.0268, 0.0193, 0.0062, 0.0357, 0.0266], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,831][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0288, 0.2465, 0.0166, 0.0637, 0.0205, 0.1102, 0.1188, 0.0426, 0.0317,
        0.0658, 0.0866, 0.0377, 0.0306, 0.0998], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,833][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.1525, 0.2980, 0.0427, 0.0494, 0.0502, 0.0663, 0.0370, 0.0212, 0.0235,
        0.0369, 0.0724, 0.0349, 0.0697, 0.0453], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,835][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0005, 0.0367, 0.1012, 0.2727, 0.0302, 0.1063, 0.0897, 0.0898, 0.0855,
        0.0575, 0.0503, 0.0385, 0.0201, 0.0211], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,837][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.1308, 0.1147, 0.1163, 0.0850, 0.0447, 0.0779, 0.0378, 0.0340, 0.0291,
        0.0651, 0.0840, 0.0374, 0.0535, 0.0898], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,838][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0981, 0.4732, 0.0198, 0.0277, 0.0293, 0.0630, 0.0350, 0.0124, 0.0166,
        0.0282, 0.0317, 0.0543, 0.0565, 0.0540], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:40,840][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.5370, 0.0405, 0.0106, 0.0075, 0.0165, 0.0142, 0.0161, 0.0127, 0.0131,
        0.0211, 0.0269, 0.0274, 0.0644, 0.0484, 0.1435], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,842][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1302, 0.1847, 0.0174, 0.0250, 0.0101, 0.0575, 0.0436, 0.0100, 0.0162,
        0.0230, 0.0430, 0.0783, 0.0220, 0.0620, 0.2771], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,843][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2105, 0.0422, 0.0463, 0.0368, 0.0786, 0.0329, 0.0519, 0.0196, 0.0630,
        0.0422, 0.0516, 0.0984, 0.0917, 0.0690, 0.0652], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,844][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.6496, 0.0407, 0.0141, 0.0108, 0.0220, 0.0163, 0.0130, 0.0053, 0.0156,
        0.0210, 0.0271, 0.0233, 0.0418, 0.0628, 0.0366], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,845][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.9224e-01, 1.2624e-03, 6.7784e-04, 2.8307e-04, 2.6153e-04, 1.2549e-04,
        9.5996e-05, 5.0511e-05, 3.9805e-05, 1.3083e-03, 2.2908e-03, 2.5371e-04,
        2.5599e-04, 3.6294e-04, 4.9521e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,846][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.3053, 0.0724, 0.0213, 0.0270, 0.0414, 0.0403, 0.0345, 0.0212, 0.0296,
        0.0333, 0.0402, 0.0531, 0.0762, 0.0842, 0.1202], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,847][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.3327e-01, 4.5391e-03, 1.1699e-03, 2.9733e-03, 2.6283e-03, 2.2676e-03,
        1.7702e-03, 5.6043e-04, 9.0270e-04, 1.1419e-02, 1.1580e-02, 1.9810e-03,
        9.7102e-03, 7.4113e-03, 7.8135e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,848][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1175, 0.1130, 0.0154, 0.0362, 0.0176, 0.0629, 0.0745, 0.0304, 0.0280,
        0.0622, 0.0835, 0.0310, 0.0340, 0.1252, 0.1687], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,850][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.5624, 0.0320, 0.0124, 0.0087, 0.0132, 0.0124, 0.0127, 0.0073, 0.0167,
        0.0159, 0.0279, 0.0241, 0.0407, 0.0417, 0.1717], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,852][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0015, 0.0342, 0.0437, 0.1746, 0.0130, 0.1113, 0.0835, 0.1369, 0.0764,
        0.0633, 0.0663, 0.0323, 0.0154, 0.0376, 0.1099], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,854][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.4575, 0.0626, 0.0326, 0.0414, 0.0197, 0.0170, 0.0175, 0.0118, 0.0109,
        0.0592, 0.1004, 0.0210, 0.0247, 0.0653, 0.0583], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,855][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.3106, 0.0428, 0.0314, 0.0099, 0.0474, 0.0214, 0.0227, 0.0086, 0.0274,
        0.0165, 0.0191, 0.0494, 0.1565, 0.0740, 0.1625], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:40,859][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:25:40,861][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[4735],
        [3812],
        [3652],
        [ 157],
        [ 850],
        [ 191],
        [ 343],
        [ 184],
        [ 622],
        [ 112],
        [ 123],
        [ 138],
        [ 951],
        [ 104],
        [ 356]], device='cuda:0')
[2024-07-24 10:25:40,863][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 5810],
        [22065],
        [23423],
        [ 5427],
        [ 9136],
        [ 5632],
        [ 5050],
        [ 3466],
        [ 9231],
        [ 5595],
        [ 5225],
        [ 3912],
        [10221],
        [ 4430],
        [ 6242]], device='cuda:0')
[2024-07-24 10:25:40,865][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[14519],
        [17562],
        [17171],
        [17921],
        [18700],
        [19639],
        [20172],
        [20942],
        [21387],
        [21366],
        [21315],
        [21476],
        [21245],
        [21368],
        [21196]], device='cuda:0')
[2024-07-24 10:25:40,866][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[3526],
        [2696],
        [2687],
        [3052],
        [3079],
        [2916],
        [2975],
        [3145],
        [3186],
        [3188],
        [3182],
        [3202],
        [3171],
        [3170],
        [3209]], device='cuda:0')
[2024-07-24 10:25:40,868][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[2666],
        [1412],
        [ 926],
        [ 577],
        [1015],
        [ 658],
        [ 632],
        [ 674],
        [ 885],
        [ 817],
        [ 824],
        [ 839],
        [1029],
        [ 960],
        [1041]], device='cuda:0')
[2024-07-24 10:25:40,870][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[24536],
        [17365],
        [10970],
        [11278],
        [ 7515],
        [ 7672],
        [ 8148],
        [ 7969],
        [ 8147],
        [ 8063],
        [ 8361],
        [ 7909],
        [ 7010],
        [ 7335],
        [ 7209]], device='cuda:0')
[2024-07-24 10:25:40,871][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 898],
        [1300],
        [1200],
        [1194],
        [1435],
        [1265],
        [1285],
        [1484],
        [2158],
        [1958],
        [2105],
        [2775],
        [2280],
        [3704],
        [4133]], device='cuda:0')
[2024-07-24 10:25:40,873][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[11953],
        [ 8310],
        [ 9664],
        [ 7439],
        [ 9616],
        [ 9313],
        [ 9831],
        [ 8167],
        [ 8447],
        [ 9454],
        [ 8873],
        [ 8075],
        [ 9911],
        [ 9706],
        [ 9816]], device='cuda:0')
[2024-07-24 10:25:40,874][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[15167],
        [15212],
        [15506],
        [15412],
        [15650],
        [15275],
        [15477],
        [15336],
        [15382],
        [15412],
        [15672],
        [17067],
        [17039],
        [17017],
        [16498]], device='cuda:0')
[2024-07-24 10:25:40,876][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[38720],
        [17342],
        [17465],
        [18418],
        [17049],
        [17477],
        [16363],
        [15892],
        [15319],
        [18199],
        [17003],
        [15119],
        [13566],
        [15662],
        [15009]], device='cuda:0')
[2024-07-24 10:25:40,878][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[421],
        [188],
        [176],
        [204],
        [229],
        [258],
        [262],
        [273],
        [309],
        [320],
        [320],
        [340],
        [351],
        [358],
        [367]], device='cuda:0')
[2024-07-24 10:25:40,879][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[10748],
        [ 3528],
        [ 2668],
        [   14],
        [ 1922],
        [  717],
        [  971],
        [  862],
        [ 1002],
        [  445],
        [  470],
        [ 1047],
        [ 2296],
        [  492],
        [  771]], device='cuda:0')
[2024-07-24 10:25:40,881][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[29178],
        [17644],
        [19586],
        [19038],
        [18982],
        [17729],
        [17712],
        [16925],
        [16517],
        [16263],
        [16167],
        [15205],
        [16599],
        [15518],
        [15737]], device='cuda:0')
[2024-07-24 10:25:40,883][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[29932],
        [29752],
        [21755],
        [25334],
        [15591],
        [24159],
        [28049],
        [26177],
        [24244],
        [27044],
        [26686],
        [21917],
        [20085],
        [20457],
        [23781]], device='cuda:0')
[2024-07-24 10:25:40,884][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[9473],
        [5244],
        [5273],
        [4053],
        [3630],
        [1834],
        [4428],
        [2789],
        [5053],
        [2879],
        [3660],
        [4028],
        [3899],
        [2289],
        [3514]], device='cuda:0')
[2024-07-24 10:25:40,886][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[19693],
        [19490],
        [14161],
        [15291],
        [ 9335],
        [10285],
        [14364],
        [15491],
        [12258],
        [10957],
        [ 9918],
        [11868],
        [ 5665],
        [ 9646],
        [ 6781]], device='cuda:0')
[2024-07-24 10:25:40,887][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[42056],
        [ 4755],
        [ 7145],
        [ 5502],
        [ 7108],
        [ 8856],
        [ 7128],
        [ 8228],
        [ 7558],
        [13320],
        [14550],
        [13533],
        [15294],
        [10885],
        [23682]], device='cuda:0')
[2024-07-24 10:25:40,889][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 3864],
        [33084],
        [41595],
        [38925],
        [38165],
        [37509],
        [40745],
        [39761],
        [40032],
        [38758],
        [39401],
        [40715],
        [41927],
        [41552],
        [43519]], device='cuda:0')
[2024-07-24 10:25:40,891][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 8561],
        [24554],
        [15290],
        [24970],
        [20426],
        [17952],
        [19214],
        [18713],
        [19198],
        [19044],
        [17981],
        [17750],
        [17721],
        [14144],
        [13675]], device='cuda:0')
[2024-07-24 10:25:40,892][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[30150],
        [30169],
        [30099],
        [30069],
        [30044],
        [30057],
        [30093],
        [29994],
        [30062],
        [30118],
        [30816],
        [30938],
        [30378],
        [30610],
        [30283]], device='cuda:0')
[2024-07-24 10:25:40,894][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 1978],
        [10066],
        [12478],
        [23297],
        [30201],
        [27501],
        [27003],
        [26268],
        [26445],
        [30992],
        [30337],
        [27836],
        [27993],
        [28315],
        [20901]], device='cuda:0')
[2024-07-24 10:25:40,895][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[28982],
        [28809],
        [28975],
        [28714],
        [29077],
        [28754],
        [28733],
        [28608],
        [28492],
        [26500],
        [26458],
        [26243],
        [27789],
        [28405],
        [27543]], device='cuda:0')
[2024-07-24 10:25:40,897][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[17190],
        [10439],
        [ 8409],
        [ 4047],
        [ 2273],
        [ 2920],
        [ 2885],
        [ 2094],
        [ 2162],
        [ 1873],
        [ 2230],
        [ 2251],
        [ 2351],
        [ 2979],
        [ 2705]], device='cuda:0')
[2024-07-24 10:25:40,899][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[44831],
        [13304],
        [36874],
        [ 6297],
        [13773],
        [11308],
        [ 4484],
        [ 5521],
        [ 5182],
        [ 6917],
        [ 7139],
        [ 6244],
        [11258],
        [ 5427],
        [22149]], device='cuda:0')
[2024-07-24 10:25:40,900][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[19164],
        [18830],
        [18573],
        [21476],
        [21417],
        [21967],
        [21815],
        [22084],
        [22075],
        [20654],
        [20839],
        [20525],
        [20157],
        [21339],
        [19828]], device='cuda:0')
[2024-07-24 10:25:40,902][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 7191],
        [17426],
        [15848],
        [15207],
        [13928],
        [15061],
        [15610],
        [16187],
        [15437],
        [18347],
        [19244],
        [18767],
        [17922],
        [19338],
        [18989]], device='cuda:0')
[2024-07-24 10:25:40,904][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[16275],
        [40526],
        [35873],
        [39285],
        [39250],
        [37371],
        [36750],
        [36100],
        [35930],
        [34868],
        [34524],
        [32548],
        [32019],
        [36764],
        [30620]], device='cuda:0')
[2024-07-24 10:25:40,906][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[25354],
        [14634],
        [11436],
        [15460],
        [15919],
        [16097],
        [17886],
        [17966],
        [18561],
        [16960],
        [15950],
        [16536],
        [17115],
        [17565],
        [15961]], device='cuda:0')
[2024-07-24 10:25:40,907][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[43027],
        [38074],
        [39352],
        [38290],
        [33327],
        [41462],
        [36502],
        [36087],
        [35190],
        [37080],
        [37148],
        [34526],
        [33792],
        [37139],
        [33353]], device='cuda:0')
[2024-07-24 10:25:40,909][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[18667],
        [18667],
        [18667],
        [18667],
        [18667],
        [18667],
        [18667],
        [18667],
        [18667],
        [18667],
        [18667],
        [18667],
        [18667],
        [18667],
        [18667]], device='cuda:0')
[2024-07-24 10:25:40,995][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:40,996][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,998][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:40,999][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,000][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,002][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,003][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,004][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,006][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,007][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,009][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,010][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,011][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,013][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4784, 0.5216], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,015][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0764, 0.9236], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,016][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0857, 0.9143], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,018][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1738, 0.8262], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,019][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9064, 0.0936], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,021][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9898, 0.0102], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,022][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.5720, 0.4280], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,023][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2278, 0.7722], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,024][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3315, 0.6685], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,025][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3589, 0.6411], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,025][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([6.8856e-04, 9.9931e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,027][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1926, 0.8074], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,028][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Jose] are: tensor([0.7785, 0.1844, 0.0370], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,029][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Jose] are: tensor([0.0415, 0.3935, 0.5649], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,031][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Jose] are: tensor([0.0441, 0.3911, 0.5648], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,033][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Jose] are: tensor([0.1108, 0.4812, 0.4080], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,034][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Jose] are: tensor([0.8845, 0.0635, 0.0520], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,036][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Jose] are: tensor([0.9916, 0.0058, 0.0026], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,037][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Jose] are: tensor([0.4033, 0.2716, 0.3251], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,039][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Jose] are: tensor([0.5262, 0.4096, 0.0641], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,040][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Jose] are: tensor([0.7340, 0.2092, 0.0569], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,042][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Jose] are: tensor([0.6491, 0.3074, 0.0435], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,044][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Jose] are: tensor([0.0082, 0.8415, 0.1503], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,045][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Jose] are: tensor([0.1939, 0.5896, 0.2165], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,047][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2132, 0.6523, 0.1041, 0.0304], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,048][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0176, 0.3158, 0.3933, 0.2733], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,050][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0069, 0.3118, 0.3910, 0.2903], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,052][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0648, 0.3638, 0.3064, 0.2650], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,053][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4440, 0.1281, 0.1323, 0.2956], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,055][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.9799, 0.0128, 0.0051, 0.0022], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,057][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2271, 0.2132, 0.3514, 0.2083], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,058][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3463, 0.4988, 0.0898, 0.0651], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,060][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1631, 0.7128, 0.0762, 0.0479], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,061][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2038, 0.6033, 0.1478, 0.0451], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,063][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0018, 0.3986, 0.1465, 0.4531], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,065][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0433, 0.1757, 0.2362, 0.5447], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,066][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Stephanie] are: tensor([0.1694, 0.5952, 0.0668, 0.0683, 0.1003], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,068][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Stephanie] are: tensor([0.0190, 0.2146, 0.2709, 0.2273, 0.2684], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,069][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Stephanie] are: tensor([0.0134, 0.2304, 0.3555, 0.2465, 0.1542], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,069][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Stephanie] are: tensor([0.0577, 0.2869, 0.2413, 0.2075, 0.2066], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,070][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Stephanie] are: tensor([0.7619, 0.0471, 0.0304, 0.1058, 0.0548], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,071][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Stephanie] are: tensor([0.9012, 0.0340, 0.0148, 0.0103, 0.0398], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,073][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Stephanie] are: tensor([0.2748, 0.1588, 0.1954, 0.1616, 0.2095], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,074][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Stephanie] are: tensor([0.2196, 0.3771, 0.1486, 0.1541, 0.1007], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,076][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Stephanie] are: tensor([0.2845, 0.3807, 0.1001, 0.0958, 0.1388], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,077][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Stephanie] are: tensor([0.2357, 0.5045, 0.0625, 0.0958, 0.1014], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,079][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Stephanie] are: tensor([0.0037, 0.2042, 0.0472, 0.6819, 0.0630], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,080][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Stephanie] are: tensor([0.1018, 0.2369, 0.0473, 0.6023, 0.0117], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,082][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.4715, 0.3493, 0.0350, 0.0201, 0.0650, 0.0591], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,084][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0256, 0.1821, 0.2021, 0.1946, 0.2267, 0.1688], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,086][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0062, 0.1785, 0.2968, 0.1730, 0.1172, 0.2283], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,087][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0457, 0.2267, 0.1925, 0.1698, 0.1690, 0.1963], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,089][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.7688, 0.0161, 0.0118, 0.0323, 0.0375, 0.1335], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,090][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ had] are: tensor([9.7115e-01, 4.6828e-03, 2.9275e-03, 1.0312e-03, 1.9607e-02, 5.9914e-04],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,092][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.1771, 0.1214, 0.1686, 0.1244, 0.1548, 0.2537], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,093][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.5309, 0.3040, 0.0491, 0.0469, 0.0367, 0.0324], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,095][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.2055, 0.5399, 0.0620, 0.0495, 0.0745, 0.0685], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,096][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.3805, 0.2813, 0.0827, 0.0308, 0.1429, 0.0818], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,098][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ had] are: tensor([5.2358e-04, 9.7263e-02, 4.2746e-02, 2.5984e-01, 6.0548e-02, 5.3908e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,099][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0144, 0.1670, 0.1505, 0.5181, 0.0265, 0.1235], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,101][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0649, 0.7938, 0.0064, 0.0320, 0.0140, 0.0789, 0.0101],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,103][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0180, 0.1438, 0.1830, 0.1436, 0.1770, 0.1300, 0.2045],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,104][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0046, 0.1457, 0.2298, 0.1485, 0.1042, 0.1984, 0.1688],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,106][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0351, 0.1975, 0.1611, 0.1411, 0.1389, 0.1669, 0.1594],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,108][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.7326, 0.0048, 0.0021, 0.0117, 0.0084, 0.0533, 0.1871],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,109][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.9476, 0.0159, 0.0036, 0.0020, 0.0248, 0.0024, 0.0037],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,111][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1458, 0.1153, 0.1276, 0.1039, 0.1284, 0.2279, 0.1510],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,112][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.4758, 0.3437, 0.0521, 0.0369, 0.0235, 0.0350, 0.0331],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,113][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0920, 0.7129, 0.0201, 0.0435, 0.0314, 0.0687, 0.0314],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,114][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0866, 0.5869, 0.0350, 0.0507, 0.0452, 0.1470, 0.0485],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,114][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([3.4324e-04, 5.6740e-02, 2.7913e-02, 1.3335e-01, 4.2614e-02, 5.5160e-01,
        1.8744e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,115][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0177, 0.1052, 0.1012, 0.4144, 0.0168, 0.0990, 0.2457],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,117][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0355, 0.7476, 0.0126, 0.0365, 0.0216, 0.1016, 0.0390, 0.0056],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,118][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0178, 0.1259, 0.1447, 0.1303, 0.1533, 0.0996, 0.1932, 0.1351],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,120][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0037, 0.1178, 0.2029, 0.1410, 0.0796, 0.1655, 0.1609, 0.1286],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,122][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0296, 0.1738, 0.1392, 0.1237, 0.1204, 0.1459, 0.1401, 0.1273],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,123][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.4612, 0.0066, 0.0026, 0.0135, 0.0077, 0.0586, 0.2779, 0.1718],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,125][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.9541, 0.0122, 0.0030, 0.0023, 0.0199, 0.0026, 0.0041, 0.0019],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,127][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.1205, 0.0863, 0.1267, 0.0835, 0.1376, 0.2075, 0.1472, 0.0906],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,129][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.3854, 0.2687, 0.0921, 0.0730, 0.0413, 0.0640, 0.0518, 0.0236],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,130][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0738, 0.7302, 0.0201, 0.0361, 0.0357, 0.0415, 0.0513, 0.0112],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,132][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0610, 0.5856, 0.0183, 0.0446, 0.0307, 0.1593, 0.0773, 0.0233],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,133][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ long] are: tensor([2.3893e-04, 2.3137e-02, 4.2007e-02, 1.0900e-01, 2.7184e-02, 5.8804e-01,
        1.3333e-01, 7.7057e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,135][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0192, 0.0759, 0.1176, 0.3686, 0.0199, 0.0678, 0.2351, 0.0958],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,136][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0692, 0.7233, 0.0056, 0.0390, 0.0187, 0.0802, 0.0427, 0.0048, 0.0166],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,138][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0102, 0.1040, 0.0947, 0.1224, 0.1105, 0.0884, 0.1963, 0.1192, 0.1542],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,140][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0056, 0.1038, 0.1865, 0.1157, 0.0803, 0.1575, 0.1260, 0.1034, 0.1212],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,142][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0266, 0.1531, 0.1217, 0.1092, 0.1074, 0.1277, 0.1236, 0.1136, 0.1172],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,143][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.2344, 0.0062, 0.0019, 0.0129, 0.0050, 0.0663, 0.3331, 0.2381, 0.1020],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,145][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.9591, 0.0114, 0.0018, 0.0018, 0.0158, 0.0020, 0.0031, 0.0015, 0.0037],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,147][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.1214, 0.0636, 0.1077, 0.0868, 0.1167, 0.1981, 0.1315, 0.0926, 0.0817],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,148][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.3265, 0.2207, 0.0560, 0.0752, 0.0294, 0.0861, 0.0683, 0.0453, 0.0926],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,150][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.1235, 0.5011, 0.0117, 0.0474, 0.0249, 0.1314, 0.1054, 0.0215, 0.0331],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,152][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0492, 0.5277, 0.0145, 0.0575, 0.0170, 0.1756, 0.0948, 0.0240, 0.0396],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,154][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0008, 0.0198, 0.0334, 0.1297, 0.0278, 0.5411, 0.1099, 0.1068, 0.0307],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,155][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0465, 0.0549, 0.0863, 0.3898, 0.0118, 0.0850, 0.2089, 0.0815, 0.0353],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,156][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0935, 0.4021, 0.0392, 0.0325, 0.0906, 0.1446, 0.0485, 0.0191, 0.0970,
        0.0330], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,157][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0057, 0.0912, 0.1113, 0.0941, 0.1077, 0.0829, 0.1772, 0.1051, 0.1521,
        0.0726], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,158][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0011, 0.1268, 0.1764, 0.1150, 0.0727, 0.1374, 0.1157, 0.0978, 0.1119,
        0.0451], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,159][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0178, 0.1393, 0.1154, 0.0971, 0.0989, 0.1192, 0.1150, 0.1056, 0.1117,
        0.0801], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,161][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0811, 0.0044, 0.0024, 0.0117, 0.0080, 0.0702, 0.3110, 0.2648, 0.1496,
        0.0969], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,162][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.7379, 0.0579, 0.0137, 0.0099, 0.0595, 0.0111, 0.0205, 0.0249, 0.0318,
        0.0329], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,164][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0783, 0.0685, 0.1194, 0.0696, 0.1182, 0.1865, 0.1285, 0.0875, 0.0872,
        0.0564], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,166][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0518, 0.3786, 0.0946, 0.0617, 0.0355, 0.0905, 0.0774, 0.0472, 0.0667,
        0.0961], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,167][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0449, 0.4209, 0.0626, 0.0401, 0.0708, 0.1136, 0.0973, 0.0715, 0.0554,
        0.0231], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,169][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0430, 0.2646, 0.0844, 0.0361, 0.1032, 0.1707, 0.1073, 0.0549, 0.0932,
        0.0427], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,170][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([2.0646e-05, 3.4731e-02, 1.8032e-02, 8.8037e-02, 1.3331e-02, 4.1064e-01,
        1.9048e-01, 1.6240e-01, 4.7507e-02, 3.4818e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,172][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0084, 0.0579, 0.0835, 0.3608, 0.0079, 0.0759, 0.2367, 0.0878, 0.0345,
        0.0466], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,173][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0890, 0.3393, 0.0569, 0.0218, 0.1140, 0.1255, 0.0507, 0.0257, 0.1070,
        0.0376, 0.0326], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,175][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0057, 0.0956, 0.1262, 0.0798, 0.1017, 0.0739, 0.1711, 0.0844, 0.1394,
        0.0719, 0.0503], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,177][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0008, 0.1163, 0.1806, 0.1103, 0.0698, 0.1390, 0.1071, 0.0914, 0.1060,
        0.0398, 0.0390], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,179][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0154, 0.1306, 0.1084, 0.0895, 0.0922, 0.1119, 0.1095, 0.1009, 0.1077,
        0.0751, 0.0587], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,181][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0135, 0.0042, 0.0031, 0.0109, 0.0094, 0.0576, 0.2305, 0.2974, 0.2439,
        0.0856, 0.0439], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,182][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.6999, 0.0527, 0.0104, 0.0120, 0.0443, 0.0098, 0.0280, 0.0321, 0.0318,
        0.0378, 0.0410], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,184][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0591, 0.0608, 0.1146, 0.0610, 0.1140, 0.1861, 0.1244, 0.0822, 0.0816,
        0.0569, 0.0592], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,186][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0219, 0.2723, 0.0813, 0.0634, 0.0441, 0.1048, 0.1109, 0.0798, 0.1089,
        0.0791, 0.0333], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,188][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0489, 0.3946, 0.0701, 0.0316, 0.0599, 0.1090, 0.1042, 0.0729, 0.0566,
        0.0257, 0.0266], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,189][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0579, 0.2565, 0.0919, 0.0261, 0.1070, 0.1234, 0.0904, 0.0728, 0.1104,
        0.0352, 0.0284], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,190][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([7.5444e-06, 2.6291e-02, 1.1094e-02, 6.3569e-02, 8.6908e-03, 4.3998e-01,
        1.7504e-01, 2.0455e-01, 3.4521e-02, 2.4060e-02, 1.2196e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,192][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0068, 0.0683, 0.0753, 0.3383, 0.0072, 0.0658, 0.2502, 0.0987, 0.0365,
        0.0392, 0.0137], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,194][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0350, 0.4629, 0.0159, 0.0621, 0.0219, 0.1589, 0.0821, 0.0145, 0.0489,
        0.0415, 0.0401, 0.0161], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,196][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0170, 0.0882, 0.0889, 0.0796, 0.0910, 0.0727, 0.1246, 0.0837, 0.0918,
        0.0681, 0.0597, 0.1346], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,197][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0072, 0.0896, 0.1651, 0.1047, 0.0665, 0.1235, 0.0973, 0.0833, 0.0906,
        0.0467, 0.0494, 0.0760], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,199][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0191, 0.1213, 0.1000, 0.0857, 0.0854, 0.1045, 0.1002, 0.0904, 0.0953,
        0.0704, 0.0563, 0.0713], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,200][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.2772, 0.0039, 0.0018, 0.0097, 0.0038, 0.0568, 0.2115, 0.1466, 0.0791,
        0.0666, 0.0410, 0.1019], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,201][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.8134, 0.0362, 0.0039, 0.0049, 0.0207, 0.0061, 0.0083, 0.0035, 0.0073,
        0.0214, 0.0385, 0.0359], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,202][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0834, 0.0509, 0.0750, 0.0722, 0.0916, 0.1722, 0.1407, 0.0783, 0.0854,
        0.0520, 0.0665, 0.0317], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,203][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0705, 0.2177, 0.1042, 0.0908, 0.0539, 0.0671, 0.0680, 0.0657, 0.0600,
        0.0907, 0.0770, 0.0344], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,204][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0284, 0.3610, 0.0291, 0.0570, 0.0346, 0.1350, 0.1485, 0.0560, 0.0717,
        0.0336, 0.0277, 0.0172], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,206][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0355, 0.2864, 0.0224, 0.0491, 0.0364, 0.1692, 0.1160, 0.0486, 0.0888,
        0.0409, 0.0400, 0.0668], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,207][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([4.1074e-05, 8.9571e-03, 8.5584e-03, 8.7633e-02, 8.6670e-03, 4.7154e-01,
        1.0914e-01, 1.2223e-01, 4.0187e-02, 4.2362e-02, 6.8286e-02, 3.2397e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,209][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0152, 0.0548, 0.0916, 0.4032, 0.0104, 0.0616, 0.2107, 0.0743, 0.0239,
        0.0315, 0.0180, 0.0048], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,210][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Stephanie] are: tensor([0.1069, 0.3339, 0.0167, 0.0265, 0.0257, 0.1081, 0.0869, 0.0294, 0.0696,
        0.0423, 0.0363, 0.0573, 0.0604], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,212][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Stephanie] are: tensor([0.0109, 0.0667, 0.0843, 0.0759, 0.0772, 0.0662, 0.1140, 0.0821, 0.0960,
        0.0639, 0.0714, 0.1018, 0.0894], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,214][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Stephanie] are: tensor([0.0083, 0.0830, 0.1466, 0.0906, 0.0655, 0.1145, 0.0910, 0.0765, 0.0876,
        0.0467, 0.0467, 0.0744, 0.0686], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,216][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Stephanie] are: tensor([0.0203, 0.1154, 0.0936, 0.0789, 0.0777, 0.0982, 0.0938, 0.0840, 0.0889,
        0.0657, 0.0524, 0.0682, 0.0629], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,217][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Stephanie] are: tensor([0.1939, 0.0047, 0.0018, 0.0087, 0.0036, 0.0579, 0.2320, 0.1586, 0.0779,
        0.0758, 0.0385, 0.1318, 0.0147], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,219][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Stephanie] are: tensor([0.6549, 0.0430, 0.0099, 0.0084, 0.0310, 0.0136, 0.0130, 0.0097, 0.0229,
        0.0369, 0.0492, 0.0603, 0.0473], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,221][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Stephanie] are: tensor([0.1130, 0.0614, 0.0747, 0.0622, 0.0842, 0.1450, 0.1092, 0.0645, 0.0791,
        0.0579, 0.0551, 0.0351, 0.0584], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,223][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Stephanie] are: tensor([0.0685, 0.1692, 0.0899, 0.0873, 0.0451, 0.0853, 0.0623, 0.0695, 0.0853,
        0.0785, 0.0721, 0.0350, 0.0520], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,224][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Stephanie] are: tensor([0.0972, 0.1911, 0.0256, 0.0352, 0.0410, 0.0771, 0.1192, 0.0489, 0.0979,
        0.0439, 0.0396, 0.0753, 0.1080], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,226][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Stephanie] are: tensor([0.0511, 0.2047, 0.0211, 0.0325, 0.0269, 0.1446, 0.1018, 0.0426, 0.1108,
        0.0534, 0.0462, 0.0964, 0.0679], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,227][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Stephanie] are: tensor([3.8306e-05, 5.4306e-03, 3.6974e-03, 4.3891e-02, 5.3125e-03, 4.6697e-01,
        1.0087e-01, 9.0505e-02, 4.8600e-02, 1.1559e-01, 9.3082e-02, 1.8887e-02,
        7.1321e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,229][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Stephanie] are: tensor([0.0342, 0.0724, 0.0206, 0.3525, 0.0026, 0.0472, 0.2633, 0.1094, 0.0378,
        0.0424, 0.0104, 0.0059, 0.0013], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,231][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0583, 0.6311, 0.0135, 0.0318, 0.0308, 0.0726, 0.0174, 0.0049, 0.0164,
        0.0201, 0.0242, 0.0181, 0.0322, 0.0289], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:41,233][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0063, 0.0647, 0.0733, 0.0722, 0.0893, 0.0556, 0.1068, 0.0600, 0.0760,
        0.0573, 0.0579, 0.0788, 0.1178, 0.0840], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:41,234][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0059, 0.0677, 0.1432, 0.0836, 0.0645, 0.1175, 0.0836, 0.0785, 0.0735,
        0.0380, 0.0365, 0.0710, 0.0561, 0.0804], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:41,236][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0162, 0.1090, 0.0880, 0.0754, 0.0742, 0.0919, 0.0878, 0.0793, 0.0829,
        0.0620, 0.0495, 0.0617, 0.0586, 0.0634], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:41,238][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.1165, 0.0048, 0.0024, 0.0084, 0.0065, 0.0451, 0.1670, 0.1810, 0.1129,
        0.0542, 0.0283, 0.1274, 0.0273, 0.1183], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:41,240][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.5812, 0.0399, 0.0109, 0.0102, 0.0809, 0.0085, 0.0116, 0.0094, 0.0173,
        0.0237, 0.0348, 0.0495, 0.0990, 0.0231], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:41,241][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0459, 0.0500, 0.0749, 0.0619, 0.0866, 0.1444, 0.0731, 0.0665, 0.0725,
        0.0447, 0.0580, 0.0326, 0.0590, 0.1298], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:41,243][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0621, 0.1819, 0.0606, 0.0515, 0.0429, 0.0892, 0.0703, 0.0707, 0.0588,
        0.0870, 0.0476, 0.0339, 0.0502, 0.0930], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:41,245][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0627, 0.5801, 0.0141, 0.0481, 0.0244, 0.0713, 0.0382, 0.0171, 0.0133,
        0.0194, 0.0224, 0.0124, 0.0335, 0.0431], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:41,246][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0291, 0.3523, 0.0431, 0.0398, 0.0538, 0.1277, 0.0544, 0.0268, 0.0357,
        0.0247, 0.0251, 0.0410, 0.0677, 0.0787], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:41,247][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ said] are: tensor([8.7031e-06, 1.0795e-02, 8.2930e-03, 7.6736e-02, 1.3656e-02, 4.1446e-01,
        1.3254e-01, 1.7343e-01, 2.2395e-02, 4.3375e-02, 3.0953e-02, 5.1337e-02,
        8.2176e-03, 1.3801e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:41,248][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0050, 0.0360, 0.0777, 0.3970, 0.0073, 0.0549, 0.2503, 0.0701, 0.0211,
        0.0405, 0.0183, 0.0045, 0.0039, 0.0134], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:41,249][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.3081, 0.1202, 0.0227, 0.0124, 0.0377, 0.0343, 0.0223, 0.0082, 0.0466,
        0.0217, 0.0222, 0.0487, 0.0793, 0.0622, 0.1534], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:41,250][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0113, 0.0619, 0.0788, 0.0642, 0.0680, 0.0499, 0.1046, 0.0599, 0.0915,
        0.0507, 0.0488, 0.1102, 0.0897, 0.0690, 0.0417], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:41,251][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0033, 0.0668, 0.1152, 0.0761, 0.0519, 0.0912, 0.0786, 0.0694, 0.0703,
        0.0378, 0.0375, 0.0675, 0.0562, 0.0826, 0.0957], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:41,253][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0171, 0.0945, 0.0807, 0.0684, 0.0693, 0.0833, 0.0797, 0.0739, 0.0798,
        0.0577, 0.0467, 0.0581, 0.0571, 0.0588, 0.0749], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:41,254][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.2947, 0.0022, 0.0017, 0.0055, 0.0039, 0.0242, 0.1012, 0.1288, 0.1124,
        0.0382, 0.0190, 0.1056, 0.0198, 0.0850, 0.0579], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:41,256][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.9031, 0.0063, 0.0025, 0.0015, 0.0170, 0.0012, 0.0016, 0.0017, 0.0024,
        0.0065, 0.0118, 0.0087, 0.0227, 0.0071, 0.0059], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:41,258][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0688, 0.0479, 0.0771, 0.0500, 0.0782, 0.1431, 0.0813, 0.0603, 0.0585,
        0.0417, 0.0522, 0.0372, 0.0551, 0.0982, 0.0505], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:41,259][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1107, 0.2016, 0.0621, 0.0489, 0.0308, 0.0487, 0.0388, 0.0300, 0.0302,
        0.0695, 0.0455, 0.0217, 0.0295, 0.0945, 0.1373], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:41,261][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1979, 0.1367, 0.0470, 0.0174, 0.0541, 0.0448, 0.0436, 0.0253, 0.0493,
        0.0148, 0.0190, 0.0289, 0.1311, 0.0894, 0.1007], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:41,263][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1861, 0.0749, 0.0491, 0.0165, 0.0400, 0.0711, 0.0444, 0.0235, 0.0595,
        0.0273, 0.0282, 0.0678, 0.0998, 0.1435, 0.0682], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:41,264][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([1.0922e-05, 1.1960e-02, 3.5354e-03, 6.9442e-02, 9.0374e-03, 2.2426e-01,
        1.3135e-01, 1.8823e-01, 2.8155e-02, 6.0923e-02, 4.3113e-02, 4.0942e-02,
        7.8538e-03, 1.9095e-02, 1.6210e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:41,266][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0046, 0.1234, 0.0737, 0.2926, 0.0118, 0.0597, 0.2023, 0.0609, 0.0264,
        0.0363, 0.0152, 0.0077, 0.0061, 0.0147, 0.0646], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:41,356][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:41,358][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,359][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,361][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,362][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,363][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,365][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,367][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,368][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,370][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,371][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,372][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,374][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,375][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4784, 0.5216], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,377][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.7140, 0.2860], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,378][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([7.1445e-05, 9.9993e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,380][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.7023, 0.2977], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,381][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5340, 0.4660], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,383][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9898, 0.0102], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,384][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.8114, 0.1886], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,384][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2278, 0.7722], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,385][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3315, 0.6685], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,386][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.3589, 0.6411], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,388][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0012, 0.9988], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,389][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2125, 0.7875], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,391][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Jose] are: tensor([0.7785, 0.1844, 0.0370], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,392][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Jose] are: tensor([0.9474, 0.0210, 0.0316], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,394][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Jose] are: tensor([0.0009, 0.8451, 0.1540], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,395][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Jose] are: tensor([0.9322, 0.0578, 0.0100], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,397][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Jose] are: tensor([0.6572, 0.2205, 0.1222], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,399][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Jose] are: tensor([0.9916, 0.0058, 0.0026], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,400][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Jose] are: tensor([0.8172, 0.1397, 0.0430], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,402][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Jose] are: tensor([0.5262, 0.4096, 0.0641], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,404][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Jose] are: tensor([0.7340, 0.2092, 0.0569], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,405][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Jose] are: tensor([0.6491, 0.3074, 0.0435], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,407][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Jose] are: tensor([0.0032, 0.8990, 0.0978], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,409][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Jose] are: tensor([0.5146, 0.3671, 0.1183], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,410][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2132, 0.6523, 0.1041, 0.0304], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,412][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.2771, 0.1900, 0.4245, 0.1085], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,413][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([1.7734e-04, 3.7628e-01, 1.2984e-01, 4.9370e-01], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,414][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.5364, 0.3639, 0.0539, 0.0457], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,416][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2160, 0.5676, 0.1173, 0.0991], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,418][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9799, 0.0128, 0.0051, 0.0022], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,419][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6083, 0.2316, 0.0856, 0.0745], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,421][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.3463, 0.4988, 0.0898, 0.0651], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,422][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1631, 0.7128, 0.0762, 0.0479], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,424][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.2038, 0.6033, 0.1478, 0.0451], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,426][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0007, 0.4502, 0.3848, 0.1643], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,427][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4449, 0.1990, 0.2273, 0.1288], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,428][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Stephanie] are: tensor([0.1694, 0.5952, 0.0668, 0.0683, 0.1003], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,429][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Stephanie] are: tensor([0.2871, 0.1916, 0.1855, 0.1407, 0.1951], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,430][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Stephanie] are: tensor([3.8036e-04, 2.5432e-01, 1.7248e-01, 4.7615e-01, 9.6668e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,430][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Stephanie] are: tensor([0.6938, 0.2056, 0.0337, 0.0377, 0.0292], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,431][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Stephanie] are: tensor([0.3288, 0.3661, 0.0827, 0.0947, 0.1277], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,433][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Stephanie] are: tensor([0.9012, 0.0340, 0.0148, 0.0103, 0.0398], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,434][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Stephanie] are: tensor([0.5101, 0.2269, 0.0927, 0.0966, 0.0736], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,436][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Stephanie] are: tensor([0.2196, 0.3771, 0.1486, 0.1541, 0.1007], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,437][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Stephanie] are: tensor([0.2845, 0.3807, 0.1001, 0.0958, 0.1388], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,439][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Stephanie] are: tensor([0.2357, 0.5045, 0.0625, 0.0958, 0.1014], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,440][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Stephanie] are: tensor([0.0014, 0.3127, 0.1517, 0.4476, 0.0866], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,442][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Stephanie] are: tensor([0.2587, 0.3037, 0.1013, 0.2454, 0.0909], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,444][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.4715, 0.3493, 0.0350, 0.0201, 0.0650, 0.0591], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,446][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.5632, 0.0895, 0.1121, 0.0529, 0.1078, 0.0745], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,447][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0004, 0.1394, 0.2139, 0.3128, 0.1219, 0.2116], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,449][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.7646, 0.1232, 0.0313, 0.0206, 0.0225, 0.0378], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,451][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.5292, 0.2853, 0.0473, 0.0337, 0.0737, 0.0308], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,452][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([9.7115e-01, 4.6828e-03, 2.9275e-03, 1.0312e-03, 1.9607e-02, 5.9914e-04],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,453][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.5748, 0.2114, 0.0441, 0.0722, 0.0312, 0.0663], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,455][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.5309, 0.3040, 0.0491, 0.0469, 0.0367, 0.0324], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,457][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.2055, 0.5399, 0.0620, 0.0495, 0.0745, 0.0685], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,458][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.3805, 0.2813, 0.0827, 0.0308, 0.1429, 0.0818], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,460][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0005, 0.1639, 0.2448, 0.1445, 0.1351, 0.3112], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,462][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.1826, 0.2055, 0.1869, 0.1326, 0.1181, 0.1744], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,464][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0649, 0.7938, 0.0064, 0.0320, 0.0140, 0.0789, 0.0101],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,465][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.5612, 0.0627, 0.0832, 0.0381, 0.1279, 0.0805, 0.0463],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,466][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([2.8203e-04, 1.0249e-01, 8.3192e-02, 2.7049e-01, 5.3955e-02, 2.0482e-01,
        2.8477e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,468][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.4751, 0.3681, 0.0191, 0.0358, 0.0187, 0.0612, 0.0220],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,470][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.3136, 0.5133, 0.0124, 0.0559, 0.0275, 0.0514, 0.0259],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,471][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.9476, 0.0159, 0.0036, 0.0020, 0.0248, 0.0024, 0.0037],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,473][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.5449, 0.2179, 0.0477, 0.0687, 0.0291, 0.0703, 0.0214],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,474][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.4758, 0.3437, 0.0521, 0.0369, 0.0235, 0.0350, 0.0331],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,475][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0920, 0.7129, 0.0201, 0.0435, 0.0314, 0.0687, 0.0314],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,475][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0866, 0.5869, 0.0350, 0.0507, 0.0452, 0.1470, 0.0485],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,476][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0005, 0.1087, 0.1347, 0.0696, 0.1106, 0.1924, 0.3836],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,478][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.2706, 0.2079, 0.1507, 0.1023, 0.0983, 0.1157, 0.0544],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,479][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0355, 0.7476, 0.0126, 0.0365, 0.0216, 0.1016, 0.0390, 0.0056],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,481][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.6145, 0.0839, 0.0509, 0.0417, 0.0714, 0.0594, 0.0460, 0.0323],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,482][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([6.3505e-05, 1.6592e-02, 9.5572e-02, 1.9430e-01, 3.5300e-02, 1.2632e-01,
        1.5960e-01, 3.7225e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,484][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.4860, 0.3702, 0.0123, 0.0278, 0.0148, 0.0562, 0.0253, 0.0074],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,486][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.1635, 0.5922, 0.0127, 0.0624, 0.0291, 0.0636, 0.0580, 0.0184],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,487][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.9541, 0.0122, 0.0030, 0.0023, 0.0199, 0.0026, 0.0041, 0.0019],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,489][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.5979, 0.1780, 0.0484, 0.0529, 0.0264, 0.0631, 0.0226, 0.0109],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,491][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.3854, 0.2687, 0.0921, 0.0730, 0.0413, 0.0640, 0.0518, 0.0236],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,492][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0738, 0.7302, 0.0201, 0.0361, 0.0357, 0.0415, 0.0513, 0.0112],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,494][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0610, 0.5856, 0.0183, 0.0446, 0.0307, 0.1593, 0.0773, 0.0233],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,495][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([2.5448e-04, 3.6170e-02, 1.9794e-01, 9.1263e-02, 5.9147e-02, 2.2928e-01,
        3.0512e-01, 8.0829e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,497][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.2198, 0.0879, 0.2139, 0.1078, 0.1188, 0.1071, 0.0713, 0.0734],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,498][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0692, 0.7233, 0.0056, 0.0390, 0.0187, 0.0802, 0.0427, 0.0048, 0.0166],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,500][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.7548, 0.0316, 0.0288, 0.0307, 0.0460, 0.0349, 0.0180, 0.0178, 0.0374],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,502][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0004, 0.0233, 0.0373, 0.1513, 0.0182, 0.1195, 0.1597, 0.2300, 0.2602],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,504][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.4879, 0.3458, 0.0111, 0.0340, 0.0156, 0.0508, 0.0253, 0.0097, 0.0197],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,506][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.1945, 0.5683, 0.0099, 0.0645, 0.0238, 0.0515, 0.0433, 0.0200, 0.0241],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,507][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.9591, 0.0114, 0.0018, 0.0018, 0.0158, 0.0020, 0.0031, 0.0015, 0.0037],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,509][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.7059, 0.1034, 0.0322, 0.0432, 0.0221, 0.0466, 0.0214, 0.0106, 0.0146],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,511][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.3265, 0.2207, 0.0560, 0.0752, 0.0294, 0.0861, 0.0683, 0.0453, 0.0926],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,512][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.1235, 0.5011, 0.0117, 0.0474, 0.0249, 0.1314, 0.1054, 0.0215, 0.0331],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,514][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0492, 0.5277, 0.0145, 0.0575, 0.0170, 0.1756, 0.0948, 0.0240, 0.0396],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,516][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0014, 0.0422, 0.1619, 0.0989, 0.0608, 0.1850, 0.2374, 0.0993, 0.1129],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,517][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.2814, 0.0737, 0.1265, 0.1161, 0.0825, 0.1313, 0.0483, 0.0799, 0.0603],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,518][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0935, 0.4021, 0.0392, 0.0325, 0.0906, 0.1446, 0.0485, 0.0191, 0.0970,
        0.0330], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,519][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0976, 0.0883, 0.1452, 0.0743, 0.0835, 0.1464, 0.0885, 0.0838, 0.0956,
        0.0966], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,520][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([2.2891e-06, 3.3926e-02, 2.2802e-02, 1.5576e-01, 6.6230e-03, 1.1209e-01,
        1.8376e-01, 2.9563e-01, 1.5633e-01, 3.3081e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,521][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.2424, 0.3251, 0.0382, 0.0495, 0.0360, 0.1019, 0.0613, 0.0274, 0.0518,
        0.0664], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,522][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1008, 0.3545, 0.0319, 0.0713, 0.0531, 0.1255, 0.0781, 0.0502, 0.0549,
        0.0798], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,524][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.7379, 0.0579, 0.0137, 0.0099, 0.0595, 0.0111, 0.0205, 0.0249, 0.0318,
        0.0329], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,526][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3091, 0.2147, 0.0613, 0.0787, 0.0378, 0.0822, 0.0384, 0.0282, 0.0256,
        0.1240], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,528][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0518, 0.3786, 0.0946, 0.0617, 0.0355, 0.0905, 0.0774, 0.0472, 0.0667,
        0.0961], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,529][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0449, 0.4209, 0.0626, 0.0401, 0.0708, 0.1136, 0.0973, 0.0715, 0.0554,
        0.0231], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,531][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0430, 0.2646, 0.0844, 0.0361, 0.1032, 0.1707, 0.1073, 0.0549, 0.0932,
        0.0427], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,532][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([3.2233e-05, 6.5104e-02, 6.8438e-02, 5.2600e-02, 2.5376e-02, 1.7133e-01,
        3.7862e-01, 1.3525e-01, 9.5859e-02, 7.3987e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,534][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0441, 0.0787, 0.0918, 0.0940, 0.0567, 0.1738, 0.0989, 0.1657, 0.0834,
        0.1129], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,535][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0890, 0.3393, 0.0569, 0.0218, 0.1140, 0.1255, 0.0507, 0.0257, 0.1070,
        0.0376, 0.0326], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,537][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0318, 0.1079, 0.1629, 0.0640, 0.0828, 0.1501, 0.0912, 0.0977, 0.0867,
        0.0730, 0.0518], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,538][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([1.0410e-06, 3.1142e-02, 2.2909e-02, 1.1765e-01, 6.8881e-03, 1.3188e-01,
        1.9713e-01, 3.1645e-01, 1.4952e-01, 2.3209e-02, 3.2327e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,540][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1978, 0.2596, 0.0377, 0.0440, 0.0380, 0.0926, 0.0674, 0.0395, 0.0671,
        0.0735, 0.0828], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,542][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0696, 0.2629, 0.0432, 0.0700, 0.0552, 0.1198, 0.0792, 0.0587, 0.0808,
        0.0706, 0.0900], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,544][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.6999, 0.0527, 0.0104, 0.0120, 0.0443, 0.0098, 0.0280, 0.0321, 0.0318,
        0.0378, 0.0410], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,545][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2092, 0.1808, 0.0597, 0.0852, 0.0412, 0.0842, 0.0472, 0.0380, 0.0354,
        0.1216, 0.0975], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,547][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0219, 0.2723, 0.0813, 0.0634, 0.0441, 0.1048, 0.1109, 0.0798, 0.1089,
        0.0791, 0.0333], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,549][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0489, 0.3946, 0.0701, 0.0316, 0.0599, 0.1090, 0.1042, 0.0729, 0.0566,
        0.0257, 0.0266], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,550][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0579, 0.2565, 0.0919, 0.0261, 0.1070, 0.1234, 0.0904, 0.0728, 0.1104,
        0.0352, 0.0284], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,552][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([1.3593e-05, 5.3452e-02, 4.1054e-02, 4.2328e-02, 1.8622e-02, 1.9165e-01,
        3.8958e-01, 1.7777e-01, 7.8388e-02, 5.9690e-03, 1.1722e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,553][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0320, 0.0729, 0.0773, 0.0782, 0.0554, 0.1456, 0.1035, 0.1975, 0.1002,
        0.0901, 0.0474], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,555][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0350, 0.4629, 0.0159, 0.0621, 0.0219, 0.1589, 0.0821, 0.0145, 0.0489,
        0.0415, 0.0401, 0.0161], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,557][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.2456, 0.0602, 0.0536, 0.0619, 0.0632, 0.0803, 0.0839, 0.0641, 0.0561,
        0.0965, 0.0940, 0.0405], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,558][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([5.6779e-05, 2.1304e-02, 2.3866e-02, 1.1765e-01, 1.2969e-02, 1.5742e-01,
        1.1926e-01, 2.8713e-01, 1.3703e-01, 6.3937e-02, 2.7342e-02, 3.2039e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,560][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.2648, 0.2635, 0.0179, 0.0487, 0.0226, 0.0818, 0.0459, 0.0156, 0.0346,
        0.0618, 0.0802, 0.0628], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,562][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0511, 0.3812, 0.0173, 0.0740, 0.0275, 0.0909, 0.0741, 0.0370, 0.0586,
        0.0545, 0.0764, 0.0575], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,562][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.8134, 0.0362, 0.0039, 0.0049, 0.0207, 0.0061, 0.0083, 0.0035, 0.0073,
        0.0214, 0.0385, 0.0359], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,563][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.2209, 0.1661, 0.0436, 0.0863, 0.0310, 0.0766, 0.0328, 0.0245, 0.0248,
        0.1158, 0.1062, 0.0715], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,564][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0705, 0.2177, 0.1042, 0.0908, 0.0539, 0.0671, 0.0680, 0.0657, 0.0600,
        0.0907, 0.0770, 0.0344], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,565][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0284, 0.3610, 0.0291, 0.0570, 0.0346, 0.1350, 0.1485, 0.0560, 0.0717,
        0.0336, 0.0277, 0.0172], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,567][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0355, 0.2864, 0.0224, 0.0491, 0.0364, 0.1692, 0.1160, 0.0486, 0.0888,
        0.0409, 0.0400, 0.0668], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,568][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([1.8977e-04, 3.2390e-02, 5.3636e-02, 1.0542e-01, 2.3941e-02, 2.1725e-01,
        2.6246e-01, 1.3618e-01, 1.0115e-01, 2.3491e-02, 1.7336e-02, 2.6563e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,570][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0634, 0.0519, 0.0894, 0.1145, 0.0653, 0.1586, 0.0802, 0.0891, 0.0478,
        0.0842, 0.1137, 0.0419], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,572][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Stephanie] are: tensor([0.1069, 0.3339, 0.0167, 0.0265, 0.0257, 0.1081, 0.0869, 0.0294, 0.0696,
        0.0423, 0.0363, 0.0573, 0.0604], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,573][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Stephanie] are: tensor([0.1135, 0.0713, 0.0747, 0.0669, 0.0912, 0.1397, 0.0594, 0.0472, 0.0446,
        0.0788, 0.0987, 0.0422, 0.0719], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,575][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Stephanie] are: tensor([2.0511e-05, 2.5328e-02, 1.9520e-02, 9.3891e-02, 9.2541e-03, 1.6535e-01,
        1.3627e-01, 2.3143e-01, 1.7020e-01, 8.3747e-02, 2.2463e-02, 2.7760e-02,
        1.4769e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,576][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Stephanie] are: tensor([0.3279, 0.1819, 0.0194, 0.0375, 0.0159, 0.0800, 0.0404, 0.0114, 0.0341,
        0.0541, 0.0782, 0.0764, 0.0428], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,578][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Stephanie] are: tensor([0.1204, 0.2118, 0.0213, 0.0445, 0.0362, 0.0725, 0.0837, 0.0393, 0.0671,
        0.0610, 0.0616, 0.1040, 0.0767], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,580][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Stephanie] are: tensor([0.6549, 0.0430, 0.0099, 0.0084, 0.0310, 0.0136, 0.0130, 0.0097, 0.0229,
        0.0369, 0.0492, 0.0603, 0.0473], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,582][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Stephanie] are: tensor([0.2485, 0.1318, 0.0423, 0.0534, 0.0339, 0.0723, 0.0291, 0.0267, 0.0327,
        0.0938, 0.0830, 0.1058, 0.0466], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,583][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Stephanie] are: tensor([0.0685, 0.1692, 0.0899, 0.0873, 0.0451, 0.0853, 0.0623, 0.0695, 0.0853,
        0.0785, 0.0721, 0.0350, 0.0520], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,585][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Stephanie] are: tensor([0.0972, 0.1911, 0.0256, 0.0352, 0.0410, 0.0771, 0.1192, 0.0489, 0.0979,
        0.0439, 0.0396, 0.0753, 0.1080], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,587][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Stephanie] are: tensor([0.0511, 0.2047, 0.0211, 0.0325, 0.0269, 0.1446, 0.1018, 0.0426, 0.1108,
        0.0534, 0.0462, 0.0964, 0.0679], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,588][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Stephanie] are: tensor([1.8777e-04, 3.6336e-02, 4.0710e-02, 8.4982e-02, 1.9814e-02, 2.2224e-01,
        2.7915e-01, 8.0479e-02, 1.3087e-01, 4.5173e-02, 2.0345e-02, 1.9780e-02,
        1.9935e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,590][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Stephanie] are: tensor([0.0693, 0.0699, 0.0399, 0.0874, 0.0316, 0.0862, 0.0790, 0.1274, 0.1070,
        0.1171, 0.0746, 0.0745, 0.0360], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,592][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0583, 0.6311, 0.0135, 0.0318, 0.0308, 0.0726, 0.0174, 0.0049, 0.0164,
        0.0201, 0.0242, 0.0181, 0.0322, 0.0289], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:41,593][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0543, 0.0522, 0.0750, 0.0320, 0.1148, 0.1121, 0.0679, 0.0542, 0.0745,
        0.0727, 0.0544, 0.0366, 0.1056, 0.0937], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:41,595][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([1.6064e-05, 1.4771e-02, 2.5348e-02, 1.3470e-01, 1.3804e-02, 1.3116e-01,
        1.6004e-01, 2.6674e-01, 1.3735e-01, 3.5718e-02, 8.5226e-03, 4.6824e-02,
        1.5754e-02, 9.2576e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:41,596][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.2066, 0.2568, 0.0168, 0.0425, 0.0186, 0.0717, 0.0375, 0.0112, 0.0216,
        0.0523, 0.0668, 0.0357, 0.0374, 0.1246], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:41,598][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0781, 0.4496, 0.0317, 0.0502, 0.0424, 0.0642, 0.0290, 0.0185, 0.0233,
        0.0250, 0.0354, 0.0262, 0.0446, 0.0818], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:41,600][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.5812, 0.0399, 0.0109, 0.0102, 0.0809, 0.0085, 0.0116, 0.0094, 0.0173,
        0.0237, 0.0348, 0.0495, 0.0990, 0.0231], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:41,602][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.1884, 0.1405, 0.0480, 0.0641, 0.0285, 0.0777, 0.0316, 0.0223, 0.0270,
        0.0956, 0.0972, 0.0586, 0.0401, 0.0804], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:41,604][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0621, 0.1819, 0.0606, 0.0515, 0.0429, 0.0892, 0.0703, 0.0707, 0.0588,
        0.0870, 0.0476, 0.0339, 0.0502, 0.0930], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:41,606][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0627, 0.5801, 0.0141, 0.0481, 0.0244, 0.0713, 0.0382, 0.0171, 0.0133,
        0.0194, 0.0224, 0.0124, 0.0335, 0.0431], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:41,607][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0291, 0.3523, 0.0431, 0.0398, 0.0538, 0.1277, 0.0544, 0.0268, 0.0357,
        0.0247, 0.0251, 0.0410, 0.0677, 0.0787], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:41,607][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([2.3862e-05, 3.0825e-02, 3.9864e-02, 6.1295e-02, 2.6842e-02, 1.8859e-01,
        3.4194e-01, 1.8670e-01, 5.9700e-02, 1.2113e-02, 3.1248e-03, 2.6495e-02,
        1.6158e-02, 6.3270e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:41,608][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0400, 0.0363, 0.0822, 0.0741, 0.0592, 0.1040, 0.0851, 0.0962, 0.0568,
        0.0912, 0.0616, 0.0474, 0.0671, 0.0989], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:41,609][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.3081, 0.1202, 0.0227, 0.0124, 0.0377, 0.0343, 0.0223, 0.0082, 0.0466,
        0.0217, 0.0222, 0.0487, 0.0793, 0.0622, 0.1534], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:41,611][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.3415, 0.0469, 0.0450, 0.0301, 0.0603, 0.0592, 0.0199, 0.0250, 0.0228,
        0.0552, 0.0784, 0.0282, 0.0649, 0.0611, 0.0616], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:41,612][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.7115e-05, 3.5382e-02, 1.6466e-02, 1.0293e-01, 7.2044e-03, 1.0903e-01,
        1.3566e-01, 2.4302e-01, 1.0503e-01, 5.4432e-02, 1.4327e-02, 2.6046e-02,
        1.0380e-02, 1.2900e-02, 1.2717e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:41,614][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.5481, 0.0761, 0.0134, 0.0180, 0.0149, 0.0267, 0.0169, 0.0066, 0.0171,
        0.0292, 0.0428, 0.0265, 0.0333, 0.0741, 0.0565], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:41,616][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.4009, 0.1039, 0.0151, 0.0252, 0.0204, 0.0271, 0.0167, 0.0121, 0.0215,
        0.0319, 0.0491, 0.0486, 0.0494, 0.1040, 0.0741], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:41,618][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.9031, 0.0063, 0.0025, 0.0015, 0.0170, 0.0012, 0.0016, 0.0017, 0.0024,
        0.0065, 0.0118, 0.0087, 0.0227, 0.0071, 0.0059], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:41,619][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.4713, 0.0855, 0.0243, 0.0376, 0.0203, 0.0285, 0.0114, 0.0091, 0.0112,
        0.0766, 0.0790, 0.0514, 0.0274, 0.0354, 0.0310], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:41,621][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1107, 0.2016, 0.0621, 0.0489, 0.0308, 0.0487, 0.0388, 0.0300, 0.0302,
        0.0695, 0.0455, 0.0217, 0.0295, 0.0945, 0.1373], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:41,623][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1979, 0.1367, 0.0470, 0.0174, 0.0541, 0.0448, 0.0436, 0.0253, 0.0493,
        0.0148, 0.0190, 0.0289, 0.1311, 0.0894, 0.1007], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:41,625][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1861, 0.0749, 0.0491, 0.0165, 0.0400, 0.0711, 0.0444, 0.0235, 0.0595,
        0.0273, 0.0282, 0.0678, 0.0998, 0.1435, 0.0682], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:41,626][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([9.5370e-05, 6.3670e-02, 4.1901e-02, 6.8259e-02, 3.2155e-02, 1.9091e-01,
        3.0314e-01, 1.3190e-01, 5.6414e-02, 1.7021e-02, 5.4957e-03, 2.0814e-02,
        1.9904e-02, 9.9741e-03, 3.8346e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:41,628][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0879, 0.0566, 0.0523, 0.0468, 0.0548, 0.0771, 0.0458, 0.0762, 0.0389,
        0.0659, 0.0541, 0.0777, 0.0535, 0.1014, 0.1110], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:41,632][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:25:41,634][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 8513],
        [ 3758],
        [12684],
        [ 1825],
        [ 5492],
        [ 2136],
        [ 1295],
        [ 2208],
        [ 2433],
        [ 1266],
        [ 1717],
        [ 2688],
        [ 4554],
        [ 1421],
        [ 1358]], device='cuda:0')
[2024-07-24 10:25:41,635][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 8205],
        [ 7284],
        [14793],
        [ 3265],
        [ 7547],
        [ 2925],
        [ 1612],
        [ 3371],
        [ 3816],
        [ 2409],
        [ 3034],
        [ 4444],
        [ 7593],
        [ 1872],
        [ 2278]], device='cuda:0')
[2024-07-24 10:25:41,637][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[38491],
        [42654],
        [43396],
        [43981],
        [44333],
        [44293],
        [42616],
        [42992],
        [43181],
        [45791],
        [46397],
        [44457],
        [45627],
        [43822],
        [47065]], device='cuda:0')
[2024-07-24 10:25:41,639][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[5315],
        [1040],
        [ 324],
        [ 643],
        [ 708],
        [ 727],
        [ 674],
        [ 693],
        [ 656],
        [ 602],
        [ 611],
        [ 548],
        [ 542],
        [ 500],
        [ 487]], device='cuda:0')
[2024-07-24 10:25:41,640][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[17683],
        [12167],
        [21420],
        [16437],
        [16915],
        [16528],
        [15071],
        [13700],
        [13412],
        [13060],
        [12969],
        [12843],
        [13083],
        [13319],
        [13071]], device='cuda:0')
[2024-07-24 10:25:41,642][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[8175],
        [2392],
        [2348],
        [2825],
        [3094],
        [3528],
        [3574],
        [3163],
        [3070],
        [3105],
        [3179],
        [3048],
        [2991],
        [3071],
        [3025]], device='cuda:0')
[2024-07-24 10:25:41,643][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[24976],
        [12962],
        [ 9541],
        [ 8456],
        [ 9586],
        [14514],
        [16472],
        [13474],
        [12651],
        [12599],
        [11898],
        [13067],
        [12914],
        [12524],
        [13037]], device='cuda:0')
[2024-07-24 10:25:41,645][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[10367],
        [10102],
        [10431],
        [10350],
        [ 9700],
        [10130],
        [ 9807],
        [ 9963],
        [10116],
        [11022],
        [ 9910],
        [ 8465],
        [ 9292],
        [ 9155],
        [ 9143]], device='cuda:0')
[2024-07-24 10:25:41,647][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 8256],
        [27580],
        [37177],
        [36778],
        [35350],
        [32516],
        [31884],
        [32184],
        [32465],
        [32934],
        [32633],
        [31942],
        [32441],
        [33256],
        [33416]], device='cuda:0')
[2024-07-24 10:25:41,648][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[18164],
        [26057],
        [28496],
        [29024],
        [32252],
        [28860],
        [28577],
        [31352],
        [33763],
        [34074],
        [35763],
        [36004],
        [37045],
        [37029],
        [37557]], device='cuda:0')
[2024-07-24 10:25:41,650][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[2773],
        [1784],
        [1693],
        [1954],
        [1912],
        [1693],
        [1688],
        [1680],
        [1037],
        [ 894],
        [ 857],
        [ 741],
        [ 845],
        [1435],
        [1482]], device='cuda:0')
[2024-07-24 10:25:41,652][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[32696],
        [ 9113],
        [11017],
        [ 7297],
        [ 9472],
        [11702],
        [ 8907],
        [ 8983],
        [ 8878],
        [ 8942],
        [ 8426],
        [ 7617],
        [ 7028],
        [ 7395],
        [ 5976]], device='cuda:0')
[2024-07-24 10:25:41,653][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[22182],
        [ 3809],
        [17727],
        [11689],
        [ 3372],
        [ 5642],
        [ 5536],
        [ 7106],
        [ 6524],
        [ 5806],
        [ 5761],
        [ 4624],
        [ 4187],
        [ 4916],
        [ 3205]], device='cuda:0')
[2024-07-24 10:25:41,655][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[14287],
        [ 3590],
        [ 6025],
        [ 1445],
        [  865],
        [ 1282],
        [ 1535],
        [ 1884],
        [ 1486],
        [ 1539],
        [ 1588],
        [ 1435],
        [ 1402],
        [ 1441],
        [ 2073]], device='cuda:0')
[2024-07-24 10:25:41,656][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[18269],
        [16525],
        [17832],
        [13754],
        [20102],
        [16949],
        [14892],
        [15754],
        [15441],
        [14455],
        [14205],
        [17807],
        [17172],
        [19326],
        [15539]], device='cuda:0')
[2024-07-24 10:25:41,658][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[36835],
        [14143],
        [24798],
        [11960],
        [11428],
        [15767],
        [11063],
        [10518],
        [10478],
        [11237],
        [11615],
        [ 9894],
        [11177],
        [10459],
        [17549]], device='cuda:0')
[2024-07-24 10:25:41,660][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 9040],
        [18919],
        [ 6906],
        [14968],
        [16696],
        [13945],
        [13980],
        [14649],
        [10200],
        [18480],
        [18860],
        [19192],
        [20032],
        [19608],
        [18674]], device='cuda:0')
[2024-07-24 10:25:41,661][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[14355],
        [10464],
        [11048],
        [ 9123],
        [ 8719],
        [21890],
        [28024],
        [37842],
        [26139],
        [32028],
        [34337],
        [33770],
        [31397],
        [32355],
        [30515]], device='cuda:0')
[2024-07-24 10:25:41,663][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[5621],
        [ 878],
        [2635],
        [ 865],
        [ 834],
        [1070],
        [ 700],
        [ 672],
        [ 643],
        [ 932],
        [1535],
        [1609],
        [1539],
        [1162],
        [1696]], device='cuda:0')
[2024-07-24 10:25:41,665][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[10261],
        [ 1694],
        [ 2418],
        [ 1319],
        [ 1186],
        [ 1479],
        [ 1116],
        [  732],
        [  710],
        [  210],
        [  179],
        [  214],
        [  146],
        [  259],
        [  230]], device='cuda:0')
[2024-07-24 10:25:41,666][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[33466],
        [33331],
        [33316],
        [33127],
        [33393],
        [34138],
        [33991],
        [33852],
        [33642],
        [23213],
        [19777],
        [28401],
        [17799],
        [14313],
        [33423]], device='cuda:0')
[2024-07-24 10:25:41,668][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[13027],
        [17997],
        [16547],
        [18666],
        [20111],
        [18440],
        [18669],
        [18115],
        [17179],
        [24384],
        [26407],
        [26599],
        [25240],
        [25618],
        [24327]], device='cuda:0')
[2024-07-24 10:25:41,670][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[30142],
        [ 5013],
        [ 6623],
        [ 5347],
        [ 5090],
        [ 6485],
        [ 6243],
        [ 5529],
        [ 4749],
        [ 4924],
        [ 4725],
        [ 4960],
        [ 4919],
        [ 5909],
        [ 6699]], device='cuda:0')
[2024-07-24 10:25:41,671][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[45152],
        [31698],
        [41137],
        [30443],
        [35587],
        [33482],
        [29649],
        [29368],
        [31643],
        [32284],
        [32429],
        [31804],
        [37335],
        [32581],
        [38683]], device='cuda:0')
[2024-07-24 10:25:41,673][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[27615],
        [ 5571],
        [ 8322],
        [ 5245],
        [ 8281],
        [14434],
        [ 6524],
        [ 6605],
        [ 7303],
        [14823],
        [15938],
        [11834],
        [15862],
        [10641],
        [22570]], device='cuda:0')
[2024-07-24 10:25:41,675][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[44086],
        [46405],
        [45819],
        [42815],
        [44959],
        [45304],
        [45783],
        [45930],
        [45786],
        [46634],
        [46867],
        [46913],
        [46854],
        [46759],
        [46801]], device='cuda:0')
[2024-07-24 10:25:41,677][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[25308],
        [22510],
        [24941],
        [26798],
        [26697],
        [26057],
        [26047],
        [27938],
        [29423],
        [29384],
        [29461],
        [26672],
        [28731],
        [28038],
        [26639]], device='cuda:0')
[2024-07-24 10:25:41,678][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 6373],
        [34440],
        [26123],
        [37006],
        [33262],
        [28193],
        [34015],
        [33090],
        [35407],
        [30790],
        [29879],
        [30555],
        [29026],
        [31282],
        [21516]], device='cuda:0')
[2024-07-24 10:25:41,680][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[23012],
        [24995],
        [23713],
        [28192],
        [21574],
        [22818],
        [26801],
        [26105],
        [26892],
        [26411],
        [26765],
        [22698],
        [24675],
        [22710],
        [24817]], device='cuda:0')
[2024-07-24 10:25:41,681][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[16705],
        [16705],
        [16705],
        [16705],
        [16705],
        [16705],
        [16705],
        [16705],
        [16705],
        [16705],
        [16705],
        [16705],
        [16705],
        [16705],
        [16705]], device='cuda:0')
[2024-07-24 10:25:41,779][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:41,780][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,782][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,783][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,784][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,786][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,787][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,787][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,788][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,789][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,789][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,790][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,792][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:41,793][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4843, 0.5157], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,795][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0562, 0.9438], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,796][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9885, 0.0115], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,798][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.7660, 0.2340], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,799][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0299, 0.9701], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,801][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9860, 0.0140], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,803][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9381, 0.0619], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,804][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.4914, 0.5086], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,806][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1150, 0.8850], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,807][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.5194, 0.4806], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,809][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.8621, 0.1379], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,811][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6553, 0.3447], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:41,812][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Jose] are: tensor([0.3785, 0.3928, 0.2288], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,814][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Jose] are: tensor([0.0250, 0.8167, 0.1584], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,815][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Jose] are: tensor([0.9607, 0.0178, 0.0215], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,817][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Jose] are: tensor([0.8983, 0.0347, 0.0670], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,819][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Jose] are: tensor([0.0366, 0.9565, 0.0069], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,820][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Jose] are: tensor([9.8651e-01, 1.2903e-02, 5.8643e-04], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,821][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Jose] are: tensor([0.9471, 0.0408, 0.0121], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,823][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Jose] are: tensor([0.1388, 0.8141, 0.0471], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,824][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Jose] are: tensor([0.0557, 0.4978, 0.4465], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,826][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Jose] are: tensor([0.3083, 0.3537, 0.3380], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,828][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Jose] are: tensor([0.9372, 0.0452, 0.0176], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,829][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Jose] are: tensor([0.1163, 0.5258, 0.3579], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:41,831][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2789, 0.3054, 0.1738, 0.2419], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,832][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0248, 0.5139, 0.3687, 0.0926], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,832][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.9465, 0.0202, 0.0222, 0.0111], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,833][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3713, 0.1075, 0.4384, 0.0828], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,834][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0091, 0.8601, 0.0021, 0.1287], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,835][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([9.8070e-01, 1.7581e-02, 4.1495e-04, 1.3088e-03], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,836][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.9123, 0.0525, 0.0296, 0.0057], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,838][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0305, 0.6686, 0.0886, 0.2123], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,839][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0455, 0.3332, 0.3232, 0.2982], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,841][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2589, 0.3098, 0.3618, 0.0696], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,843][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.7345, 0.1746, 0.0468, 0.0441], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,844][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2460, 0.2026, 0.4219, 0.1294], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:41,846][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Stephanie] are: tensor([0.2306, 0.2681, 0.1502, 0.2119, 0.1392], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,847][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Stephanie] are: tensor([0.0046, 0.4615, 0.1803, 0.2537, 0.0999], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,849][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Stephanie] are: tensor([0.8927, 0.0254, 0.0208, 0.0208, 0.0403], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,851][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Stephanie] are: tensor([0.4688, 0.1051, 0.1669, 0.0966, 0.1625], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,852][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Stephanie] are: tensor([0.0235, 0.7923, 0.0029, 0.1670, 0.0143], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,853][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Stephanie] are: tensor([9.8832e-01, 9.0967e-03, 2.2706e-04, 9.8689e-04, 1.3710e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,855][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Stephanie] are: tensor([0.7417, 0.1400, 0.0329, 0.0470, 0.0384], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,856][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Stephanie] are: tensor([0.3809, 0.3113, 0.0249, 0.0404, 0.2425], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,858][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Stephanie] are: tensor([0.0259, 0.2714, 0.2473, 0.2313, 0.2241], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,860][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Stephanie] are: tensor([0.0859, 0.1639, 0.3327, 0.2160, 0.2015], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,861][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Stephanie] are: tensor([0.7163, 0.1515, 0.0416, 0.0474, 0.0432], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,863][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Stephanie] are: tensor([0.3131, 0.1377, 0.1752, 0.1525, 0.2215], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:41,865][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.2285, 0.2322, 0.1288, 0.1842, 0.1151, 0.1112], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,866][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.1782, 0.2291, 0.2887, 0.0605, 0.2018, 0.0416], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,868][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.9110, 0.0186, 0.0127, 0.0096, 0.0266, 0.0214], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,870][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.3708, 0.0744, 0.1791, 0.0422, 0.2280, 0.1055], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,871][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0097, 0.5370, 0.0022, 0.0858, 0.0103, 0.3550], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,872][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ had] are: tensor([9.9846e-01, 1.1720e-03, 3.3568e-05, 8.6760e-05, 2.0593e-04, 3.7777e-05],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,874][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ had] are: tensor([9.7978e-01, 9.2063e-03, 4.1571e-03, 1.0116e-03, 5.2662e-03, 5.8227e-04],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,875][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.2801, 0.1316, 0.0163, 0.0172, 0.2522, 0.3026], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,877][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0315, 0.2211, 0.2013, 0.1999, 0.1971, 0.1491], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,878][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0420, 0.2093, 0.1069, 0.3188, 0.2645, 0.0585], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,878][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.8059, 0.0849, 0.0251, 0.0250, 0.0306, 0.0284], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,879][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.1807, 0.1050, 0.1464, 0.0616, 0.1124, 0.3939], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:41,880][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1758, 0.1743, 0.0965, 0.1337, 0.0863, 0.0794, 0.2541],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,881][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.4390, 0.1791, 0.0945, 0.0625, 0.0718, 0.0611, 0.0921],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,883][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.9175, 0.0142, 0.0107, 0.0065, 0.0209, 0.0159, 0.0142],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,885][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2573, 0.0982, 0.1663, 0.0476, 0.1728, 0.1090, 0.1487],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,886][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([7.8343e-03, 5.5196e-01, 3.1588e-04, 9.0033e-02, 2.2861e-03, 2.1886e-01,
        1.2871e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,887][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([9.9366e-01, 5.7730e-03, 1.0622e-05, 1.8757e-04, 1.8203e-04, 1.0049e-04,
        8.9405e-05], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,888][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([9.9341e-01, 3.3533e-03, 9.8634e-04, 2.6828e-04, 1.1173e-03, 2.8725e-04,
        5.7875e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,889][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([7.2667e-01, 4.5345e-03, 3.8622e-04, 1.8271e-04, 2.1318e-03, 4.3790e-03,
        2.6172e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,891][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0259, 0.2058, 0.1783, 0.1842, 0.1689, 0.1423, 0.0946],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,893][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0314, 0.1874, 0.1710, 0.2611, 0.1670, 0.0570, 0.1251],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,894][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.7289, 0.1594, 0.0161, 0.0264, 0.0245, 0.0235, 0.0210],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,896][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.2632, 0.1077, 0.1105, 0.0750, 0.0704, 0.2993, 0.0739],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:41,898][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.1307, 0.1558, 0.0887, 0.1214, 0.0787, 0.0741, 0.2282, 0.1224],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,899][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.2739, 0.2226, 0.1178, 0.0850, 0.0712, 0.0583, 0.0841, 0.0872],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,901][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.8448, 0.0235, 0.0196, 0.0121, 0.0372, 0.0280, 0.0214, 0.0134],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,903][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.4287, 0.0816, 0.0576, 0.0273, 0.0761, 0.0645, 0.1094, 0.1547],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,904][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ long] are: tensor([1.1485e-02, 4.4412e-01, 1.8701e-04, 6.4187e-02, 1.5440e-03, 1.8990e-01,
        2.5588e-01, 3.2701e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,905][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ long] are: tensor([9.9345e-01, 5.4459e-03, 1.3152e-05, 2.4980e-04, 2.4961e-04, 1.7220e-04,
        3.3647e-04, 7.8888e-05], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,906][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ long] are: tensor([9.7433e-01, 1.5430e-02, 1.7939e-03, 1.8209e-03, 2.7233e-03, 1.0090e-03,
        2.0560e-03, 8.3215e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,908][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ long] are: tensor([1.6098e-01, 3.7116e-03, 2.8037e-04, 1.0586e-04, 1.8811e-03, 3.5317e-03,
        4.7728e-01, 3.5223e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,909][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0168, 0.1830, 0.1527, 0.1552, 0.1690, 0.1222, 0.0851, 0.1161],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,911][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0901, 0.1354, 0.1443, 0.1468, 0.1171, 0.0549, 0.0787, 0.2326],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,913][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.7002, 0.1703, 0.0130, 0.0297, 0.0194, 0.0255, 0.0279, 0.0140],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,914][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0546, 0.1545, 0.0994, 0.0569, 0.0853, 0.2950, 0.0705, 0.1838],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:41,916][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.1342, 0.1393, 0.0760, 0.1082, 0.0682, 0.0648, 0.2056, 0.1075, 0.0962],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,918][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0876, 0.0952, 0.0789, 0.1438, 0.0547, 0.1379, 0.1625, 0.1520, 0.0873],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,920][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.8530, 0.0191, 0.0136, 0.0106, 0.0271, 0.0235, 0.0205, 0.0105, 0.0221],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,921][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.3539, 0.0959, 0.0635, 0.0572, 0.0485, 0.0775, 0.1125, 0.0843, 0.1068],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,922][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([8.6394e-03, 3.4512e-01, 6.1604e-05, 4.3792e-02, 9.3665e-04, 1.6840e-01,
        3.6364e-01, 3.2256e-02, 3.7157e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,923][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([9.9283e-01, 5.9837e-03, 5.6071e-06, 2.6635e-04, 1.4264e-04, 1.2362e-04,
        4.1938e-04, 1.0113e-04, 1.2761e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,924][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([9.8479e-01, 6.2611e-03, 1.0300e-03, 1.3294e-03, 2.2616e-03, 7.7447e-04,
        1.9080e-03, 6.0331e-04, 1.0443e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,924][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([8.6849e-01, 9.8938e-04, 3.0274e-05, 4.4942e-05, 2.0507e-04, 1.3189e-03,
        6.5759e-02, 4.1700e-02, 2.1467e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,925][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0117, 0.1573, 0.1501, 0.1353, 0.1421, 0.1021, 0.0741, 0.1035, 0.1237],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,927][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0282, 0.0898, 0.0225, 0.1152, 0.0281, 0.0303, 0.0791, 0.4825, 0.1242],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,929][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.6377, 0.2033, 0.0103, 0.0407, 0.0135, 0.0327, 0.0368, 0.0122, 0.0128],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,930][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0430, 0.0277, 0.0458, 0.0368, 0.0960, 0.1762, 0.1109, 0.3124, 0.1512],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:41,932][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1048, 0.1239, 0.0708, 0.0966, 0.0600, 0.0597, 0.1881, 0.0975, 0.0892,
        0.1094], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,933][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0023, 0.0882, 0.1447, 0.0886, 0.0363, 0.1086, 0.2444, 0.2039, 0.0690,
        0.0139], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,935][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6747, 0.0379, 0.0247, 0.0169, 0.0385, 0.0449, 0.0405, 0.0255, 0.0425,
        0.0540], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,937][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0226, 0.0613, 0.1068, 0.0389, 0.0744, 0.1113, 0.1752, 0.1393, 0.2092,
        0.0608], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,939][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0009, 0.1237, 0.0005, 0.0247, 0.0020, 0.1793, 0.3757, 0.1230, 0.1396,
        0.0305], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,940][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([9.2493e-01, 2.8052e-02, 6.2898e-04, 2.9700e-03, 5.1784e-03, 2.9423e-03,
        5.9326e-03, 3.2163e-03, 6.1876e-03, 1.9964e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,942][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.5591, 0.0869, 0.0853, 0.0148, 0.0723, 0.0307, 0.0544, 0.0353, 0.0319,
        0.0294], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,943][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([6.1482e-04, 2.0850e-04, 1.8815e-04, 3.0795e-05, 1.5608e-03, 1.4823e-03,
        1.9752e-01, 4.6827e-01, 3.2804e-01, 2.0893e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,945][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0131, 0.1377, 0.1297, 0.1194, 0.1244, 0.1036, 0.0674, 0.1013, 0.1239,
        0.0795], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,946][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0174, 0.0719, 0.1086, 0.0769, 0.0579, 0.0252, 0.1493, 0.3879, 0.0737,
        0.0312], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,948][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2120, 0.2364, 0.0462, 0.0565, 0.0759, 0.0733, 0.0939, 0.0579, 0.0649,
        0.0831], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,950][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0424, 0.0196, 0.0470, 0.0199, 0.0584, 0.1294, 0.0691, 0.5078, 0.0847,
        0.0216], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:41,951][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0806, 0.1109, 0.0630, 0.0886, 0.0542, 0.0529, 0.1787, 0.0909, 0.0830,
        0.1016, 0.0956], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,953][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.2712e-04, 6.8760e-02, 1.1119e-01, 7.7889e-02, 2.6722e-02, 1.1845e-01,
        2.7633e-01, 2.4393e-01, 6.5865e-02, 7.9822e-03, 2.6479e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,954][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3892, 0.0474, 0.0435, 0.0265, 0.0649, 0.0806, 0.0685, 0.0509, 0.0718,
        0.0773, 0.0796], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,956][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0145, 0.0567, 0.1042, 0.0430, 0.0743, 0.0910, 0.1816, 0.1638, 0.1771,
        0.0583, 0.0354], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,958][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0018, 0.1077, 0.0008, 0.0169, 0.0036, 0.1321, 0.3528, 0.1369, 0.1998,
        0.0294, 0.0181], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,960][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.8214, 0.0375, 0.0018, 0.0049, 0.0104, 0.0063, 0.0136, 0.0108, 0.0151,
        0.0337, 0.0446], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,961][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1429, 0.1903, 0.1503, 0.0241, 0.1194, 0.0524, 0.0904, 0.0692, 0.0877,
        0.0436, 0.0295], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,963][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([8.0672e-05, 2.1982e-04, 1.3539e-04, 4.0359e-05, 1.2101e-03, 1.2999e-03,
        1.9180e-01, 5.9489e-01, 2.0896e-01, 1.2019e-03, 1.6532e-04],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,964][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0132, 0.1289, 0.1237, 0.1093, 0.1142, 0.0981, 0.0629, 0.0928, 0.1168,
        0.0708, 0.0695], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,966][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0324, 0.0770, 0.0771, 0.0271, 0.0797, 0.0262, 0.1112, 0.4176, 0.1021,
        0.0302, 0.0194], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,967][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1201, 0.2122, 0.0440, 0.0677, 0.0648, 0.0874, 0.1049, 0.0738, 0.0686,
        0.0878, 0.0687], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,968][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0152, 0.0223, 0.0476, 0.0223, 0.0323, 0.2388, 0.0547, 0.4378, 0.0836,
        0.0316, 0.0136], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:41,969][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0837, 0.1024, 0.0572, 0.0800, 0.0517, 0.0485, 0.1574, 0.0810, 0.0742,
        0.0892, 0.0872, 0.0876], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,969][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0045, 0.0512, 0.0819, 0.1016, 0.0279, 0.1625, 0.1843, 0.1497, 0.1199,
        0.0407, 0.0310, 0.0449], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,971][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.6669, 0.0212, 0.0216, 0.0134, 0.0374, 0.0264, 0.0267, 0.0165, 0.0285,
        0.0343, 0.0553, 0.0517], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,973][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0860, 0.0592, 0.0704, 0.0502, 0.0628, 0.0869, 0.1281, 0.0949, 0.1087,
        0.0921, 0.0783, 0.0824], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,974][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([3.0862e-03, 1.9648e-01, 6.1113e-05, 2.5291e-02, 4.8150e-04, 2.4793e-01,
        3.4762e-01, 4.1778e-02, 4.2457e-02, 3.6046e-02, 3.0592e-02, 2.8181e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,975][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([9.6051e-01, 9.7888e-03, 4.3372e-05, 8.4884e-04, 7.6099e-04, 5.3814e-04,
        1.5608e-03, 4.7182e-04, 8.6723e-04, 7.8597e-03, 1.3733e-02, 3.0133e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,977][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.5676, 0.0978, 0.0289, 0.0162, 0.0337, 0.0201, 0.0386, 0.0191, 0.0365,
        0.0224, 0.0388, 0.0804], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,978][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([4.4101e-01, 3.9031e-03, 2.4052e-04, 1.9427e-04, 1.4806e-03, 5.1247e-03,
        1.8181e-01, 2.0409e-01, 1.0320e-01, 1.7765e-02, 1.8682e-03, 3.9322e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,980][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0086, 0.1205, 0.1055, 0.1003, 0.1103, 0.0813, 0.0540, 0.0909, 0.1201,
        0.0683, 0.0656, 0.0747], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,981][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0351, 0.1381, 0.0527, 0.1453, 0.1328, 0.0184, 0.0454, 0.0777, 0.0934,
        0.0641, 0.0892, 0.1078], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,983][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.2734, 0.1947, 0.0234, 0.0534, 0.0351, 0.0640, 0.0714, 0.0320, 0.0374,
        0.0647, 0.0737, 0.0769], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,985][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0389, 0.0153, 0.0308, 0.0143, 0.0726, 0.1337, 0.0492, 0.4317, 0.1295,
        0.0278, 0.0114, 0.0449], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:41,987][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Stephanie] are: tensor([0.0789, 0.0955, 0.0538, 0.0740, 0.0492, 0.0433, 0.1537, 0.0765, 0.0701,
        0.0834, 0.0807, 0.0802, 0.0607], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,988][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Stephanie] are: tensor([0.0016, 0.0918, 0.0512, 0.0975, 0.0308, 0.1388, 0.1675, 0.1902, 0.0819,
        0.0435, 0.0197, 0.0364, 0.0490], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,990][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Stephanie] are: tensor([0.5381, 0.0259, 0.0198, 0.0193, 0.0376, 0.0316, 0.0350, 0.0229, 0.0353,
        0.0515, 0.0707, 0.0524, 0.0598], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,992][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Stephanie] are: tensor([0.0788, 0.0427, 0.0504, 0.0411, 0.0495, 0.1030, 0.0966, 0.1248, 0.1207,
        0.0632, 0.0499, 0.1116, 0.0675], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,994][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Stephanie] are: tensor([0.0079, 0.2180, 0.0004, 0.0272, 0.0020, 0.2024, 0.2761, 0.0627, 0.0651,
        0.0444, 0.0240, 0.0624, 0.0075], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,995][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Stephanie] are: tensor([9.4644e-01, 8.9245e-03, 1.4286e-04, 8.9576e-04, 1.1651e-03, 7.4413e-04,
        2.5954e-03, 7.7290e-04, 1.6821e-03, 1.0783e-02, 1.3735e-02, 5.5914e-03,
        6.5283e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,996][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Stephanie] are: tensor([0.4469, 0.0791, 0.0171, 0.0240, 0.0247, 0.0273, 0.0471, 0.0285, 0.0366,
        0.0658, 0.0827, 0.0529, 0.0673], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:41,998][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Stephanie] are: tensor([5.4140e-01, 1.8826e-03, 3.1488e-04, 8.8669e-05, 1.2115e-03, 3.5338e-03,
        9.6712e-02, 1.4262e-01, 9.0933e-02, 7.6097e-03, 1.1350e-03, 3.6340e-02,
        7.6219e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,000][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Stephanie] are: tensor([0.0106, 0.1241, 0.1111, 0.0996, 0.0959, 0.0754, 0.0483, 0.0826, 0.0922,
        0.0616, 0.0619, 0.0676, 0.0691], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,001][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Stephanie] are: tensor([0.0380, 0.0502, 0.1268, 0.0772, 0.0727, 0.0294, 0.0386, 0.1480, 0.0654,
        0.0400, 0.0603, 0.1301, 0.1234], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,003][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Stephanie] are: tensor([0.2797, 0.1480, 0.0231, 0.0450, 0.0268, 0.0563, 0.0634, 0.0289, 0.0431,
        0.0705, 0.0759, 0.0848, 0.0547], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,005][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Stephanie] are: tensor([0.0569, 0.0250, 0.0211, 0.0282, 0.0259, 0.2812, 0.0457, 0.3265, 0.0495,
        0.0362, 0.0197, 0.0574, 0.0265], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,007][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0719, 0.0916, 0.0496, 0.0698, 0.0415, 0.0416, 0.1384, 0.0686, 0.0628,
        0.0770, 0.0736, 0.0692, 0.0488, 0.0956], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,008][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0029, 0.1411, 0.0862, 0.0903, 0.0454, 0.0958, 0.1541, 0.2125, 0.0399,
        0.0210, 0.0095, 0.0419, 0.0435, 0.0160], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,010][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.6201, 0.0257, 0.0156, 0.0120, 0.0279, 0.0260, 0.0226, 0.0158, 0.0230,
        0.0379, 0.0486, 0.0435, 0.0423, 0.0391], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,012][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0119, 0.0779, 0.0954, 0.0406, 0.0711, 0.0907, 0.0975, 0.0856, 0.1442,
        0.0557, 0.0353, 0.0433, 0.0513, 0.0993], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,012][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0012, 0.2757, 0.0004, 0.0493, 0.0023, 0.2299, 0.1965, 0.0363, 0.0297,
        0.0282, 0.0207, 0.0106, 0.0031, 0.1161], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,013][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ said] are: tensor([8.4451e-01, 7.6257e-02, 5.5777e-04, 3.3182e-03, 3.9337e-03, 3.2292e-03,
        3.3291e-03, 1.5107e-03, 1.9039e-03, 8.6347e-03, 1.3066e-02, 6.2324e-03,
        9.7949e-03, 2.3719e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,014][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.6048, 0.0425, 0.0262, 0.0072, 0.0448, 0.0172, 0.0235, 0.0221, 0.0186,
        0.0170, 0.0263, 0.0325, 0.0912, 0.0261], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,015][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.2670, 0.0056, 0.0007, 0.0005, 0.0033, 0.0073, 0.1418, 0.2687, 0.0790,
        0.0200, 0.0026, 0.0678, 0.1123, 0.0233], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,017][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0104, 0.1123, 0.0943, 0.0925, 0.0908, 0.0748, 0.0486, 0.0817, 0.0971,
        0.0639, 0.0580, 0.0659, 0.0667, 0.0428], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,019][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0141, 0.0856, 0.0217, 0.1090, 0.0800, 0.0158, 0.0476, 0.1481, 0.0225,
        0.0381, 0.0733, 0.0538, 0.1133, 0.1771], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,020][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.1329, 0.1903, 0.0370, 0.0508, 0.0449, 0.0663, 0.0527, 0.0282, 0.0254,
        0.0562, 0.0574, 0.0386, 0.0619, 0.1574], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,022][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0076, 0.0043, 0.0300, 0.0143, 0.0315, 0.1285, 0.0197, 0.4677, 0.1439,
        0.0143, 0.0186, 0.0196, 0.0281, 0.0720], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,024][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0835, 0.0820, 0.0436, 0.0608, 0.0377, 0.0358, 0.1205, 0.0611, 0.0534,
        0.0725, 0.0684, 0.0639, 0.0442, 0.0842, 0.0884], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,025][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0064, 0.1345, 0.0953, 0.1000, 0.0480, 0.0742, 0.1017, 0.1624, 0.0395,
        0.0274, 0.0171, 0.0595, 0.0555, 0.0218, 0.0565], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,027][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.5520, 0.0192, 0.0190, 0.0128, 0.0326, 0.0230, 0.0225, 0.0159, 0.0302,
        0.0406, 0.0565, 0.0406, 0.0501, 0.0443, 0.0408], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,029][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0603, 0.0804, 0.1017, 0.0421, 0.0656, 0.0643, 0.0593, 0.0630, 0.0787,
        0.0626, 0.0476, 0.0397, 0.0495, 0.1098, 0.0757], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,031][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0146, 0.0526, 0.0025, 0.0205, 0.0097, 0.1181, 0.1885, 0.0814, 0.1109,
        0.0418, 0.0255, 0.0660, 0.0366, 0.1718, 0.0596], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,032][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([9.1852e-01, 1.0172e-02, 6.7273e-04, 9.6163e-04, 3.6707e-03, 9.2373e-04,
        2.0370e-03, 1.0147e-03, 2.4796e-03, 6.2525e-03, 9.2332e-03, 5.2488e-03,
        1.1639e-02, 2.2672e-02, 4.5004e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,034][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.7197, 0.0278, 0.0183, 0.0063, 0.0192, 0.0064, 0.0103, 0.0072, 0.0074,
        0.0177, 0.0324, 0.0149, 0.0344, 0.0322, 0.0460], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,035][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([6.9884e-01, 1.2787e-03, 5.2660e-04, 1.0197e-04, 2.5354e-03, 2.1668e-03,
        2.8022e-02, 8.3470e-02, 4.0562e-02, 5.8710e-03, 1.1800e-03, 2.6238e-02,
        7.1545e-02, 6.6477e-03, 3.1019e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,037][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0119, 0.0980, 0.0925, 0.0924, 0.0924, 0.0656, 0.0424, 0.0649, 0.0869,
        0.0583, 0.0623, 0.0681, 0.0725, 0.0379, 0.0539], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,039][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1003, 0.0500, 0.1445, 0.0678, 0.0979, 0.0111, 0.0318, 0.0903, 0.0345,
        0.0245, 0.0426, 0.1087, 0.0962, 0.0379, 0.0620], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,040][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.3458, 0.1340, 0.0275, 0.0381, 0.0338, 0.0326, 0.0297, 0.0141, 0.0179,
        0.0529, 0.0608, 0.0377, 0.0493, 0.0802, 0.0457], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,042][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0127, 0.0262, 0.0291, 0.0285, 0.0478, 0.1598, 0.0294, 0.2021, 0.2181,
        0.0414, 0.0239, 0.0428, 0.0479, 0.0757, 0.0147], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,142][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:42,143][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:42,144][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:42,145][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:42,145][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:42,147][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:42,148][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:42,149][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:42,151][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:42,152][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:42,153][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:42,154][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:42,155][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:42,157][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9596, 0.0404], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:42,159][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0989, 0.9011], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:42,160][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9555, 0.0445], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:42,162][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.7660, 0.2340], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:42,163][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3289, 0.6711], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:42,164][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.8472, 0.1528], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:42,168][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.7872, 0.2128], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:42,174][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.8450, 0.1550], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:42,174][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9110, 0.0890], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:42,175][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9425, 0.0575], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:42,176][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.8621, 0.1379], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:42,177][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.7670, 0.2330], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:42,178][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Jose] are: tensor([9.6635e-01, 3.3265e-02, 3.8624e-04], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:42,184][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Jose] are: tensor([0.0499, 0.6911, 0.2590], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:42,189][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Jose] are: tensor([0.9629, 0.0283, 0.0088], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:42,192][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Jose] are: tensor([0.8983, 0.0347, 0.0670], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:42,193][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Jose] are: tensor([0.6484, 0.3257, 0.0259], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:42,194][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Jose] are: tensor([0.8819, 0.1121, 0.0060], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:42,195][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Jose] are: tensor([0.8719, 0.0792, 0.0488], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:42,198][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Jose] are: tensor([0.8790, 0.1102, 0.0107], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:42,204][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Jose] are: tensor([0.9853, 0.0090, 0.0057], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:42,209][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Jose] are: tensor([0.9747, 0.0151, 0.0102], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:42,211][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Jose] are: tensor([0.9372, 0.0452, 0.0176], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:42,211][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Jose] are: tensor([0.6228, 0.3108, 0.0664], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:42,212][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9071, 0.0741, 0.0010, 0.0177], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:42,213][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0345, 0.4067, 0.4959, 0.0630], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:42,214][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.9286, 0.0455, 0.0153, 0.0106], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:42,217][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3713, 0.1075, 0.4384, 0.0828], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:42,222][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2169, 0.6766, 0.0239, 0.0826], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:42,227][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.5262, 0.4203, 0.0233, 0.0302], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:42,230][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.7666, 0.0998, 0.1110, 0.0226], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:42,230][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4222, 0.5387, 0.0231, 0.0161], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:42,231][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9071, 0.0580, 0.0287, 0.0062], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:42,232][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.8608, 0.0967, 0.0279, 0.0146], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:42,233][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.7345, 0.1746, 0.0468, 0.0441], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:42,236][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.6009, 0.2912, 0.0590, 0.0489], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:42,242][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Stephanie] are: tensor([0.9229, 0.0571, 0.0011, 0.0137, 0.0052], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:42,247][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Stephanie] are: tensor([0.0119, 0.4063, 0.2515, 0.1814, 0.1488], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:42,248][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Stephanie] are: tensor([0.8496, 0.0767, 0.0147, 0.0264, 0.0326], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:42,249][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Stephanie] are: tensor([0.4688, 0.1051, 0.1669, 0.0966, 0.1625], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:42,250][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Stephanie] are: tensor([0.2995, 0.4993, 0.0313, 0.0972, 0.0727], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:42,251][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Stephanie] are: tensor([0.5972, 0.3126, 0.0121, 0.0372, 0.0409], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:42,254][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Stephanie] are: tensor([0.4389, 0.1898, 0.1376, 0.1111, 0.1227], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:42,259][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Stephanie] are: tensor([0.5929, 0.3213, 0.0208, 0.0267, 0.0382], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:42,265][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Stephanie] are: tensor([0.8765, 0.0636, 0.0191, 0.0083, 0.0326], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:42,267][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Stephanie] are: tensor([0.7693, 0.1070, 0.0449, 0.0286, 0.0502], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:42,268][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Stephanie] are: tensor([0.7163, 0.1515, 0.0416, 0.0474, 0.0432], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:42,268][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Stephanie] are: tensor([0.2724, 0.4312, 0.0322, 0.2151, 0.0491], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:42,269][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([9.3226e-01, 5.2174e-02, 5.0323e-04, 1.3068e-02, 1.8248e-03, 1.6985e-04],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:42,270][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.1937, 0.1692, 0.3474, 0.0377, 0.2228, 0.0291], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:42,273][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.9246, 0.0306, 0.0061, 0.0057, 0.0166, 0.0163], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:42,279][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.3708, 0.0744, 0.1791, 0.0422, 0.2280, 0.1055], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:42,284][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.2812, 0.4774, 0.0239, 0.0652, 0.0502, 0.1021], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:42,286][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.7949, 0.1560, 0.0063, 0.0096, 0.0248, 0.0085], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:42,287][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.9030, 0.0254, 0.0295, 0.0056, 0.0315, 0.0049], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:42,287][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.8341, 0.1351, 0.0053, 0.0039, 0.0135, 0.0081], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:42,288][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.9416, 0.0257, 0.0079, 0.0024, 0.0173, 0.0052], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:42,292][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.9174, 0.0503, 0.0099, 0.0058, 0.0137, 0.0029], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:42,296][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.8059, 0.0849, 0.0251, 0.0250, 0.0306, 0.0284], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:42,302][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.5026, 0.2862, 0.0292, 0.0646, 0.0453, 0.0722], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:42,304][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([6.4810e-01, 2.9100e-02, 2.7086e-04, 4.7679e-03, 1.0809e-03, 4.5036e-05,
        3.1663e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:42,305][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.4009, 0.1775, 0.1579, 0.0507, 0.1009, 0.0507, 0.0615],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:42,306][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.9284, 0.0331, 0.0054, 0.0037, 0.0111, 0.0134, 0.0049],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:42,307][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.2573, 0.0982, 0.1663, 0.0476, 0.1728, 0.1090, 0.1487],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:42,309][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0879, 0.6581, 0.0046, 0.0979, 0.0129, 0.1153, 0.0235],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:42,314][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.5100, 0.4486, 0.0018, 0.0145, 0.0098, 0.0095, 0.0056],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:42,319][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.9672, 0.0113, 0.0063, 0.0018, 0.0075, 0.0024, 0.0035],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:42,323][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.2921, 0.6747, 0.0018, 0.0109, 0.0042, 0.0125, 0.0037],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:42,324][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.9125, 0.0473, 0.0067, 0.0024, 0.0220, 0.0052, 0.0039],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:42,324][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.8882, 0.0721, 0.0115, 0.0069, 0.0142, 0.0036, 0.0035],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:42,325][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.7289, 0.1594, 0.0161, 0.0264, 0.0245, 0.0235, 0.0210],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:42,327][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3088, 0.4477, 0.0179, 0.0436, 0.0253, 0.0590, 0.0976],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:42,330][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([5.1997e-01, 4.3379e-02, 5.0919e-04, 7.6981e-03, 1.5849e-03, 1.3400e-04,
        4.1996e-01, 6.7628e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:42,335][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.3145, 0.1863, 0.1642, 0.0597, 0.0931, 0.0453, 0.0537, 0.0832],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:42,340][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.8198, 0.0678, 0.0135, 0.0114, 0.0255, 0.0359, 0.0135, 0.0126],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:42,342][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.4287, 0.0816, 0.0576, 0.0273, 0.0761, 0.0645, 0.1094, 0.1547],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:42,343][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.1628, 0.5830, 0.0030, 0.0707, 0.0105, 0.1015, 0.0611, 0.0075],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:42,343][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.4614, 0.4469, 0.0020, 0.0233, 0.0139, 0.0194, 0.0276, 0.0056],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:42,344][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.9203, 0.0303, 0.0108, 0.0068, 0.0134, 0.0053, 0.0088, 0.0043],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:42,348][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.1648, 0.7718, 0.0020, 0.0135, 0.0067, 0.0182, 0.0199, 0.0031],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:42,352][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.8195, 0.0939, 0.0113, 0.0067, 0.0361, 0.0133, 0.0125, 0.0066],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:42,358][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.8043, 0.1196, 0.0192, 0.0132, 0.0223, 0.0084, 0.0086, 0.0044],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:42,360][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.7002, 0.1703, 0.0130, 0.0297, 0.0194, 0.0255, 0.0279, 0.0140],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:42,361][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.1333, 0.5097, 0.0167, 0.0641, 0.0219, 0.0826, 0.1317, 0.0400],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:42,362][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([5.4683e-01, 3.6789e-02, 2.4806e-04, 6.5342e-03, 1.0252e-03, 8.8023e-05,
        4.0185e-01, 5.2911e-03, 1.3453e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:42,363][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.1343, 0.0825, 0.1100, 0.1001, 0.0767, 0.1099, 0.1096, 0.1542, 0.1226],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:42,366][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.9364, 0.0227, 0.0033, 0.0036, 0.0089, 0.0117, 0.0047, 0.0035, 0.0052],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:42,371][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.3539, 0.0959, 0.0635, 0.0572, 0.0485, 0.0775, 0.1125, 0.0843, 0.1068],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:42,376][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0939, 0.5815, 0.0018, 0.0747, 0.0093, 0.1194, 0.0985, 0.0094, 0.0116],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:42,381][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.5991, 0.3475, 0.0007, 0.0138, 0.0066, 0.0085, 0.0170, 0.0038, 0.0031],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:42,381][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.9190, 0.0174, 0.0102, 0.0065, 0.0170, 0.0060, 0.0105, 0.0049, 0.0086],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:42,382][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([3.5543e-01, 5.7895e-01, 5.3151e-04, 1.6994e-02, 2.9979e-03, 1.6914e-02,
        2.2963e-02, 2.1137e-03, 3.1044e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:42,383][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.9164, 0.0496, 0.0027, 0.0037, 0.0123, 0.0055, 0.0044, 0.0031, 0.0023],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:42,387][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.8883, 0.0751, 0.0048, 0.0083, 0.0087, 0.0049, 0.0041, 0.0022, 0.0036],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:42,391][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.6377, 0.2033, 0.0103, 0.0407, 0.0135, 0.0327, 0.0368, 0.0122, 0.0128],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:42,397][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.1247, 0.4005, 0.0137, 0.0952, 0.0212, 0.0810, 0.1777, 0.0566, 0.0293],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:42,399][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([2.5037e-01, 4.7730e-02, 9.5291e-04, 1.1348e-02, 1.7037e-03, 2.4452e-04,
        5.7073e-01, 1.2944e-02, 2.8366e-03, 1.0114e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:42,400][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0031, 0.0868, 0.2103, 0.0733, 0.0505, 0.0917, 0.1705, 0.2050, 0.0951,
        0.0137], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:42,401][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6415, 0.0922, 0.0173, 0.0181, 0.0303, 0.0562, 0.0296, 0.0265, 0.0271,
        0.0611], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:42,402][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0226, 0.0613, 0.1068, 0.0389, 0.0744, 0.1113, 0.1752, 0.1393, 0.2092,
        0.0608], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:42,407][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0290, 0.4068, 0.0201, 0.0825, 0.0325, 0.1885, 0.1101, 0.0502, 0.0410,
        0.0394], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:42,413][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2810, 0.3709, 0.0167, 0.0389, 0.0528, 0.0447, 0.0552, 0.0308, 0.0352,
        0.0738], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:42,417][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3482, 0.0838, 0.1295, 0.0270, 0.1084, 0.0523, 0.0834, 0.0592, 0.0503,
        0.0580], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:42,418][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1559, 0.4375, 0.0254, 0.0320, 0.0453, 0.1151, 0.0656, 0.0486, 0.0351,
        0.0395], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:42,419][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.5537, 0.1147, 0.0322, 0.0121, 0.0824, 0.0308, 0.0346, 0.0548, 0.0400,
        0.0449], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:42,419][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.3848, 0.2709, 0.0602, 0.0488, 0.0539, 0.0336, 0.0460, 0.0225, 0.0207,
        0.0586], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:42,423][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2120, 0.2364, 0.0462, 0.0565, 0.0759, 0.0733, 0.0939, 0.0579, 0.0649,
        0.0831], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:42,427][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1294, 0.2502, 0.0295, 0.0359, 0.0355, 0.0705, 0.1811, 0.0924, 0.0859,
        0.0896], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:42,431][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([1.3241e-01, 3.4481e-02, 8.4562e-04, 1.0731e-02, 1.6940e-03, 2.1117e-04,
        6.3414e-01, 1.6687e-02, 3.6401e-03, 9.9533e-02, 6.5633e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:42,435][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0004, 0.0678, 0.1570, 0.0667, 0.0379, 0.1058, 0.2063, 0.2540, 0.0924,
        0.0086, 0.0031], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:42,436][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3646, 0.0828, 0.0355, 0.0264, 0.0587, 0.1073, 0.0555, 0.0658, 0.0655,
        0.0828, 0.0549], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:42,437][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0145, 0.0567, 0.1042, 0.0430, 0.0743, 0.0910, 0.1816, 0.1638, 0.1771,
        0.0583, 0.0354], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:42,438][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0375, 0.3220, 0.0273, 0.0632, 0.0479, 0.1547, 0.1253, 0.0697, 0.0681,
        0.0395, 0.0448], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:42,441][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2306, 0.2592, 0.0254, 0.0331, 0.0646, 0.0523, 0.0701, 0.0613, 0.0545,
        0.0737, 0.0753], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:42,447][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1137, 0.1293, 0.1731, 0.0326, 0.1265, 0.0609, 0.0975, 0.0764, 0.0851,
        0.0636, 0.0412], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:42,452][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1401, 0.3127, 0.0411, 0.0281, 0.0601, 0.1097, 0.0772, 0.0908, 0.0435,
        0.0438, 0.0528], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:42,454][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.4406, 0.1037, 0.0242, 0.0175, 0.0714, 0.0313, 0.0459, 0.0823, 0.0509,
        0.0608, 0.0712], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:42,454][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.2795, 0.2571, 0.0554, 0.0619, 0.0540, 0.0398, 0.0550, 0.0316, 0.0269,
        0.0693, 0.0693], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:42,455][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1201, 0.2122, 0.0440, 0.0677, 0.0648, 0.0874, 0.1049, 0.0738, 0.0686,
        0.0878, 0.0687], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:42,456][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0653, 0.1905, 0.0252, 0.0451, 0.0303, 0.0837, 0.2071, 0.1222, 0.0919,
        0.1046, 0.0341], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:42,458][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([3.5141e-01, 3.1177e-02, 4.2734e-04, 7.1144e-03, 1.7547e-03, 1.5573e-04,
        4.3809e-01, 9.7484e-03, 2.4606e-03, 6.5897e-02, 6.2514e-02, 2.9247e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:42,463][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0101, 0.0497, 0.1125, 0.0760, 0.0415, 0.1349, 0.1326, 0.1547, 0.1595,
        0.0394, 0.0319, 0.0571], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:42,468][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.5921, 0.0625, 0.0176, 0.0143, 0.0256, 0.0487, 0.0231, 0.0187, 0.0182,
        0.0560, 0.0605, 0.0629], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:42,472][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0860, 0.0592, 0.0704, 0.0502, 0.0628, 0.0869, 0.1281, 0.0949, 0.1087,
        0.0921, 0.0783, 0.0824], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:42,473][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0514, 0.3524, 0.0032, 0.0593, 0.0078, 0.2308, 0.1411, 0.0226, 0.0242,
        0.0403, 0.0492, 0.0177], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:42,474][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.2650, 0.3976, 0.0030, 0.0325, 0.0166, 0.0251, 0.0544, 0.0158, 0.0164,
        0.0629, 0.0769, 0.0338], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:42,477][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.2769, 0.0798, 0.0742, 0.0280, 0.0734, 0.0459, 0.0709, 0.0473, 0.0780,
        0.0393, 0.0484, 0.1379], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:42,482][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.1059, 0.6420, 0.0026, 0.0296, 0.0074, 0.0415, 0.0619, 0.0119, 0.0147,
        0.0318, 0.0286, 0.0221], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:42,487][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.6270, 0.0971, 0.0123, 0.0151, 0.0301, 0.0240, 0.0270, 0.0122, 0.0158,
        0.0453, 0.0751, 0.0188], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:42,490][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.5306, 0.1656, 0.0344, 0.0318, 0.0442, 0.0179, 0.0258, 0.0140, 0.0169,
        0.0487, 0.0432, 0.0268], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:42,491][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.2734, 0.1947, 0.0234, 0.0534, 0.0351, 0.0640, 0.0714, 0.0320, 0.0374,
        0.0647, 0.0737, 0.0769], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:42,491][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0810, 0.2748, 0.0136, 0.0669, 0.0239, 0.0812, 0.1813, 0.0640, 0.0444,
        0.0889, 0.0425, 0.0374], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:42,492][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Stephanie] are: tensor([3.1414e-01, 2.3110e-02, 5.6265e-04, 5.7782e-03, 2.1787e-03, 1.2900e-04,
        4.9794e-01, 1.0144e-02, 3.2390e-03, 5.5649e-02, 5.1664e-02, 1.9997e-02,
        1.5462e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,496][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Stephanie] are: tensor([0.0036, 0.0885, 0.0732, 0.0775, 0.0456, 0.1181, 0.1248, 0.1903, 0.1060,
        0.0415, 0.0207, 0.0450, 0.0651], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,500][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Stephanie] are: tensor([0.5087, 0.0677, 0.0129, 0.0211, 0.0255, 0.0383, 0.0288, 0.0229, 0.0198,
        0.0781, 0.0677, 0.0510, 0.0574], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,506][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Stephanie] are: tensor([0.0788, 0.0427, 0.0504, 0.0411, 0.0495, 0.1030, 0.0966, 0.1248, 0.1207,
        0.0632, 0.0499, 0.1116, 0.0675], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,508][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Stephanie] are: tensor([0.0852, 0.3239, 0.0121, 0.0518, 0.0220, 0.1522, 0.1102, 0.0324, 0.0343,
        0.0480, 0.0444, 0.0458, 0.0376], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,509][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Stephanie] are: tensor([0.2667, 0.2353, 0.0062, 0.0250, 0.0195, 0.0299, 0.0759, 0.0267, 0.0339,
        0.0848, 0.0773, 0.0638, 0.0549], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,510][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Stephanie] are: tensor([0.1908, 0.0711, 0.0450, 0.0366, 0.0503, 0.0492, 0.0786, 0.0591, 0.0743,
        0.0803, 0.0785, 0.0904, 0.0957], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,513][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Stephanie] are: tensor([0.2416, 0.2637, 0.0083, 0.0223, 0.0162, 0.0498, 0.0992, 0.0371, 0.0460,
        0.0536, 0.0421, 0.0722, 0.0479], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,518][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Stephanie] are: tensor([0.6087, 0.1006, 0.0127, 0.0103, 0.0220, 0.0201, 0.0191, 0.0188, 0.0160,
        0.0481, 0.0617, 0.0310, 0.0309], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,524][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Stephanie] are: tensor([0.4064, 0.1607, 0.0403, 0.0397, 0.0428, 0.0372, 0.0343, 0.0206, 0.0281,
        0.0530, 0.0513, 0.0421, 0.0435], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,526][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Stephanie] are: tensor([0.2797, 0.1480, 0.0231, 0.0450, 0.0268, 0.0563, 0.0634, 0.0289, 0.0431,
        0.0705, 0.0759, 0.0848, 0.0547], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,527][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Stephanie] are: tensor([0.0607, 0.2049, 0.0088, 0.0744, 0.0124, 0.0757, 0.1731, 0.0833, 0.0504,
        0.1054, 0.0533, 0.0689, 0.0287], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,528][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([1.7370e-01, 3.6097e-02, 4.3411e-04, 7.8284e-03, 8.4912e-04, 1.4720e-04,
        4.6818e-01, 6.5996e-03, 1.8632e-03, 6.7535e-02, 5.6603e-02, 1.3850e-02,
        5.9410e-03, 1.6037e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,529][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0047, 0.1263, 0.1264, 0.0702, 0.0636, 0.0812, 0.1085, 0.2084, 0.0557,
        0.0201, 0.0098, 0.0516, 0.0566, 0.0169], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,532][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.3602, 0.0983, 0.0224, 0.0200, 0.0380, 0.0670, 0.0320, 0.0325, 0.0206,
        0.0702, 0.0393, 0.0637, 0.0639, 0.0719], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,538][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0119, 0.0779, 0.0954, 0.0406, 0.0711, 0.0907, 0.0975, 0.0856, 0.1442,
        0.0557, 0.0353, 0.0433, 0.0513, 0.0993], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,543][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0157, 0.4463, 0.0095, 0.0940, 0.0213, 0.1899, 0.0620, 0.0168, 0.0105,
        0.0275, 0.0305, 0.0065, 0.0139, 0.0557], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,545][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.1622, 0.5840, 0.0082, 0.0279, 0.0200, 0.0258, 0.0189, 0.0078, 0.0065,
        0.0245, 0.0273, 0.0176, 0.0255, 0.0436], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,545][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.3010, 0.0470, 0.0684, 0.0158, 0.0819, 0.0337, 0.0450, 0.0436, 0.0321,
        0.0368, 0.0410, 0.0649, 0.1346, 0.0543], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,546][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0828, 0.6771, 0.0076, 0.0314, 0.0122, 0.0495, 0.0172, 0.0080, 0.0035,
        0.0169, 0.0207, 0.0104, 0.0120, 0.0507], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,550][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.4252, 0.1815, 0.0166, 0.0187, 0.0388, 0.0329, 0.0206, 0.0224, 0.0121,
        0.0469, 0.0671, 0.0325, 0.0341, 0.0508], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,555][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.4490, 0.2482, 0.0303, 0.0387, 0.0382, 0.0184, 0.0184, 0.0089, 0.0083,
        0.0327, 0.0420, 0.0200, 0.0251, 0.0218], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,560][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.1329, 0.1903, 0.0370, 0.0508, 0.0449, 0.0663, 0.0527, 0.0282, 0.0254,
        0.0562, 0.0574, 0.0386, 0.0619, 0.1574], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,562][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0568, 0.2765, 0.0229, 0.0446, 0.0365, 0.0571, 0.1210, 0.0667, 0.0414,
        0.0609, 0.0279, 0.0498, 0.0470, 0.0907], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,563][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([3.2633e-01, 2.8165e-02, 4.3688e-04, 5.0467e-03, 1.2411e-03, 1.0191e-04,
        2.9122e-01, 6.6670e-03, 1.1732e-03, 7.1896e-02, 4.9818e-02, 1.3167e-02,
        6.7104e-03, 8.8745e-02, 1.0928e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,564][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0073, 0.1274, 0.1384, 0.0810, 0.0646, 0.0660, 0.0755, 0.1555, 0.0520,
        0.0242, 0.0155, 0.0652, 0.0640, 0.0216, 0.0418], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,565][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.6806, 0.0265, 0.0088, 0.0073, 0.0197, 0.0163, 0.0086, 0.0080, 0.0111,
        0.0356, 0.0337, 0.0322, 0.0418, 0.0441, 0.0257], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,568][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0603, 0.0804, 0.1017, 0.0421, 0.0656, 0.0643, 0.0593, 0.0630, 0.0787,
        0.0626, 0.0476, 0.0397, 0.0495, 0.1098, 0.0757], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,574][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1616, 0.1337, 0.0341, 0.0451, 0.0571, 0.0943, 0.0555, 0.0296, 0.0374,
        0.0446, 0.0521, 0.0335, 0.0768, 0.0970, 0.0476], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,580][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.4482, 0.1492, 0.0160, 0.0140, 0.0403, 0.0141, 0.0207, 0.0096, 0.0151,
        0.0319, 0.0378, 0.0292, 0.0689, 0.0803, 0.0248], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,581][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.4633, 0.0391, 0.0433, 0.0141, 0.0431, 0.0166, 0.0203, 0.0164, 0.0168,
        0.0340, 0.0489, 0.0353, 0.0681, 0.0662, 0.0746], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,582][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.3893, 0.1221, 0.0138, 0.0123, 0.0224, 0.0244, 0.0248, 0.0159, 0.0187,
        0.0325, 0.0295, 0.0472, 0.0511, 0.0769, 0.1191], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,585][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.7287, 0.0445, 0.0150, 0.0045, 0.0480, 0.0073, 0.0046, 0.0090, 0.0067,
        0.0160, 0.0285, 0.0164, 0.0368, 0.0214, 0.0128], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,591][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.6484, 0.1133, 0.0318, 0.0215, 0.0321, 0.0083, 0.0082, 0.0062, 0.0063,
        0.0211, 0.0305, 0.0187, 0.0235, 0.0135, 0.0167], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,597][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.3458, 0.1340, 0.0275, 0.0381, 0.0338, 0.0326, 0.0297, 0.0141, 0.0179,
        0.0529, 0.0608, 0.0377, 0.0493, 0.0802, 0.0457], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,598][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1038, 0.1634, 0.0168, 0.0557, 0.0195, 0.0642, 0.0848, 0.0411, 0.0255,
        0.0806, 0.0399, 0.0445, 0.0258, 0.1162, 0.1181], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,602][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:25:42,605][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[7601],
        [4430],
        [7403],
        [3030],
        [5826],
        [2817],
        [3293],
        [4736],
        [6719],
        [2004],
        [4812],
        [5663],
        [5437],
        [3013],
        [2657]], device='cuda:0')
[2024-07-24 10:25:42,607][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 9107],
        [12253],
        [29495],
        [ 9509],
        [16589],
        [ 5048],
        [ 3132],
        [ 3860],
        [ 6022],
        [ 3975],
        [ 3953],
        [ 4985],
        [ 8627],
        [ 3748],
        [ 3458]], device='cuda:0')
[2024-07-24 10:25:42,610][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[32897],
        [45219],
        [42773],
        [43889],
        [43069],
        [42718],
        [41031],
        [41292],
        [40820],
        [40830],
        [40953],
        [40985],
        [40378],
        [39799],
        [39208]], device='cuda:0')
[2024-07-24 10:25:42,612][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 7528],
        [  115],
        [ 1688],
        [19652],
        [ 3667],
        [30305],
        [ 5321],
        [ 4999],
        [ 2753],
        [ 6034],
        [ 4229],
        [ 2821],
        [ 2051],
        [ 3226],
        [ 3515]], device='cuda:0')
[2024-07-24 10:25:42,615][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 3606],
        [ 3894],
        [ 5210],
        [ 5630],
        [ 8582],
        [ 7560],
        [ 6990],
        [10753],
        [10987],
        [16685],
        [22627],
        [15057],
        [19873],
        [19269],
        [20793]], device='cuda:0')
[2024-07-24 10:25:42,617][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 7867],
        [19050],
        [ 9834],
        [17330],
        [15950],
        [17478],
        [20637],
        [24688],
        [26856],
        [30230],
        [30146],
        [29975],
        [29956],
        [29411],
        [27413]], device='cuda:0')
[2024-07-24 10:25:42,619][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[35256],
        [ 9076],
        [ 9096],
        [ 8970],
        [ 8948],
        [ 6309],
        [ 7441],
        [ 7807],
        [ 8273],
        [ 7328],
        [ 7111],
        [ 7527],
        [ 7044],
        [ 7670],
        [ 7532]], device='cuda:0')
[2024-07-24 10:25:42,621][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 8892],
        [ 9114],
        [ 9122],
        [ 9309],
        [ 9180],
        [ 8930],
        [ 9006],
        [ 9028],
        [ 9044],
        [11366],
        [14975],
        [ 9861],
        [10342],
        [12864],
        [11402]], device='cuda:0')
[2024-07-24 10:25:42,622][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[17420],
        [19040],
        [21157],
        [25262],
        [32883],
        [20270],
        [18172],
        [19541],
        [18975],
        [42317],
        [42382],
        [35900],
        [38711],
        [44191],
        [39411]], device='cuda:0')
[2024-07-24 10:25:42,625][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 4498],
        [ 6778],
        [ 9466],
        [11326],
        [11914],
        [15213],
        [ 7722],
        [26508],
        [ 5483],
        [27045],
        [28976],
        [18237],
        [14217],
        [23115],
        [ 8318]], device='cuda:0')
[2024-07-24 10:25:42,628][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[2422],
        [5602],
        [ 445],
        [ 524],
        [ 568],
        [ 654],
        [ 740],
        [ 904],
        [ 992],
        [1191],
        [1263],
        [1334],
        [1253],
        [1353],
        [1475]], device='cuda:0')
[2024-07-24 10:25:42,630][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[29877],
        [29253],
        [ 7989],
        [ 7557],
        [ 7027],
        [14571],
        [15375],
        [23211],
        [37653],
        [32238],
        [33951],
        [22896],
        [18153],
        [27919],
        [15679]], device='cuda:0')
[2024-07-24 10:25:42,633][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[41253],
        [23492],
        [32328],
        [11782],
        [10000],
        [16029],
        [11967],
        [10316],
        [ 9029],
        [ 3770],
        [ 3755],
        [ 4773],
        [ 4483],
        [ 3354],
        [ 4417]], device='cuda:0')
[2024-07-24 10:25:42,635][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 5943],
        [15297],
        [   71],
        [    8],
        [  384],
        [ 1544],
        [ 2466],
        [ 4302],
        [11061],
        [ 9822],
        [10404],
        [11567],
        [11983],
        [12682],
        [14601]], device='cuda:0')
[2024-07-24 10:25:42,638][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 9492],
        [ 4889],
        [ 6881],
        [15637],
        [13827],
        [30362],
        [33019],
        [38393],
        [33609],
        [ 6625],
        [18490],
        [33971],
        [18619],
        [20034],
        [15786]], device='cuda:0')
[2024-07-24 10:25:42,640][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 5776],
        [ 3806],
        [ 4055],
        [ 1926],
        [ 2242],
        [ 2526],
        [11196],
        [13164],
        [12965],
        [14451],
        [15007],
        [13147],
        [14404],
        [17824],
        [15147]], device='cuda:0')
[2024-07-24 10:25:42,642][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[10032],
        [26956],
        [24111],
        [22147],
        [25006],
        [19293],
        [23695],
        [22231],
        [21792],
        [20422],
        [19824],
        [21227],
        [20261],
        [20064],
        [19627]], device='cuda:0')
[2024-07-24 10:25:42,643][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[20067],
        [25978],
        [24521],
        [27542],
        [32003],
        [29618],
        [29221],
        [33041],
        [28550],
        [33242],
        [31914],
        [34655],
        [33674],
        [34974],
        [35369]], device='cuda:0')
[2024-07-24 10:25:42,645][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[41616],
        [44602],
        [45290],
        [23603],
        [25852],
        [21356],
        [20655],
        [32693],
        [26194],
        [18353],
        [19306],
        [22223],
        [21657],
        [17458],
        [19505]], device='cuda:0')
[2024-07-24 10:25:42,647][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[12309],
        [15354],
        [20339],
        [15881],
        [18624],
        [20665],
        [18002],
        [19169],
        [19613],
        [24215],
        [26417],
        [24866],
        [27146],
        [22960],
        [32960]], device='cuda:0')
[2024-07-24 10:25:42,650][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[21994],
        [19279],
        [19864],
        [13145],
        [14540],
        [18384],
        [13331],
        [13017],
        [14591],
        [12151],
        [11664],
        [11227],
        [12198],
        [12028],
        [15841]], device='cuda:0')
[2024-07-24 10:25:42,652][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[20610],
        [ 7654],
        [ 8365],
        [ 4199],
        [ 3188],
        [ 8580],
        [16917],
        [11882],
        [11136],
        [ 3572],
        [ 3918],
        [ 4010],
        [ 3624],
        [ 2642],
        [ 2313]], device='cuda:0')
[2024-07-24 10:25:42,655][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[18038],
        [12911],
        [14076],
        [ 3943],
        [ 6069],
        [12456],
        [ 2732],
        [ 1891],
        [ 2812],
        [  927],
        [  928],
        [ 1087],
        [  905],
        [ 1102],
        [ 1491]], device='cuda:0')
[2024-07-24 10:25:42,657][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[11401],
        [10802],
        [11318],
        [12427],
        [12210],
        [11273],
        [11325],
        [11608],
        [10886],
        [17473],
        [18656],
        [14395],
        [15037],
        [18817],
        [11404]], device='cuda:0')
[2024-07-24 10:25:42,660][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[30989],
        [24470],
        [27612],
        [15727],
        [11110],
        [21365],
        [18633],
        [13407],
        [19393],
        [12796],
        [13914],
        [12790],
        [13754],
        [11570],
        [11895]], device='cuda:0')
[2024-07-24 10:25:42,662][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 4036],
        [14074],
        [ 9953],
        [22280],
        [24461],
        [18342],
        [21288],
        [21276],
        [23412],
        [31194],
        [30196],
        [27437],
        [28193],
        [31999],
        [30026]], device='cuda:0')
[2024-07-24 10:25:42,663][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[13501],
        [32946],
        [19733],
        [20742],
        [24184],
        [23573],
        [26689],
        [25879],
        [25773],
        [20552],
        [19441],
        [20927],
        [19085],
        [20492],
        [20597]], device='cuda:0')
[2024-07-24 10:25:42,665][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[25515],
        [25436],
        [23492],
        [38158],
        [35658],
        [29192],
        [30989],
        [31507],
        [30537],
        [31611],
        [29985],
        [33298],
        [31841],
        [32970],
        [32172]], device='cuda:0')
[2024-07-24 10:25:42,668][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[31287],
        [13105],
        [ 9282],
        [25345],
        [21089],
        [12061],
        [13723],
        [18957],
        [16877],
        [34578],
        [36912],
        [25998],
        [31958],
        [27628],
        [30267]], device='cuda:0')
[2024-07-24 10:25:42,670][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[14768],
        [14768],
        [14768],
        [14768],
        [14768],
        [14768],
        [14768],
        [14768],
        [14768],
        [14768],
        [14768],
        [14768],
        [14768],
        [14768],
        [14768]], device='cuda:0')
[2024-07-24 10:25:42,763][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:42,764][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:42,765][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:42,765][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:42,766][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:42,767][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:42,767][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:42,768][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:42,769][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:42,769][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:42,770][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:42,771][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:42,771][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:42,772][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9470, 0.0530], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:42,773][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1548, 0.8452], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:42,773][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2461, 0.7539], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:42,774][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9500, 0.0500], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:42,776][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0231, 0.9769], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:42,777][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4910, 0.5090], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:42,779][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0614, 0.9386], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:42,779][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.8345, 0.1655], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:42,780][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4494, 0.5506], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:42,781][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0750, 0.9250], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:42,781][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0222, 0.9778], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:42,782][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0543, 0.9457], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:42,784][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Jose] are: tensor([0.9284, 0.0151, 0.0565], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:42,785][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Jose] are: tensor([0.1061, 0.2479, 0.6460], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:42,787][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Jose] are: tensor([0.1618, 0.3618, 0.4764], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:42,788][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Jose] are: tensor([9.9001e-01, 9.6693e-03, 3.2110e-04], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:42,789][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Jose] are: tensor([0.0149, 0.4622, 0.5229], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:42,790][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Jose] are: tensor([0.2970, 0.3307, 0.3723], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:42,792][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Jose] are: tensor([0.0486, 0.7208, 0.2307], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:42,794][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Jose] are: tensor([0.8194, 0.1359, 0.0447], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:42,795][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Jose] are: tensor([0.1676, 0.1875, 0.6449], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:42,796][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Jose] are: tensor([0.0151, 0.2933, 0.6916], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:42,798][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Jose] are: tensor([0.0178, 0.5111, 0.4711], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:42,799][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Jose] are: tensor([0.0196, 0.4766, 0.5037], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:42,801][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.7348, 0.0614, 0.1865, 0.0173], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:42,802][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0447, 0.2543, 0.5551, 0.1458], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:42,804][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0769, 0.2621, 0.3508, 0.3103], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:42,805][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.7193, 0.2676, 0.0018, 0.0113], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:42,807][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0065, 0.2840, 0.3272, 0.3823], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:42,809][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2210, 0.2660, 0.2943, 0.2187], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:42,810][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0219, 0.3755, 0.3527, 0.2499], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:42,811][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.5848, 0.3443, 0.0386, 0.0323], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:42,813][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1038, 0.1437, 0.5713, 0.1812], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:42,815][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0139, 0.2316, 0.5996, 0.1549], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:42,816][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0078, 0.3391, 0.3056, 0.3475], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:42,817][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0180, 0.2901, 0.3532, 0.3388], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:42,819][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Stephanie] are: tensor([0.7833, 0.0147, 0.0733, 0.0076, 0.1210], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:42,821][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Stephanie] are: tensor([0.0132, 0.1917, 0.4601, 0.1093, 0.2257], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:42,821][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Stephanie] are: tensor([0.0708, 0.1895, 0.2741, 0.2280, 0.2376], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:42,822][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Stephanie] are: tensor([9.5328e-01, 3.7336e-02, 5.1071e-04, 5.5533e-03, 3.3232e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:42,823][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Stephanie] are: tensor([0.0054, 0.2086, 0.2494, 0.2716, 0.2649], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:42,823][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Stephanie] are: tensor([0.1925, 0.2703, 0.1781, 0.1773, 0.1817], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:42,825][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Stephanie] are: tensor([0.0664, 0.2462, 0.1627, 0.3948, 0.1298], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:42,826][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Stephanie] are: tensor([0.2882, 0.4003, 0.1029, 0.0709, 0.1377], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:42,828][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Stephanie] are: tensor([0.0855, 0.1268, 0.3126, 0.1726, 0.3025], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:42,829][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Stephanie] are: tensor([0.0114, 0.1860, 0.4599, 0.1316, 0.2112], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:42,831][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Stephanie] are: tensor([0.0056, 0.2564, 0.2387, 0.2779, 0.2214], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:42,832][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Stephanie] are: tensor([0.0065, 0.1969, 0.2329, 0.2697, 0.2942], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:42,834][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.8508, 0.0208, 0.0334, 0.0066, 0.0775, 0.0108], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:42,835][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0393, 0.1646, 0.4039, 0.0944, 0.2034, 0.0944], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:42,837][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0573, 0.1517, 0.1880, 0.1768, 0.1828, 0.2434], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:42,838][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ had] are: tensor([9.5590e-01, 3.9884e-02, 1.3851e-04, 2.2026e-03, 1.3910e-03, 4.7993e-04],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:42,839][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0057, 0.1573, 0.1791, 0.2049, 0.1971, 0.2559], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:42,841][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.1507, 0.1889, 0.1388, 0.1485, 0.1333, 0.2398], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:42,842][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0318, 0.1476, 0.1461, 0.1203, 0.0873, 0.4669], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:42,844][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.5043, 0.3329, 0.0361, 0.0351, 0.0499, 0.0417], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:42,846][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1133, 0.0720, 0.2340, 0.1032, 0.2429, 0.2344], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:42,847][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0094, 0.1634, 0.3704, 0.1179, 0.1690, 0.1699], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:42,849][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0056, 0.2008, 0.1797, 0.2102, 0.1675, 0.2362], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:42,850][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0121, 0.1702, 0.1700, 0.1940, 0.2029, 0.2508], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:42,852][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.8637, 0.0206, 0.0332, 0.0039, 0.0689, 0.0067, 0.0030],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:42,853][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0616, 0.2080, 0.2541, 0.0760, 0.1927, 0.0939, 0.1137],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:42,855][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0574, 0.1311, 0.1562, 0.1570, 0.1453, 0.2077, 0.1453],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:42,856][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([6.1687e-01, 3.7389e-01, 3.0163e-05, 7.5004e-03, 4.0849e-04, 1.1552e-03,
        1.3898e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:42,857][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0055, 0.1261, 0.1452, 0.1638, 0.1573, 0.1884, 0.2137],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:42,859][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1232, 0.1840, 0.1266, 0.1451, 0.1085, 0.1916, 0.1211],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:42,860][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0212, 0.1562, 0.0501, 0.0816, 0.0346, 0.2764, 0.3798],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:42,862][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.2442, 0.6043, 0.0132, 0.0457, 0.0333, 0.0383, 0.0209],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:42,863][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0535, 0.0632, 0.1880, 0.0898, 0.1895, 0.1884, 0.2275],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:42,863][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0075, 0.1405, 0.2961, 0.1048, 0.1460, 0.1394, 0.1657],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:42,864][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0046, 0.1697, 0.1348, 0.1735, 0.1266, 0.1897, 0.2012],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:42,865][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0096, 0.1515, 0.1530, 0.1624, 0.1698, 0.1811, 0.1726],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:42,866][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.7511, 0.0513, 0.0387, 0.0143, 0.1145, 0.0139, 0.0124, 0.0038],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:42,868][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0571, 0.1981, 0.2590, 0.0682, 0.2214, 0.0674, 0.0913, 0.0375],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:42,869][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0310, 0.1155, 0.1403, 0.1379, 0.1327, 0.1884, 0.1233, 0.1311],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:42,871][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ long] are: tensor([3.9563e-01, 5.7606e-01, 9.0542e-05, 1.5624e-02, 9.4949e-04, 5.0563e-03,
        5.4915e-03, 1.0966e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:42,872][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0026, 0.0957, 0.1149, 0.1397, 0.1224, 0.1646, 0.1944, 0.1656],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:42,873][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0644, 0.1788, 0.1070, 0.1409, 0.1011, 0.1933, 0.1148, 0.0997],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:42,875][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0084, 0.1348, 0.0600, 0.0723, 0.0277, 0.2289, 0.3100, 0.1579],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:42,877][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.1167, 0.6328, 0.0098, 0.0419, 0.0380, 0.0379, 0.0635, 0.0593],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:42,878][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0245, 0.0595, 0.1496, 0.0780, 0.1413, 0.1507, 0.1712, 0.2251],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:42,880][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0020, 0.1218, 0.2621, 0.0916, 0.1343, 0.1175, 0.1511, 0.1196],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:42,881][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0030, 0.1427, 0.1126, 0.1500, 0.1089, 0.1662, 0.1861, 0.1305],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:42,883][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0043, 0.1037, 0.1079, 0.1248, 0.1238, 0.1407, 0.1543, 0.2404],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:42,884][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.9250, 0.0196, 0.0101, 0.0049, 0.0271, 0.0073, 0.0022, 0.0012, 0.0024],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:42,886][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0433, 0.1613, 0.2952, 0.0674, 0.1618, 0.0664, 0.0897, 0.0413, 0.0735],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:42,888][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0099, 0.0879, 0.1182, 0.1115, 0.1204, 0.1527, 0.1027, 0.1067, 0.1900],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:42,889][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([6.3453e-01, 3.5087e-01, 1.4843e-05, 1.0126e-02, 2.5997e-04, 1.6736e-03,
        1.6930e-03, 4.6100e-04, 3.7430e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:42,890][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0032, 0.0874, 0.1014, 0.1202, 0.1048, 0.1427, 0.1674, 0.1342, 0.1388],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:42,892][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.1299, 0.1612, 0.0856, 0.1273, 0.0887, 0.1659, 0.0923, 0.0716, 0.0776],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:42,894][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0082, 0.0969, 0.0304, 0.0823, 0.0159, 0.1886, 0.2953, 0.1834, 0.0991],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:42,895][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.1643, 0.5233, 0.0101, 0.0604, 0.0298, 0.0683, 0.0638, 0.0521, 0.0280],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:42,897][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0249, 0.0466, 0.1094, 0.0687, 0.1155, 0.1381, 0.1620, 0.2188, 0.1160],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:42,898][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0020, 0.0949, 0.2404, 0.0641, 0.1107, 0.0908, 0.1050, 0.1279, 0.1641],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:42,900][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0028, 0.1275, 0.0984, 0.1334, 0.0951, 0.1443, 0.1659, 0.1160, 0.1167],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:42,901][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0049, 0.0878, 0.0887, 0.1010, 0.0990, 0.1180, 0.1279, 0.2001, 0.1726],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:42,903][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3464, 0.0534, 0.1333, 0.0151, 0.3263, 0.0341, 0.0248, 0.0184, 0.0247,
        0.0235], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:42,904][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0058, 0.0767, 0.2587, 0.0624, 0.1459, 0.1020, 0.1496, 0.0687, 0.1098,
        0.0205], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:42,905][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0090, 0.0821, 0.1119, 0.1049, 0.1041, 0.1463, 0.1074, 0.0977, 0.1582,
        0.0786], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:42,906][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6503, 0.2697, 0.0010, 0.0238, 0.0068, 0.0092, 0.0060, 0.0036, 0.0027,
        0.0269], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:42,907][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0012, 0.0769, 0.0953, 0.1048, 0.1050, 0.1346, 0.1660, 0.1243, 0.1239,
        0.0680], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:42,908][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0395, 0.1196, 0.0995, 0.1042, 0.1042, 0.2024, 0.0955, 0.0713, 0.0830,
        0.0809], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:42,909][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0015, 0.0642, 0.0301, 0.0427, 0.0121, 0.2288, 0.3948, 0.1499, 0.0554,
        0.0205], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:42,911][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1757, 0.3734, 0.0212, 0.0497, 0.0782, 0.0633, 0.0612, 0.1005, 0.0345,
        0.0422], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:42,912][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0181, 0.0327, 0.1313, 0.0552, 0.1293, 0.1289, 0.1520, 0.1966, 0.1124,
        0.0436], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:42,914][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0038, 0.0860, 0.2193, 0.0604, 0.0961, 0.0976, 0.1252, 0.1164, 0.1529,
        0.0422], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:42,915][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0013, 0.1088, 0.0982, 0.1162, 0.0913, 0.1314, 0.1470, 0.1088, 0.1101,
        0.0869], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:42,917][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0035, 0.0628, 0.0853, 0.0823, 0.0950, 0.1141, 0.1368, 0.1921, 0.1619,
        0.0662], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:42,919][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2696, 0.0618, 0.1382, 0.0224, 0.3069, 0.0355, 0.0300, 0.0284, 0.0376,
        0.0315, 0.0381], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:42,920][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0036, 0.0655, 0.1952, 0.0586, 0.1228, 0.0918, 0.2054, 0.0971, 0.1252,
        0.0209, 0.0139], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:42,922][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0079, 0.0724, 0.0952, 0.0962, 0.0893, 0.1402, 0.0964, 0.0927, 0.1669,
        0.0756, 0.0671], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:42,924][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.5379, 0.2796, 0.0053, 0.0246, 0.0188, 0.0186, 0.0100, 0.0083, 0.0075,
        0.0321, 0.0574], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:42,925][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0012, 0.0741, 0.0875, 0.0956, 0.1028, 0.1248, 0.1567, 0.1220, 0.1187,
        0.0626, 0.0541], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:42,927][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0316, 0.0954, 0.0923, 0.0994, 0.1022, 0.1958, 0.0909, 0.0723, 0.0866,
        0.0634, 0.0700], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:42,928][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0008, 0.0570, 0.0237, 0.0279, 0.0084, 0.2401, 0.3920, 0.1757, 0.0543,
        0.0163, 0.0037], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:42,930][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1443, 0.2988, 0.0231, 0.0523, 0.0887, 0.0655, 0.0646, 0.1121, 0.0491,
        0.0474, 0.0541], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:42,931][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0225, 0.0284, 0.1258, 0.0457, 0.1356, 0.1144, 0.1488, 0.1955, 0.1098,
        0.0400, 0.0335], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:42,933][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0024, 0.0893, 0.2278, 0.0591, 0.0949, 0.1034, 0.1045, 0.1067, 0.1488,
        0.0387, 0.0244], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:42,935][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0012, 0.0987, 0.0927, 0.1037, 0.0851, 0.1213, 0.1353, 0.1024, 0.1049,
        0.0796, 0.0750], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:42,936][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0033, 0.0628, 0.0789, 0.0795, 0.0925, 0.1030, 0.1255, 0.1739, 0.1461,
        0.0646, 0.0700], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:42,938][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.5977, 0.0399, 0.0444, 0.0124, 0.1248, 0.0238, 0.0203, 0.0119, 0.0162,
        0.0309, 0.0351, 0.0426], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:42,940][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0182, 0.0637, 0.1799, 0.0430, 0.1902, 0.0745, 0.1256, 0.0644, 0.1133,
        0.0272, 0.0262, 0.0738], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:42,941][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0091, 0.0753, 0.0939, 0.0992, 0.0791, 0.1329, 0.0841, 0.0778, 0.1448,
        0.0695, 0.0670, 0.0674], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:42,943][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([3.3335e-01, 5.2092e-01, 1.3936e-04, 2.4053e-02, 1.6472e-03, 1.0452e-02,
        1.0442e-02, 4.4857e-03, 5.6291e-03, 3.4274e-02, 4.6085e-02, 8.5199e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:42,944][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0013, 0.0683, 0.0786, 0.0908, 0.0889, 0.1204, 0.1445, 0.1143, 0.1046,
        0.0632, 0.0564, 0.0686], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:42,946][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0523, 0.1265, 0.0596, 0.0890, 0.0544, 0.1132, 0.0852, 0.0700, 0.0817,
        0.0747, 0.0983, 0.0951], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:42,947][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0018, 0.0582, 0.0230, 0.0489, 0.0089, 0.1419, 0.3667, 0.1988, 0.0731,
        0.0472, 0.0161, 0.0153], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:42,948][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0631, 0.4020, 0.0113, 0.0584, 0.0289, 0.0514, 0.0834, 0.0923, 0.0429,
        0.0589, 0.0508, 0.0565], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:42,948][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0209, 0.0280, 0.0754, 0.0517, 0.0840, 0.1382, 0.1546, 0.2190, 0.0993,
        0.0505, 0.0386, 0.0398], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:42,949][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0024, 0.0896, 0.1766, 0.0683, 0.0835, 0.0795, 0.1112, 0.0970, 0.1475,
        0.0543, 0.0358, 0.0543], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:42,951][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0014, 0.0948, 0.0780, 0.1014, 0.0734, 0.1133, 0.1311, 0.0933, 0.0960,
        0.0780, 0.0748, 0.0645], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:42,952][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0025, 0.0681, 0.0715, 0.0810, 0.0888, 0.0913, 0.0940, 0.1548, 0.1278,
        0.0904, 0.0677, 0.0622], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:42,954][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Stephanie] are: tensor([0.5405, 0.0330, 0.0798, 0.0104, 0.1519, 0.0229, 0.0116, 0.0062, 0.0194,
        0.0145, 0.0215, 0.0234, 0.0648], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,956][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Stephanie] are: tensor([0.0066, 0.0835, 0.1558, 0.0531, 0.1032, 0.0971, 0.1349, 0.0420, 0.1128,
        0.0323, 0.0227, 0.0807, 0.0752], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,957][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Stephanie] are: tensor([0.0137, 0.0624, 0.0939, 0.0793, 0.0809, 0.1263, 0.0789, 0.0816, 0.1418,
        0.0591, 0.0617, 0.0593, 0.0611], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,958][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Stephanie] are: tensor([6.1828e-01, 1.5467e-01, 5.1612e-04, 1.2967e-02, 3.6037e-03, 1.3101e-02,
        2.6611e-02, 1.7313e-02, 2.0981e-02, 4.8463e-02, 4.5818e-02, 2.5261e-02,
        1.2406e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,960][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Stephanie] are: tensor([0.0011, 0.0619, 0.0772, 0.0848, 0.0866, 0.1088, 0.1350, 0.1050, 0.1031,
        0.0590, 0.0504, 0.0613, 0.0657], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,962][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Stephanie] are: tensor([0.0804, 0.1156, 0.0612, 0.0686, 0.0581, 0.1267, 0.0615, 0.0684, 0.0832,
        0.0765, 0.0587, 0.0724, 0.0685], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,964][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Stephanie] are: tensor([0.0024, 0.0170, 0.0162, 0.0270, 0.0100, 0.1513, 0.3705, 0.1916, 0.0748,
        0.0439, 0.0219, 0.0268, 0.0466], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,966][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Stephanie] are: tensor([0.0622, 0.2117, 0.0228, 0.0386, 0.0441, 0.0845, 0.0716, 0.1317, 0.0587,
        0.0473, 0.0404, 0.1252, 0.0613], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,967][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Stephanie] are: tensor([0.0295, 0.0327, 0.0886, 0.0460, 0.0972, 0.1223, 0.1401, 0.2083, 0.0965,
        0.0414, 0.0329, 0.0373, 0.0271], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,969][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Stephanie] are: tensor([0.0040, 0.0760, 0.1871, 0.0559, 0.0769, 0.0931, 0.0815, 0.1002, 0.1733,
        0.0389, 0.0285, 0.0498, 0.0348], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,971][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Stephanie] are: tensor([0.0010, 0.0843, 0.0742, 0.0894, 0.0681, 0.1065, 0.1272, 0.0905, 0.0948,
        0.0721, 0.0656, 0.0625, 0.0638], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,972][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Stephanie] are: tensor([0.0014, 0.0525, 0.0595, 0.0712, 0.0768, 0.0888, 0.0903, 0.1536, 0.1289,
        0.0729, 0.0618, 0.0548, 0.0875], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:42,974][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.2786, 0.0397, 0.1031, 0.0171, 0.2654, 0.0308, 0.0208, 0.0107, 0.0177,
        0.0248, 0.0356, 0.0191, 0.0976, 0.0388], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,976][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0032, 0.0453, 0.1931, 0.0397, 0.1103, 0.0559, 0.1409, 0.0806, 0.1391,
        0.0162, 0.0106, 0.0751, 0.0640, 0.0261], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,978][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0090, 0.0605, 0.0738, 0.0799, 0.0741, 0.1177, 0.0675, 0.0710, 0.1275,
        0.0593, 0.0593, 0.0568, 0.0514, 0.0922], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,979][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ said] are: tensor([1.3962e-01, 7.5330e-01, 4.4835e-04, 3.8391e-02, 2.3954e-03, 8.8800e-03,
        2.2649e-03, 7.5850e-04, 4.5536e-04, 1.1997e-02, 2.6084e-02, 1.5829e-03,
        1.8344e-03, 1.1980e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,981][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0006, 0.0558, 0.0700, 0.0796, 0.0792, 0.1095, 0.1238, 0.0948, 0.0943,
        0.0527, 0.0527, 0.0565, 0.0643, 0.0662], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,983][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0256, 0.1058, 0.0643, 0.0797, 0.0572, 0.1294, 0.0644, 0.0483, 0.0636,
        0.0569, 0.0653, 0.0420, 0.0539, 0.1438], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,984][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0005, 0.0237, 0.0185, 0.0219, 0.0160, 0.1487, 0.3377, 0.2065, 0.0682,
        0.0192, 0.0053, 0.0126, 0.0375, 0.0837], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,986][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0562, 0.5471, 0.0109, 0.0589, 0.0292, 0.0472, 0.0292, 0.0342, 0.0136,
        0.0277, 0.0372, 0.0250, 0.0256, 0.0579], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,988][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0216, 0.0276, 0.0899, 0.0443, 0.1046, 0.1294, 0.1431, 0.2064, 0.0998,
        0.0354, 0.0289, 0.0357, 0.0268, 0.0065], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,989][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0025, 0.0707, 0.1590, 0.0601, 0.0823, 0.0723, 0.0974, 0.0864, 0.1335,
        0.0414, 0.0324, 0.0519, 0.0418, 0.0683], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,989][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0010, 0.0889, 0.0728, 0.0904, 0.0660, 0.1017, 0.1100, 0.0775, 0.0792,
        0.0649, 0.0612, 0.0536, 0.0568, 0.0759], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,990][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0010, 0.0546, 0.0560, 0.0670, 0.0648, 0.0852, 0.0871, 0.1504, 0.1022,
        0.0612, 0.0542, 0.0525, 0.0686, 0.0954], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:42,991][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.5274, 0.0408, 0.0765, 0.0104, 0.1609, 0.0143, 0.0065, 0.0040, 0.0074,
        0.0143, 0.0232, 0.0175, 0.0516, 0.0291, 0.0159], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,993][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0100, 0.0805, 0.1749, 0.0637, 0.1075, 0.0739, 0.0901, 0.0504, 0.0901,
        0.0272, 0.0223, 0.0732, 0.0569, 0.0375, 0.0418], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,995][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0105, 0.0560, 0.0733, 0.0772, 0.0729, 0.0904, 0.0684, 0.0643, 0.1114,
        0.0557, 0.0598, 0.0574, 0.0536, 0.0751, 0.0740], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,996][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.6558, 0.1539, 0.0018, 0.0156, 0.0072, 0.0072, 0.0049, 0.0033, 0.0046,
        0.0264, 0.0394, 0.0110, 0.0122, 0.0417, 0.0151], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,998][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0028, 0.0611, 0.0733, 0.0799, 0.0741, 0.0962, 0.1046, 0.0846, 0.0805,
        0.0515, 0.0502, 0.0548, 0.0550, 0.0608, 0.0707], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:42,999][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1168, 0.0932, 0.0689, 0.0754, 0.0747, 0.1164, 0.0470, 0.0490, 0.0410,
        0.0501, 0.0521, 0.0376, 0.0510, 0.1003, 0.0265], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,001][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0038, 0.0558, 0.0535, 0.0277, 0.0245, 0.1565, 0.2168, 0.1604, 0.0493,
        0.0138, 0.0057, 0.0130, 0.0375, 0.0583, 0.1234], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,003][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1959, 0.2883, 0.0206, 0.0435, 0.0529, 0.0359, 0.0268, 0.0460, 0.0157,
        0.0302, 0.0401, 0.0462, 0.0512, 0.0887, 0.0181], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,005][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0214, 0.0258, 0.1195, 0.0417, 0.1319, 0.0993, 0.1205, 0.1703, 0.0921,
        0.0361, 0.0337, 0.0448, 0.0389, 0.0070, 0.0172], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,007][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0018, 0.0730, 0.1899, 0.0543, 0.0675, 0.0808, 0.0961, 0.0844, 0.1072,
        0.0368, 0.0247, 0.0428, 0.0316, 0.0648, 0.0443], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,008][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0015, 0.0728, 0.0675, 0.0784, 0.0617, 0.0895, 0.0982, 0.0739, 0.0765,
        0.0602, 0.0573, 0.0520, 0.0559, 0.0716, 0.0829], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,010][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0032, 0.0545, 0.0572, 0.0611, 0.0704, 0.0669, 0.0782, 0.1172, 0.0866,
        0.0610, 0.0524, 0.0503, 0.0812, 0.0818, 0.0778], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,118][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:43,119][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,121][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,122][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,123][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,123][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,124][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,125][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,126][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,127][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,128][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,129][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,131][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,132][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9470, 0.0530], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,133][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1548, 0.8452], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,134][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9590, 0.0410], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,135][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9500, 0.0500], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,135][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.4267, 0.5733], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,136][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9769, 0.0231], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,137][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0514, 0.9486], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,137][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.8345, 0.1655], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,138][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9174, 0.0826], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,139][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0135, 0.9865], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,139][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.5094, 0.4906], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,141][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0481, 0.9519], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,143][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Jose] are: tensor([0.9284, 0.0151, 0.0565], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,144][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Jose] are: tensor([0.1061, 0.2479, 0.6460], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,146][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Jose] are: tensor([0.9676, 0.0151, 0.0173], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,147][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Jose] are: tensor([9.9001e-01, 9.6693e-03, 3.2110e-04], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,149][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Jose] are: tensor([0.6464, 0.1547, 0.1989], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,150][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Jose] are: tensor([0.9715, 0.0158, 0.0127], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,152][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Jose] are: tensor([0.0254, 0.4413, 0.5333], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,153][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Jose] are: tensor([0.8194, 0.1359, 0.0447], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,155][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Jose] are: tensor([0.7620, 0.0566, 0.1814], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,157][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Jose] are: tensor([0.0052, 0.4686, 0.5262], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,158][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Jose] are: tensor([0.9392, 0.0553, 0.0054], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,160][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Jose] are: tensor([0.0072, 0.8452, 0.1476], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,161][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.7348, 0.0614, 0.1865, 0.0173], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,163][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0447, 0.2543, 0.5551, 0.1458], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,165][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.6812, 0.0990, 0.1920, 0.0278], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,166][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.7193, 0.2676, 0.0018, 0.0113], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,168][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1004, 0.2562, 0.3639, 0.2794], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,169][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9464, 0.0232, 0.0186, 0.0118], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,171][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0044, 0.1442, 0.7621, 0.0893], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,173][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.5848, 0.3443, 0.0386, 0.0323], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,174][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.4662, 0.1415, 0.3535, 0.0388], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,176][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0013, 0.2021, 0.4441, 0.3525], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,177][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4144, 0.5054, 0.0119, 0.0683], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,178][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0158, 0.6512, 0.1661, 0.1669], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,178][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Stephanie] are: tensor([0.7833, 0.0147, 0.0733, 0.0076, 0.1210], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,179][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Stephanie] are: tensor([0.0132, 0.1917, 0.4601, 0.1093, 0.2257], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,180][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Stephanie] are: tensor([0.6974, 0.0636, 0.0648, 0.0223, 0.1519], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,181][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Stephanie] are: tensor([9.5328e-01, 3.7336e-02, 5.1071e-04, 5.5533e-03, 3.3232e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,182][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Stephanie] are: tensor([0.1409, 0.1895, 0.2370, 0.1667, 0.2659], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,184][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Stephanie] are: tensor([0.8869, 0.0404, 0.0127, 0.0157, 0.0442], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,186][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Stephanie] are: tensor([0.0029, 0.1329, 0.4203, 0.2362, 0.2077], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,187][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Stephanie] are: tensor([0.2882, 0.4003, 0.1029, 0.0709, 0.1377], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,189][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Stephanie] are: tensor([0.4075, 0.1944, 0.1468, 0.0609, 0.1904], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,190][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Stephanie] are: tensor([4.9717e-04, 1.2540e-01, 2.2881e-01, 5.2814e-01, 1.1716e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,192][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Stephanie] are: tensor([0.6862, 0.1933, 0.0107, 0.0772, 0.0325], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,193][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Stephanie] are: tensor([0.0025, 0.5032, 0.1209, 0.2772, 0.0963], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,195][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.8508, 0.0208, 0.0334, 0.0066, 0.0775, 0.0108], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,197][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0393, 0.1646, 0.4039, 0.0944, 0.2034, 0.0944], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,198][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.7397, 0.0567, 0.0559, 0.0207, 0.1092, 0.0178], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,199][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([9.5590e-01, 3.9884e-02, 1.3851e-04, 2.2026e-03, 1.3910e-03, 4.7993e-04],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,201][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1273, 0.1396, 0.1574, 0.1114, 0.2115, 0.2527], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,203][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.8780, 0.0301, 0.0103, 0.0143, 0.0336, 0.0337], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,204][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0032, 0.0656, 0.3859, 0.0690, 0.1632, 0.3131], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,206][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.5043, 0.3329, 0.0361, 0.0351, 0.0499, 0.0417], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,207][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.5980, 0.0814, 0.1435, 0.0242, 0.1363, 0.0166], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,209][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([4.5741e-04, 6.8338e-02, 1.0152e-01, 1.4558e-01, 7.8335e-02, 6.0576e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,210][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.6993, 0.2474, 0.0041, 0.0277, 0.0132, 0.0083], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,212][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0402, 0.2451, 0.1797, 0.1508, 0.1325, 0.2515], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,214][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.8637, 0.0206, 0.0332, 0.0039, 0.0689, 0.0067, 0.0030],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:43,215][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0616, 0.2080, 0.2541, 0.0760, 0.1927, 0.0939, 0.1137],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:43,217][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.7754, 0.0630, 0.0365, 0.0135, 0.0967, 0.0118, 0.0031],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:43,218][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([6.1687e-01, 3.7389e-01, 3.0163e-05, 7.5004e-03, 4.0849e-04, 1.1552e-03,
        1.3898e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:43,219][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1622, 0.1721, 0.1567, 0.1082, 0.2335, 0.1254, 0.0419],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:43,220][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.8811, 0.0338, 0.0101, 0.0156, 0.0268, 0.0247, 0.0078],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:43,220][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0049, 0.1190, 0.2634, 0.0531, 0.1588, 0.2514, 0.1495],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:43,221][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.2442, 0.6043, 0.0132, 0.0457, 0.0333, 0.0383, 0.0209],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:43,222][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.4986, 0.1320, 0.1501, 0.0352, 0.1402, 0.0328, 0.0109],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:43,224][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0005, 0.0788, 0.0702, 0.0685, 0.0370, 0.4285, 0.3165],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:43,225][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([2.4525e-01, 7.0411e-01, 3.2868e-04, 4.1281e-02, 1.9837e-03, 5.8289e-03,
        1.2172e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:43,227][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0367, 0.3212, 0.2055, 0.1041, 0.1347, 0.1379, 0.0600],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:43,228][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.7511, 0.0513, 0.0387, 0.0143, 0.1145, 0.0139, 0.0124, 0.0038],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:43,230][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0571, 0.1981, 0.2590, 0.0682, 0.2214, 0.0674, 0.0913, 0.0375],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:43,231][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.5645, 0.1493, 0.0648, 0.0382, 0.1329, 0.0347, 0.0128, 0.0028],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:43,233][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([3.9563e-01, 5.7606e-01, 9.0542e-05, 1.5624e-02, 9.4949e-04, 5.0563e-03,
        5.4915e-03, 1.0966e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:43,234][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0808, 0.1013, 0.1460, 0.1346, 0.1759, 0.2057, 0.0859, 0.0699],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:43,236][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.8117, 0.0547, 0.0119, 0.0251, 0.0361, 0.0382, 0.0113, 0.0111],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:43,238][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0018, 0.0987, 0.2522, 0.0658, 0.0966, 0.2056, 0.1490, 0.1303],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:43,239][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.1167, 0.6328, 0.0098, 0.0419, 0.0380, 0.0379, 0.0635, 0.0593],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:43,241][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.3034, 0.2762, 0.1608, 0.0459, 0.1481, 0.0393, 0.0149, 0.0115],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:43,242][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([8.3785e-05, 3.3304e-02, 3.7126e-02, 7.5975e-02, 1.3329e-02, 3.3954e-01,
        2.5960e-01, 2.4104e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:43,243][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([2.5152e-01, 6.5599e-01, 2.1609e-04, 6.2182e-02, 2.4429e-03, 1.3211e-02,
        1.3556e-02, 8.7693e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:43,245][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0044, 0.2245, 0.2394, 0.1135, 0.0892, 0.1615, 0.0570, 0.1104],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:43,246][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.9250, 0.0196, 0.0101, 0.0049, 0.0271, 0.0073, 0.0022, 0.0012, 0.0024],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:43,248][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0433, 0.1613, 0.2952, 0.0674, 0.1618, 0.0664, 0.0897, 0.0413, 0.0735],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:43,250][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.8258, 0.0630, 0.0177, 0.0212, 0.0469, 0.0153, 0.0049, 0.0014, 0.0038],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:43,251][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([6.3453e-01, 3.5087e-01, 1.4843e-05, 1.0126e-02, 2.5997e-04, 1.6736e-03,
        1.6930e-03, 4.6100e-04, 3.7430e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:43,252][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.1687, 0.1229, 0.1065, 0.1262, 0.1235, 0.1565, 0.0520, 0.0356, 0.1082],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:43,254][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.8738, 0.0356, 0.0063, 0.0169, 0.0234, 0.0246, 0.0069, 0.0046, 0.0080],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:43,256][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0033, 0.0939, 0.1565, 0.0857, 0.0627, 0.2042, 0.1661, 0.1483, 0.0791],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:43,258][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.1643, 0.5233, 0.0101, 0.0604, 0.0298, 0.0683, 0.0638, 0.0521, 0.0280],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:43,259][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.5364, 0.1854, 0.0786, 0.0477, 0.0906, 0.0341, 0.0121, 0.0080, 0.0071],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:43,261][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([1.6664e-04, 4.5232e-02, 2.6851e-02, 6.4980e-02, 1.1987e-02, 2.3031e-01,
        1.9873e-01, 2.5154e-01, 1.7021e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:43,261][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([1.6514e-01, 7.2305e-01, 2.0266e-04, 7.8737e-02, 1.5099e-03, 1.0264e-02,
        1.8558e-02, 1.0355e-03, 1.4975e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:43,262][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0100, 0.2288, 0.1001, 0.1665, 0.0701, 0.1650, 0.0963, 0.1211, 0.0421],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:43,263][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3464, 0.0534, 0.1333, 0.0151, 0.3263, 0.0341, 0.0248, 0.0184, 0.0247,
        0.0235], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:43,264][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0058, 0.0767, 0.2587, 0.0624, 0.1459, 0.1020, 0.1496, 0.0687, 0.1098,
        0.0205], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:43,265][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2779, 0.1783, 0.1196, 0.0558, 0.2168, 0.0574, 0.0246, 0.0095, 0.0177,
        0.0425], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:43,267][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6503, 0.2697, 0.0010, 0.0238, 0.0068, 0.0092, 0.0060, 0.0036, 0.0027,
        0.0269], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:43,269][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0076, 0.1141, 0.1667, 0.0712, 0.1813, 0.1731, 0.0968, 0.0505, 0.1209,
        0.0178], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:43,270][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4567, 0.0770, 0.0383, 0.0429, 0.0867, 0.1258, 0.0382, 0.0329, 0.0494,
        0.0520], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:43,271][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([2.1421e-04, 4.7927e-02, 2.6546e-01, 3.5770e-02, 9.8605e-02, 1.8252e-01,
        1.5148e-01, 1.3051e-01, 7.3328e-02, 1.4191e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:43,273][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1757, 0.3734, 0.0212, 0.0497, 0.0782, 0.0633, 0.0612, 0.1005, 0.0345,
        0.0422], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:43,275][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1448, 0.1605, 0.2635, 0.0545, 0.1963, 0.0755, 0.0266, 0.0242, 0.0140,
        0.0402], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:43,276][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([1.2766e-05, 2.2648e-02, 3.1903e-02, 3.2376e-02, 1.3196e-02, 2.1327e-01,
        2.8896e-01, 2.6664e-01, 1.2351e-01, 7.4922e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:43,277][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1004, 0.6199, 0.0066, 0.1159, 0.0279, 0.0464, 0.0285, 0.0108, 0.0120,
        0.0317], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:43,279][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0023, 0.2765, 0.1005, 0.1246, 0.0578, 0.1458, 0.1096, 0.1273, 0.0326,
        0.0230], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:43,281][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2696, 0.0618, 0.1382, 0.0224, 0.3069, 0.0355, 0.0300, 0.0284, 0.0376,
        0.0315, 0.0381], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:43,282][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0036, 0.0655, 0.1952, 0.0586, 0.1228, 0.0918, 0.2054, 0.0971, 0.1252,
        0.0209, 0.0139], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:43,284][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2355, 0.1415, 0.1345, 0.0583, 0.2224, 0.0512, 0.0296, 0.0150, 0.0255,
        0.0440, 0.0424], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:43,286][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.5379, 0.2796, 0.0053, 0.0246, 0.0188, 0.0186, 0.0100, 0.0083, 0.0075,
        0.0321, 0.0574], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:43,288][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0091, 0.1137, 0.1248, 0.0589, 0.1795, 0.1682, 0.1096, 0.0712, 0.1363,
        0.0191, 0.0095], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:43,289][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3734, 0.0629, 0.0431, 0.0454, 0.0829, 0.1373, 0.0467, 0.0427, 0.0641,
        0.0436, 0.0576], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:43,291][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0002, 0.0429, 0.1872, 0.0279, 0.0835, 0.1887, 0.1584, 0.1874, 0.1022,
        0.0148, 0.0067], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:43,293][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1443, 0.2988, 0.0231, 0.0523, 0.0887, 0.0655, 0.0646, 0.1121, 0.0491,
        0.0474, 0.0541], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:43,295][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1124, 0.1377, 0.2487, 0.0582, 0.2061, 0.0559, 0.0365, 0.0307, 0.0198,
        0.0486, 0.0454], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:43,296][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([3.8151e-06, 1.8109e-02, 1.5754e-02, 2.7168e-02, 6.6412e-03, 1.7574e-01,
        2.7616e-01, 3.6759e-01, 1.0551e-01, 6.0295e-03, 1.3043e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:43,298][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1556, 0.4490, 0.0190, 0.0806, 0.0547, 0.0561, 0.0348, 0.0226, 0.0249,
        0.0346, 0.0682], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:43,299][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0017, 0.2401, 0.0744, 0.1176, 0.0432, 0.1402, 0.1457, 0.1561, 0.0410,
        0.0257, 0.0144], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:43,301][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.5977, 0.0399, 0.0444, 0.0124, 0.1248, 0.0238, 0.0203, 0.0119, 0.0162,
        0.0309, 0.0351, 0.0426], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:43,303][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0182, 0.0637, 0.1799, 0.0430, 0.1902, 0.0745, 0.1256, 0.0644, 0.1133,
        0.0272, 0.0262, 0.0738], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:43,303][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.5689, 0.0852, 0.0443, 0.0321, 0.0832, 0.0417, 0.0216, 0.0062, 0.0105,
        0.0513, 0.0367, 0.0182], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:43,304][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([3.3335e-01, 5.2092e-01, 1.3936e-04, 2.4053e-02, 1.6472e-03, 1.0452e-02,
        1.0442e-02, 4.4857e-03, 5.6291e-03, 3.4274e-02, 4.6085e-02, 8.5199e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:43,305][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0260, 0.0994, 0.0848, 0.0788, 0.1314, 0.1876, 0.1040, 0.0641, 0.0901,
        0.0393, 0.0250, 0.0694], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:43,306][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.4893, 0.0754, 0.0159, 0.0297, 0.0388, 0.0573, 0.0302, 0.0236, 0.0465,
        0.0453, 0.0715, 0.0764], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:43,308][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0004, 0.0449, 0.1528, 0.0566, 0.0578, 0.1620, 0.2180, 0.1549, 0.0849,
        0.0300, 0.0156, 0.0221], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:43,309][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0631, 0.4020, 0.0113, 0.0584, 0.0289, 0.0514, 0.0834, 0.0923, 0.0429,
        0.0589, 0.0508, 0.0565], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:43,311][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.1271, 0.1971, 0.1330, 0.0835, 0.1326, 0.0892, 0.0366, 0.0260, 0.0158,
        0.0712, 0.0580, 0.0298], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:43,312][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([7.4655e-05, 1.8476e-02, 4.1907e-02, 3.8107e-02, 1.8635e-02, 2.1278e-01,
        2.5148e-01, 2.0768e-01, 1.8180e-01, 1.2698e-02, 5.6940e-03, 1.0667e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:43,314][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.1223, 0.5316, 0.0012, 0.1020, 0.0049, 0.0284, 0.0429, 0.0050, 0.0093,
        0.0454, 0.0936, 0.0135], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:43,315][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0021, 0.2137, 0.0901, 0.1367, 0.0570, 0.1839, 0.0762, 0.1315, 0.0298,
        0.0275, 0.0235, 0.0281], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:43,317][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Stephanie] are: tensor([0.5405, 0.0330, 0.0798, 0.0104, 0.1519, 0.0229, 0.0116, 0.0062, 0.0194,
        0.0145, 0.0215, 0.0234, 0.0648], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:43,319][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Stephanie] are: tensor([0.0066, 0.0835, 0.1558, 0.0531, 0.1032, 0.0971, 0.1349, 0.0420, 0.1128,
        0.0323, 0.0227, 0.0807, 0.0752], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:43,321][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Stephanie] are: tensor([0.3869, 0.1356, 0.0707, 0.0442, 0.1155, 0.0453, 0.0191, 0.0098, 0.0180,
        0.0504, 0.0353, 0.0286, 0.0406], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:43,322][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Stephanie] are: tensor([6.1828e-01, 1.5467e-01, 5.1612e-04, 1.2967e-02, 3.6037e-03, 1.3101e-02,
        2.6611e-02, 1.7313e-02, 2.0981e-02, 4.8463e-02, 4.5818e-02, 2.5261e-02,
        1.2406e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:43,324][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Stephanie] are: tensor([0.0202, 0.1019, 0.1306, 0.0899, 0.1409, 0.1419, 0.0757, 0.0463, 0.1066,
        0.0315, 0.0185, 0.0445, 0.0516], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:43,325][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Stephanie] are: tensor([0.5481, 0.0557, 0.0143, 0.0196, 0.0385, 0.0578, 0.0183, 0.0215, 0.0418,
        0.0399, 0.0439, 0.0502, 0.0504], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:43,327][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Stephanie] are: tensor([0.0003, 0.0264, 0.1145, 0.0433, 0.0485, 0.1606, 0.2161, 0.1450, 0.1236,
        0.0260, 0.0163, 0.0273, 0.0522], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:43,329][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Stephanie] are: tensor([0.0622, 0.2117, 0.0228, 0.0386, 0.0441, 0.0845, 0.0716, 0.1317, 0.0587,
        0.0473, 0.0404, 0.1252, 0.0613], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:43,331][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Stephanie] are: tensor([0.2079, 0.1704, 0.1074, 0.0450, 0.1583, 0.0530, 0.0250, 0.0193, 0.0170,
        0.0510, 0.0510, 0.0348, 0.0599], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:43,332][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Stephanie] are: tensor([5.3586e-05, 2.1777e-02, 3.0653e-02, 6.5887e-02, 1.6432e-02, 2.5932e-01,
        2.1936e-01, 1.7295e-01, 1.6298e-01, 1.4023e-02, 7.5896e-03, 1.3002e-02,
        1.5970e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:43,334][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Stephanie] are: tensor([0.1474, 0.2457, 0.0042, 0.0609, 0.0120, 0.0458, 0.1437, 0.0239, 0.0533,
        0.0784, 0.0957, 0.0629, 0.0259], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:43,335][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Stephanie] are: tensor([0.0010, 0.2075, 0.0572, 0.1116, 0.0413, 0.2223, 0.1448, 0.0941, 0.0306,
        0.0320, 0.0160, 0.0158, 0.0256], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:43,337][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.2786, 0.0397, 0.1031, 0.0171, 0.2654, 0.0308, 0.0208, 0.0107, 0.0177,
        0.0248, 0.0356, 0.0191, 0.0976, 0.0388], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:43,339][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0032, 0.0453, 0.1931, 0.0397, 0.1103, 0.0559, 0.1409, 0.0806, 0.1391,
        0.0162, 0.0106, 0.0751, 0.0640, 0.0261], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:43,340][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.1704, 0.1506, 0.1065, 0.0589, 0.2188, 0.0735, 0.0213, 0.0070, 0.0162,
        0.0511, 0.0379, 0.0176, 0.0512, 0.0188], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:43,342][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([1.3962e-01, 7.5330e-01, 4.4835e-04, 3.8391e-02, 2.3954e-03, 8.8800e-03,
        2.2649e-03, 7.5850e-04, 4.5536e-04, 1.1997e-02, 2.6084e-02, 1.5829e-03,
        1.8344e-03, 1.1980e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:43,344][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0023, 0.0811, 0.1206, 0.0622, 0.1101, 0.2366, 0.0876, 0.0495, 0.1206,
        0.0191, 0.0108, 0.0224, 0.0340, 0.0432], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:43,345][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.3137, 0.0819, 0.0253, 0.0378, 0.0538, 0.0983, 0.0319, 0.0214, 0.0449,
        0.0407, 0.0557, 0.0376, 0.0510, 0.1060], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:43,346][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([1.0487e-04, 1.8723e-02, 1.7997e-01, 2.0275e-02, 1.0112e-01, 1.2335e-01,
        1.4473e-01, 1.7968e-01, 8.8731e-02, 1.1184e-02, 4.5644e-03, 1.4876e-02,
        6.3125e-02, 4.9571e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:43,346][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0562, 0.5471, 0.0109, 0.0589, 0.0292, 0.0472, 0.0292, 0.0342, 0.0136,
        0.0277, 0.0372, 0.0250, 0.0256, 0.0579], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:43,347][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.1331, 0.1441, 0.2021, 0.0449, 0.2074, 0.0557, 0.0238, 0.0158, 0.0117,
        0.0356, 0.0372, 0.0266, 0.0435, 0.0184], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:43,349][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([3.8835e-06, 1.0419e-02, 2.5357e-02, 2.5624e-02, 1.2005e-02, 1.4263e-01,
        3.1526e-01, 3.1079e-01, 1.1637e-01, 7.4603e-03, 1.6352e-03, 4.3589e-03,
        1.1955e-02, 1.6129e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:43,350][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0314, 0.7803, 0.0020, 0.0797, 0.0050, 0.0202, 0.0069, 0.0011, 0.0013,
        0.0107, 0.0221, 0.0036, 0.0026, 0.0333], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:43,352][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0019, 0.1587, 0.0799, 0.1016, 0.0518, 0.1592, 0.1467, 0.1263, 0.0418,
        0.0262, 0.0141, 0.0238, 0.0287, 0.0393], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:43,353][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.5274, 0.0408, 0.0765, 0.0104, 0.1609, 0.0143, 0.0065, 0.0040, 0.0074,
        0.0143, 0.0232, 0.0175, 0.0516, 0.0291, 0.0159], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,355][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0100, 0.0805, 0.1749, 0.0637, 0.1075, 0.0739, 0.0901, 0.0504, 0.0901,
        0.0272, 0.0223, 0.0732, 0.0569, 0.0375, 0.0418], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,357][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3931, 0.1069, 0.1110, 0.0334, 0.1760, 0.0254, 0.0075, 0.0043, 0.0064,
        0.0271, 0.0248, 0.0141, 0.0386, 0.0098, 0.0217], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,359][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.6558, 0.1539, 0.0018, 0.0156, 0.0072, 0.0072, 0.0049, 0.0033, 0.0046,
        0.0264, 0.0394, 0.0110, 0.0122, 0.0417, 0.0151], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,361][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0377, 0.1834, 0.1385, 0.0796, 0.1082, 0.1367, 0.0461, 0.0284, 0.0527,
        0.0260, 0.0210, 0.0311, 0.0321, 0.0503, 0.0281], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,362][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.5733, 0.0481, 0.0184, 0.0241, 0.0424, 0.0524, 0.0138, 0.0137, 0.0159,
        0.0273, 0.0398, 0.0273, 0.0334, 0.0511, 0.0189], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,364][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0007, 0.0324, 0.2660, 0.0246, 0.1164, 0.1216, 0.0778, 0.0992, 0.0697,
        0.0113, 0.0080, 0.0177, 0.0606, 0.0516, 0.0424], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,366][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1959, 0.2883, 0.0206, 0.0435, 0.0529, 0.0359, 0.0268, 0.0460, 0.0157,
        0.0302, 0.0401, 0.0462, 0.0512, 0.0887, 0.0181], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,368][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2628, 0.1274, 0.1750, 0.0383, 0.1625, 0.0222, 0.0118, 0.0096, 0.0073,
        0.0277, 0.0400, 0.0226, 0.0475, 0.0184, 0.0269], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,369][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.3965e-05, 2.7305e-02, 3.9906e-02, 5.0727e-02, 1.9745e-02, 1.9012e-01,
        1.9784e-01, 2.4450e-01, 1.0865e-01, 9.9307e-03, 3.4951e-03, 6.2956e-03,
        1.4002e-02, 2.1237e-02, 6.6224e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,370][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.3505, 0.2564, 0.0093, 0.0433, 0.0231, 0.0199, 0.0145, 0.0067, 0.0136,
        0.0243, 0.0488, 0.0266, 0.0224, 0.1086, 0.0321], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,372][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0035, 0.2794, 0.1106, 0.0763, 0.0632, 0.1427, 0.0731, 0.0758, 0.0228,
        0.0215, 0.0123, 0.0255, 0.0284, 0.0315, 0.0335], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,376][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:25:43,377][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[13345],
        [ 2269],
        [ 2389],
        [  229],
        [  659],
        [  124],
        [  212],
        [  492],
        [  436],
        [  152],
        [  267],
        [  539],
        [  446],
        [  186],
        [  274]], device='cuda:0')
[2024-07-24 10:25:43,379][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[13242],
        [ 6586],
        [10147],
        [ 2201],
        [ 3360],
        [ 1053],
        [ 1938],
        [ 3128],
        [ 2481],
        [  996],
        [ 1806],
        [ 2456],
        [ 1864],
        [ 1187],
        [ 1588]], device='cuda:0')
[2024-07-24 10:25:43,381][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 447],
        [ 315],
        [ 692],
        [4734],
        [ 865],
        [ 319],
        [ 314],
        [ 462],
        [ 249],
        [2757],
        [2848],
        [ 972],
        [1577],
        [2190],
        [1342]], device='cuda:0')
[2024-07-24 10:25:43,382][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[20159],
        [20188],
        [25194],
        [24868],
        [31167],
        [30008],
        [29508],
        [29412],
        [26583],
        [24457],
        [22357],
        [25625],
        [26879],
        [25202],
        [26748]], device='cuda:0')
[2024-07-24 10:25:43,384][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 7120],
        [17806],
        [ 5179],
        [ 7265],
        [ 9825],
        [ 9780],
        [10982],
        [10379],
        [ 9504],
        [ 9871],
        [ 9820],
        [ 9954],
        [10143],
        [10125],
        [10691]], device='cuda:0')
[2024-07-24 10:25:43,386][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 8975],
        [10760],
        [ 9331],
        [17935],
        [10617],
        [10544],
        [20180],
        [23755],
        [19836],
        [19686],
        [21800],
        [24815],
        [20705],
        [26380],
        [19283]], device='cuda:0')
[2024-07-24 10:25:43,388][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[1325],
        [1939],
        [ 716],
        [ 866],
        [1192],
        [1572],
        [2101],
        [2630],
        [3364],
        [3423],
        [3403],
        [3254],
        [3191],
        [3194],
        [3032]], device='cuda:0')
[2024-07-24 10:25:43,389][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[30919],
        [ 8804],
        [ 7395],
        [ 6376],
        [ 4753],
        [ 3710],
        [ 3941],
        [ 3229],
        [ 3542],
        [ 2933],
        [ 2854],
        [ 3214],
        [ 2717],
        [ 2840],
        [ 2753]], device='cuda:0')
[2024-07-24 10:25:43,390][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[44648],
        [ 2488],
        [13900],
        [24403],
        [11771],
        [12303],
        [ 4344],
        [ 4643],
        [ 3854],
        [ 3812],
        [ 3652],
        [ 3766],
        [ 4624],
        [ 4859],
        [ 7594]], device='cuda:0')
[2024-07-24 10:25:43,392][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[32780],
        [29406],
        [28085],
        [26408],
        [30753],
        [29895],
        [26752],
        [28186],
        [29421],
        [32553],
        [33391],
        [31137],
        [34964],
        [28565],
        [32026]], device='cuda:0')
[2024-07-24 10:25:43,394][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 192],
        [ 838],
        [7083],
        [3628],
        [1209],
        [ 897],
        [ 676],
        [ 618],
        [ 541],
        [ 645],
        [ 661],
        [ 567],
        [ 599],
        [ 579],
        [ 640]], device='cuda:0')
[2024-07-24 10:25:43,395][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[10485],
        [ 6851],
        [    1],
        [    2],
        [   10],
        [   23],
        [  141],
        [  285],
        [  456],
        [  585],
        [  462],
        [  982],
        [  859],
        [ 1224],
        [  690]], device='cuda:0')
[2024-07-24 10:25:43,397][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[10707],
        [18303],
        [19669],
        [19240],
        [17943],
        [17950],
        [17974],
        [17450],
        [16947],
        [16562],
        [16065],
        [15510],
        [15354],
        [15290],
        [15184]], device='cuda:0')
[2024-07-24 10:25:43,399][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[16422],
        [ 3357],
        [ 1190],
        [ 1565],
        [ 1927],
        [ 2444],
        [ 2360],
        [ 2608],
        [ 3529],
        [ 3528],
        [ 3439],
        [ 3568],
        [ 3474],
        [ 3346],
        [ 3081]], device='cuda:0')
[2024-07-24 10:25:43,400][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[18250],
        [10998],
        [ 9714],
        [ 8528],
        [10930],
        [ 9095],
        [ 6955],
        [ 8547],
        [ 9501],
        [ 7789],
        [ 8588],
        [10241],
        [11137],
        [ 9431],
        [ 7537]], device='cuda:0')
[2024-07-24 10:25:43,402][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 6678],
        [ 7772],
        [ 3178],
        [ 1339],
        [ 2579],
        [ 5032],
        [ 4958],
        [ 4745],
        [ 6647],
        [ 7668],
        [ 9763],
        [ 8045],
        [ 6265],
        [11757],
        [ 7912]], device='cuda:0')
[2024-07-24 10:25:43,404][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[41108],
        [23129],
        [ 9127],
        [12889],
        [ 8928],
        [10693],
        [15118],
        [12365],
        [13236],
        [13676],
        [16259],
        [13763],
        [18651],
        [14241],
        [16220]], device='cuda:0')
[2024-07-24 10:25:43,405][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[18006],
        [14264],
        [13186],
        [ 4731],
        [ 8699],
        [ 7285],
        [ 7722],
        [ 7865],
        [ 7314],
        [ 8925],
        [ 8306],
        [ 5989],
        [ 7602],
        [ 9162],
        [ 8803]], device='cuda:0')
[2024-07-24 10:25:43,407][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[6439],
        [6401],
        [6421],
        [7448],
        [6398],
        [6397],
        [7820],
        [7672],
        [7736],
        [7160],
        [6766],
        [6719],
        [6323],
        [6744],
        [6316]], device='cuda:0')
[2024-07-24 10:25:43,409][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 5706],
        [ 9931],
        [12540],
        [17090],
        [16795],
        [14584],
        [15714],
        [17207],
        [17515],
        [18808],
        [19417],
        [19896],
        [19288],
        [19044],
        [18656]], device='cuda:0')
[2024-07-24 10:25:43,410][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[6874],
        [5414],
        [5024],
        [4322],
        [3353],
        [2223],
        [2421],
        [2215],
        [2390],
        [2616],
        [2743],
        [3067],
        [2516],
        [2209],
        [2223]], device='cuda:0')
[2024-07-24 10:25:43,412][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[20833],
        [20861],
        [21296],
        [25952],
        [28259],
        [33056],
        [33240],
        [26924],
        [23031],
        [25623],
        [22394],
        [22233],
        [21972],
        [22406],
        [24646]], device='cuda:0')
[2024-07-24 10:25:43,414][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 4963],
        [16720],
        [18910],
        [28401],
        [29938],
        [30166],
        [30823],
        [30558],
        [31378],
        [31106],
        [31516],
        [30731],
        [30253],
        [29974],
        [27649]], device='cuda:0')
[2024-07-24 10:25:43,415][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 6086],
        [ 2839],
        [ 7015],
        [ 9242],
        [ 8285],
        [ 6907],
        [ 7786],
        [ 8545],
        [ 7781],
        [ 9978],
        [10941],
        [12051],
        [10560],
        [10659],
        [11010]], device='cuda:0')
[2024-07-24 10:25:43,417][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[31463],
        [38696],
        [47973],
        [47940],
        [46539],
        [46531],
        [45377],
        [43850],
        [42162],
        [41938],
        [41264],
        [42142],
        [43095],
        [41476],
        [42893]], device='cuda:0')
[2024-07-24 10:25:43,419][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 3715],
        [15021],
        [ 5302],
        [14869],
        [12358],
        [13097],
        [14393],
        [14818],
        [14605],
        [16044],
        [18200],
        [16931],
        [22967],
        [14830],
        [19390]], device='cuda:0')
[2024-07-24 10:25:43,420][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[9698],
        [6341],
        [7532],
        [7419],
        [6780],
        [6454],
        [6428],
        [6124],
        [5595],
        [5737],
        [5423],
        [5730],
        [5604],
        [5195],
        [5841]], device='cuda:0')
[2024-07-24 10:25:43,422][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[42379],
        [42069],
        [41854],
        [41213],
        [41867],
        [41906],
        [40134],
        [42688],
        [41466],
        [42302],
        [41314],
        [41982],
        [41615],
        [42175],
        [41333]], device='cuda:0')
[2024-07-24 10:25:43,423][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[26650],
        [31622],
        [40332],
        [37447],
        [36184],
        [35416],
        [34232],
        [34447],
        [34249],
        [36759],
        [35517],
        [33546],
        [32059],
        [34978],
        [37848]], device='cuda:0')
[2024-07-24 10:25:43,425][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[12428],
        [12428],
        [12428],
        [12428],
        [12428],
        [12428],
        [12428],
        [12428],
        [12428],
        [12428],
        [12428],
        [12428],
        [12428],
        [12428],
        [12428]], device='cuda:0')
[2024-07-24 10:25:43,528][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:43,530][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,531][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,532][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,533][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,534][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,535][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,535][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,536][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,537][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,538][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,538][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,539][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,540][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.8018, 0.1982], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,540][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0220, 0.9780], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,541][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2890, 0.7110], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,542][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9939, 0.0061], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,542][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1421, 0.8579], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,544][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0282, 0.9718], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,545][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0955, 0.9045], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,547][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.6673, 0.3327], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,549][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0765, 0.9235], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,550][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1366, 0.8634], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,551][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([6.5111e-04, 9.9935e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,553][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1803, 0.8197], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,554][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Jose] are: tensor([0.1883, 0.3123, 0.4994], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,556][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Jose] are: tensor([0.0108, 0.2805, 0.7087], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,558][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Jose] are: tensor([0.0569, 0.4261, 0.5170], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,559][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Jose] are: tensor([0.9904, 0.0045, 0.0050], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,561][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Jose] are: tensor([0.0855, 0.8621, 0.0524], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,563][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Jose] are: tensor([0.0143, 0.6928, 0.2930], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,564][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Jose] are: tensor([0.0867, 0.3514, 0.5619], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,565][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Jose] are: tensor([0.8345, 0.0334, 0.1321], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,567][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Jose] are: tensor([0.0694, 0.5280, 0.4026], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,569][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Jose] are: tensor([0.6594, 0.2963, 0.0443], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,570][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Jose] are: tensor([2.5497e-04, 9.6153e-01, 3.8217e-02], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,571][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Jose] are: tensor([0.0762, 0.4085, 0.5153], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,573][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.5423, 0.1319, 0.2542, 0.0716], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,575][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0029, 0.1589, 0.4852, 0.3529], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,575][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0316, 0.1983, 0.3664, 0.4037], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,576][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.9358, 0.0304, 0.0262, 0.0076], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,577][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0306, 0.3269, 0.0304, 0.6121], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,578][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0075, 0.3589, 0.1502, 0.4834], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,579][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0156, 0.3843, 0.4950, 0.1052], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,581][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2839, 0.1800, 0.4952, 0.0409], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,582][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0153, 0.3554, 0.2382, 0.3911], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,584][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0620, 0.9158, 0.0026, 0.0196], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,585][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([3.7113e-05, 2.0980e-01, 4.4850e-03, 7.8568e-01], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,587][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0197, 0.2644, 0.6566, 0.0593], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,588][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Stephanie] are: tensor([0.0332, 0.0892, 0.4013, 0.0804, 0.3960], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,590][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Stephanie] are: tensor([0.0029, 0.1515, 0.4546, 0.2805, 0.1104], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,591][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Stephanie] are: tensor([0.0068, 0.1001, 0.2772, 0.5008, 0.1150], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,593][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Stephanie] are: tensor([0.9473, 0.0149, 0.0165, 0.0043, 0.0170], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,595][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Stephanie] are: tensor([0.0211, 0.2821, 0.0321, 0.6323, 0.0324], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,596][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Stephanie] are: tensor([0.0055, 0.3446, 0.1080, 0.3416, 0.2003], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,598][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Stephanie] are: tensor([0.0131, 0.1820, 0.4148, 0.0769, 0.3132], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,600][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Stephanie] are: tensor([0.4865, 0.0694, 0.3474, 0.0126, 0.0841], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,601][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Stephanie] are: tensor([0.0117, 0.2692, 0.1582, 0.3419, 0.2190], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,603][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Stephanie] are: tensor([0.4991, 0.3787, 0.0122, 0.0593, 0.0507], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,604][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Stephanie] are: tensor([3.9922e-05, 8.6836e-02, 3.4235e-03, 9.0890e-01, 7.9985e-04],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,606][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Stephanie] are: tensor([0.0740, 0.1200, 0.2466, 0.0426, 0.5168], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,607][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.2389, 0.0731, 0.3294, 0.0594, 0.2397, 0.0594], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,609][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0040, 0.1255, 0.2514, 0.2259, 0.0835, 0.3096], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,611][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0103, 0.0381, 0.1743, 0.1642, 0.0804, 0.5327], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,612][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.9366, 0.0181, 0.0139, 0.0050, 0.0150, 0.0115], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,614][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0080, 0.1076, 0.0301, 0.3279, 0.0240, 0.5025], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,616][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0106, 0.3332, 0.0719, 0.2740, 0.1137, 0.1966], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,617][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0199, 0.1740, 0.2911, 0.0643, 0.1521, 0.2987], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,618][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.3943, 0.1069, 0.3764, 0.0214, 0.0600, 0.0409], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,619][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0161, 0.1636, 0.2859, 0.1839, 0.2583, 0.0922], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,620][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.4522, 0.4999, 0.0042, 0.0246, 0.0130, 0.0061], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,620][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ had] are: tensor([1.0673e-05, 1.0635e-01, 1.3846e-03, 8.6265e-01, 1.8395e-04, 2.9418e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,622][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.1303, 0.0571, 0.3950, 0.0245, 0.3475, 0.0456], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,624][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.3851, 0.0544, 0.2745, 0.0458, 0.1728, 0.0418, 0.0257],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:43,625][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0017, 0.0861, 0.1457, 0.1380, 0.0532, 0.2112, 0.3640],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:43,627][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0045, 0.0467, 0.0569, 0.0686, 0.0420, 0.2130, 0.5684],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:43,628][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.7779, 0.0848, 0.0375, 0.0169, 0.0315, 0.0339, 0.0174],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:43,630][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0062, 0.0746, 0.0063, 0.1584, 0.0057, 0.2239, 0.5249],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:43,632][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0095, 0.2257, 0.0402, 0.1800, 0.0517, 0.1589, 0.3340],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:43,633][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0109, 0.2600, 0.2293, 0.0536, 0.1083, 0.2524, 0.0855],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:43,635][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0906, 0.3038, 0.4474, 0.0373, 0.0687, 0.0344, 0.0178],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:43,637][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0107, 0.2713, 0.2764, 0.2044, 0.1579, 0.0371, 0.0422],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:43,638][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([7.2075e-02, 9.2071e-01, 7.2403e-06, 6.7104e-03, 5.5937e-05, 3.6058e-04,
        8.0891e-05], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:43,639][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([9.1210e-05, 1.8903e-01, 2.7513e-03, 7.1321e-01, 6.3715e-04, 3.6916e-02,
        5.7359e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:43,641][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.2555, 0.1903, 0.2535, 0.0236, 0.2121, 0.0384, 0.0267],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:43,642][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0542, 0.2218, 0.1875, 0.0959, 0.2027, 0.0616, 0.0685, 0.1078],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:43,644][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0018, 0.0701, 0.2079, 0.1251, 0.0557, 0.1610, 0.2862, 0.0923],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:43,646][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0017, 0.0418, 0.0500, 0.0981, 0.0296, 0.2161, 0.4262, 0.1363],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:43,647][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.7307, 0.0880, 0.0366, 0.0200, 0.0415, 0.0320, 0.0280, 0.0232],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:43,649][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0026, 0.0595, 0.0060, 0.1351, 0.0059, 0.1614, 0.5895, 0.0400],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:43,651][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0040, 0.1542, 0.0251, 0.1256, 0.0435, 0.1326, 0.3636, 0.1514],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:43,652][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0066, 0.2180, 0.1831, 0.0558, 0.0864, 0.2822, 0.1035, 0.0643],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:43,654][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0954, 0.2767, 0.4881, 0.0290, 0.0332, 0.0385, 0.0215, 0.0176],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:43,656][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0045, 0.2735, 0.1738, 0.2761, 0.0965, 0.0588, 0.0795, 0.0373],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:43,657][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ long] are: tensor([9.0092e-02, 8.9126e-01, 5.2617e-06, 1.1778e-02, 7.7318e-05, 1.0037e-03,
        5.5326e-03, 2.5617e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:43,658][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ long] are: tensor([3.7358e-07, 1.8440e-01, 4.1892e-04, 7.4748e-01, 5.9168e-05, 1.7655e-02,
        4.9013e-02, 9.6744e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:43,659][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0754, 0.2240, 0.1217, 0.0587, 0.1537, 0.0909, 0.1351, 0.1405],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:43,660][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0300, 0.1143, 0.1576, 0.0366, 0.1178, 0.0576, 0.0422, 0.1287, 0.3152],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:43,661][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0015, 0.0822, 0.1156, 0.1416, 0.0423, 0.1522, 0.2862, 0.0978, 0.0807],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:43,662][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0022, 0.0387, 0.0367, 0.0910, 0.0310, 0.1419, 0.3786, 0.1503, 0.1296],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:43,663][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.7294, 0.0794, 0.0332, 0.0236, 0.0315, 0.0336, 0.0212, 0.0191, 0.0288],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:43,664][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0048, 0.0656, 0.0041, 0.1587, 0.0059, 0.1830, 0.4877, 0.0466, 0.0435],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:43,666][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0027, 0.1648, 0.0202, 0.1047, 0.0326, 0.1044, 0.3377, 0.1165, 0.1165],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:43,667][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0133, 0.2525, 0.1695, 0.0734, 0.0934, 0.2188, 0.0826, 0.0538, 0.0427],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:43,669][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.1640, 0.2529, 0.3711, 0.0389, 0.0395, 0.0495, 0.0164, 0.0124, 0.0552],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:43,670][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0072, 0.2144, 0.1231, 0.2984, 0.1282, 0.0522, 0.0867, 0.0322, 0.0576],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:43,672][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([2.9638e-02, 9.4181e-01, 6.2396e-06, 1.9825e-02, 6.0879e-05, 1.6485e-03,
        5.0501e-03, 3.1829e-04, 1.6394e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:43,673][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([6.6765e-06, 1.4511e-01, 1.0485e-03, 6.9634e-01, 3.3979e-04, 5.9118e-02,
        9.5377e-02, 2.5497e-03, 1.0730e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:43,675][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.2903, 0.1170, 0.0658, 0.0377, 0.0822, 0.0719, 0.0576, 0.0672, 0.2103],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:43,676][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1107, 0.0276, 0.1572, 0.0223, 0.2179, 0.0351, 0.0387, 0.1164, 0.2558,
        0.0184], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:43,678][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0006, 0.0468, 0.1113, 0.1073, 0.0309, 0.1645, 0.3304, 0.0853, 0.0848,
        0.0380], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:43,680][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0020, 0.0313, 0.0575, 0.0646, 0.0266, 0.2234, 0.3883, 0.1109, 0.0758,
        0.0195], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:43,681][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.7484, 0.0502, 0.0387, 0.0155, 0.0392, 0.0241, 0.0181, 0.0215, 0.0252,
        0.0191], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:43,683][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0014, 0.0409, 0.0072, 0.0857, 0.0043, 0.1530, 0.4368, 0.0223, 0.0448,
        0.2037], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:43,685][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0010, 0.1135, 0.0255, 0.1226, 0.0490, 0.0928, 0.3118, 0.1235, 0.1129,
        0.0473], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:43,686][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0026, 0.1423, 0.2107, 0.0504, 0.0928, 0.2529, 0.1018, 0.0638, 0.0523,
        0.0305], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:43,688][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0237, 0.0809, 0.5480, 0.0204, 0.1827, 0.0245, 0.0190, 0.0201, 0.0508,
        0.0299], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:43,690][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0015, 0.2480, 0.1567, 0.2582, 0.0682, 0.0498, 0.0888, 0.0270, 0.0310,
        0.0709], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:43,691][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([2.8104e-02, 9.2976e-01, 2.8038e-04, 2.6808e-02, 1.9181e-03, 3.2999e-03,
        2.3959e-03, 9.2464e-04, 1.6811e-03, 4.8260e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:43,692][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([1.0658e-06, 9.7109e-02, 1.1164e-03, 2.3573e-01, 2.0181e-04, 2.8370e-02,
        4.6658e-02, 2.2406e-03, 1.6176e-04, 5.8841e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:43,694][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0026, 0.0911, 0.2449, 0.0313, 0.1582, 0.0565, 0.1081, 0.0887, 0.2072,
        0.0114], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:43,696][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0858, 0.0462, 0.1321, 0.0329, 0.2040, 0.0549, 0.0466, 0.1065, 0.2346,
        0.0272, 0.0293], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:43,697][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0004, 0.0390, 0.0931, 0.1055, 0.0294, 0.1534, 0.3374, 0.0972, 0.0859,
        0.0333, 0.0253], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:43,699][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0015, 0.0229, 0.0429, 0.0484, 0.0271, 0.1586, 0.3905, 0.1579, 0.1229,
        0.0203, 0.0071], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:43,701][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.6911, 0.0429, 0.0317, 0.0161, 0.0408, 0.0261, 0.0223, 0.0284, 0.0299,
        0.0311, 0.0397], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:43,702][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0014, 0.0313, 0.0077, 0.0666, 0.0048, 0.1334, 0.4258, 0.0313, 0.0654,
        0.1870, 0.0453], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:43,702][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0007, 0.0915, 0.0205, 0.1007, 0.0482, 0.0805, 0.3306, 0.1329, 0.1228,
        0.0447, 0.0271], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:43,703][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0034, 0.1249, 0.1405, 0.0589, 0.0893, 0.2238, 0.1325, 0.0892, 0.0665,
        0.0434, 0.0276], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:43,704][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0362, 0.0774, 0.3714, 0.0316, 0.2363, 0.0293, 0.0323, 0.0445, 0.0598,
        0.0513, 0.0298], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:43,706][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0021, 0.1531, 0.1225, 0.2426, 0.0573, 0.0608, 0.1406, 0.0443, 0.0624,
        0.0800, 0.0343], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:43,707][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0402, 0.8702, 0.0020, 0.0301, 0.0085, 0.0081, 0.0036, 0.0023, 0.0050,
        0.0088, 0.0213], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:43,709][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([5.9755e-07, 5.8411e-02, 5.6062e-04, 1.2527e-01, 1.2132e-04, 3.1532e-02,
        3.7700e-02, 3.0567e-03, 2.3022e-04, 4.1919e-01, 3.2393e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:43,710][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0020, 0.1059, 0.2080, 0.0339, 0.1188, 0.0520, 0.1237, 0.1318, 0.2010,
        0.0123, 0.0106], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:43,712][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0126, 0.0417, 0.0675, 0.0155, 0.0951, 0.0301, 0.0298, 0.1261, 0.3133,
        0.0215, 0.0141, 0.2327], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:43,714][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0005, 0.0441, 0.1009, 0.0968, 0.0338, 0.1674, 0.2994, 0.0800, 0.0814,
        0.0390, 0.0270, 0.0297], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:43,715][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([3.5984e-04, 2.0515e-02, 4.5608e-02, 8.0072e-02, 2.3225e-02, 1.4245e-01,
        3.6647e-01, 1.4214e-01, 1.2790e-01, 1.9175e-02, 6.9553e-03, 2.5133e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:43,717][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.6210, 0.0847, 0.0453, 0.0245, 0.0335, 0.0363, 0.0242, 0.0204, 0.0279,
        0.0261, 0.0346, 0.0214], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:43,718][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0013, 0.0382, 0.0029, 0.0683, 0.0025, 0.1155, 0.3872, 0.0301, 0.0429,
        0.2164, 0.0507, 0.0440], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:43,720][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0012, 0.1256, 0.0168, 0.0901, 0.0271, 0.0811, 0.3168, 0.1072, 0.1103,
        0.0440, 0.0246, 0.0552], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:43,722][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0025, 0.1195, 0.1587, 0.0559, 0.0793, 0.2421, 0.1327, 0.0716, 0.0497,
        0.0374, 0.0205, 0.0299], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:43,723][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0435, 0.0764, 0.5199, 0.0175, 0.1120, 0.0317, 0.0203, 0.0108, 0.0750,
        0.0301, 0.0210, 0.0419], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:43,725][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0079, 0.1375, 0.0869, 0.2365, 0.0789, 0.0485, 0.1046, 0.0333, 0.0600,
        0.0916, 0.0564, 0.0580], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:43,726][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([9.4788e-03, 9.1263e-01, 5.4559e-05, 2.5863e-02, 3.4404e-04, 4.9899e-03,
        1.4565e-02, 1.4175e-03, 9.2180e-03, 7.5035e-03, 1.0650e-02, 3.2816e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:43,728][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([1.0303e-06, 1.5186e-02, 2.5127e-04, 9.5562e-02, 8.4549e-05, 9.7303e-03,
        2.7100e-02, 9.7100e-04, 6.1006e-05, 3.6109e-01, 4.8988e-01, 8.5782e-05],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:43,729][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0364, 0.1139, 0.0866, 0.0249, 0.1093, 0.0647, 0.1173, 0.0763, 0.2280,
        0.0291, 0.0298, 0.0838], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:43,731][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Stephanie] are: tensor([0.0152, 0.0420, 0.1212, 0.0236, 0.0869, 0.0292, 0.0292, 0.0997, 0.1493,
        0.0202, 0.0216, 0.1386, 0.2233], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:43,733][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Stephanie] are: tensor([0.0010, 0.0577, 0.0932, 0.0881, 0.0382, 0.1271, 0.2471, 0.0653, 0.0915,
        0.0511, 0.0325, 0.0442, 0.0628], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:43,734][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Stephanie] are: tensor([0.0004, 0.0154, 0.0504, 0.0645, 0.0219, 0.1487, 0.3418, 0.1575, 0.1320,
        0.0166, 0.0054, 0.0325, 0.0129], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:43,736][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Stephanie] are: tensor([0.6738, 0.0415, 0.0420, 0.0102, 0.0308, 0.0170, 0.0111, 0.0135, 0.0215,
        0.0153, 0.0223, 0.0514, 0.0498], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:43,738][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Stephanie] are: tensor([0.0018, 0.0456, 0.0051, 0.0903, 0.0054, 0.1412, 0.4225, 0.0265, 0.0315,
        0.1363, 0.0380, 0.0312, 0.0246], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:43,740][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Stephanie] are: tensor([0.0004, 0.0789, 0.0154, 0.0619, 0.0268, 0.0677, 0.3115, 0.1117, 0.1299,
        0.0442, 0.0250, 0.0860, 0.0407], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:43,741][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Stephanie] are: tensor([0.0034, 0.1164, 0.1525, 0.0411, 0.1044, 0.2145, 0.0871, 0.0423, 0.0597,
        0.0267, 0.0156, 0.0299, 0.1065], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:43,743][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Stephanie] are: tensor([0.1078, 0.0864, 0.4148, 0.0192, 0.0982, 0.0211, 0.0178, 0.0086, 0.0934,
        0.0276, 0.0210, 0.0345, 0.0494], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:43,744][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Stephanie] are: tensor([0.0031, 0.1806, 0.0664, 0.2471, 0.0748, 0.0400, 0.0856, 0.0287, 0.0414,
        0.0850, 0.0444, 0.0449, 0.0582], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:43,745][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Stephanie] are: tensor([0.0592, 0.3950, 0.0008, 0.0288, 0.0034, 0.0153, 0.1348, 0.0177, 0.1917,
        0.0371, 0.0411, 0.0574, 0.0177], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:43,746][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Stephanie] are: tensor([2.4401e-06, 1.5275e-02, 4.9670e-04, 1.1835e-01, 1.1505e-04, 8.1650e-03,
        1.4319e-02, 1.3003e-03, 5.4066e-05, 3.3156e-01, 5.1017e-01, 8.0626e-05,
        1.0325e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:43,747][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Stephanie] are: tensor([0.0237, 0.1216, 0.1068, 0.0254, 0.1605, 0.0608, 0.0816, 0.0749, 0.1671,
        0.0140, 0.0152, 0.0373, 0.1111], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:43,748][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0606, 0.0318, 0.1145, 0.0172, 0.0955, 0.0320, 0.0265, 0.0773, 0.1552,
        0.0182, 0.0163, 0.1171, 0.1812, 0.0565], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:43,750][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0003, 0.0448, 0.0780, 0.0897, 0.0324, 0.1340, 0.2561, 0.0950, 0.0846,
        0.0294, 0.0242, 0.0297, 0.0523, 0.0494], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:43,751][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ said] are: tensor([2.8374e-04, 1.7160e-02, 4.7109e-02, 4.2201e-02, 2.6235e-02, 9.8685e-02,
        4.6489e-01, 1.2998e-01, 9.8512e-02, 9.8802e-03, 2.9569e-03, 1.2477e-02,
        1.2413e-02, 3.7212e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:43,753][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.3709, 0.1170, 0.0675, 0.0216, 0.0627, 0.0398, 0.0245, 0.0265, 0.0258,
        0.0269, 0.0391, 0.0648, 0.0766, 0.0363], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:43,755][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0011, 0.0381, 0.0054, 0.0821, 0.0041, 0.1266, 0.3785, 0.0198, 0.0315,
        0.1630, 0.0495, 0.0488, 0.0234, 0.0281], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:43,756][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0006, 0.1479, 0.0188, 0.1152, 0.0326, 0.0804, 0.2730, 0.0790, 0.0724,
        0.0441, 0.0255, 0.0412, 0.0260, 0.0435], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:43,758][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0017, 0.0991, 0.1999, 0.0401, 0.0907, 0.1701, 0.0876, 0.0504, 0.0513,
        0.0266, 0.0177, 0.0173, 0.0975, 0.0500], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:43,760][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0102, 0.0624, 0.5610, 0.0236, 0.0683, 0.0300, 0.0262, 0.0229, 0.0647,
        0.0337, 0.0180, 0.0102, 0.0322, 0.0367], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:43,761][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0007, 0.1080, 0.1403, 0.2246, 0.0596, 0.0319, 0.1235, 0.0340, 0.0386,
        0.0813, 0.0249, 0.0332, 0.0481, 0.0512], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:43,763][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ said] are: tensor([2.6393e-03, 9.6670e-01, 9.3056e-05, 1.8055e-02, 5.1064e-04, 1.8138e-03,
        5.8094e-04, 9.5206e-05, 1.6087e-04, 9.7784e-04, 2.8738e-03, 1.3030e-04,
        2.1524e-04, 5.1555e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:43,764][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ said] are: tensor([3.9458e-08, 2.5899e-02, 1.1621e-04, 1.9592e-01, 1.5230e-05, 7.3432e-03,
        1.0603e-02, 3.0126e-04, 1.3470e-05, 2.7637e-01, 4.8339e-01, 1.0870e-05,
        8.2110e-06, 1.4562e-05], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:43,766][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0018, 0.0909, 0.1029, 0.0387, 0.1278, 0.0745, 0.1462, 0.0808, 0.1660,
        0.0172, 0.0106, 0.0158, 0.0737, 0.0532], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:43,767][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0285, 0.0206, 0.0785, 0.0272, 0.0801, 0.0424, 0.0320, 0.0863, 0.1054,
        0.0202, 0.0280, 0.1102, 0.2282, 0.0253, 0.0872], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,769][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0004, 0.0401, 0.0834, 0.0873, 0.0296, 0.1412, 0.2229, 0.0855, 0.0760,
        0.0278, 0.0202, 0.0260, 0.0496, 0.0456, 0.0645], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,771][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0013, 0.0292, 0.0968, 0.0560, 0.0643, 0.1453, 0.2928, 0.0893, 0.0835,
        0.0148, 0.0070, 0.0186, 0.0195, 0.0593, 0.0222], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,773][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.7596, 0.0266, 0.0171, 0.0073, 0.0229, 0.0119, 0.0073, 0.0111, 0.0126,
        0.0139, 0.0212, 0.0398, 0.0212, 0.0150, 0.0124], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,774][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0014, 0.0246, 0.0055, 0.0414, 0.0040, 0.0816, 0.1533, 0.0120, 0.0276,
        0.0851, 0.0265, 0.0315, 0.0136, 0.0212, 0.4708], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,776][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0015, 0.0834, 0.0178, 0.0823, 0.0297, 0.0746, 0.2174, 0.0973, 0.1052,
        0.0500, 0.0343, 0.0656, 0.0329, 0.0629, 0.0450], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,778][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0022, 0.0883, 0.1803, 0.0396, 0.1051, 0.1792, 0.0686, 0.0391, 0.0409,
        0.0228, 0.0147, 0.0217, 0.1072, 0.0390, 0.0514], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,780][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0727, 0.0727, 0.3652, 0.0247, 0.0993, 0.0253, 0.0203, 0.0143, 0.0774,
        0.0411, 0.0286, 0.0232, 0.0526, 0.0457, 0.0369], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,781][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0070, 0.1322, 0.2212, 0.1313, 0.0852, 0.0357, 0.0533, 0.0269, 0.0378,
        0.0643, 0.0261, 0.0557, 0.0412, 0.0357, 0.0462], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,783][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1635, 0.6679, 0.0011, 0.0251, 0.0043, 0.0051, 0.0029, 0.0013, 0.0059,
        0.0111, 0.0240, 0.0059, 0.0080, 0.0689, 0.0049], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,784][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([2.5897e-07, 4.5268e-02, 4.3239e-04, 1.5734e-01, 7.3342e-05, 1.1202e-02,
        1.9048e-02, 9.6836e-04, 8.8251e-05, 4.0190e-01, 3.5821e-01, 8.7599e-05,
        5.9583e-05, 1.2461e-04, 5.1965e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,785][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0262, 0.1772, 0.1716, 0.0269, 0.1324, 0.0355, 0.0359, 0.0461, 0.1057,
        0.0169, 0.0176, 0.0250, 0.0894, 0.0590, 0.0348], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:43,904][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:43,905][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,907][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,908][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,910][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,911][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,912][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,913][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,913][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,914][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,915][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,916][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,917][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:43,917][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0789, 0.9211], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,918][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0080, 0.9920], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,919][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2743, 0.7257], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,919][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9262, 0.0738], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,920][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.8332, 0.1668], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,921][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.3706, 0.6294], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,922][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0813, 0.9187], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,923][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.6673, 0.3327], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,924][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0765, 0.9235], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,926][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1366, 0.8634], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,927][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9971, 0.0029], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,929][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1803, 0.8197], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:43,930][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Jose] are: tensor([0.0085, 0.1043, 0.8872], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,931][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Jose] are: tensor([8.2879e-04, 1.3256e-01, 8.6661e-01], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,933][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Jose] are: tensor([0.0982, 0.1546, 0.7471], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,934][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Jose] are: tensor([0.4818, 0.1207, 0.3975], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,936][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Jose] are: tensor([0.6526, 0.3231, 0.0244], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,938][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Jose] are: tensor([0.6980, 0.2620, 0.0401], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,939][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Jose] are: tensor([0.0268, 0.1857, 0.7875], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,941][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Jose] are: tensor([0.8345, 0.0334, 0.1321], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,943][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Jose] are: tensor([0.0694, 0.5280, 0.4026], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,944][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Jose] are: tensor([0.6594, 0.2963, 0.0443], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,945][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Jose] are: tensor([9.0238e-02, 1.4755e-04, 9.0961e-01], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,947][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Jose] are: tensor([0.0762, 0.4085, 0.5153], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:43,949][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0018, 0.1077, 0.8185, 0.0720], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,950][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([6.5827e-05, 5.1815e-02, 8.5168e-01, 9.6438e-02], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,951][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0175, 0.0928, 0.7207, 0.1689], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,953][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2449, 0.1187, 0.5191, 0.1173], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,954][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2681, 0.4178, 0.0555, 0.2587], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,956][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4383, 0.4189, 0.0100, 0.1328], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,958][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0018, 0.1963, 0.7642, 0.0378], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,959][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2839, 0.1800, 0.4952, 0.0409], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,960][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0153, 0.3554, 0.2382, 0.3911], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,961][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0620, 0.9158, 0.0026, 0.0196], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,962][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([1.0225e-02, 2.9600e-05, 9.8973e-01, 1.7628e-05], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,962][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0197, 0.2644, 0.6566, 0.0593], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:43,963][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Stephanie] are: tensor([0.0026, 0.0636, 0.5475, 0.0920, 0.2944], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,964][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Stephanie] are: tensor([2.4706e-05, 2.6668e-02, 7.8228e-01, 1.2650e-01, 6.4530e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,966][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Stephanie] are: tensor([0.0066, 0.0630, 0.4926, 0.2238, 0.2140], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,967][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Stephanie] are: tensor([0.1258, 0.0867, 0.4413, 0.1246, 0.2216], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,969][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Stephanie] are: tensor([0.4393, 0.2219, 0.0334, 0.2295, 0.0759], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,971][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Stephanie] are: tensor([0.3897, 0.3720, 0.0134, 0.1936, 0.0313], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,972][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Stephanie] are: tensor([0.0025, 0.0476, 0.5519, 0.0369, 0.3611], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,974][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Stephanie] are: tensor([0.4865, 0.0694, 0.3474, 0.0126, 0.0841], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,975][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Stephanie] are: tensor([0.0117, 0.2692, 0.1582, 0.3419, 0.2190], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,977][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Stephanie] are: tensor([0.4991, 0.3787, 0.0122, 0.0593, 0.0507], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,978][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Stephanie] are: tensor([4.5559e-03, 2.5589e-05, 5.9279e-01, 3.9821e-05, 4.0259e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,980][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Stephanie] are: tensor([0.0740, 0.1200, 0.2466, 0.0426, 0.5168], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:43,981][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0014, 0.0756, 0.4641, 0.0965, 0.2423, 0.1201], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,982][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([1.9195e-05, 3.4124e-02, 6.5539e-01, 9.1569e-02, 4.4390e-02, 1.7451e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,984][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0073, 0.0237, 0.4152, 0.0890, 0.1589, 0.3058], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,986][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1461, 0.0401, 0.4010, 0.0792, 0.2040, 0.1295], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,987][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.2837, 0.1768, 0.0915, 0.1734, 0.0811, 0.1935], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,989][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.6022, 0.3192, 0.0025, 0.0615, 0.0077, 0.0070], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,991][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0023, 0.0620, 0.6002, 0.0307, 0.1576, 0.1472], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,992][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.3943, 0.1069, 0.3764, 0.0214, 0.0600, 0.0409], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,994][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0161, 0.1636, 0.2859, 0.1839, 0.2583, 0.0922], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,996][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.4522, 0.4999, 0.0042, 0.0246, 0.0130, 0.0061], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,997][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([2.7309e-03, 2.5586e-05, 5.7702e-01, 2.6360e-05, 4.2008e-01, 1.1985e-04],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:43,998][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.1303, 0.0571, 0.3950, 0.0245, 0.3475, 0.0456], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:44,000][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0009, 0.1681, 0.4235, 0.0908, 0.1598, 0.0983, 0.0585],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,001][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([1.2457e-05, 6.6691e-02, 4.5752e-01, 7.4566e-02, 3.6602e-02, 1.0198e-01,
        2.6263e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,002][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0056, 0.0571, 0.2892, 0.0699, 0.1901, 0.1776, 0.2106],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,003][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0738, 0.1248, 0.3319, 0.1306, 0.0985, 0.1501, 0.0903],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,004][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.4435, 0.2081, 0.0206, 0.1374, 0.0213, 0.1087, 0.0604],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,004][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([4.0325e-01, 5.4247e-01, 5.2981e-05, 5.0633e-02, 1.4616e-04, 2.7405e-03,
        7.0796e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,005][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0022, 0.1725, 0.4851, 0.0362, 0.0984, 0.1687, 0.0369],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,007][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0906, 0.3038, 0.4474, 0.0373, 0.0687, 0.0344, 0.0178],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,008][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0107, 0.2713, 0.2764, 0.2044, 0.1579, 0.0371, 0.0422],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,009][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([7.2075e-02, 9.2071e-01, 7.2403e-06, 6.7104e-03, 5.5937e-05, 3.6058e-04,
        8.0891e-05], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,011][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([2.7041e-03, 3.2627e-05, 5.8312e-01, 1.9750e-05, 4.1375e-01, 1.1332e-04,
        2.5443e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,012][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.2555, 0.1903, 0.2535, 0.0236, 0.2121, 0.0384, 0.0267],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,013][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0014, 0.1960, 0.2337, 0.1845, 0.0786, 0.1442, 0.0971, 0.0645],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,015][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([8.4069e-06, 1.8390e-02, 6.1935e-01, 4.7595e-02, 2.0595e-02, 7.7525e-02,
        1.8732e-01, 2.9220e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,016][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0034, 0.0625, 0.3198, 0.0883, 0.1277, 0.1814, 0.1494, 0.0674],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,018][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0577, 0.1538, 0.1897, 0.1585, 0.0938, 0.0979, 0.1819, 0.0666],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,020][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.2974, 0.2440, 0.0209, 0.1789, 0.0230, 0.1136, 0.1097, 0.0124],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,021][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([2.7996e-01, 6.1302e-01, 3.2300e-05, 7.5325e-02, 2.3065e-04, 7.8164e-03,
        2.0412e-02, 3.2051e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,023][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0021, 0.1665, 0.2677, 0.0491, 0.0834, 0.3227, 0.0700, 0.0385],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,024][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0954, 0.2767, 0.4881, 0.0290, 0.0332, 0.0385, 0.0215, 0.0176],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,026][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0045, 0.2735, 0.1738, 0.2761, 0.0965, 0.0588, 0.0795, 0.0373],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,027][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([9.0092e-02, 8.9126e-01, 5.2617e-06, 1.1778e-02, 7.7318e-05, 1.0037e-03,
        5.5326e-03, 2.5617e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,028][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([1.6573e-03, 3.4612e-05, 5.3084e-01, 2.3322e-05, 4.6051e-01, 1.7251e-04,
        5.2761e-04, 6.2397e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,030][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0754, 0.2240, 0.1217, 0.0587, 0.1537, 0.0909, 0.1351, 0.1405],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,032][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0021, 0.1867, 0.1942, 0.1833, 0.0878, 0.1779, 0.0585, 0.0394, 0.0702],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,033][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([1.2164e-05, 5.8373e-02, 2.2451e-01, 1.3868e-01, 2.5442e-02, 1.4183e-01,
        3.1408e-01, 4.1101e-02, 5.5961e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,034][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0059, 0.0608, 0.1841, 0.0853, 0.1347, 0.1497, 0.1746, 0.0917, 0.1131],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,036][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0343, 0.1400, 0.1818, 0.1563, 0.0754, 0.1272, 0.1096, 0.0501, 0.1252],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,038][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.5159, 0.1360, 0.0086, 0.1137, 0.0160, 0.0923, 0.0562, 0.0120, 0.0494],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,039][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([3.2714e-02, 8.3541e-01, 2.3786e-05, 9.0208e-02, 1.7903e-04, 5.1705e-03,
        3.0241e-02, 2.3090e-03, 3.7406e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,041][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0042, 0.2200, 0.2687, 0.0697, 0.1037, 0.2380, 0.0461, 0.0291, 0.0203],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,042][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.1640, 0.2529, 0.3711, 0.0389, 0.0395, 0.0495, 0.0164, 0.0124, 0.0552],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,044][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0072, 0.2144, 0.1231, 0.2984, 0.1282, 0.0522, 0.0867, 0.0322, 0.0576],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,045][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([2.9638e-02, 9.4181e-01, 6.2396e-06, 1.9825e-02, 6.0879e-05, 1.6485e-03,
        5.0501e-03, 3.1829e-04, 1.6394e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,046][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([2.0614e-03, 7.4016e-05, 3.3889e-01, 7.0292e-05, 3.3581e-01, 3.6180e-04,
        6.7149e-04, 4.9809e-03, 3.1707e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,046][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.2903, 0.1170, 0.0658, 0.0377, 0.0822, 0.0719, 0.0576, 0.0672, 0.2103],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,047][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([2.6161e-04, 5.5994e-02, 5.5138e-01, 3.3604e-02, 1.9864e-01, 5.7154e-02,
        2.2795e-02, 2.5752e-02, 4.2956e-02, 1.1468e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,048][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([2.7724e-06, 2.7343e-02, 5.0839e-01, 4.4871e-02, 3.1573e-02, 8.2840e-02,
        2.1298e-01, 3.3956e-02, 5.3324e-02, 4.7207e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,050][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0005, 0.0303, 0.2270, 0.0581, 0.0909, 0.2055, 0.1902, 0.0948, 0.0804,
        0.0224], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,052][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0184, 0.0706, 0.3153, 0.0688, 0.0995, 0.0934, 0.0605, 0.0932, 0.1262,
        0.0540], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,053][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0999, 0.1471, 0.0369, 0.1141, 0.0295, 0.0885, 0.0877, 0.0134, 0.1216,
        0.2612], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,055][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2421, 0.5521, 0.0012, 0.1142, 0.0040, 0.0171, 0.0139, 0.0057, 0.0067,
        0.0429], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,056][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([2.5357e-04, 9.5412e-02, 5.2313e-01, 2.6676e-02, 8.9202e-02, 1.6932e-01,
        3.7175e-02, 2.8497e-02, 2.2207e-02, 8.1352e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,058][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0237, 0.0809, 0.5480, 0.0204, 0.1827, 0.0245, 0.0190, 0.0201, 0.0508,
        0.0299], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,060][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0015, 0.2480, 0.1567, 0.2582, 0.0682, 0.0498, 0.0888, 0.0270, 0.0310,
        0.0709], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,061][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([2.8104e-02, 9.2976e-01, 2.8038e-04, 2.6808e-02, 1.9181e-03, 3.2999e-03,
        2.3959e-03, 9.2464e-04, 1.6811e-03, 4.8260e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,062][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([1.8164e-04, 2.9255e-05, 5.0421e-01, 1.7517e-05, 2.5705e-01, 1.2608e-04,
        3.1974e-04, 4.0911e-03, 2.3395e-01, 2.6518e-05], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,064][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0026, 0.0911, 0.2449, 0.0313, 0.1582, 0.0565, 0.1081, 0.0887, 0.2072,
        0.0114], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,065][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([2.6952e-04, 6.6916e-02, 4.7725e-01, 3.6497e-02, 2.0727e-01, 5.1154e-02,
        3.1129e-02, 4.4662e-02, 6.3631e-02, 1.4012e-02, 7.2088e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,066][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([4.5522e-06, 3.5351e-02, 3.7612e-01, 5.3182e-02, 3.6452e-02, 8.4454e-02,
        2.6329e-01, 6.0058e-02, 8.1167e-02, 6.9373e-03, 2.9764e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,068][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0007, 0.0280, 0.1649, 0.0494, 0.0939, 0.1559, 0.2051, 0.1374, 0.1273,
        0.0243, 0.0130], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,070][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0295, 0.0618, 0.2140, 0.0660, 0.0958, 0.0759, 0.0732, 0.1262, 0.1383,
        0.0745, 0.0446], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,071][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1104, 0.0934, 0.0324, 0.0799, 0.0327, 0.0615, 0.0678, 0.0193, 0.1288,
        0.2114, 0.1624], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,073][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3560, 0.3231, 0.0036, 0.0771, 0.0122, 0.0207, 0.0142, 0.0095, 0.0101,
        0.0521, 0.1213], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,075][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0004, 0.1252, 0.3374, 0.0450, 0.1076, 0.1767, 0.0797, 0.0607, 0.0391,
        0.0191, 0.0090], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,076][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0362, 0.0774, 0.3714, 0.0316, 0.2363, 0.0293, 0.0323, 0.0445, 0.0598,
        0.0513, 0.0298], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,078][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0021, 0.1531, 0.1225, 0.2426, 0.0573, 0.0608, 0.1406, 0.0443, 0.0624,
        0.0800, 0.0343], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,080][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0402, 0.8702, 0.0020, 0.0301, 0.0085, 0.0081, 0.0036, 0.0023, 0.0050,
        0.0088, 0.0213], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,081][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([2.7258e-04, 4.2553e-05, 4.0981e-01, 3.1221e-05, 3.0056e-01, 2.1443e-04,
        5.8264e-04, 7.4684e-03, 2.8031e-01, 4.7652e-05, 6.7010e-04],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,083][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0020, 0.1059, 0.2080, 0.0339, 0.1188, 0.0520, 0.1237, 0.1318, 0.2010,
        0.0123, 0.0106], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,084][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([3.0859e-04, 6.9918e-02, 3.7300e-01, 6.4410e-02, 1.6212e-01, 7.6263e-02,
        5.0659e-02, 3.8265e-02, 1.0467e-01, 3.1330e-02, 1.0952e-02, 1.8101e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,085][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([5.7559e-06, 1.7214e-02, 3.9489e-01, 6.9091e-02, 4.0389e-02, 8.6387e-02,
        2.7680e-01, 3.4459e-02, 6.2894e-02, 7.2399e-03, 3.5018e-03, 7.1290e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,086][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0008, 0.0290, 0.1831, 0.0754, 0.0942, 0.1461, 0.1955, 0.0949, 0.0940,
        0.0254, 0.0154, 0.0462], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,087][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0307, 0.0822, 0.1810, 0.0907, 0.1011, 0.0712, 0.0943, 0.0464, 0.0920,
        0.0798, 0.0533, 0.0774], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,088][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0526, 0.1201, 0.0095, 0.0661, 0.0116, 0.0695, 0.0648, 0.0149, 0.0902,
        0.2541, 0.1535, 0.0932], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,089][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([2.7320e-02, 7.1881e-01, 9.1712e-05, 8.2671e-02, 3.8713e-04, 8.5378e-03,
        3.5506e-02, 6.3432e-03, 1.2837e-02, 3.9555e-02, 5.8810e-02, 9.1307e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,090][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0005, 0.1106, 0.3648, 0.0456, 0.1181, 0.1780, 0.0765, 0.0406, 0.0271,
        0.0191, 0.0076, 0.0114], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,092][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0435, 0.0764, 0.5199, 0.0175, 0.1120, 0.0317, 0.0203, 0.0108, 0.0750,
        0.0301, 0.0210, 0.0419], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,094][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0079, 0.1375, 0.0869, 0.2365, 0.0789, 0.0485, 0.1046, 0.0333, 0.0600,
        0.0916, 0.0564, 0.0580], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,095][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([9.4788e-03, 9.1263e-01, 5.4559e-05, 2.5863e-02, 3.4404e-04, 4.9899e-03,
        1.4565e-02, 1.4175e-03, 9.2180e-03, 7.5035e-03, 1.0650e-02, 3.2816e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,096][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([3.1262e-04, 2.6525e-05, 4.7239e-01, 3.8285e-05, 2.9026e-01, 2.5999e-04,
        8.0372e-04, 5.1987e-03, 2.2844e-01, 5.5179e-05, 8.7505e-04, 1.3327e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,098][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0364, 0.1139, 0.0866, 0.0249, 0.1093, 0.0647, 0.1173, 0.0763, 0.2280,
        0.0291, 0.0298, 0.0838], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,100][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Stephanie] are: tensor([0.0006, 0.0704, 0.3147, 0.0732, 0.1764, 0.0971, 0.0392, 0.0308, 0.0876,
        0.0211, 0.0121, 0.0187, 0.0581], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,101][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Stephanie] are: tensor([5.9848e-06, 2.3825e-02, 3.6304e-01, 6.1907e-02, 3.9698e-02, 8.5727e-02,
        2.9183e-01, 1.6887e-02, 8.0482e-02, 7.1412e-03, 3.3164e-03, 9.4351e-03,
        1.6706e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,102][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Stephanie] are: tensor([0.0006, 0.0235, 0.1569, 0.0611, 0.0682, 0.1374, 0.2000, 0.1013, 0.1068,
        0.0222, 0.0129, 0.0614, 0.0477], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,104][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Stephanie] are: tensor([0.0109, 0.0480, 0.1950, 0.0562, 0.0833, 0.0915, 0.0767, 0.0344, 0.0789,
        0.0523, 0.0409, 0.1637, 0.0682], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,106][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Stephanie] are: tensor([0.0665, 0.1020, 0.0119, 0.0848, 0.0236, 0.0793, 0.0868, 0.0130, 0.0634,
        0.1754, 0.1417, 0.0764, 0.0751], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,108][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Stephanie] are: tensor([0.0468, 0.2235, 0.0008, 0.0524, 0.0022, 0.0205, 0.1583, 0.0471, 0.1185,
        0.1082, 0.1020, 0.1051, 0.0146], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,109][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Stephanie] are: tensor([0.0006, 0.0759, 0.3208, 0.0413, 0.2038, 0.1772, 0.0572, 0.0237, 0.0324,
        0.0121, 0.0056, 0.0089, 0.0405], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,111][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Stephanie] are: tensor([0.1078, 0.0864, 0.4148, 0.0192, 0.0982, 0.0211, 0.0178, 0.0086, 0.0934,
        0.0276, 0.0210, 0.0345, 0.0494], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,113][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Stephanie] are: tensor([0.0031, 0.1806, 0.0664, 0.2471, 0.0748, 0.0400, 0.0856, 0.0287, 0.0414,
        0.0850, 0.0444, 0.0449, 0.0582], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,115][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Stephanie] are: tensor([0.0592, 0.3950, 0.0008, 0.0288, 0.0034, 0.0153, 0.1348, 0.0177, 0.1917,
        0.0371, 0.0411, 0.0574, 0.0177], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,116][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Stephanie] are: tensor([6.7441e-04, 1.9157e-05, 2.9067e-01, 2.8298e-05, 2.0643e-01, 1.5098e-04,
        6.9549e-04, 2.4494e-03, 1.2791e-01, 7.2993e-05, 1.3231e-03, 2.0462e-03,
        3.6753e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,118][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Stephanie] are: tensor([0.0237, 0.1216, 0.1068, 0.0254, 0.1605, 0.0608, 0.0816, 0.0749, 0.1671,
        0.0140, 0.0152, 0.0373, 0.1111], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,119][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([5.5588e-05, 3.7371e-02, 4.9736e-01, 2.4971e-02, 2.3950e-01, 4.9396e-02,
        2.0426e-02, 1.4880e-02, 3.8260e-02, 5.8288e-03, 2.6933e-03, 4.7405e-03,
        5.5589e-02, 8.9314e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,120][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([1.4572e-06, 2.5494e-02, 4.1246e-01, 4.4053e-02, 4.8886e-02, 6.6415e-02,
        2.2663e-01, 4.9142e-02, 7.1950e-02, 4.5052e-03, 2.0106e-03, 8.6206e-03,
        2.2946e-02, 1.6888e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,121][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([2.1979e-04, 2.1687e-02, 2.4315e-01, 4.1657e-02, 9.6524e-02, 1.0401e-01,
        2.1082e-01, 8.6461e-02, 8.7824e-02, 1.1081e-02, 6.0036e-03, 2.1504e-02,
        4.2719e-02, 2.6339e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,123][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0035, 0.0410, 0.2476, 0.0608, 0.0981, 0.0602, 0.0613, 0.0571, 0.0784,
        0.0384, 0.0240, 0.1276, 0.0702, 0.0317], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,125][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0234, 0.1228, 0.0128, 0.1026, 0.0171, 0.0662, 0.0559, 0.0070, 0.0399,
        0.1740, 0.1400, 0.0870, 0.0431, 0.1082], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,126][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([1.9039e-02, 7.8441e-01, 3.2147e-04, 1.0499e-01, 1.1801e-03, 9.3287e-03,
        3.6595e-03, 5.9745e-04, 7.6473e-04, 1.4676e-02, 3.9126e-02, 1.4547e-03,
        9.3763e-04, 1.9517e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,127][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([1.3595e-04, 4.8820e-02, 5.6122e-01, 2.1974e-02, 1.2209e-01, 9.6227e-02,
        3.7630e-02, 1.9703e-02, 2.5054e-02, 8.0779e-03, 3.5657e-03, 3.4959e-03,
        3.9618e-02, 1.2387e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,128][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0102, 0.0624, 0.5610, 0.0236, 0.0683, 0.0300, 0.0262, 0.0229, 0.0647,
        0.0337, 0.0180, 0.0102, 0.0322, 0.0367], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,129][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0007, 0.1080, 0.1403, 0.2246, 0.0596, 0.0319, 0.1235, 0.0340, 0.0386,
        0.0813, 0.0249, 0.0332, 0.0481, 0.0512], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,130][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([2.6393e-03, 9.6670e-01, 9.3056e-05, 1.8055e-02, 5.1064e-04, 1.8138e-03,
        5.8094e-04, 9.5206e-05, 1.6087e-04, 9.7784e-04, 2.8738e-03, 1.3030e-04,
        2.1524e-04, 5.1555e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,131][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([5.5504e-05, 1.0671e-05, 2.6859e-01, 8.7254e-06, 1.8539e-01, 7.6319e-05,
        2.5402e-04, 3.7935e-03, 2.2110e-01, 1.5300e-05, 2.4980e-04, 3.9111e-04,
        3.1957e-01, 5.0107e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,133][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0018, 0.0909, 0.1029, 0.0387, 0.1278, 0.0745, 0.1462, 0.0808, 0.1660,
        0.0172, 0.0106, 0.0158, 0.0737, 0.0532], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,134][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([2.0978e-04, 5.9181e-02, 5.6258e-01, 3.1042e-02, 1.8904e-01, 3.3638e-02,
        1.2654e-02, 1.2760e-02, 2.8422e-02, 6.3057e-03, 4.1086e-03, 9.2410e-03,
        3.3708e-02, 9.1918e-03, 7.9211e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,135][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.1096e-05, 3.1718e-02, 4.7329e-01, 5.4327e-02, 5.6251e-02, 6.6387e-02,
        1.6569e-01, 2.6083e-02, 4.9906e-02, 5.4863e-03, 2.7839e-03, 6.3941e-03,
        1.6028e-02, 1.8399e-02, 2.7245e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,137][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0022, 0.0268, 0.2674, 0.0409, 0.1535, 0.1015, 0.1112, 0.0494, 0.0572,
        0.0169, 0.0135, 0.0323, 0.0562, 0.0382, 0.0329], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,139][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0365, 0.0552, 0.2449, 0.0592, 0.0942, 0.0517, 0.0319, 0.0369, 0.0549,
        0.0437, 0.0362, 0.1494, 0.0508, 0.0356, 0.0190], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,140][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1817, 0.0645, 0.0191, 0.0418, 0.0214, 0.0392, 0.0287, 0.0058, 0.0519,
        0.1117, 0.0969, 0.0706, 0.0400, 0.1202, 0.1065], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,142][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.5476, 0.1658, 0.0011, 0.0409, 0.0025, 0.0096, 0.0058, 0.0033, 0.0059,
        0.0366, 0.0878, 0.0116, 0.0048, 0.0683, 0.0087], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,143][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([2.9144e-04, 6.8862e-02, 5.3903e-01, 2.2662e-02, 1.4400e-01, 1.0382e-01,
        2.2489e-02, 1.1502e-02, 1.5399e-02, 6.1745e-03, 3.0716e-03, 4.3984e-03,
        3.4836e-02, 9.4815e-03, 1.3979e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,145][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0727, 0.0727, 0.3652, 0.0247, 0.0993, 0.0253, 0.0203, 0.0143, 0.0774,
        0.0411, 0.0286, 0.0232, 0.0526, 0.0457, 0.0369], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,147][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0070, 0.1322, 0.2212, 0.1313, 0.0852, 0.0357, 0.0533, 0.0269, 0.0378,
        0.0643, 0.0261, 0.0557, 0.0412, 0.0357, 0.0462], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,149][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1635, 0.6679, 0.0011, 0.0251, 0.0043, 0.0051, 0.0029, 0.0013, 0.0059,
        0.0111, 0.0240, 0.0059, 0.0080, 0.0689, 0.0049], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,150][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([3.3499e-04, 1.9445e-05, 3.9341e-01, 1.6915e-05, 2.5905e-01, 8.7857e-05,
        2.0398e-04, 1.7561e-03, 1.0232e-01, 2.3708e-05, 4.3902e-04, 3.9182e-04,
        2.4134e-01, 5.6424e-04, 4.4539e-05], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,152][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0262, 0.1772, 0.1716, 0.0269, 0.1324, 0.0355, 0.0359, 0.0461, 0.1057,
        0.0169, 0.0176, 0.0250, 0.0894, 0.0590, 0.0348], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,155][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:25:44,157][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[21512],
        [ 8933],
        [ 4136],
        [ 3309],
        [ 1500],
        [  870],
        [ 1109],
        [  704],
        [ 1078],
        [  313],
        [  239],
        [  802],
        [  341],
        [  382],
        [  163]], device='cuda:0')
[2024-07-24 10:25:44,159][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[16082],
        [13927],
        [ 5615],
        [ 8382],
        [ 5071],
        [ 3810],
        [ 5939],
        [ 4592],
        [ 5707],
        [ 2831],
        [ 1943],
        [ 4671],
        [ 2568],
        [ 3698],
        [ 1486]], device='cuda:0')
[2024-07-24 10:25:44,160][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[10065],
        [  742],
        [    6],
        [    9],
        [   20],
        [   12],
        [   12],
        [   41],
        [   29],
        [   38],
        [   47],
        [   86],
        [   57],
        [   51],
        [   73]], device='cuda:0')
[2024-07-24 10:25:44,162][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[20631],
        [ 6447],
        [40271],
        [36650],
        [35681],
        [27020],
        [22735],
        [23589],
        [18343],
        [19068],
        [17936],
        [18608],
        [18340],
        [16518],
        [16263]], device='cuda:0')
[2024-07-24 10:25:44,164][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[13376],
        [ 4017],
        [49094],
        [37163],
        [30920],
        [26041],
        [ 6169],
        [ 6038],
        [ 6208],
        [ 7448],
        [ 6836],
        [ 6815],
        [ 8095],
        [ 7291],
        [15532]], device='cuda:0')
[2024-07-24 10:25:44,165][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[22579],
        [22716],
        [23691],
        [28082],
        [25073],
        [25690],
        [29432],
        [30220],
        [31415],
        [31501],
        [31085],
        [32293],
        [29180],
        [28696],
        [28489]], device='cuda:0')
[2024-07-24 10:25:44,167][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[1744],
        [1839],
        [1906],
        [1001],
        [ 993],
        [2031],
        [1402],
        [1345],
        [1487],
        [1283],
        [1334],
        [1215],
        [1314],
        [1289],
        [1607]], device='cuda:0')
[2024-07-24 10:25:44,169][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[25889],
        [ 3715],
        [ 4342],
        [ 4910],
        [ 6257],
        [ 4756],
        [ 5163],
        [ 5304],
        [ 5756],
        [ 6108],
        [ 6243],
        [ 5834],
        [ 6550],
        [ 6135],
        [ 6497]], device='cuda:0')
[2024-07-24 10:25:44,171][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[33657],
        [12662],
        [49798],
        [49252],
        [47690],
        [45705],
        [43042],
        [42889],
        [41590],
        [45037],
        [43036],
        [43568],
        [41291],
        [44505],
        [43113]], device='cuda:0')
[2024-07-24 10:25:44,172][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[8146],
        [9942],
        [   4],
        [   2],
        [   2],
        [   2],
        [   3],
        [   3],
        [   5],
        [   2],
        [   5],
        [   2],
        [   3],
        [   2],
        [   5]], device='cuda:0')
[2024-07-24 10:25:44,173][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 7409],
        [23046],
        [21468],
        [20892],
        [24325],
        [25341],
        [24204],
        [23845],
        [24372],
        [23456],
        [24119],
        [23960],
        [25341],
        [25446],
        [24650]], device='cuda:0')
[2024-07-24 10:25:44,175][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[10782],
        [17170],
        [13586],
        [17598],
        [15842],
        [15792],
        [17452],
        [17429],
        [17713],
        [17758],
        [17616],
        [17740],
        [16807],
        [17784],
        [17124]], device='cuda:0')
[2024-07-24 10:25:44,176][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[32197],
        [36777],
        [35054],
        [23078],
        [21074],
        [21534],
        [23529],
        [23394],
        [23311],
        [23328],
        [23080],
        [22360],
        [22219],
        [22140],
        [22628]], device='cuda:0')
[2024-07-24 10:25:44,178][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 6581],
        [15591],
        [15482],
        [15517],
        [15738],
        [14386],
        [12849],
        [12110],
        [ 9256],
        [12077],
        [11900],
        [11551],
        [12355],
        [11690],
        [13345]], device='cuda:0')
[2024-07-24 10:25:44,179][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[19430],
        [17342],
        [21243],
        [12926],
        [17152],
        [ 8526],
        [ 8990],
        [ 8995],
        [ 3827],
        [ 7970],
        [ 5709],
        [ 6033],
        [ 7389],
        [ 1586],
        [ 1845]], device='cuda:0')
[2024-07-24 10:25:44,181][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[19577],
        [22792],
        [21130],
        [21247],
        [22432],
        [21778],
        [21559],
        [20983],
        [21480],
        [21042],
        [20604],
        [20192],
        [20438],
        [21495],
        [21444]], device='cuda:0')
[2024-07-24 10:25:44,183][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[27756],
        [12717],
        [24277],
        [24625],
        [25136],
        [26661],
        [25350],
        [25640],
        [24875],
        [26739],
        [26967],
        [26454],
        [26148],
        [27258],
        [26765]], device='cuda:0')
[2024-07-24 10:25:44,184][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[37748],
        [22059],
        [ 8090],
        [ 8451],
        [10066],
        [11227],
        [13180],
        [12388],
        [13835],
        [13023],
        [13388],
        [12685],
        [12421],
        [11771],
        [11035]], device='cuda:0')
[2024-07-24 10:25:44,186][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[25832],
        [33475],
        [ 9635],
        [ 8697],
        [ 9320],
        [ 8271],
        [ 7881],
        [ 8815],
        [ 9561],
        [ 8726],
        [ 9260],
        [ 8242],
        [ 7653],
        [ 8015],
        [ 7477]], device='cuda:0')
[2024-07-24 10:25:44,188][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[29418],
        [23973],
        [20934],
        [22608],
        [24493],
        [19583],
        [19587],
        [18559],
        [16816],
        [14689],
        [14700],
        [15381],
        [15664],
        [16435],
        [14825]], device='cuda:0')
[2024-07-24 10:25:44,189][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[17078],
        [27830],
        [26632],
        [25296],
        [24063],
        [25947],
        [27042],
        [26964],
        [27126],
        [26436],
        [27723],
        [27807],
        [26594],
        [27460],
        [30014]], device='cuda:0')
[2024-07-24 10:25:44,191][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[5185],
        [2316],
        [1978],
        [1939],
        [3123],
        [2165],
        [1918],
        [2032],
        [2016],
        [2108],
        [2343],
        [2370],
        [2713],
        [2533],
        [2458]], device='cuda:0')
[2024-07-24 10:25:44,193][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[18614],
        [15498],
        [26146],
        [30884],
        [33581],
        [33567],
        [34962],
        [33885],
        [35225],
        [36546],
        [40818],
        [36131],
        [38255],
        [36066],
        [40078]], device='cuda:0')
[2024-07-24 10:25:44,194][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[8280],
        [5187],
        [7682],
        [6106],
        [5681],
        [6167],
        [6411],
        [6036],
        [5944],
        [6318],
        [6712],
        [7067],
        [6643],
        [7028],
        [7716]], device='cuda:0')
[2024-07-24 10:25:44,196][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[42956],
        [33530],
        [36533],
        [33246],
        [33039],
        [33490],
        [33428],
        [33314],
        [33205],
        [33016],
        [32404],
        [32649],
        [26054],
        [33207],
        [31752]], device='cuda:0')
[2024-07-24 10:25:44,198][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[40590],
        [40548],
        [16397],
        [16258],
        [25177],
        [25501],
        [25384],
        [26487],
        [30355],
        [26424],
        [28662],
        [27283],
        [29225],
        [29989],
        [27982]], device='cuda:0')
[2024-07-24 10:25:44,199][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[15581],
        [13963],
        [18721],
        [19981],
        [ 7660],
        [11485],
        [11600],
        [ 9130],
        [ 7232],
        [ 9394],
        [ 8708],
        [ 6959],
        [ 6615],
        [ 7775],
        [ 8561]], device='cuda:0')
[2024-07-24 10:25:44,201][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 4797],
        [ 8043],
        [13494],
        [14302],
        [14075],
        [13251],
        [12355],
        [13847],
        [12961],
        [14149],
        [12258],
        [15161],
        [15684],
        [14076],
        [12377]], device='cuda:0')
[2024-07-24 10:25:44,203][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[16091],
        [14073],
        [18452],
        [26778],
        [22204],
        [31634],
        [30662],
        [30555],
        [36998],
        [28630],
        [32382],
        [27747],
        [28367],
        [39084],
        [39481]], device='cuda:0')
[2024-07-24 10:25:44,204][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[10252],
        [10252],
        [10252],
        [10252],
        [10252],
        [10252],
        [10252],
        [10252],
        [10252],
        [10252],
        [10252],
        [10252],
        [10252],
        [10252],
        [10252]], device='cuda:0')
[2024-07-24 10:25:44,330][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:44,331][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:44,332][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:44,334][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:44,335][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:44,335][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:44,336][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:44,337][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:44,337][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:44,338][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:44,339][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:44,339][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:44,340][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:44,341][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3150, 0.6850], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:44,342][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.8446, 0.1554], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:44,342][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.8508, 0.1492], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:44,344][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9935, 0.0065], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:44,345][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0118, 0.9882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:44,347][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1319, 0.8681], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:44,349][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2558, 0.7442], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:44,350][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0186, 0.9814], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:44,352][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0269, 0.9731], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:44,353][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9605, 0.0395], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:44,355][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9244, 0.0756], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:44,356][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.9325, 0.0675], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:44,358][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Jose] are: tensor([0.7145, 0.1631, 0.1224], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:44,359][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Jose] are: tensor([0.9484, 0.0386, 0.0131], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:44,360][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Jose] are: tensor([0.9666, 0.0312, 0.0022], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:44,360][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Jose] are: tensor([0.9445, 0.0082, 0.0473], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:44,361][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Jose] are: tensor([0.0450, 0.3692, 0.5859], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:44,362][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Jose] are: tensor([0.1560, 0.8178, 0.0262], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:44,363][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Jose] are: tensor([0.6955, 0.2320, 0.0725], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:44,365][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Jose] are: tensor([0.0089, 0.9262, 0.0650], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:44,366][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Jose] are: tensor([0.0853, 0.6909, 0.2238], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:44,368][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Jose] are: tensor([0.9319, 0.0564, 0.0117], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:44,369][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Jose] are: tensor([9.9908e-01, 8.7016e-04, 5.2971e-05], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:44,370][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Jose] are: tensor([0.7614, 0.0254, 0.2132], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:44,372][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.4490, 0.1435, 0.0915, 0.3159], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:44,374][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.8001, 0.1136, 0.0188, 0.0675], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:44,375][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3797, 0.5402, 0.0532, 0.0269], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:44,377][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.9335, 0.0084, 0.0416, 0.0165], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:44,379][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0221, 0.4927, 0.2422, 0.2430], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:44,380][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0384, 0.7972, 0.0314, 0.1331], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:44,382][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2707, 0.6292, 0.0371, 0.0630], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:44,383][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0011, 0.3527, 0.0271, 0.6191], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:44,385][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0118, 0.0188, 0.0078, 0.9616], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:44,386][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4184, 0.0958, 0.4602, 0.0256], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:44,387][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([9.9911e-01, 6.7834e-04, 6.3076e-05, 1.5250e-04], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:44,389][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4703, 0.0385, 0.4000, 0.0911], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:44,391][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Stephanie] are: tensor([0.4625, 0.1584, 0.0969, 0.2455, 0.0366], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:44,392][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Stephanie] are: tensor([0.8926, 0.0626, 0.0036, 0.0395, 0.0018], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:44,394][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Stephanie] are: tensor([0.9139, 0.0632, 0.0105, 0.0079, 0.0046], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:44,395][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Stephanie] are: tensor([9.8745e-01, 6.9916e-04, 2.7311e-03, 2.5409e-03, 6.5757e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:44,397][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Stephanie] are: tensor([0.0248, 0.1191, 0.4033, 0.0385, 0.4143], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:44,398][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Stephanie] are: tensor([0.1195, 0.5351, 0.0404, 0.0755, 0.2296], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:44,400][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Stephanie] are: tensor([0.4741, 0.3741, 0.0440, 0.0783, 0.0296], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:44,401][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Stephanie] are: tensor([0.0046, 0.6298, 0.0279, 0.2809, 0.0567], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:44,402][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Stephanie] are: tensor([0.0019, 0.0456, 0.0084, 0.9207, 0.0234], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:44,403][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Stephanie] are: tensor([0.6048, 0.2125, 0.0485, 0.0317, 0.1025], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:44,404][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Stephanie] are: tensor([9.9986e-01, 7.8996e-05, 1.1299e-05, 1.2104e-05, 3.6311e-05],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:44,404][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Stephanie] are: tensor([0.2771, 0.0019, 0.1152, 0.0027, 0.6031], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:44,405][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.4144, 0.0449, 0.2074, 0.1317, 0.0686, 0.1331], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:44,407][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.6123, 0.1790, 0.0366, 0.1064, 0.0242, 0.0414], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:44,408][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.3546, 0.4422, 0.1330, 0.0331, 0.0266, 0.0104], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:44,410][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.8978, 0.0069, 0.0144, 0.0239, 0.0395, 0.0176], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:44,411][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0183, 0.1372, 0.5015, 0.1757, 0.0972, 0.0701], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:44,413][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0226, 0.4274, 0.1418, 0.1648, 0.1942, 0.0492], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:44,414][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2385, 0.5238, 0.1299, 0.0808, 0.0177, 0.0093], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:44,416][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0014, 0.3498, 0.0179, 0.5227, 0.0477, 0.0605], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:44,417][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0152, 0.0050, 0.0021, 0.7240, 0.0160, 0.2377], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:44,419][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0057, 0.0746, 0.2233, 0.0242, 0.6283, 0.0439], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:44,420][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ had] are: tensor([9.9790e-01, 6.3566e-04, 3.3459e-04, 2.3545e-04, 5.0593e-04, 3.9133e-04],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:44,422][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0864, 0.0031, 0.2203, 0.0151, 0.6602, 0.0149], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:44,423][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2144, 0.1060, 0.0397, 0.1447, 0.0103, 0.1057, 0.3791],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,425][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.6644, 0.1658, 0.0372, 0.0734, 0.0183, 0.0281, 0.0130],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,427][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2554, 0.5362, 0.1074, 0.0410, 0.0378, 0.0171, 0.0051],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,428][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([9.9440e-01, 9.1277e-04, 1.1455e-04, 2.4076e-03, 2.5404e-04, 1.1234e-03,
        7.8534e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,429][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0149, 0.1541, 0.3886, 0.1929, 0.0962, 0.0706, 0.0827],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,431][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0168, 0.5024, 0.1604, 0.1955, 0.0759, 0.0248, 0.0242],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,433][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1984, 0.6178, 0.0521, 0.1002, 0.0177, 0.0083, 0.0055],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,434][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0011, 0.1041, 0.0097, 0.2369, 0.0228, 0.0161, 0.6094],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,435][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([3.8333e-02, 1.9877e-03, 2.0456e-04, 1.5222e-01, 9.5306e-04, 8.0168e-02,
        7.2614e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,437][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0239, 0.1529, 0.2615, 0.0399, 0.4784, 0.0407, 0.0026],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,438][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([9.9960e-01, 2.9461e-04, 8.6992e-06, 4.0653e-05, 2.0770e-05, 2.0487e-05,
        1.9159e-05], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,440][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.5801, 0.0079, 0.0742, 0.0147, 0.2355, 0.0141, 0.0736],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,442][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0307, 0.0477, 0.0418, 0.1168, 0.0150, 0.0723, 0.4056, 0.2701],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,443][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.8967, 0.0605, 0.0060, 0.0200, 0.0036, 0.0054, 0.0051, 0.0027],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,444][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ long] are: tensor([2.3485e-01, 6.8718e-01, 3.5047e-02, 2.4306e-02, 8.1764e-03, 7.1906e-03,
        2.7897e-03, 4.6544e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,445][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ long] are: tensor([9.5978e-01, 2.1875e-03, 1.1881e-04, 6.8070e-03, 2.2445e-04, 3.0342e-03,
        1.9639e-02, 8.2051e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,447][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0366, 0.4287, 0.2338, 0.1531, 0.0421, 0.0280, 0.0529, 0.0249],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,449][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0180, 0.5317, 0.0336, 0.1808, 0.0339, 0.0403, 0.0465, 0.1152],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,450][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ long] are: tensor([1.0580e-02, 9.1209e-01, 9.7125e-03, 5.8961e-02, 2.7862e-03, 3.6954e-03,
        2.0186e-03, 1.5803e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,451][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ long] are: tensor([6.4495e-04, 1.2298e-01, 5.0187e-03, 1.4198e-01, 9.1766e-03, 1.2458e-02,
        6.5993e-01, 4.7815e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,451][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ long] are: tensor([8.8738e-04, 1.5701e-04, 2.9791e-05, 2.4265e-02, 1.4833e-04, 1.5427e-02,
        4.2834e-01, 5.3075e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,452][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0108, 0.2096, 0.2349, 0.1116, 0.2725, 0.1090, 0.0076, 0.0440],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,453][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ long] are: tensor([9.9812e-01, 7.2252e-04, 5.6304e-05, 1.6013e-04, 5.1002e-05, 1.8685e-04,
        3.6155e-04, 3.3701e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,455][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.2455, 0.0022, 0.0071, 0.0069, 0.0292, 0.0085, 0.1188, 0.5818],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,456][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0598, 0.0405, 0.0463, 0.0809, 0.0177, 0.0913, 0.3420, 0.1643, 0.1572],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,458][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.6104, 0.1831, 0.0326, 0.0649, 0.0232, 0.0325, 0.0281, 0.0086, 0.0166],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,459][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([6.0950e-01, 3.2373e-01, 2.6805e-02, 1.5523e-02, 1.5258e-02, 6.7209e-03,
        1.3034e-03, 4.4428e-04, 7.1563e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,460][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([9.0986e-01, 2.7466e-03, 1.9786e-04, 8.7944e-03, 5.5794e-04, 9.1329e-03,
        1.6241e-02, 2.5293e-02, 2.7173e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,462][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0129, 0.2056, 0.2602, 0.1201, 0.1368, 0.0663, 0.0841, 0.0319, 0.0821],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,464][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0138, 0.5711, 0.0283, 0.1500, 0.0604, 0.0351, 0.0302, 0.0764, 0.0346],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,465][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([4.2411e-02, 9.1576e-01, 1.0680e-02, 2.3007e-02, 2.3693e-03, 2.9662e-03,
        2.6194e-03, 1.1645e-04, 6.7304e-05], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,466][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0008, 0.2180, 0.0039, 0.1847, 0.0141, 0.0176, 0.4390, 0.0590, 0.0629],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,468][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([1.5653e-03, 2.1492e-04, 6.0489e-05, 1.5991e-02, 1.4361e-04, 1.4252e-02,
        3.4877e-01, 4.8720e-01, 1.3180e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,469][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0290, 0.2930, 0.0582, 0.0998, 0.2960, 0.0982, 0.0050, 0.0377, 0.0830],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,470][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([9.9098e-01, 1.9476e-03, 1.3597e-04, 3.2863e-04, 4.9710e-04, 3.1776e-04,
        2.6234e-04, 6.0565e-04, 4.9204e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,472][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0374, 0.0008, 0.0099, 0.0034, 0.0503, 0.0046, 0.0554, 0.5331, 0.3052],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,474][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0758, 0.0543, 0.0702, 0.0967, 0.0404, 0.0739, 0.2493, 0.1839, 0.0645,
        0.0910], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,475][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1789, 0.1682, 0.0167, 0.1820, 0.0132, 0.1892, 0.0598, 0.0205, 0.0391,
        0.1324], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,477][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0408, 0.6621, 0.0935, 0.0750, 0.0318, 0.0595, 0.0112, 0.0028, 0.0065,
        0.0168], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,478][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([9.7370e-01, 2.6746e-03, 7.5462e-04, 2.8809e-03, 1.9445e-03, 2.1353e-03,
        2.0414e-03, 2.2212e-03, 8.5247e-03, 3.1267e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,480][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0082, 0.2872, 0.1655, 0.2625, 0.0259, 0.0600, 0.0894, 0.0232, 0.0257,
        0.0524], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,482][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0201, 0.4415, 0.0813, 0.1332, 0.0838, 0.0442, 0.0239, 0.0558, 0.0420,
        0.0743], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,483][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([3.5466e-03, 9.0403e-01, 1.9809e-02, 3.9332e-02, 3.6398e-03, 9.9908e-03,
        5.4010e-03, 5.6676e-04, 6.5924e-04, 1.3030e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,485][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0094, 0.2625, 0.0132, 0.3175, 0.0147, 0.0097, 0.2709, 0.0336, 0.0381,
        0.0303], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,486][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([4.7929e-04, 1.4850e-04, 3.8798e-05, 4.9681e-02, 3.0570e-04, 1.8603e-02,
        1.2850e-01, 3.0996e-01, 3.1854e-02, 4.6042e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,487][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0045, 0.0800, 0.3119, 0.0273, 0.4594, 0.0419, 0.0034, 0.0054, 0.0603,
        0.0059], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,489][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([9.9081e-01, 1.9147e-03, 3.9419e-04, 8.0306e-04, 4.4865e-04, 4.6109e-04,
        1.1362e-04, 2.4055e-04, 1.4813e-03, 3.3357e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,490][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.4480, 0.0034, 0.0330, 0.0027, 0.1469, 0.0095, 0.0114, 0.1609, 0.1473,
        0.0369], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,491][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2390, 0.0961, 0.0514, 0.0658, 0.0396, 0.0383, 0.1124, 0.1624, 0.0574,
        0.0659, 0.0715], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,492][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.5722, 0.1073, 0.0044, 0.0461, 0.0045, 0.0166, 0.0294, 0.0064, 0.0065,
        0.0539, 0.1525], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,493][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0155, 0.8305, 0.0394, 0.0490, 0.0139, 0.0192, 0.0066, 0.0011, 0.0016,
        0.0119, 0.0114], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,494][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.9344, 0.0064, 0.0026, 0.0022, 0.0056, 0.0034, 0.0052, 0.0096, 0.0229,
        0.0056, 0.0021], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,495][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0107, 0.1885, 0.1420, 0.2735, 0.0363, 0.0432, 0.1047, 0.0285, 0.0418,
        0.0496, 0.0811], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,497][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0824, 0.3597, 0.0575, 0.0919, 0.1009, 0.0317, 0.0289, 0.0754, 0.0660,
        0.0553, 0.0503], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,498][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([6.5343e-03, 9.3466e-01, 5.6614e-03, 2.4582e-02, 1.7488e-03, 4.2689e-03,
        2.4675e-03, 3.0422e-04, 2.2363e-04, 8.8544e-03, 1.0698e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,500][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0292, 0.2862, 0.0190, 0.2358, 0.0191, 0.0083, 0.2592, 0.0440, 0.0417,
        0.0295, 0.0279], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,501][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([1.1583e-04, 1.0935e-04, 9.2573e-05, 1.8992e-02, 8.9280e-04, 2.7850e-02,
        1.3614e-01, 5.8443e-01, 4.5805e-02, 1.5612e-01, 2.9449e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,503][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0277, 0.0586, 0.2021, 0.0179, 0.5247, 0.0334, 0.0054, 0.0123, 0.0992,
        0.0082, 0.0106], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,504][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([9.7340e-01, 3.2045e-03, 1.5420e-03, 8.0460e-04, 1.1068e-03, 4.5961e-04,
        1.1723e-04, 9.0426e-04, 2.1933e-03, 2.3447e-03, 1.3927e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,506][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.6305, 0.0026, 0.0407, 0.0009, 0.0872, 0.0054, 0.0062, 0.0878, 0.1154,
        0.0099, 0.0133], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,507][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0407, 0.0629, 0.0374, 0.0674, 0.0118, 0.0341, 0.2122, 0.1726, 0.0831,
        0.1404, 0.0896, 0.0479], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,509][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.7427, 0.0687, 0.0062, 0.0206, 0.0021, 0.0045, 0.0084, 0.0033, 0.0068,
        0.0217, 0.0584, 0.0564], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,511][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.2523, 0.6433, 0.0212, 0.0265, 0.0118, 0.0095, 0.0055, 0.0023, 0.0014,
        0.0116, 0.0105, 0.0041], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,512][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([7.4616e-01, 4.1465e-03, 3.8172e-04, 4.5881e-03, 1.2346e-03, 1.3810e-02,
        2.5232e-02, 2.7719e-02, 1.3515e-01, 2.1094e-02, 1.0706e-02, 9.7773e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,514][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0188, 0.1277, 0.2652, 0.0827, 0.0679, 0.0220, 0.0783, 0.0332, 0.0598,
        0.0181, 0.0214, 0.2050], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,515][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0647, 0.3243, 0.0125, 0.0489, 0.0201, 0.0184, 0.0420, 0.0580, 0.0217,
        0.0827, 0.0671, 0.2396], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,517][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([7.6389e-03, 8.5426e-01, 3.1163e-03, 6.6956e-02, 1.5144e-03, 3.9795e-03,
        5.5754e-03, 2.7775e-04, 1.1291e-04, 2.9142e-02, 2.5765e-02, 1.6588e-03],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,518][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0104, 0.3239, 0.0051, 0.1100, 0.0062, 0.0098, 0.3276, 0.0608, 0.0511,
        0.0536, 0.0160, 0.0255], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,520][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([5.5012e-05, 7.1592e-05, 1.4439e-05, 6.0919e-03, 1.0878e-04, 6.2024e-03,
        1.2101e-01, 5.4410e-01, 8.4709e-02, 8.9116e-02, 2.1371e-02, 1.2715e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,521][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0073, 0.2417, 0.1033, 0.0548, 0.3006, 0.0487, 0.0120, 0.0332, 0.1272,
        0.0169, 0.0119, 0.0423], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,522][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([9.7528e-01, 3.9088e-03, 2.1294e-04, 3.5978e-04, 3.7379e-04, 2.1936e-04,
        1.8889e-04, 5.7021e-04, 5.0531e-03, 2.2091e-03, 1.0830e-02, 7.9387e-04],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,524][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0338, 0.0007, 0.0078, 0.0012, 0.0284, 0.0024, 0.0261, 0.3307, 0.4703,
        0.0256, 0.0380, 0.0351], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,526][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Stephanie] are: tensor([0.0892, 0.1087, 0.0565, 0.1044, 0.0179, 0.0470, 0.2016, 0.0921, 0.0437,
        0.0936, 0.0694, 0.0266, 0.0492], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,528][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Stephanie] are: tensor([0.7536, 0.0748, 0.0014, 0.0409, 0.0009, 0.0023, 0.0012, 0.0015, 0.0012,
        0.0229, 0.0919, 0.0061, 0.0012], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,529][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Stephanie] are: tensor([0.7740, 0.1414, 0.0257, 0.0195, 0.0110, 0.0057, 0.0010, 0.0011, 0.0013,
        0.0064, 0.0075, 0.0013, 0.0040], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,531][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Stephanie] are: tensor([8.7308e-01, 1.1606e-03, 2.9596e-04, 4.7739e-04, 9.3015e-04, 5.0432e-03,
        7.5361e-03, 1.8495e-02, 7.7079e-02, 7.7432e-03, 2.2946e-03, 3.2930e-03,
        2.5757e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,532][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Stephanie] are: tensor([0.0208, 0.2105, 0.2763, 0.0713, 0.1597, 0.0173, 0.0502, 0.0102, 0.0477,
        0.0111, 0.0123, 0.0726, 0.0402], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,533][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Stephanie] are: tensor([0.0537, 0.3357, 0.0206, 0.0587, 0.1147, 0.0303, 0.0448, 0.0301, 0.0304,
        0.0366, 0.0201, 0.1779, 0.0463], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,534][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Stephanie] are: tensor([0.0610, 0.7431, 0.0323, 0.0696, 0.0175, 0.0041, 0.0017, 0.0013, 0.0009,
        0.0232, 0.0297, 0.0126, 0.0029], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,535][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Stephanie] are: tensor([0.0311, 0.5951, 0.0140, 0.0914, 0.0175, 0.0065, 0.1494, 0.0174, 0.0361,
        0.0179, 0.0091, 0.0093, 0.0052], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,536][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Stephanie] are: tensor([5.1986e-07, 8.4291e-05, 1.2484e-05, 5.7102e-03, 6.0501e-05, 7.6160e-03,
        1.0520e-01, 7.3048e-01, 6.6677e-02, 3.1585e-02, 3.1018e-03, 4.9377e-02,
        9.4411e-05], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,537][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Stephanie] are: tensor([0.0320, 0.4185, 0.0548, 0.1169, 0.1416, 0.0717, 0.0159, 0.0066, 0.0574,
        0.0247, 0.0170, 0.0111, 0.0317], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,539][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Stephanie] are: tensor([9.8586e-01, 1.4347e-03, 1.7793e-04, 1.1303e-04, 5.5367e-04, 1.3934e-04,
        1.0701e-04, 5.8034e-04, 3.0338e-03, 8.1704e-04, 3.7825e-03, 1.1568e-03,
        2.2454e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,540][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Stephanie] are: tensor([1.9748e-01, 2.7826e-04, 1.4809e-02, 2.6169e-04, 7.4425e-02, 2.1807e-03,
        1.3132e-02, 9.6211e-02, 4.9337e-01, 4.0170e-03, 8.6816e-03, 3.7453e-02,
        5.7694e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,541][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0423, 0.0687, 0.0332, 0.0526, 0.0150, 0.0273, 0.1086, 0.0465, 0.0267,
        0.0651, 0.0396, 0.0178, 0.0494, 0.4073], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,543][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.6004, 0.2251, 0.0052, 0.0520, 0.0019, 0.0051, 0.0026, 0.0017, 0.0042,
        0.0101, 0.0448, 0.0277, 0.0016, 0.0177], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,545][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0109, 0.7897, 0.0706, 0.0618, 0.0193, 0.0171, 0.0032, 0.0009, 0.0009,
        0.0056, 0.0053, 0.0017, 0.0021, 0.0107], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,546][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ said] are: tensor([6.6679e-01, 7.3244e-03, 6.2320e-04, 1.0446e-02, 3.4001e-03, 1.6745e-02,
        1.3399e-02, 4.7389e-03, 1.3137e-02, 1.4981e-02, 8.7543e-03, 1.0215e-03,
        4.8531e-03, 2.3378e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,548][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0024, 0.0765, 0.3303, 0.1358, 0.0684, 0.0328, 0.0698, 0.0210, 0.0568,
        0.0135, 0.0174, 0.0514, 0.0327, 0.0913], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,549][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0021, 0.1245, 0.0536, 0.0864, 0.1602, 0.0244, 0.0214, 0.0592, 0.0796,
        0.0254, 0.0145, 0.2627, 0.0644, 0.0214], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,551][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ said] are: tensor([2.3085e-03, 9.3591e-01, 1.3333e-02, 3.8771e-02, 1.5461e-03, 2.8874e-03,
        7.4687e-04, 7.8545e-05, 4.1830e-05, 1.2748e-03, 1.8397e-03, 2.6711e-04,
        3.8282e-05, 9.6072e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,553][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0020, 0.1813, 0.0048, 0.2393, 0.0222, 0.0111, 0.3719, 0.0393, 0.0645,
        0.0256, 0.0131, 0.0071, 0.0078, 0.0101], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,554][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ said] are: tensor([1.3002e-04, 8.8253e-04, 8.5573e-05, 5.7878e-02, 4.4383e-04, 3.1772e-02,
        9.2109e-02, 2.2968e-01, 2.1517e-02, 2.8778e-01, 6.2334e-02, 5.0176e-02,
        1.5805e-04, 1.6506e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,555][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0023, 0.0765, 0.1060, 0.0387, 0.4323, 0.0582, 0.0069, 0.0098, 0.1176,
        0.0076, 0.0053, 0.0166, 0.0930, 0.0291], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,557][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.7068, 0.0091, 0.0128, 0.0054, 0.0077, 0.0053, 0.0017, 0.0046, 0.0192,
        0.0202, 0.0649, 0.0044, 0.0314, 0.1064], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,559][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.3117, 0.0021, 0.0237, 0.0025, 0.1350, 0.0124, 0.0229, 0.0771, 0.1264,
        0.0290, 0.0372, 0.0152, 0.0924, 0.1125], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,561][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1875, 0.0560, 0.0173, 0.0497, 0.0117, 0.0301, 0.0966, 0.0825, 0.0149,
        0.0674, 0.0427, 0.0094, 0.0376, 0.1860, 0.1105], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,563][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0961, 0.3062, 0.0187, 0.0995, 0.0077, 0.0327, 0.0326, 0.0047, 0.0128,
        0.0482, 0.1131, 0.1079, 0.0069, 0.0831, 0.0298], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,564][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0135, 0.7795, 0.0416, 0.0703, 0.0160, 0.0185, 0.0059, 0.0009, 0.0013,
        0.0084, 0.0128, 0.0028, 0.0036, 0.0177, 0.0071], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,566][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([9.6894e-01, 2.4042e-03, 4.7049e-04, 1.2286e-03, 9.9284e-04, 2.4365e-03,
        3.7281e-04, 9.1561e-04, 3.9455e-03, 5.3601e-04, 3.7985e-04, 2.9551e-04,
        5.5698e-04, 1.6332e-02, 1.9452e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,567][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0220, 0.1252, 0.2808, 0.1962, 0.0521, 0.0483, 0.0387, 0.0087, 0.0166,
        0.0176, 0.0332, 0.0382, 0.0129, 0.0767, 0.0329], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,569][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0512, 0.4070, 0.0804, 0.1027, 0.0471, 0.0139, 0.0120, 0.0174, 0.0122,
        0.0408, 0.0334, 0.1427, 0.0163, 0.0095, 0.0135], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,570][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([1.0017e-03, 9.0453e-01, 8.8057e-03, 3.9837e-02, 1.4241e-03, 4.6766e-03,
        3.8213e-03, 2.7804e-04, 1.7969e-04, 1.2407e-02, 1.0067e-02, 1.1855e-03,
        2.6456e-04, 3.7247e-03, 7.7937e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,572][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0170, 0.3288, 0.0107, 0.2620, 0.0072, 0.0093, 0.1660, 0.0281, 0.0687,
        0.0282, 0.0298, 0.0089, 0.0020, 0.0101, 0.0232], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,573][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([4.8822e-03, 3.6227e-04, 3.7649e-05, 3.2081e-02, 3.0984e-04, 1.6450e-02,
        6.4447e-02, 2.5922e-01, 2.3395e-02, 2.9848e-01, 1.2516e-01, 4.9678e-02,
        3.2834e-04, 1.0054e-01, 2.4624e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,575][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0383, 0.0902, 0.2773, 0.0147, 0.4892, 0.0103, 0.0009, 0.0016, 0.0271,
        0.0017, 0.0022, 0.0128, 0.0280, 0.0047, 0.0009], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,576][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([9.8957e-01, 4.1787e-04, 6.2558e-05, 1.5326e-04, 7.6791e-05, 6.2162e-05,
        1.3988e-05, 4.2849e-05, 2.5838e-04, 5.9474e-04, 4.6925e-03, 1.1366e-04,
        9.5429e-04, 2.7045e-03, 2.8572e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,576][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([7.5714e-01, 4.0685e-03, 3.1601e-02, 1.7925e-03, 3.9205e-02, 3.0576e-03,
        1.9213e-03, 4.8423e-02, 4.3205e-02, 1.1311e-02, 1.6956e-02, 9.0877e-03,
        1.1290e-02, 2.0593e-02, 3.4862e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,702][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:44,703][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:44,703][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:44,704][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:44,705][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:44,706][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:44,707][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:44,707][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:44,708][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:44,709][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:44,709][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:44,710][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:44,711][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:44,711][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3150, 0.6850], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:44,712][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.6980, 0.3020], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:44,713][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1975, 0.8025], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:44,714][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9908, 0.0092], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:44,714][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0118, 0.9882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:44,716][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1319, 0.8681], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:44,717][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.5771, 0.4229], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:44,719][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0661, 0.9339], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:44,720][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9250, 0.0750], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:44,722][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9605, 0.0395], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:44,723][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9244, 0.0756], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:44,725][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9325, 0.0675], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:44,726][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Jose] are: tensor([0.7145, 0.1631, 0.1224], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:44,728][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Jose] are: tensor([0.8684, 0.0915, 0.0401], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:44,730][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Jose] are: tensor([0.5361, 0.4014, 0.0625], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:44,731][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Jose] are: tensor([0.9176, 0.0112, 0.0713], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:44,733][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Jose] are: tensor([0.0450, 0.3692, 0.5859], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:44,734][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Jose] are: tensor([0.1560, 0.8178, 0.0262], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:44,736][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Jose] are: tensor([0.5788, 0.1847, 0.2365], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:44,738][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Jose] are: tensor([0.2510, 0.6734, 0.0756], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:44,739][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Jose] are: tensor([0.0872, 0.0941, 0.8186], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:44,741][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Jose] are: tensor([0.9319, 0.0564, 0.0117], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:44,742][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Jose] are: tensor([9.9908e-01, 8.7016e-04, 5.2971e-05], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:44,743][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Jose] are: tensor([0.7614, 0.0254, 0.2132], device='cuda:0') for source tokens [Then, Jose]
[2024-07-24 10:25:44,745][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.4490, 0.1435, 0.0915, 0.3159], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:44,747][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.5649, 0.2476, 0.1486, 0.0389], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:44,748][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0188, 0.6047, 0.1706, 0.2059], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:44,750][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.9182, 0.0101, 0.0561, 0.0156], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:44,751][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0221, 0.4927, 0.2422, 0.2430], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:44,753][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0384, 0.7972, 0.0314, 0.1331], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:44,753][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1190, 0.5572, 0.2800, 0.0437], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:44,754][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0227, 0.7716, 0.0857, 0.1200], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:44,755][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9469, 0.0026, 0.0233, 0.0272], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:44,756][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4184, 0.0958, 0.4602, 0.0256], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:44,757][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([9.9911e-01, 6.7834e-04, 6.3076e-05, 1.5250e-04], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:44,758][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4703, 0.0385, 0.4000, 0.0911], device='cuda:0') for source tokens [Then, Jose and]
[2024-07-24 10:25:44,760][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Stephanie] are: tensor([0.4625, 0.1584, 0.0969, 0.2455, 0.0366], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:44,762][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Stephanie] are: tensor([0.8560, 0.0298, 0.0049, 0.0012, 0.1082], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:44,763][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Stephanie] are: tensor([0.3380, 0.2671, 0.0636, 0.0685, 0.2628], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:44,765][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Stephanie] are: tensor([0.9837, 0.0011, 0.0050, 0.0027, 0.0075], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:44,767][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Stephanie] are: tensor([0.0248, 0.1191, 0.4033, 0.0385, 0.4143], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:44,768][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Stephanie] are: tensor([0.1195, 0.5351, 0.0404, 0.0755, 0.2296], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:44,770][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Stephanie] are: tensor([0.0861, 0.2751, 0.4231, 0.0208, 0.1949], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:44,772][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Stephanie] are: tensor([0.3968, 0.4834, 0.0445, 0.0178, 0.0575], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:44,773][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Stephanie] are: tensor([0.0467, 0.0158, 0.2704, 0.2365, 0.4305], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:44,775][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Stephanie] are: tensor([0.6048, 0.2125, 0.0485, 0.0317, 0.1025], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:44,776][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Stephanie] are: tensor([9.9986e-01, 7.8996e-05, 1.1299e-05, 1.2104e-05, 3.6311e-05],
       device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:44,778][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Stephanie] are: tensor([0.2771, 0.0019, 0.1152, 0.0027, 0.6031], device='cuda:0') for source tokens [Then, Jose and Stephanie]
[2024-07-24 10:25:44,779][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.4144, 0.0449, 0.2074, 0.1317, 0.0686, 0.1331], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:44,781][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0842, 0.0217, 0.0811, 0.0055, 0.7921, 0.0154], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:44,783][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0050, 0.0351, 0.1268, 0.0288, 0.7728, 0.0314], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:44,784][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.9136, 0.0070, 0.0170, 0.0207, 0.0274, 0.0143], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:44,786][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0183, 0.1372, 0.5015, 0.1757, 0.0972, 0.0701], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:44,788][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0226, 0.4274, 0.1418, 0.1648, 0.1942, 0.0492], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:44,789][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0150, 0.2875, 0.4364, 0.0422, 0.1989, 0.0200], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:44,791][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0350, 0.5196, 0.0705, 0.1257, 0.1672, 0.0820], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:44,793][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.4333, 0.0036, 0.0231, 0.2032, 0.3042, 0.0326], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:44,794][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0057, 0.0746, 0.2233, 0.0242, 0.6283, 0.0439], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:44,795][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([9.9790e-01, 6.3566e-04, 3.3459e-04, 2.3545e-04, 5.0593e-04, 3.9133e-04],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:44,796][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0864, 0.0031, 0.2203, 0.0151, 0.6602, 0.0149], device='cuda:0') for source tokens [Then, Jose and Stephanie had]
[2024-07-24 10:25:44,797][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2144, 0.1060, 0.0397, 0.1447, 0.0103, 0.1057, 0.3791],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,797][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0879, 0.0377, 0.0308, 0.0058, 0.8172, 0.0175, 0.0032],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,799][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0013, 0.2002, 0.1015, 0.1063, 0.4570, 0.1139, 0.0198],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,800][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([9.9606e-01, 7.8853e-04, 1.0290e-04, 1.6462e-03, 1.5238e-04, 7.0518e-04,
        5.4678e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,802][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0149, 0.1541, 0.3886, 0.1929, 0.0962, 0.0706, 0.0827],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,803][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0168, 0.5024, 0.1604, 0.1955, 0.0759, 0.0248, 0.0242],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,805][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0147, 0.4187, 0.3241, 0.0413, 0.1631, 0.0278, 0.0105],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,807][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0257, 0.2491, 0.0753, 0.0949, 0.1387, 0.0342, 0.3820],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,808][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.7744, 0.0018, 0.0065, 0.0575, 0.0720, 0.0144, 0.0734],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,810][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0239, 0.1529, 0.2615, 0.0399, 0.4784, 0.0407, 0.0026],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,811][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([9.9960e-01, 2.9461e-04, 8.6992e-06, 4.0653e-05, 2.0770e-05, 2.0487e-05,
        1.9159e-05], device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,812][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.5801, 0.0079, 0.0742, 0.0147, 0.2355, 0.0141, 0.0736],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a]
[2024-07-24 10:25:44,814][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0307, 0.0477, 0.0418, 0.1168, 0.0150, 0.0723, 0.4056, 0.2701],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,816][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.3547, 0.0879, 0.0312, 0.0203, 0.4306, 0.0417, 0.0132, 0.0204],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,817][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0094, 0.3426, 0.0764, 0.1122, 0.2807, 0.1207, 0.0405, 0.0174],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,819][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([9.5244e-01, 2.8236e-03, 1.6960e-04, 6.5305e-03, 1.8991e-04, 2.7796e-03,
        2.0188e-02, 1.4877e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,820][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0366, 0.4287, 0.2338, 0.1531, 0.0421, 0.0280, 0.0529, 0.0249],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,822][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0180, 0.5317, 0.0336, 0.1808, 0.0339, 0.0403, 0.0465, 0.1152],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,824][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0179, 0.6550, 0.1517, 0.0734, 0.0492, 0.0301, 0.0121, 0.0107],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,825][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0390, 0.2752, 0.0460, 0.0538, 0.0494, 0.0207, 0.4423, 0.0737],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,827][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.5126, 0.0008, 0.0019, 0.0287, 0.0063, 0.0027, 0.0313, 0.4158],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,829][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0108, 0.2096, 0.2349, 0.1116, 0.2725, 0.1090, 0.0076, 0.0440],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,830][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([9.9812e-01, 7.2252e-04, 5.6304e-05, 1.6013e-04, 5.1002e-05, 1.8685e-04,
        3.6155e-04, 3.3701e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,831][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.2455, 0.0022, 0.0071, 0.0069, 0.0292, 0.0085, 0.1188, 0.5818],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long]
[2024-07-24 10:25:44,833][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0598, 0.0405, 0.0463, 0.0809, 0.0177, 0.0913, 0.3420, 0.1643, 0.1572],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,835][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.2681, 0.2447, 0.0185, 0.0136, 0.3911, 0.0360, 0.0039, 0.0096, 0.0146],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,837][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0032, 0.2417, 0.0783, 0.0838, 0.4844, 0.0622, 0.0121, 0.0117, 0.0227],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,837][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([8.8067e-01, 3.6794e-03, 2.8140e-04, 9.0086e-03, 4.8266e-04, 9.0659e-03,
        1.4775e-02, 4.6551e-02, 3.5491e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,838][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0129, 0.2056, 0.2602, 0.1201, 0.1368, 0.0663, 0.0841, 0.0319, 0.0821],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,839][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0138, 0.5711, 0.0283, 0.1500, 0.0604, 0.0351, 0.0302, 0.0764, 0.0346],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,841][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0321, 0.5839, 0.1528, 0.0402, 0.0884, 0.0444, 0.0083, 0.0080, 0.0419],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,842][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0180, 0.3266, 0.0261, 0.0597, 0.0677, 0.0267, 0.1922, 0.0567, 0.2263],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,843][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([1.3807e-01, 3.2806e-04, 1.6504e-03, 1.2693e-02, 4.9798e-03, 3.7391e-03,
        1.8930e-02, 6.1012e-01, 2.0949e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,845][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0290, 0.2930, 0.0582, 0.0998, 0.2960, 0.0982, 0.0050, 0.0377, 0.0830],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,846][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([9.9098e-01, 1.9476e-03, 1.3597e-04, 3.2863e-04, 4.9710e-04, 3.1776e-04,
        2.6234e-04, 6.0565e-04, 4.9204e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,848][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0374, 0.0008, 0.0099, 0.0034, 0.0503, 0.0046, 0.0554, 0.5331, 0.3052],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument]
[2024-07-24 10:25:44,850][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0758, 0.0543, 0.0702, 0.0967, 0.0404, 0.0739, 0.2493, 0.1839, 0.0645,
        0.0910], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,851][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0933, 0.0424, 0.0353, 0.0050, 0.7967, 0.0120, 0.0017, 0.0019, 0.0082,
        0.0034], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,853][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0008, 0.3111, 0.0814, 0.0893, 0.4168, 0.0590, 0.0089, 0.0028, 0.0155,
        0.0145], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,855][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9627, 0.0046, 0.0013, 0.0034, 0.0024, 0.0023, 0.0024, 0.0044, 0.0123,
        0.0042], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,856][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0082, 0.2872, 0.1655, 0.2625, 0.0259, 0.0600, 0.0894, 0.0232, 0.0257,
        0.0524], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,858][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0201, 0.4415, 0.0813, 0.1332, 0.0838, 0.0442, 0.0239, 0.0558, 0.0420,
        0.0743], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,860][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0025, 0.6672, 0.2048, 0.0482, 0.0451, 0.0084, 0.0027, 0.0031, 0.0110,
        0.0069], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,861][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0870, 0.3505, 0.0525, 0.0853, 0.0684, 0.0308, 0.1509, 0.0378, 0.1008,
        0.0361], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,863][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([5.4657e-01, 6.1815e-05, 1.7912e-04, 2.6776e-03, 4.9871e-03, 1.4464e-03,
        3.8774e-03, 2.2308e-01, 9.4673e-02, 1.2244e-01], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,864][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0045, 0.0800, 0.3119, 0.0273, 0.4594, 0.0419, 0.0034, 0.0054, 0.0603,
        0.0059], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,865][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([9.9081e-01, 1.9147e-03, 3.9419e-04, 8.0306e-04, 4.4865e-04, 4.6109e-04,
        1.1362e-04, 2.4055e-04, 1.4813e-03, 3.3357e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,867][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.4480, 0.0034, 0.0330, 0.0027, 0.1469, 0.0095, 0.0114, 0.1609, 0.1473,
        0.0369], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument,]
[2024-07-24 10:25:44,869][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2390, 0.0961, 0.0514, 0.0658, 0.0396, 0.0383, 0.1124, 0.1624, 0.0574,
        0.0659, 0.0715], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,870][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.4630, 0.0486, 0.0205, 0.0033, 0.4292, 0.0087, 0.0018, 0.0026, 0.0096,
        0.0045, 0.0082], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,872][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0045, 0.4740, 0.0771, 0.0868, 0.2282, 0.0487, 0.0096, 0.0044, 0.0198,
        0.0190, 0.0280], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,874][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.8901, 0.0116, 0.0045, 0.0028, 0.0077, 0.0041, 0.0068, 0.0214, 0.0391,
        0.0087, 0.0032], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,876][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0107, 0.1885, 0.1420, 0.2735, 0.0363, 0.0432, 0.1047, 0.0285, 0.0418,
        0.0496, 0.0811], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,877][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0824, 0.3597, 0.0575, 0.0919, 0.1009, 0.0317, 0.0289, 0.0754, 0.0660,
        0.0553, 0.0503], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,878][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0068, 0.6570, 0.1875, 0.0441, 0.0502, 0.0057, 0.0032, 0.0047, 0.0176,
        0.0077, 0.0155], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,879][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4858, 0.1743, 0.0274, 0.0253, 0.0410, 0.0100, 0.0681, 0.0277, 0.0552,
        0.0252, 0.0600], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,880][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1641, 0.0006, 0.0010, 0.0042, 0.0094, 0.0054, 0.0085, 0.3288, 0.1994,
        0.2522, 0.0265], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,881][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0277, 0.0586, 0.2021, 0.0179, 0.5247, 0.0334, 0.0054, 0.0123, 0.0992,
        0.0082, 0.0106], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,882][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([9.7340e-01, 3.2045e-03, 1.5420e-03, 8.0460e-04, 1.1068e-03, 4.5961e-04,
        1.1723e-04, 9.0426e-04, 2.1933e-03, 2.3447e-03, 1.3927e-02],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,883][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.6305, 0.0026, 0.0407, 0.0009, 0.0872, 0.0054, 0.0062, 0.0878, 0.1154,
        0.0099, 0.0133], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and]
[2024-07-24 10:25:44,885][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0407, 0.0629, 0.0374, 0.0674, 0.0118, 0.0341, 0.2122, 0.1726, 0.0831,
        0.1404, 0.0896, 0.0479], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,887][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.6094, 0.1149, 0.0081, 0.0038, 0.0989, 0.0114, 0.0028, 0.0051, 0.0099,
        0.0064, 0.0103, 0.1190], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,888][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0023, 0.2795, 0.0823, 0.0670, 0.3270, 0.0775, 0.0176, 0.0072, 0.0480,
        0.0208, 0.0210, 0.0499], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,890][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.6034, 0.0061, 0.0006, 0.0050, 0.0012, 0.0169, 0.0333, 0.0570, 0.2122,
        0.0326, 0.0157, 0.0160], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,891][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0188, 0.1277, 0.2652, 0.0827, 0.0679, 0.0220, 0.0783, 0.0332, 0.0598,
        0.0181, 0.0214, 0.2050], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,893][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0647, 0.3243, 0.0125, 0.0489, 0.0201, 0.0184, 0.0420, 0.0580, 0.0217,
        0.0827, 0.0671, 0.2396], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,895][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0077, 0.5494, 0.2637, 0.0254, 0.0730, 0.0086, 0.0039, 0.0030, 0.0247,
        0.0038, 0.0054, 0.0313], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,896][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.2967, 0.2684, 0.0149, 0.0155, 0.0123, 0.0058, 0.0703, 0.0367, 0.1103,
        0.0372, 0.0287, 0.1033], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,898][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([1.3703e-01, 1.2986e-04, 5.8462e-04, 3.8291e-03, 1.5700e-03, 1.9185e-03,
        1.7064e-02, 2.8735e-01, 1.5382e-01, 9.3343e-02, 3.6023e-02, 2.6733e-01],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,899][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0073, 0.2417, 0.1033, 0.0548, 0.3006, 0.0487, 0.0120, 0.0332, 0.1272,
        0.0169, 0.0119, 0.0423], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,901][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([9.7528e-01, 3.9088e-03, 2.1294e-04, 3.5978e-04, 3.7379e-04, 2.1936e-04,
        1.8889e-04, 5.7021e-04, 5.0531e-03, 2.2091e-03, 1.0830e-02, 7.9387e-04],
       device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,902][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0338, 0.0007, 0.0078, 0.0012, 0.0284, 0.0024, 0.0261, 0.3307, 0.4703,
        0.0256, 0.0380, 0.0351], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards]
[2024-07-24 10:25:44,904][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Stephanie] are: tensor([0.0892, 0.1087, 0.0565, 0.1044, 0.0179, 0.0470, 0.2016, 0.0921, 0.0437,
        0.0936, 0.0694, 0.0266, 0.0492], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,905][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Stephanie] are: tensor([8.3161e-01, 3.6920e-02, 2.8442e-03, 9.3456e-04, 4.2096e-02, 3.6761e-03,
        4.5714e-04, 3.8021e-04, 2.2304e-03, 1.6652e-03, 3.2144e-03, 3.0668e-02,
        4.3302e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,907][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Stephanie] are: tensor([0.0695, 0.2983, 0.0864, 0.0706, 0.2052, 0.0752, 0.0119, 0.0033, 0.0355,
        0.0215, 0.0308, 0.0228, 0.0690], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,908][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Stephanie] are: tensor([7.8255e-01, 2.1568e-03, 5.5756e-04, 5.4332e-04, 1.0652e-03, 6.4070e-03,
        9.5957e-03, 4.0833e-02, 1.3309e-01, 1.1132e-02, 3.2567e-03, 5.3435e-03,
        3.4649e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,910][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Stephanie] are: tensor([0.0208, 0.2105, 0.2763, 0.0713, 0.1597, 0.0173, 0.0502, 0.0102, 0.0477,
        0.0111, 0.0123, 0.0726, 0.0402], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,912][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Stephanie] are: tensor([0.0537, 0.3357, 0.0206, 0.0587, 0.1147, 0.0303, 0.0448, 0.0301, 0.0304,
        0.0366, 0.0201, 0.1779, 0.0463], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,914][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Stephanie] are: tensor([0.0086, 0.5586, 0.3079, 0.0193, 0.0557, 0.0068, 0.0021, 0.0007, 0.0230,
        0.0018, 0.0032, 0.0075, 0.0048], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,915][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Stephanie] are: tensor([0.7174, 0.1825, 0.0097, 0.0037, 0.0102, 0.0016, 0.0143, 0.0036, 0.0206,
        0.0057, 0.0067, 0.0115, 0.0125], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,917][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Stephanie] are: tensor([0.0030, 0.0037, 0.0124, 0.0601, 0.0067, 0.0234, 0.0627, 0.3698, 0.2304,
        0.1240, 0.0283, 0.0700, 0.0055], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,919][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Stephanie] are: tensor([0.0320, 0.4185, 0.0548, 0.1169, 0.1416, 0.0717, 0.0159, 0.0066, 0.0574,
        0.0247, 0.0170, 0.0111, 0.0317], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,920][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Stephanie] are: tensor([9.8586e-01, 1.4347e-03, 1.7793e-04, 1.1303e-04, 5.5367e-04, 1.3934e-04,
        1.0701e-04, 5.8034e-04, 3.0338e-03, 8.1704e-04, 3.7825e-03, 1.1568e-03,
        2.2454e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,921][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Stephanie] are: tensor([1.9748e-01, 2.7826e-04, 1.4809e-02, 2.6169e-04, 7.4425e-02, 2.1807e-03,
        1.3132e-02, 9.6211e-02, 4.9337e-01, 4.0170e-03, 8.6816e-03, 3.7453e-02,
        5.7694e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie]
[2024-07-24 10:25:44,922][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0423, 0.0687, 0.0332, 0.0526, 0.0150, 0.0273, 0.1086, 0.0465, 0.0267,
        0.0651, 0.0396, 0.0178, 0.0494, 0.4073], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,923][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0248, 0.0355, 0.0161, 0.0036, 0.4230, 0.0097, 0.0013, 0.0014, 0.0069,
        0.0018, 0.0026, 0.0932, 0.3382, 0.0418], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,924][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([4.1151e-04, 3.5874e-02, 1.0297e-01, 1.8864e-02, 5.7080e-01, 2.5124e-02,
        2.9335e-03, 2.8505e-03, 1.1136e-02, 3.9468e-03, 3.8281e-03, 1.4107e-02,
        1.5014e-01, 5.7020e-02], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,925][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.6650, 0.0102, 0.0008, 0.0096, 0.0029, 0.0154, 0.0127, 0.0070, 0.0146,
        0.0178, 0.0096, 0.0012, 0.0046, 0.2285], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,927][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0024, 0.0765, 0.3303, 0.1358, 0.0684, 0.0328, 0.0698, 0.0210, 0.0568,
        0.0135, 0.0174, 0.0514, 0.0327, 0.0913], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,929][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0021, 0.1245, 0.0536, 0.0864, 0.1602, 0.0244, 0.0214, 0.0592, 0.0796,
        0.0254, 0.0145, 0.2627, 0.0644, 0.0214], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,930][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0017, 0.1936, 0.2567, 0.0297, 0.2620, 0.0106, 0.0075, 0.0060, 0.0819,
        0.0060, 0.0075, 0.0297, 0.0756, 0.0315], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,932][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0201, 0.2313, 0.0177, 0.0527, 0.0767, 0.0236, 0.1169, 0.0415, 0.1944,
        0.0195, 0.0224, 0.0295, 0.0521, 0.1015], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,934][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0163, 0.0035, 0.0032, 0.0563, 0.0142, 0.0081, 0.0102, 0.2806, 0.1597,
        0.2338, 0.0484, 0.0884, 0.0102, 0.0672], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,936][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0023, 0.0765, 0.1060, 0.0387, 0.4323, 0.0582, 0.0069, 0.0098, 0.1176,
        0.0076, 0.0053, 0.0166, 0.0930, 0.0291], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,937][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.7068, 0.0091, 0.0128, 0.0054, 0.0077, 0.0053, 0.0017, 0.0046, 0.0192,
        0.0202, 0.0649, 0.0044, 0.0314, 0.1064], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,939][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.3117, 0.0021, 0.0237, 0.0025, 0.1350, 0.0124, 0.0229, 0.0771, 0.1264,
        0.0290, 0.0372, 0.0152, 0.0924, 0.1125], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said]
[2024-07-24 10:25:44,941][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1875, 0.0560, 0.0173, 0.0497, 0.0117, 0.0301, 0.0966, 0.0825, 0.0149,
        0.0674, 0.0427, 0.0094, 0.0376, 0.1860, 0.1105], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,943][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.2041, 0.0785, 0.0231, 0.0037, 0.4779, 0.0055, 0.0005, 0.0008, 0.0023,
        0.0022, 0.0055, 0.0354, 0.1392, 0.0195, 0.0016], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,945][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0042, 0.2950, 0.0810, 0.0584, 0.3062, 0.0428, 0.0040, 0.0017, 0.0117,
        0.0087, 0.0165, 0.0176, 0.0633, 0.0741, 0.0149], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,946][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([9.6486e-01, 3.4892e-03, 6.8032e-04, 1.2345e-03, 1.0447e-03, 2.1520e-03,
        3.4494e-04, 1.5304e-03, 4.6326e-03, 5.7416e-04, 3.8436e-04, 3.5639e-04,
        5.7495e-04, 1.7984e-02, 1.5689e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,948][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0220, 0.1252, 0.2808, 0.1962, 0.0521, 0.0483, 0.0387, 0.0087, 0.0166,
        0.0176, 0.0332, 0.0382, 0.0129, 0.0767, 0.0329], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,949][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0512, 0.4070, 0.0804, 0.1027, 0.0471, 0.0139, 0.0120, 0.0174, 0.0122,
        0.0408, 0.0334, 0.1427, 0.0163, 0.0095, 0.0135], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,951][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0103, 0.4398, 0.3016, 0.0301, 0.1085, 0.0074, 0.0019, 0.0029, 0.0202,
        0.0049, 0.0092, 0.0153, 0.0199, 0.0214, 0.0067], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,953][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.3021, 0.3094, 0.0323, 0.0367, 0.0230, 0.0099, 0.0329, 0.0150, 0.0628,
        0.0181, 0.0457, 0.0275, 0.0138, 0.0590, 0.0118], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,954][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([4.6817e-01, 7.6325e-05, 5.5731e-04, 1.8697e-03, 4.9356e-03, 9.0193e-04,
        4.8898e-03, 9.4248e-02, 5.5992e-02, 2.8987e-02, 3.3687e-02, 1.5915e-01,
        2.5578e-02, 1.1256e-01, 8.4005e-03], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,956][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0383, 0.0902, 0.2773, 0.0147, 0.4892, 0.0103, 0.0009, 0.0016, 0.0271,
        0.0017, 0.0022, 0.0128, 0.0280, 0.0047, 0.0009], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,957][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([9.8957e-01, 4.1787e-04, 6.2558e-05, 1.5326e-04, 7.6791e-05, 6.2162e-05,
        1.3988e-05, 4.2849e-05, 2.5838e-04, 5.9474e-04, 4.6925e-03, 1.1366e-04,
        9.5429e-04, 2.7045e-03, 2.8572e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,958][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([7.5714e-01, 4.0685e-03, 3.1601e-02, 1.7925e-03, 3.9205e-02, 3.0576e-03,
        1.9213e-03, 4.8423e-02, 4.3205e-02, 1.1311e-02, 1.6956e-02, 9.0877e-03,
        1.1290e-02, 2.0593e-02, 3.4862e-04], device='cuda:0') for source tokens [Then, Jose and Stephanie had a long argument, and afterwards Stephanie said to]
[2024-07-24 10:25:44,962][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:25:44,963][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[26227],
        [ 2765],
        [ 2220],
        [  226],
        [  489],
        [   32],
        [    6],
        [   14],
        [   24],
        [    4],
        [    3],
        [   41],
        [   23],
        [    9],
        [    1]], device='cuda:0')
[2024-07-24 10:25:44,965][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[22029],
        [ 8376],
        [ 5215],
        [  703],
        [  781],
        [  117],
        [   50],
        [   48],
        [   46],
        [   28],
        [   12],
        [   77],
        [   57],
        [   13],
        [   33]], device='cuda:0')
[2024-07-24 10:25:44,966][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[10660],
        [24622],
        [16963],
        [27115],
        [27941],
        [30758],
        [38651],
        [40696],
        [43522],
        [40205],
        [38368],
        [40792],
        [39966],
        [40482],
        [40120]], device='cuda:0')
[2024-07-24 10:25:44,968][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 2789],
        [15008],
        [ 4097],
        [25831],
        [13171],
        [40747],
        [37068],
        [11112],
        [40085],
        [48191],
        [46503],
        [37744],
        [39633],
        [42189],
        [47896]], device='cuda:0')
[2024-07-24 10:25:44,970][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 8444],
        [ 9590],
        [ 7221],
        [10872],
        [ 5840],
        [ 6210],
        [ 8957],
        [13389],
        [10673],
        [11288],
        [14293],
        [14649],
        [ 7376],
        [12553],
        [13957]], device='cuda:0')
[2024-07-24 10:25:44,971][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 8661],
        [10018],
        [29302],
        [30829],
        [12150],
        [36246],
        [10080],
        [22802],
        [37368],
        [18140],
        [32230],
        [46739],
        [42681],
        [47133],
        [20033]], device='cuda:0')
[2024-07-24 10:25:44,973][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[9180],
        [ 106],
        [ 287],
        [  98],
        [1076],
        [ 453],
        [ 378],
        [ 159],
        [ 412],
        [ 224],
        [ 346],
        [ 729],
        [ 525],
        [ 698],
        [ 517]], device='cuda:0')
[2024-07-24 10:25:44,974][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[38155],
        [26551],
        [26255],
        [26840],
        [26170],
        [24261],
        [24770],
        [27384],
        [26935],
        [25054],
        [25128],
        [28253],
        [27753],
        [27413],
        [26773]], device='cuda:0')
[2024-07-24 10:25:44,976][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[23962],
        [13934],
        [ 8503],
        [13390],
        [13587],
        [ 9912],
        [13640],
        [14334],
        [13766],
        [13943],
        [14358],
        [15918],
        [15160],
        [13943],
        [14732]], device='cuda:0')
[2024-07-24 10:25:44,978][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[43009],
        [ 1500],
        [ 1194],
        [ 1187],
        [ 1099],
        [ 1099],
        [  587],
        [  573],
        [  646],
        [  822],
        [  832],
        [  756],
        [  925],
        [  705],
        [  901]], device='cuda:0')
[2024-07-24 10:25:44,980][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 6447],
        [ 7695],
        [16262],
        [ 3955],
        [ 3945],
        [ 4050],
        [ 3703],
        [ 2750],
        [ 2734],
        [ 2301],
        [ 2079],
        [ 2275],
        [ 2136],
        [ 4010],
        [ 3295]], device='cuda:0')
[2024-07-24 10:25:44,981][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[20750],
        [24754],
        [28876],
        [45542],
        [32177],
        [28334],
        [32518],
        [36541],
        [30947],
        [33827],
        [28970],
        [31110],
        [33415],
        [27704],
        [31581]], device='cuda:0')
[2024-07-24 10:25:44,983][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[21018],
        [27271],
        [21078],
        [21081],
        [21012],
        [20899],
        [21044],
        [21228],
        [21305],
        [21446],
        [21249],
        [21822],
        [20526],
        [13754],
        [20896]], device='cuda:0')
[2024-07-24 10:25:44,985][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[19456],
        [23026],
        [39962],
        [39738],
        [31713],
        [33476],
        [29268],
        [22061],
        [21143],
        [24284],
        [24426],
        [19624],
        [19620],
        [23967],
        [24985]], device='cuda:0')
[2024-07-24 10:25:44,987][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[4510],
        [2506],
        [2574],
        [3330],
        [3505],
        [2267],
        [2742],
        [2442],
        [2032],
        [2071],
        [2390],
        [2294],
        [2655],
        [2063],
        [1639]], device='cuda:0')
[2024-07-24 10:25:44,988][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 7599],
        [13990],
        [12332],
        [14190],
        [14003],
        [12227],
        [12984],
        [14062],
        [13663],
        [13832],
        [14076],
        [13946],
        [13627],
        [13035],
        [13292]], device='cuda:0')
[2024-07-24 10:25:44,990][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[11455],
        [17276],
        [14141],
        [18104],
        [15546],
        [14144],
        [14045],
        [15632],
        [17222],
        [14245],
        [14473],
        [18558],
        [15708],
        [13330],
        [14445]], device='cuda:0')
[2024-07-24 10:25:44,992][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[27878],
        [12958],
        [13648],
        [10630],
        [ 9731],
        [ 9524],
        [ 8707],
        [ 8739],
        [ 8990],
        [ 8686],
        [ 9222],
        [ 8914],
        [ 8809],
        [ 9979],
        [ 9534]], device='cuda:0')
[2024-07-24 10:25:44,993][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[11392],
        [11339],
        [ 7252],
        [ 7390],
        [10945],
        [ 7691],
        [11214],
        [ 9183],
        [ 8191],
        [10171],
        [ 8038],
        [ 5594],
        [ 7175],
        [ 4382],
        [ 9701]], device='cuda:0')
[2024-07-24 10:25:44,995][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[10915],
        [ 7231],
        [ 7217],
        [ 8642],
        [ 9582],
        [ 9565],
        [10793],
        [10074],
        [13544],
        [12930],
        [12660],
        [12174],
        [11256],
        [10399],
        [ 9809]], device='cuda:0')
[2024-07-24 10:25:44,997][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[3206],
        [1386],
        [1435],
        [1376],
        [1914],
        [2359],
        [2002],
        [1470],
        [1601],
        [2031],
        [2248],
        [3240],
        [3171],
        [4788],
        [2829]], device='cuda:0')
[2024-07-24 10:25:44,998][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[10082],
        [18263],
        [19896],
        [21387],
        [20841],
        [21188],
        [21829],
        [20295],
        [20155],
        [20908],
        [20701],
        [20742],
        [21478],
        [16557],
        [21207]], device='cuda:0')
[2024-07-24 10:25:45,000][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[8167],
        [5293],
        [5974],
        [6682],
        [6040],
        [7745],
        [9712],
        [9593],
        [8714],
        [8449],
        [7990],
        [8701],
        [6554],
        [8965],
        [7945]], device='cuda:0')
[2024-07-24 10:25:45,002][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[11714],
        [11709],
        [17910],
        [11736],
        [13835],
        [12015],
        [11766],
        [11989],
        [13201],
        [11851],
        [12245],
        [12909],
        [ 8007],
        [ 8965],
        [11934]], device='cuda:0')
[2024-07-24 10:25:45,004][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[6135],
        [6797],
        [6709],
        [3232],
        [5838],
        [8207],
        [7019],
        [4752],
        [5201],
        [6363],
        [7155],
        [5269],
        [4289],
        [6321],
        [7393]], device='cuda:0')
[2024-07-24 10:25:45,005][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 3324],
        [ 3909],
        [ 3325],
        [ 3326],
        [ 3325],
        [ 3322],
        [ 3325],
        [ 3330],
        [ 3365],
        [ 3355],
        [ 3430],
        [ 3447],
        [ 3365],
        [11953],
        [ 3352]], device='cuda:0')
[2024-07-24 10:25:45,006][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[2754],
        [3410],
        [5686],
        [5875],
        [5749],
        [5879],
        [5693],
        [4219],
        [4814],
        [5263],
        [5363],
        [5380],
        [5861],
        [5854],
        [5159]], device='cuda:0')
[2024-07-24 10:25:45,008][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[34601],
        [36420],
        [37983],
        [38031],
        [36137],
        [35528],
        [34478],
        [37054],
        [37289],
        [35708],
        [36101],
        [35797],
        [37322],
        [33720],
        [34644]], device='cuda:0')
[2024-07-24 10:25:45,010][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[35558],
        [35028],
        [35150],
        [32021],
        [31590],
        [33268],
        [33128],
        [34934],
        [39045],
        [34113],
        [36023],
        [37817],
        [34932],
        [36681],
        [37805]], device='cuda:0')
[2024-07-24 10:25:45,011][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[14455],
        [14455],
        [14455],
        [14455],
        [14455],
        [14455],
        [14455],
        [14455],
        [14455],
        [14455],
        [14455],
        [14455],
        [14455],
        [14455],
        [14455]], device='cuda:0')
