[2024-07-24 10:16:34,136][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isAfter Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to
[2024-07-24 10:16:34,136][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Benjamin
[2024-07-24 10:16:34,136][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:16:34,136][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:16:34,137][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:16:34,137][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,137][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:16:34,137][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:16:34,137][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:16:34,137][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit27']
[2024-07-24 10:16:34,137][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:16:34,138][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:16:34,138][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:16:34,138][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,138][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:16:34,138][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,138][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:16:34,138][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,138][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:16:34,139][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,139][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:16:34,139][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,139][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:16:34,139][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit4', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,139][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:16:34,139][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21', 'circuit22', 'circuit27']
[2024-07-24 10:16:34,139][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:16:34,140][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,140][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:16:34,140][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,140][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:16:34,140][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,140][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:16:34,140][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,140][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:16:34,141][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,141][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:16:34,141][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,141][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:16:34,141][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit13', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:16:34,141][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:16:34,141][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit5', 'circuit7', 'circuit11', 'circuit27']
[2024-07-24 10:16:34,142][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:16:34,142][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit27']
[2024-07-24 10:16:34,142][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:16:34,142][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,142][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:16:34,142][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit21']
[2024-07-24 10:16:34,142][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:16:34,142][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,143][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:16:34,143][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,143][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:16:34,143][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,143][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:16:34,143][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit23']
[2024-07-24 10:16:34,143][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:16:34,143][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,144][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:16:34,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,144][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:16:34,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,144][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:16:34,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,144][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,145][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:16:34,145][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,145][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,145][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:16:34,145][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,145][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,145][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:16:34,145][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,146][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,146][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:16:34,146][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,146][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,146][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:16:34,146][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,146][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,147][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:16:34,147][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,147][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,147][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:16:34,147][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,147][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,147][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:16:34,147][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:16:34,148][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,148][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:16:34,148][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,148][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,148][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:16:34,148][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,148][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,148][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:16:34,149][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,149][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,149][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:16:34,149][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,149][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,149][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:16:34,149][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,150][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,150][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:16:34,150][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,150][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,150][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:16:34,150][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,150][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,150][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:16:34,151][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,151][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:16:34,151][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:16:34,151][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,151][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,151][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:16:34,151][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,151][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,152][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:16:34,152][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,152][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,152][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:16:34,152][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:16:34,152][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,152][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:16:34,152][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,153][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,153][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:16:34,153][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:16:34,153][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,153][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:16:34,153][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,153][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,153][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:16:34,154][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:16:34,154][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,154][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:16:34,154][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,154][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,154][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:16:34,154][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,155][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,155][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:16:34,155][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,155][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,155][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:16:34,155][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,155][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,155][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:16:34,156][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,156][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,156][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,156][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:16:34,156][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:34,156][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,156][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,157][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:16:34,157][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,157][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:16:34,157][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit19']
[2024-07-24 10:16:34,157][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:16:34,157][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,157][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:16:34,158][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,158][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:16:34,158][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18']
[2024-07-24 10:16:34,158][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,158][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,158][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:16:34,158][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,158][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,159][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,159][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:16:34,159][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit19']
[2024-07-24 10:16:34,159][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,159][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19']
[2024-07-24 10:16:34,159][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:16:34,159][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,159][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:16:34,160][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,160][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:16:34,160][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,160][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,160][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,160][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:16:34,160][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,161][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,161][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,161][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:16:34,161][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,161][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,161][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,161][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:16:34,161][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,162][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19']
[2024-07-24 10:16:34,162][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,162][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:16:34,162][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,162][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,162][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,162][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:16:34,162][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,163][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,163][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,163][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:16:34,163][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:16:34,163][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,163][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,163][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:16:34,164][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,164][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,164][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,164][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:16:34,164][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,164][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,164][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,164][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:16:34,165][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,165][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,165][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,165][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:16:34,165][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,165][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit25']
[2024-07-24 10:16:34,165][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,165][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:16:34,166][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,166][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,166][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,166][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:16:34,166][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,166][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,166][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,167][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:16:34,167][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,167][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,167][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,167][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:16:34,167][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,167][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,167][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,168][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:16:34,168][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,168][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,168][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,168][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:16:34,168][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,168][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,168][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,169][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:16:34,169][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,169][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,169][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,169][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:16:34,169][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,169][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,170][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,170][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:16:34,170][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,170][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,170][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,170][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:16:34,170][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,170][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,171][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,171][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:16:34,171][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,171][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit6', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,171][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,171][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,171][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:16:34,172][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,172][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,172][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,172][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,172][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:16:34,172][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,172][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,172][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,173][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,173][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:16:34,173][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:16:34,173][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6']
[2024-07-24 10:16:34,173][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit26']
[2024-07-24 10:16:34,173][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,173][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:16:34,174][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,174][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,174][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit26']
[2024-07-24 10:16:34,174][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,174][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:16:34,174][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,174][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,174][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:16:34,175][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit1', 'circuit3', 'circuit13']
[2024-07-24 10:16:34,175][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:16:34,175][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit18', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:16:34,175][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,175][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,175][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,175][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:16:34,175][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,176][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,176][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,176][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,176][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:16:34,176][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,176][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,176][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,177][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,177][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:16:34,177][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,177][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,177][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit20', 'circuit23']
[2024-07-24 10:16:34,177][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:34,177][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:16:34,177][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,178][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,178][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,178][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,178][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:16:34,178][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,178][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,178][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17']
[2024-07-24 10:16:34,178][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,179][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:16:34,179][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,179][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,179][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,179][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,179][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:16:34,179][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,179][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,180][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,180][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:34,180][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:16:34,180][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,180][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,180][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,180][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,180][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:16:34,181][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,181][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,181][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,181][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,181][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:16:34,181][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,181][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,181][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,182][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,182][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:16:34,182][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,182][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,182][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,182][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,182][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:16:34,183][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,183][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,183][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,183][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,183][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:16:34,183][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,183][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,183][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,184][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,184][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:16:34,184][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,184][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,184][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,184][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,184][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:16:34,185][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,185][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,185][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,185][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,185][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:16:34,185][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,185][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,185][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,186][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,186][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:16:34,186][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,186][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,186][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,186][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,186][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:16:34,186][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,187][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,187][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,187][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,187][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:16:34,187][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,187][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,187][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,188][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,188][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:16:34,188][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,188][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,188][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,188][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,188][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:16:34,188][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,189][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,189][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,189][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,189][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:16:34,189][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,189][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,189][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,190][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,190][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:16:34,190][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,190][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,190][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,190][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,190][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,191][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:16:34,191][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,191][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit7', 'circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,191][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,191][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit11', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,191][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,191][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:16:34,191][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit20', 'circuit22']
[2024-07-24 10:16:34,192][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit19']
[2024-07-24 10:16:34,192][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit26']
[2024-07-24 10:16:34,192][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:34,192][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit17', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,192][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:16:34,192][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,192][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,193][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17']
[2024-07-24 10:16:34,193][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit18', 'circuit20']
[2024-07-24 10:16:34,193][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,193][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:16:34,193][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,193][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,193][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit26']
[2024-07-24 10:16:34,193][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,194][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,194][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:16:34,194][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,194][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,194][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,194][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,194][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,195][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:16:34,195][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:16:34,195][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,195][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit24']
[2024-07-24 10:16:34,195][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,195][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit24']
[2024-07-24 10:16:34,195][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:16:34,195][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:16:34,196][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,196][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,196][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,196][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:16:34,196][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:16:34,196][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:16:34,196][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit13']
[2024-07-24 10:16:34,197][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,197][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,197][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,197][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:16:34,197][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16']
[2024-07-24 10:16:34,197][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:16:34,197][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,197][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,198][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,198][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:16:34,198][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22']
[2024-07-24 10:16:34,198][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,198][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,198][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,198][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,198][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:16:34,199][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,199][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,199][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit26']
[2024-07-24 10:16:34,199][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,199][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,199][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:16:34,199][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,200][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15']
[2024-07-24 10:16:34,200][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit26']
[2024-07-24 10:16:34,200][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,200][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:16:34,200][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:16:34,200][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,200][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,200][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,201][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,201][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,201][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:16:34,201][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,201][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,201][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,201][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,201][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,202][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:16:34,202][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,202][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,202][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,202][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,202][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,202][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:16:34,202][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,203][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,203][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,203][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,203][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,203][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:16:34,203][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,203][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,203][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,204][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,204][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,204][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:16:34,204][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,204][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,204][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,204][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,205][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,205][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:16:34,205][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,205][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit5', 'circuit6', 'circuit10']
[2024-07-24 10:16:34,205][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit26']
[2024-07-24 10:16:34,205][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,205][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,205][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:16:34,206][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,206][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,206][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,206][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,206][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,206][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:16:34,206][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,207][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,207][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,207][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,207][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,207][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:16:34,207][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,207][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,207][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,208][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,208][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,208][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:16:34,208][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,208][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,208][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,208][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,208][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,209][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:16:34,209][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,209][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,209][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,209][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,209][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,209][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:16:34,210][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,210][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,210][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,210][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,210][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,210][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:16:34,210][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,210][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,211][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,211][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,211][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,211][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:16:34,211][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,211][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,211][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,212][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,212][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,212][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:16:34,212][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,212][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,212][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,212][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,213][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,213][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:16:34,213][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,213][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,213][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,213][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,213][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,214][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,214][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:16:34,214][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit9', 'circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,214][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit8', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,214][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,214][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,214][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,215][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,215][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:16:34,215][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:16:34,215][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,215][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,215][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,215][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,215][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,216][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:16:34,216][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,216][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit24']
[2024-07-24 10:16:34,216][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,216][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,216][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,216][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit19', 'circuit23', 'circuit26']
[2024-07-24 10:16:34,217][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:16:34,217][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit26']
[2024-07-24 10:16:34,217][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,217][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,217][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,217][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,217][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,217][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:16:34,218][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,218][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,218][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit26']
[2024-07-24 10:16:34,218][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,218][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,218][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,218][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:16:34,219][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,219][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,219][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,219][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,219][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:16:34,219][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:16:34,219][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:16:34,219][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,220][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:16:34,220][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,220][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit26']
[2024-07-24 10:16:34,220][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,220][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit23', 'circuit25']
[2024-07-24 10:16:34,220][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:16:34,220][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,221][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,221][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,221][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,221][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,221][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,221][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:16:34,221][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,221][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,222][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,222][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,222][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,222][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,222][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:16:34,222][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,222][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,223][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,223][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,223][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,223][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,223][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:16:34,223][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,223][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit8', 'circuit10', 'circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,223][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,224][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,224][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,224][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit10', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,224][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:16:34,224][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,224][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,224][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,225][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,225][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,225][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,225][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:16:34,225][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,225][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,225][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,226][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,226][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,226][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,226][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:16:34,226][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,226][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,226][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,226][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,227][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,227][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,227][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:16:34,227][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,227][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,227][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,227][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,227][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,228][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,228][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:16:34,228][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,228][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,228][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,228][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,228][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,229][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,229][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:16:34,229][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,229][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,229][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,229][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,229][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,229][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,229][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:16:34,230][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,230][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,230][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,230][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,230][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,230][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,230][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:16:34,231][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,231][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,231][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,231][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,231][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,231][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,231][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:16:34,232][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,232][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,232][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,232][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,232][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,232][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,232][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:16:34,232][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,233][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,233][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,233][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,233][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,233][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,233][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:16:34,233][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,234][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,234][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,234][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,234][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,234][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,234][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:16:34,234][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,234][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,235][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,235][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,235][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,235][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,235][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:16:34,235][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,235][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,236][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,236][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,236][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,236][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,236][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:16:34,236][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,236][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,236][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,237][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,237][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,237][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,237][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:16:34,237][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,237][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,237][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,238][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,238][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,238][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,238][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:16:34,238][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,238][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,238][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,239][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,239][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,239][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,239][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:16:34,239][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,239][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,239][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,240][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,240][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,240][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,240][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:16:34,240][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,240][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,240][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,240][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,241][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,241][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,241][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,241][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:16:34,241][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,241][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit13']
[2024-07-24 10:16:34,241][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,242][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,242][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,242][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,242][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,242][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:16:34,242][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,242][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,243][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,243][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,243][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,243][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,243][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,243][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:16:34,243][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,243][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,244][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,244][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,244][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,244][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,244][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,244][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:16:34,244][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,245][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,245][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,245][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,245][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit24']
[2024-07-24 10:16:34,245][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:16:34,245][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,245][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:16:34,245][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-24 10:16:34,246][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit13', 'circuit15', 'circuit18']
[2024-07-24 10:16:34,246][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,246][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:34,246][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,246][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit20', 'circuit27']
[2024-07-24 10:16:34,246][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit17']
[2024-07-24 10:16:34,246][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:16:34,247][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,247][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,247][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit6', 'circuit12']
[2024-07-24 10:16:34,247][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,247][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,247][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,247][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,247][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:16:34,248][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,248][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,248][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit26']
[2024-07-24 10:16:34,248][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,248][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,248][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,248][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,249][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:16:34,249][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,249][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit13']
[2024-07-24 10:16:34,249][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,249][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit28']
[2024-07-24 10:16:34,249][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit26']
[2024-07-24 10:16:34,249][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit19', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,249][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,250][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:16:34,250][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit20']
[2024-07-24 10:16:34,250][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,250][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,250][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,250][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,250][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,251][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,251][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:16:34,251][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:16:34,251][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,251][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,251][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,251][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:16:34,251][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,252][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit11', 'circuit13', 'circuit14']
[2024-07-24 10:16:34,252][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:16:34,252][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit7', 'circuit13', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:16:34,252][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6', 'circuit13', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,252][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,252][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21']
[2024-07-24 10:16:34,252][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,252][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:16:34,253][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,253][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:16:34,253][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:16:34,253][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8']
[2024-07-24 10:16:34,253][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,253][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,253][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:16:34,253][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23']
[2024-07-24 10:16:34,254][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,254][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:16:34,254][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,254][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,254][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,254][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,254][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,255][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,255][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,255][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:16:34,255][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,255][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,255][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,255][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,255][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,256][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,256][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,256][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:16:34,256][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,256][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,256][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,256][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,257][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,257][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,257][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,257][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:16:34,257][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,257][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,257][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,257][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,258][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,258][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,258][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,258][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:16:34,258][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,258][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,258][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,259][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,259][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,259][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,259][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,259][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:16:34,259][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,259][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,259][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,260][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,260][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,260][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,260][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,260][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:16:34,260][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,260][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,261][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,261][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,261][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,261][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,261][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,261][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:16:34,261][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,261][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,262][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,262][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,262][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,262][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,262][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,262][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:16:34,262][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,263][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,263][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,263][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,263][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,263][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,263][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,263][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:16:34,263][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,264][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,264][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,264][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,264][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,264][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,264][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,264][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:16:34,265][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,265][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,265][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,265][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,265][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,265][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,265][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,265][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:16:34,266][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,266][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,266][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,266][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,266][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,266][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,266][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,267][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:16:34,267][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,267][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,267][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,267][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,267][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,267][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,268][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,268][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:16:34,268][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,268][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,268][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,268][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,268][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,268][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,269][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,269][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:16:34,269][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,269][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,269][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,269][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,269][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,270][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,270][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,270][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:16:34,270][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,270][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,270][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,270][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,271][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,271][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,271][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,271][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:16:34,271][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,271][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,271][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,272][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,272][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,272][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,272][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,272][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,272][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:16:34,272][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit11', 'circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,273][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,273][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,273][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit14', 'circuit21']
[2024-07-24 10:16:34,273][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit17', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,273][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:16:34,273][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit25']
[2024-07-24 10:16:34,273][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:16:34,273][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:16:34,274][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,274][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit27']
[2024-07-24 10:16:34,274][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:16:34,274][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:16:34,274][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13']
[2024-07-24 10:16:34,274][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,274][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit14']
[2024-07-24 10:16:34,274][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:16:34,275][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:16:34,275][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:16:34,275][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit23']
[2024-07-24 10:16:34,275][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit19', 'circuit23']
[2024-07-24 10:16:34,275][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit19', 'circuit22', 'circuit23']
[2024-07-24 10:16:34,275][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,275][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,275][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,276][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,276][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:16:34,276][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,276][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,276][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,276][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,276][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,277][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,277][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,277][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,277][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:16:34,277][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,277][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,277][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,277][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,278][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,278][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,278][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,278][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,278][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:16:34,278][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,278][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,278][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,279][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,279][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,279][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,279][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,279][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,279][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:16:34,279][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit5', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,280][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,280][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,280][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,280][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,280][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,280][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,280][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,280][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:16:34,281][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,281][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,281][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,281][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,281][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,281][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,281][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,282][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,282][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:16:34,282][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,282][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,282][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,282][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,282][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,283][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,283][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,283][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,283][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:16:34,283][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit26']
[2024-07-24 10:16:34,283][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,283][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,283][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,284][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,284][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,284][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,284][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,284][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:16:34,284][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,284][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,285][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,285][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23']
[2024-07-24 10:16:34,285][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,285][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,285][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,285][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,285][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:16:34,285][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,286][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit8']
[2024-07-24 10:16:34,286][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2']
[2024-07-24 10:16:34,286][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,286][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,286][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,286][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,286][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,286][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:16:34,287][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,287][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,287][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,287][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,287][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,287][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,287][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:16:34,288][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,288][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:16:34,288][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,288][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,288][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,288][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,288][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,289][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,289][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,289][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,289][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:16:34,289][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,289][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,289][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,289][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,290][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,290][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,290][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,290][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,290][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:16:34,290][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,290][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,291][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,291][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,291][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,291][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,291][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,291][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,291][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:16:34,291][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,292][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,292][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,292][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,292][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,292][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,292][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,292][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,292][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:16:34,293][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,293][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,293][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,293][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,293][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,293][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,293][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,294][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,294][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:16:34,294][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,294][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,294][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,294][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,294][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,295][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,295][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,295][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,295][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:16:34,295][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,295][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,295][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,295][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,296][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,296][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,296][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,296][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,296][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:16:34,296][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,296][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,296][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,297][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,297][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,297][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,297][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,297][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,297][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:16:34,297][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,297][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,298][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,298][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,298][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,298][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,298][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,298][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,298][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:16:34,298][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,299][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,299][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,299][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,299][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,299][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,299][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,299][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,299][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:16:34,300][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,300][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,300][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,300][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,300][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,300][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,300][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,301][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,301][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:16:34,301][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,301][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,301][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,301][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,301][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,302][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,302][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,302][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,302][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:16:34,302][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,302][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,302][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,302][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,303][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,303][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,303][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,303][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,303][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:16:34,303][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,303][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,304][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,304][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,304][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,304][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,304][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,304][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,304][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:16:34,305][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,305][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,305][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,305][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,305][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,305][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,305][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,306][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,306][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:16:34,306][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,306][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit10', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,306][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,306][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,306][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,307][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,307][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:16:34,307][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:16:34,307][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,307][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:16:34,307][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,307][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,307][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,308][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,308][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,308][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,308][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,308][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,308][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,308][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:16:34,309][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,309][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,309][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,309][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,309][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,309][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,309][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,309][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,310][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,310][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:16:34,310][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit22', 'circuit23']
[2024-07-24 10:16:34,310][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,310][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit25']
[2024-07-24 10:16:34,310][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit24']
[2024-07-24 10:16:34,310][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit16']
[2024-07-24 10:16:34,311][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,311][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit18', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,311][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,311][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:34,311][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:16:34,311][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit21', 'circuit26']
[2024-07-24 10:16:34,311][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:16:34,311][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit23', 'circuit25']
[2024-07-24 10:16:34,312][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,312][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,312][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:16:34,312][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,312][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,312][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit16', 'circuit21', 'circuit25']
[2024-07-24 10:16:34,312][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:16:34,313][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:16:34,313][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,313][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit23']
[2024-07-24 10:16:34,313][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:34,313][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,313][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,313][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,314][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,314][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,314][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:16:34,314][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,314][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,314][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:16:34,314][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,314][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,315][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,315][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,315][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,315][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,315][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:16:34,315][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit20']
[2024-07-24 10:16:34,315][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,316][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,316][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,316][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,316][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,316][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,316][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,316][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,316][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:16:34,317][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,317][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,317][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,317][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,317][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,317][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,317][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,318][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,318][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,318][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:16:34,318][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17']
[2024-07-24 10:16:34,318][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,318][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,318][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,318][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,319][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,319][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,319][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,319][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,319][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:16:34,319][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,319][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,319][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,320][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,320][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,320][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,320][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,320][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,320][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,320][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:16:34,320][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,321][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,321][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,321][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:34,321][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,321][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,321][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:16:34,321][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,322][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit17', 'circuit19']
[2024-07-24 10:16:34,322][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:16:34,322][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14']
[2024-07-24 10:16:34,322][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,322][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,322][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,322][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,322][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,323][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,323][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,323][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit24']
[2024-07-24 10:16:34,323][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:16:34,323][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,323][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,323][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,324][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit21']
[2024-07-24 10:16:34,324][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,324][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,324][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,324][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,324][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:16:34,324][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:16:34,324][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,325][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,325][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,325][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,325][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,325][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,325][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,325][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,326][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,326][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:16:34,326][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,326][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,326][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,326][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,326][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,327][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,327][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,327][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,327][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,327][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:16:34,327][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,327][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,327][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,328][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,328][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,328][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,328][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,328][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,328][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,328][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:16:34,329][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,329][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,329][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,329][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,329][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,329][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,329][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,329][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,330][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,330][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:16:34,330][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,330][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,330][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,330][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,330][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,331][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,331][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,331][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,331][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,331][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:16:34,331][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,331][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,331][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,332][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,332][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,332][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,332][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,332][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,332][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,332][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:16:34,333][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,333][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,333][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,333][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,333][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,333][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,333][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,333][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,334][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,334][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:16:34,334][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,334][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,334][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,334][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,334][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,335][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,335][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,335][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,335][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,335][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:16:34,335][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,335][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,335][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,336][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,336][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,336][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,336][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,336][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,336][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,336][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:16:34,337][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,337][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,337][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,337][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,337][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,337][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,337][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,337][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,338][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,338][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:16:34,338][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,338][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,338][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,338][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,338][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,339][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,339][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,339][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,339][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,339][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:16:34,339][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,339][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,339][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,340][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,340][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,340][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,340][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,340][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,340][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,340][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:16:34,341][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,341][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,341][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,341][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,341][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,341][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,341][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,342][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,342][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,342][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:16:34,342][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,342][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,342][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,342][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,342][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,343][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,343][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,343][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,343][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,343][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:16:34,343][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,343][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,344][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,344][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,344][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,344][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,344][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,344][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,344][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,344][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:16:34,345][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,345][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,345][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,345][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,345][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,345][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,345][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit14', 'circuit20']
[2024-07-24 10:16:34,346][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit7', 'circuit13', 'circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:16:34,346][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,346][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,346][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:16:34,346][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:16:34,346][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,346][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,346][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,347][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,347][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,347][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,347][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,347][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,347][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:16:34,347][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:16:34,348][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:16:34,348][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,348][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,348][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,348][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,348][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,348][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,349][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,349][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:16:34,349][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit16', 'circuit22']
[2024-07-24 10:16:34,349][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:16:34,349][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit24']
[2024-07-24 10:16:34,349][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,349][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,349][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,350][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:16:34,350][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,350][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit19', 'circuit21', 'circuit26']
[2024-07-24 10:16:34,350][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit21', 'circuit25']
[2024-07-24 10:16:34,350][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit24']
[2024-07-24 10:16:34,350][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,350][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:16:34,351][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,351][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,351][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,351][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,351][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,351][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,351][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,351][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,352][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,352][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,352][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:16:34,352][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,352][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,352][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,352][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,353][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,353][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,353][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,353][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,353][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,353][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,353][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:16:34,353][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23']
[2024-07-24 10:16:34,354][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,354][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,354][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,354][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,354][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,354][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,354][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,355][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,355][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,355][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:16:34,355][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:16:34,355][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22']
[2024-07-24 10:16:34,355][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,355][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,355][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,356][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:16:34,356][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit18', 'circuit20']
[2024-07-24 10:16:34,356][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,356][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,356][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit5', 'circuit16']
[2024-07-24 10:16:34,356][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:16:34,356][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,357][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,357][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,357][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,357][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,357][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,357][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,357][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,358][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,358][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,358][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:16:34,358][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,358][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,358][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,358][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,358][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,359][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,359][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,359][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,359][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,359][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,359][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:16:34,359][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,360][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,360][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,360][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,360][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,360][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,360][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,360][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,361][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,361][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,361][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:16:34,361][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit13', 'circuit16', 'circuit17', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,361][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,361][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,361][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,361][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,362][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,362][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,362][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,362][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,362][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,362][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:16:34,362][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit12', 'circuit13', 'circuit21', 'circuit26']
[2024-07-24 10:16:34,363][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,363][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,363][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,363][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:16:34,363][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,363][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,363][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,363][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,364][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,364][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:16:34,364][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,364][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,364][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,364][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,364][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,365][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,365][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,365][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,365][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,365][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit22']
[2024-07-24 10:16:34,365][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:16:34,365][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,365][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,366][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,366][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,366][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,366][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,366][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,366][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,366][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,366][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,367][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:16:34,367][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,367][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,367][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,367][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,367][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,367][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,367][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,368][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,368][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,368][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,368][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:16:34,368][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,368][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,368][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,369][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,369][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,369][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,369][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,369][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,369][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,369][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,369][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:16:34,370][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,370][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,370][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,370][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,370][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,370][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,370][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,371][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,371][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,371][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,371][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:16:34,371][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,371][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,371][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,371][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,372][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,372][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,372][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,372][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,372][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,372][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,372][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:16:34,373][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,373][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,373][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,373][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,373][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,373][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,373][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,373][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,374][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,374][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,374][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:16:34,374][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,374][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,374][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,374][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,375][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,375][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,375][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,375][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,375][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,375][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,375][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:16:34,375][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,376][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,376][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,376][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,376][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,376][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,376][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,376][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,377][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,377][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,377][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:16:34,377][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,377][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,377][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,377][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,378][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,378][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,378][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,378][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,378][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,378][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,378][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:16:34,378][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,379][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,379][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,379][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,379][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,379][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,379][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,379][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,380][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,380][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,380][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:16:34,380][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,380][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,380][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,380][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,380][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,381][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,381][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,381][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,381][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,381][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,381][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:16:34,381][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,382][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,382][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,382][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,382][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,382][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,382][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,382][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,382][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,383][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,383][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:16:34,383][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,383][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,383][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,383][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,383][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,384][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,384][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,384][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,384][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,384][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,384][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:16:34,384][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,385][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,385][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,385][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,385][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,385][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,385][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,385][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,386][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,386][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,386][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:16:34,386][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,386][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,386][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,386][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,387][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,387][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,387][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,387][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,387][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,387][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,387][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:16:34,387][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:16:34,388][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit19', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,388][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,388][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:34,388][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,388][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit27']
[2024-07-24 10:16:34,388][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit23', 'circuit28']
[2024-07-24 10:16:34,388][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit18', 'circuit19', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,389][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:34,389][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit9', 'circuit11', 'circuit13', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,389][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:16:34,389][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:16:34,389][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,389][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,389][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,389][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,390][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,390][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,390][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,390][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,390][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,390][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,390][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:34,390][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:16:34,391][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,391][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,391][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,391][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,391][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,391][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,391][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,392][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,392][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,392][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,392][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:16:34,392][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:16:34,392][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,392][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,392][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,393][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,393][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,393][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24']
[2024-07-24 10:16:34,393][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,393][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,393][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,393][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:16:34,394][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,394][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:16:34,394][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:16:34,394][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,394][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,394][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,394][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,395][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit3', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:16:34,395][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,395][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,395][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit25']
[2024-07-24 10:16:34,395][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit7', 'circuit9', 'circuit11', 'circuit14', 'circuit15']
[2024-07-24 10:16:34,395][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,395][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:16:34,395][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,396][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,396][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,396][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,396][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,396][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,396][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,396][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,397][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,397][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:16:34,397][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:16:34,397][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:16:34,397][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:16:34,397][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,397][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,398][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,398][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,398][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:34,398][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:16:34,398][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:16:34,398][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit14', 'circuit20']
[2024-07-24 10:16:34,398][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:16:34,398][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit13', 'circuit20', 'circuit21', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,399][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:16:34,399][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:16:34,399][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit16', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,399][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,399][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:16:34,399][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit26']
[2024-07-24 10:16:34,399][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,400][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit18']
[2024-07-24 10:16:34,400][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit25']
[2024-07-24 10:16:34,400][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:34,400][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:16:34,400][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,400][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:16:34,400][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,401][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,401][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,401][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,401][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,401][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,401][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,401][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,401][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,402][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:16:34,402][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:16:34,402][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:16:34,402][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:16:34,402][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:34,402][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:34,402][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20']
[2024-07-24 10:16:34,403][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,403][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,403][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,403][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,403][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:16:34,403][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,403][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:34,403][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:16:34,404][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:16:34,404][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,404][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,404][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,404][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,404][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24']
[2024-07-24 10:16:34,404][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,405][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,405][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,405][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit22', 'circuit25']
[2024-07-24 10:16:34,405][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit13', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:16:34,405][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:16:34,405][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,405][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,406][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,406][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,406][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,406][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,406][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,406][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,406][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,406][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,407][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:34,407][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:16:34,407][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,407][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,407][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:16:34,407][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,407][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13']
[2024-07-24 10:16:34,408][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,408][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit3', 'circuit13']
[2024-07-24 10:16:34,408][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit22']
[2024-07-24 10:16:34,408][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,408][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit25']
[2024-07-24 10:16:34,408][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit19']
[2024-07-24 10:16:34,408][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:16:34,408][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,409][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,409][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,409][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,409][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit7', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,409][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,409][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:16:34,409][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit19', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:16:34,410][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,410][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:34,410][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:16:34,410][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:16:34,410][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,410][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,410][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,410][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,411][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,411][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,411][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,411][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,411][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,411][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,411][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:34,411][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:16:34,412][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,412][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,412][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,412][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,412][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,412][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,412][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,412][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,413][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,413][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,413][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:34,413][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:16:34,413][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,413][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,413][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,413][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,414][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,414][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,414][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,414][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,414][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,414][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,414][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:34,415][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:16:34,415][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,415][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,415][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,415][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,415][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,415][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,415][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,416][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,416][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,416][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,416][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:34,416][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:16:34,416][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,416][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,417][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,417][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,417][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,417][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,417][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,417][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,417][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,418][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,418][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:34,418][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:16:34,418][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,418][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,418][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,418][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,418][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,419][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,419][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,419][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,419][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,419][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,419][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:34,419][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:16:34,420][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,420][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,420][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,420][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,420][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,420][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,420][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,420][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,421][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,421][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,421][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:34,421][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:16:34,421][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,421][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,421][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,422][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,422][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,422][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,422][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,422][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,422][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,422][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,422][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:34,423][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:16:34,423][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,423][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:34,423][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,423][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,423][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,423][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,424][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,424][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,424][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,424][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,424][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:34,424][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:16:34,424][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,424][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,425][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,425][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,425][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,425][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,425][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,425][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,425][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,426][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,426][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:34,426][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:16:34,426][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,426][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,426][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,426][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,426][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,427][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,427][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,427][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,427][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,427][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,427][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:34,427][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:16:34,428][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:34,428][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:34,428][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:34,428][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:34,428][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:34,428][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:34,428][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:34,429][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:34,429][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:34,429][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:34,429][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:34,429][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:16:34,429][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,429][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,429][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,430][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,430][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,430][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,430][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,430][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,430][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,430][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,431][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,431][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:16:34,431][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,431][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,431][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,431][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,431][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,432][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,432][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,432][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,432][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,432][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,432][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,432][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:16:34,432][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,433][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,433][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,433][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,433][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,433][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,433][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,433][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,434][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,434][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:34,434][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:36,183][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:36,211][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,213][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,215][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,216][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,218][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,219][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,220][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,221][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,222][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,223][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,223][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,224][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,225][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.8183, 0.1817], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,226][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([6.2538e-04, 9.9937e-01], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,227][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.8797, 0.1203], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,229][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.1231, 0.8769], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,231][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.3480, 0.6520], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,232][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.0271, 0.9729], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,234][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.6174, 0.3826], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,236][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.9223, 0.0777], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,238][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.7616, 0.2384], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,240][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.9496, 0.0504], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,242][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.6785, 0.3215], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,243][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.7509, 0.2491], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,245][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.7969, 0.1355, 0.0675], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,246][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([4.4099e-03, 4.6795e-04, 9.9512e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,247][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4097, 0.0612, 0.5291], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,247][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2514, 0.0119, 0.7367], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,248][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.6844, 0.1153, 0.2003], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,249][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1826, 0.0143, 0.8031], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,250][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.5948, 0.3836, 0.0216], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,252][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.4940, 0.2521, 0.2539], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,253][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2531, 0.0421, 0.7048], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,255][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.6193, 0.1254, 0.2553], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,256][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.6686, 0.0977, 0.2337], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,258][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.5429, 0.1165, 0.3407], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,260][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Jonathan] are: tensor([0.4541, 0.1531, 0.3077, 0.0851], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,261][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Jonathan] are: tensor([8.6947e-05, 4.6498e-03, 9.7697e-05, 9.9517e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,263][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Jonathan] are: tensor([0.6467, 0.1770, 0.1059, 0.0703], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,264][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Jonathan] are: tensor([4.9763e-03, 3.5405e-02, 2.8729e-04, 9.5933e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,266][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Jonathan] are: tensor([0.0198, 0.1210, 0.0058, 0.8534], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,267][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Jonathan] are: tensor([1.0449e-02, 5.7745e-03, 5.1229e-07, 9.8378e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,269][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Jonathan] are: tensor([0.2380, 0.4592, 0.1252, 0.1776], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,270][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Jonathan] are: tensor([0.2488, 0.2917, 0.3518, 0.1076], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,271][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Jonathan] are: tensor([0.4117, 0.2209, 0.2118, 0.1556], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,271][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Jonathan] are: tensor([0.5763, 0.1408, 0.2440, 0.0389], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,272][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Jonathan] are: tensor([0.3842, 0.1801, 0.1508, 0.2849], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,273][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Jonathan] are: tensor([0.3877, 0.1694, 0.2985, 0.1443], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,274][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.4891, 0.0697, 0.0865, 0.0848, 0.2698], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,275][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ went] are: tensor([1.1720e-03, 3.3742e-04, 1.7629e-03, 1.2766e-03, 9.9545e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,277][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.5972, 0.0500, 0.1889, 0.0783, 0.0856], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,278][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ went] are: tensor([3.0829e-02, 3.7631e-04, 2.0199e-03, 7.2062e-04, 9.6605e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,280][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.4271, 0.0305, 0.0626, 0.0538, 0.4259], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,281][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ went] are: tensor([2.6719e-02, 3.0249e-05, 6.5631e-05, 4.2428e-05, 9.7314e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,283][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.2880, 0.2831, 0.0437, 0.3424, 0.0428], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,285][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.2295, 0.1012, 0.2441, 0.2219, 0.2032], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,286][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.3871, 0.0816, 0.3770, 0.0913, 0.0630], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,289][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.4315, 0.1139, 0.2109, 0.1278, 0.1159], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,290][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.4062, 0.0821, 0.1829, 0.0732, 0.2556], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,292][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.4609, 0.0877, 0.2295, 0.1060, 0.1160], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,293][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.4447, 0.0954, 0.0599, 0.1276, 0.2406, 0.0319], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,294][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([5.9629e-03, 4.1574e-04, 6.7586e-02, 1.5978e-04, 8.4855e-04, 9.2503e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,295][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.3881, 0.0449, 0.1748, 0.0639, 0.0788, 0.2496], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,296][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0319, 0.0076, 0.0208, 0.0238, 0.4531, 0.4628], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,296][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1537, 0.0295, 0.0259, 0.0472, 0.6138, 0.1299], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,297][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0827, 0.0245, 0.1440, 0.0059, 0.0154, 0.7275], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,299][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2748, 0.2024, 0.0151, 0.1001, 0.0716, 0.3361], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,301][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1294, 0.0594, 0.1102, 0.1897, 0.2812, 0.2301], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,303][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0607, 0.0138, 0.3510, 0.0121, 0.0657, 0.4967], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,304][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.3581, 0.0797, 0.1917, 0.0930, 0.0900, 0.1874], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,306][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.3479, 0.0723, 0.2399, 0.0550, 0.0899, 0.1950], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,308][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.3258, 0.1007, 0.1731, 0.1031, 0.1197, 0.1776], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,310][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.4995, 0.1136, 0.0439, 0.1506, 0.1339, 0.0231, 0.0353],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,311][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ the] are: tensor([9.1082e-03, 1.3045e-03, 6.6742e-02, 5.1406e-04, 1.9123e-04, 8.7303e-02,
        8.3484e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,313][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.3294, 0.0565, 0.1404, 0.0557, 0.1084, 0.2702, 0.0395],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,315][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0500, 0.0102, 0.0230, 0.0226, 0.0843, 0.1804, 0.6295],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,317][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2970, 0.0472, 0.0413, 0.0636, 0.2866, 0.1229, 0.1413],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,318][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1743, 0.0361, 0.1477, 0.0205, 0.0399, 0.1314, 0.4501],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,319][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2877, 0.3247, 0.0067, 0.2859, 0.0805, 0.0106, 0.0039],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,319][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1198, 0.0310, 0.0834, 0.0788, 0.1481, 0.2316, 0.3072],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,320][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0306, 0.0074, 0.1963, 0.0125, 0.0525, 0.2103, 0.4904],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,321][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.3269, 0.0727, 0.1593, 0.0780, 0.0799, 0.1549, 0.1283],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,322][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.3517, 0.0699, 0.1688, 0.0681, 0.0447, 0.1147, 0.1822],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,324][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.2670, 0.0912, 0.1398, 0.1123, 0.1017, 0.1357, 0.1522],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,326][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.2748, 0.1260, 0.1532, 0.1300, 0.0479, 0.0841, 0.0776, 0.1065],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,327][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([4.9434e-04, 9.1351e-03, 3.6800e-04, 3.3022e-04, 1.3612e-03, 3.2732e-04,
        9.2571e-05, 9.8789e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,329][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.3397, 0.1204, 0.0552, 0.0624, 0.0561, 0.0535, 0.0883, 0.2244],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,330][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([3.5714e-03, 4.9955e-04, 6.1549e-05, 9.9744e-04, 3.9128e-03, 8.8983e-04,
        5.8476e-04, 9.8948e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,332][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.0371, 0.0267, 0.0124, 0.0709, 0.0428, 0.0271, 0.0341, 0.7490],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,334][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([8.0576e-03, 6.2904e-03, 3.7012e-06, 4.2156e-05, 1.7310e-05, 2.2615e-07,
        9.4839e-07, 9.8559e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,335][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.2096, 0.1596, 0.0630, 0.1111, 0.0218, 0.0163, 0.0449, 0.3737],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,337][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.0892, 0.0148, 0.0684, 0.0395, 0.1701, 0.1745, 0.2724, 0.1711],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,339][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.3215, 0.0736, 0.1416, 0.0408, 0.0472, 0.1134, 0.1428, 0.1192],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,341][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.3262, 0.1724, 0.1286, 0.0819, 0.0600, 0.1056, 0.1032, 0.0222],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,342][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.2365, 0.0970, 0.1466, 0.0392, 0.0487, 0.0996, 0.0803, 0.2521],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,343][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.2622, 0.0611, 0.1626, 0.0788, 0.0856, 0.1116, 0.0633, 0.1747],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,344][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4430, 0.0866, 0.0204, 0.1339, 0.1197, 0.0187, 0.0592, 0.1048, 0.0137],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,345][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([3.4325e-03, 3.6754e-04, 2.5585e-02, 1.1891e-04, 5.2717e-04, 9.1328e-03,
        1.2522e-03, 2.2983e-05, 9.5956e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,345][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2775, 0.0241, 0.1214, 0.0188, 0.0479, 0.0613, 0.0139, 0.0160, 0.4192],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,347][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0535, 0.0015, 0.0084, 0.0020, 0.0764, 0.0462, 0.1221, 0.0298, 0.6601],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,349][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5113, 0.0353, 0.0152, 0.0261, 0.0710, 0.0512, 0.0280, 0.0890, 0.1731],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,350][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1342, 0.0401, 0.1930, 0.0238, 0.0580, 0.0959, 0.1431, 0.0284, 0.2833],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,352][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2362, 0.2053, 0.0082, 0.1465, 0.0508, 0.0163, 0.0054, 0.3262, 0.0050],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,353][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0476, 0.0222, 0.0302, 0.0495, 0.0615, 0.0810, 0.1595, 0.2378, 0.3105],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,355][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0343, 0.0072, 0.1786, 0.0060, 0.0216, 0.1586, 0.2321, 0.0099, 0.3517],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,357][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2652, 0.0787, 0.1345, 0.0693, 0.0719, 0.1247, 0.0988, 0.0553, 0.1016],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,359][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2270, 0.0772, 0.1633, 0.0615, 0.0694, 0.1353, 0.0985, 0.0577, 0.1101],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,361][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2467, 0.0748, 0.1213, 0.0832, 0.0913, 0.1109, 0.0631, 0.0735, 0.1352],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,363][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Jonathan] are: tensor([0.2294, 0.0843, 0.1526, 0.0516, 0.0306, 0.1245, 0.1170, 0.0295, 0.1305,
        0.0502], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,364][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Jonathan] are: tensor([2.4184e-05, 1.1617e-03, 2.0309e-05, 5.2147e-01, 1.1519e-04, 2.7569e-05,
        2.2059e-05, 8.3169e-06, 5.4102e-06, 4.7715e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,366][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Jonathan] are: tensor([0.3548, 0.1328, 0.0719, 0.0598, 0.0478, 0.0680, 0.1020, 0.0480, 0.0669,
        0.0481], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,367][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Jonathan] are: tensor([5.0296e-04, 7.4170e-04, 2.6419e-06, 1.3789e-02, 6.9577e-06, 1.8603e-05,
        8.7750e-05, 3.5458e-04, 8.4035e-05, 9.8441e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,368][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Jonathan] are: tensor([0.0044, 0.0184, 0.0010, 0.1155, 0.0014, 0.0020, 0.0026, 0.0035, 0.0043,
        0.8469], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,368][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Jonathan] are: tensor([2.3208e-03, 2.4616e-03, 8.5470e-08, 6.1135e-01, 6.5190e-07, 4.3038e-08,
        3.8777e-07, 8.7157e-07, 3.3109e-08, 3.8386e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,369][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Jonathan] are: tensor([0.1153, 0.2823, 0.0745, 0.1565, 0.0182, 0.0270, 0.0708, 0.0508, 0.0676,
        0.1369], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,370][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Jonathan] are: tensor([0.0698, 0.0429, 0.0450, 0.0148, 0.0540, 0.1231, 0.1793, 0.0580, 0.2929,
        0.1201], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,373][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Jonathan] are: tensor([0.1889, 0.1292, 0.1176, 0.1009, 0.0365, 0.1001, 0.0718, 0.0548, 0.1009,
        0.0993], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,374][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Jonathan] are: tensor([0.2669, 0.0880, 0.1317, 0.0219, 0.0632, 0.1122, 0.1136, 0.0756, 0.1082,
        0.0186], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,376][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Jonathan] are: tensor([0.1292, 0.1018, 0.0801, 0.2594, 0.0344, 0.0599, 0.0618, 0.0237, 0.0509,
        0.1988], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,378][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Jonathan] are: tensor([0.1591, 0.0870, 0.1122, 0.0798, 0.1402, 0.0905, 0.0528, 0.0851, 0.1025,
        0.0907], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,380][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.2783, 0.0231, 0.0336, 0.0442, 0.2253, 0.0219, 0.0207, 0.0753, 0.0240,
        0.0500, 0.2037], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,381][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([9.4375e-04, 1.2007e-03, 2.3511e-03, 2.2007e-03, 8.8160e-03, 1.1940e-03,
        3.2112e-04, 1.3245e-04, 3.6651e-04, 1.3823e-03, 9.8109e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,383][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.2948, 0.0332, 0.0715, 0.0682, 0.0825, 0.1090, 0.0705, 0.0819, 0.0443,
        0.0613, 0.0826], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,384][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([2.3839e-03, 2.3407e-05, 2.9772e-05, 3.1019e-05, 1.0942e-03, 1.3015e-04,
        1.9858e-04, 3.9729e-04, 1.7804e-03, 1.7527e-03, 9.9218e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,386][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1257, 0.0167, 0.0131, 0.0211, 0.0360, 0.0296, 0.0195, 0.0782, 0.0423,
        0.1049, 0.5129], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,388][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([4.7298e-02, 3.3996e-04, 3.9505e-05, 8.2181e-05, 1.0252e-02, 4.1297e-06,
        1.4026e-05, 4.8301e-05, 1.9010e-06, 2.9909e-05, 9.4189e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,389][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.1303, 0.1073, 0.0181, 0.1936, 0.0287, 0.0131, 0.0173, 0.2038, 0.0145,
        0.2425, 0.0309], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,390][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0437, 0.0085, 0.0195, 0.0263, 0.0221, 0.0443, 0.0742, 0.0466, 0.1820,
        0.3023, 0.2306], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,391][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.1260, 0.0303, 0.1370, 0.0320, 0.0459, 0.1303, 0.1782, 0.0812, 0.1596,
        0.0350, 0.0445], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,392][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.1922, 0.0747, 0.1020, 0.0612, 0.0834, 0.0993, 0.0814, 0.0783, 0.0900,
        0.0641, 0.0733], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,393][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.1538, 0.0710, 0.0910, 0.0725, 0.0970, 0.0867, 0.0611, 0.0406, 0.0662,
        0.0614, 0.1986], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,393][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.2970, 0.0480, 0.1251, 0.0507, 0.0502, 0.1060, 0.0470, 0.0476, 0.1031,
        0.0491, 0.0762], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,395][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2496, 0.0650, 0.0235, 0.0836, 0.0613, 0.0152, 0.0280, 0.1985, 0.0242,
        0.1073, 0.1212, 0.0226], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,396][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([3.0351e-03, 1.6572e-03, 3.7305e-03, 6.1850e-04, 1.0825e-04, 9.8398e-03,
        3.0981e-02, 8.7666e-05, 1.0094e-03, 3.7180e-04, 2.1889e-04, 9.4834e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,398][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1841, 0.0344, 0.1200, 0.0469, 0.0830, 0.1944, 0.0274, 0.0531, 0.0792,
        0.0463, 0.1059, 0.0254], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,399][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([1.2018e-02, 3.9765e-04, 9.4343e-04, 8.8672e-04, 1.9819e-03, 4.0915e-03,
        1.6115e-02, 3.4761e-03, 4.9332e-02, 3.5747e-02, 1.3411e-01, 7.4090e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,401][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0593, 0.0060, 0.0060, 0.0108, 0.0607, 0.0158, 0.0170, 0.0395, 0.0306,
        0.0639, 0.5152, 0.1753], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,403][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0647, 0.0158, 0.1032, 0.0046, 0.0109, 0.0914, 0.2220, 0.0040, 0.0310,
        0.0020, 0.0074, 0.4431], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,405][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1519, 0.1451, 0.0043, 0.1119, 0.0629, 0.0081, 0.0033, 0.2715, 0.0030,
        0.1518, 0.0808, 0.0055], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,407][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0355, 0.0052, 0.0115, 0.0098, 0.0240, 0.0232, 0.0404, 0.0461, 0.1192,
        0.1012, 0.2940, 0.2898], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,409][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0159, 0.0035, 0.0800, 0.0046, 0.0220, 0.0968, 0.2272, 0.0106, 0.1534,
        0.0063, 0.0280, 0.3516], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,411][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1892, 0.0495, 0.1079, 0.0510, 0.0541, 0.1032, 0.0879, 0.0629, 0.0849,
        0.0505, 0.0704, 0.0885], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,413][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1717, 0.0521, 0.1099, 0.0526, 0.0380, 0.1022, 0.1094, 0.0513, 0.0719,
        0.0421, 0.0397, 0.1591], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,414][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1914, 0.0667, 0.0838, 0.0688, 0.0660, 0.0928, 0.0504, 0.0518, 0.0958,
        0.0712, 0.0921, 0.0691], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,415][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.1775, 0.0691, 0.1210, 0.0999, 0.0165, 0.1120, 0.0545, 0.0905, 0.0776,
        0.0886, 0.0197, 0.0489, 0.0240], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,415][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([2.9195e-04, 1.2179e-02, 2.8737e-04, 9.2038e-03, 6.2881e-04, 1.5386e-04,
        7.2789e-05, 1.5602e-04, 1.5883e-04, 5.4001e-03, 1.0214e-03, 9.7854e-05,
        9.7035e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,416][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.2186, 0.0933, 0.0791, 0.0646, 0.1005, 0.0480, 0.0850, 0.0691, 0.0294,
        0.0536, 0.0722, 0.0687, 0.0178], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,417][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([1.0434e-03, 7.9251e-06, 6.5413e-07, 3.9981e-05, 6.4663e-05, 3.0931e-06,
        2.1794e-06, 5.5350e-04, 1.7014e-05, 1.3293e-03, 2.8193e-03, 8.4084e-05,
        9.9403e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,418][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([2.3148e-02, 6.5553e-03, 4.7484e-04, 6.6315e-03, 4.9350e-03, 7.8837e-04,
        1.2255e-03, 4.2925e-03, 2.1299e-03, 2.4809e-02, 3.7414e-02, 3.3060e-03,
        8.8429e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,420][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([2.2825e-05, 5.1351e-06, 1.5531e-09, 2.3891e-07, 1.7650e-07, 7.5640e-11,
        5.9342e-11, 1.7025e-07, 1.7791e-10, 5.7061e-08, 8.0127e-09, 6.4064e-11,
        9.9997e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,422][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.1253, 0.0862, 0.0748, 0.1504, 0.0169, 0.0152, 0.0533, 0.1043, 0.0626,
        0.1397, 0.0149, 0.0573, 0.0991], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,423][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.0414, 0.0261, 0.0219, 0.0063, 0.0213, 0.0453, 0.0477, 0.0106, 0.1220,
        0.0348, 0.2271, 0.3446, 0.0508], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,426][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.2173, 0.0665, 0.0586, 0.0550, 0.0474, 0.0386, 0.0473, 0.0532, 0.0391,
        0.0464, 0.0425, 0.0415, 0.2465], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,428][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.2010, 0.0813, 0.0928, 0.0408, 0.0521, 0.0783, 0.0715, 0.0972, 0.0794,
        0.0384, 0.0839, 0.0752, 0.0081], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,430][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.1448, 0.0758, 0.0943, 0.0491, 0.0549, 0.0716, 0.0465, 0.0476, 0.0618,
        0.0360, 0.0457, 0.0474, 0.2244], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,432][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0818, 0.0734, 0.0731, 0.0418, 0.0762, 0.0844, 0.0705, 0.0378, 0.0944,
        0.0476, 0.1215, 0.1134, 0.0842], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,434][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1975, 0.0384, 0.0208, 0.0552, 0.1162, 0.0112, 0.0252, 0.0796, 0.0220,
        0.0720, 0.1246, 0.0252, 0.1971, 0.0149], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:36,435][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.8457e-03, 1.0106e-04, 2.1803e-02, 4.8456e-05, 2.6970e-04, 4.6079e-01,
        1.1719e-03, 2.5527e-05, 4.8525e-03, 2.7403e-05, 3.8294e-04, 7.0105e-04,
        8.8118e-06, 5.0697e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:36,437][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1957, 0.0247, 0.0967, 0.0429, 0.0540, 0.1467, 0.0286, 0.0295, 0.0578,
        0.0404, 0.0665, 0.0257, 0.0220, 0.1687], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:36,438][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([4.1733e-03, 1.2287e-04, 1.9985e-04, 1.6645e-04, 2.9067e-03, 2.0498e-03,
        2.5537e-03, 7.8336e-04, 6.8020e-03, 5.1351e-03, 2.5736e-01, 7.1689e-02,
        5.8197e-02, 5.8787e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:36,440][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0367, 0.0029, 0.0032, 0.0033, 0.0611, 0.0119, 0.0072, 0.0136, 0.0105,
        0.0183, 0.3386, 0.0759, 0.1835, 0.2334], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:36,441][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([2.1940e-02, 1.1027e-02, 6.1812e-02, 2.2591e-03, 8.7790e-03, 3.8188e-01,
        1.4173e-01, 1.2740e-03, 1.3804e-02, 1.0021e-03, 4.3741e-03, 9.6299e-02,
        2.6297e-04, 2.5356e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:36,443][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1081, 0.0809, 0.0048, 0.0512, 0.0320, 0.1434, 0.0030, 0.0524, 0.0037,
        0.0744, 0.0490, 0.0052, 0.1297, 0.2621], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:36,444][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0257, 0.0039, 0.0061, 0.0086, 0.0122, 0.0085, 0.0190, 0.0186, 0.0486,
        0.0720, 0.1179, 0.1603, 0.2152, 0.2833], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:36,445][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0133, 0.0031, 0.0879, 0.0029, 0.0195, 0.1199, 0.1620, 0.0120, 0.1383,
        0.0038, 0.0188, 0.1900, 0.0089, 0.2196], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:36,446][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1560, 0.0421, 0.0893, 0.0499, 0.0476, 0.0853, 0.0762, 0.0483, 0.0713,
        0.0504, 0.0630, 0.0810, 0.0389, 0.1008], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:36,446][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1256, 0.0334, 0.1080, 0.0363, 0.0668, 0.1209, 0.0841, 0.0405, 0.0771,
        0.0301, 0.0593, 0.0827, 0.0230, 0.1122], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:36,448][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1656, 0.0575, 0.0754, 0.0591, 0.0619, 0.0746, 0.0363, 0.0409, 0.0786,
        0.0584, 0.0832, 0.0485, 0.0829, 0.0771], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:36,460][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:36,461][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,462][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,463][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,463][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,464][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,465][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,465][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,467][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,467][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,468][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,469][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,469][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,470][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.8183, 0.1817], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,471][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([6.2538e-04, 9.9937e-01], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,472][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.8797, 0.1203], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,474][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.1231, 0.8769], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,476][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.3480, 0.6520], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,478][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.0271, 0.9729], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,479][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.6174, 0.3826], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,481][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.9223, 0.0777], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,482][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.7616, 0.2384], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,483][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.9496, 0.0504], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,483][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.6785, 0.3215], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,484][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.7509, 0.2491], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,485][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.7969, 0.1355, 0.0675], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,485][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([4.4099e-03, 4.6795e-04, 9.9512e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,487][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4097, 0.0612, 0.5291], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,489][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2514, 0.0119, 0.7367], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,491][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.6844, 0.1153, 0.2003], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,492][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1826, 0.0143, 0.8031], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,495][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.5948, 0.3836, 0.0216], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,496][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4940, 0.2521, 0.2539], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,498][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2531, 0.0421, 0.7048], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,500][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.6193, 0.1254, 0.2553], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,502][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.6686, 0.0977, 0.2337], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,503][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.5429, 0.1165, 0.3407], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,505][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Jonathan] are: tensor([0.4541, 0.1531, 0.3077, 0.0851], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,506][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Jonathan] are: tensor([8.6947e-05, 4.6498e-03, 9.7697e-05, 9.9517e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,507][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Jonathan] are: tensor([0.6467, 0.1770, 0.1059, 0.0703], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,507][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Jonathan] are: tensor([4.9763e-03, 3.5405e-02, 2.8729e-04, 9.5933e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,508][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Jonathan] are: tensor([0.0198, 0.1210, 0.0058, 0.8534], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,509][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Jonathan] are: tensor([1.0449e-02, 5.7745e-03, 5.1229e-07, 9.8378e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,509][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Jonathan] are: tensor([0.2380, 0.4592, 0.1252, 0.1776], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,511][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Jonathan] are: tensor([0.2488, 0.2917, 0.3518, 0.1076], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,513][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Jonathan] are: tensor([0.4117, 0.2209, 0.2118, 0.1556], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,515][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Jonathan] are: tensor([0.5763, 0.1408, 0.2440, 0.0389], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,517][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Jonathan] are: tensor([0.3842, 0.1801, 0.1508, 0.2849], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,519][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Jonathan] are: tensor([0.3877, 0.1694, 0.2985, 0.1443], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,521][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.4891, 0.0697, 0.0865, 0.0848, 0.2698], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,522][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([1.1720e-03, 3.3742e-04, 1.7629e-03, 1.2766e-03, 9.9545e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,523][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.5972, 0.0500, 0.1889, 0.0783, 0.0856], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,525][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([3.0829e-02, 3.7631e-04, 2.0199e-03, 7.2062e-04, 9.6605e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,527][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.4271, 0.0305, 0.0626, 0.0538, 0.4259], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,528][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([2.6719e-02, 3.0249e-05, 6.5631e-05, 4.2428e-05, 9.7314e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,530][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.2880, 0.2831, 0.0437, 0.3424, 0.0428], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,531][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.2295, 0.1012, 0.2441, 0.2219, 0.2032], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,531][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.3871, 0.0816, 0.3770, 0.0913, 0.0630], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,532][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.4315, 0.1139, 0.2109, 0.1278, 0.1159], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,533][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.4062, 0.0821, 0.1829, 0.0732, 0.2556], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,534][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.4609, 0.0877, 0.2295, 0.1060, 0.1160], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,535][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.4447, 0.0954, 0.0599, 0.1276, 0.2406, 0.0319], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,537][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([5.9629e-03, 4.1574e-04, 6.7586e-02, 1.5978e-04, 8.4855e-04, 9.2503e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,538][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3881, 0.0449, 0.1748, 0.0639, 0.0788, 0.2496], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,540][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0319, 0.0076, 0.0208, 0.0238, 0.4531, 0.4628], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,541][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1537, 0.0295, 0.0259, 0.0472, 0.6138, 0.1299], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,544][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0827, 0.0245, 0.1440, 0.0059, 0.0154, 0.7275], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,545][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.2748, 0.2024, 0.0151, 0.1001, 0.0716, 0.3361], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,547][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1294, 0.0594, 0.1102, 0.1897, 0.2812, 0.2301], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,549][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0607, 0.0138, 0.3510, 0.0121, 0.0657, 0.4967], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,551][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.3581, 0.0797, 0.1917, 0.0930, 0.0900, 0.1874], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,553][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.3479, 0.0723, 0.2399, 0.0550, 0.0899, 0.1950], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,554][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.3258, 0.1007, 0.1731, 0.1031, 0.1197, 0.1776], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,555][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.4995, 0.1136, 0.0439, 0.1506, 0.1339, 0.0231, 0.0353],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,555][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([9.1082e-03, 1.3045e-03, 6.6742e-02, 5.1406e-04, 1.9123e-04, 8.7303e-02,
        8.3484e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,556][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.3294, 0.0565, 0.1404, 0.0557, 0.1084, 0.2702, 0.0395],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,557][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0500, 0.0102, 0.0230, 0.0226, 0.0843, 0.1804, 0.6295],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,558][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.2970, 0.0472, 0.0413, 0.0636, 0.2866, 0.1229, 0.1413],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,560][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1743, 0.0361, 0.1477, 0.0205, 0.0399, 0.1314, 0.4501],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,562][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2877, 0.3247, 0.0067, 0.2859, 0.0805, 0.0106, 0.0039],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,563][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1198, 0.0310, 0.0834, 0.0788, 0.1481, 0.2316, 0.3072],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,565][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0306, 0.0074, 0.1963, 0.0125, 0.0525, 0.2103, 0.4904],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,567][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.3269, 0.0727, 0.1593, 0.0780, 0.0799, 0.1549, 0.1283],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,569][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.3517, 0.0699, 0.1688, 0.0681, 0.0447, 0.1147, 0.1822],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,571][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2670, 0.0912, 0.1398, 0.1123, 0.1017, 0.1357, 0.1522],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,573][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.2748, 0.1260, 0.1532, 0.1300, 0.0479, 0.0841, 0.0776, 0.1065],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,574][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([4.9434e-04, 9.1351e-03, 3.6800e-04, 3.3022e-04, 1.3612e-03, 3.2732e-04,
        9.2571e-05, 9.8789e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,576][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([0.3397, 0.1204, 0.0552, 0.0624, 0.0561, 0.0535, 0.0883, 0.2244],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,577][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([3.5714e-03, 4.9955e-04, 6.1549e-05, 9.9744e-04, 3.9128e-03, 8.8983e-04,
        5.8476e-04, 9.8948e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,578][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.0371, 0.0267, 0.0124, 0.0709, 0.0428, 0.0271, 0.0341, 0.7490],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,579][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([8.0576e-03, 6.2904e-03, 3.7012e-06, 4.2156e-05, 1.7310e-05, 2.2615e-07,
        9.4839e-07, 9.8559e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,580][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.2096, 0.1596, 0.0630, 0.1111, 0.0218, 0.0163, 0.0449, 0.3737],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,580][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.0892, 0.0148, 0.0684, 0.0395, 0.1701, 0.1745, 0.2724, 0.1711],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,581][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.3215, 0.0736, 0.1416, 0.0408, 0.0472, 0.1134, 0.1428, 0.1192],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,583][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.3262, 0.1724, 0.1286, 0.0819, 0.0600, 0.1056, 0.1032, 0.0222],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,584][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.2365, 0.0970, 0.1466, 0.0392, 0.0487, 0.0996, 0.0803, 0.2521],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,586][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.2622, 0.0611, 0.1626, 0.0788, 0.0856, 0.1116, 0.0633, 0.1747],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,588][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4430, 0.0866, 0.0204, 0.1339, 0.1197, 0.0187, 0.0592, 0.1048, 0.0137],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,589][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([3.4325e-03, 3.6754e-04, 2.5585e-02, 1.1891e-04, 5.2717e-04, 9.1328e-03,
        1.2522e-03, 2.2983e-05, 9.5956e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,591][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2775, 0.0241, 0.1214, 0.0188, 0.0479, 0.0613, 0.0139, 0.0160, 0.4192],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,593][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0535, 0.0015, 0.0084, 0.0020, 0.0764, 0.0462, 0.1221, 0.0298, 0.6601],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,594][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5113, 0.0353, 0.0152, 0.0261, 0.0710, 0.0512, 0.0280, 0.0890, 0.1731],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,597][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1342, 0.0401, 0.1930, 0.0238, 0.0580, 0.0959, 0.1431, 0.0284, 0.2833],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,599][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2362, 0.2053, 0.0082, 0.1465, 0.0508, 0.0163, 0.0054, 0.3262, 0.0050],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,600][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0476, 0.0222, 0.0302, 0.0495, 0.0615, 0.0810, 0.1595, 0.2378, 0.3105],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,602][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0343, 0.0072, 0.1786, 0.0060, 0.0216, 0.1586, 0.2321, 0.0099, 0.3517],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,602][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2652, 0.0787, 0.1345, 0.0693, 0.0719, 0.1247, 0.0988, 0.0553, 0.1016],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,603][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2270, 0.0772, 0.1633, 0.0615, 0.0694, 0.1353, 0.0985, 0.0577, 0.1101],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,604][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2467, 0.0748, 0.1213, 0.0832, 0.0913, 0.1109, 0.0631, 0.0735, 0.1352],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,605][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Jonathan] are: tensor([0.2294, 0.0843, 0.1526, 0.0516, 0.0306, 0.1245, 0.1170, 0.0295, 0.1305,
        0.0502], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,606][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Jonathan] are: tensor([2.4184e-05, 1.1617e-03, 2.0309e-05, 5.2147e-01, 1.1519e-04, 2.7569e-05,
        2.2059e-05, 8.3169e-06, 5.4102e-06, 4.7715e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,608][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Jonathan] are: tensor([0.3548, 0.1328, 0.0719, 0.0598, 0.0478, 0.0680, 0.1020, 0.0480, 0.0669,
        0.0481], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,609][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Jonathan] are: tensor([5.0296e-04, 7.4170e-04, 2.6419e-06, 1.3789e-02, 6.9577e-06, 1.8603e-05,
        8.7750e-05, 3.5458e-04, 8.4035e-05, 9.8441e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,611][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Jonathan] are: tensor([0.0044, 0.0184, 0.0010, 0.1155, 0.0014, 0.0020, 0.0026, 0.0035, 0.0043,
        0.8469], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,612][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Jonathan] are: tensor([2.3208e-03, 2.4616e-03, 8.5470e-08, 6.1135e-01, 6.5190e-07, 4.3038e-08,
        3.8777e-07, 8.7157e-07, 3.3109e-08, 3.8386e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,614][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Jonathan] are: tensor([0.1153, 0.2823, 0.0745, 0.1565, 0.0182, 0.0270, 0.0708, 0.0508, 0.0676,
        0.1369], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,616][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Jonathan] are: tensor([0.0698, 0.0429, 0.0450, 0.0148, 0.0540, 0.1231, 0.1793, 0.0580, 0.2929,
        0.1201], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,618][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Jonathan] are: tensor([0.1889, 0.1292, 0.1176, 0.1009, 0.0365, 0.1001, 0.0718, 0.0548, 0.1009,
        0.0993], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,620][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Jonathan] are: tensor([0.2669, 0.0880, 0.1317, 0.0219, 0.0632, 0.1122, 0.1136, 0.0756, 0.1082,
        0.0186], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,622][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Jonathan] are: tensor([0.1292, 0.1018, 0.0801, 0.2594, 0.0344, 0.0599, 0.0618, 0.0237, 0.0509,
        0.1988], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,624][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Jonathan] are: tensor([0.1591, 0.0870, 0.1122, 0.0798, 0.1402, 0.0905, 0.0528, 0.0851, 0.1025,
        0.0907], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,626][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.2783, 0.0231, 0.0336, 0.0442, 0.2253, 0.0219, 0.0207, 0.0753, 0.0240,
        0.0500, 0.2037], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,627][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([9.4375e-04, 1.2007e-03, 2.3511e-03, 2.2007e-03, 8.8160e-03, 1.1940e-03,
        3.2112e-04, 1.3245e-04, 3.6651e-04, 1.3823e-03, 9.8109e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,627][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.2948, 0.0332, 0.0715, 0.0682, 0.0825, 0.1090, 0.0705, 0.0819, 0.0443,
        0.0613, 0.0826], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,628][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([2.3839e-03, 2.3407e-05, 2.9772e-05, 3.1019e-05, 1.0942e-03, 1.3015e-04,
        1.9858e-04, 3.9729e-04, 1.7804e-03, 1.7527e-03, 9.9218e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,629][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1257, 0.0167, 0.0131, 0.0211, 0.0360, 0.0296, 0.0195, 0.0782, 0.0423,
        0.1049, 0.5129], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,630][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([4.7298e-02, 3.3996e-04, 3.9505e-05, 8.2181e-05, 1.0252e-02, 4.1297e-06,
        1.4026e-05, 4.8301e-05, 1.9010e-06, 2.9909e-05, 9.4189e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,632][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.1303, 0.1073, 0.0181, 0.1936, 0.0287, 0.0131, 0.0173, 0.2038, 0.0145,
        0.2425, 0.0309], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,634][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0437, 0.0085, 0.0195, 0.0263, 0.0221, 0.0443, 0.0742, 0.0466, 0.1820,
        0.3023, 0.2306], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,636][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.1260, 0.0303, 0.1370, 0.0320, 0.0459, 0.1303, 0.1782, 0.0812, 0.1596,
        0.0350, 0.0445], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,637][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.1922, 0.0747, 0.1020, 0.0612, 0.0834, 0.0993, 0.0814, 0.0783, 0.0900,
        0.0641, 0.0733], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,639][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.1538, 0.0710, 0.0910, 0.0725, 0.0970, 0.0867, 0.0611, 0.0406, 0.0662,
        0.0614, 0.1986], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,641][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.2970, 0.0480, 0.1251, 0.0507, 0.0502, 0.1060, 0.0470, 0.0476, 0.1031,
        0.0491, 0.0762], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,643][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2496, 0.0650, 0.0235, 0.0836, 0.0613, 0.0152, 0.0280, 0.1985, 0.0242,
        0.1073, 0.1212, 0.0226], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,645][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([3.0351e-03, 1.6572e-03, 3.7305e-03, 6.1850e-04, 1.0825e-04, 9.8398e-03,
        3.0981e-02, 8.7666e-05, 1.0094e-03, 3.7180e-04, 2.1889e-04, 9.4834e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,647][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1841, 0.0344, 0.1200, 0.0469, 0.0830, 0.1944, 0.0274, 0.0531, 0.0792,
        0.0463, 0.1059, 0.0254], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,648][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.2018e-02, 3.9765e-04, 9.4343e-04, 8.8672e-04, 1.9819e-03, 4.0915e-03,
        1.6115e-02, 3.4761e-03, 4.9332e-02, 3.5747e-02, 1.3411e-01, 7.4090e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,650][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0593, 0.0060, 0.0060, 0.0108, 0.0607, 0.0158, 0.0170, 0.0395, 0.0306,
        0.0639, 0.5152, 0.1753], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,650][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0647, 0.0158, 0.1032, 0.0046, 0.0109, 0.0914, 0.2220, 0.0040, 0.0310,
        0.0020, 0.0074, 0.4431], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,651][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1519, 0.1451, 0.0043, 0.1119, 0.0629, 0.0081, 0.0033, 0.2715, 0.0030,
        0.1518, 0.0808, 0.0055], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,652][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0355, 0.0052, 0.0115, 0.0098, 0.0240, 0.0232, 0.0404, 0.0461, 0.1192,
        0.1012, 0.2940, 0.2898], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,653][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0159, 0.0035, 0.0800, 0.0046, 0.0220, 0.0968, 0.2272, 0.0106, 0.1534,
        0.0063, 0.0280, 0.3516], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,654][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1892, 0.0495, 0.1079, 0.0510, 0.0541, 0.1032, 0.0879, 0.0629, 0.0849,
        0.0505, 0.0704, 0.0885], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,656][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1717, 0.0521, 0.1099, 0.0526, 0.0380, 0.1022, 0.1094, 0.0513, 0.0719,
        0.0421, 0.0397, 0.1591], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,658][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1914, 0.0667, 0.0838, 0.0688, 0.0660, 0.0928, 0.0504, 0.0518, 0.0958,
        0.0712, 0.0921, 0.0691], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,659][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.1775, 0.0691, 0.1210, 0.0999, 0.0165, 0.1120, 0.0545, 0.0905, 0.0776,
        0.0886, 0.0197, 0.0489, 0.0240], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,661][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([2.9195e-04, 1.2179e-02, 2.8737e-04, 9.2038e-03, 6.2881e-04, 1.5386e-04,
        7.2789e-05, 1.5602e-04, 1.5883e-04, 5.4001e-03, 1.0214e-03, 9.7854e-05,
        9.7035e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,663][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.2186, 0.0933, 0.0791, 0.0646, 0.1005, 0.0480, 0.0850, 0.0691, 0.0294,
        0.0536, 0.0722, 0.0687, 0.0178], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,664][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([1.0434e-03, 7.9251e-06, 6.5413e-07, 3.9981e-05, 6.4663e-05, 3.0931e-06,
        2.1794e-06, 5.5350e-04, 1.7014e-05, 1.3293e-03, 2.8193e-03, 8.4084e-05,
        9.9403e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,665][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([2.3148e-02, 6.5553e-03, 4.7484e-04, 6.6315e-03, 4.9350e-03, 7.8837e-04,
        1.2255e-03, 4.2925e-03, 2.1299e-03, 2.4809e-02, 3.7414e-02, 3.3060e-03,
        8.8429e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,667][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([2.2825e-05, 5.1351e-06, 1.5531e-09, 2.3891e-07, 1.7650e-07, 7.5640e-11,
        5.9342e-11, 1.7025e-07, 1.7791e-10, 5.7061e-08, 8.0127e-09, 6.4064e-11,
        9.9997e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,669][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.1253, 0.0862, 0.0748, 0.1504, 0.0169, 0.0152, 0.0533, 0.1043, 0.0626,
        0.1397, 0.0149, 0.0573, 0.0991], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,671][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.0414, 0.0261, 0.0219, 0.0063, 0.0213, 0.0453, 0.0477, 0.0106, 0.1220,
        0.0348, 0.2271, 0.3446, 0.0508], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,672][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.2173, 0.0665, 0.0586, 0.0550, 0.0474, 0.0386, 0.0473, 0.0532, 0.0391,
        0.0464, 0.0425, 0.0415, 0.2465], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,674][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.2010, 0.0813, 0.0928, 0.0408, 0.0521, 0.0783, 0.0715, 0.0972, 0.0794,
        0.0384, 0.0839, 0.0752, 0.0081], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,674][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.1448, 0.0758, 0.0943, 0.0491, 0.0549, 0.0716, 0.0465, 0.0476, 0.0618,
        0.0360, 0.0457, 0.0474, 0.2244], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,675][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.0818, 0.0734, 0.0731, 0.0418, 0.0762, 0.0844, 0.0705, 0.0378, 0.0944,
        0.0476, 0.1215, 0.1134, 0.0842], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,676][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1975, 0.0384, 0.0208, 0.0552, 0.1162, 0.0112, 0.0252, 0.0796, 0.0220,
        0.0720, 0.1246, 0.0252, 0.1971, 0.0149], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:36,677][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.8457e-03, 1.0106e-04, 2.1803e-02, 4.8456e-05, 2.6970e-04, 4.6079e-01,
        1.1719e-03, 2.5527e-05, 4.8525e-03, 2.7403e-05, 3.8294e-04, 7.0105e-04,
        8.8118e-06, 5.0697e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:36,678][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1957, 0.0247, 0.0967, 0.0429, 0.0540, 0.1467, 0.0286, 0.0295, 0.0578,
        0.0404, 0.0665, 0.0257, 0.0220, 0.1687], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:36,680][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([4.1733e-03, 1.2287e-04, 1.9985e-04, 1.6645e-04, 2.9067e-03, 2.0498e-03,
        2.5537e-03, 7.8336e-04, 6.8020e-03, 5.1351e-03, 2.5736e-01, 7.1689e-02,
        5.8197e-02, 5.8787e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:36,682][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0367, 0.0029, 0.0032, 0.0033, 0.0611, 0.0119, 0.0072, 0.0136, 0.0105,
        0.0183, 0.3386, 0.0759, 0.1835, 0.2334], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:36,683][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.1940e-02, 1.1027e-02, 6.1812e-02, 2.2591e-03, 8.7790e-03, 3.8188e-01,
        1.4173e-01, 1.2740e-03, 1.3804e-02, 1.0021e-03, 4.3741e-03, 9.6299e-02,
        2.6297e-04, 2.5356e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:36,685][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1081, 0.0809, 0.0048, 0.0512, 0.0320, 0.1434, 0.0030, 0.0524, 0.0037,
        0.0744, 0.0490, 0.0052, 0.1297, 0.2621], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:36,687][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0257, 0.0039, 0.0061, 0.0086, 0.0122, 0.0085, 0.0190, 0.0186, 0.0486,
        0.0720, 0.1179, 0.1603, 0.2152, 0.2833], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:36,689][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0133, 0.0031, 0.0879, 0.0029, 0.0195, 0.1199, 0.1620, 0.0120, 0.1383,
        0.0038, 0.0188, 0.1900, 0.0089, 0.2196], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:36,690][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1560, 0.0421, 0.0893, 0.0499, 0.0476, 0.0853, 0.0762, 0.0483, 0.0713,
        0.0504, 0.0630, 0.0810, 0.0389, 0.1008], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:36,693][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1256, 0.0334, 0.1080, 0.0363, 0.0668, 0.1209, 0.0841, 0.0405, 0.0771,
        0.0301, 0.0593, 0.0827, 0.0230, 0.1122], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:36,695][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1656, 0.0575, 0.0754, 0.0591, 0.0619, 0.0746, 0.0363, 0.0409, 0.0786,
        0.0584, 0.0832, 0.0485, 0.0829, 0.0771], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:36,698][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:16:36,708][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 1455],
        [    1],
        [10683],
        [   17],
        [ 9142],
        [ 6898],
        [14498],
        [18841],
        [ 2403],
        [   14],
        [ 8282],
        [13198],
        [17108],
        [ 5421]], device='cuda:0')
[2024-07-24 10:16:36,711][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[35333],
        [    1],
        [20655],
        [   48],
        [40427],
        [28052],
        [12098],
        [25046],
        [20039],
        [   63],
        [20175],
        [12424],
        [17157],
        [23672]], device='cuda:0')
[2024-07-24 10:16:36,713][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 5914],
        [ 2276],
        [ 2776],
        [ 3574],
        [13579],
        [12921],
        [ 6975],
        [ 5955],
        [ 5564],
        [ 8983],
        [20698],
        [ 7211],
        [ 8174],
        [ 4087]], device='cuda:0')
[2024-07-24 10:16:36,714][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[42295],
        [ 5627],
        [31440],
        [ 6422],
        [20413],
        [30808],
        [47704],
        [16690],
        [ 9115],
        [ 6421],
        [17246],
        [40836],
        [39205],
        [30528]], device='cuda:0')
[2024-07-24 10:16:36,716][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[17594],
        [15051],
        [37023],
        [17018],
        [24992],
        [32239],
        [30740],
        [27825],
        [22527],
        [18497],
        [26294],
        [30405],
        [21054],
        [31862]], device='cuda:0')
[2024-07-24 10:16:36,718][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[26817],
        [ 8766],
        [31180],
        [ 5344],
        [29582],
        [26189],
        [21417],
        [29137],
        [27278],
        [ 2546],
        [30722],
        [12950],
        [27267],
        [19044]], device='cuda:0')
[2024-07-24 10:16:36,720][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 6908],
        [  144],
        [ 4344],
        [ 3121],
        [ 8078],
        [13321],
        [11139],
        [14720],
        [ 9953],
        [ 5284],
        [14926],
        [21232],
        [23090],
        [24482]], device='cuda:0')
[2024-07-24 10:16:36,721][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[37392],
        [ 8232],
        [26367],
        [15648],
        [30798],
        [23338],
        [28181],
        [37970],
        [27891],
        [15311],
        [39370],
        [25757],
        [15748],
        [23134]], device='cuda:0')
[2024-07-24 10:16:36,723][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[34365],
        [ 3062],
        [ 3041],
        [  401],
        [  546],
        [ 6068],
        [  532],
        [ 6302],
        [ 3116],
        [  551],
        [  732],
        [ 1289],
        [ 1805],
        [ 6092]], device='cuda:0')
[2024-07-24 10:16:36,724][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 8627],
        [ 7676],
        [ 5412],
        [ 4280],
        [ 7727],
        [16633],
        [20345],
        [23633],
        [ 7006],
        [ 4670],
        [ 4992],
        [23036],
        [25703],
        [20752]], device='cuda:0')
[2024-07-24 10:16:36,726][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 6761],
        [12064],
        [ 1135],
        [ 9182],
        [ 2154],
        [ 1262],
        [ 1739],
        [ 3071],
        [ 1414],
        [ 6152],
        [ 1223],
        [ 2405],
        [36463],
        [ 1804]], device='cuda:0')
[2024-07-24 10:16:36,727][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[24254],
        [22570],
        [18603],
        [16848],
        [14081],
        [17725],
        [17248],
        [11877],
        [16149],
        [15825],
        [13909],
        [15451],
        [13203],
        [15568]], device='cuda:0')
[2024-07-24 10:16:36,729][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[16571],
        [28934],
        [19938],
        [35402],
        [26777],
        [22159],
        [33042],
        [36811],
        [29352],
        [41883],
        [34422],
        [38666],
        [37029],
        [30901]], device='cuda:0')
[2024-07-24 10:16:36,730][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[35312],
        [31968],
        [22541],
        [17941],
        [17919],
        [12625],
        [15418],
        [15866],
        [13457],
        [ 9787],
        [12078],
        [ 8712],
        [ 6606],
        [ 8580]], device='cuda:0')
[2024-07-24 10:16:36,732][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 6782],
        [    4],
        [24127],
        [  925],
        [48076],
        [12668],
        [26075],
        [32979],
        [10090],
        [  755],
        [43949],
        [36618],
        [37787],
        [11918]], device='cuda:0')
[2024-07-24 10:16:36,734][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[45925],
        [44969],
        [42895],
        [28169],
        [22622],
        [24493],
        [27660],
        [25998],
        [25199],
        [22785],
        [16831],
        [22321],
        [23990],
        [19867]], device='cuda:0')
[2024-07-24 10:16:36,735][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 4551],
        [37234],
        [ 7830],
        [35862],
        [35962],
        [ 6652],
        [ 4836],
        [24537],
        [13862],
        [36197],
        [28346],
        [ 3963],
        [16689],
        [ 6114]], device='cuda:0')
[2024-07-24 10:16:36,737][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[34909],
        [35345],
        [39638],
        [36457],
        [37371],
        [26092],
        [25600],
        [33143],
        [17001],
        [33284],
        [31169],
        [26623],
        [35839],
        [20145]], device='cuda:0')
[2024-07-24 10:16:36,739][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[12138],
        [15130],
        [23730],
        [ 9152],
        [14797],
        [28618],
        [32445],
        [12120],
        [36799],
        [16848],
        [26795],
        [35624],
        [15121],
        [34436]], device='cuda:0')
[2024-07-24 10:16:36,740][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[19672],
        [31949],
        [23964],
        [30761],
        [21552],
        [19668],
        [23298],
        [24906],
        [30344],
        [23369],
        [30138],
        [30797],
        [21064],
        [34497]], device='cuda:0')
[2024-07-24 10:16:36,742][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[22628],
        [ 4286],
        [12009],
        [ 6074],
        [ 6424],
        [12677],
        [ 4916],
        [11141],
        [ 8109],
        [ 6409],
        [ 1643],
        [ 6624],
        [17647],
        [11609]], device='cuda:0')
[2024-07-24 10:16:36,744][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[40841],
        [ 7760],
        [ 7115],
        [ 3523],
        [ 8276],
        [13646],
        [ 7511],
        [41142],
        [35298],
        [ 8042],
        [19509],
        [28838],
        [17692],
        [27852]], device='cuda:0')
[2024-07-24 10:16:36,746][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[13032],
        [11840],
        [ 9257],
        [ 9946],
        [ 6872],
        [ 2537],
        [10053],
        [10256],
        [ 5531],
        [ 8657],
        [10840],
        [ 8186],
        [ 7929],
        [ 4429]], device='cuda:0')
[2024-07-24 10:16:36,748][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[15403],
        [27244],
        [10253],
        [30446],
        [18437],
        [ 7941],
        [ 5418],
        [17108],
        [ 4422],
        [23386],
        [10742],
        [ 6928],
        [25650],
        [ 6906]], device='cuda:0')
[2024-07-24 10:16:36,749][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[34798],
        [34928],
        [34711],
        [34811],
        [38543],
        [37827],
        [37926],
        [36824],
        [36838],
        [36315],
        [39443],
        [39335],
        [39279],
        [38950]], device='cuda:0')
[2024-07-24 10:16:36,750][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[46042],
        [42048],
        [48391],
        [43525],
        [45030],
        [48622],
        [48137],
        [45218],
        [48034],
        [42397],
        [45735],
        [47508],
        [44459],
        [47821]], device='cuda:0')
[2024-07-24 10:16:36,752][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 8764],
        [10332],
        [ 5993],
        [19214],
        [20667],
        [24701],
        [18068],
        [32283],
        [26995],
        [31154],
        [26660],
        [25914],
        [21706],
        [23419]], device='cuda:0')
[2024-07-24 10:16:36,753][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 5686],
        [10615],
        [10890],
        [12249],
        [12007],
        [11773],
        [13192],
        [ 7920],
        [ 8966],
        [11966],
        [11148],
        [10782],
        [ 9993],
        [12209]], device='cuda:0')
[2024-07-24 10:16:36,755][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[35492],
        [50249],
        [19400],
        [47905],
        [ 1499],
        [31094],
        [17165],
        [13017],
        [33490],
        [48292],
        [ 4187],
        [ 8676],
        [ 8813],
        [31602]], device='cuda:0')
[2024-07-24 10:16:36,756][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[19016],
        [19016],
        [19016],
        [19016],
        [19016],
        [19016],
        [19016],
        [19016],
        [19016],
        [19016],
        [19016],
        [19016],
        [19016],
        [19016]], device='cuda:0')
[2024-07-24 10:16:36,777][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:36,778][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,779][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,779][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,780][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,781][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,782][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,783][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,785][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,786][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,787][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,789][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,791][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:36,797][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.1250, 0.8750], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,799][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.9499, 0.0501], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,799][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.5966, 0.4034], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,800][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.4472, 0.5528], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,801][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.9573, 0.0427], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,802][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.5592, 0.4408], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,802][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.9627, 0.0373], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,803][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.8595, 0.1405], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,805][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.9826, 0.0174], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,806][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([1.0000e+00, 4.4450e-06], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,807][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.1801, 0.8199], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,809][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.1641, 0.8359], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:36,811][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0068, 0.9842, 0.0090], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,813][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.6810, 0.0760, 0.2431], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,814][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4323, 0.2713, 0.2963], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,816][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3515, 0.3039, 0.3446], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,818][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.7735, 0.0883, 0.1382], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,820][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0273, 0.0314, 0.9412], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,821][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3925, 0.0254, 0.5821], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,822][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.6586, 0.1947, 0.1467], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,823][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.8563, 0.0155, 0.1282], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,823][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([9.9701e-01, 6.5785e-05, 2.9248e-03], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,824][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1119, 0.5405, 0.3476], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,825][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.3399, 0.0009, 0.6592], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:36,826][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Jonathan] are: tensor([0.0394, 0.4894, 0.0668, 0.4045], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,827][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Jonathan] are: tensor([0.5343, 0.0405, 0.3882, 0.0370], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,829][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Jonathan] are: tensor([0.3391, 0.2148, 0.2336, 0.2124], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,831][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Jonathan] are: tensor([0.2684, 0.2365, 0.2687, 0.2264], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,833][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Jonathan] are: tensor([0.7095, 0.0584, 0.1518, 0.0804], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,834][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Jonathan] are: tensor([0.0167, 0.1729, 0.0028, 0.8076], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,836][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Jonathan] are: tensor([0.4987, 0.0169, 0.4586, 0.0257], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,838][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Jonathan] are: tensor([0.5169, 0.2327, 0.1440, 0.1064], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,840][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Jonathan] are: tensor([0.7967, 0.0185, 0.1430, 0.0418], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,841][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Jonathan] are: tensor([9.9924e-01, 2.1307e-05, 3.3023e-04, 4.0472e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,843][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Jonathan] are: tensor([0.0889, 0.3790, 0.2587, 0.2734], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,844][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Jonathan] are: tensor([0.0032, 0.0051, 0.0085, 0.9832], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:36,845][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0551, 0.0932, 0.0282, 0.3494, 0.4741], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,846][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.5605, 0.0346, 0.2604, 0.0349, 0.1096], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,847][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.2858, 0.1719, 0.1872, 0.1693, 0.1859], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,847][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.1952, 0.1704, 0.1963, 0.1773, 0.2608], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,848][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.5115, 0.0680, 0.1435, 0.1099, 0.1672], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,850][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0779, 0.1138, 0.0181, 0.1407, 0.6494], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,852][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.2825, 0.0144, 0.4777, 0.0370, 0.1884], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,853][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.5056, 0.1504, 0.1149, 0.1356, 0.0934], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,855][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.6845, 0.0282, 0.1312, 0.0455, 0.1105], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,856][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ went] are: tensor([9.9964e-01, 1.9440e-05, 9.5712e-05, 2.3493e-04, 7.3218e-06],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,858][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0615, 0.2828, 0.1862, 0.2060, 0.2635], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,860][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ went] are: tensor([2.2628e-03, 1.7139e-05, 1.1324e-02, 9.4312e-05, 9.8630e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:36,861][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([7.4398e-04, 2.1269e-02, 1.6054e-04, 1.5806e-02, 9.6201e-01, 1.5174e-05],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,863][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.3009, 0.0550, 0.2293, 0.0413, 0.0983, 0.2751], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,865][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2372, 0.1440, 0.1569, 0.1420, 0.1565, 0.1635], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,866][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1840, 0.1404, 0.1548, 0.1363, 0.2051, 0.1794], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,867][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.3310, 0.0610, 0.1182, 0.0963, 0.1504, 0.2431], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,868][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.2653, 0.1911, 0.2031, 0.1972, 0.1101, 0.0333], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,869][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0897, 0.0122, 0.1837, 0.0267, 0.1020, 0.5858], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,869][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.4102, 0.1276, 0.0975, 0.1228, 0.1154, 0.1264], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,870][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.6256, 0.0359, 0.0920, 0.0496, 0.0753, 0.1216], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,871][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([8.5322e-01, 5.6326e-06, 1.0351e-04, 1.3258e-04, 1.3887e-07, 1.4654e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,873][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0517, 0.2393, 0.1543, 0.1766, 0.2231, 0.1550], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,874][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.2100e-01, 6.0841e-04, 1.7535e-01, 2.1355e-03, 1.4965e-03, 6.9941e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:36,876][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0245, 0.0398, 0.0203, 0.3709, 0.3979, 0.1112, 0.0354],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,877][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.3747, 0.0347, 0.0943, 0.0247, 0.0486, 0.2108, 0.2121],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,879][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.2058, 0.1252, 0.1369, 0.1241, 0.1366, 0.1419, 0.1294],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,881][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1504, 0.1147, 0.1272, 0.1132, 0.1731, 0.1484, 0.1731],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,883][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2539, 0.0513, 0.1018, 0.0702, 0.1252, 0.1914, 0.2062],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,884][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ the] are: tensor([3.6501e-02, 3.4454e-01, 2.5396e-01, 1.5609e-01, 3.4145e-02, 6.2874e-05,
        1.7470e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,886][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0650, 0.0096, 0.1443, 0.0223, 0.0767, 0.4397, 0.2423],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,888][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.3414, 0.1005, 0.0687, 0.1006, 0.1298, 0.0898, 0.1692],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,889][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.4425, 0.0353, 0.0882, 0.0411, 0.0603, 0.1166, 0.2160],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,890][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ the] are: tensor([7.8897e-01, 2.4022e-05, 3.8336e-04, 9.6454e-04, 5.0103e-06, 1.5668e-01,
        5.2972e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,890][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0457, 0.2091, 0.1362, 0.1536, 0.1933, 0.1332, 0.1289],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,891][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ the] are: tensor([3.1627e-02, 4.5149e-04, 4.9043e-02, 4.0818e-03, 3.7051e-03, 2.6979e-02,
        8.8411e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:36,892][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.0006, 0.0792, 0.0051, 0.3364, 0.4037, 0.0068, 0.0569, 0.1113],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,893][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([0.1616, 0.0259, 0.1465, 0.0253, 0.0898, 0.1357, 0.3007, 0.1145],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,895][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.1912, 0.1078, 0.1187, 0.1066, 0.1170, 0.1226, 0.1109, 0.1252],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,897][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.1331, 0.1039, 0.1253, 0.1004, 0.1531, 0.1547, 0.1611, 0.0684],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,898][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.2778, 0.0523, 0.0863, 0.0658, 0.1059, 0.1521, 0.1442, 0.1157],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,899][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([6.4910e-04, 1.2695e-03, 8.8621e-04, 1.2710e-03, 3.7240e-03, 1.1567e-05,
        1.0470e-02, 9.8172e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,901][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.0775, 0.0040, 0.1194, 0.0067, 0.0383, 0.3740, 0.2458, 0.1343],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,903][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.2830, 0.1285, 0.0537, 0.1573, 0.0895, 0.0883, 0.1577, 0.0420],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,905][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.3654, 0.0207, 0.0998, 0.0386, 0.0747, 0.0920, 0.2750, 0.0338],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,906][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([9.0498e-01, 7.9940e-05, 5.1609e-04, 1.0240e-03, 1.6334e-05, 6.0513e-02,
        3.2018e-02, 8.5796e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,908][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.0382, 0.1773, 0.1151, 0.1273, 0.1599, 0.1123, 0.1049, 0.1650],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,910][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([1.2717e-02, 1.0143e-03, 2.5409e-02, 1.7825e-04, 2.7626e-03, 1.3454e-02,
        1.4216e-03, 9.4304e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:36,911][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0246, 0.1293, 0.0097, 0.3116, 0.1424, 0.0249, 0.0591, 0.2917, 0.0067],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,912][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.2959, 0.0234, 0.0827, 0.0235, 0.0369, 0.1051, 0.2132, 0.1287, 0.0906],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,912][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1639, 0.0960, 0.1056, 0.0953, 0.1050, 0.1095, 0.0995, 0.1125, 0.1126],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,913][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1465, 0.0873, 0.1050, 0.0878, 0.1371, 0.1208, 0.1367, 0.0600, 0.1188],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,914][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1872, 0.0403, 0.0731, 0.0531, 0.0971, 0.1263, 0.1253, 0.1146, 0.1830],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,915][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([3.0761e-02, 5.7100e-02, 4.6976e-01, 7.2171e-02, 5.2805e-02, 1.6101e-05,
        2.3132e-01, 6.9689e-02, 1.6377e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,917][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0387, 0.0051, 0.0793, 0.0138, 0.0485, 0.2604, 0.1631, 0.1826, 0.2086],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,919][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2718, 0.0784, 0.0591, 0.0853, 0.0790, 0.0745, 0.1089, 0.1391, 0.1040],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,920][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3710, 0.0243, 0.1447, 0.0310, 0.0568, 0.0892, 0.1611, 0.0451, 0.0769],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,921][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([7.6963e-01, 4.2239e-06, 2.6266e-04, 1.4784e-04, 8.5893e-08, 2.2697e-01,
        2.8159e-03, 1.3853e-05, 1.5118e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,924][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0336, 0.1557, 0.1023, 0.1143, 0.1486, 0.1002, 0.0939, 0.1566, 0.0947],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,925][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2120, 0.0452, 0.1945, 0.0656, 0.0365, 0.0872, 0.0648, 0.0796, 0.2145],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:36,927][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Jonathan] are: tensor([0.0147, 0.1966, 0.0282, 0.1355, 0.1058, 0.0280, 0.1072, 0.1296, 0.0952,
        0.1592], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,929][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Jonathan] are: tensor([0.1699, 0.0135, 0.0988, 0.0106, 0.0630, 0.1243, 0.2380, 0.1213, 0.1396,
        0.0211], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,931][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Jonathan] are: tensor([0.1503, 0.0877, 0.0959, 0.0871, 0.0949, 0.0988, 0.0900, 0.1029, 0.1022,
        0.0902], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,933][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Jonathan] are: tensor([0.1258, 0.0813, 0.1024, 0.0778, 0.1306, 0.1204, 0.1294, 0.0605, 0.1117,
        0.0602], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,934][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Jonathan] are: tensor([0.2298, 0.0322, 0.0806, 0.0374, 0.0701, 0.1213, 0.1163, 0.0664, 0.1904,
        0.0554], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,934][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Jonathan] are: tensor([8.1877e-03, 9.2509e-02, 1.6681e-03, 4.3391e-01, 1.1657e-02, 7.1096e-05,
        1.1797e-02, 6.3740e-04, 5.8243e-04, 4.3898e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,935][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Jonathan] are: tensor([0.0666, 0.0029, 0.0767, 0.0058, 0.0241, 0.2703, 0.1981, 0.1184, 0.2260,
        0.0110], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,936][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Jonathan] are: tensor([0.1532, 0.0798, 0.0438, 0.0358, 0.0716, 0.0848, 0.1201, 0.1791, 0.2055,
        0.0262], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,937][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Jonathan] are: tensor([0.3440, 0.0053, 0.0479, 0.0115, 0.0634, 0.0792, 0.2062, 0.0422, 0.1831,
        0.0172], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,939][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Jonathan] are: tensor([9.2636e-01, 3.3998e-05, 4.6044e-04, 5.0750e-04, 4.1100e-06, 6.2966e-02,
        8.1060e-03, 3.4483e-04, 2.3307e-04, 9.8638e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,941][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Jonathan] are: tensor([0.0336, 0.1388, 0.0949, 0.1008, 0.1294, 0.0936, 0.0868, 0.1345, 0.0876,
        0.1000], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,942][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Jonathan] are: tensor([4.5292e-05, 3.5753e-03, 3.8524e-04, 3.9354e-01, 1.9896e-05, 3.6634e-04,
        1.0988e-04, 1.8295e-05, 5.0589e-02, 5.5135e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:36,943][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0023, 0.0205, 0.0065, 0.0640, 0.6251, 0.0160, 0.0227, 0.0938, 0.0197,
        0.0745, 0.0549], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,945][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.1425, 0.0157, 0.1216, 0.0104, 0.0570, 0.1117, 0.2064, 0.1177, 0.1024,
        0.0166, 0.0980], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,947][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.1371, 0.0800, 0.0873, 0.0792, 0.0870, 0.0906, 0.0823, 0.0939, 0.0933,
        0.0819, 0.0873], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,949][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.1174, 0.0697, 0.0891, 0.0723, 0.1077, 0.1044, 0.1142, 0.0522, 0.1046,
        0.0567, 0.1117], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,952][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1767, 0.0296, 0.0655, 0.0418, 0.0703, 0.1117, 0.1009, 0.0725, 0.1636,
        0.0641, 0.1033], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,953][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([5.0755e-02, 1.5776e-01, 1.4527e-02, 2.0380e-01, 2.0934e-01, 4.6447e-05,
        3.0016e-02, 5.2470e-02, 1.2013e-03, 2.0268e-01, 7.7409e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,955][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0321, 0.0026, 0.0612, 0.0066, 0.0288, 0.2508, 0.1618, 0.1611, 0.1952,
        0.0121, 0.0878], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,955][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.1960, 0.0642, 0.0551, 0.0627, 0.0599, 0.0753, 0.1068, 0.1436, 0.1336,
        0.0472, 0.0556], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,956][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.3392, 0.0133, 0.0849, 0.0219, 0.0573, 0.0816, 0.1754, 0.0314, 0.0993,
        0.0280, 0.0678], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,957][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([7.6723e-01, 1.6213e-05, 1.0229e-04, 2.6221e-04, 8.5210e-07, 1.6664e-01,
        6.5077e-02, 1.9083e-05, 1.6874e-04, 4.5741e-04, 2.7819e-05],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,958][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0276, 0.1237, 0.0812, 0.0918, 0.1187, 0.0805, 0.0744, 0.1243, 0.0762,
        0.0918, 0.1099], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,959][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([4.8003e-03, 5.7254e-04, 7.7038e-03, 1.0626e-03, 1.5736e-03, 2.9261e-03,
        1.5655e-04, 2.2519e-03, 1.4533e-02, 1.4040e-04, 9.6428e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:36,961][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0023, 0.0140, 0.0051, 0.0933, 0.4074, 0.0116, 0.0378, 0.0203, 0.0168,
        0.1214, 0.2443, 0.0257], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,963][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1875, 0.0166, 0.0588, 0.0117, 0.0240, 0.1032, 0.1785, 0.0834, 0.1299,
        0.0219, 0.0565, 0.1280], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,964][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1257, 0.0732, 0.0803, 0.0726, 0.0799, 0.0830, 0.0752, 0.0862, 0.0854,
        0.0753, 0.0803, 0.0828], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,966][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1166, 0.0666, 0.0797, 0.0636, 0.1000, 0.0907, 0.1065, 0.0457, 0.0916,
        0.0475, 0.1007, 0.0909], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,968][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1065, 0.0220, 0.0534, 0.0304, 0.0565, 0.1011, 0.1065, 0.0799, 0.1574,
        0.0510, 0.1029, 0.1322], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,969][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([3.2622e-02, 1.6385e-01, 2.9689e-01, 2.7400e-02, 4.1002e-02, 9.1425e-05,
        1.0922e-01, 2.3194e-01, 5.6776e-03, 2.5411e-02, 2.2963e-02, 4.2934e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,971][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0212, 0.0041, 0.0560, 0.0115, 0.0353, 0.1933, 0.1063, 0.1725, 0.1618,
        0.0160, 0.1030, 0.1189], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,974][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.2051, 0.0602, 0.0434, 0.0487, 0.0545, 0.0653, 0.0936, 0.0944, 0.1133,
        0.0375, 0.0685, 0.1155], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,975][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2922, 0.0217, 0.0717, 0.0241, 0.0407, 0.0839, 0.1632, 0.0443, 0.0658,
        0.0309, 0.0495, 0.1121], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,977][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([6.7299e-01, 1.3527e-05, 1.5871e-04, 3.4112e-04, 1.4305e-06, 2.0336e-01,
        1.8354e-02, 1.8455e-05, 2.5517e-04, 6.0225e-04, 3.9721e-05, 1.0387e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,977][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0256, 0.1155, 0.0753, 0.0851, 0.1073, 0.0734, 0.0701, 0.1155, 0.0701,
        0.0853, 0.1031, 0.0737], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,978][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([5.5149e-03, 1.1488e-04, 4.4942e-03, 4.1397e-04, 1.8722e-03, 9.2557e-03,
        1.7043e-03, 3.8419e-03, 2.1684e-02, 1.6121e-04, 3.0110e-04, 9.5064e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:36,979][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.0003, 0.0114, 0.0011, 0.0684, 0.1118, 0.0026, 0.0253, 0.2650, 0.0031,
        0.0851, 0.3044, 0.0599, 0.0615], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,980][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.0655, 0.0131, 0.0705, 0.0088, 0.0569, 0.0759, 0.1773, 0.0968, 0.0688,
        0.0163, 0.1428, 0.1621, 0.0451], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,981][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.1202, 0.0677, 0.0742, 0.0671, 0.0733, 0.0758, 0.0685, 0.0791, 0.0780,
        0.0689, 0.0728, 0.0749, 0.0796], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,983][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.1179, 0.0556, 0.0805, 0.0544, 0.0945, 0.0976, 0.1023, 0.0348, 0.0972,
        0.0432, 0.1036, 0.0900, 0.0284], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,985][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.1317, 0.0291, 0.0585, 0.0350, 0.0533, 0.0919, 0.0811, 0.0542, 0.1457,
        0.0520, 0.0954, 0.0986, 0.0734], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,986][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([1.2726e-04, 2.0008e-02, 3.4393e-04, 3.2284e-02, 5.8986e-03, 2.8572e-06,
        5.5763e-03, 4.4104e-01, 1.2379e-04, 3.4952e-02, 1.1866e-03, 8.7142e-04,
        4.5759e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,988][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.0469, 0.0025, 0.0632, 0.0050, 0.0200, 0.2034, 0.1407, 0.0879, 0.1668,
        0.0090, 0.0583, 0.1511, 0.0453], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,990][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.1636, 0.0438, 0.0412, 0.0564, 0.1039, 0.0612, 0.0806, 0.0971, 0.0867,
        0.0442, 0.0937, 0.1119, 0.0156], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,992][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.2050, 0.0049, 0.0472, 0.0115, 0.0511, 0.0636, 0.2020, 0.0312, 0.1345,
        0.0221, 0.0611, 0.1375, 0.0282], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,993][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([7.1245e-01, 8.5362e-06, 4.5792e-04, 2.3869e-04, 1.0541e-06, 1.0503e-01,
        1.3057e-02, 5.7755e-05, 3.3628e-04, 4.6999e-04, 4.1926e-05, 1.6785e-01,
        4.7122e-07], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,996][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.0258, 0.1037, 0.0720, 0.0759, 0.0972, 0.0682, 0.0634, 0.1018, 0.0660,
        0.0751, 0.0915, 0.0663, 0.0930], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,997][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([8.2489e-03, 8.5797e-04, 1.7264e-02, 7.7239e-04, 4.6173e-04, 6.5971e-03,
        1.7005e-03, 3.6809e-03, 1.5160e-02, 5.8145e-05, 6.4693e-04, 7.8132e-04,
        9.4377e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:36,998][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([5.5530e-04, 1.3370e-02, 1.1667e-04, 9.5633e-03, 7.1134e-01, 8.5947e-06,
        1.2090e-03, 5.0753e-03, 6.3586e-04, 1.1967e-02, 2.1475e-01, 5.5729e-03,
        2.5831e-02, 7.7636e-06], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:36,999][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0818, 0.0137, 0.0575, 0.0092, 0.0216, 0.0644, 0.1448, 0.0747, 0.1057,
        0.0174, 0.0553, 0.1849, 0.0464, 0.1228], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,000][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1085, 0.0619, 0.0681, 0.0614, 0.0674, 0.0706, 0.0640, 0.0726, 0.0728,
        0.0636, 0.0682, 0.0705, 0.0735, 0.0769], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,001][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1113, 0.0535, 0.0758, 0.0524, 0.0926, 0.0906, 0.1033, 0.0386, 0.0902,
        0.0398, 0.0929, 0.0851, 0.0262, 0.0476], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,002][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0854, 0.0182, 0.0406, 0.0274, 0.0448, 0.0819, 0.0751, 0.0570, 0.1150,
        0.0449, 0.0894, 0.1027, 0.0746, 0.1429], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,003][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([4.1817e-02, 3.9178e-02, 3.4600e-02, 4.2235e-02, 2.3295e-02, 8.5705e-03,
        1.1857e-02, 1.1406e-01, 1.2558e-04, 4.2092e-02, 4.3480e-03, 2.2230e-03,
        6.2202e-01, 1.3579e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,005][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0156, 0.0037, 0.0427, 0.0116, 0.0306, 0.1421, 0.0786, 0.1534, 0.1225,
        0.0155, 0.0815, 0.0885, 0.0610, 0.1528], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,007][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1515, 0.0450, 0.0367, 0.0408, 0.0452, 0.0517, 0.0640, 0.0843, 0.1016,
        0.0304, 0.0598, 0.0873, 0.1183, 0.0833], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,009][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2578, 0.0198, 0.0636, 0.0238, 0.0375, 0.0810, 0.1368, 0.0444, 0.0561,
        0.0322, 0.0459, 0.1040, 0.0323, 0.0648], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,010][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([6.9938e-01, 4.6427e-06, 5.0222e-05, 1.4138e-04, 1.1358e-07, 1.1385e-01,
        1.0295e-02, 9.3370e-06, 5.5952e-05, 2.6195e-04, 6.4702e-06, 7.8049e-02,
        5.4395e-08, 9.7898e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,012][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0214, 0.0977, 0.0630, 0.0724, 0.0911, 0.0630, 0.0582, 0.0975, 0.0591,
        0.0726, 0.0873, 0.0611, 0.0917, 0.0639], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,013][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.5484e-02, 2.8304e-04, 5.6865e-02, 1.4866e-03, 9.2292e-04, 3.1187e-01,
        1.5414e-03, 5.4893e-03, 8.6120e-02, 7.3382e-04, 9.5092e-04, 4.9336e-03,
        1.1477e-03, 5.0217e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,043][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:37,055][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,055][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,055][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,055][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,056][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,056][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,056][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,057][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,057][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,057][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,058][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,058][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,058][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.4994, 0.5006], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,058][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.3862, 0.6138], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,059][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.8363, 0.1637], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,059][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.4826, 0.5174], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,059][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.5968, 0.4032], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,060][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.1508, 0.8492], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,060][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.4995, 0.5005], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,060][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.4726, 0.5274], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,061][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.4146, 0.5854], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,061][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.4999, 0.5001], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,061][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.4998, 0.5002], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,062][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.0063, 0.9937], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,062][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3332, 0.3339, 0.3329], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,062][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0711, 0.8690, 0.0600], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,063][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.5566, 0.1141, 0.3293], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,064][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3215, 0.5473, 0.1313], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,066][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3785, 0.2847, 0.3367], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,067][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0388, 0.3921, 0.5691], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,069][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.3331, 0.3337, 0.3333], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,071][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.3414, 0.3774, 0.2812], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,072][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2361, 0.1270, 0.6369], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,074][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.3331, 0.3332, 0.3336], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,074][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.3332, 0.3335, 0.3333], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,074][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([1.1437e-02, 1.3262e-05, 9.8855e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,075][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Jonathan] are: tensor([0.2499, 0.2504, 0.2497, 0.2500], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,075][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Jonathan] are: tensor([0.1728, 0.2354, 0.2471, 0.3447], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,075][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Jonathan] are: tensor([0.3985, 0.1208, 0.3370, 0.1438], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,076][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Jonathan] are: tensor([0.3369, 0.3314, 0.1602, 0.1715], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,076][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Jonathan] are: tensor([0.2475, 0.1856, 0.3355, 0.2314], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,076][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Jonathan] are: tensor([1.6542e-03, 1.3631e-01, 3.5974e-05, 8.6200e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,077][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Jonathan] are: tensor([0.2498, 0.2503, 0.2500, 0.2499], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,077][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Jonathan] are: tensor([0.1865, 0.2078, 0.2120, 0.3936], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,077][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Jonathan] are: tensor([0.1860, 0.2617, 0.4489, 0.1033], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,078][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Jonathan] are: tensor([0.2497, 0.2498, 0.2501, 0.2505], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,079][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Jonathan] are: tensor([0.2499, 0.2501, 0.2499, 0.2501], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,080][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Jonathan] are: tensor([2.1684e-05, 1.1925e-04, 8.9368e-04, 9.9897e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,082][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.2000, 0.2004, 0.1998, 0.2000, 0.1998], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,083][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0301, 0.2533, 0.0608, 0.6373, 0.0186], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,084][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.3660, 0.1106, 0.2582, 0.1280, 0.1373], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,086][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.2641, 0.3076, 0.1066, 0.1655, 0.1562], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,088][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.2011, 0.1801, 0.2167, 0.2198, 0.1822], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,089][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([9.7012e-03, 1.1395e-01, 3.5114e-04, 1.8557e-01, 6.9043e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,090][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.1999, 0.2002, 0.2000, 0.2000, 0.1999], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,092][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.1119, 0.1252, 0.1022, 0.2035, 0.4573], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,094][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.2154, 0.1972, 0.4767, 0.0751, 0.0356], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,095][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.1997, 0.1998, 0.2000, 0.2004, 0.2002], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,097][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.1999, 0.2001, 0.2000, 0.2001, 0.1999], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,097][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([1.8113e-03, 3.2919e-06, 1.0251e-01, 2.9116e-04, 8.9538e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,098][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1666, 0.1670, 0.1665, 0.1667, 0.1664, 0.1667], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,098][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0334, 0.1685, 0.1243, 0.5521, 0.1099, 0.0117], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,098][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3102, 0.0829, 0.1710, 0.1092, 0.1073, 0.2194], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,099][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2321, 0.3433, 0.0714, 0.1609, 0.1427, 0.0496], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,099][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2124, 0.1311, 0.1515, 0.2030, 0.1270, 0.1750], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,099][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0514, 0.3887, 0.0075, 0.4409, 0.1028, 0.0088], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,100][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1665, 0.1669, 0.1666, 0.1666, 0.1666, 0.1667], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,100][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0663, 0.0753, 0.0631, 0.1194, 0.2592, 0.4166], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,101][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1063, 0.0775, 0.2806, 0.0371, 0.0157, 0.4828], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,101][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1663, 0.1664, 0.1666, 0.1669, 0.1667, 0.1672], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,101][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1666, 0.1667, 0.1666, 0.1667, 0.1666, 0.1668], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,103][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.2293e-03, 4.1457e-06, 7.1724e-02, 8.5949e-06, 3.8416e-06, 9.2603e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,104][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1428, 0.1432, 0.1427, 0.1429, 0.1427, 0.1429, 0.1428],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,106][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0626, 0.1262, 0.1290, 0.3585, 0.2108, 0.0878, 0.0250],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,107][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.2422, 0.0786, 0.1562, 0.1033, 0.0980, 0.1538, 0.1679],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,108][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.2016, 0.3235, 0.0734, 0.1589, 0.1277, 0.0447, 0.0703],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,110][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1495, 0.1226, 0.1242, 0.1621, 0.1064, 0.1196, 0.2157],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,111][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([4.6593e-03, 6.2277e-01, 8.9788e-03, 2.7880e-01, 2.2567e-02, 6.9748e-06,
        6.2210e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,113][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.1428, 0.1430, 0.1429, 0.1428, 0.1428, 0.1429, 0.1428],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,114][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0529, 0.0592, 0.0534, 0.0945, 0.2319, 0.3698, 0.1382],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,116][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0626, 0.0367, 0.1850, 0.0207, 0.0100, 0.2680, 0.4171],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,118][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1426, 0.1426, 0.1428, 0.1430, 0.1429, 0.1433, 0.1427],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,119][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1428, 0.1429, 0.1428, 0.1429, 0.1428, 0.1429, 0.1429],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,120][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([2.2587e-03, 4.6527e-05, 2.9404e-01, 1.4430e-04, 3.4661e-05, 5.7628e-03,
        6.9771e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,121][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.1250, 0.1253, 0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1250],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,121][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([0.0374, 0.0590, 0.0587, 0.4020, 0.3065, 0.0199, 0.0929, 0.0236],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,121][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([0.2148, 0.0818, 0.1670, 0.0869, 0.0832, 0.1643, 0.1076, 0.0943],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,122][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.2088, 0.2819, 0.0883, 0.1294, 0.1142, 0.0510, 0.0521, 0.0744],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,122][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.1079, 0.1124, 0.1254, 0.1352, 0.0759, 0.1034, 0.1510, 0.1888],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,123][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([2.4407e-05, 6.0750e-04, 6.7538e-06, 6.7578e-04, 1.1049e-03, 1.6833e-06,
        1.5574e-03, 9.9602e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,123][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.1249, 0.1252, 0.1250, 0.1250, 0.1250, 0.1250, 0.1249, 0.1249],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,123][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.0341, 0.0374, 0.0414, 0.0754, 0.1913, 0.3897, 0.1212, 0.1095],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,124][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.0699, 0.0545, 0.1348, 0.0284, 0.0091, 0.3283, 0.3486, 0.0264],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,124][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.1248, 0.1248, 0.1250, 0.1252, 0.1250, 0.1254, 0.1249, 0.1249],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,125][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.1249, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,126][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([1.0173e-03, 5.9834e-04, 1.2524e-01, 1.8449e-05, 6.9332e-05, 1.2429e-02,
        3.1430e-05, 8.6060e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,128][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1111, 0.1113, 0.1110, 0.1111, 0.1110, 0.1112, 0.1110, 0.1111, 0.1111],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,129][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0152, 0.1078, 0.0498, 0.5809, 0.0938, 0.0156, 0.0268, 0.0921, 0.0181],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,131][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1847, 0.0551, 0.1049, 0.0744, 0.0808, 0.1135, 0.0961, 0.0854, 0.2050],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,132][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1970, 0.2552, 0.0680, 0.1322, 0.1187, 0.0446, 0.0476, 0.0815, 0.0553],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,134][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1305, 0.0831, 0.1047, 0.1304, 0.0973, 0.0957, 0.1492, 0.1540, 0.0551],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,135][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([7.5151e-03, 1.5875e-01, 4.2892e-02, 2.9280e-01, 1.0750e-01, 2.4269e-06,
        2.1265e-01, 1.7742e-01, 4.7970e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,137][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1111, 0.1113, 0.1111, 0.1111, 0.1111, 0.1112, 0.1111, 0.1111, 0.1111],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,138][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0479, 0.0529, 0.0374, 0.0706, 0.1373, 0.2238, 0.1036, 0.1260, 0.2004],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,140][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0454, 0.0343, 0.1332, 0.0163, 0.0074, 0.1831, 0.3229, 0.0177, 0.2396],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,142][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1109, 0.1110, 0.1111, 0.1113, 0.1112, 0.1115, 0.1111, 0.1111, 0.1110],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,143][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1110, 0.1111, 0.1111, 0.1112, 0.1110, 0.1112, 0.1111, 0.1112, 0.1111],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,145][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([4.1252e-02, 1.0508e-03, 5.5599e-01, 3.1059e-04, 2.5728e-04, 6.3280e-02,
        6.7013e-03, 6.0908e-04, 3.3055e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,146][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Jonathan] are: tensor([0.1000, 0.1002, 0.0999, 0.1000, 0.0999, 0.1001, 0.1000, 0.1000, 0.1000,
        0.0998], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,148][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Jonathan] are: tensor([0.0552, 0.0729, 0.0704, 0.0953, 0.1640, 0.0513, 0.0833, 0.1971, 0.1205,
        0.0900], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,149][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Jonathan] are: tensor([0.1353, 0.0562, 0.1364, 0.0615, 0.0754, 0.1164, 0.0880, 0.0789, 0.1837,
        0.0680], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,149][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Jonathan] are: tensor([0.1926, 0.1751, 0.0845, 0.0927, 0.1192, 0.0552, 0.0594, 0.0739, 0.0727,
        0.0746], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,149][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Jonathan] are: tensor([0.0955, 0.0757, 0.1373, 0.0924, 0.0671, 0.1035, 0.1466, 0.1124, 0.0669,
        0.1027], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,150][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Jonathan] are: tensor([6.7482e-04, 6.4912e-02, 1.6575e-05, 3.7157e-01, 4.8097e-03, 1.1433e-05,
        2.7843e-03, 3.2202e-04, 5.7045e-06, 5.5489e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,150][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Jonathan] are: tensor([0.1000, 0.1001, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,
        0.0999], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,150][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Jonathan] are: tensor([0.0319, 0.0349, 0.0331, 0.0599, 0.1421, 0.2402, 0.0871, 0.0960, 0.1817,
        0.0930], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,151][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Jonathan] are: tensor([0.0408, 0.0502, 0.1060, 0.0211, 0.0099, 0.2548, 0.2786, 0.0322, 0.1812,
        0.0252], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,151][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Jonathan] are: tensor([0.0998, 0.0999, 0.1000, 0.1002, 0.1001, 0.1004, 0.1000, 0.1000, 0.0999,
        0.0998], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,152][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Jonathan] are: tensor([0.0999, 0.1000, 0.1000, 0.1000, 0.0999, 0.1000, 0.1000, 0.1001, 0.1000,
        0.1000], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,152][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Jonathan] are: tensor([1.5736e-05, 1.0978e-04, 7.2776e-04, 7.6351e-01, 4.5523e-07, 1.1544e-04,
        6.4788e-07, 8.6542e-08, 1.4920e-03, 2.3403e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,153][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0909, 0.0911, 0.0909, 0.0909, 0.0908, 0.0910, 0.0909, 0.0909, 0.0909,
        0.0908, 0.0909], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,155][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0066, 0.0754, 0.0177, 0.3706, 0.0154, 0.0077, 0.0343, 0.0927, 0.0235,
        0.3423, 0.0138], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,157][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.1305, 0.0499, 0.1071, 0.0579, 0.0629, 0.1055, 0.0726, 0.0721, 0.1914,
        0.0653, 0.0848], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,158][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.1810, 0.1503, 0.0661, 0.0947, 0.0964, 0.0490, 0.0437, 0.0694, 0.0661,
        0.0769, 0.1064], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,159][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0835, 0.0737, 0.0863, 0.0980, 0.0802, 0.0819, 0.1164, 0.1549, 0.0520,
        0.1100, 0.0630], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,160][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([5.7075e-03, 1.8151e-01, 1.6598e-04, 2.5933e-01, 1.4126e-01, 4.6270e-06,
        6.0176e-03, 3.4790e-02, 9.8027e-06, 3.2445e-01, 4.6755e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,162][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0909, 0.0910, 0.0909, 0.0909, 0.0909, 0.0909, 0.0909, 0.0909, 0.0909,
        0.0909, 0.0910], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,164][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0273, 0.0309, 0.0264, 0.0502, 0.1076, 0.1909, 0.0802, 0.1001, 0.1348,
        0.0816, 0.1699], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,165][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0508, 0.0273, 0.1321, 0.0127, 0.0068, 0.2115, 0.3087, 0.0173, 0.2126,
        0.0158, 0.0043], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,168][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0908, 0.0908, 0.0909, 0.0911, 0.0910, 0.0912, 0.0909, 0.0909, 0.0908,
        0.0907, 0.0910], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,169][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0909, 0.0909, 0.0909, 0.0909, 0.0908, 0.0909, 0.0909, 0.0910, 0.0909,
        0.0909, 0.0909], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,170][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([6.5967e-03, 3.4384e-04, 2.2922e-01, 8.2458e-03, 1.4486e-04, 2.9921e-02,
        1.0001e-05, 6.1303e-05, 2.3398e-01, 2.6775e-03, 4.8880e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,171][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0833, 0.0835, 0.0833, 0.0834, 0.0832, 0.0834, 0.0833, 0.0834, 0.0833,
        0.0832, 0.0833, 0.0834], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,172][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0320, 0.0758, 0.0338, 0.1630, 0.0556, 0.0336, 0.0828, 0.1279, 0.0664,
        0.1617, 0.1580, 0.0095], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,172][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1122, 0.0441, 0.0879, 0.0544, 0.0490, 0.0920, 0.0857, 0.0773, 0.1675,
        0.0665, 0.0698, 0.0936], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,173][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1519, 0.1978, 0.0491, 0.0993, 0.0812, 0.0353, 0.0483, 0.0646, 0.0493,
        0.0793, 0.0997, 0.0443], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,173][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0915, 0.0643, 0.0815, 0.0803, 0.0522, 0.0771, 0.1309, 0.1347, 0.0488,
        0.0915, 0.0534, 0.0939], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,173][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([5.2986e-03, 3.4416e-01, 1.3824e-02, 5.8511e-02, 4.3695e-02, 1.5168e-05,
        4.5029e-02, 3.7889e-01, 1.0539e-04, 6.7039e-02, 2.0883e-02, 2.2554e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,174][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0833, 0.0834, 0.0833, 0.0833, 0.0833, 0.0834, 0.0833, 0.0833, 0.0833,
        0.0833, 0.0834, 0.0834], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,174][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0211, 0.0235, 0.0203, 0.0406, 0.0952, 0.1745, 0.0671, 0.0734, 0.1197,
        0.0683, 0.1498, 0.1465], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,175][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0434, 0.0214, 0.1279, 0.0108, 0.0059, 0.1661, 0.2824, 0.0124, 0.2101,
        0.0131, 0.0045, 0.1020], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,175][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0832, 0.0832, 0.0833, 0.0835, 0.0834, 0.0836, 0.0833, 0.0833, 0.0832,
        0.0831, 0.0834, 0.0835], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,176][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0833, 0.0834, 0.0833, 0.0834, 0.0833, 0.0834, 0.0833, 0.0834, 0.0833,
        0.0833, 0.0833, 0.0834], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,177][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([4.4534e-04, 9.7023e-06, 1.6283e-02, 2.3890e-05, 1.3977e-05, 3.6028e-03,
        4.3284e-04, 1.6033e-05, 2.3766e-02, 1.2631e-05, 1.6151e-05, 9.5538e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,179][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.0769, 0.0771, 0.0769, 0.0769, 0.0768, 0.0770, 0.0769, 0.0769, 0.0769,
        0.0768, 0.0769, 0.0770, 0.0770], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,181][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.0180, 0.0485, 0.0486, 0.2231, 0.1657, 0.0200, 0.0405, 0.0385, 0.0456,
        0.1787, 0.1112, 0.0484, 0.0133], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,182][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.1076, 0.0470, 0.1079, 0.0491, 0.0538, 0.0948, 0.0612, 0.0598, 0.1673,
        0.0547, 0.0777, 0.0690, 0.0501], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,184][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.1673, 0.1900, 0.0683, 0.0862, 0.0852, 0.0363, 0.0364, 0.0482, 0.0525,
        0.0604, 0.0899, 0.0325, 0.0466], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,186][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.0788, 0.0619, 0.1085, 0.0808, 0.0517, 0.0830, 0.0981, 0.1032, 0.0598,
        0.0888, 0.0531, 0.0714, 0.0608], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,187][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([7.5698e-06, 2.0650e-02, 5.4255e-06, 4.5876e-02, 3.9933e-03, 3.3512e-07,
        1.2613e-03, 7.1123e-01, 1.2988e-06, 7.0327e-02, 6.2500e-04, 2.3515e-04,
        1.4578e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,188][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.0769, 0.0770, 0.0769, 0.0769, 0.0769, 0.0769, 0.0769, 0.0769, 0.0769,
        0.0769, 0.0770, 0.0769, 0.0770], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,190][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.0157, 0.0171, 0.0181, 0.0341, 0.0854, 0.1806, 0.0592, 0.0585, 0.1198,
        0.0578, 0.1365, 0.1469, 0.0702], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,192][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.0517, 0.0451, 0.1008, 0.0193, 0.0066, 0.2205, 0.2468, 0.0255, 0.1625,
        0.0232, 0.0035, 0.0906, 0.0040], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,193][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.0768, 0.0768, 0.0769, 0.0770, 0.0770, 0.0772, 0.0769, 0.0769, 0.0768,
        0.0767, 0.0770, 0.0771, 0.0769], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,195][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.0769, 0.0769, 0.0769, 0.0769, 0.0769, 0.0770, 0.0769, 0.0770, 0.0769,
        0.0769, 0.0769, 0.0770, 0.0770], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,195][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([5.5712e-05, 5.7980e-05, 9.9364e-03, 7.9849e-05, 8.6246e-06, 1.1014e-03,
        9.3503e-06, 5.2877e-05, 1.4231e-02, 2.9478e-05, 5.0730e-06, 3.5896e-05,
        9.7440e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,195][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0714, 0.0716, 0.0714, 0.0714, 0.0713, 0.0715, 0.0714, 0.0714, 0.0714,
        0.0713, 0.0714, 0.0715, 0.0715, 0.0714], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,196][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0139, 0.0605, 0.0490, 0.2234, 0.0398, 0.0042, 0.0453, 0.0833, 0.0397,
        0.2046, 0.0819, 0.0590, 0.0928, 0.0027], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,196][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0888, 0.0368, 0.0622, 0.0472, 0.0491, 0.0828, 0.0662, 0.0643, 0.1328,
        0.0591, 0.0752, 0.0721, 0.0564, 0.1071], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,197][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1449, 0.2064, 0.0429, 0.1005, 0.0860, 0.0304, 0.0318, 0.0547, 0.0388,
        0.0724, 0.0988, 0.0287, 0.0495, 0.0141], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,197][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0877, 0.0503, 0.0584, 0.0794, 0.0482, 0.0687, 0.1043, 0.1104, 0.0357,
        0.0916, 0.0510, 0.0768, 0.0579, 0.0795], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,198][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.7622e-03, 1.1225e-01, 1.4758e-03, 1.1569e-01, 2.0860e-02, 3.7108e-03,
        2.8004e-03, 3.3974e-01, 1.2324e-06, 1.3862e-01, 3.0692e-03, 5.8243e-04,
        2.4147e-01, 9.9668e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,198][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0714, 0.0715, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714,
        0.0714, 0.0715, 0.0714, 0.0715, 0.0714], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,199][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0182, 0.0204, 0.0185, 0.0345, 0.0803, 0.1366, 0.0495, 0.0568, 0.1135,
        0.0564, 0.1235, 0.1291, 0.0669, 0.0959], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,201][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0348, 0.0238, 0.0963, 0.0116, 0.0053, 0.1518, 0.2309, 0.0126, 0.1739,
        0.0141, 0.0037, 0.0954, 0.0066, 0.1390], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,202][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0713, 0.0713, 0.0714, 0.0715, 0.0715, 0.0717, 0.0714, 0.0714, 0.0713,
        0.0712, 0.0715, 0.0716, 0.0714, 0.0715], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,204][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0714, 0.0714, 0.0714, 0.0715, 0.0714, 0.0715, 0.0714, 0.0715, 0.0714,
        0.0714, 0.0714, 0.0715, 0.0715, 0.0714], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,205][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.0872e-03, 3.0519e-06, 4.3432e-02, 6.0602e-06, 2.9344e-06, 5.1868e-01,
        1.8492e-05, 3.6784e-06, 2.8312e-02, 3.5451e-06, 2.1289e-06, 7.4947e-05,
        1.5208e-05, 4.0836e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,206][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:16:37,208][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 3570],
        [  168],
        [ 3563],
        [ 1358],
        [ 3229],
        [ 2944],
        [12836],
        [ 4529],
        [ 1820],
        [ 2533],
        [ 5899],
        [10621],
        [ 4361],
        [  591]], device='cuda:0')
[2024-07-24 10:16:37,210][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[  965],
        [    4],
        [20075],
        [  174],
        [13512],
        [ 9313],
        [20165],
        [22560],
        [ 8450],
        [  108],
        [12147],
        [17404],
        [17492],
        [ 6796]], device='cuda:0')
[2024-07-24 10:16:37,211][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[20474],
        [18676],
        [18659],
        [15163],
        [ 9886],
        [10353],
        [ 7076],
        [ 7915],
        [ 7747],
        [ 6420],
        [ 7852],
        [ 7328],
        [ 6941],
        [ 8794]], device='cuda:0')
[2024-07-24 10:16:37,212][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[41773],
        [41380],
        [43952],
        [44751],
        [43494],
        [44904],
        [45886],
        [44713],
        [44460],
        [44171],
        [43570],
        [44487],
        [43195],
        [44754]], device='cuda:0')
[2024-07-24 10:16:37,214][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[12279],
        [13088],
        [14200],
        [14847],
        [15044],
        [15294],
        [15324],
        [15537],
        [15736],
        [15880],
        [15844],
        [15936],
        [15881],
        [16088]], device='cuda:0')
[2024-07-24 10:16:37,216][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 7256],
        [12808],
        [ 7705],
        [12488],
        [12641],
        [10487],
        [ 9483],
        [10694],
        [ 9975],
        [10894],
        [10694],
        [10031],
        [ 9586],
        [ 9556]], device='cuda:0')
[2024-07-24 10:16:37,217][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[17099],
        [16517],
        [17933],
        [20171],
        [15131],
        [23994],
        [28254],
        [25763],
        [31622],
        [34152],
        [32157],
        [34355],
        [31115],
        [34920]], device='cuda:0')
[2024-07-24 10:16:37,219][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[11197],
        [26155],
        [13616],
        [38807],
        [17161],
        [24266],
        [29547],
        [16867],
        [18588],
        [38295],
        [28943],
        [21221],
        [ 3006],
        [ 1131]], device='cuda:0')
[2024-07-24 10:16:37,220][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 9806],
        [ 9727],
        [10031],
        [ 9762],
        [ 9307],
        [10351],
        [10182],
        [10078],
        [10351],
        [10403],
        [10120],
        [ 9792],
        [ 9930],
        [ 9666]], device='cuda:0')
[2024-07-24 10:16:37,221][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[1431],
        [ 153],
        [ 193],
        [  89],
        [  98],
        [ 204],
        [ 412],
        [ 204],
        [ 718],
        [1947],
        [ 801],
        [1099],
        [ 958],
        [2171]], device='cuda:0')
[2024-07-24 10:16:37,222][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[35719],
        [36605],
        [35992],
        [35698],
        [34106],
        [34229],
        [29072],
        [25771],
        [26025],
        [21596],
        [23859],
        [23593],
        [20534],
        [23768]], device='cuda:0')
[2024-07-24 10:16:37,223][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[8632],
        [8632],
        [8643],
        [8630],
        [8631],
        [8888],
        [9208],
        [8919],
        [9053],
        [8776],
        [9300],
        [9740],
        [9895],
        [9339]], device='cuda:0')
[2024-07-24 10:16:37,224][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 8106],
        [11077],
        [ 9803],
        [10670],
        [ 9728],
        [ 9688],
        [ 9941],
        [ 9026],
        [ 8991],
        [ 9370],
        [ 9398],
        [ 9498],
        [ 9247],
        [ 9313]], device='cuda:0')
[2024-07-24 10:16:37,225][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 7871],
        [17628],
        [ 4853],
        [22731],
        [27421],
        [ 5162],
        [27634],
        [22595],
        [ 8057],
        [34017],
        [27472],
        [29347],
        [33763],
        [12105]], device='cuda:0')
[2024-07-24 10:16:37,226][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 6157],
        [ 2681],
        [ 4634],
        [ 3277],
        [14674],
        [ 4734],
        [ 6048],
        [18868],
        [ 6316],
        [10384],
        [10032],
        [12661],
        [15494],
        [ 5673]], device='cuda:0')
[2024-07-24 10:16:37,228][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[25655],
        [25611],
        [25609],
        [25610],
        [25624],
        [25622],
        [25613],
        [25615],
        [25606],
        [25615],
        [25623],
        [25620],
        [25613],
        [25616]], device='cuda:0')
[2024-07-24 10:16:37,229][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[1387],
        [ 894],
        [1644],
        [ 751],
        [ 895],
        [ 613],
        [ 539],
        [ 574],
        [ 656],
        [ 889],
        [ 834],
        [ 838],
        [ 665],
        [ 803]], device='cuda:0')
[2024-07-24 10:16:37,231][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[25005],
        [25522],
        [24846],
        [26894],
        [26503],
        [26931],
        [26799],
        [27902],
        [27409],
        [28067],
        [27685],
        [28077],
        [27752],
        [28068]], device='cuda:0')
[2024-07-24 10:16:37,232][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[10595],
        [35620],
        [39981],
        [40848],
        [39973],
        [39080],
        [39299],
        [36553],
        [35832],
        [35403],
        [35565],
        [36355],
        [37025],
        [35758]], device='cuda:0')
[2024-07-24 10:16:37,234][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[24260],
        [23502],
        [20859],
        [21519],
        [19359],
        [18573],
        [16972],
        [14166],
        [15177],
        [16196],
        [15241],
        [15473],
        [15067],
        [14572]], device='cuda:0')
[2024-07-24 10:16:37,235][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[44580],
        [35147],
        [38999],
        [39577],
        [33610],
        [36085],
        [33724],
        [23294],
        [23693],
        [40036],
        [35232],
        [21923],
        [19591],
        [22734]], device='cuda:0')
[2024-07-24 10:16:37,237][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[28417],
        [28352],
        [28498],
        [28516],
        [28514],
        [28479],
        [28473],
        [28434],
        [28405],
        [28401],
        [28386],
        [28389],
        [28378],
        [28381]], device='cuda:0')
[2024-07-24 10:16:37,239][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[41420],
        [41571],
        [42321],
        [42420],
        [42247],
        [43244],
        [43753],
        [44058],
        [44022],
        [43925],
        [43363],
        [43018],
        [42967],
        [43255]], device='cuda:0')
[2024-07-24 10:16:37,240][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[4301],
        [3654],
        [3163],
        [3489],
        [3518],
        [2945],
        [3664],
        [3521],
        [3570],
        [3539],
        [3554],
        [3567],
        [3513],
        [3375]], device='cuda:0')
[2024-07-24 10:16:37,242][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[7040],
        [7042],
        [7047],
        [7045],
        [7044],
        [7046],
        [7044],
        [7043],
        [7039],
        [7039],
        [7040],
        [7042],
        [7039],
        [7039]], device='cuda:0')
[2024-07-24 10:16:37,243][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[10542],
        [10530],
        [10524],
        [10523],
        [10523],
        [10526],
        [10526],
        [10528],
        [10531],
        [10534],
        [10534],
        [10533],
        [10531],
        [10530]], device='cuda:0')
[2024-07-24 10:16:37,244][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 8399],
        [16559],
        [17942],
        [24472],
        [11497],
        [15195],
        [11147],
        [11829],
        [19385],
        [24759],
        [11952],
        [ 9284],
        [ 9952],
        [15468]], device='cuda:0')
[2024-07-24 10:16:37,245][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[18942],
        [20935],
        [19198],
        [16544],
        [18155],
        [20985],
        [22141],
        [22074],
        [23798],
        [18226],
        [19542],
        [22685],
        [22669],
        [22538]], device='cuda:0')
[2024-07-24 10:16:37,246][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[40297],
        [48846],
        [35454],
        [46658],
        [34155],
        [43541],
        [41084],
        [31978],
        [41629],
        [42152],
        [35594],
        [38188],
        [40100],
        [42749]], device='cuda:0')
[2024-07-24 10:16:37,247][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[34123],
        [34123],
        [34123],
        [34123],
        [34123],
        [34123],
        [34123],
        [34123],
        [34123],
        [34123],
        [34123],
        [34123],
        [34123],
        [34123]], device='cuda:0')
[2024-07-24 10:16:37,277][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:37,278][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,278][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,278][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,279][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,279][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,279][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,280][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,280][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,280][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,281][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,281][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,281][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,283][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.6173, 0.3827], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,285][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.0066, 0.9934], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,286][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.0029, 0.9971], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,288][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.0608, 0.9392], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,288][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.8589, 0.1411], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,290][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.0257, 0.9743], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,299][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.3526, 0.6474], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,301][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.5352, 0.4648], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,303][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.1916, 0.8084], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,304][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.4291, 0.5709], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,305][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.1804, 0.8196], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,305][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.0496, 0.9504], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,305][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.4585, 0.4108, 0.1308], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,305][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0032, 0.9830, 0.0138], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,306][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([3.3167e-05, 3.5577e-01, 6.4420e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,306][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0060, 0.3789, 0.6151], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,306][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2341, 0.2020, 0.5639], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,307][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0032, 0.2293, 0.7674], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,307][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2544, 0.4631, 0.2825], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,307][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3084, 0.3617, 0.3300], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,308][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0190, 0.2793, 0.7017], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,308][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2735, 0.3873, 0.3393], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,309][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1547, 0.5426, 0.3027], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,311][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0319, 0.6330, 0.3352], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,312][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Jonathan] are: tensor([0.3818, 0.1940, 0.3841, 0.0401], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,314][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Jonathan] are: tensor([0.0056, 0.8985, 0.0102, 0.0857], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,315][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Jonathan] are: tensor([1.8330e-06, 4.9911e-03, 7.3965e-02, 9.2104e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,315][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Jonathan] are: tensor([6.6046e-04, 3.1662e-02, 1.9401e-01, 7.7367e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,317][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Jonathan] are: tensor([0.4054, 0.1102, 0.4170, 0.0674], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,318][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Jonathan] are: tensor([1.6398e-04, 1.5551e-02, 2.2900e-01, 7.5529e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,320][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Jonathan] are: tensor([0.1603, 0.3339, 0.2069, 0.2989], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,321][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Jonathan] are: tensor([0.2389, 0.2200, 0.2744, 0.2667], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,323][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Jonathan] are: tensor([0.0022, 0.0525, 0.3208, 0.6245], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,325][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Jonathan] are: tensor([0.2042, 0.2803, 0.2442, 0.2713], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,326][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Jonathan] are: tensor([0.0875, 0.3979, 0.2201, 0.2945], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,327][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Jonathan] are: tensor([0.0132, 0.2384, 0.1893, 0.5591], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,328][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.1030, 0.4152, 0.2844, 0.1947, 0.0027], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,328][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0101, 0.4448, 0.0432, 0.3140, 0.1878], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,329][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ went] are: tensor([6.7398e-07, 1.7479e-03, 3.4194e-02, 7.2898e-01, 2.3508e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,329][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ went] are: tensor([4.6256e-04, 1.6537e-02, 9.0486e-02, 5.4714e-01, 3.4537e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,329][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.3059, 0.0306, 0.4668, 0.0738, 0.1229], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,330][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ went] are: tensor([6.7892e-05, 6.5429e-03, 9.3376e-02, 5.9671e-01, 3.0330e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,330][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.1240, 0.2207, 0.1341, 0.2190, 0.3022], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,330][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.1948, 0.1822, 0.2328, 0.2098, 0.1805], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,331][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0017, 0.0213, 0.1545, 0.5135, 0.3089], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,331][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.1577, 0.2212, 0.1939, 0.2164, 0.2108], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,331][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0596, 0.2637, 0.1385, 0.1960, 0.3421], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,332][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0157, 0.1907, 0.1390, 0.4017, 0.2528], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,334][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.5598, 0.0996, 0.3112, 0.0164, 0.0052, 0.0079], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,336][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0039, 0.2567, 0.0195, 0.6632, 0.0472, 0.0095], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,336][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([1.4667e-07, 8.6809e-05, 2.3556e-03, 4.4476e-02, 4.6113e-01, 4.9195e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,337][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([2.5812e-04, 9.9264e-03, 3.3288e-02, 2.5806e-01, 1.6573e-01, 5.3273e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,338][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0868, 0.0940, 0.2495, 0.1184, 0.2375, 0.2137], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,339][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([7.3359e-05, 2.0153e-03, 3.4363e-02, 1.1703e-01, 1.0218e-01, 7.4434e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,341][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1342, 0.1855, 0.1466, 0.1825, 0.2381, 0.1130], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,343][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1522, 0.1633, 0.1632, 0.1827, 0.1737, 0.1649], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,344][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([1.9447e-04, 3.1208e-03, 1.4804e-02, 6.1993e-02, 6.8770e-01, 2.3219e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,345][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1342, 0.1824, 0.1614, 0.1776, 0.1751, 0.1693], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,347][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0599, 0.2043, 0.1284, 0.1746, 0.2722, 0.1606], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,349][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0134, 0.1505, 0.1017, 0.2945, 0.1918, 0.2481], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,350][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1708, 0.1299, 0.3431, 0.0539, 0.0213, 0.2730, 0.0079],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,351][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0005, 0.4510, 0.0112, 0.4697, 0.0589, 0.0022, 0.0065],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,351][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ the] are: tensor([1.2195e-08, 1.2649e-05, 4.3142e-04, 1.2042e-02, 4.2585e-02, 8.0310e-01,
        1.4183e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,351][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ the] are: tensor([8.3310e-05, 3.0422e-03, 1.1193e-02, 1.3606e-01, 9.1700e-02, 3.9246e-01,
        3.6546e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,352][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1335, 0.0812, 0.2090, 0.1011, 0.0656, 0.2390, 0.1708],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,352][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ the] are: tensor([2.2279e-05, 8.7694e-04, 9.3779e-03, 4.7946e-02, 5.5932e-02, 5.7171e-01,
        3.1413e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,352][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1087, 0.1638, 0.1283, 0.1588, 0.2414, 0.0998, 0.0992],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,353][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1365, 0.1344, 0.1427, 0.1456, 0.1369, 0.1381, 0.1658],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,353][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ the] are: tensor([1.4222e-04, 1.7306e-03, 1.0161e-02, 5.0505e-02, 1.9823e-01, 4.7461e-01,
        2.6462e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,353][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1161, 0.1541, 0.1378, 0.1516, 0.1498, 0.1452, 0.1453],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,354][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0524, 0.1853, 0.1114, 0.1506, 0.2306, 0.1345, 0.1353],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,354][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0121, 0.1267, 0.0775, 0.2372, 0.1583, 0.1935, 0.1948],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,355][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.1707, 0.3483, 0.1386, 0.1484, 0.0095, 0.1331, 0.0355, 0.0159],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,356][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([6.6995e-04, 2.7119e-02, 1.2054e-03, 1.9822e-02, 3.7312e-02, 2.4213e-04,
        3.1517e-03, 9.1048e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,358][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([8.7288e-09, 6.6481e-06, 1.3168e-04, 8.6964e-03, 1.5145e-02, 2.4591e-01,
        3.3079e-01, 3.9932e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,358][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([2.4235e-05, 7.2670e-04, 3.2494e-03, 3.5354e-02, 3.6456e-02, 1.4554e-01,
        5.0360e-01, 2.7505e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,360][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.0958, 0.0227, 0.2044, 0.0508, 0.1299, 0.1845, 0.2619, 0.0500],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,361][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([1.0023e-05, 3.6675e-04, 3.8288e-03, 3.1559e-02, 2.2437e-02, 2.6254e-01,
        4.1444e-01, 2.6481e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,362][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.0704, 0.1305, 0.0794, 0.1395, 0.2135, 0.0673, 0.0686, 0.2308],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,364][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.1273, 0.1075, 0.1318, 0.1221, 0.1125, 0.1345, 0.1391, 0.1253],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,365][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([1.3281e-04, 1.1134e-03, 6.6568e-03, 1.6666e-02, 9.0402e-02, 2.6053e-01,
        3.8563e-01, 2.3886e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,367][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.0994, 0.1326, 0.1184, 0.1340, 0.1309, 0.1291, 0.1292, 0.1264],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,368][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.0342, 0.1383, 0.0777, 0.1043, 0.1998, 0.0910, 0.0932, 0.2615],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,370][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.0122, 0.0878, 0.0777, 0.1811, 0.1227, 0.1766, 0.1644, 0.1774],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,372][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4050, 0.0571, 0.1862, 0.0401, 0.0517, 0.1783, 0.0697, 0.0096, 0.0023],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,373][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0043, 0.2890, 0.0141, 0.3493, 0.0781, 0.0053, 0.0664, 0.1715, 0.0221],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,374][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([7.4756e-10, 3.3103e-07, 7.4063e-06, 2.1008e-04, 8.5796e-04, 7.3294e-03,
        2.0982e-02, 1.4407e-01, 8.2654e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,374][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([1.6466e-05, 2.7512e-04, 1.2531e-03, 1.0062e-02, 9.6021e-03, 6.3274e-02,
        1.2389e-01, 1.1547e-01, 6.7616e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,375][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0604, 0.0727, 0.1184, 0.0710, 0.0402, 0.1281, 0.2162, 0.1049, 0.1881],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,375][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([1.4779e-06, 2.8955e-05, 5.2762e-04, 1.9192e-03, 4.5800e-03, 3.5904e-02,
        6.0949e-02, 1.0684e-01, 7.8925e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,375][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0731, 0.1216, 0.0801, 0.1145, 0.1530, 0.0654, 0.0690, 0.1932, 0.1302],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,376][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0963, 0.1027, 0.1064, 0.1176, 0.1094, 0.1022, 0.1204, 0.1195, 0.1254],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,376][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([3.7218e-05, 1.7759e-04, 1.9449e-03, 3.4910e-03, 3.9561e-02, 8.1408e-02,
        1.0770e-01, 1.8306e-01, 5.8262e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,376][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0830, 0.1207, 0.1058, 0.1183, 0.1162, 0.1136, 0.1142, 0.1156, 0.1127],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,377][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0387, 0.1299, 0.0775, 0.1100, 0.1636, 0.0876, 0.0939, 0.2235, 0.0754],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,377][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0108, 0.0871, 0.0564, 0.1489, 0.0946, 0.1189, 0.1215, 0.1384, 0.2234],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,379][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Jonathan] are: tensor([0.1331, 0.0488, 0.1378, 0.0117, 0.0907, 0.2145, 0.2192, 0.0254, 0.1078,
        0.0110], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,381][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Jonathan] are: tensor([0.0018, 0.4494, 0.0037, 0.0339, 0.0942, 0.0025, 0.0108, 0.3543, 0.0225,
        0.0270], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,381][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Jonathan] are: tensor([1.1472e-10, 6.3117e-09, 7.6745e-08, 1.0425e-06, 3.4444e-06, 1.0554e-04,
        4.7370e-04, 2.8161e-03, 6.2458e-02, 9.3414e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,382][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Jonathan] are: tensor([1.1770e-06, 1.6744e-05, 8.2796e-05, 4.3906e-04, 1.1396e-03, 5.8957e-03,
        1.8047e-02, 2.3729e-02, 2.0140e-01, 7.4925e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,384][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Jonathan] are: tensor([0.0934, 0.0237, 0.1055, 0.0148, 0.0409, 0.1592, 0.1550, 0.0837, 0.2971,
        0.0266], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,385][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Jonathan] are: tensor([1.5896e-07, 2.4684e-06, 4.1337e-05, 9.5734e-05, 6.6683e-04, 3.9619e-03,
        9.9529e-03, 4.1174e-02, 3.5367e-01, 5.9044e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,387][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Jonathan] are: tensor([0.0534, 0.1055, 0.0680, 0.0952, 0.1690, 0.0502, 0.0524, 0.1878, 0.1182,
        0.1002], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,388][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Jonathan] are: tensor([0.0898, 0.0772, 0.1025, 0.0932, 0.0904, 0.0983, 0.1142, 0.0948, 0.1318,
        0.1079], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,389][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Jonathan] are: tensor([9.6480e-06, 4.0133e-05, 2.9377e-04, 4.7173e-04, 2.6098e-03, 1.5128e-02,
        2.5971e-02, 1.1268e-01, 3.6848e-01, 4.7431e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,390][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Jonathan] are: tensor([0.0794, 0.1075, 0.0950, 0.1043, 0.1039, 0.1010, 0.1019, 0.1038, 0.1017,
        0.1015], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,392][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Jonathan] are: tensor([0.0267, 0.1206, 0.0680, 0.0891, 0.1559, 0.0763, 0.0804, 0.2191, 0.0735,
        0.0903], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,394][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Jonathan] are: tensor([0.0045, 0.0433, 0.0327, 0.0793, 0.0524, 0.0706, 0.0767, 0.0708, 0.1555,
        0.4141], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,395][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0417, 0.0534, 0.0930, 0.0188, 0.1330, 0.2334, 0.0885, 0.2694, 0.0484,
        0.0193, 0.0010], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,396][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([8.3611e-05, 2.2866e-01, 4.8146e-03, 4.8660e-02, 5.7812e-02, 4.1831e-04,
        2.5781e-03, 5.0630e-01, 5.9831e-03, 5.4737e-02, 8.9961e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,397][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([7.6047e-12, 4.4919e-10, 1.2604e-08, 5.3349e-07, 4.4330e-07, 1.0939e-05,
        4.4069e-05, 1.7303e-04, 1.8323e-02, 7.8626e-01, 1.9519e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,397][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([1.0429e-06, 6.9075e-06, 4.9715e-05, 2.6582e-04, 2.6639e-04, 2.7685e-03,
        4.7505e-03, 7.5017e-03, 1.0615e-01, 5.8725e-01, 2.9100e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,397][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0742, 0.0191, 0.1269, 0.0314, 0.0388, 0.1329, 0.1398, 0.0751, 0.2830,
        0.0561, 0.0228], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,398][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([7.0893e-08, 1.1300e-06, 1.6531e-05, 6.5466e-05, 1.1008e-04, 9.7202e-04,
        2.7066e-03, 6.6173e-03, 1.6877e-01, 5.7185e-01, 2.4890e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,398][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0503, 0.0857, 0.0573, 0.0978, 0.1357, 0.0449, 0.0486, 0.1561, 0.1100,
        0.1056, 0.1080], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,399][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0811, 0.0733, 0.0909, 0.0839, 0.0816, 0.0942, 0.1000, 0.0851, 0.1213,
        0.0950, 0.0935], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,399][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([5.9215e-06, 2.6261e-05, 1.8608e-04, 4.7453e-04, 1.1504e-03, 7.1557e-03,
        9.9660e-03, 1.2471e-02, 2.2046e-01, 4.6555e-01, 2.8255e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,399][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0723, 0.0983, 0.0873, 0.0959, 0.0943, 0.0921, 0.0926, 0.0930, 0.0919,
        0.0926, 0.0897], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,400][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0254, 0.1040, 0.0570, 0.0785, 0.1413, 0.0691, 0.0678, 0.1857, 0.0585,
        0.0799, 0.1328], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,401][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0056, 0.0375, 0.0303, 0.0640, 0.0458, 0.0708, 0.0624, 0.0572, 0.1529,
        0.3136, 0.1598], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,402][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0963, 0.0654, 0.2735, 0.0779, 0.0069, 0.1142, 0.0855, 0.0949, 0.0482,
        0.1203, 0.0102, 0.0065], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,404][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0004, 0.1718, 0.0119, 0.1680, 0.0371, 0.0022, 0.0049, 0.3748, 0.0092,
        0.1610, 0.0570, 0.0017], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,405][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([1.0209e-11, 2.7487e-10, 5.6688e-09, 1.3676e-07, 5.6063e-07, 1.0717e-05,
        1.3753e-05, 1.0077e-04, 4.8297e-03, 1.3045e-01, 5.6348e-01, 3.0111e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,406][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([8.2976e-07, 6.0262e-06, 2.1955e-05, 2.4440e-04, 1.5484e-04, 8.4830e-04,
        2.0219e-03, 4.9893e-03, 3.6408e-02, 4.1374e-01, 2.7214e-01, 2.6943e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,407][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0646, 0.0198, 0.1343, 0.0387, 0.0346, 0.1211, 0.1144, 0.0414, 0.2311,
        0.0542, 0.0365, 0.1094], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,408][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([1.2159e-07, 9.0845e-07, 1.0651e-05, 4.9093e-05, 5.6382e-05, 6.4780e-04,
        1.0077e-03, 2.9045e-03, 6.9932e-02, 2.8423e-01, 2.8547e-01, 3.5569e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,410][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0481, 0.0796, 0.0612, 0.0835, 0.1219, 0.0489, 0.0497, 0.1496, 0.1051,
        0.0873, 0.1112, 0.0538], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,412][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0676, 0.0764, 0.0809, 0.0823, 0.0747, 0.0771, 0.0922, 0.0923, 0.0938,
        0.0916, 0.0834, 0.0878], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,413][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([1.1607e-06, 3.0581e-06, 2.5585e-05, 7.4007e-05, 3.3491e-04, 9.4178e-04,
        1.3162e-03, 2.3503e-03, 2.6708e-02, 6.0250e-02, 7.8769e-01, 1.2030e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,415][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0650, 0.0885, 0.0794, 0.0879, 0.0866, 0.0846, 0.0845, 0.0847, 0.0850,
        0.0864, 0.0834, 0.0842], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,416][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0270, 0.0950, 0.0565, 0.0768, 0.1181, 0.0682, 0.0687, 0.1692, 0.0558,
        0.0783, 0.1199, 0.0665], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,418][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0066, 0.0361, 0.0262, 0.0573, 0.0375, 0.0560, 0.0516, 0.0544, 0.1097,
        0.2638, 0.1371, 0.1638], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,419][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.0695, 0.0467, 0.2589, 0.0656, 0.0339, 0.1598, 0.0337, 0.0833, 0.0742,
        0.0604, 0.0987, 0.0091, 0.0060], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,420][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([1.5876e-04, 2.4484e-02, 2.1879e-03, 1.0243e-02, 2.8486e-02, 1.5244e-04,
        2.5307e-03, 7.8436e-01, 3.0710e-03, 1.0191e-02, 3.4749e-02, 9.7588e-04,
        9.8407e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,420][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([1.9718e-12, 8.5432e-11, 3.4540e-09, 5.6651e-08, 1.5656e-07, 3.5084e-06,
        8.0498e-06, 4.5220e-05, 2.5978e-03, 3.9080e-02, 9.5175e-02, 6.6338e-01,
        1.9971e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,421][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([1.0546e-07, 1.2568e-06, 7.9096e-06, 5.7105e-05, 1.2936e-04, 4.3459e-04,
        9.3364e-04, 1.6661e-03, 1.9936e-02, 9.6228e-02, 1.5368e-01, 5.6246e-01,
        1.6447e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,421][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.0488, 0.0283, 0.0882, 0.0518, 0.0291, 0.0978, 0.1062, 0.0425, 0.2322,
        0.0720, 0.0455, 0.1074, 0.0502], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,421][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([1.8110e-08, 3.4420e-07, 3.7138e-06, 1.4391e-05, 4.5716e-05, 2.8386e-04,
        4.0199e-04, 1.2052e-03, 2.5910e-02, 1.0251e-01, 2.0278e-01, 5.0477e-01,
        1.6207e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,422][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.0380, 0.0757, 0.0460, 0.0736, 0.1317, 0.0376, 0.0375, 0.1281, 0.0877,
        0.0814, 0.1150, 0.0435, 0.1040], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,422][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.0737, 0.0654, 0.0861, 0.0705, 0.0665, 0.0798, 0.0791, 0.0690, 0.1054,
        0.0760, 0.0790, 0.0803, 0.0692], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,423][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([8.1349e-07, 4.7734e-06, 3.3717e-05, 1.3587e-04, 2.3137e-04, 1.5669e-03,
        1.8719e-03, 2.8172e-03, 4.1174e-02, 1.0378e-01, 2.5861e-01, 3.4786e-01,
        2.4191e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,423][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.0576, 0.0809, 0.0718, 0.0810, 0.0798, 0.0784, 0.0782, 0.0775, 0.0788,
        0.0806, 0.0773, 0.0781, 0.0799], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,424][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.0179, 0.0850, 0.0463, 0.0644, 0.1200, 0.0517, 0.0524, 0.1523, 0.0504,
        0.0651, 0.1119, 0.0509, 0.1317], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,426][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0071, 0.0315, 0.0311, 0.0562, 0.0398, 0.0586, 0.0491, 0.0488, 0.1170,
        0.2153, 0.1154, 0.1518, 0.0784], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,427][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.4186, 0.0371, 0.1752, 0.0114, 0.0044, 0.0031, 0.0342, 0.0317, 0.0316,
        0.0156, 0.0128, 0.0385, 0.1843, 0.0013], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,429][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0016, 0.0753, 0.0087, 0.2443, 0.0245, 0.0041, 0.0209, 0.2074, 0.0213,
        0.2176, 0.0815, 0.0053, 0.0853, 0.0022], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,430][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([1.4333e-12, 1.8273e-12, 4.2605e-11, 6.0752e-10, 5.8985e-09, 6.9408e-09,
        2.1601e-07, 7.8228e-07, 2.7023e-05, 5.9786e-04, 6.1853e-03, 2.3992e-02,
        5.0753e-02, 9.1844e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,431][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.2300e-07, 7.0741e-07, 1.9803e-06, 1.8975e-05, 1.1252e-05, 3.2188e-05,
        2.4429e-04, 5.8298e-04, 4.3642e-03, 2.8029e-02, 3.6665e-02, 1.3692e-01,
        1.6726e-01, 6.2587e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,433][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0313, 0.0330, 0.0858, 0.0360, 0.0723, 0.0713, 0.0729, 0.0412, 0.1408,
        0.0502, 0.0633, 0.0997, 0.1230, 0.0793], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,434][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.3342e-08, 2.6629e-08, 4.5387e-07, 1.1434e-06, 1.3187e-06, 7.8039e-06,
        4.3652e-05, 1.4983e-04, 2.7976e-03, 6.2975e-03, 1.5229e-02, 5.7378e-02,
        1.2442e-01, 7.9368e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,436][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0471, 0.0685, 0.0568, 0.0709, 0.0924, 0.0422, 0.0458, 0.1202, 0.0946,
        0.0747, 0.0944, 0.0522, 0.0988, 0.0414], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,437][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0614, 0.0647, 0.0666, 0.0694, 0.0679, 0.0664, 0.0766, 0.0737, 0.0835,
        0.0760, 0.0751, 0.0738, 0.0697, 0.0751], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,439][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([4.5193e-07, 8.0353e-07, 4.4790e-06, 1.4277e-05, 1.9874e-04, 5.5122e-05,
        3.3008e-04, 4.4287e-04, 5.8756e-03, 9.8362e-03, 2.5675e-01, 8.8611e-02,
        2.0764e-01, 4.3024e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,440][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0568, 0.0753, 0.0673, 0.0747, 0.0733, 0.0721, 0.0726, 0.0718, 0.0727,
        0.0736, 0.0710, 0.0722, 0.0736, 0.0730], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,442][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0217, 0.0755, 0.0483, 0.0655, 0.0987, 0.0587, 0.0569, 0.1357, 0.0498,
        0.0672, 0.1007, 0.0558, 0.1186, 0.0469], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,442][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0066, 0.0277, 0.0198, 0.0412, 0.0298, 0.0372, 0.0380, 0.0393, 0.0782,
        0.1696, 0.0971, 0.1141, 0.0739, 0.2274], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,461][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:37,462][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,464][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,465][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,466][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,468][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,469][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,469][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,469][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,470][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,470][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,470][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,470][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,471][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.4259, 0.5741], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,471][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.0016, 0.9984], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,471][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.0221, 0.9779], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,472][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.0608, 0.9392], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,472][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.0133, 0.9867], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,472][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.0257, 0.9743], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,473][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.3587, 0.6413], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,473][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.4777, 0.5223], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,473][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.1246, 0.8754], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,474][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.0056, 0.9944], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,474][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.1082, 0.8918], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,474][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.0496, 0.9504], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,474][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2858, 0.3480, 0.3661], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,475][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0027, 0.9872, 0.0101], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,475][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([9.9697e-01, 3.0308e-03, 8.0480e-12], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,475][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0060, 0.3789, 0.6151], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,476][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0020, 0.6639, 0.3341], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,476][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0032, 0.2293, 0.7674], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,476][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.3002, 0.4524, 0.2475], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,477][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2971, 0.3750, 0.3278], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,477][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0542, 0.1871, 0.7586], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,477][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([3.8206e-04, 3.6923e-01, 6.3039e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,478][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1707, 0.6549, 0.1744], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,478][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0319, 0.6330, 0.3352], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,478][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Jonathan] are: tensor([0.1900, 0.2632, 0.2987, 0.2481], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,479][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Jonathan] are: tensor([0.0015, 0.9132, 0.0064, 0.0790], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,480][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Jonathan] are: tensor([1.2423e-04, 1.7132e-04, 8.6700e-09, 9.9970e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,480][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Jonathan] are: tensor([6.6046e-04, 3.1662e-02, 1.9401e-01, 7.7367e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,482][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Jonathan] are: tensor([0.0008, 0.1200, 0.2379, 0.6413], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,483][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Jonathan] are: tensor([1.6398e-04, 1.5551e-02, 2.2900e-01, 7.5529e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,483][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Jonathan] are: tensor([0.1759, 0.3434, 0.1879, 0.2928], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,484][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Jonathan] are: tensor([0.2486, 0.2744, 0.2686, 0.2084], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,484][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Jonathan] are: tensor([0.0177, 0.0853, 0.6302, 0.2669], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,484][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Jonathan] are: tensor([4.7672e-05, 2.1727e-02, 2.9500e-01, 6.8322e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,485][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Jonathan] are: tensor([0.0616, 0.4936, 0.1598, 0.2850], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,485][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Jonathan] are: tensor([0.0132, 0.2384, 0.1893, 0.5591], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,485][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.1559, 0.2100, 0.2342, 0.1981, 0.2017], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,486][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0033, 0.5548, 0.0363, 0.2816, 0.1240], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,486][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([1.2462e-09, 5.8945e-09, 1.4470e-15, 2.2533e-03, 9.9775e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,486][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([4.6256e-04, 1.6537e-02, 9.0486e-02, 5.4714e-01, 3.4537e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,487][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([2.2777e-04, 2.1471e-02, 1.3796e-01, 4.9900e-01, 3.4134e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,487][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([6.7892e-05, 6.5429e-03, 9.3376e-02, 5.9671e-01, 3.0330e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,489][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.1473, 0.2249, 0.1212, 0.2331, 0.2734], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,491][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.1898, 0.2052, 0.2150, 0.1549, 0.2350], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,492][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.0153, 0.0489, 0.3237, 0.1503, 0.4619], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,493][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([7.7066e-06, 7.5748e-03, 5.7139e-02, 6.5797e-01, 2.7731e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,494][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0446, 0.3714, 0.0926, 0.1908, 0.3006], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,496][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.0157, 0.1907, 0.1390, 0.4017, 0.2528], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,497][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1341, 0.1713, 0.1880, 0.1652, 0.1683, 0.1730], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,499][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0045, 0.3272, 0.0318, 0.5812, 0.0489, 0.0062], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,500][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([7.0853e-04, 2.6579e-14, 2.7268e-20, 2.1261e-03, 9.9715e-01, 1.9795e-05],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,501][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.5812e-04, 9.9264e-03, 3.3288e-02, 2.5806e-01, 1.6573e-01, 5.3273e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,502][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.9977e-05, 4.5095e-03, 5.6154e-03, 9.8959e-02, 7.6551e-01, 1.2538e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,503][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([7.3359e-05, 2.0153e-03, 3.4363e-02, 1.1703e-01, 1.0218e-01, 7.4434e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,505][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.2141, 0.1769, 0.1650, 0.1758, 0.1954, 0.0729], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,506][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1491, 0.1798, 0.1678, 0.1336, 0.2002, 0.1695], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,506][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0104, 0.0247, 0.1051, 0.0625, 0.1582, 0.6391], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,507][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([4.6257e-06, 2.1430e-03, 1.3423e-02, 1.7802e-01, 2.2804e-01, 5.7837e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,507][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0686, 0.2647, 0.1175, 0.1834, 0.2607, 0.1051], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,507][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0134, 0.1505, 0.1017, 0.2945, 0.1918, 0.2481], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,508][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1149, 0.1453, 0.1635, 0.1407, 0.1434, 0.1496, 0.1426],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,508][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([4.5313e-04, 5.4550e-01, 1.1962e-02, 3.7104e-01, 6.5976e-02, 7.0611e-04,
        4.3632e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,508][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([1.0736e-03, 1.3707e-12, 2.0236e-17, 2.2969e-03, 9.1779e-01, 2.8208e-03,
        7.6015e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,509][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([8.3310e-05, 3.0422e-03, 1.1193e-02, 1.3606e-01, 9.1700e-02, 3.9246e-01,
        3.6546e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,509][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([4.2429e-05, 8.3886e-03, 1.0625e-02, 1.0582e-01, 2.3357e-01, 3.3606e-01,
        3.0549e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,509][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([2.2279e-05, 8.7694e-04, 9.3779e-03, 4.7946e-02, 5.5932e-02, 5.7171e-01,
        3.1413e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,510][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.1577, 0.1598, 0.1418, 0.1633, 0.2365, 0.0668, 0.0739],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,512][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1257, 0.1563, 0.1441, 0.1142, 0.1656, 0.1432, 0.1510],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,514][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0051, 0.0118, 0.0581, 0.0302, 0.0784, 0.3505, 0.4658],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,514][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([2.5471e-06, 1.2036e-03, 4.4573e-03, 8.2883e-02, 1.0066e-01, 4.5861e-01,
        3.5219e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,516][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0640, 0.2550, 0.1009, 0.1524, 0.2211, 0.0878, 0.1188],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,517][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0121, 0.1267, 0.0775, 0.2372, 0.1583, 0.1935, 0.1948],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,519][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.0986, 0.1295, 0.1497, 0.1237, 0.1255, 0.1335, 0.1260, 0.1135],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,520][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([6.0955e-05, 1.7701e-02, 3.2580e-04, 6.9742e-03, 2.1356e-02, 2.7412e-05,
        9.8721e-04, 9.5257e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,521][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([1.8650e-11, 1.9319e-19, 4.9503e-24, 3.0991e-13, 1.6799e-12, 3.0712e-14,
        3.7116e-14, 1.0000e+00], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,522][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([2.4235e-05, 7.2670e-04, 3.2494e-03, 3.5354e-02, 3.6456e-02, 1.4554e-01,
        5.0360e-01, 2.7505e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,523][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([2.0404e-05, 1.0171e-03, 5.8488e-03, 7.3733e-02, 1.1163e-01, 1.4783e-01,
        3.4656e-01, 3.1336e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,524][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([1.0023e-05, 3.6675e-04, 3.8288e-03, 3.1559e-02, 2.2437e-02, 2.6254e-01,
        4.1444e-01, 2.6481e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,526][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.0911, 0.1449, 0.0742, 0.1644, 0.2273, 0.0421, 0.0485, 0.2075],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,528][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.1160, 0.1238, 0.1285, 0.0939, 0.1480, 0.1315, 0.1322, 0.1260],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,529][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.0019, 0.0042, 0.0299, 0.0104, 0.0402, 0.3210, 0.5321, 0.0604],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,530][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([2.0999e-06, 5.6100e-04, 2.9640e-03, 4.1409e-02, 4.2980e-02, 2.6676e-01,
        4.0416e-01, 2.4117e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,530][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.0285, 0.2057, 0.0594, 0.1253, 0.2102, 0.0439, 0.0747, 0.2523],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,530][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.0122, 0.0878, 0.0777, 0.1811, 0.1227, 0.1766, 0.1644, 0.1774],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,531][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0999, 0.1128, 0.1175, 0.1118, 0.1123, 0.1143, 0.1115, 0.1033, 0.1166],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,531][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0095, 0.3896, 0.0114, 0.2912, 0.1184, 0.0022, 0.0677, 0.0977, 0.0124],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,531][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([1.0248e-10, 8.3562e-27, 7.8140e-32, 1.7997e-16, 1.2866e-16, 3.1675e-19,
        1.5633e-16, 5.3063e-01, 4.6937e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,532][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([1.6466e-05, 2.7512e-04, 1.2531e-03, 1.0062e-02, 9.6021e-03, 6.3274e-02,
        1.2389e-01, 1.1547e-01, 6.7616e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,532][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([9.5137e-06, 1.7433e-03, 1.4531e-03, 1.9649e-02, 1.0032e-02, 3.8827e-02,
        1.2750e-01, 2.6587e-01, 5.3491e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,532][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([1.4779e-06, 2.8955e-05, 5.2762e-04, 1.9192e-03, 4.5800e-03, 3.5904e-02,
        6.0949e-02, 1.0684e-01, 7.8925e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,533][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1118, 0.1326, 0.0882, 0.1282, 0.1446, 0.0451, 0.0552, 0.1711, 0.1232],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,533][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0987, 0.1182, 0.1111, 0.0912, 0.1318, 0.1098, 0.1166, 0.1153, 0.1073],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,535][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0036, 0.0063, 0.0331, 0.0135, 0.0353, 0.1753, 0.2667, 0.0786, 0.3876],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,536][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([1.8599e-07, 6.6918e-05, 3.5962e-04, 5.3737e-03, 7.3910e-03, 5.4642e-02,
        8.3650e-02, 1.5541e-01, 6.9311e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,538][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0446, 0.2024, 0.0645, 0.1334, 0.1675, 0.0423, 0.0813, 0.2190, 0.0449],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,539][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0108, 0.0871, 0.0564, 0.1489, 0.0946, 0.1189, 0.1215, 0.1384, 0.2234],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,541][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Jonathan] are: tensor([0.0758, 0.1018, 0.1175, 0.0971, 0.0995, 0.1051, 0.0996, 0.0898, 0.1217,
        0.0920], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,543][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Jonathan] are: tensor([0.0007, 0.5192, 0.0025, 0.0321, 0.0829, 0.0005, 0.0036, 0.3324, 0.0110,
        0.0152], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,543][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Jonathan] are: tensor([6.6389e-11, 9.9815e-22, 6.4529e-25, 1.5411e-15, 1.1518e-15, 1.9671e-16,
        2.0797e-15, 4.1082e-04, 6.3551e-03, 9.9323e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,544][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Jonathan] are: tensor([1.1770e-06, 1.6744e-05, 8.2796e-05, 4.3906e-04, 1.1396e-03, 5.8957e-03,
        1.8047e-02, 2.3729e-02, 2.0140e-01, 7.4925e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,545][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Jonathan] are: tensor([5.0074e-06, 1.2664e-04, 2.8956e-04, 5.0231e-04, 1.6067e-03, 1.1996e-02,
        2.7250e-02, 8.5773e-02, 2.6105e-01, 6.1140e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,546][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Jonathan] are: tensor([1.5896e-07, 2.4684e-06, 4.1337e-05, 9.5734e-05, 6.6683e-04, 3.9619e-03,
        9.9529e-03, 4.1174e-02, 3.5367e-01, 5.9044e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,549][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Jonathan] are: tensor([0.0672, 0.1198, 0.0694, 0.1025, 0.1786, 0.0323, 0.0387, 0.1803, 0.1083,
        0.1030], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,550][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Jonathan] are: tensor([0.0960, 0.1035, 0.1034, 0.0792, 0.1227, 0.1037, 0.1086, 0.1051, 0.1076,
        0.0702], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,552][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Jonathan] are: tensor([0.0005, 0.0019, 0.0143, 0.0050, 0.0207, 0.1704, 0.2642, 0.0434, 0.4558,
        0.0236], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,552][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Jonathan] are: tensor([4.8223e-08, 3.7624e-06, 4.9119e-05, 1.2575e-04, 7.4974e-04, 6.2297e-03,
        9.1153e-03, 2.0463e-02, 2.5021e-01, 7.1305e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,552][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Jonathan] are: tensor([0.0215, 0.1830, 0.0631, 0.1002, 0.1540, 0.0367, 0.0697, 0.2177, 0.0591,
        0.0950], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,553][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Jonathan] are: tensor([0.0045, 0.0433, 0.0327, 0.0793, 0.0524, 0.0706, 0.0767, 0.0708, 0.1555,
        0.4141], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,553][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0737, 0.0938, 0.1037, 0.0905, 0.0923, 0.0953, 0.0912, 0.0831, 0.1050,
        0.0854, 0.0860], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,554][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([1.1342e-05, 2.9768e-01, 1.4362e-03, 3.0358e-02, 2.9213e-02, 2.5696e-05,
        5.6226e-04, 5.6348e-01, 1.9225e-03, 3.0892e-02, 4.4412e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,554][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([5.1290e-19, 4.2372e-34, 4.7712e-39, 1.0278e-26, 2.3692e-28, 3.3251e-30,
        9.0764e-29, 9.6697e-13, 2.0510e-12, 2.7051e-09, 1.0000e+00],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,554][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([1.0429e-06, 6.9075e-06, 4.9715e-05, 2.6582e-04, 2.6639e-04, 2.7685e-03,
        4.7505e-03, 7.5017e-03, 1.0615e-01, 5.8725e-01, 2.9100e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,555][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([1.0952e-06, 2.9944e-05, 1.2471e-04, 4.6358e-04, 5.0700e-04, 3.0201e-03,
        6.0346e-03, 1.4541e-02, 1.1998e-01, 4.1888e-01, 4.3642e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,555][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([7.0893e-08, 1.1300e-06, 1.6531e-05, 6.5466e-05, 1.1008e-04, 9.7202e-04,
        2.7066e-03, 6.6173e-03, 1.6877e-01, 5.7185e-01, 2.4890e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,556][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0638, 0.0928, 0.0576, 0.1171, 0.1403, 0.0271, 0.0353, 0.1480, 0.1092,
        0.1213, 0.0876], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,557][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0859, 0.0931, 0.0957, 0.0713, 0.1134, 0.0995, 0.0981, 0.0959, 0.0981,
        0.0628, 0.0862], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,558][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0011, 0.0026, 0.0174, 0.0066, 0.0189, 0.1529, 0.2422, 0.0537, 0.4007,
        0.0281, 0.0758], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,560][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([7.1781e-09, 8.0810e-07, 8.7193e-06, 9.2190e-05, 9.0794e-05, 8.6545e-04,
        1.6852e-03, 4.4068e-03, 7.5447e-02, 7.2691e-01, 1.9050e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,561][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0225, 0.1639, 0.0437, 0.0832, 0.1651, 0.0361, 0.0576, 0.1786, 0.0412,
        0.0804, 0.1277], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,562][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0056, 0.0375, 0.0303, 0.0640, 0.0458, 0.0708, 0.0624, 0.0572, 0.1529,
        0.3136, 0.1598], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,564][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0669, 0.0858, 0.0967, 0.0826, 0.0841, 0.0878, 0.0835, 0.0768, 0.0989,
        0.0781, 0.0801, 0.0787], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,566][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([2.4621e-04, 2.6854e-01, 1.1492e-02, 1.4445e-01, 4.2980e-02, 6.7318e-04,
        3.5537e-03, 3.4685e-01, 7.0504e-03, 1.2327e-01, 5.0275e-02, 6.1733e-04],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,567][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([2.0676e-25, 0.0000e+00, 0.0000e+00, 3.3199e-36, 3.0230e-37, 2.9456e-40,
        1.3815e-37, 3.5488e-18, 7.3734e-19, 8.2949e-14, 9.9999e-01, 8.9006e-06],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,568][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([8.2976e-07, 6.0262e-06, 2.1955e-05, 2.4440e-04, 1.5484e-04, 8.4830e-04,
        2.0219e-03, 4.9893e-03, 3.6408e-02, 4.1374e-01, 2.7214e-01, 2.6943e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,569][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([7.6689e-07, 1.1420e-05, 3.1383e-05, 2.3476e-04, 4.6383e-04, 7.5349e-04,
        1.0696e-03, 2.4904e-03, 3.0033e-02, 1.2762e-01, 6.0015e-01, 2.3714e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,570][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.2159e-07, 9.0845e-07, 1.0651e-05, 4.9093e-05, 5.6382e-05, 6.4780e-04,
        1.0077e-03, 2.9045e-03, 6.9932e-02, 2.8423e-01, 2.8547e-01, 3.5569e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,572][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0687, 0.0794, 0.0693, 0.0909, 0.1226, 0.0350, 0.0400, 0.1416, 0.1143,
        0.0910, 0.1051, 0.0421], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,573][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0767, 0.0947, 0.0874, 0.0694, 0.0990, 0.0866, 0.0919, 0.0915, 0.0834,
        0.0605, 0.0759, 0.0830], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,575][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0025, 0.0044, 0.0228, 0.0093, 0.0254, 0.1026, 0.1394, 0.0520, 0.2240,
        0.0279, 0.0688, 0.3208], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,575][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([9.6868e-09, 6.3875e-07, 3.8282e-06, 4.7030e-05, 5.3711e-05, 3.8298e-04,
        3.0771e-04, 3.0195e-03, 3.2910e-02, 2.8337e-01, 3.4965e-01, 3.3026e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,576][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0348, 0.1354, 0.0491, 0.0860, 0.1186, 0.0444, 0.0629, 0.1753, 0.0374,
        0.0829, 0.1145, 0.0589], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,576][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0066, 0.0361, 0.0262, 0.0573, 0.0375, 0.0560, 0.0516, 0.0544, 0.1097,
        0.2638, 0.1371, 0.1638], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,577][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.0605, 0.0797, 0.0914, 0.0763, 0.0780, 0.0820, 0.0776, 0.0705, 0.0939,
        0.0720, 0.0750, 0.0727, 0.0704], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,577][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([2.2086e-05, 2.3193e-02, 8.3442e-04, 6.4452e-03, 1.6780e-02, 1.7601e-05,
        5.6382e-04, 8.6897e-01, 1.3385e-03, 4.9408e-03, 1.2744e-02, 1.4478e-04,
        6.4010e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,577][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([2.2353e-25, 0.0000e+00, 0.0000e+00, 2.8177e-36, 1.2028e-37, 2.3892e-42,
        3.2678e-40, 1.2632e-19, 1.0311e-21, 7.9237e-16, 2.9548e-04, 4.5242e-11,
        9.9970e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,578][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([1.0546e-07, 1.2568e-06, 7.9096e-06, 5.7105e-05, 1.2936e-04, 4.3459e-04,
        9.3364e-04, 1.6661e-03, 1.9936e-02, 9.6228e-02, 1.5368e-01, 5.6246e-01,
        1.6447e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,578][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([3.5690e-07, 7.6457e-06, 4.0580e-05, 2.9355e-04, 9.4027e-05, 9.2938e-04,
        1.3516e-03, 5.3493e-03, 3.2360e-02, 1.8427e-01, 1.1760e-01, 4.2260e-01,
        2.3511e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,579][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([1.8110e-08, 3.4420e-07, 3.7138e-06, 1.4391e-05, 4.5716e-05, 2.8386e-04,
        4.0199e-04, 1.2052e-03, 2.5910e-02, 1.0251e-01, 2.0278e-01, 5.0477e-01,
        1.6207e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,579][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.0465, 0.0840, 0.0439, 0.0853, 0.1489, 0.0245, 0.0270, 0.1177, 0.0849,
        0.0928, 0.1196, 0.0330, 0.0919], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,581][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.0734, 0.0796, 0.0840, 0.0598, 0.0937, 0.0851, 0.0834, 0.0810, 0.0874,
        0.0528, 0.0737, 0.0782, 0.0679], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,582][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([3.4725e-04, 1.0102e-03, 7.6455e-03, 2.4581e-03, 9.6385e-03, 8.2293e-02,
        1.3700e-01, 1.8009e-02, 2.2522e-01, 1.0512e-02, 4.1915e-02, 4.3644e-01,
        2.7520e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,583][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([3.7738e-09, 2.9109e-07, 2.7948e-06, 2.3798e-05, 4.7466e-05, 4.2579e-04,
        3.9324e-04, 1.0142e-03, 2.0347e-02, 1.0759e-01, 2.4221e-01, 3.3805e-01,
        2.8990e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,585][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.0157, 0.1339, 0.0369, 0.0827, 0.1342, 0.0247, 0.0391, 0.1312, 0.0440,
        0.0766, 0.1100, 0.0437, 0.1274], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,586][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.0071, 0.0315, 0.0311, 0.0562, 0.0398, 0.0586, 0.0491, 0.0488, 0.1170,
        0.2153, 0.1154, 0.1518, 0.0784], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,588][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0603, 0.0736, 0.0815, 0.0716, 0.0727, 0.0755, 0.0725, 0.0662, 0.0824,
        0.0678, 0.0689, 0.0687, 0.0668, 0.0716], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,589][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0038, 0.0927, 0.0132, 0.1979, 0.0275, 0.0045, 0.0354, 0.1840, 0.0428,
        0.2243, 0.0787, 0.0039, 0.0853, 0.0061], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,590][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([2.0758e-23, 0.0000e+00, 0.0000e+00, 3.1103e-38, 2.8710e-41, 1.4013e-45,
        5.8855e-42, 4.1048e-21, 9.5105e-23, 5.0046e-17, 1.1018e-04, 6.6401e-11,
        6.0955e-01, 3.9034e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,591][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.2300e-07, 7.0741e-07, 1.9803e-06, 1.8975e-05, 1.1252e-05, 3.2188e-05,
        2.4429e-04, 5.8298e-04, 4.3642e-03, 2.8029e-02, 3.6665e-02, 1.3692e-01,
        1.6726e-01, 6.2587e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,593][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.4153e-08, 1.1098e-06, 1.9914e-06, 2.0122e-05, 1.8411e-04, 3.2855e-05,
        1.1826e-04, 4.6412e-04, 1.6024e-03, 1.8872e-02, 1.5132e-01, 4.4470e-02,
        4.3736e-01, 3.4556e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,594][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.3342e-08, 2.6629e-08, 4.5387e-07, 1.1434e-06, 1.3187e-06, 7.8039e-06,
        4.3652e-05, 1.4983e-04, 2.7976e-03, 6.2975e-03, 1.5229e-02, 5.7378e-02,
        1.2442e-01, 7.9368e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,596][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0861, 0.0718, 0.0762, 0.0734, 0.0844, 0.0330, 0.0424, 0.1030, 0.1131,
        0.0735, 0.0876, 0.0483, 0.0809, 0.0261], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,597][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0674, 0.0805, 0.0757, 0.0607, 0.0886, 0.0764, 0.0786, 0.0791, 0.0748,
        0.0532, 0.0680, 0.0722, 0.0647, 0.0602], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,598][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0021, 0.0037, 0.0161, 0.0076, 0.0193, 0.0652, 0.0989, 0.0397, 0.1484,
        0.0229, 0.0503, 0.2344, 0.0592, 0.2323], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,598][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([7.9081e-10, 2.2546e-08, 1.4360e-07, 1.7282e-06, 2.0862e-06, 7.1121e-06,
        2.8369e-05, 1.0886e-04, 1.4017e-03, 9.0352e-03, 1.3040e-02, 4.7795e-02,
        1.2777e-01, 8.0081e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,599][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0276, 0.1044, 0.0517, 0.0746, 0.1127, 0.0456, 0.0571, 0.1193, 0.0426,
        0.0711, 0.1044, 0.0525, 0.0973, 0.0390], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,599][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0066, 0.0277, 0.0198, 0.0412, 0.0298, 0.0372, 0.0380, 0.0393, 0.0782,
        0.1696, 0.0971, 0.1141, 0.0739, 0.2274], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,601][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:16:37,601][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 7843],
        [ 2813],
        [ 8213],
        [ 1960],
        [11605],
        [12728],
        [12279],
        [30869],
        [ 6481],
        [ 7595],
        [19617],
        [13736],
        [26136],
        [11818]], device='cuda:0')
[2024-07-24 10:16:37,603][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 4768],
        [15739],
        [11072],
        [13955],
        [13948],
        [10904],
        [25219],
        [16488],
        [13504],
        [20440],
        [17375],
        [25985],
        [18486],
        [ 8362]], device='cuda:0')
[2024-07-24 10:16:37,604][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[22640],
        [11488],
        [ 8154],
        [10524],
        [ 5799],
        [14663],
        [11839],
        [ 8148],
        [18148],
        [15547],
        [34489],
        [15830],
        [18006],
        [24811]], device='cuda:0')
[2024-07-24 10:16:37,606][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[30596],
        [   41],
        [   41],
        [   48],
        [  780],
        [ 3703],
        [  713],
        [24808],
        [ 2984],
        [ 3051],
        [11374],
        [10150],
        [23714],
        [11033]], device='cuda:0')
[2024-07-24 10:16:37,607][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[47219],
        [45014],
        [37875],
        [36625],
        [38177],
        [36787],
        [41018],
        [21010],
        [40905],
        [34297],
        [35269],
        [36363],
        [39599],
        [41999]], device='cuda:0')
[2024-07-24 10:16:37,609][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[17513],
        [35829],
        [31957],
        [29942],
        [29144],
        [30082],
        [29949],
        [31784],
        [27233],
        [25619],
        [21525],
        [18209],
        [17600],
        [24925]], device='cuda:0')
[2024-07-24 10:16:37,610][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[30880],
        [29775],
        [20642],
        [22454],
        [21381],
        [20602],
        [20678],
        [19935],
        [18049],
        [19720],
        [18385],
        [17598],
        [16698],
        [17679]], device='cuda:0')
[2024-07-24 10:16:37,612][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 7820],
        [14031],
        [13690],
        [16933],
        [16084],
        [13398],
        [13732],
        [28148],
        [34898],
        [22896],
        [16180],
        [ 8631],
        [12174],
        [17620]], device='cuda:0')
[2024-07-24 10:16:37,613][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[35822],
        [30403],
        [30354],
        [28285],
        [29489],
        [30263],
        [29646],
        [28894],
        [28224],
        [27673],
        [28620],
        [28641],
        [27889],
        [27921]], device='cuda:0')
[2024-07-24 10:16:37,615][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[24256],
        [20481],
        [20990],
        [23039],
        [19132],
        [15574],
        [13785],
        [11687],
        [10469],
        [12279],
        [11671],
        [11314],
        [10151],
        [ 9232]], device='cuda:0')
[2024-07-24 10:16:37,617][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[13601],
        [ 2503],
        [ 8532],
        [ 2897],
        [ 9548],
        [31212],
        [14356],
        [ 9005],
        [ 7122],
        [ 3288],
        [ 2722],
        [ 5961],
        [ 2477],
        [ 5597]], device='cuda:0')
[2024-07-24 10:16:37,618][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[17911],
        [19271],
        [19325],
        [19391],
        [18793],
        [18787],
        [18801],
        [18745],
        [18497],
        [18587],
        [18474],
        [18345],
        [18255],
        [18200]], device='cuda:0')
[2024-07-24 10:16:37,620][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[2292],
        [1903],
        [2063],
        [2119],
        [1402],
        [1519],
        [1453],
        [1221],
        [1309],
        [1308],
        [1121],
        [1108],
        [1028],
        [1083]], device='cuda:0')
[2024-07-24 10:16:37,621][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[14758],
        [ 9772],
        [ 9393],
        [12808],
        [16980],
        [14704],
        [13703],
        [14438],
        [14639],
        [15739],
        [18584],
        [18009],
        [17599],
        [16039]], device='cuda:0')
[2024-07-24 10:16:37,622][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 9215],
        [ 1499],
        [19377],
        [  909],
        [24627],
        [30010],
        [17037],
        [43363],
        [11517],
        [23551],
        [17705],
        [21607],
        [25186],
        [36209]], device='cuda:0')
[2024-07-24 10:16:37,623][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[9352],
        [9460],
        [9229],
        [9353],
        [9401],
        [9379],
        [9611],
        [9701],
        [9518],
        [9581],
        [9705],
        [9742],
        [9819],
        [9853]], device='cuda:0')
[2024-07-24 10:16:37,624][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[32046],
        [33163],
        [32785],
        [33236],
        [33937],
        [28777],
        [33172],
        [40681],
        [36567],
        [44548],
        [42096],
        [39270],
        [39865],
        [34434]], device='cuda:0')
[2024-07-24 10:16:37,625][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[13991],
        [ 1831],
        [13706],
        [23307],
        [36077],
        [36073],
        [36189],
        [19236],
        [ 5005],
        [21786],
        [ 7498],
        [ 7498],
        [14121],
        [11358]], device='cuda:0')
[2024-07-24 10:16:37,626][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[20373],
        [29053],
        [25914],
        [22837],
        [18075],
        [23867],
        [20852],
        [13878],
        [21872],
        [24893],
        [25814],
        [25942],
        [18372],
        [24694]], device='cuda:0')
[2024-07-24 10:16:37,627][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[14333],
        [ 9401],
        [15108],
        [11669],
        [13622],
        [20153],
        [10973],
        [18961],
        [15901],
        [12351],
        [14125],
        [10970],
        [12871],
        [14520]], device='cuda:0')
[2024-07-24 10:16:37,629][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[21845],
        [ 9086],
        [17580],
        [ 6526],
        [ 5676],
        [ 4543],
        [ 5155],
        [ 6555],
        [ 5645],
        [ 8015],
        [ 8804],
        [ 4466],
        [ 3696],
        [ 5010]], device='cuda:0')
[2024-07-24 10:16:37,630][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[2568],
        [ 798],
        [ 783],
        [ 882],
        [1250],
        [1069],
        [1127],
        [1226],
        [1052],
        [1140],
        [1196],
        [1139],
        [1221],
        [1024]], device='cuda:0')
[2024-07-24 10:16:37,632][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[5958],
        [8310],
        [7996],
        [9349],
        [9467],
        [8984],
        [8862],
        [9009],
        [9126],
        [9501],
        [9483],
        [9382],
        [9534],
        [9531]], device='cuda:0')
[2024-07-24 10:16:37,633][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[30112],
        [19972],
        [25572],
        [25998],
        [25575],
        [26505],
        [28566],
        [28808],
        [28883],
        [29292],
        [28859],
        [29460],
        [30179],
        [29386]], device='cuda:0')
[2024-07-24 10:16:37,635][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 716],
        [ 768],
        [ 980],
        [ 921],
        [1045],
        [1255],
        [1117],
        [ 916],
        [ 862],
        [ 955],
        [ 973],
        [ 949],
        [ 731],
        [1043]], device='cuda:0')
[2024-07-24 10:16:37,636][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 3925],
        [13244],
        [ 7407],
        [ 9826],
        [10113],
        [ 6994],
        [ 4739],
        [ 8857],
        [ 7348],
        [ 8335],
        [ 9360],
        [ 6726],
        [ 8927],
        [ 5826]], device='cuda:0')
[2024-07-24 10:16:37,638][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 7384],
        [16914],
        [17336],
        [15095],
        [14729],
        [14045],
        [13404],
        [13012],
        [12784],
        [13358],
        [13646],
        [13643],
        [13296],
        [11698]], device='cuda:0')
[2024-07-24 10:16:37,639][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[34413],
        [39350],
        [33483],
        [35850],
        [34515],
        [35689],
        [36121],
        [37234],
        [37382],
        [34380],
        [36103],
        [39132],
        [39614],
        [35507]], device='cuda:0')
[2024-07-24 10:16:37,641][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[34215],
        [35907],
        [40629],
        [41975],
        [32631],
        [32002],
        [46054],
        [19133],
        [41545],
        [15477],
        [24191],
        [38183],
        [19811],
        [33297]], device='cuda:0')
[2024-07-24 10:16:37,643][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[49919],
        [49919],
        [49919],
        [49919],
        [49919],
        [49919],
        [49919],
        [49919],
        [49919],
        [49919],
        [49919],
        [49919],
        [49919],
        [49919]], device='cuda:0')
[2024-07-24 10:16:37,675][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:37,676][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,677][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,677][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,677][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,678][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,678][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,678][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,679][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,679][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,679][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,679][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,680][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,680][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.6376, 0.3624], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,680][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.3889, 0.6111], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,681][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([3.3703e-04, 9.9966e-01], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,682][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([1.1773e-04, 9.9988e-01], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,684][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.7684, 0.2316], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,685][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.4954, 0.5046], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,686][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.0978, 0.9022], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,688][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.4818, 0.5182], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,689][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.8790, 0.1210], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,689][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.7493, 0.2507], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,689][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.1730, 0.8270], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,690][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.9306, 0.0694], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,690][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.4450, 0.2068, 0.3482], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,690][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2383, 0.3831, 0.3785], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,691][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([2.0755e-08, 9.9995e-01, 4.8186e-05], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,691][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([7.7858e-06, 7.5491e-01, 2.4508e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,691][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.5139, 0.2110, 0.2751], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,692][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3255, 0.3298, 0.3447], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,692][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0100, 0.5986, 0.3914], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,692][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([2.8804e-04, 9.9952e-01, 1.9231e-04], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,693][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0123, 0.9846, 0.0031], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,693][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0251, 0.9490, 0.0260], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,693][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0696, 0.4402, 0.4902], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,693][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0489, 0.9293, 0.0218], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,694][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Jonathan] are: tensor([0.3215, 0.1615, 0.2324, 0.2846], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,694][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Jonathan] are: tensor([0.1809, 0.2688, 0.2675, 0.2828], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,694][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Jonathan] are: tensor([4.3005e-06, 1.6324e-01, 2.7263e-05, 8.3673e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,695][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Jonathan] are: tensor([4.6964e-06, 9.3041e-04, 1.1083e-04, 9.9895e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,696][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Jonathan] are: tensor([0.4413, 0.2067, 0.2201, 0.1318], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,697][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Jonathan] are: tensor([0.2216, 0.2508, 0.2571, 0.2704], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,699][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Jonathan] are: tensor([0.0537, 0.2437, 0.1420, 0.5607], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,700][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Jonathan] are: tensor([1.5302e-02, 9.1137e-01, 3.3686e-04, 7.2991e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,702][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Jonathan] are: tensor([0.1294, 0.8399, 0.0019, 0.0288], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,703][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Jonathan] are: tensor([0.0787, 0.7229, 0.0079, 0.1905], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,705][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Jonathan] are: tensor([0.0854, 0.2723, 0.3033, 0.3390], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,706][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Jonathan] are: tensor([0.2021, 0.7031, 0.0085, 0.0863], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,707][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.3122, 0.1210, 0.2101, 0.1752, 0.1816], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,707][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.1411, 0.2064, 0.2100, 0.2198, 0.2228], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,707][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ went] are: tensor([1.0832e-06, 1.6752e-01, 4.1916e-05, 8.0608e-01, 2.6359e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,708][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ went] are: tensor([3.2587e-09, 4.6185e-05, 1.0366e-05, 9.9734e-01, 2.6012e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,708][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.3544, 0.1581, 0.1737, 0.1210, 0.1927], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,708][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.1700, 0.1917, 0.2050, 0.2035, 0.2298], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,708][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0194, 0.1850, 0.1382, 0.4789, 0.1785], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,709][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ went] are: tensor([6.2556e-04, 7.0988e-01, 8.6878e-05, 2.6311e-01, 2.6297e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,709][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0274, 0.8123, 0.0021, 0.1285, 0.0298], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,709][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.0995, 0.6807, 0.0126, 0.1528, 0.0544], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,710][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0540, 0.1974, 0.2403, 0.2602, 0.2481], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,710][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.2282, 0.5957, 0.0122, 0.1248, 0.0392], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,710][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2694, 0.1219, 0.1814, 0.1590, 0.1280, 0.1404], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,710][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1109, 0.1722, 0.1762, 0.1852, 0.1866, 0.1689], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,711][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([3.7256e-09, 6.0707e-02, 3.2433e-05, 8.2553e-01, 1.1101e-01, 2.7217e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,712][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.7295e-11, 2.4206e-05, 8.5729e-06, 7.5966e-01, 2.4030e-01, 3.6531e-06],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,714][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.3043, 0.1282, 0.1691, 0.0960, 0.1834, 0.1189], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,715][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1546, 0.1662, 0.1694, 0.2002, 0.2039, 0.1058], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,717][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0129, 0.1466, 0.1289, 0.3893, 0.1912, 0.1310], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,717][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([2.7932e-05, 4.1178e-01, 4.0125e-05, 3.0943e-01, 2.7840e-01, 3.2464e-04],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,719][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0020, 0.5337, 0.0018, 0.2199, 0.2391, 0.0034], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,721][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0017, 0.1667, 0.0013, 0.1634, 0.6661, 0.0007], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,722][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0460, 0.1511, 0.1786, 0.2070, 0.2180, 0.1992], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,724][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0046, 0.6403, 0.0025, 0.1934, 0.1545, 0.0047], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,726][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.2161, 0.1031, 0.1570, 0.1302, 0.1097, 0.1061, 0.1778],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,727][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0957, 0.1462, 0.1498, 0.1592, 0.1593, 0.1459, 0.1439],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,728][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ the] are: tensor([1.9302e-09, 5.1012e-02, 7.5652e-06, 8.1059e-01, 1.2600e-01, 1.0652e-02,
        1.7417e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,729][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ the] are: tensor([1.9396e-11, 1.2207e-04, 1.6871e-05, 8.5914e-01, 1.4071e-01, 1.3252e-05,
        5.2704e-07], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,730][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2725, 0.1153, 0.1567, 0.0863, 0.1469, 0.0998, 0.1225],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,730][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1287, 0.1513, 0.1407, 0.1760, 0.1762, 0.0981, 0.1289],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,730][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0081, 0.1248, 0.0971, 0.3500, 0.1746, 0.1189, 0.1266],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,731][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ the] are: tensor([1.2219e-05, 4.6872e-01, 1.5281e-05, 2.2171e-01, 3.0904e-01, 4.4209e-04,
        5.6736e-05], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,731][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ the] are: tensor([8.0330e-04, 6.7802e-01, 4.3939e-04, 1.1504e-01, 2.0226e-01, 3.0832e-03,
        3.5235e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,731][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0015, 0.4785, 0.0022, 0.2238, 0.2884, 0.0027, 0.0029],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,731][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0378, 0.1377, 0.1487, 0.1831, 0.1872, 0.1681, 0.1374],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,732][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0045, 0.6506, 0.0021, 0.2399, 0.0931, 0.0083, 0.0016],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,732][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.2046, 0.0849, 0.1455, 0.1040, 0.0963, 0.0998, 0.1516, 0.1134],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,732][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([0.0899, 0.1252, 0.1313, 0.1349, 0.1365, 0.1236, 0.1221, 0.1364],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,733][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([2.5389e-07, 1.9661e-02, 4.5241e-06, 1.9158e-01, 2.9331e-02, 1.5446e-03,
        1.7750e-03, 7.5610e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,733][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([1.1526e-09, 2.5064e-04, 6.5350e-06, 9.9136e-01, 7.9984e-03, 1.8249e-06,
        2.4531e-07, 3.8549e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,733][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.2778, 0.1192, 0.1307, 0.0816, 0.1288, 0.0862, 0.0980, 0.0777],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,734][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.1006, 0.1325, 0.1261, 0.1663, 0.1641, 0.0852, 0.1132, 0.1121],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,736][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.0103, 0.0789, 0.0460, 0.2461, 0.1118, 0.0834, 0.0890, 0.3345],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,737][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([1.0345e-03, 6.1540e-01, 8.3867e-05, 1.8882e-01, 1.7133e-01, 2.3836e-04,
        8.4366e-05, 2.3008e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,738][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([1.3686e-02, 5.8976e-01, 6.7614e-04, 2.2734e-01, 8.0186e-02, 1.6800e-03,
        3.4925e-04, 8.6327e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,739][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.0268, 0.8080, 0.0044, 0.0706, 0.0561, 0.0035, 0.0036, 0.0270],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,740][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.0437, 0.1048, 0.0886, 0.1418, 0.1186, 0.1287, 0.1057, 0.2681],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,742][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.0917, 0.5709, 0.0065, 0.1220, 0.1204, 0.0072, 0.0025, 0.0789],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,744][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1818, 0.0784, 0.1323, 0.0993, 0.0858, 0.0898, 0.1386, 0.0826, 0.1116],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,745][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0673, 0.1149, 0.1122, 0.1210, 0.1193, 0.1093, 0.1076, 0.1231, 0.1253],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,746][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([1.6744e-10, 1.7127e-02, 8.5782e-06, 1.8309e-01, 2.3647e-02, 8.1321e-04,
        1.3113e-03, 7.7399e-01, 1.2085e-05], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,748][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([1.1239e-12, 1.5961e-04, 1.3912e-05, 6.6373e-01, 3.1865e-01, 3.5069e-05,
        3.3405e-06, 1.7410e-02, 2.5573e-09], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,749][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2289, 0.0856, 0.1237, 0.0651, 0.1197, 0.0831, 0.0957, 0.0960, 0.1022],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,751][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1036, 0.1138, 0.1108, 0.1344, 0.1412, 0.0786, 0.1075, 0.1038, 0.1062],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,752][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0030, 0.0915, 0.0686, 0.2292, 0.0939, 0.0646, 0.0821, 0.3142, 0.0528],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,753][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([3.2174e-06, 2.5507e-01, 1.1994e-05, 1.8689e-01, 2.1017e-01, 4.1413e-04,
        2.2369e-04, 3.4716e-01, 6.2066e-05], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,753][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([6.5181e-05, 2.3393e-01, 2.1416e-04, 5.1050e-02, 3.6985e-01, 2.2381e-03,
        1.2189e-03, 3.4130e-01, 1.2928e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,753][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0005, 0.4986, 0.0027, 0.1824, 0.1320, 0.0022, 0.0039, 0.1766, 0.0010],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,754][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0223, 0.0876, 0.0785, 0.1203, 0.1243, 0.0974, 0.0777, 0.2865, 0.1055],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,754][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0005, 0.3342, 0.0030, 0.0814, 0.2263, 0.0073, 0.0032, 0.3414, 0.0028],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,754][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Jonathan] are: tensor([0.1574, 0.0767, 0.1095, 0.1349, 0.0754, 0.0779, 0.1176, 0.0613, 0.0872,
        0.1021], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,755][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Jonathan] are: tensor([0.0678, 0.0983, 0.0979, 0.1036, 0.1067, 0.0996, 0.1001, 0.1081, 0.1064,
        0.1114], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,755][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Jonathan] are: tensor([3.1206e-07, 1.2133e-02, 1.7600e-06, 7.9532e-02, 1.5375e-02, 1.2886e-03,
        6.5647e-04, 5.0509e-01, 2.5416e-05, 3.8590e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,755][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Jonathan] are: tensor([7.8466e-08, 3.0998e-03, 1.6133e-04, 8.8901e-01, 4.6494e-02, 4.9152e-05,
        8.1125e-06, 6.0020e-02, 1.5540e-07, 1.1559e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,756][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Jonathan] are: tensor([0.2394, 0.0997, 0.1098, 0.0622, 0.0980, 0.0751, 0.0864, 0.0926, 0.0877,
        0.0489], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,756][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Jonathan] are: tensor([0.0906, 0.1000, 0.1060, 0.1107, 0.1170, 0.0750, 0.1022, 0.0894, 0.0979,
        0.1112], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,756][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Jonathan] are: tensor([0.0136, 0.0650, 0.0332, 0.1502, 0.0840, 0.0668, 0.0670, 0.2254, 0.0514,
        0.2434], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,757][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Jonathan] are: tensor([1.3390e-02, 5.2982e-01, 6.6587e-05, 2.4512e-02, 1.8022e-01, 1.4125e-04,
        6.4682e-05, 1.6366e-01, 5.1436e-05, 8.8078e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,758][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Jonathan] are: tensor([5.9140e-02, 5.5009e-01, 4.1263e-04, 1.7763e-02, 6.5994e-02, 5.9667e-04,
        2.8649e-04, 2.3443e-01, 1.0527e-04, 7.1182e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,760][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Jonathan] are: tensor([0.0448, 0.4401, 0.0031, 0.1193, 0.0516, 0.0014, 0.0034, 0.0797, 0.0018,
        0.2548], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,761][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Jonathan] are: tensor([0.0316, 0.0916, 0.0775, 0.1135, 0.0872, 0.0951, 0.0814, 0.1658, 0.1021,
        0.1541], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,763][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Jonathan] are: tensor([0.0777, 0.5435, 0.0033, 0.0485, 0.0405, 0.0028, 0.0012, 0.1736, 0.0014,
        0.1075], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,764][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.1556, 0.0647, 0.1113, 0.0979, 0.0742, 0.0791, 0.1109, 0.0714, 0.0893,
        0.0754, 0.0701], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,765][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0613, 0.0882, 0.0906, 0.0931, 0.0951, 0.0884, 0.0877, 0.0957, 0.0984,
        0.1021, 0.0993], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,767][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([1.0578e-07, 2.2175e-02, 2.7115e-06, 9.0338e-02, 5.5387e-03, 4.5861e-04,
        5.0806e-04, 3.3905e-01, 1.4862e-05, 5.2896e-01, 1.2960e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,768][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([5.5800e-12, 1.3633e-04, 2.4941e-05, 9.4894e-01, 4.4774e-02, 1.9827e-05,
        1.9534e-06, 5.3963e-03, 1.3815e-08, 7.1045e-04, 2.6570e-07],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,769][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.2056, 0.0698, 0.1014, 0.0626, 0.1069, 0.0697, 0.0892, 0.0983, 0.0827,
        0.0511, 0.0628], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,771][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0720, 0.0984, 0.0932, 0.1106, 0.1040, 0.0616, 0.0886, 0.0833, 0.0881,
        0.1081, 0.0921], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,773][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0124, 0.0660, 0.0463, 0.1574, 0.0753, 0.0570, 0.0581, 0.1595, 0.0449,
        0.2216, 0.1016], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,774][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([1.1657e-03, 3.6260e-01, 3.0888e-05, 9.9126e-02, 7.6670e-02, 5.5629e-05,
        3.3043e-05, 5.5218e-02, 6.7494e-05, 3.5981e-01, 4.5226e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,775][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([1.4730e-02, 4.6349e-01, 4.9196e-04, 3.9855e-02, 5.8551e-02, 7.0011e-04,
        2.2852e-04, 2.7267e-01, 1.7483e-04, 1.2277e-01, 2.6337e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,776][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0348, 0.5071, 0.0050, 0.0925, 0.0705, 0.0024, 0.0031, 0.1042, 0.0042,
        0.1461, 0.0302], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,776][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0278, 0.0670, 0.0578, 0.0914, 0.0875, 0.0785, 0.0659, 0.1658, 0.0847,
        0.1218, 0.1518], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,777][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0711, 0.4887, 0.0051, 0.0797, 0.0486, 0.0036, 0.0008, 0.1503, 0.0026,
        0.1101, 0.0394], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,777][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1474, 0.0684, 0.0986, 0.0843, 0.0689, 0.0676, 0.1073, 0.0675, 0.0801,
        0.0663, 0.0507, 0.0930], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,777][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0545, 0.0793, 0.0827, 0.0853, 0.0858, 0.0800, 0.0789, 0.0882, 0.0899,
        0.0946, 0.0922, 0.0885], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,778][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([1.2758e-08, 6.2855e-03, 6.2386e-07, 6.5908e-02, 9.4012e-03, 5.5283e-04,
        3.3049e-04, 3.4144e-01, 1.0166e-05, 4.3423e-01, 3.6777e-02, 1.0507e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,778][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([4.4221e-12, 7.3907e-05, 2.6789e-05, 2.0557e-01, 7.8266e-01, 1.1105e-04,
        4.6238e-06, 1.1485e-02, 1.4178e-08, 6.3934e-05, 4.0259e-06, 1.6819e-08],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,778][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1623, 0.0720, 0.0981, 0.0555, 0.1005, 0.0638, 0.0804, 0.0897, 0.0832,
        0.0464, 0.0681, 0.0798], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,779][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0694, 0.0906, 0.0816, 0.0997, 0.1005, 0.0567, 0.0779, 0.0781, 0.0781,
        0.0988, 0.0903, 0.0783], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,779][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0044, 0.0475, 0.0296, 0.1263, 0.0673, 0.0472, 0.0477, 0.1873, 0.0401,
        0.2068, 0.1002, 0.0955], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,779][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([2.2705e-03, 7.5192e-02, 4.0665e-06, 2.1584e-02, 4.0684e-02, 2.3550e-05,
        7.3237e-06, 5.8758e-02, 7.1569e-06, 1.0576e-01, 2.7805e-01, 4.1766e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,780][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([2.6993e-02, 2.2685e-01, 9.1093e-05, 2.1765e-02, 3.2138e-02, 2.0014e-04,
        1.9753e-05, 5.1762e-02, 2.8206e-05, 1.0688e-01, 1.0987e-01, 4.2339e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,780][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([8.4307e-03, 8.8523e-02, 5.4379e-04, 3.1144e-02, 5.2247e-02, 5.1685e-04,
        3.7738e-04, 1.8192e-02, 3.0897e-04, 5.9508e-02, 6.1543e-01, 1.2478e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,782][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0217, 0.0568, 0.0439, 0.0816, 0.0816, 0.0637, 0.0550, 0.1667, 0.0676,
        0.1105, 0.1475, 0.1033], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,784][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0800, 0.3154, 0.0012, 0.0396, 0.0519, 0.0018, 0.0005, 0.0484, 0.0011,
        0.0790, 0.1365, 0.2446], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,785][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.1432, 0.0645, 0.0929, 0.0773, 0.0622, 0.0612, 0.0985, 0.0607, 0.0764,
        0.0589, 0.0462, 0.0725, 0.0854], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,786][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.0533, 0.0732, 0.0775, 0.0782, 0.0799, 0.0720, 0.0701, 0.0795, 0.0837,
        0.0866, 0.0849, 0.0795, 0.0815], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,787][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([3.1227e-07, 2.4845e-04, 3.0060e-08, 1.3672e-03, 4.1482e-04, 2.5728e-05,
        2.6525e-05, 1.1364e-02, 7.2227e-07, 1.8001e-02, 1.9102e-03, 5.0714e-02,
        9.1593e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,789][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([2.0121e-08, 1.7915e-03, 1.2591e-04, 6.6831e-01, 2.1196e-01, 1.9923e-04,
        3.7408e-05, 1.1020e-01, 2.6226e-07, 3.8705e-04, 1.7134e-06, 6.3018e-07,
        6.9874e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,790][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.2050, 0.0638, 0.0900, 0.0539, 0.0923, 0.0675, 0.0676, 0.0870, 0.0750,
        0.0425, 0.0561, 0.0681, 0.0312], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,792][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.0649, 0.0723, 0.0722, 0.0871, 0.0959, 0.0552, 0.0703, 0.0707, 0.0702,
        0.0874, 0.0920, 0.0735, 0.0883], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,793][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.0068, 0.0345, 0.0165, 0.0991, 0.0487, 0.0384, 0.0363, 0.1435, 0.0294,
        0.1723, 0.0819, 0.0867, 0.2059], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,794][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([8.2793e-03, 9.9601e-03, 2.5933e-06, 9.8867e-04, 1.7472e-03, 2.1491e-06,
        1.2375e-06, 2.2780e-03, 1.0499e-06, 3.1174e-03, 1.5312e-02, 4.5881e-02,
        9.1243e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,796][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([5.4848e-02, 1.9979e-02, 1.9098e-05, 1.4774e-03, 3.8531e-03, 3.2122e-05,
        5.9450e-06, 1.0928e-02, 4.9192e-06, 7.4116e-03, 1.2101e-02, 7.4096e-02,
        8.1524e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,797][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.1319, 0.0286, 0.0011, 0.0147, 0.0174, 0.0009, 0.0008, 0.0142, 0.0005,
        0.0327, 0.0641, 0.2132, 0.4800], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,799][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.0224, 0.0488, 0.0348, 0.0708, 0.0649, 0.0587, 0.0471, 0.1452, 0.0583,
        0.0943, 0.1185, 0.0844, 0.1517], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,799][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([9.6821e-02, 3.7767e-02, 5.3786e-04, 7.5662e-03, 6.9295e-03, 3.2861e-04,
        1.2782e-04, 1.4364e-02, 2.9186e-04, 1.4836e-02, 2.3443e-02, 9.3837e-02,
        7.0315e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,799][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1283, 0.0598, 0.0882, 0.0768, 0.0605, 0.0658, 0.0939, 0.0574, 0.0727,
        0.0602, 0.0460, 0.0716, 0.0559, 0.0628], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,800][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0448, 0.0674, 0.0701, 0.0725, 0.0730, 0.0654, 0.0645, 0.0759, 0.0769,
        0.0817, 0.0784, 0.0746, 0.0774, 0.0775], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,800][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([3.4248e-09, 2.7325e-04, 4.2302e-08, 2.0489e-03, 4.6070e-04, 8.4345e-06,
        2.7746e-05, 1.3986e-02, 8.5881e-07, 2.2945e-02, 3.9346e-03, 2.7007e-02,
        9.0861e-01, 2.0702e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,801][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.8857e-11, 3.3747e-05, 1.9930e-05, 7.4498e-02, 9.2214e-01, 5.8042e-05,
        1.1446e-05, 3.1187e-03, 1.4655e-08, 3.4355e-05, 4.4567e-06, 4.9548e-08,
        7.7058e-05, 8.1173e-08], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,801][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1619, 0.0630, 0.0861, 0.0474, 0.0917, 0.0615, 0.0707, 0.0739, 0.0735,
        0.0387, 0.0597, 0.0684, 0.0538, 0.0498], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,801][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0659, 0.0697, 0.0701, 0.0830, 0.0842, 0.0467, 0.0669, 0.0627, 0.0681,
        0.0821, 0.0819, 0.0706, 0.0832, 0.0649], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,802][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0072, 0.0377, 0.0244, 0.0972, 0.0531, 0.0377, 0.0407, 0.1122, 0.0335,
        0.1497, 0.0745, 0.0768, 0.1546, 0.1007], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,802][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([1.1442e-03, 5.8945e-04, 7.1162e-08, 1.4571e-04, 9.9675e-05, 5.4430e-08,
        5.4183e-08, 2.6304e-04, 7.7955e-08, 5.8201e-04, 2.6416e-03, 1.2580e-02,
        6.1759e-01, 3.6437e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,802][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([1.0535e-02, 2.5306e-03, 3.5301e-06, 3.3026e-04, 1.4345e-04, 1.2208e-06,
        1.4140e-06, 1.3743e-03, 7.8292e-07, 1.2538e-03, 2.4049e-03, 2.6691e-02,
        4.5968e-01, 4.9505e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,803][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([3.9876e-02, 2.1291e-02, 2.0551e-04, 9.8647e-03, 3.5323e-02, 3.7529e-05,
        2.2510e-04, 5.3159e-03, 1.6990e-04, 2.6313e-02, 2.8356e-01, 1.1496e-01,
        3.4044e-01, 1.2242e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,805][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0223, 0.0405, 0.0273, 0.0639, 0.0630, 0.0457, 0.0385, 0.1185, 0.0480,
        0.0867, 0.1144, 0.0751, 0.1303, 0.1259], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,806][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.4802e-02, 2.0666e-02, 7.9549e-05, 2.5537e-03, 2.5797e-03, 4.4910e-05,
        4.4289e-05, 4.2916e-03, 5.7991e-05, 5.5225e-03, 1.5974e-02, 6.4798e-02,
        5.1353e-01, 3.4506e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,835][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:37,836][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,836][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,836][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,837][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,837][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,837][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,837][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,838][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,838][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,838][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,839][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,840][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:37,841][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.3958, 0.6042], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,843][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.6666, 0.3334], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,844][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.9762, 0.0238], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,846][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.1773, 0.8227], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,848][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.4225, 0.5775], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,849][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.9581, 0.0419], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,850][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.9511, 0.0489], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,853][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.4818, 0.5182], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,854][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.8790, 0.1210], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,856][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.7493, 0.2507], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,857][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.9941, 0.0059], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,857][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.9306, 0.0694], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:37,857][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0627, 0.0023, 0.9350], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,857][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0093, 0.9867, 0.0040], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,858][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([3.1918e-03, 9.9658e-01, 2.3040e-04], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,858][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([1.1711e-04, 9.9954e-01, 3.4193e-04], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,858][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2490, 0.3446, 0.4064], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,858][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3112, 0.6565, 0.0324], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,859][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0063, 0.9925, 0.0012], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,859][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([2.8804e-04, 9.9952e-01, 1.9231e-04], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,859][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0123, 0.9846, 0.0031], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,860][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0251, 0.9490, 0.0260], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,860][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9329, 0.0565, 0.0106], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,860][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0489, 0.9293, 0.0218], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:37,860][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Jonathan] are: tensor([0.0291, 0.0051, 0.2176, 0.7482], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,861][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Jonathan] are: tensor([0.1506, 0.7018, 0.0195, 0.1281], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,862][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Jonathan] are: tensor([2.9233e-01, 6.5748e-01, 4.7632e-04, 4.9714e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,863][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Jonathan] are: tensor([8.1586e-03, 9.0593e-01, 2.4558e-04, 8.5670e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,865][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Jonathan] are: tensor([0.1875, 0.2837, 0.2779, 0.2509], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,866][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Jonathan] are: tensor([0.8898, 0.0802, 0.0196, 0.0104], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,867][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Jonathan] are: tensor([0.3133, 0.5626, 0.0056, 0.1185], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,869][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Jonathan] are: tensor([1.5302e-02, 9.1137e-01, 3.3686e-04, 7.2991e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,870][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Jonathan] are: tensor([0.1294, 0.8399, 0.0019, 0.0288], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,872][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Jonathan] are: tensor([0.0787, 0.7229, 0.0079, 0.1905], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,873][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Jonathan] are: tensor([0.9274, 0.0421, 0.0029, 0.0276], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,875][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Jonathan] are: tensor([0.2021, 0.7031, 0.0085, 0.0863], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:37,877][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.1809, 0.0011, 0.4915, 0.0204, 0.3061], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,878][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0316, 0.7553, 0.0113, 0.1666, 0.0351], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,879][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([1.3281e-02, 8.9531e-01, 1.4323e-04, 8.2835e-02, 8.4353e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,880][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([1.9577e-03, 6.2538e-01, 1.5666e-04, 3.1236e-01, 6.0151e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,882][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.1441, 0.2159, 0.2197, 0.1963, 0.2240], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,884][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.6594, 0.1898, 0.0668, 0.0445, 0.0395], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,885][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.0269, 0.7544, 0.0013, 0.2032, 0.0143], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,885][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([6.2556e-04, 7.0988e-01, 8.6878e-05, 2.6311e-01, 2.6297e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,885][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.0274, 0.8123, 0.0021, 0.1285, 0.0298], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,886][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.0995, 0.6807, 0.0126, 0.1528, 0.0544], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,886][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.9089, 0.0260, 0.0041, 0.0298, 0.0312], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,886][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.2282, 0.5957, 0.0122, 0.1248, 0.0392], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:37,886][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0497, 0.0023, 0.1411, 0.0167, 0.0118, 0.7785], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,887][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0027, 0.6840, 0.0047, 0.2364, 0.0687, 0.0035], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,887][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([3.3334e-04, 5.9915e-01, 6.7941e-05, 1.6321e-01, 2.3714e-01, 1.0555e-04],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,887][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.2915e-05, 5.3252e-02, 6.6216e-06, 4.1043e-02, 9.0552e-01, 1.6462e-04],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,888][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1214, 0.1735, 0.1957, 0.1577, 0.1975, 0.1543], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,888][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.2705, 0.4344, 0.0507, 0.1185, 0.0792, 0.0466], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,888][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0019, 0.5253, 0.0008, 0.3527, 0.1186, 0.0007], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,888][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([2.7932e-05, 4.1178e-01, 4.0125e-05, 3.0943e-01, 2.7840e-01, 3.2464e-04],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,889][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0020, 0.5337, 0.0018, 0.2199, 0.2391, 0.0034], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,891][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0017, 0.1667, 0.0013, 0.1634, 0.6661, 0.0007], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,892][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.6406, 0.0793, 0.0118, 0.0958, 0.1513, 0.0212], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,894][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0046, 0.6403, 0.0025, 0.1934, 0.1545, 0.0047], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:37,895][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([8.4299e-03, 6.8944e-04, 6.6850e-02, 3.5158e-03, 3.9937e-03, 4.9759e-02,
        8.6676e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,896][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0022, 0.6147, 0.0039, 0.2764, 0.0917, 0.0048, 0.0063],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,897][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([3.0447e-04, 6.0168e-01, 3.8560e-05, 1.2422e-01, 2.7278e-01, 8.9679e-04,
        7.7041e-05], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,898][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([4.5210e-06, 3.5999e-01, 9.0502e-06, 1.8844e-01, 4.5089e-01, 6.4662e-04,
        1.5557e-05], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,899][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1033, 0.1474, 0.1676, 0.1350, 0.1601, 0.1314, 0.1552],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,901][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1913, 0.4575, 0.0566, 0.1244, 0.0860, 0.0445, 0.0397],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,902][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([1.1450e-03, 5.6152e-01, 5.2240e-04, 3.4652e-01, 8.8487e-02, 1.4492e-03,
        3.5155e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,903][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([1.2219e-05, 4.6872e-01, 1.5281e-05, 2.2171e-01, 3.0904e-01, 4.4209e-04,
        5.6736e-05], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,904][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([8.0330e-04, 6.7802e-01, 4.3939e-04, 1.1504e-01, 2.0226e-01, 3.0832e-03,
        3.5235e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,906][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0015, 0.4785, 0.0022, 0.2238, 0.2884, 0.0027, 0.0029],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,907][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.5971, 0.1117, 0.0071, 0.0853, 0.1624, 0.0087, 0.0277],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,908][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0045, 0.6506, 0.0021, 0.2399, 0.0931, 0.0083, 0.0016],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:37,908][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([9.8605e-03, 2.6612e-04, 1.4703e-01, 5.1961e-04, 3.6737e-03, 2.7445e-01,
        5.4864e-01, 1.5561e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,908][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([0.0810, 0.4968, 0.0124, 0.2564, 0.0948, 0.0084, 0.0107, 0.0396],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,909][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([5.6383e-02, 6.1715e-01, 4.2761e-04, 1.2117e-01, 1.3619e-01, 3.9584e-04,
        5.9935e-04, 6.7683e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,909][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([2.2119e-03, 6.0095e-01, 5.2280e-05, 2.0105e-01, 1.5861e-01, 1.5299e-04,
        1.9038e-05, 3.6952e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,909][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.0885, 0.1425, 0.1510, 0.1230, 0.1430, 0.1161, 0.1352, 0.1007],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,910][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.3200, 0.2364, 0.0312, 0.1443, 0.1099, 0.0372, 0.0531, 0.0678],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,910][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.0265, 0.6532, 0.0025, 0.2216, 0.0695, 0.0021, 0.0009, 0.0236],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,910][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([1.0345e-03, 6.1540e-01, 8.3867e-05, 1.8882e-01, 1.7133e-01, 2.3836e-04,
        8.4366e-05, 2.3008e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,911][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([1.3686e-02, 5.8976e-01, 6.7614e-04, 2.2734e-01, 8.0186e-02, 1.6800e-03,
        3.4925e-04, 8.6327e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,911][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.0268, 0.8080, 0.0044, 0.0706, 0.0561, 0.0035, 0.0036, 0.0270],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,911][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.8891, 0.0201, 0.0037, 0.0160, 0.0206, 0.0019, 0.0026, 0.0460],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,912][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.0917, 0.5709, 0.0065, 0.1220, 0.1204, 0.0072, 0.0025, 0.0789],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:37,913][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0191, 0.0005, 0.1258, 0.0033, 0.0062, 0.1203, 0.3050, 0.0018, 0.4181],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,915][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0006, 0.6162, 0.0036, 0.2247, 0.0836, 0.0057, 0.0109, 0.0523, 0.0024],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,916][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([4.6904e-05, 5.1300e-01, 6.4032e-05, 1.1112e-01, 2.8297e-01, 4.7044e-04,
        8.6361e-04, 9.1445e-02, 2.1679e-05], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,917][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([1.7308e-06, 2.7740e-01, 5.1567e-06, 9.1239e-02, 1.7631e-01, 3.2786e-04,
        6.4535e-05, 4.5460e-01, 4.8030e-05], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,918][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0791, 0.1099, 0.1325, 0.1039, 0.1240, 0.1019, 0.1194, 0.0983, 0.1309],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,920][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0523, 0.3062, 0.0218, 0.1187, 0.1099, 0.0317, 0.0459, 0.2940, 0.0194],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,920][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([1.0344e-04, 6.9443e-01, 4.9867e-04, 1.9397e-01, 4.8194e-02, 8.5874e-04,
        8.9778e-04, 6.0873e-02, 1.7372e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,920][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([3.2174e-06, 2.5507e-01, 1.1994e-05, 1.8689e-01, 2.1017e-01, 4.1413e-04,
        2.2369e-04, 3.4716e-01, 6.2066e-05], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,921][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([6.5181e-05, 2.3393e-01, 2.1416e-04, 5.1050e-02, 3.6985e-01, 2.2381e-03,
        1.2189e-03, 3.4130e-01, 1.2928e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,921][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0005, 0.4986, 0.0027, 0.1824, 0.1320, 0.0022, 0.0039, 0.1766, 0.0010],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,921][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.3783, 0.0862, 0.0153, 0.0849, 0.1244, 0.0118, 0.0325, 0.2519, 0.0147],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,922][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0005, 0.3342, 0.0030, 0.0814, 0.2263, 0.0073, 0.0032, 0.3414, 0.0028],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:37,922][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Jonathan] are: tensor([1.1086e-02, 2.1454e-03, 7.2987e-02, 1.9013e-01, 3.5491e-03, 1.1437e-01,
        2.6117e-01, 7.3465e-05, 2.5094e-01, 9.3547e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,923][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Jonathan] are: tensor([0.0724, 0.4696, 0.0113, 0.0715, 0.0868, 0.0062, 0.0093, 0.1309, 0.0054,
        0.1366], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,924][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Jonathan] are: tensor([1.5205e-01, 5.5793e-01, 1.8372e-04, 3.6085e-02, 5.4392e-02, 2.5329e-04,
        1.7390e-04, 7.6573e-02, 3.8421e-05, 1.2231e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,925][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Jonathan] are: tensor([9.4733e-03, 4.6129e-01, 4.0132e-05, 2.8012e-02, 1.1147e-01, 1.2806e-04,
        1.0736e-05, 1.2797e-01, 2.2172e-05, 2.6158e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,927][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Jonathan] are: tensor([0.0737, 0.1130, 0.1161, 0.1008, 0.1113, 0.0937, 0.1078, 0.0862, 0.1131,
        0.0843], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,929][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Jonathan] are: tensor([0.6185, 0.1417, 0.0348, 0.0234, 0.0277, 0.0213, 0.0203, 0.0755, 0.0097,
        0.0270], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,930][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Jonathan] are: tensor([1.7558e-01, 4.3576e-01, 1.8818e-03, 7.6191e-02, 3.5551e-02, 9.0250e-04,
        2.5496e-04, 5.5381e-02, 5.1961e-04, 2.1798e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,931][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Jonathan] are: tensor([1.3390e-02, 5.2982e-01, 6.6587e-05, 2.4512e-02, 1.8022e-01, 1.4125e-04,
        6.4682e-05, 1.6366e-01, 5.1436e-05, 8.8078e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,932][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Jonathan] are: tensor([5.9140e-02, 5.5009e-01, 4.1263e-04, 1.7763e-02, 6.5994e-02, 5.9667e-04,
        2.8649e-04, 2.3443e-01, 1.0527e-04, 7.1182e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,933][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Jonathan] are: tensor([0.0448, 0.4401, 0.0031, 0.1193, 0.0516, 0.0014, 0.0034, 0.0797, 0.0018,
        0.2548], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,933][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Jonathan] are: tensor([0.7386, 0.0936, 0.0032, 0.0433, 0.0205, 0.0014, 0.0033, 0.0136, 0.0013,
        0.0813], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,934][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Jonathan] are: tensor([0.0777, 0.5435, 0.0033, 0.0485, 0.0405, 0.0028, 0.0012, 0.1736, 0.0014,
        0.1075], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:37,934][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0188, 0.0006, 0.1108, 0.0111, 0.0061, 0.2110, 0.2027, 0.0016, 0.3807,
        0.0081, 0.0484], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,934][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0352, 0.3928, 0.0092, 0.1195, 0.0401, 0.0030, 0.0062, 0.0391, 0.0044,
        0.3038, 0.0466], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,935][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([1.7017e-02, 6.2608e-01, 4.1740e-05, 4.6003e-02, 1.1117e-02, 1.0307e-04,
        1.2706e-04, 4.7295e-02, 1.1521e-05, 2.2606e-01, 2.6139e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,935][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([2.1135e-03, 3.2024e-01, 3.9939e-05, 7.1200e-02, 7.5344e-02, 1.4174e-04,
        1.1886e-05, 4.7544e-02, 4.9678e-05, 4.2025e-01, 6.3067e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,935][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0680, 0.0933, 0.1082, 0.0896, 0.1049, 0.0857, 0.1026, 0.0857, 0.1066,
        0.0758, 0.0796], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,936][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.2404, 0.2366, 0.0380, 0.0605, 0.0426, 0.0286, 0.0202, 0.1848, 0.0206,
        0.0810, 0.0469], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,936][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([1.0180e-02, 4.2250e-01, 3.7128e-04, 1.2211e-01, 2.4605e-02, 2.7450e-04,
        1.7274e-04, 3.9013e-02, 1.8062e-04, 3.6709e-01, 1.3505e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,936][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([1.1657e-03, 3.6260e-01, 3.0888e-05, 9.9126e-02, 7.6670e-02, 5.5629e-05,
        3.3043e-05, 5.5218e-02, 6.7494e-05, 3.5981e-01, 4.5226e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,937][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([1.4730e-02, 4.6349e-01, 4.9196e-04, 3.9855e-02, 5.8551e-02, 7.0011e-04,
        2.2852e-04, 2.7267e-01, 1.7483e-04, 1.2277e-01, 2.6337e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,937][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0348, 0.5071, 0.0050, 0.0925, 0.0705, 0.0024, 0.0031, 0.1042, 0.0042,
        0.1461, 0.0302], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,939][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.6935, 0.0289, 0.0038, 0.0242, 0.0712, 0.0027, 0.0050, 0.0524, 0.0023,
        0.0666, 0.0495], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,941][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0711, 0.4887, 0.0051, 0.0797, 0.0486, 0.0036, 0.0008, 0.1503, 0.0026,
        0.1101, 0.0394], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:37,942][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0053, 0.0008, 0.0223, 0.0017, 0.0026, 0.0315, 0.1491, 0.0015, 0.0847,
        0.0012, 0.0016, 0.6978], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,944][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0374, 0.1906, 0.0032, 0.0501, 0.0278, 0.0013, 0.0018, 0.0259, 0.0020,
        0.1185, 0.0529, 0.4885], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,944][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([5.3611e-02, 3.7406e-01, 3.3612e-05, 4.3394e-02, 3.2712e-02, 5.8034e-05,
        4.0867e-05, 3.8731e-02, 8.2179e-06, 1.5236e-01, 1.1386e-01, 1.9112e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,946][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.7731e-03, 3.9305e-02, 2.8799e-06, 8.7259e-03, 1.0108e-01, 4.0088e-05,
        1.4107e-06, 4.0047e-02, 5.4572e-06, 5.4672e-02, 5.4416e-01, 2.1019e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,948][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0623, 0.0865, 0.0991, 0.0800, 0.0967, 0.0780, 0.0923, 0.0782, 0.0984,
        0.0688, 0.0769, 0.0829], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,949][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2427, 0.2119, 0.0290, 0.0625, 0.0385, 0.0187, 0.0201, 0.0949, 0.0155,
        0.0914, 0.0416, 0.1333], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,950][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([4.0135e-02, 2.9951e-01, 1.7052e-04, 7.5770e-02, 2.3356e-02, 2.9397e-04,
        6.1932e-05, 4.1557e-02, 9.3993e-05, 2.1815e-01, 5.4022e-02, 2.4688e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,951][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([2.2705e-03, 7.5192e-02, 4.0665e-06, 2.1584e-02, 4.0684e-02, 2.3550e-05,
        7.3237e-06, 5.8758e-02, 7.1569e-06, 1.0576e-01, 2.7805e-01, 4.1766e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,953][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([2.6993e-02, 2.2685e-01, 9.1093e-05, 2.1765e-02, 3.2138e-02, 2.0014e-04,
        1.9753e-05, 5.1762e-02, 2.8206e-05, 1.0688e-01, 1.0987e-01, 4.2339e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,954][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([8.4307e-03, 8.8523e-02, 5.4379e-04, 3.1144e-02, 5.2247e-02, 5.1685e-04,
        3.7738e-04, 1.8192e-02, 3.0897e-04, 5.9508e-02, 6.1543e-01, 1.2478e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,955][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.7041, 0.0257, 0.0022, 0.0153, 0.0275, 0.0016, 0.0028, 0.0412, 0.0012,
        0.0366, 0.0316, 0.1102], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,956][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0800, 0.3154, 0.0012, 0.0396, 0.0519, 0.0018, 0.0005, 0.0484, 0.0011,
        0.0790, 0.1365, 0.2446], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:37,956][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.0224, 0.0007, 0.0699, 0.0018, 0.0032, 0.0550, 0.2246, 0.0009, 0.4060,
        0.0010, 0.0017, 0.0959, 0.1169], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,957][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.1509, 0.0739, 0.0031, 0.0223, 0.0172, 0.0013, 0.0020, 0.0129, 0.0016,
        0.0600, 0.0289, 0.3672, 0.2587], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,957][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([2.6288e-01, 1.1844e-02, 1.1092e-05, 9.2322e-04, 1.5759e-03, 5.1713e-06,
        6.7056e-06, 1.8935e-03, 1.4824e-06, 4.2597e-03, 7.5940e-03, 1.7924e-01,
        5.2977e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,957][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([7.6911e-03, 3.0994e-03, 5.2581e-07, 3.0930e-04, 1.1158e-03, 1.0010e-06,
        1.5029e-07, 2.0708e-03, 2.1065e-07, 2.5815e-03, 3.7164e-03, 1.4374e-02,
        9.6504e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,958][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.0568, 0.0842, 0.0901, 0.0785, 0.0912, 0.0749, 0.0836, 0.0738, 0.0874,
        0.0658, 0.0706, 0.0775, 0.0655], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,958][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.3388, 0.0567, 0.0226, 0.0416, 0.0349, 0.0143, 0.0248, 0.0513, 0.0106,
        0.0532, 0.0647, 0.1512, 0.1352], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,958][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([2.2236e-01, 7.4748e-02, 2.3736e-04, 1.7672e-02, 6.4907e-03, 2.0263e-04,
        4.5187e-05, 8.6033e-03, 6.6015e-05, 4.4186e-02, 2.8593e-02, 1.5189e-01,
        4.4491e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,959][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([8.2793e-03, 9.9601e-03, 2.5933e-06, 9.8867e-04, 1.7472e-03, 2.1491e-06,
        1.2375e-06, 2.2780e-03, 1.0499e-06, 3.1174e-03, 1.5312e-02, 4.5881e-02,
        9.1243e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,959][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([5.4848e-02, 1.9979e-02, 1.9098e-05, 1.4774e-03, 3.8531e-03, 3.2122e-05,
        5.9450e-06, 1.0928e-02, 4.9192e-06, 7.4116e-03, 1.2101e-02, 7.4096e-02,
        8.1524e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,959][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.1319, 0.0286, 0.0011, 0.0147, 0.0174, 0.0009, 0.0008, 0.0142, 0.0005,
        0.0327, 0.0641, 0.2132, 0.4800], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,960][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([7.8716e-01, 5.0737e-03, 1.4177e-03, 3.1240e-03, 4.3190e-03, 5.8393e-04,
        5.3852e-04, 1.4021e-02, 7.3201e-04, 8.0824e-03, 9.0656e-03, 1.2659e-02,
        1.5322e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,961][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([9.6821e-02, 3.7767e-02, 5.3786e-04, 7.5662e-03, 6.9295e-03, 3.2861e-04,
        1.2782e-04, 1.4364e-02, 2.9186e-04, 1.4836e-02, 2.3443e-02, 9.3837e-02,
        7.0315e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:37,962][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0113, 0.0006, 0.0311, 0.0041, 0.0036, 0.1898, 0.1362, 0.0009, 0.1264,
        0.0030, 0.0037, 0.0735, 0.0006, 0.4151], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,964][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([5.0392e-02, 8.4418e-02, 5.6757e-04, 1.9355e-02, 5.2006e-03, 1.3591e-04,
        4.3129e-04, 2.6900e-03, 2.1587e-04, 2.9925e-02, 9.5971e-03, 1.4838e-01,
        2.5147e-01, 3.9722e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,965][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([5.6040e-02, 1.1959e-02, 1.0955e-06, 8.0961e-04, 7.7339e-04, 1.3393e-07,
        2.1756e-06, 8.3735e-04, 2.4541e-07, 3.8256e-03, 1.0932e-02, 1.1954e-01,
        6.5824e-01, 1.3703e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,965][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.1778e-03, 1.2278e-04, 1.5523e-08, 1.8115e-05, 5.3962e-04, 3.1081e-08,
        1.3124e-08, 7.4554e-05, 1.7682e-08, 1.6837e-04, 2.7998e-03, 6.3818e-03,
        2.3358e-01, 7.5513e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,967][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0532, 0.0758, 0.0847, 0.0691, 0.0839, 0.0678, 0.0780, 0.0650, 0.0830,
        0.0584, 0.0674, 0.0708, 0.0696, 0.0733], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,969][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.3624, 0.0513, 0.0161, 0.0196, 0.0238, 0.0113, 0.0117, 0.0297, 0.0105,
        0.0331, 0.0382, 0.0835, 0.1261, 0.1827], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,970][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([5.9920e-02, 3.0815e-02, 4.2847e-05, 6.3818e-03, 2.8851e-03, 1.2733e-05,
        1.8577e-05, 3.4220e-03, 1.1398e-05, 1.5736e-02, 3.7370e-03, 1.1189e-01,
        3.3734e-01, 4.2779e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,971][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.1442e-03, 5.8945e-04, 7.1162e-08, 1.4571e-04, 9.9675e-05, 5.4430e-08,
        5.4183e-08, 2.6304e-04, 7.7955e-08, 5.8201e-04, 2.6416e-03, 1.2580e-02,
        6.1759e-01, 3.6437e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,972][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.0535e-02, 2.5306e-03, 3.5301e-06, 3.3026e-04, 1.4345e-04, 1.2208e-06,
        1.4140e-06, 1.3743e-03, 7.8292e-07, 1.2538e-03, 2.4049e-03, 2.6691e-02,
        4.5968e-01, 4.9505e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,973][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([3.9876e-02, 2.1291e-02, 2.0551e-04, 9.8647e-03, 3.5323e-02, 3.7529e-05,
        2.2510e-04, 5.3159e-03, 1.6990e-04, 2.6313e-02, 2.8356e-01, 1.1496e-01,
        3.4044e-01, 1.2242e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,974][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([6.3840e-01, 7.3337e-03, 7.7443e-04, 5.1842e-03, 7.4487e-03, 8.0864e-04,
        6.1941e-04, 9.7982e-03, 6.1529e-04, 1.2201e-02, 2.6630e-02, 2.3270e-02,
        1.3147e-01, 1.3544e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,975][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.4802e-02, 2.0666e-02, 7.9549e-05, 2.5537e-03, 2.5797e-03, 4.4910e-05,
        4.4289e-05, 4.2916e-03, 5.7991e-05, 5.5225e-03, 1.5974e-02, 6.4798e-02,
        5.1353e-01, 3.4506e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:37,976][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:16:37,978][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 7624],
        [ 8199],
        [ 5711],
        [ 3802],
        [ 9556],
        [ 7825],
        [ 6113],
        [27796],
        [ 4186],
        [12124],
        [12767],
        [ 6756],
        [18864],
        [ 5493]], device='cuda:0')
[2024-07-24 10:16:37,980][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 7749],
        [14116],
        [ 8794],
        [ 6167],
        [12793],
        [11682],
        [11056],
        [33288],
        [ 7523],
        [19101],
        [20480],
        [14924],
        [28507],
        [11584]], device='cuda:0')
[2024-07-24 10:16:37,980][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[22606],
        [21210],
        [21651],
        [20756],
        [22214],
        [21398],
        [21449],
        [21478],
        [21403],
        [20921],
        [21410],
        [21658],
        [21395],
        [21335]], device='cuda:0')
[2024-07-24 10:16:37,981][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[26977],
        [26201],
        [24913],
        [24710],
        [24319],
        [23924],
        [23114],
        [22658],
        [22196],
        [22423],
        [22281],
        [22378],
        [22247],
        [22283]], device='cuda:0')
[2024-07-24 10:16:37,982][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[30106],
        [40160],
        [40159],
        [37471],
        [37171],
        [35565],
        [35178],
        [31872],
        [31806],
        [33823],
        [34940],
        [33034],
        [29316],
        [29295]], device='cuda:0')
[2024-07-24 10:16:37,983][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[42774],
        [11454],
        [11965],
        [11044],
        [11027],
        [ 9309],
        [10040],
        [10969],
        [ 8783],
        [10252],
        [10675],
        [10144],
        [ 8718],
        [11245]], device='cuda:0')
[2024-07-24 10:16:37,985][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[10206],
        [ 8115],
        [ 7233],
        [ 7257],
        [ 7329],
        [ 7550],
        [ 7264],
        [ 6998],
        [ 7182],
        [ 7175],
        [ 6948],
        [ 6445],
        [ 6485],
        [ 6417]], device='cuda:0')
[2024-07-24 10:16:37,986][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[20357],
        [13770],
        [15117],
        [12754],
        [13363],
        [13674],
        [13604],
        [14661],
        [15193],
        [14212],
        [13462],
        [13589],
        [13401],
        [13529]], device='cuda:0')
[2024-07-24 10:16:37,988][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[24301],
        [38716],
        [37794],
        [35518],
        [34900],
        [34361],
        [34139],
        [33717],
        [33647],
        [32587],
        [32537],
        [32300],
        [31571],
        [31631]], device='cuda:0')
[2024-07-24 10:16:37,989][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 4747],
        [10455],
        [18035],
        [17206],
        [15626],
        [13410],
        [13911],
        [15074],
        [15484],
        [14678],
        [ 9399],
        [ 5903],
        [13538],
        [ 5220]], device='cuda:0')
[2024-07-24 10:16:37,990][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[14872],
        [23376],
        [46827],
        [46322],
        [45902],
        [43203],
        [44786],
        [45487],
        [44727],
        [47051],
        [46909],
        [45307],
        [45365],
        [47572]], device='cuda:0')
[2024-07-24 10:16:37,992][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[  575],
        [ 1840],
        [10837],
        [12125],
        [13276],
        [40067],
        [26616],
        [13440],
        [20795],
        [16595],
        [16514],
        [20779],
        [18367],
        [22194]], device='cuda:0')
[2024-07-24 10:16:37,993][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[28379],
        [ 9601],
        [15003],
        [14525],
        [17306],
        [19237],
        [20101],
        [21804],
        [22464],
        [21640],
        [22909],
        [23427],
        [23389],
        [23850]], device='cuda:0')
[2024-07-24 10:16:37,995][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[38760],
        [38582],
        [27705],
        [30527],
        [31123],
        [27524],
        [28633],
        [28809],
        [26732],
        [30178],
        [30764],
        [25747],
        [15586],
        [20503]], device='cuda:0')
[2024-07-24 10:16:37,996][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 4227],
        [11588],
        [16917],
        [22630],
        [22420],
        [15462],
        [ 7898],
        [14889],
        [15610],
        [31520],
        [ 8658],
        [ 7849],
        [17286],
        [11625]], device='cuda:0')
[2024-07-24 10:16:37,998][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[16804],
        [21848],
        [34298],
        [28448],
        [30843],
        [32433],
        [31033],
        [32062],
        [35924],
        [33082],
        [35627],
        [32731],
        [36000],
        [33782]], device='cuda:0')
[2024-07-24 10:16:37,999][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[2618],
        [1062],
        [2270],
        [2197],
        [2483],
        [2674],
        [2840],
        [2685],
        [2653],
        [2515],
        [3598],
        [3546],
        [4009],
        [2552]], device='cuda:0')
[2024-07-24 10:16:38,001][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[17006],
        [16094],
        [ 5553],
        [ 6303],
        [ 5108],
        [ 4690],
        [ 4908],
        [ 5388],
        [ 5966],
        [ 5360],
        [ 3918],
        [ 3452],
        [ 6608],
        [ 5754]], device='cuda:0')
[2024-07-24 10:16:38,002][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[18877],
        [19021],
        [18397],
        [17238],
        [12786],
        [16357],
        [14957],
        [14926],
        [25433],
        [16256],
        [11973],
        [23738],
        [ 8074],
        [16446]], device='cuda:0')
[2024-07-24 10:16:38,003][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[28278],
        [29859],
        [31245],
        [32541],
        [33966],
        [32932],
        [32651],
        [33051],
        [32741],
        [33042],
        [33493],
        [33243],
        [33335],
        [32972]], device='cuda:0')
[2024-07-24 10:16:38,004][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[29199],
        [29213],
        [32387],
        [30356],
        [30784],
        [31639],
        [32165],
        [33841],
        [37618],
        [33595],
        [35900],
        [34813],
        [32290],
        [36805]], device='cuda:0')
[2024-07-24 10:16:38,005][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 4991],
        [ 5595],
        [ 6044],
        [13916],
        [11054],
        [20833],
        [18851],
        [16686],
        [15744],
        [20048],
        [20590],
        [21103],
        [20682],
        [ 7028]], device='cuda:0')
[2024-07-24 10:16:38,006][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[13032],
        [ 6469],
        [ 2752],
        [ 3206],
        [ 4635],
        [ 4599],
        [ 3632],
        [ 3556],
        [  899],
        [ 2122],
        [ 8462],
        [ 2907],
        [ 1356],
        [ 1367]], device='cuda:0')
[2024-07-24 10:16:38,007][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[23367],
        [22937],
        [15122],
        [16009],
        [15001],
        [14418],
        [14286],
        [14211],
        [ 7631],
        [12841],
        [12059],
        [ 6105],
        [ 5680],
        [ 6666]], device='cuda:0')
[2024-07-24 10:16:38,008][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 8761],
        [ 9212],
        [ 6655],
        [ 5645],
        [ 4797],
        [12789],
        [ 5050],
        [ 5286],
        [ 4198],
        [ 4358],
        [ 4076],
        [ 2318],
        [ 1845],
        [ 2323]], device='cuda:0')
[2024-07-24 10:16:38,009][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[19600],
        [20404],
        [29067],
        [28372],
        [27817],
        [35699],
        [38101],
        [28660],
        [39784],
        [38045],
        [32231],
        [36382],
        [35475],
        [31963]], device='cuda:0')
[2024-07-24 10:16:38,011][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 5826],
        [ 6093],
        [13190],
        [ 9737],
        [ 7051],
        [ 5692],
        [ 6152],
        [ 5805],
        [ 6553],
        [ 6695],
        [ 5358],
        [ 9298],
        [17942],
        [12860]], device='cuda:0')
[2024-07-24 10:16:38,012][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[31079],
        [30720],
        [32684],
        [32155],
        [33869],
        [30332],
        [32645],
        [32373],
        [32163],
        [32916],
        [32816],
        [34881],
        [35251],
        [35527]], device='cuda:0')
[2024-07-24 10:16:38,014][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[38179],
        [38727],
        [12919],
        [15961],
        [17905],
        [18283],
        [27166],
        [26677],
        [15479],
        [ 9721],
        [19521],
        [34992],
        [20608],
        [26324]], device='cuda:0')
[2024-07-24 10:16:38,015][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[42366],
        [42366],
        [42366],
        [42366],
        [42366],
        [42366],
        [42366],
        [42366],
        [42366],
        [42366],
        [42366],
        [42366],
        [42366],
        [42366]], device='cuda:0')
[2024-07-24 10:16:38,047][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:38,049][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,050][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,052][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,053][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,053][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,053][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,054][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,054][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,054][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,055][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,055][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,055][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,056][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.2828, 0.7172], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,056][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.1341, 0.8659], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,056][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.5100, 0.4900], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,056][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.4452, 0.5548], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,057][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.8588, 0.1412], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,059][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.1639, 0.8361], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,060][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.7312, 0.2688], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,062][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.2089, 0.7911], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,063][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.3977, 0.6023], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,064][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.6010, 0.3990], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,066][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.3358, 0.6642], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,067][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.9876, 0.0124], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,069][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.4850, 0.4202, 0.0947], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,070][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0111, 0.9741, 0.0148], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,072][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3412, 0.3364, 0.3224], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,074][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3098, 0.3586, 0.3316], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,075][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3952, 0.3110, 0.2938], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,076][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2075, 0.5804, 0.2121], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,076][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.5389, 0.2252, 0.2359], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,077][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0560, 0.6796, 0.2644], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,077][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2406, 0.3367, 0.4227], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,077][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1624, 0.8266, 0.0110], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,077][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2046, 0.4703, 0.3251], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,078][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([1.9225e-06, 1.0000e+00, 2.8285e-08], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,078][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Jonathan] are: tensor([0.1434, 0.3693, 0.4091, 0.0782], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,078][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Jonathan] are: tensor([0.0211, 0.8588, 0.0158, 0.1042], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,078][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Jonathan] are: tensor([0.2587, 0.2526, 0.2418, 0.2469], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,079][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Jonathan] are: tensor([0.2120, 0.2694, 0.2427, 0.2758], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,079][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Jonathan] are: tensor([0.5523, 0.2110, 0.0160, 0.2207], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,079][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Jonathan] are: tensor([0.0512, 0.6869, 0.2169, 0.0451], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,080][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Jonathan] are: tensor([0.2768, 0.1871, 0.4729, 0.0632], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,080][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Jonathan] are: tensor([0.0382, 0.4775, 0.0758, 0.4086], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,082][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Jonathan] are: tensor([0.1687, 0.2494, 0.2886, 0.2934], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,084][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Jonathan] are: tensor([0.2222, 0.6549, 0.0117, 0.1112], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,085][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Jonathan] are: tensor([0.0962, 0.3417, 0.2626, 0.2995], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,086][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Jonathan] are: tensor([1.7707e-04, 9.9981e-01, 1.2154e-05, 3.9490e-06], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,087][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0754, 0.3472, 0.3349, 0.0478, 0.1947], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,089][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0098, 0.8066, 0.0142, 0.1403, 0.0291], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,090][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.2053, 0.2039, 0.1953, 0.1985, 0.1970], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,092][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.1641, 0.2085, 0.1890, 0.2135, 0.2248], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,093][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.1116, 0.3794, 0.0442, 0.2975, 0.1673], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,096][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0813, 0.5467, 0.2560, 0.0464, 0.0696], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,097][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.2417, 0.1908, 0.3173, 0.1167, 0.1334], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,098][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0249, 0.3476, 0.0971, 0.3517, 0.1787], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,099][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.1204, 0.1850, 0.2096, 0.2166, 0.2683], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,099][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.1499, 0.6354, 0.0119, 0.1622, 0.0406], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,100][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0566, 0.2994, 0.1852, 0.2321, 0.2267], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,100][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ went] are: tensor([5.4851e-07, 9.9990e-01, 2.5366e-07, 1.0004e-04, 4.4007e-07],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,100][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1979, 0.2416, 0.0495, 0.0879, 0.3762, 0.0469], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,101][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0032, 0.7967, 0.0078, 0.1481, 0.0336, 0.0105], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,101][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1795, 0.1705, 0.1618, 0.1658, 0.1623, 0.1600], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,101][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1473, 0.1684, 0.1547, 0.1752, 0.1859, 0.1686], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,101][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1463, 0.2568, 0.0632, 0.2028, 0.1985, 0.1323], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,102][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0591, 0.6287, 0.2011, 0.0310, 0.0494, 0.0306], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,102][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2876, 0.1196, 0.2299, 0.0781, 0.1665, 0.1182], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,102][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0155, 0.2451, 0.0936, 0.2620, 0.1824, 0.2014], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,103][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1039, 0.1493, 0.1833, 0.1811, 0.2292, 0.1532], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,103][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1080, 0.5950, 0.0075, 0.2189, 0.0630, 0.0077], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,105][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0530, 0.2521, 0.1690, 0.1757, 0.2163, 0.1340], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,106][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.8667e-08, 9.9986e-01, 6.6726e-08, 1.1905e-04, 2.0438e-05, 1.0351e-07],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,108][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.2712, 0.3124, 0.0535, 0.0605, 0.1555, 0.1060, 0.0408],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,109][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0029, 0.7921, 0.0085, 0.1364, 0.0258, 0.0170, 0.0172],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,110][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1471, 0.1468, 0.1393, 0.1431, 0.1408, 0.1406, 0.1423],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,112][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1223, 0.1459, 0.1342, 0.1502, 0.1603, 0.1488, 0.1381],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,113][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2310, 0.3281, 0.0537, 0.2321, 0.0866, 0.0323, 0.0362],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,115][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0515, 0.4160, 0.1583, 0.0311, 0.0670, 0.0937, 0.1823],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,116][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2258, 0.1081, 0.1787, 0.0612, 0.1775, 0.1273, 0.1215],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,119][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0142, 0.2002, 0.0776, 0.2453, 0.1371, 0.1687, 0.1569],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,120][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0871, 0.1308, 0.1611, 0.1577, 0.2015, 0.1329, 0.1289],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,121][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1177, 0.6621, 0.0075, 0.1473, 0.0435, 0.0079, 0.0140],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,122][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0639, 0.2543, 0.1296, 0.1462, 0.1658, 0.1013, 0.1389],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,122][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ the] are: tensor([3.2393e-08, 9.9993e-01, 4.6046e-08, 6.5688e-05, 3.5285e-06, 2.9396e-07,
        7.1227e-08], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,123][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.0617, 0.1106, 0.1263, 0.0456, 0.1895, 0.3134, 0.0899, 0.0631],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,123][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([0.0099, 0.7230, 0.0135, 0.1289, 0.0599, 0.0119, 0.0200, 0.0329],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,123][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.1332, 0.1316, 0.1236, 0.1267, 0.1261, 0.1244, 0.1267, 0.1077],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,124][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.1105, 0.1272, 0.1170, 0.1323, 0.1404, 0.1296, 0.1210, 0.1220],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,124][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.9192, 0.0165, 0.0091, 0.0173, 0.0068, 0.0026, 0.0045, 0.0240],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,124][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.0271, 0.3559, 0.1801, 0.0183, 0.0702, 0.0805, 0.2242, 0.0438],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,125][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.1263, 0.1203, 0.2010, 0.0569, 0.1373, 0.1152, 0.1644, 0.0785],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,125][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.0063, 0.2444, 0.0349, 0.2013, 0.0793, 0.1012, 0.0838, 0.2488],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,125][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.0806, 0.1244, 0.1302, 0.1330, 0.1726, 0.1032, 0.1033, 0.1527],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,125][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.1163, 0.6554, 0.0114, 0.1359, 0.0518, 0.0087, 0.0097, 0.0108],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,126][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.0872, 0.1800, 0.0823, 0.1731, 0.1476, 0.0856, 0.0827, 0.1614],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,127][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([1.1086e-08, 9.9989e-01, 3.0457e-08, 1.0635e-04, 2.7301e-06, 1.6252e-07,
        1.5345e-07, 1.2215e-06], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,128][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2460, 0.2244, 0.0318, 0.0737, 0.1785, 0.0595, 0.0624, 0.0969, 0.0268],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,130][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0031, 0.7046, 0.0079, 0.1247, 0.0310, 0.0116, 0.0218, 0.0882, 0.0071],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,132][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1191, 0.1156, 0.1103, 0.1127, 0.1124, 0.1113, 0.1130, 0.0968, 0.1086],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,133][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0959, 0.1144, 0.1048, 0.1176, 0.1251, 0.1168, 0.1096, 0.1095, 0.1063],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,135][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1535, 0.3432, 0.0614, 0.1708, 0.1269, 0.0531, 0.0255, 0.0139, 0.0517],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,136][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0948, 0.2876, 0.1751, 0.0242, 0.0645, 0.0701, 0.1849, 0.0573, 0.0415],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,138][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2059, 0.0761, 0.1211, 0.0575, 0.1204, 0.0928, 0.1148, 0.1354, 0.0761],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,139][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0058, 0.1419, 0.0538, 0.1572, 0.0912, 0.1399, 0.1172, 0.2022, 0.0908],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,142][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0673, 0.1018, 0.1209, 0.1163, 0.1481, 0.0960, 0.0967, 0.1500, 0.1030],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,143][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1036, 0.6112, 0.0122, 0.1289, 0.0710, 0.0150, 0.0269, 0.0232, 0.0080],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,144][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0307, 0.1322, 0.0898, 0.1079, 0.1485, 0.0838, 0.1111, 0.2150, 0.0809],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,145][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([1.1655e-10, 9.9935e-01, 1.8396e-09, 2.2836e-04, 1.5459e-06, 7.9483e-08,
        4.4716e-07, 4.1983e-04, 3.6030e-09], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,145][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Jonathan] are: tensor([0.0370, 0.1034, 0.0997, 0.0235, 0.0966, 0.2482, 0.1311, 0.0956, 0.1352,
        0.0297], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,146][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Jonathan] are: tensor([0.0052, 0.7744, 0.0038, 0.0651, 0.0145, 0.0038, 0.0052, 0.0280, 0.0035,
        0.0965], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,146][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Jonathan] are: tensor([0.1081, 0.1034, 0.0993, 0.1005, 0.1005, 0.1000, 0.1015, 0.0867, 0.0987,
        0.1013], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,146][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Jonathan] are: tensor([0.0859, 0.1020, 0.0930, 0.1052, 0.1107, 0.1038, 0.0968, 0.0986, 0.0920,
        0.1120], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,147][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Jonathan] are: tensor([0.1265, 0.3204, 0.0161, 0.2301, 0.0224, 0.0080, 0.0124, 0.0226, 0.0109,
        0.2304], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,147][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Jonathan] are: tensor([0.0208, 0.3478, 0.0969, 0.0210, 0.0442, 0.1188, 0.1777, 0.0778, 0.0628,
        0.0324], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,147][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Jonathan] are: tensor([0.0725, 0.0521, 0.1295, 0.0194, 0.1099, 0.1075, 0.1268, 0.1941, 0.1581,
        0.0302], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,148][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Jonathan] are: tensor([0.0072, 0.1662, 0.0198, 0.1417, 0.0567, 0.0494, 0.0632, 0.0863, 0.0282,
        0.3814], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,148][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Jonathan] are: tensor([0.0587, 0.0872, 0.1034, 0.1028, 0.1497, 0.0895, 0.0896, 0.1351, 0.0897,
        0.0943], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,148][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Jonathan] are: tensor([0.1233, 0.6354, 0.0072, 0.0837, 0.0295, 0.0062, 0.0100, 0.0173, 0.0037,
        0.0836], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,149][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Jonathan] are: tensor([0.0248, 0.1333, 0.0954, 0.1519, 0.1169, 0.0766, 0.0983, 0.1243, 0.0638,
        0.1146], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,149][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Jonathan] are: tensor([5.2440e-07, 9.9998e-01, 5.1058e-08, 6.4864e-07, 6.7305e-07, 1.8267e-08,
        2.1566e-07, 1.6795e-05, 8.4953e-08, 2.7514e-06], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,151][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0249, 0.1050, 0.1091, 0.0291, 0.1015, 0.2151, 0.1188, 0.0752, 0.1292,
        0.0415, 0.0506], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,153][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0043, 0.6650, 0.0040, 0.0832, 0.0140, 0.0048, 0.0086, 0.0279, 0.0041,
        0.1606, 0.0236], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,154][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0976, 0.0950, 0.0904, 0.0920, 0.0914, 0.0915, 0.0930, 0.0800, 0.0897,
        0.0930, 0.0865], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,155][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0755, 0.0922, 0.0840, 0.0949, 0.0993, 0.0923, 0.0864, 0.0882, 0.0840,
        0.1014, 0.1018], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,157][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.4955, 0.1044, 0.0437, 0.0906, 0.0271, 0.0149, 0.0188, 0.0335, 0.0198,
        0.1146, 0.0371], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,159][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0333, 0.3345, 0.1349, 0.0211, 0.0219, 0.0676, 0.2258, 0.0466, 0.0601,
        0.0304, 0.0239], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,160][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.1279, 0.0675, 0.1201, 0.0359, 0.0962, 0.0796, 0.1043, 0.1556, 0.1003,
        0.0489, 0.0637], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,162][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0129, 0.1510, 0.0288, 0.1106, 0.0786, 0.0618, 0.0536, 0.1307, 0.0429,
        0.1675, 0.1616], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,164][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0580, 0.0809, 0.0934, 0.0938, 0.1259, 0.0790, 0.0780, 0.1192, 0.0819,
        0.0856, 0.1044], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,165][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.1157, 0.6102, 0.0046, 0.1082, 0.0388, 0.0042, 0.0060, 0.0058, 0.0024,
        0.0814, 0.0228], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,167][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0478, 0.1259, 0.0680, 0.1250, 0.1082, 0.0680, 0.0680, 0.1081, 0.0515,
        0.1092, 0.1203], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,168][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([9.7913e-08, 9.9991e-01, 2.2511e-10, 1.6239e-05, 2.6915e-07, 7.2164e-10,
        1.2674e-09, 2.4252e-06, 1.6091e-10, 6.5332e-05, 9.6919e-07],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,168][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1385, 0.1966, 0.0577, 0.0319, 0.1033, 0.0965, 0.0506, 0.0854, 0.0667,
        0.0408, 0.1008, 0.0314], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,169][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0067, 0.4861, 0.0070, 0.0923, 0.0267, 0.0100, 0.0099, 0.0501, 0.0073,
        0.1746, 0.0433, 0.0860], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,169][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0879, 0.0870, 0.0828, 0.0847, 0.0841, 0.0841, 0.0850, 0.0738, 0.0814,
        0.0856, 0.0791, 0.0845], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,169][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0690, 0.0837, 0.0765, 0.0861, 0.0908, 0.0848, 0.0791, 0.0803, 0.0769,
        0.0916, 0.0927, 0.0886], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,170][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.3088, 0.1620, 0.0205, 0.1855, 0.0237, 0.0062, 0.0117, 0.0062, 0.0152,
        0.1823, 0.0190, 0.0587], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,170][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0202, 0.4456, 0.0845, 0.0187, 0.0287, 0.0601, 0.1550, 0.0420, 0.0428,
        0.0247, 0.0309, 0.0466], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,170][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1014, 0.0475, 0.1075, 0.0359, 0.0803, 0.0725, 0.1057, 0.1538, 0.1012,
        0.0548, 0.0932, 0.0462], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,171][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0048, 0.1073, 0.0262, 0.0919, 0.0697, 0.0704, 0.0677, 0.1209, 0.0380,
        0.1816, 0.1123, 0.1092], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,171][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0516, 0.0739, 0.0911, 0.0894, 0.1134, 0.0744, 0.0725, 0.1070, 0.0775,
        0.0821, 0.0987, 0.0685], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,171][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1213, 0.4953, 0.0070, 0.0931, 0.0473, 0.0079, 0.0104, 0.0089, 0.0050,
        0.0899, 0.0660, 0.0477], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,172][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0150, 0.1245, 0.0491, 0.1099, 0.0931, 0.0583, 0.0677, 0.1562, 0.0479,
        0.0901, 0.0955, 0.0927], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,173][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([5.7568e-08, 9.9820e-01, 6.1452e-09, 6.7724e-05, 3.1784e-06, 2.3393e-08,
        2.3651e-08, 2.9819e-05, 4.8946e-09, 4.0122e-04, 2.7200e-04, 1.0293e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,174][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.0428, 0.0372, 0.1161, 0.0166, 0.0963, 0.1560, 0.0765, 0.0614, 0.1481,
        0.0208, 0.0589, 0.1012, 0.0681], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,176][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.0138, 0.5011, 0.0044, 0.0488, 0.0238, 0.0044, 0.0064, 0.0144, 0.0036,
        0.0557, 0.0216, 0.0853, 0.2165], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,178][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.0818, 0.0816, 0.0769, 0.0785, 0.0783, 0.0778, 0.0792, 0.0675, 0.0765,
        0.0792, 0.0744, 0.0798, 0.0683], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,179][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0622, 0.0767, 0.0698, 0.0792, 0.0840, 0.0787, 0.0729, 0.0741, 0.0702,
        0.0843, 0.0859, 0.0818, 0.0802], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,181][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.7178, 0.0520, 0.0217, 0.0499, 0.0101, 0.0053, 0.0088, 0.0089, 0.0079,
        0.0691, 0.0172, 0.0106, 0.0207], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,182][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.0145, 0.3048, 0.1630, 0.0107, 0.0260, 0.0911, 0.1265, 0.0466, 0.0564,
        0.0142, 0.0409, 0.0873, 0.0180], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,184][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.0650, 0.0563, 0.1177, 0.0293, 0.0877, 0.0721, 0.1350, 0.1014, 0.1187,
        0.0441, 0.0805, 0.0701, 0.0221], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,185][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.0034, 0.0786, 0.0169, 0.0762, 0.0477, 0.0491, 0.0413, 0.1332, 0.0217,
        0.1418, 0.0765, 0.0817, 0.2320], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,188][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.0484, 0.0712, 0.0820, 0.0786, 0.1098, 0.0651, 0.0638, 0.1080, 0.0708,
        0.0713, 0.0882, 0.0627, 0.0803], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,189][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.1739, 0.5014, 0.0056, 0.0639, 0.0319, 0.0044, 0.0050, 0.0073, 0.0022,
        0.0556, 0.0490, 0.0486, 0.0512], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,190][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.0371, 0.1626, 0.0534, 0.0957, 0.0948, 0.0819, 0.0624, 0.0618, 0.0481,
        0.0582, 0.0700, 0.0678, 0.1062], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,191][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([3.5633e-07, 9.9926e-01, 4.9763e-10, 7.2413e-06, 1.2199e-07, 9.1413e-10,
        1.5579e-09, 5.4508e-07, 2.0897e-10, 2.1750e-05, 1.7678e-06, 7.0196e-04,
        9.5499e-06], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,191][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0770, 0.1354, 0.0195, 0.0477, 0.1722, 0.0149, 0.0627, 0.0783, 0.0242,
        0.0548, 0.0895, 0.0708, 0.1391, 0.0138], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,192][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0111, 0.4275, 0.0023, 0.0534, 0.0141, 0.0021, 0.0047, 0.0170, 0.0021,
        0.0620, 0.0107, 0.0543, 0.2001, 0.1386], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,192][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0780, 0.0749, 0.0712, 0.0735, 0.0725, 0.0716, 0.0732, 0.0625, 0.0705,
        0.0748, 0.0679, 0.0728, 0.0637, 0.0725], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,192][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0605, 0.0707, 0.0650, 0.0736, 0.0781, 0.0721, 0.0674, 0.0678, 0.0649,
        0.0783, 0.0796, 0.0757, 0.0741, 0.0721], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,193][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1674, 0.1766, 0.0271, 0.1807, 0.0524, 0.0218, 0.0173, 0.0143, 0.0218,
        0.1485, 0.0386, 0.0437, 0.0402, 0.0493], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,193][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0311, 0.3507, 0.1085, 0.0145, 0.0242, 0.0132, 0.1590, 0.0598, 0.0346,
        0.0194, 0.0213, 0.1315, 0.0212, 0.0109], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,194][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1108, 0.0478, 0.0968, 0.0324, 0.0629, 0.0469, 0.0806, 0.1483, 0.0695,
        0.0476, 0.0898, 0.0646, 0.0481, 0.0538], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,194][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0093, 0.0842, 0.0215, 0.0738, 0.0522, 0.0420, 0.0355, 0.0423, 0.0247,
        0.1310, 0.0628, 0.0637, 0.0796, 0.2774], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,194][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0418, 0.0617, 0.0815, 0.0779, 0.1022, 0.0660, 0.0644, 0.0945, 0.0689,
        0.0717, 0.0858, 0.0596, 0.0805, 0.0435], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,195][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.2661, 0.3466, 0.0035, 0.0785, 0.0325, 0.0028, 0.0051, 0.0058, 0.0024,
        0.0724, 0.0369, 0.0415, 0.0579, 0.0479], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,195][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0136, 0.0958, 0.0508, 0.0727, 0.0902, 0.0557, 0.0676, 0.1324, 0.0518,
        0.0666, 0.0901, 0.0696, 0.0928, 0.0503], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,196][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([5.8631e-06, 7.6806e-01, 6.6007e-10, 1.7141e-05, 3.0349e-06, 5.6314e-10,
        9.3190e-09, 3.8021e-06, 7.3676e-10, 9.3582e-05, 1.2476e-04, 1.4365e-02,
        4.9856e-03, 2.1234e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,238][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:38,238][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,239][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,239][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,239][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,240][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,241][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,243][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,244][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,245][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,246][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,247][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,248][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,250][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.1252, 0.8748], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,252][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.1341, 0.8659], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,253][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.9145, 0.0855], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,255][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.5488, 0.4512], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,256][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([9.9936e-01, 6.3715e-04], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,258][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.4472, 0.5528], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,259][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.6089, 0.3911], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,259][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.2089, 0.7911], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,259][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.9596, 0.0404], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,259][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.6010, 0.3990], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,260][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.9895, 0.0105], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,260][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.9876, 0.0124], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,260][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0071, 0.9833, 0.0096], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,260][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0111, 0.9741, 0.0148], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,261][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.6054, 0.3180, 0.0767], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,261][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0444, 0.9398, 0.0159], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,261][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([9.9650e-01, 7.4745e-04, 2.7561e-03], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,262][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0826, 0.8749, 0.0425], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,262][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0759, 0.8897, 0.0344], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,262][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0560, 0.6796, 0.2644], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,262][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9142, 0.0560, 0.0298], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,263][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1624, 0.8266, 0.0110], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,265][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9774, 0.0115, 0.0111], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,266][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([1.9225e-06, 1.0000e+00, 2.8285e-08], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,267][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Jonathan] are: tensor([0.0181, 0.8784, 0.0087, 0.0948], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,268][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Jonathan] are: tensor([0.0211, 0.8588, 0.0158, 0.1042], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,270][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Jonathan] are: tensor([0.7218, 0.1551, 0.0459, 0.0772], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,271][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Jonathan] are: tensor([0.1143, 0.6785, 0.0278, 0.1793], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,273][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Jonathan] are: tensor([0.9962, 0.0011, 0.0013, 0.0014], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,274][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Jonathan] are: tensor([0.1405, 0.6736, 0.0230, 0.1629], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,276][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Jonathan] are: tensor([0.2266, 0.6137, 0.0289, 0.1308], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,278][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Jonathan] are: tensor([0.0382, 0.4775, 0.0758, 0.4086], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,280][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Jonathan] are: tensor([0.8984, 0.0549, 0.0131, 0.0336], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,281][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Jonathan] are: tensor([0.2222, 0.6549, 0.0117, 0.1112], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,282][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Jonathan] are: tensor([0.9641, 0.0153, 0.0124, 0.0082], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,282][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Jonathan] are: tensor([1.7707e-04, 9.9981e-01, 1.2154e-05, 3.9490e-06], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,282][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.0162, 0.7855, 0.0198, 0.1222, 0.0563], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,283][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0098, 0.8066, 0.0142, 0.1403, 0.0291], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,283][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.4997, 0.2153, 0.0589, 0.1197, 0.1063], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,283][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.0402, 0.5814, 0.0346, 0.2319, 0.1120], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,283][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.9886, 0.0020, 0.0042, 0.0019, 0.0033], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,284][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.0711, 0.5854, 0.0443, 0.2453, 0.0539], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,284][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.0692, 0.6357, 0.0316, 0.1969, 0.0666], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,284][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0249, 0.3476, 0.0971, 0.3517, 0.1787], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,285][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.7273, 0.0974, 0.0418, 0.0714, 0.0621], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,285][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.1499, 0.6354, 0.0119, 0.1622, 0.0406], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,285][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.9290, 0.0242, 0.0127, 0.0101, 0.0240], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,285][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([5.4851e-07, 9.9990e-01, 2.5366e-07, 1.0004e-04, 4.4007e-07],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,286][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0027, 0.7480, 0.0083, 0.1389, 0.0938, 0.0083], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,288][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0032, 0.7967, 0.0078, 0.1481, 0.0336, 0.0105], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,289][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.4658, 0.1816, 0.0523, 0.1176, 0.1201, 0.0625], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,291][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0448, 0.5051, 0.0084, 0.2776, 0.1513, 0.0129], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,292][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.9552e-01, 7.0438e-04, 1.6732e-03, 7.5133e-04, 1.1488e-03, 2.0323e-04],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,293][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0300, 0.5990, 0.0228, 0.2313, 0.0993, 0.0176], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,294][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0403, 0.6523, 0.0261, 0.1989, 0.0649, 0.0174], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,296][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0155, 0.2451, 0.0936, 0.2620, 0.1824, 0.2014], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,298][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.9000, 0.0370, 0.0128, 0.0219, 0.0225, 0.0058], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,299][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1080, 0.5950, 0.0075, 0.2189, 0.0630, 0.0077], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,301][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.9574, 0.0102, 0.0066, 0.0033, 0.0132, 0.0093], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,302][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.8667e-08, 9.9986e-01, 6.6726e-08, 1.1905e-04, 2.0438e-05, 1.0351e-07],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,304][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0029, 0.7636, 0.0097, 0.1199, 0.0691, 0.0173, 0.0174],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,305][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0029, 0.7921, 0.0085, 0.1364, 0.0258, 0.0170, 0.0172],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,305][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.4958, 0.1697, 0.0414, 0.0947, 0.0755, 0.0465, 0.0764],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,305][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0394, 0.5066, 0.0136, 0.2461, 0.1507, 0.0235, 0.0202],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,306][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([9.9708e-01, 5.0461e-04, 1.1089e-03, 5.5964e-04, 5.6383e-04, 8.5066e-05,
        9.3463e-05], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,306][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0528, 0.5585, 0.0278, 0.1922, 0.0998, 0.0302, 0.0386],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,306][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0418, 0.6615, 0.0200, 0.1828, 0.0678, 0.0139, 0.0122],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,306][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0142, 0.2002, 0.0776, 0.2453, 0.1371, 0.1687, 0.1569],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,307][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.9226, 0.0288, 0.0088, 0.0137, 0.0182, 0.0031, 0.0048],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,307][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1177, 0.6621, 0.0075, 0.1473, 0.0435, 0.0079, 0.0140],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,307][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.9610, 0.0079, 0.0044, 0.0023, 0.0112, 0.0065, 0.0066],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,308][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([3.2393e-08, 9.9993e-01, 4.6046e-08, 6.5688e-05, 3.5285e-06, 2.9396e-07,
        7.1227e-08], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,308][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.0175, 0.7493, 0.0064, 0.0900, 0.0548, 0.0133, 0.0110, 0.0578],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,308][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([0.0099, 0.7230, 0.0135, 0.1289, 0.0599, 0.0119, 0.0200, 0.0329],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,309][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([0.5097, 0.1805, 0.0441, 0.0863, 0.0654, 0.0470, 0.0518, 0.0152],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,311][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.1050, 0.5189, 0.0117, 0.2097, 0.1152, 0.0120, 0.0138, 0.0137],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,312][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([9.9852e-01, 2.6948e-04, 3.3377e-04, 1.3162e-04, 4.9360e-04, 3.6971e-05,
        3.6415e-05, 1.7374e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,314][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.0706, 0.6622, 0.0184, 0.1406, 0.0486, 0.0145, 0.0178, 0.0272],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,315][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.0497, 0.6483, 0.0129, 0.2070, 0.0437, 0.0086, 0.0096, 0.0202],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,317][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.0063, 0.2444, 0.0349, 0.2013, 0.0793, 0.1012, 0.0838, 0.2488],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,318][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.9344, 0.0261, 0.0046, 0.0142, 0.0104, 0.0022, 0.0035, 0.0045],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,320][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.1163, 0.6554, 0.0114, 0.1359, 0.0518, 0.0087, 0.0097, 0.0108],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,321][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([9.8254e-01, 2.2281e-03, 7.8665e-04, 6.5783e-04, 3.6580e-03, 9.0088e-04,
        8.1510e-04, 8.4098e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,322][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([1.1086e-08, 9.9989e-01, 3.0457e-08, 1.0635e-04, 2.7301e-06, 1.6252e-07,
        1.5345e-07, 1.2215e-06], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,324][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0027, 0.5795, 0.0090, 0.1019, 0.0669, 0.0164, 0.0353, 0.1790, 0.0093],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,325][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0031, 0.7046, 0.0079, 0.1247, 0.0310, 0.0116, 0.0218, 0.0882, 0.0071],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,327][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.3374, 0.1417, 0.0509, 0.0672, 0.0854, 0.0579, 0.0910, 0.0528, 0.1156],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,328][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0467, 0.4781, 0.0060, 0.2474, 0.1322, 0.0112, 0.0275, 0.0413, 0.0096],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,328][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([9.9219e-01, 9.5682e-04, 2.4926e-03, 7.8408e-04, 1.3859e-03, 2.5397e-04,
        1.7670e-04, 1.3678e-04, 1.6244e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,328][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0266, 0.4845, 0.0347, 0.1744, 0.0903, 0.0320, 0.0766, 0.0549, 0.0261],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,329][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0328, 0.5550, 0.0205, 0.1959, 0.0679, 0.0151, 0.0192, 0.0842, 0.0094],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,329][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0058, 0.1419, 0.0538, 0.1572, 0.0912, 0.1399, 0.1172, 0.2022, 0.0908],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,329][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8484, 0.0508, 0.0175, 0.0286, 0.0263, 0.0066, 0.0096, 0.0040, 0.0083],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,329][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1036, 0.6112, 0.0122, 0.1289, 0.0710, 0.0150, 0.0269, 0.0232, 0.0080],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,330][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9313, 0.0075, 0.0056, 0.0024, 0.0149, 0.0074, 0.0085, 0.0029, 0.0197],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,330][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([1.1655e-10, 9.9935e-01, 1.8396e-09, 2.2836e-04, 1.5459e-06, 7.9483e-08,
        4.4716e-07, 4.1983e-04, 3.6030e-09], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,330][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Jonathan] are: tensor([0.0055, 0.7164, 0.0021, 0.0484, 0.0301, 0.0042, 0.0051, 0.0702, 0.0012,
        0.1167], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,331][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Jonathan] are: tensor([0.0052, 0.7744, 0.0038, 0.0651, 0.0145, 0.0038, 0.0052, 0.0280, 0.0035,
        0.0965], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,331][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Jonathan] are: tensor([0.4641, 0.1177, 0.0272, 0.0629, 0.0583, 0.0424, 0.0466, 0.0477, 0.0735,
        0.0597], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,332][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Jonathan] are: tensor([0.1031, 0.5414, 0.0069, 0.1023, 0.0768, 0.0084, 0.0090, 0.0259, 0.0051,
        0.1212], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,333][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Jonathan] are: tensor([9.8949e-01, 2.2461e-03, 1.8117e-03, 2.0749e-03, 1.5055e-03, 2.6029e-04,
        2.1924e-04, 2.1708e-04, 8.5380e-04, 1.3212e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,335][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Jonathan] are: tensor([0.0760, 0.6237, 0.0101, 0.0819, 0.0550, 0.0089, 0.0165, 0.0231, 0.0061,
        0.0987], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,336][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Jonathan] are: tensor([0.0906, 0.5770, 0.0115, 0.0990, 0.0454, 0.0074, 0.0099, 0.0536, 0.0059,
        0.0997], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,337][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Jonathan] are: tensor([0.0072, 0.1662, 0.0198, 0.1417, 0.0567, 0.0494, 0.0632, 0.0863, 0.0282,
        0.3814], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,338][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Jonathan] are: tensor([0.7725, 0.0635, 0.0139, 0.0415, 0.0389, 0.0107, 0.0164, 0.0150, 0.0075,
        0.0202], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,340][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Jonathan] are: tensor([0.1233, 0.6354, 0.0072, 0.0837, 0.0295, 0.0062, 0.0100, 0.0173, 0.0037,
        0.0836], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,342][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Jonathan] are: tensor([0.8925, 0.0144, 0.0072, 0.0064, 0.0227, 0.0111, 0.0140, 0.0035, 0.0232,
        0.0049], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,343][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Jonathan] are: tensor([5.2440e-07, 9.9998e-01, 5.1058e-08, 6.4864e-07, 6.7305e-07, 1.8267e-08,
        2.1566e-07, 1.6795e-05, 8.4953e-08, 2.7514e-06], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,344][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0157, 0.6167, 0.0044, 0.0515, 0.0427, 0.0072, 0.0082, 0.0564, 0.0031,
        0.1008, 0.0932], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,346][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0043, 0.6650, 0.0040, 0.0832, 0.0140, 0.0048, 0.0086, 0.0279, 0.0041,
        0.1606, 0.0236], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,348][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.5366, 0.1575, 0.0229, 0.0659, 0.0416, 0.0241, 0.0315, 0.0173, 0.0333,
        0.0594, 0.0097], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,350][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0291, 0.4595, 0.0105, 0.1385, 0.0407, 0.0084, 0.0082, 0.0260, 0.0043,
        0.2181, 0.0567], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,351][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([9.9646e-01, 3.4298e-04, 8.7176e-04, 2.2628e-04, 6.9059e-04, 7.9004e-05,
        9.2731e-05, 1.7930e-04, 6.0870e-04, 3.3011e-04, 1.1939e-04],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,351][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0449, 0.5175, 0.0141, 0.1223, 0.0203, 0.0073, 0.0140, 0.0129, 0.0070,
        0.1964, 0.0433], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,351][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0402, 0.5690, 0.0111, 0.1379, 0.0319, 0.0096, 0.0084, 0.0340, 0.0068,
        0.1292, 0.0218], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,352][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0129, 0.1510, 0.0288, 0.1106, 0.0786, 0.0618, 0.0536, 0.1307, 0.0429,
        0.1675, 0.1616], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,352][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([9.3420e-01, 1.8096e-02, 4.9486e-03, 7.7509e-03, 1.6394e-02, 2.2965e-03,
        3.4891e-03, 3.9162e-03, 2.9445e-03, 5.1150e-03, 8.5151e-04],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,352][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.1157, 0.6102, 0.0046, 0.1082, 0.0388, 0.0042, 0.0060, 0.0058, 0.0024,
        0.0814, 0.0228], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,353][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.9586, 0.0070, 0.0019, 0.0018, 0.0094, 0.0030, 0.0028, 0.0041, 0.0072,
        0.0017, 0.0025], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,353][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([9.7913e-08, 9.9991e-01, 2.2511e-10, 1.6239e-05, 2.6915e-07, 7.2164e-10,
        1.2674e-09, 2.4252e-06, 1.6091e-10, 6.5332e-05, 9.6919e-07],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,353][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0071, 0.4258, 0.0035, 0.0568, 0.0367, 0.0066, 0.0052, 0.0529, 0.0017,
        0.1156, 0.2435, 0.0445], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,354][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0067, 0.4861, 0.0070, 0.0923, 0.0267, 0.0100, 0.0099, 0.0501, 0.0073,
        0.1746, 0.0433, 0.0860], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,354][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.3261, 0.1273, 0.0359, 0.0716, 0.0555, 0.0411, 0.0649, 0.0248, 0.0632,
        0.0820, 0.0269, 0.0806], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,354][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0342, 0.2851, 0.0089, 0.1218, 0.0720, 0.0113, 0.0100, 0.0211, 0.0068,
        0.2102, 0.1235, 0.0951], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,355][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([9.8266e-01, 1.3978e-03, 3.4042e-03, 1.1306e-03, 2.1387e-03, 4.1700e-04,
        4.9428e-04, 5.4638e-04, 2.7600e-03, 1.1554e-03, 2.9410e-04, 3.6008e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,357][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0508, 0.3379, 0.0137, 0.1022, 0.0365, 0.0138, 0.0237, 0.0407, 0.0169,
        0.1905, 0.0847, 0.0886], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,358][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0668, 0.4152, 0.0153, 0.1363, 0.0499, 0.0099, 0.0126, 0.0314, 0.0082,
        0.1483, 0.0482, 0.0578], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,360][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0048, 0.1073, 0.0262, 0.0919, 0.0697, 0.0704, 0.0677, 0.1209, 0.0380,
        0.1816, 0.1123, 0.1092], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,361][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.6716, 0.0559, 0.0265, 0.0338, 0.0425, 0.0167, 0.0256, 0.0078, 0.0203,
        0.0315, 0.0077, 0.0602], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,363][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1213, 0.4953, 0.0070, 0.0931, 0.0473, 0.0079, 0.0104, 0.0089, 0.0050,
        0.0899, 0.0660, 0.0477], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,365][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.7729, 0.0185, 0.0073, 0.0057, 0.0228, 0.0170, 0.0156, 0.0183, 0.0415,
        0.0067, 0.0088, 0.0651], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,366][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([5.7568e-08, 9.9820e-01, 6.1452e-09, 6.7724e-05, 3.1784e-06, 2.3393e-08,
        2.3651e-08, 2.9819e-05, 4.8946e-09, 4.0122e-04, 2.7200e-04, 1.0293e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,367][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.0365, 0.3611, 0.0017, 0.0400, 0.0285, 0.0029, 0.0028, 0.0233, 0.0009,
        0.0736, 0.1140, 0.0549, 0.2599], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,369][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.0138, 0.5011, 0.0044, 0.0488, 0.0238, 0.0044, 0.0064, 0.0144, 0.0036,
        0.0557, 0.0216, 0.0853, 0.2165], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,371][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.4828, 0.1097, 0.0259, 0.0497, 0.0548, 0.0287, 0.0347, 0.0147, 0.0458,
        0.0471, 0.0245, 0.0746, 0.0071], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,372][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.1074, 0.3563, 0.0035, 0.0949, 0.0448, 0.0031, 0.0042, 0.0106, 0.0019,
        0.1117, 0.0539, 0.0968, 0.1109], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,373][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([9.9744e-01, 3.4320e-04, 5.2873e-04, 2.0509e-04, 3.6718e-04, 3.0309e-05,
        3.4507e-05, 4.6626e-05, 2.2126e-04, 1.8608e-04, 4.0332e-05, 4.3566e-04,
        1.1724e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,374][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.0730, 0.4352, 0.0081, 0.0645, 0.0338, 0.0059, 0.0111, 0.0146, 0.0060,
        0.1094, 0.0428, 0.1238, 0.0718], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,374][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.0773, 0.5077, 0.0094, 0.1046, 0.0391, 0.0067, 0.0075, 0.0272, 0.0050,
        0.0837, 0.0353, 0.0475, 0.0492], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,374][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.0034, 0.0786, 0.0169, 0.0762, 0.0477, 0.0491, 0.0413, 0.1332, 0.0217,
        0.1418, 0.0765, 0.0817, 0.2320], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,375][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.8097, 0.0389, 0.0080, 0.0223, 0.0155, 0.0048, 0.0107, 0.0086, 0.0085,
        0.0236, 0.0028, 0.0408, 0.0057], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,375][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.1739, 0.5014, 0.0056, 0.0639, 0.0319, 0.0044, 0.0050, 0.0073, 0.0022,
        0.0556, 0.0490, 0.0486, 0.0512], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,375][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.9472, 0.0075, 0.0010, 0.0010, 0.0060, 0.0023, 0.0016, 0.0041, 0.0057,
        0.0010, 0.0020, 0.0166, 0.0040], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,376][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([3.5633e-07, 9.9926e-01, 4.9763e-10, 7.2413e-06, 1.2199e-07, 9.1413e-10,
        1.5579e-09, 5.4508e-07, 2.0897e-10, 2.1750e-05, 1.7678e-06, 7.0196e-04,
        9.5499e-06], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,376][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0130, 0.2932, 0.0013, 0.0280, 0.0175, 0.0011, 0.0030, 0.0201, 0.0008,
        0.0583, 0.0974, 0.0346, 0.2979, 0.1339], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,377][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0111, 0.4275, 0.0023, 0.0534, 0.0141, 0.0021, 0.0047, 0.0170, 0.0021,
        0.0620, 0.0107, 0.0543, 0.2001, 0.1386], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,377][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3914, 0.0987, 0.0267, 0.0517, 0.0501, 0.0263, 0.0418, 0.0238, 0.0512,
        0.0614, 0.0172, 0.0800, 0.0117, 0.0677], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,377][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1383, 0.1851, 0.0035, 0.0890, 0.0658, 0.0028, 0.0054, 0.0066, 0.0030,
        0.1199, 0.0507, 0.0840, 0.0932, 0.1527], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,378][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.9369e-01, 5.9593e-04, 1.3206e-03, 4.9306e-04, 1.0381e-03, 1.1843e-04,
        9.3461e-05, 1.1175e-04, 6.2654e-04, 4.1731e-04, 8.4571e-05, 9.3939e-04,
        2.3091e-04, 2.4458e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,380][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0955, 0.2937, 0.0086, 0.0684, 0.0253, 0.0034, 0.0171, 0.0091, 0.0078,
        0.1322, 0.0351, 0.0946, 0.0665, 0.1428], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,381][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0925, 0.3652, 0.0087, 0.0890, 0.0276, 0.0041, 0.0062, 0.0246, 0.0040,
        0.0809, 0.0313, 0.0555, 0.1364, 0.0738], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,383][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0093, 0.0842, 0.0215, 0.0738, 0.0522, 0.0420, 0.0355, 0.0423, 0.0247,
        0.1310, 0.0628, 0.0637, 0.0796, 0.2774], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,384][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.8472, 0.0356, 0.0109, 0.0189, 0.0195, 0.0047, 0.0061, 0.0029, 0.0070,
        0.0127, 0.0027, 0.0214, 0.0042, 0.0061], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,386][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.2661, 0.3466, 0.0035, 0.0785, 0.0325, 0.0028, 0.0051, 0.0058, 0.0024,
        0.0724, 0.0369, 0.0415, 0.0579, 0.0479], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,388][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.8686, 0.0090, 0.0044, 0.0022, 0.0116, 0.0091, 0.0078, 0.0052, 0.0235,
        0.0023, 0.0031, 0.0304, 0.0042, 0.0185], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,389][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([5.8631e-06, 7.6806e-01, 6.6007e-10, 1.7141e-05, 3.0349e-06, 5.6314e-10,
        9.3190e-09, 3.8021e-06, 7.3676e-10, 9.3582e-05, 1.2476e-04, 1.4365e-02,
        4.9856e-03, 2.1234e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,390][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:16:38,392][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 7419],
        [35062],
        [11973],
        [ 9695],
        [ 9078],
        [ 5079],
        [ 6334],
        [26210],
        [ 3515],
        [13223],
        [12655],
        [ 7167],
        [18369],
        [ 4140]], device='cuda:0')
[2024-07-24 10:16:38,394][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 7737],
        [42221],
        [20792],
        [19848],
        [18789],
        [11666],
        [12492],
        [33334],
        [ 7734],
        [26169],
        [20171],
        [11786],
        [26467],
        [ 8447]], device='cuda:0')
[2024-07-24 10:16:38,395][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 9739],
        [27068],
        [23463],
        [25923],
        [23306],
        [15664],
        [17809],
        [14823],
        [16758],
        [15562],
        [15445],
        [16460],
        [14694],
        [13944]], device='cuda:0')
[2024-07-24 10:16:38,396][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[49345],
        [47421],
        [46888],
        [46342],
        [46210],
        [46153],
        [46368],
        [47182],
        [47646],
        [46194],
        [45545],
        [46330],
        [48575],
        [48710]], device='cuda:0')
[2024-07-24 10:16:38,398][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[6619],
        [8329],
        [9294],
        [9214],
        [9092],
        [8925],
        [8778],
        [8450],
        [8471],
        [8423],
        [8675],
        [8722],
        [8402],
        [8213]], device='cuda:0')
[2024-07-24 10:16:38,399][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[7734],
        [7394],
        [6096],
        [6651],
        [6756],
        [6653],
        [6626],
        [6561],
        [6365],
        [6559],
        [6360],
        [6455],
        [6419],
        [6392]], device='cuda:0')
[2024-07-24 10:16:38,399][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[819],
        [ 89],
        [100],
        [ 11],
        [ 12],
        [ 21],
        [ 15],
        [267],
        [ 24],
        [ 15],
        [ 29],
        [ 20],
        [ 46],
        [ 35]], device='cuda:0')
[2024-07-24 10:16:38,400][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[4696],
        [3570],
        [4073],
        [3962],
        [4331],
        [4382],
        [5196],
        [5223],
        [5131],
        [4901],
        [4358],
        [4302],
        [5782],
        [4964]], device='cuda:0')
[2024-07-24 10:16:38,401][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[10102],
        [19396],
        [11136],
        [ 9213],
        [15623],
        [13838],
        [14048],
        [13627],
        [13541],
        [12207],
        [14582],
        [14596],
        [13922],
        [14822]], device='cuda:0')
[2024-07-24 10:16:38,402][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 7136],
        [ 6332],
        [ 8216],
        [ 9853],
        [10759],
        [13902],
        [15601],
        [12353],
        [14701],
        [14487],
        [14150],
        [14655],
        [14143],
        [16892]], device='cuda:0')
[2024-07-24 10:16:38,404][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[28543],
        [22645],
        [22977],
        [22290],
        [23760],
        [24281],
        [23396],
        [23588],
        [23837],
        [23768],
        [23436],
        [23318],
        [23250],
        [23247]], device='cuda:0')
[2024-07-24 10:16:38,405][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 1271],
        [18706],
        [33540],
        [31744],
        [33792],
        [34421],
        [34212],
        [34116],
        [33812],
        [32590],
        [33850],
        [33382],
        [31140],
        [26009]], device='cuda:0')
[2024-07-24 10:16:38,407][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[19147],
        [18838],
        [13754],
        [13956],
        [13040],
        [13744],
        [14430],
        [12482],
        [11401],
        [12186],
        [12053],
        [11390],
        [13150],
        [11722]], device='cuda:0')
[2024-07-24 10:16:38,408][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[26893],
        [27082],
        [37550],
        [37549],
        [37549],
        [37547],
        [37549],
        [37549],
        [37545],
        [37550],
        [37549],
        [37523],
        [37536],
        [30190]], device='cuda:0')
[2024-07-24 10:16:38,409][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[33024],
        [33982],
        [38650],
        [38023],
        [39153],
        [34192],
        [36663],
        [36672],
        [35074],
        [32919],
        [36546],
        [36808],
        [27260],
        [29497]], device='cuda:0')
[2024-07-24 10:16:38,411][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[18851],
        [13953],
        [13055],
        [14439],
        [15010],
        [15460],
        [15083],
        [14922],
        [16365],
        [15984],
        [12686],
        [ 9089],
        [ 9660],
        [10442]], device='cuda:0')
[2024-07-24 10:16:38,412][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[21001],
        [11230],
        [11201],
        [11303],
        [11073],
        [11018],
        [11182],
        [11067],
        [11796],
        [12373],
        [13113],
        [15675],
        [16542],
        [17003]], device='cuda:0')
[2024-07-24 10:16:38,414][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[6218],
        [3041],
        [1039],
        [1536],
        [ 894],
        [ 743],
        [ 795],
        [ 790],
        [ 612],
        [ 877],
        [1035],
        [ 909],
        [ 913],
        [ 892]], device='cuda:0')
[2024-07-24 10:16:38,415][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[7025],
        [7312],
        [7682],
        [7821],
        [8527],
        [8440],
        [8691],
        [8539],
        [8993],
        [8211],
        [8104],
        [8422],
        [7940],
        [7664]], device='cuda:0')
[2024-07-24 10:16:38,417][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[16155],
        [16094],
        [15883],
        [15850],
        [14916],
        [15685],
        [15884],
        [15995],
        [15372],
        [15094],
        [15808],
        [14200],
        [15886],
        [15426]], device='cuda:0')
[2024-07-24 10:16:38,418][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[18572],
        [15981],
        [13023],
        [11621],
        [10479],
        [10194],
        [10583],
        [11089],
        [10761],
        [10063],
        [ 9142],
        [ 9444],
        [ 9855],
        [ 9769]], device='cuda:0')
[2024-07-24 10:16:38,420][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 9005],
        [11857],
        [14753],
        [14469],
        [15098],
        [15282],
        [15277],
        [15054],
        [12634],
        [12687],
        [13516],
        [11517],
        [10832],
        [ 6828]], device='cuda:0')
[2024-07-24 10:16:38,421][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[37455],
        [34900],
        [30251],
        [31863],
        [30468],
        [25299],
        [23781],
        [27817],
        [24523],
        [28661],
        [27575],
        [27232],
        [28900],
        [24720]], device='cuda:0')
[2024-07-24 10:16:38,422][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[11301],
        [10583],
        [11351],
        [10858],
        [13753],
        [11271],
        [11130],
        [10608],
        [11046],
        [10101],
        [10377],
        [ 9324],
        [ 7055],
        [ 8327]], device='cuda:0')
[2024-07-24 10:16:38,423][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[33892],
        [19787],
        [10098],
        [10217],
        [ 8801],
        [ 8060],
        [ 8568],
        [ 8661],
        [ 8859],
        [ 8779],
        [ 7877],
        [ 7710],
        [ 8295],
        [ 9480]], device='cuda:0')
[2024-07-24 10:16:38,424][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[22372],
        [22104],
        [22307],
        [21882],
        [21108],
        [21792],
        [21965],
        [22264],
        [22041],
        [21663],
        [21888],
        [24701],
        [22550],
        [23300]], device='cuda:0')
[2024-07-24 10:16:38,425][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[49931],
        [49901],
        [34111],
        [34117],
        [34111],
        [34111],
        [34111],
        [34111],
        [34111],
        [34111],
        [34111],
        [34124],
        [34119],
        [33873]], device='cuda:0')
[2024-07-24 10:16:38,426][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[24747],
        [28641],
        [32249],
        [32156],
        [33007],
        [33657],
        [33463],
        [33378],
        [34048],
        [34289],
        [34608],
        [35861],
        [35880],
        [36501]], device='cuda:0')
[2024-07-24 10:16:38,427][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 7202],
        [ 6955],
        [ 5894],
        [ 5147],
        [ 4857],
        [ 7683],
        [ 6661],
        [ 6693],
        [ 8168],
        [ 8341],
        [ 5964],
        [ 6966],
        [11806],
        [10759]], device='cuda:0')
[2024-07-24 10:16:38,428][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[17480],
        [17480],
        [17480],
        [17480],
        [17480],
        [17480],
        [17480],
        [17480],
        [17480],
        [17480],
        [17480],
        [17480],
        [17480],
        [17480]], device='cuda:0')
[2024-07-24 10:16:38,462][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:38,464][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,466][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,467][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,468][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,468][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,468][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,469][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,469][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,469][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,470][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,470][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,470][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,470][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.2429, 0.7571], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,471][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.5265, 0.4735], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,471][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.6382, 0.3618], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,471][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.5103, 0.4897], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,472][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.6062, 0.3938], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,474][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.1226, 0.8774], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,475][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.5256, 0.4744], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,477][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.5022, 0.4978], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,478][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.9391, 0.0609], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,479][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.1434, 0.8566], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,481][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.5914, 0.4086], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,483][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.5463, 0.4537], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,484][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1447, 0.6962, 0.1591], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,486][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.3112, 0.2878, 0.4010], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,488][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3252, 0.3298, 0.3450], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,489][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3460, 0.3376, 0.3164], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,491][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1956, 0.7498, 0.0546], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,491][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0619, 0.4519, 0.4862], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,491][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.4081, 0.5792, 0.0127], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,492][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3812, 0.5808, 0.0380], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,492][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.6200, 0.3598, 0.0202], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,492][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0800, 0.4647, 0.4553], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,493][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4412, 0.2815, 0.2773], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,493][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.3881, 0.3037, 0.3082], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,493][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Jonathan] are: tensor([0.1432, 0.5884, 0.1237, 0.1447], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,494][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Jonathan] are: tensor([0.3250, 0.2237, 0.3175, 0.1338], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,494][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Jonathan] are: tensor([0.3418, 0.2250, 0.2520, 0.1812], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,494][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Jonathan] are: tensor([0.2551, 0.2500, 0.2376, 0.2573], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,495][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Jonathan] are: tensor([0.2412, 0.5673, 0.0612, 0.1302], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,497][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Jonathan] are: tensor([0.0487, 0.3288, 0.3483, 0.2742], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,499][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Jonathan] are: tensor([0.3394, 0.4220, 0.1343, 0.1043], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,500][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Jonathan] are: tensor([0.5176, 0.3582, 0.0139, 0.1104], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,501][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Jonathan] are: tensor([0.7514, 0.1553, 0.0117, 0.0816], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,503][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Jonathan] are: tensor([0.0577, 0.3113, 0.3092, 0.3218], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,505][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Jonathan] are: tensor([0.3272, 0.2261, 0.2198, 0.2269], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,506][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Jonathan] are: tensor([0.2832, 0.2424, 0.2374, 0.2370], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,508][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.1125, 0.5195, 0.1142, 0.1255, 0.1283], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,510][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.1978, 0.1931, 0.2757, 0.1099, 0.2235], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,512][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.2661, 0.2082, 0.2233, 0.1699, 0.1325], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,513][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.2022, 0.2009, 0.1910, 0.2068, 0.1990], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,514][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.1427, 0.5027, 0.0845, 0.1735, 0.0967], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,514][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0345, 0.2438, 0.2627, 0.2077, 0.2514], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,514][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.2935, 0.4982, 0.0595, 0.1230, 0.0258], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,515][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.4310, 0.2575, 0.0242, 0.1275, 0.1598], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,515][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.6474, 0.1821, 0.0187, 0.1093, 0.0425], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,515][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.0401, 0.2386, 0.2383, 0.2478, 0.2353], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,516][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.2716, 0.1831, 0.1774, 0.1851, 0.1829], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,516][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.2344, 0.1948, 0.1923, 0.1921, 0.1864], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,516][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0926, 0.4169, 0.1059, 0.1129, 0.1153, 0.1564], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,517][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1451, 0.1355, 0.2176, 0.0856, 0.1695, 0.2466], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,517][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1899, 0.1986, 0.1956, 0.1550, 0.1183, 0.1426], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,518][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1753, 0.1683, 0.1598, 0.1739, 0.1677, 0.1550], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,520][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1154, 0.5378, 0.0518, 0.1608, 0.0770, 0.0571], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,522][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0264, 0.1923, 0.2141, 0.1677, 0.1998, 0.1997], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,523][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.3701, 0.4153, 0.0209, 0.1302, 0.0546, 0.0090], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,524][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1845, 0.3855, 0.0402, 0.2343, 0.1321, 0.0234], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,526][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.3634, 0.3037, 0.0434, 0.1933, 0.0606, 0.0355], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,528][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0286, 0.1979, 0.1974, 0.2061, 0.1971, 0.1728], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,529][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.2520, 0.1503, 0.1475, 0.1547, 0.1528, 0.1426], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,531][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.2098, 0.1597, 0.1641, 0.1605, 0.1544, 0.1514], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,533][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0856, 0.3623, 0.0919, 0.0992, 0.0951, 0.1355, 0.1304],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,534][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1138, 0.1185, 0.1775, 0.0718, 0.1449, 0.2061, 0.1673],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,536][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1663, 0.1771, 0.1706, 0.1345, 0.1012, 0.1247, 0.1256],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,536][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1472, 0.1462, 0.1388, 0.1508, 0.1452, 0.1352, 0.1366],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,537][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1023, 0.5050, 0.0586, 0.1467, 0.0775, 0.0721, 0.0378],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,537][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0207, 0.1611, 0.1781, 0.1403, 0.1680, 0.1661, 0.1656],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,537][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.3254, 0.3881, 0.0196, 0.1754, 0.0628, 0.0114, 0.0173],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,538][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.2577, 0.3749, 0.0380, 0.1640, 0.1229, 0.0160, 0.0265],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,538][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.3700, 0.2974, 0.0349, 0.1808, 0.0607, 0.0304, 0.0258],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,539][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0279, 0.1660, 0.1635, 0.1721, 0.1644, 0.1457, 0.1603],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,539][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.2069, 0.1334, 0.1288, 0.1350, 0.1340, 0.1270, 0.1348],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,539][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1776, 0.1391, 0.1420, 0.1392, 0.1347, 0.1320, 0.1353],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,540][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.0727, 0.3204, 0.0734, 0.0851, 0.0825, 0.1146, 0.1090, 0.1423],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,540][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([0.1163, 0.0923, 0.1338, 0.0530, 0.1043, 0.1460, 0.1246, 0.2298],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,542][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.1519, 0.1517, 0.1432, 0.1188, 0.0932, 0.1131, 0.1142, 0.1140],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,543][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.1313, 0.1284, 0.1209, 0.1323, 0.1270, 0.1176, 0.1189, 0.1237],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,545][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.1177, 0.5417, 0.0341, 0.1387, 0.0666, 0.0524, 0.0244, 0.0245],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,546][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.0240, 0.1356, 0.1421, 0.1152, 0.1341, 0.1323, 0.1363, 0.1805],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,548][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.2366, 0.2610, 0.0595, 0.1255, 0.0619, 0.0278, 0.0829, 0.1448],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,550][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.4739, 0.2726, 0.0169, 0.0907, 0.0903, 0.0078, 0.0088, 0.0391],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,552][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.6338, 0.1546, 0.0092, 0.1053, 0.0269, 0.0118, 0.0144, 0.0439],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,553][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.0294, 0.1406, 0.1407, 0.1421, 0.1365, 0.1237, 0.1325, 0.1545],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,555][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.1987, 0.1145, 0.1122, 0.1196, 0.1172, 0.1099, 0.1201, 0.1078],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,557][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.1664, 0.1217, 0.1224, 0.1210, 0.1162, 0.1115, 0.1162, 0.1247],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,558][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0642, 0.2892, 0.0718, 0.0796, 0.0747, 0.1047, 0.1025, 0.1262, 0.0870],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,560][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0835, 0.0781, 0.1266, 0.0438, 0.0983, 0.1395, 0.1166, 0.2242, 0.0895],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,562][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1431, 0.1267, 0.1284, 0.1030, 0.0831, 0.1004, 0.1032, 0.1025, 0.1097],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,563][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1167, 0.1142, 0.1081, 0.1172, 0.1132, 0.1052, 0.1066, 0.1111, 0.1077],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,565][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0800, 0.4637, 0.0489, 0.1637, 0.0736, 0.0561, 0.0428, 0.0400, 0.0312],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,565][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0146, 0.1207, 0.1361, 0.1046, 0.1268, 0.1233, 0.1227, 0.1648, 0.0863],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,565][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2622, 0.3512, 0.0068, 0.1339, 0.0504, 0.0062, 0.0242, 0.1633, 0.0018],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,566][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2200, 0.3199, 0.0273, 0.1543, 0.1177, 0.0174, 0.0228, 0.0730, 0.0474],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,566][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3886, 0.2038, 0.0209, 0.1526, 0.0506, 0.0250, 0.0268, 0.1058, 0.0258],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,566][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0178, 0.1256, 0.1236, 0.1294, 0.1245, 0.1085, 0.1205, 0.1400, 0.1100],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,567][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1658, 0.1070, 0.1025, 0.1091, 0.1079, 0.1022, 0.1074, 0.0964, 0.1017],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,567][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1429, 0.1080, 0.1117, 0.1084, 0.1046, 0.1022, 0.1055, 0.1097, 0.1070],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,568][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Jonathan] are: tensor([0.0614, 0.2834, 0.0619, 0.0695, 0.0658, 0.0936, 0.0924, 0.1125, 0.0777,
        0.0817], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,568][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Jonathan] are: tensor([0.1054, 0.0749, 0.1147, 0.0431, 0.0854, 0.1367, 0.1116, 0.1905, 0.0737,
        0.0640], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,569][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Jonathan] are: tensor([0.1596, 0.1148, 0.1248, 0.0908, 0.0704, 0.0871, 0.0895, 0.0923, 0.0989,
        0.0718], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,571][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Jonathan] are: tensor([0.1032, 0.1021, 0.0964, 0.1046, 0.1009, 0.0943, 0.0953, 0.0996, 0.0971,
        0.1064], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,572][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Jonathan] are: tensor([0.0705, 0.4468, 0.0438, 0.1173, 0.0756, 0.0608, 0.0398, 0.0516, 0.0289,
        0.0649], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,574][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Jonathan] are: tensor([0.0131, 0.1106, 0.1208, 0.0915, 0.1154, 0.1168, 0.1176, 0.1624, 0.0839,
        0.0678], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,575][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Jonathan] are: tensor([0.1641, 0.2443, 0.0702, 0.0624, 0.0331, 0.0231, 0.0957, 0.2333, 0.0311,
        0.0427], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,577][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Jonathan] are: tensor([0.2182, 0.2915, 0.0197, 0.1174, 0.0721, 0.0099, 0.0184, 0.0489, 0.0212,
        0.1828], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,579][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Jonathan] are: tensor([0.3279, 0.2238, 0.0223, 0.1241, 0.0495, 0.0225, 0.0233, 0.0993, 0.0220,
        0.0854], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,580][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Jonathan] are: tensor([0.0167, 0.1102, 0.1110, 0.1145, 0.1096, 0.0982, 0.1087, 0.1244, 0.1006,
        0.1060], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,582][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Jonathan] are: tensor([0.1440, 0.0968, 0.0948, 0.0984, 0.0961, 0.0919, 0.0968, 0.0878, 0.0933,
        0.0999], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,584][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Jonathan] are: tensor([0.1206, 0.1007, 0.0995, 0.0988, 0.0962, 0.0927, 0.0944, 0.1006, 0.0947,
        0.1018], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,586][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0597, 0.2471, 0.0579, 0.0636, 0.0625, 0.0799, 0.0774, 0.0984, 0.0639,
        0.0712, 0.1184], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,587][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0766, 0.0689, 0.1034, 0.0418, 0.0832, 0.1155, 0.0962, 0.1602, 0.0717,
        0.0572, 0.1253], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,588][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.1198, 0.1098, 0.1086, 0.0864, 0.0664, 0.0842, 0.0877, 0.0866, 0.0969,
        0.0715, 0.0820], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,588][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0932, 0.0922, 0.0872, 0.0946, 0.0909, 0.0850, 0.0861, 0.0897, 0.0882,
        0.0963, 0.0966], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,588][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1057, 0.5513, 0.0248, 0.1046, 0.0456, 0.0332, 0.0196, 0.0176, 0.0145,
        0.0519, 0.0312], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,589][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0141, 0.1013, 0.1075, 0.0864, 0.1062, 0.1014, 0.1026, 0.1394, 0.0748,
        0.0654, 0.1009], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,589][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.2308, 0.2336, 0.0414, 0.0896, 0.0256, 0.0253, 0.0638, 0.1739, 0.0187,
        0.0647, 0.0327], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,590][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.3112, 0.3734, 0.0066, 0.1065, 0.0348, 0.0021, 0.0048, 0.0108, 0.0046,
        0.1275, 0.0177], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,590][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.6363, 0.1199, 0.0049, 0.0730, 0.0212, 0.0097, 0.0086, 0.0346, 0.0115,
        0.0698, 0.0106], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,590][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0174, 0.0995, 0.1000, 0.1026, 0.0980, 0.0886, 0.0970, 0.1092, 0.0912,
        0.0955, 0.1010], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,591][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.1404, 0.0862, 0.0857, 0.0897, 0.0872, 0.0824, 0.0894, 0.0795, 0.0848,
        0.0912, 0.0835], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,591][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.1121, 0.0908, 0.0905, 0.0900, 0.0868, 0.0839, 0.0856, 0.0910, 0.0863,
        0.0922, 0.0908], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,593][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0555, 0.2470, 0.0523, 0.0563, 0.0558, 0.0769, 0.0730, 0.0933, 0.0626,
        0.0642, 0.1107, 0.0525], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,595][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0555, 0.0613, 0.1030, 0.0378, 0.0835, 0.1102, 0.0895, 0.1657, 0.0706,
        0.0551, 0.1324, 0.0353], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,596][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1372, 0.1066, 0.1095, 0.0767, 0.0564, 0.0755, 0.0793, 0.0791, 0.0854,
        0.0592, 0.0735, 0.0616], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,597][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0851, 0.0839, 0.0797, 0.0864, 0.0835, 0.0782, 0.0791, 0.0825, 0.0808,
        0.0883, 0.0888, 0.0838], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,598][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0781, 0.3216, 0.0454, 0.1077, 0.0723, 0.0597, 0.0359, 0.0382, 0.0321,
        0.0684, 0.0894, 0.0510], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,600][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0113, 0.0908, 0.0992, 0.0780, 0.0954, 0.0933, 0.0937, 0.1241, 0.0694,
        0.0602, 0.0958, 0.0888], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,602][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2029, 0.2382, 0.0147, 0.1344, 0.0441, 0.0097, 0.0143, 0.2056, 0.0042,
        0.0884, 0.0371, 0.0064], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,604][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1481, 0.2595, 0.0259, 0.1013, 0.0714, 0.0114, 0.0178, 0.0642, 0.0193,
        0.1284, 0.0985, 0.0542], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,605][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.3461, 0.1800, 0.0245, 0.0967, 0.0405, 0.0203, 0.0232, 0.0637, 0.0258,
        0.0899, 0.0442, 0.0451], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,607][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0149, 0.0904, 0.0903, 0.0934, 0.0898, 0.0798, 0.0875, 0.1004, 0.0815,
        0.0875, 0.0940, 0.0904], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,609][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1215, 0.0811, 0.0781, 0.0821, 0.0809, 0.0774, 0.0819, 0.0741, 0.0783,
        0.0830, 0.0780, 0.0837], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,610][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1014, 0.0829, 0.0828, 0.0818, 0.0802, 0.0781, 0.0794, 0.0843, 0.0801,
        0.0844, 0.0834, 0.0812], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,611][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.0568, 0.2173, 0.0483, 0.0538, 0.0521, 0.0702, 0.0672, 0.0903, 0.0581,
        0.0595, 0.1046, 0.0489, 0.0728], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,611][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.1024, 0.0609, 0.0848, 0.0297, 0.0697, 0.1056, 0.0849, 0.1587, 0.0653,
        0.0497, 0.1329, 0.0299, 0.0254], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,612][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.1418, 0.0978, 0.0967, 0.0720, 0.0568, 0.0680, 0.0706, 0.0730, 0.0753,
        0.0571, 0.0683, 0.0537, 0.0691], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,612][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0757, 0.0780, 0.0736, 0.0800, 0.0771, 0.0727, 0.0729, 0.0762, 0.0741,
        0.0816, 0.0826, 0.0779, 0.0776], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,612][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.0776, 0.3999, 0.0285, 0.1119, 0.0634, 0.0496, 0.0239, 0.0236, 0.0226,
        0.0532, 0.0688, 0.0516, 0.0254], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,613][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.0142, 0.0889, 0.0891, 0.0736, 0.0853, 0.0876, 0.0889, 0.1104, 0.0604,
        0.0553, 0.0843, 0.0824, 0.0797], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,613][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.1782, 0.2231, 0.0461, 0.0755, 0.0306, 0.0211, 0.0648, 0.1491, 0.0220,
        0.0552, 0.0483, 0.0480, 0.0381], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,614][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.2282, 0.2532, 0.0143, 0.1109, 0.0570, 0.0066, 0.0085, 0.0351, 0.0138,
        0.1291, 0.0448, 0.0415, 0.0569], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,614][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.5482, 0.1306, 0.0063, 0.0747, 0.0248, 0.0091, 0.0107, 0.0267, 0.0110,
        0.0722, 0.0190, 0.0300, 0.0367], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,615][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.0170, 0.0825, 0.0833, 0.0842, 0.0817, 0.0744, 0.0796, 0.0913, 0.0760,
        0.0788, 0.0842, 0.0817, 0.0854], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,617][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.1146, 0.0734, 0.0720, 0.0757, 0.0747, 0.0720, 0.0768, 0.0692, 0.0721,
        0.0774, 0.0720, 0.0778, 0.0722], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,619][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0953, 0.0755, 0.0769, 0.0748, 0.0725, 0.0711, 0.0732, 0.0791, 0.0736,
        0.0776, 0.0767, 0.0744, 0.0792], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,620][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0445, 0.1959, 0.0470, 0.0505, 0.0490, 0.0671, 0.0639, 0.0835, 0.0574,
        0.0575, 0.0963, 0.0454, 0.0691, 0.0730], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,621][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0752, 0.0675, 0.0930, 0.0293, 0.0672, 0.0965, 0.0801, 0.1578, 0.0670,
        0.0466, 0.1318, 0.0286, 0.0291, 0.0303], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,623][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1399, 0.0884, 0.0930, 0.0644, 0.0503, 0.0632, 0.0662, 0.0680, 0.0730,
        0.0511, 0.0640, 0.0492, 0.0663, 0.0628], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,625][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0732, 0.0722, 0.0684, 0.0742, 0.0718, 0.0671, 0.0677, 0.0703, 0.0688,
        0.0758, 0.0765, 0.0720, 0.0722, 0.0701], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,627][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0917, 0.2948, 0.0375, 0.1046, 0.0541, 0.0417, 0.0292, 0.0251, 0.0254,
        0.0660, 0.0733, 0.0510, 0.0325, 0.0732], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,628][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0092, 0.0805, 0.0873, 0.0685, 0.0837, 0.0797, 0.0809, 0.1068, 0.0579,
        0.0511, 0.0817, 0.0759, 0.0714, 0.0653], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,630][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2133, 0.2549, 0.0123, 0.0775, 0.0390, 0.0050, 0.0313, 0.1601, 0.0048,
        0.0504, 0.0356, 0.0169, 0.0962, 0.0027], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,632][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0994, 0.2285, 0.0160, 0.0870, 0.0518, 0.0075, 0.0136, 0.0519, 0.0222,
        0.1360, 0.0924, 0.0417, 0.1057, 0.0464], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,633][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2688, 0.1556, 0.0221, 0.0973, 0.0320, 0.0194, 0.0244, 0.0659, 0.0229,
        0.0926, 0.0365, 0.0459, 0.0773, 0.0392], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,634][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0115, 0.0773, 0.0777, 0.0799, 0.0768, 0.0672, 0.0741, 0.0857, 0.0692,
        0.0740, 0.0801, 0.0765, 0.0813, 0.0688], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,634][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1077, 0.0687, 0.0672, 0.0705, 0.0696, 0.0665, 0.0705, 0.0635, 0.0667,
        0.0719, 0.0667, 0.0719, 0.0664, 0.0721], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,635][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0885, 0.0695, 0.0713, 0.0697, 0.0675, 0.0665, 0.0681, 0.0722, 0.0693,
        0.0724, 0.0709, 0.0688, 0.0726, 0.0728], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,676][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:38,677][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,678][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,679][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,679][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,679][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,680][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,680][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,680][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,680][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,681][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,681][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,681][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,682][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.9497, 0.0503], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,682][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.9169, 0.0831], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,683][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.4859, 0.5141], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,685][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.5434, 0.4566], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,686][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.6062, 0.3938], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,698][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.4670, 0.5330], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,699][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.5664, 0.4336], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,701][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.5870, 0.4130], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,701][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.7465, 0.2535], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,701][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.8691, 0.1309], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,702][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.7773, 0.2227], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,702][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.9197, 0.0803], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,702][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.8978, 0.0902, 0.0120], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,703][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.7950, 0.1549, 0.0501], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,703][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1178, 0.8203, 0.0619], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,703][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2134, 0.6881, 0.0985], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,704][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1956, 0.7498, 0.0546], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,704][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2982, 0.3426, 0.3592], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,704][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.4521, 0.3799, 0.1680], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,705][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.5840, 0.3873, 0.0288], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,705][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.4002, 0.5446, 0.0552], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,707][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.8189, 0.1571, 0.0240], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,709][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9120, 0.0825, 0.0055], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,710][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.8776, 0.0981, 0.0243], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,712][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Jonathan] are: tensor([0.8554, 0.0803, 0.0167, 0.0476], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,713][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Jonathan] are: tensor([0.7623, 0.0920, 0.0603, 0.0854], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,715][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Jonathan] are: tensor([0.1668, 0.5890, 0.0865, 0.1577], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,717][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Jonathan] are: tensor([0.2432, 0.4735, 0.0833, 0.2000], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,718][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Jonathan] are: tensor([0.2412, 0.5673, 0.0612, 0.1302], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,720][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Jonathan] are: tensor([0.2224, 0.2568, 0.2723, 0.2485], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,722][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Jonathan] are: tensor([0.2808, 0.3461, 0.1933, 0.1799], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,723][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Jonathan] are: tensor([0.4141, 0.4524, 0.0158, 0.1176], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,724][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Jonathan] are: tensor([0.3988, 0.4008, 0.0477, 0.1526], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,724][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Jonathan] are: tensor([0.6466, 0.2166, 0.0351, 0.1017], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,725][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Jonathan] are: tensor([0.7017, 0.1875, 0.0234, 0.0874], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,725][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Jonathan] are: tensor([0.8182, 0.0944, 0.0275, 0.0599], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,725][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.7031, 0.1285, 0.0325, 0.0739, 0.0620], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,726][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.3986, 0.1621, 0.0861, 0.1750, 0.1783], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,726][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.1018, 0.5199, 0.1020, 0.1940, 0.0823], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,726][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.1388, 0.4186, 0.1096, 0.2226, 0.1105], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,727][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.1427, 0.5027, 0.0845, 0.1735, 0.0967], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,727][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.1792, 0.2034, 0.2167, 0.1981, 0.2025], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,727][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.2432, 0.2817, 0.1147, 0.1853, 0.1751], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,728][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.4581, 0.3051, 0.0258, 0.1145, 0.0965], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,730][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.2917, 0.3903, 0.0587, 0.1690, 0.0903], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,731][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.6404, 0.1547, 0.0421, 0.0992, 0.0636], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,733][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.6650, 0.1663, 0.0236, 0.0896, 0.0555], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,734][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.7023, 0.1090, 0.0352, 0.0688, 0.0848], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,736][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.8068, 0.0773, 0.0211, 0.0507, 0.0312, 0.0129], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,738][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.4672, 0.1341, 0.0629, 0.1280, 0.1180, 0.0899], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,739][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0891, 0.5397, 0.0723, 0.1761, 0.0655, 0.0573], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,741][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0940, 0.4626, 0.0785, 0.2185, 0.1047, 0.0417], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,742][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1154, 0.5378, 0.0518, 0.1608, 0.0770, 0.0571], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,744][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1515, 0.1636, 0.1760, 0.1610, 0.1651, 0.1828], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,746][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.2854, 0.1327, 0.1024, 0.0921, 0.1995, 0.1880], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,747][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.4370, 0.2790, 0.0334, 0.1227, 0.0984, 0.0295], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,747][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2595, 0.4207, 0.0435, 0.1865, 0.0622, 0.0276], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,747][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.6936, 0.1338, 0.0261, 0.0849, 0.0446, 0.0170], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,748][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.9390, 0.0263, 0.0021, 0.0182, 0.0128, 0.0016], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,748][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.6421, 0.1278, 0.0343, 0.0871, 0.0764, 0.0323], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,749][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.8587, 0.0551, 0.0134, 0.0318, 0.0220, 0.0080, 0.0110],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,749][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.5847, 0.1191, 0.0410, 0.0995, 0.0641, 0.0390, 0.0526],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,749][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0698, 0.5182, 0.0647, 0.1672, 0.0640, 0.0578, 0.0585],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,750][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0735, 0.4316, 0.0813, 0.2054, 0.0961, 0.0559, 0.0562],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,750][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1023, 0.5050, 0.0586, 0.1467, 0.0775, 0.0721, 0.0378],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,750][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1242, 0.1405, 0.1499, 0.1371, 0.1409, 0.1566, 0.1508],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,751][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2007, 0.1114, 0.1130, 0.0856, 0.1352, 0.2443, 0.1098],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,753][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.4326, 0.2936, 0.0352, 0.1055, 0.0824, 0.0275, 0.0232],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,754][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.2333, 0.4196, 0.0408, 0.1949, 0.0598, 0.0285, 0.0231],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,756][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.7552, 0.1070, 0.0177, 0.0578, 0.0333, 0.0120, 0.0170],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,757][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.9352, 0.0326, 0.0023, 0.0164, 0.0100, 0.0014, 0.0023],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,759][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.6606, 0.1237, 0.0332, 0.0789, 0.0549, 0.0217, 0.0271],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,761][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.8949, 0.0421, 0.0063, 0.0280, 0.0136, 0.0035, 0.0055, 0.0060],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,762][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([0.8261, 0.0309, 0.0150, 0.0317, 0.0297, 0.0078, 0.0092, 0.0496],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,764][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([0.1118, 0.4628, 0.0396, 0.1759, 0.0700, 0.0446, 0.0493, 0.0460],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,765][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.0650, 0.3963, 0.0716, 0.1758, 0.0824, 0.0749, 0.0673, 0.0667],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,767][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.1177, 0.5417, 0.0341, 0.1387, 0.0666, 0.0524, 0.0244, 0.0245],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,769][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.1114, 0.1223, 0.1304, 0.1204, 0.1227, 0.1352, 0.1309, 0.1267],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,770][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.1521, 0.1677, 0.0950, 0.1095, 0.1355, 0.1652, 0.1121, 0.0629],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,770][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.4519, 0.3260, 0.0205, 0.0831, 0.0678, 0.0154, 0.0157, 0.0196],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,771][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.3388, 0.3436, 0.0362, 0.1376, 0.0483, 0.0219, 0.0227, 0.0510],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,771][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.8016, 0.0882, 0.0115, 0.0562, 0.0245, 0.0070, 0.0080, 0.0028],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,771][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([9.8458e-01, 9.9461e-03, 1.0934e-04, 3.4419e-03, 1.5632e-03, 6.5788e-05,
        1.9355e-04, 1.0018e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,772][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.7440, 0.1383, 0.0112, 0.0435, 0.0276, 0.0038, 0.0070, 0.0245],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:38,772][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.7756, 0.0746, 0.0124, 0.0524, 0.0291, 0.0104, 0.0142, 0.0113, 0.0200],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,773][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.3294, 0.0911, 0.0418, 0.0978, 0.0729, 0.0463, 0.0593, 0.1502, 0.1111],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,773][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0763, 0.4380, 0.0444, 0.1567, 0.0640, 0.0453, 0.0630, 0.0693, 0.0431],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,773][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0535, 0.3686, 0.0752, 0.1739, 0.0848, 0.0503, 0.0506, 0.1023, 0.0409],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,774][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0800, 0.4637, 0.0489, 0.1637, 0.0736, 0.0561, 0.0428, 0.0400, 0.0312],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,775][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0980, 0.1070, 0.1140, 0.1053, 0.1085, 0.1209, 0.1164, 0.1115, 0.1184],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,777][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1399, 0.1325, 0.0908, 0.0900, 0.1227, 0.1513, 0.1199, 0.0553, 0.0976],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,778][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4398, 0.2176, 0.0363, 0.1017, 0.0926, 0.0331, 0.0288, 0.0185, 0.0315],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,780][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.2014, 0.3287, 0.0365, 0.1693, 0.0628, 0.0320, 0.0342, 0.0968, 0.0384],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,781][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.6772, 0.0947, 0.0220, 0.0743, 0.0428, 0.0183, 0.0232, 0.0227, 0.0246],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,782][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([9.3291e-01, 3.1058e-02, 2.0016e-03, 1.8154e-02, 1.1660e-02, 1.1452e-03,
        1.5242e-03, 1.5378e-04, 1.3926e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,784][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.5196, 0.1676, 0.0456, 0.0978, 0.0648, 0.0262, 0.0247, 0.0168, 0.0370],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:38,786][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Jonathan] are: tensor([0.5057, 0.1076, 0.0424, 0.0748, 0.0570, 0.0268, 0.0339, 0.0324, 0.0407,
        0.0788], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,788][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Jonathan] are: tensor([0.1682, 0.0763, 0.0795, 0.0806, 0.0776, 0.0662, 0.0822, 0.1519, 0.1164,
        0.1009], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,790][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Jonathan] are: tensor([0.0470, 0.3764, 0.0610, 0.1179, 0.0515, 0.0429, 0.0546, 0.0804, 0.0507,
        0.1177], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,791][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Jonathan] are: tensor([0.0498, 0.3188, 0.0613, 0.1429, 0.0794, 0.0481, 0.0513, 0.1031, 0.0438,
        0.1016], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,793][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Jonathan] are: tensor([0.0705, 0.4468, 0.0438, 0.1173, 0.0756, 0.0608, 0.0398, 0.0516, 0.0289,
        0.0649], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,793][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Jonathan] are: tensor([0.0849, 0.0985, 0.1043, 0.0953, 0.0979, 0.1086, 0.1044, 0.1002, 0.1085,
        0.0975], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,793][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Jonathan] are: tensor([0.0590, 0.1582, 0.0887, 0.0862, 0.1084, 0.1597, 0.1074, 0.0821, 0.0781,
        0.0721], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,794][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Jonathan] are: tensor([0.1727, 0.3970, 0.0268, 0.1223, 0.0825, 0.0244, 0.0259, 0.0337, 0.0192,
        0.0954], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,794][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Jonathan] are: tensor([0.1317, 0.3443, 0.0505, 0.1295, 0.0650, 0.0305, 0.0316, 0.0821, 0.0330,
        0.1018], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,795][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Jonathan] are: tensor([0.3532, 0.1991, 0.0452, 0.1080, 0.0650, 0.0321, 0.0363, 0.0573, 0.0407,
        0.0631], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,795][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Jonathan] are: tensor([0.4990, 0.1661, 0.0287, 0.0747, 0.0504, 0.0276, 0.0223, 0.0126, 0.0335,
        0.0850], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,795][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Jonathan] are: tensor([0.4422, 0.1049, 0.0385, 0.0643, 0.0628, 0.0306, 0.0335, 0.0599, 0.0510,
        0.1123], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:38,796][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.7725, 0.0566, 0.0105, 0.0353, 0.0194, 0.0084, 0.0121, 0.0076, 0.0192,
        0.0497, 0.0087], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,796][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.4823, 0.0569, 0.0200, 0.0669, 0.0733, 0.0298, 0.0290, 0.0523, 0.0660,
        0.1034, 0.0201], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,797][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0473, 0.3795, 0.0394, 0.1290, 0.0391, 0.0375, 0.0489, 0.0357, 0.0421,
        0.1679, 0.0337], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,799][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0505, 0.3479, 0.0541, 0.1309, 0.0624, 0.0447, 0.0478, 0.0728, 0.0341,
        0.0892, 0.0656], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,800][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1057, 0.5513, 0.0248, 0.1046, 0.0456, 0.0332, 0.0196, 0.0176, 0.0145,
        0.0519, 0.0312], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,802][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0798, 0.0890, 0.0947, 0.0872, 0.0890, 0.0985, 0.0953, 0.0913, 0.0972,
        0.0897, 0.0883], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,803][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.1360, 0.2238, 0.0555, 0.0988, 0.0907, 0.1002, 0.0626, 0.0412, 0.0521,
        0.0839, 0.0553], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,805][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.4124, 0.3095, 0.0137, 0.1005, 0.0436, 0.0092, 0.0109, 0.0055, 0.0072,
        0.0757, 0.0118], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,807][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.2775, 0.3284, 0.0166, 0.1201, 0.0400, 0.0146, 0.0136, 0.0340, 0.0204,
        0.1223, 0.0125], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,808][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.7300, 0.1024, 0.0142, 0.0525, 0.0257, 0.0105, 0.0106, 0.0068, 0.0136,
        0.0302, 0.0035], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,809][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([9.2914e-01, 3.2438e-02, 6.6073e-04, 1.0771e-02, 4.2828e-03, 4.4555e-04,
        8.4380e-04, 2.8499e-04, 6.8837e-04, 2.0079e-02, 3.6990e-04],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,812][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.6547, 0.0905, 0.0157, 0.0387, 0.0301, 0.0072, 0.0086, 0.0157, 0.0138,
        0.1060, 0.0190], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:38,813][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.6442, 0.0580, 0.0252, 0.0365, 0.0386, 0.0177, 0.0229, 0.0167, 0.0335,
        0.0443, 0.0187, 0.0439], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,815][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.2862, 0.0733, 0.0448, 0.0775, 0.0611, 0.0309, 0.0398, 0.0731, 0.0618,
        0.1064, 0.0689, 0.0762], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,816][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0469, 0.3106, 0.0530, 0.1199, 0.0474, 0.0430, 0.0531, 0.0523, 0.0442,
        0.1210, 0.0533, 0.0553], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,816][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0566, 0.2372, 0.0607, 0.1186, 0.0741, 0.0494, 0.0503, 0.0708, 0.0406,
        0.0974, 0.0879, 0.0565], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,816][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0781, 0.3216, 0.0454, 0.1077, 0.0723, 0.0597, 0.0359, 0.0382, 0.0321,
        0.0684, 0.0894, 0.0510], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,817][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0724, 0.0811, 0.0871, 0.0793, 0.0810, 0.0907, 0.0875, 0.0839, 0.0897,
        0.0818, 0.0808, 0.0848], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,817][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0768, 0.1309, 0.0666, 0.0789, 0.0857, 0.1231, 0.0706, 0.0569, 0.0696,
        0.0704, 0.0880, 0.0826], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,818][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.2235, 0.2474, 0.0356, 0.0916, 0.0914, 0.0308, 0.0281, 0.0383, 0.0241,
        0.0755, 0.0650, 0.0488], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,818][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1655, 0.2483, 0.0461, 0.1081, 0.0570, 0.0282, 0.0304, 0.0549, 0.0369,
        0.1118, 0.0498, 0.0630], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,818][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.5295, 0.0923, 0.0299, 0.0649, 0.0534, 0.0234, 0.0251, 0.0253, 0.0336,
        0.0528, 0.0210, 0.0486], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,819][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.6954, 0.0795, 0.0089, 0.0378, 0.0289, 0.0092, 0.0116, 0.0064, 0.0144,
        0.0603, 0.0081, 0.0394], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,819][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3520, 0.1202, 0.0302, 0.0649, 0.0570, 0.0262, 0.0298, 0.0324, 0.0369,
        0.1326, 0.0275, 0.0905], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:38,821][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.6999, 0.0641, 0.0139, 0.0333, 0.0278, 0.0085, 0.0109, 0.0121, 0.0212,
        0.0410, 0.0117, 0.0334, 0.0222], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,823][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.5891, 0.0368, 0.0137, 0.0297, 0.0269, 0.0077, 0.0097, 0.0382, 0.0284,
        0.0787, 0.0379, 0.0500, 0.0532], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,824][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.0472, 0.3167, 0.0251, 0.1334, 0.0424, 0.0268, 0.0328, 0.0395, 0.0262,
        0.1533, 0.0414, 0.0583, 0.0569], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,826][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.0338, 0.2789, 0.0442, 0.1222, 0.0580, 0.0427, 0.0406, 0.0629, 0.0305,
        0.0808, 0.0797, 0.0567, 0.0691], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,826][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.0776, 0.3999, 0.0285, 0.1119, 0.0634, 0.0496, 0.0239, 0.0236, 0.0226,
        0.0532, 0.0688, 0.0516, 0.0254], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,828][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.0665, 0.0747, 0.0795, 0.0733, 0.0751, 0.0835, 0.0806, 0.0779, 0.0821,
        0.0761, 0.0748, 0.0780, 0.0778], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,830][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.0706, 0.1473, 0.0516, 0.0702, 0.0813, 0.1109, 0.0765, 0.0606, 0.0565,
        0.0606, 0.0662, 0.1045, 0.0433], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,832][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.3339, 0.2659, 0.0185, 0.0794, 0.0694, 0.0178, 0.0160, 0.0224, 0.0149,
        0.0637, 0.0356, 0.0392, 0.0233], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,833][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.2331, 0.2733, 0.0228, 0.1018, 0.0417, 0.0165, 0.0180, 0.0303, 0.0223,
        0.1176, 0.0281, 0.0561, 0.0384], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,835][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.6698, 0.0787, 0.0204, 0.0507, 0.0370, 0.0137, 0.0143, 0.0110, 0.0199,
        0.0360, 0.0089, 0.0292, 0.0105], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,836][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([8.9485e-01, 3.5388e-02, 1.4090e-03, 1.4568e-02, 8.0605e-03, 8.0416e-04,
        1.5975e-03, 6.1793e-04, 1.4282e-03, 2.8490e-02, 1.1227e-03, 1.1172e-02,
        4.9028e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,838][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.4013, 0.1443, 0.0230, 0.0498, 0.0282, 0.0069, 0.0135, 0.0409, 0.0180,
        0.1483, 0.0225, 0.0620, 0.0413], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:38,839][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.5087, 0.0710, 0.0287, 0.0564, 0.0371, 0.0212, 0.0318, 0.0168, 0.0456,
        0.0627, 0.0150, 0.0363, 0.0343, 0.0346], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,839][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1128, 0.0624, 0.0454, 0.0703, 0.0505, 0.0438, 0.0589, 0.0916, 0.0697,
        0.0999, 0.0621, 0.0661, 0.1047, 0.0617], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,840][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0846, 0.2670, 0.0366, 0.0888, 0.0463, 0.0301, 0.0430, 0.0364, 0.0336,
        0.1033, 0.0489, 0.0524, 0.0659, 0.0631], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,840][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0579, 0.2236, 0.0487, 0.1068, 0.0615, 0.0334, 0.0372, 0.0585, 0.0323,
        0.0863, 0.0780, 0.0471, 0.0693, 0.0593], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,841][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0917, 0.2948, 0.0375, 0.1046, 0.0541, 0.0417, 0.0292, 0.0251, 0.0254,
        0.0660, 0.0733, 0.0510, 0.0325, 0.0732], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,841][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0614, 0.0688, 0.0736, 0.0673, 0.0690, 0.0772, 0.0745, 0.0712, 0.0758,
        0.0698, 0.0688, 0.0719, 0.0714, 0.0794], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,841][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1115, 0.0959, 0.0560, 0.0606, 0.0810, 0.0819, 0.0668, 0.0237, 0.0530,
        0.0593, 0.0673, 0.0817, 0.0319, 0.1293], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,842][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.2453, 0.1873, 0.0308, 0.0838, 0.0751, 0.0268, 0.0271, 0.0208, 0.0295,
        0.0845, 0.0507, 0.0458, 0.0360, 0.0566], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,842][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1359, 0.2245, 0.0344, 0.1011, 0.0423, 0.0231, 0.0280, 0.0583, 0.0306,
        0.1082, 0.0387, 0.0607, 0.0648, 0.0495], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,843][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.4930, 0.0801, 0.0283, 0.0636, 0.0485, 0.0211, 0.0262, 0.0209, 0.0311,
        0.0501, 0.0189, 0.0503, 0.0337, 0.0344], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,845][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.8013, 0.0473, 0.0051, 0.0266, 0.0229, 0.0042, 0.0054, 0.0021, 0.0056,
        0.0378, 0.0032, 0.0208, 0.0015, 0.0162], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,847][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.3424, 0.0982, 0.0282, 0.0566, 0.0491, 0.0243, 0.0257, 0.0259, 0.0330,
        0.1241, 0.0249, 0.0704, 0.0363, 0.0610], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:38,848][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:16:38,850][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 6523],
        [41205],
        [ 6050],
        [10250],
        [ 7841],
        [ 1166],
        [ 2442],
        [27585],
        [ 2060],
        [17070],
        [ 7402],
        [ 6115],
        [25560],
        [ 3559]], device='cuda:0')
[2024-07-24 10:16:38,851][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 7252],
        [42511],
        [10499],
        [10692],
        [ 8347],
        [ 3333],
        [ 5170],
        [24934],
        [ 3714],
        [14423],
        [10917],
        [ 7464],
        [22514],
        [ 5911]], device='cuda:0')
[2024-07-24 10:16:38,853][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[6226],
        [7663],
        [8364],
        [8359],
        [8595],
        [8532],
        [8771],
        [9026],
        [8869],
        [8753],
        [8330],
        [8111],
        [8350],
        [8419]], device='cuda:0')
[2024-07-24 10:16:38,854][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[22205],
        [14115],
        [10657],
        [11119],
        [ 9926],
        [ 9685],
        [ 9404],
        [ 9517],
        [ 9642],
        [ 9977],
        [ 9909],
        [ 9916],
        [10157],
        [10235]], device='cuda:0')
[2024-07-24 10:16:38,856][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[10651],
        [12755],
        [12514],
        [12472],
        [12626],
        [12021],
        [11730],
        [12370],
        [12078],
        [12308],
        [12283],
        [12230],
        [12477],
        [12636]], device='cuda:0')
[2024-07-24 10:16:38,858][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 1417],
        [ 7764],
        [ 8410],
        [ 8250],
        [ 8175],
        [ 8207],
        [ 8630],
        [ 9215],
        [ 9979],
        [ 9676],
        [ 9557],
        [ 9806],
        [10073],
        [10185]], device='cuda:0')
[2024-07-24 10:16:38,859][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[16207],
        [39541],
        [45570],
        [45844],
        [46601],
        [46342],
        [46412],
        [46264],
        [46761],
        [46688],
        [46653],
        [47439],
        [47076],
        [46713]], device='cuda:0')
[2024-07-24 10:16:38,861][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[30527],
        [29816],
        [25292],
        [25991],
        [25333],
        [24383],
        [23666],
        [22875],
        [22199],
        [22447],
        [22534],
        [22000],
        [21623],
        [21254]], device='cuda:0')
[2024-07-24 10:16:38,862][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[45180],
        [45650],
        [45626],
        [46191],
        [45967],
        [46042],
        [46090],
        [46400],
        [46075],
        [46343],
        [46330],
        [46172],
        [46555],
        [46089]], device='cuda:0')
[2024-07-24 10:16:38,863][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 1167],
        [ 6476],
        [ 8492],
        [ 5101],
        [ 7553],
        [11001],
        [10266],
        [ 6463],
        [11189],
        [10179],
        [ 8377],
        [11399],
        [ 9979],
        [12481]], device='cuda:0')
[2024-07-24 10:16:38,864][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[40569],
        [37015],
        [ 6961],
        [19389],
        [11408],
        [ 3088],
        [ 3163],
        [11234],
        [ 3950],
        [ 4030],
        [13948],
        [ 4546],
        [10157],
        [ 4751]], device='cuda:0')
[2024-07-24 10:16:38,865][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[  727],
        [24545],
        [28576],
        [30386],
        [31392],
        [31876],
        [32248],
        [32945],
        [33690],
        [33656],
        [33927],
        [34073],
        [34282],
        [34599]], device='cuda:0')
[2024-07-24 10:16:38,866][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[31426],
        [33422],
        [33191],
        [33479],
        [34102],
        [34499],
        [35079],
        [34143],
        [34150],
        [33970],
        [33822],
        [33973],
        [33823],
        [33669]], device='cuda:0')
[2024-07-24 10:16:38,867][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[16329],
        [13815],
        [15684],
        [14408],
        [13870],
        [14401],
        [14074],
        [14703],
        [15337],
        [14298],
        [14041],
        [13556],
        [13443],
        [13668]], device='cuda:0')
[2024-07-24 10:16:38,868][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[43821],
        [32868],
        [ 4829],
        [34181],
        [28649],
        [ 6654],
        [20201],
        [44504],
        [10409],
        [42944],
        [22238],
        [32482],
        [47467],
        [19796]], device='cuda:0')
[2024-07-24 10:16:38,870][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[16224],
        [16345],
        [16357],
        [15221],
        [14392],
        [14729],
        [14925],
        [15087],
        [14034],
        [12563],
        [13057],
        [12812],
        [12718],
        [11963]], device='cuda:0')
[2024-07-24 10:16:38,872][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[26505],
        [30583],
        [35135],
        [35374],
        [38324],
        [38084],
        [36963],
        [33958],
        [41393],
        [41704],
        [39090],
        [41161],
        [39013],
        [42220]], device='cuda:0')
[2024-07-24 10:16:38,873][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 4826],
        [11667],
        [15858],
        [15833],
        [18161],
        [16705],
        [16112],
        [14844],
        [14392],
        [13495],
        [12563],
        [13033],
        [11367],
        [11612]], device='cuda:0')
[2024-07-24 10:16:38,874][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[16069],
        [18793],
        [28323],
        [25475],
        [31604],
        [32710],
        [35864],
        [39763],
        [41699],
        [42542],
        [42864],
        [45328],
        [44337],
        [45402]], device='cuda:0')
[2024-07-24 10:16:38,876][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[26335],
        [21300],
        [20989],
        [20418],
        [24536],
        [25118],
        [26336],
        [24557],
        [26124],
        [26723],
        [23149],
        [27333],
        [25967],
        [27835]], device='cuda:0')
[2024-07-24 10:16:38,877][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[25740],
        [22774],
        [21562],
        [21408],
        [21603],
        [21320],
        [21174],
        [21300],
        [21390],
        [21422],
        [21526],
        [21602],
        [21742],
        [21765]], device='cuda:0')
[2024-07-24 10:16:38,879][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[47133],
        [27946],
        [26756],
        [21064],
        [20998],
        [24969],
        [25047],
        [24307],
        [24875],
        [23064],
        [21310],
        [22587],
        [22948],
        [24521]], device='cuda:0')
[2024-07-24 10:16:38,880][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[28837],
        [38952],
        [36612],
        [33669],
        [26393],
        [22465],
        [22641],
        [25553],
        [17523],
        [17998],
        [24849],
        [14325],
        [17397],
        [14341]], device='cuda:0')
[2024-07-24 10:16:38,882][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[38977],
        [40699],
        [36937],
        [36396],
        [35944],
        [35749],
        [35392],
        [35669],
        [35769],
        [36362],
        [35795],
        [34580],
        [35257],
        [35235]], device='cuda:0')
[2024-07-24 10:16:38,884][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[40924],
        [40546],
        [40518],
        [40590],
        [40695],
        [40554],
        [40588],
        [40496],
        [40701],
        [42056],
        [40584],
        [41342],
        [40790],
        [41741]], device='cuda:0')
[2024-07-24 10:16:38,885][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[18267],
        [21181],
        [19529],
        [22177],
        [24316],
        [19080],
        [19187],
        [18450],
        [19286],
        [35540],
        [20741],
        [32901],
        [22760],
        [28031]], device='cuda:0')
[2024-07-24 10:16:38,887][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[27929],
        [32367],
        [32266],
        [32962],
        [31792],
        [32124],
        [32432],
        [34442],
        [30172],
        [28116],
        [33616],
        [28350],
        [29876],
        [25310]], device='cuda:0')
[2024-07-24 10:16:38,888][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 7571],
        [ 8582],
        [ 9279],
        [11381],
        [11232],
        [11475],
        [10741],
        [10291],
        [11548],
        [10388],
        [11187],
        [10889],
        [11413],
        [11763]], device='cuda:0')
[2024-07-24 10:16:38,889][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 5078],
        [ 7407],
        [10599],
        [ 6944],
        [ 7580],
        [10045],
        [ 7772],
        [ 3522],
        [ 7517],
        [ 3144],
        [ 5834],
        [ 6884],
        [ 3367],
        [ 6031]], device='cuda:0')
[2024-07-24 10:16:38,890][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[22483],
        [22483],
        [22483],
        [22483],
        [22483],
        [22483],
        [22483],
        [22483],
        [22483],
        [22483],
        [22483],
        [22483],
        [22483],
        [22483]], device='cuda:0')
[2024-07-24 10:16:38,927][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:38,929][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,930][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,931][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,932][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,933][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,933][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,934][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,934][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,934][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,934][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,935][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,935][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:38,935][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.5650, 0.4350], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,936][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.7679, 0.2321], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,936][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.9569, 0.0431], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,936][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.5991, 0.4009], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,937][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.5651, 0.4349], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,937][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.3331, 0.6669], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,939][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.7698, 0.2302], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,940][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.4351, 0.5649], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,942][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.7958, 0.2042], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,943][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.1109, 0.8891], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,944][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.1821, 0.8179], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,946][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.3192, 0.6808], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:38,948][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.8860, 0.0981, 0.0159], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,949][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.9340, 0.0555, 0.0105], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,951][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.8988, 0.0555, 0.0457], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,953][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.4884, 0.2596, 0.2520], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,954][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4246, 0.3039, 0.2715], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,956][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1609, 0.4920, 0.3470], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,956][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6441, 0.1681, 0.1878], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,956][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2908, 0.5856, 0.1237], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,957][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.5232, 0.4381, 0.0387], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,957][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0423, 0.2402, 0.7175], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,957][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1331, 0.4206, 0.4463], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,958][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1445, 0.7905, 0.0650], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:38,958][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Jonathan] are: tensor([0.6863, 0.2144, 0.0692, 0.0301], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,958][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Jonathan] are: tensor([0.3519, 0.1886, 0.3710, 0.0885], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,959][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Jonathan] are: tensor([0.8470, 0.0481, 0.0503, 0.0546], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,959][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Jonathan] are: tensor([0.2025, 0.2732, 0.3001, 0.2242], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,959][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Jonathan] are: tensor([0.3129, 0.2381, 0.2191, 0.2299], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,960][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Jonathan] are: tensor([0.1456, 0.3380, 0.2526, 0.2637], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,962][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Jonathan] are: tensor([0.5182, 0.1377, 0.1541, 0.1899], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,963][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Jonathan] are: tensor([0.2652, 0.4257, 0.1068, 0.2022], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,965][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Jonathan] are: tensor([0.4811, 0.3955, 0.0541, 0.0694], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,966][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Jonathan] are: tensor([0.0452, 0.1900, 0.5359, 0.2289], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,967][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Jonathan] are: tensor([0.0991, 0.2249, 0.2791, 0.3969], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,969][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Jonathan] are: tensor([0.1085, 0.5749, 0.0688, 0.2478], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:38,971][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.7687, 0.1483, 0.0460, 0.0214, 0.0157], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,972][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.6009, 0.0968, 0.1578, 0.0733, 0.0711], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,974][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.6274, 0.0720, 0.0837, 0.0782, 0.1387], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,976][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.2455, 0.1669, 0.2083, 0.1986, 0.1807], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,977][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.2635, 0.1920, 0.1771, 0.1877, 0.1797], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,979][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0993, 0.2761, 0.2065, 0.2205, 0.1975], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,979][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.4484, 0.1140, 0.1264, 0.1532, 0.1580], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,979][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.1680, 0.3731, 0.1358, 0.2168, 0.1063], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,980][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.4424, 0.3394, 0.0694, 0.0848, 0.0640], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,980][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.0193, 0.1349, 0.5097, 0.1858, 0.1503], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,980][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0733, 0.2062, 0.2173, 0.3176, 0.1856], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,981][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.1127, 0.4447, 0.0933, 0.2548, 0.0944], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:38,981][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.8975, 0.0714, 0.0158, 0.0076, 0.0047, 0.0030], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,981][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.7516, 0.0868, 0.0281, 0.0610, 0.0573, 0.0152], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,982][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.6034, 0.0512, 0.0647, 0.0616, 0.1287, 0.0903], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,982][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.2156, 0.1390, 0.1274, 0.1595, 0.1721, 0.1863], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,983][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.2477, 0.1659, 0.1483, 0.1609, 0.1501, 0.1270], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,984][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0733, 0.2475, 0.1803, 0.1966, 0.1752, 0.1273], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,985][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.4066, 0.0987, 0.1065, 0.1267, 0.1334, 0.1281], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,987][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.2151, 0.3353, 0.0938, 0.1794, 0.0944, 0.0820], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,988][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.5225, 0.2757, 0.0479, 0.0698, 0.0646, 0.0196], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,990][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0189, 0.1069, 0.4533, 0.1303, 0.0878, 0.2027], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,991][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0451, 0.1464, 0.1345, 0.2219, 0.1266, 0.3255], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,993][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1087, 0.4045, 0.0810, 0.2346, 0.1050, 0.0662], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:38,995][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.8846, 0.0765, 0.0177, 0.0088, 0.0051, 0.0032, 0.0040],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,996][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.6415, 0.0362, 0.0415, 0.0476, 0.0858, 0.0324, 0.1150],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:38,998][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.5713, 0.0548, 0.0557, 0.0550, 0.1032, 0.0613, 0.0987],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,000][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1412, 0.1058, 0.1319, 0.1464, 0.1936, 0.1896, 0.0916],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,001][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2032, 0.1445, 0.1324, 0.1420, 0.1332, 0.1159, 0.1289],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,002][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0638, 0.2240, 0.1594, 0.1779, 0.1555, 0.1122, 0.1072],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,002][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.3895, 0.0888, 0.0927, 0.1082, 0.1141, 0.1091, 0.0976],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,003][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1373, 0.2942, 0.1021, 0.1855, 0.0962, 0.0987, 0.0861],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,003][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.3687, 0.3576, 0.0613, 0.0913, 0.0708, 0.0318, 0.0185],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,003][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0287, 0.1319, 0.3286, 0.1152, 0.0669, 0.1241, 0.2047],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,004][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0284, 0.0840, 0.0888, 0.1585, 0.0849, 0.2441, 0.3112],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,004][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0766, 0.3585, 0.0858, 0.2345, 0.1075, 0.0841, 0.0530],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,004][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.7926, 0.1197, 0.0324, 0.0133, 0.0093, 0.0062, 0.0090, 0.0176],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,005][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([0.4127, 0.0385, 0.0640, 0.0460, 0.1973, 0.0218, 0.0599, 0.1598],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,005][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.5979, 0.0499, 0.0426, 0.0402, 0.0848, 0.0477, 0.0719, 0.0652],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,005][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.0764, 0.1056, 0.1591, 0.0886, 0.1370, 0.1930, 0.1093, 0.1310],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,006][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.1985, 0.1320, 0.1197, 0.1275, 0.1187, 0.0980, 0.1129, 0.0926],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,008][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.0689, 0.1833, 0.1405, 0.1463, 0.1336, 0.0996, 0.0971, 0.1306],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,010][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.3094, 0.0853, 0.0844, 0.1042, 0.1037, 0.0999, 0.0865, 0.1266],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,011][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.1394, 0.3467, 0.0602, 0.1835, 0.0805, 0.0748, 0.0778, 0.0372],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,013][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.3215, 0.3874, 0.0436, 0.0914, 0.0668, 0.0413, 0.0239, 0.0241],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,014][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.0105, 0.0971, 0.2979, 0.1018, 0.0442, 0.0869, 0.0907, 0.2709],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,016][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.0364, 0.0912, 0.1028, 0.1507, 0.0825, 0.2115, 0.2237, 0.1012],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,018][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.0656, 0.4446, 0.0548, 0.2124, 0.0825, 0.0590, 0.0396, 0.0416],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,019][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9458, 0.0363, 0.0058, 0.0035, 0.0021, 0.0011, 0.0013, 0.0027, 0.0013],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,021][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.6222, 0.0247, 0.0099, 0.0286, 0.0551, 0.0090, 0.0562, 0.1874, 0.0069],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,023][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2315, 0.0563, 0.0685, 0.0612, 0.1025, 0.0830, 0.1176, 0.1058, 0.1736],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,024][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1304, 0.0574, 0.0651, 0.0880, 0.1174, 0.1193, 0.0621, 0.2449, 0.1154],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,025][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1761, 0.1177, 0.1068, 0.1141, 0.1071, 0.0934, 0.1042, 0.0875, 0.0932],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,025][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0512, 0.1666, 0.1347, 0.1457, 0.1263, 0.0899, 0.0866, 0.1217, 0.0772],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,025][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2669, 0.0786, 0.0817, 0.0933, 0.0939, 0.0932, 0.0834, 0.1051, 0.1038],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,026][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1417, 0.2902, 0.0616, 0.1931, 0.0903, 0.0665, 0.0664, 0.0431, 0.0472],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,026][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3335, 0.3566, 0.0495, 0.0941, 0.0623, 0.0275, 0.0208, 0.0245, 0.0312],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,027][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0086, 0.0520, 0.2029, 0.0769, 0.0475, 0.0874, 0.1289, 0.2983, 0.0975],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,027][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0409, 0.0851, 0.0772, 0.1255, 0.0802, 0.1860, 0.2181, 0.1017, 0.0852],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,027][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0696, 0.3208, 0.0715, 0.2186, 0.0904, 0.0664, 0.0540, 0.0603, 0.0486],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,028][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Jonathan] are: tensor([0.8268, 0.1032, 0.0259, 0.0088, 0.0058, 0.0039, 0.0056, 0.0104, 0.0083,
        0.0013], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,028][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Jonathan] are: tensor([0.0888, 0.0352, 0.1190, 0.0205, 0.0264, 0.0450, 0.0971, 0.4609, 0.0696,
        0.0375], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,029][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Jonathan] are: tensor([0.3214, 0.0518, 0.0537, 0.0456, 0.0858, 0.0505, 0.0727, 0.0780, 0.1466,
        0.0940], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,031][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Jonathan] are: tensor([0.0499, 0.0909, 0.0969, 0.0718, 0.1066, 0.1086, 0.0738, 0.1233, 0.1822,
        0.0958], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,033][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Jonathan] are: tensor([0.1405, 0.1072, 0.1003, 0.1055, 0.0997, 0.0876, 0.0957, 0.0808, 0.0860,
        0.0966], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,034][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Jonathan] are: tensor([0.0720, 0.1399, 0.1128, 0.1134, 0.1038, 0.0834, 0.0803, 0.1089, 0.0728,
        0.1128], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,035][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Jonathan] are: tensor([0.2345, 0.0717, 0.0730, 0.0872, 0.0880, 0.0832, 0.0742, 0.0916, 0.0928,
        0.1039], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,037][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Jonathan] are: tensor([0.0582, 0.2386, 0.0787, 0.1397, 0.0866, 0.0796, 0.0846, 0.0814, 0.0634,
        0.0891], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,039][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Jonathan] are: tensor([0.1566, 0.4211, 0.0715, 0.0943, 0.0650, 0.0387, 0.0295, 0.0379, 0.0364,
        0.0491], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,040][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Jonathan] are: tensor([0.0039, 0.0461, 0.2547, 0.0531, 0.0510, 0.0863, 0.1222, 0.2660, 0.0897,
        0.0270], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,042][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Jonathan] are: tensor([0.0256, 0.0624, 0.0729, 0.1268, 0.0627, 0.1754, 0.1901, 0.0562, 0.0601,
        0.1679], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,044][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Jonathan] are: tensor([0.0337, 0.3512, 0.0707, 0.1970, 0.0843, 0.0628, 0.0529, 0.0521, 0.0360,
        0.0592], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,045][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([8.9819e-01, 6.3091e-02, 1.3501e-02, 5.2821e-03, 3.3514e-03, 1.9472e-03,
        2.7428e-03, 5.3529e-03, 3.7506e-03, 6.9271e-04, 2.0962e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,047][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.2471, 0.0584, 0.0302, 0.0288, 0.0306, 0.0150, 0.0927, 0.3765, 0.0368,
        0.0482, 0.0358], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,048][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.3933, 0.0354, 0.0345, 0.0327, 0.0662, 0.0391, 0.0625, 0.0562, 0.1168,
        0.0878, 0.0755], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,048][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0593, 0.0700, 0.0786, 0.0651, 0.0958, 0.0923, 0.0601, 0.1501, 0.1411,
        0.1038, 0.0839], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,048][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1453, 0.0983, 0.0901, 0.0973, 0.0905, 0.0758, 0.0859, 0.0707, 0.0777,
        0.0898, 0.0785], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,049][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0522, 0.1304, 0.1028, 0.1083, 0.0983, 0.0742, 0.0712, 0.0983, 0.0653,
        0.1089, 0.0900], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,049][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.2492, 0.0643, 0.0650, 0.0782, 0.0788, 0.0718, 0.0634, 0.0877, 0.0791,
        0.0850, 0.0775], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,050][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.1102, 0.3225, 0.0445, 0.1530, 0.0597, 0.0502, 0.0476, 0.0324, 0.0328,
        0.0940, 0.0531], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,050][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.2791, 0.4062, 0.0357, 0.0772, 0.0552, 0.0214, 0.0154, 0.0146, 0.0220,
        0.0483, 0.0249], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,050][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0156, 0.0981, 0.1487, 0.1085, 0.0682, 0.1101, 0.1127, 0.1437, 0.0964,
        0.0589, 0.0391], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,051][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0189, 0.0574, 0.0535, 0.1031, 0.0603, 0.1470, 0.1586, 0.0649, 0.0575,
        0.1731, 0.1056], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,051][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0492, 0.4602, 0.0408, 0.1855, 0.0582, 0.0428, 0.0300, 0.0260, 0.0195,
        0.0478, 0.0399], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,052][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([9.4560e-01, 3.8237e-02, 6.5082e-03, 2.2668e-03, 1.3249e-03, 6.8823e-04,
        9.9952e-04, 1.7336e-03, 1.3997e-03, 2.1379e-04, 7.5015e-04, 2.7407e-04],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,054][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.2392, 0.0462, 0.0373, 0.0179, 0.0693, 0.0301, 0.1388, 0.2555, 0.0491,
        0.0399, 0.0635, 0.0131], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,055][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.3125, 0.0400, 0.0374, 0.0332, 0.0692, 0.0427, 0.0646, 0.0590, 0.1105,
        0.0789, 0.0793, 0.0728], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,057][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0808, 0.0433, 0.0519, 0.0633, 0.0825, 0.0895, 0.0447, 0.1972, 0.0947,
        0.1282, 0.0875, 0.0363], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,058][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1223, 0.0890, 0.0827, 0.0877, 0.0828, 0.0740, 0.0806, 0.0683, 0.0729,
        0.0828, 0.0750, 0.0820], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,060][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0463, 0.1196, 0.0959, 0.0997, 0.0912, 0.0694, 0.0667, 0.0912, 0.0617,
        0.1033, 0.0826, 0.0725], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,062][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2248, 0.0645, 0.0591, 0.0685, 0.0698, 0.0660, 0.0601, 0.0781, 0.0746,
        0.0842, 0.0680, 0.0822], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,063][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0669, 0.2039, 0.0659, 0.1301, 0.0686, 0.0687, 0.0658, 0.0509, 0.0515,
        0.0860, 0.0831, 0.0585], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,065][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1440, 0.3391, 0.0635, 0.0958, 0.0674, 0.0407, 0.0263, 0.0278, 0.0340,
        0.0549, 0.0586, 0.0478], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,067][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0058, 0.0675, 0.2565, 0.0711, 0.0434, 0.0841, 0.1116, 0.1493, 0.0609,
        0.0348, 0.0771, 0.0379], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,069][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0131, 0.0478, 0.0475, 0.0886, 0.0444, 0.1218, 0.1598, 0.0531, 0.0411,
        0.1296, 0.0709, 0.1824], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,070][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0459, 0.2555, 0.0729, 0.1587, 0.0810, 0.0696, 0.0471, 0.0459, 0.0361,
        0.0650, 0.0828, 0.0395], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,071][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([8.7598e-01, 7.6292e-02, 1.4150e-02, 5.6654e-03, 3.9893e-03, 2.2373e-03,
        3.4596e-03, 6.0671e-03, 4.2741e-03, 8.4205e-04, 2.5143e-03, 1.2151e-03,
        3.3119e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,071][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.1381, 0.0257, 0.0562, 0.0127, 0.0977, 0.0290, 0.0648, 0.2792, 0.0491,
        0.0219, 0.1082, 0.0358, 0.0816], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,072][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.1939, 0.0406, 0.0497, 0.0392, 0.0625, 0.0502, 0.0629, 0.0607, 0.1023,
        0.0840, 0.0826, 0.0780, 0.0934], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,072][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0589, 0.0517, 0.0583, 0.0442, 0.0857, 0.0719, 0.0475, 0.0877, 0.1382,
        0.0618, 0.0699, 0.0751, 0.1492], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,072][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.1160, 0.0844, 0.0777, 0.0827, 0.0782, 0.0671, 0.0752, 0.0634, 0.0664,
        0.0764, 0.0697, 0.0770, 0.0659], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,073][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.0464, 0.1110, 0.0864, 0.0879, 0.0807, 0.0636, 0.0619, 0.0859, 0.0607,
        0.0973, 0.0778, 0.0699, 0.0705], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,073][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.1782, 0.0597, 0.0550, 0.0681, 0.0671, 0.0642, 0.0561, 0.0748, 0.0676,
        0.0759, 0.0689, 0.0741, 0.0902], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,074][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.0581, 0.2080, 0.0533, 0.1507, 0.0610, 0.0555, 0.0590, 0.0417, 0.0416,
        0.0896, 0.0957, 0.0495, 0.0363], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,074][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.1485, 0.4092, 0.0390, 0.0886, 0.0523, 0.0306, 0.0185, 0.0288, 0.0262,
        0.0504, 0.0467, 0.0431, 0.0182], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,075][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.0119, 0.0908, 0.1935, 0.0885, 0.0389, 0.0707, 0.0738, 0.1276, 0.0628,
        0.0589, 0.0853, 0.0366, 0.0606], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,077][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.0282, 0.0641, 0.0645, 0.0945, 0.0494, 0.1208, 0.1295, 0.0518, 0.0476,
        0.0938, 0.0794, 0.1128, 0.0635], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,078][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0271, 0.3434, 0.0428, 0.2128, 0.0725, 0.0485, 0.0333, 0.0316, 0.0182,
        0.0540, 0.0602, 0.0327, 0.0230], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,079][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.3115e-01, 4.3674e-02, 7.8851e-03, 3.2595e-03, 1.9262e-03, 1.1404e-03,
        1.5195e-03, 2.4815e-03, 2.1083e-03, 3.8354e-04, 1.1159e-03, 5.1169e-04,
        1.5590e-03, 1.2834e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,081][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.2366, 0.0322, 0.0132, 0.0265, 0.0398, 0.0091, 0.0966, 0.2243, 0.0227,
        0.0711, 0.0549, 0.0253, 0.1387, 0.0091], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,083][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1296, 0.0407, 0.0468, 0.0359, 0.0585, 0.0507, 0.0676, 0.0611, 0.1039,
        0.0728, 0.0819, 0.0765, 0.0922, 0.0818], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,085][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0605, 0.0370, 0.0421, 0.0427, 0.0568, 0.0663, 0.0399, 0.1294, 0.0850,
        0.0754, 0.0534, 0.0465, 0.1763, 0.0887], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,086][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1096, 0.0785, 0.0708, 0.0765, 0.0714, 0.0629, 0.0690, 0.0605, 0.0622,
        0.0715, 0.0648, 0.0709, 0.0632, 0.0682], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,088][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0337, 0.1069, 0.0867, 0.0932, 0.0804, 0.0608, 0.0578, 0.0817, 0.0545,
        0.0984, 0.0721, 0.0619, 0.0654, 0.0465], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,090][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1631, 0.0537, 0.0504, 0.0611, 0.0613, 0.0588, 0.0512, 0.0648, 0.0647,
        0.0727, 0.0604, 0.0690, 0.0824, 0.0863], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,091][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0731, 0.1667, 0.0557, 0.1129, 0.0665, 0.0571, 0.0588, 0.0415, 0.0464,
        0.0770, 0.0902, 0.0526, 0.0414, 0.0602], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,093][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2335, 0.2353, 0.0528, 0.0680, 0.0605, 0.0331, 0.0214, 0.0236, 0.0327,
        0.0521, 0.0546, 0.0476, 0.0204, 0.0645], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,093][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0033, 0.0375, 0.2445, 0.0467, 0.0295, 0.0764, 0.1110, 0.1568, 0.0594,
        0.0249, 0.0854, 0.0286, 0.0645, 0.0314], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,094][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0252, 0.0619, 0.0497, 0.0753, 0.0428, 0.0982, 0.1188, 0.0517, 0.0410,
        0.0963, 0.0685, 0.1208, 0.0701, 0.0798], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,094][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0516, 0.2299, 0.0526, 0.1562, 0.0718, 0.0526, 0.0418, 0.0394, 0.0345,
        0.0666, 0.0707, 0.0419, 0.0402, 0.0502], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,139][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:39,141][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,142][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,142][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,143][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,143][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,143][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,144][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,144][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,144][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,144][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,145][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,145][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,145][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.6596, 0.3404], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,146][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.2900, 0.7100], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,147][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.6890, 0.3110], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,148][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.8499, 0.1501], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,150][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.7740, 0.2260], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,151][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.4709, 0.5291], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,153][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.9585, 0.0415], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,154][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.4351, 0.5649], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,156][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.7958, 0.2042], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,158][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.1109, 0.8891], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,159][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.8203, 0.1797], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,161][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.3192, 0.6808], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,163][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.5166, 0.4585, 0.0249], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,164][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0928, 0.7566, 0.1506], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,165][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4483, 0.2668, 0.2849], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,165][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.8043, 0.1572, 0.0386], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,165][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.9015, 0.0931, 0.0054], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,166][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2044, 0.6877, 0.1079], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,166][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.9596, 0.0279, 0.0125], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,166][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2908, 0.5856, 0.1237], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,167][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.5232, 0.4381, 0.0387], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,167][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0423, 0.2402, 0.7175], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,167][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.7778, 0.1262, 0.0960], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,168][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1445, 0.7905, 0.0650], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,168][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Jonathan] are: tensor([0.3368, 0.4838, 0.0617, 0.1178], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,169][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Jonathan] are: tensor([0.1146, 0.5524, 0.0598, 0.2732], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,170][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Jonathan] are: tensor([0.3760, 0.2047, 0.2593, 0.1601], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,172][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Jonathan] are: tensor([0.7244, 0.1562, 0.0484, 0.0710], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,174][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Jonathan] are: tensor([0.5701, 0.2614, 0.0620, 0.1065], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,175][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Jonathan] are: tensor([0.2489, 0.4498, 0.1024, 0.1990], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,177][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Jonathan] are: tensor([0.8781, 0.0382, 0.0138, 0.0698], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,178][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Jonathan] are: tensor([0.2652, 0.4257, 0.1068, 0.2022], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,180][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Jonathan] are: tensor([0.4811, 0.3955, 0.0541, 0.0694], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,181][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Jonathan] are: tensor([0.0452, 0.1900, 0.5359, 0.2289], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,183][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Jonathan] are: tensor([0.6514, 0.1390, 0.0877, 0.1218], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,185][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Jonathan] are: tensor([0.1085, 0.5749, 0.0688, 0.2478], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,187][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.2968, 0.4114, 0.0722, 0.1370, 0.0825], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,188][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.1289, 0.4352, 0.1132, 0.2438, 0.0790], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,188][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.2800, 0.1877, 0.2186, 0.1820, 0.1316], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,188][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.4988, 0.1791, 0.1098, 0.1028, 0.1095], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,189][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.6667, 0.1591, 0.0373, 0.0619, 0.0750], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,189][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.1551, 0.3811, 0.1414, 0.2168, 0.1056], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,189][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.8536, 0.0387, 0.0138, 0.0511, 0.0428], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,190][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.1680, 0.3731, 0.1358, 0.2168, 0.1063], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,190][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.4424, 0.3394, 0.0694, 0.0848, 0.0640], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,190][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.0193, 0.1349, 0.5097, 0.1858, 0.1503], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,191][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.4410, 0.1472, 0.1523, 0.1273, 0.1322], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,191][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.1127, 0.4447, 0.0933, 0.2548, 0.0944], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,192][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.4257, 0.3163, 0.0401, 0.1192, 0.0736, 0.0251], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,194][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1634, 0.3496, 0.1175, 0.2000, 0.0719, 0.0976], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,195][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2341, 0.1251, 0.2023, 0.1194, 0.1086, 0.2104], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,197][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.5506, 0.1622, 0.0632, 0.0748, 0.0864, 0.0628], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,198][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.8209, 0.0848, 0.0078, 0.0401, 0.0387, 0.0076], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,200][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1548, 0.3953, 0.0995, 0.1797, 0.0818, 0.0889], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,202][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.9008, 0.0221, 0.0085, 0.0301, 0.0220, 0.0165], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,203][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.2151, 0.3353, 0.0938, 0.1794, 0.0944, 0.0820], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,204][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.5225, 0.2757, 0.0479, 0.0698, 0.0646, 0.0196], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,206][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0189, 0.1069, 0.4533, 0.1303, 0.0878, 0.2027], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,208][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.6255, 0.0809, 0.0597, 0.0698, 0.0620, 0.1021], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,210][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1087, 0.4045, 0.0810, 0.2346, 0.1050, 0.0662], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,211][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.3302, 0.3540, 0.0445, 0.1289, 0.0813, 0.0328, 0.0284],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,211][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1416, 0.3650, 0.1030, 0.1807, 0.0665, 0.0933, 0.0497],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,211][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.2188, 0.1130, 0.1416, 0.1019, 0.0926, 0.1464, 0.1857],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,212][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.3849, 0.1922, 0.0744, 0.0959, 0.0933, 0.0817, 0.0776],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,212][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.8199, 0.0742, 0.0093, 0.0368, 0.0334, 0.0086, 0.0178],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,213][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1245, 0.3612, 0.0970, 0.1730, 0.0760, 0.0913, 0.0771],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,213][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.9016, 0.0205, 0.0071, 0.0253, 0.0171, 0.0113, 0.0171],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,213][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1373, 0.2942, 0.1021, 0.1855, 0.0962, 0.0987, 0.0861],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,214][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.3687, 0.3576, 0.0613, 0.0913, 0.0708, 0.0318, 0.0185],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,214][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0287, 0.1319, 0.3286, 0.1152, 0.0669, 0.1241, 0.2047],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,214][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.5649, 0.0726, 0.0430, 0.0655, 0.0505, 0.0750, 0.1285],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,216][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0766, 0.3585, 0.0858, 0.2345, 0.1075, 0.0841, 0.0530],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,218][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.3961, 0.3600, 0.0269, 0.0912, 0.0655, 0.0280, 0.0237, 0.0086],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,219][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([0.0770, 0.4515, 0.0768, 0.1741, 0.0441, 0.0784, 0.0459, 0.0522],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,221][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([0.3325, 0.0998, 0.0920, 0.0819, 0.0681, 0.1028, 0.1463, 0.0766],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,223][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.4436, 0.2351, 0.0534, 0.0725, 0.0732, 0.0439, 0.0459, 0.0324],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,225][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.8976, 0.0596, 0.0012, 0.0208, 0.0122, 0.0019, 0.0040, 0.0027],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,226][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.1443, 0.3417, 0.0801, 0.1491, 0.0654, 0.0860, 0.0664, 0.0670],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,228][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.9259, 0.0197, 0.0026, 0.0175, 0.0132, 0.0053, 0.0073, 0.0085],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,229][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.1394, 0.3467, 0.0602, 0.1835, 0.0805, 0.0748, 0.0778, 0.0372],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,231][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.3215, 0.3874, 0.0436, 0.0914, 0.0668, 0.0413, 0.0239, 0.0241],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,232][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.0105, 0.0971, 0.2979, 0.1018, 0.0442, 0.0869, 0.0907, 0.2709],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,234][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.6902, 0.0524, 0.0227, 0.0484, 0.0378, 0.0341, 0.0635, 0.0509],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,236][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.0656, 0.4446, 0.0548, 0.2124, 0.0825, 0.0590, 0.0396, 0.0416],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,238][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3661, 0.3046, 0.0319, 0.1299, 0.0784, 0.0254, 0.0270, 0.0163, 0.0204],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,239][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0665, 0.2469, 0.0981, 0.1907, 0.0721, 0.1114, 0.0608, 0.0774, 0.0760],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,239][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1334, 0.0719, 0.1101, 0.0647, 0.0644, 0.1167, 0.1465, 0.1204, 0.1719],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,240][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3066, 0.1650, 0.0640, 0.0911, 0.1007, 0.0699, 0.0671, 0.0555, 0.0801],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,240][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.8084, 0.0822, 0.0054, 0.0348, 0.0284, 0.0056, 0.0110, 0.0087, 0.0155],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,241][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0990, 0.3164, 0.0807, 0.1546, 0.0683, 0.0723, 0.0641, 0.0780, 0.0666],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,241][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.7487, 0.0372, 0.0145, 0.0413, 0.0307, 0.0210, 0.0226, 0.0211, 0.0629],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,241][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1417, 0.2902, 0.0616, 0.1931, 0.0903, 0.0665, 0.0664, 0.0431, 0.0472],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,242][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3335, 0.3566, 0.0495, 0.0941, 0.0623, 0.0275, 0.0208, 0.0245, 0.0312],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,242][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0086, 0.0520, 0.2029, 0.0769, 0.0475, 0.0874, 0.1289, 0.2983, 0.0975],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,243][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.3424, 0.0708, 0.0495, 0.0642, 0.0593, 0.0904, 0.1259, 0.0778, 0.1197],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,243][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0696, 0.3208, 0.0715, 0.2186, 0.0904, 0.0664, 0.0540, 0.0603, 0.0486],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,245][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Jonathan] are: tensor([0.1424, 0.3797, 0.0643, 0.1147, 0.0779, 0.0420, 0.0356, 0.0358, 0.0364,
        0.0712], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,247][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Jonathan] are: tensor([0.0325, 0.3244, 0.0861, 0.1941, 0.0524, 0.0700, 0.0529, 0.0648, 0.0472,
        0.0757], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,248][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Jonathan] are: tensor([0.0936, 0.0772, 0.1207, 0.0602, 0.0586, 0.1038, 0.1162, 0.1217, 0.1559,
        0.0922], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,250][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Jonathan] are: tensor([0.1891, 0.1520, 0.0680, 0.0890, 0.0919, 0.0799, 0.0757, 0.0764, 0.0826,
        0.0953], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,252][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Jonathan] are: tensor([0.2440, 0.1557, 0.0627, 0.0969, 0.0753, 0.0665, 0.0696, 0.0593, 0.0857,
        0.0843], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,253][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Jonathan] are: tensor([0.0546, 0.2643, 0.0862, 0.1410, 0.0707, 0.0767, 0.0657, 0.1038, 0.0597,
        0.0772], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,255][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Jonathan] are: tensor([0.4586, 0.0600, 0.0260, 0.0790, 0.0489, 0.0376, 0.0416, 0.0345, 0.0720,
        0.1417], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,256][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Jonathan] are: tensor([0.0582, 0.2386, 0.0787, 0.1397, 0.0866, 0.0796, 0.0846, 0.0814, 0.0634,
        0.0891], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,259][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Jonathan] are: tensor([0.1566, 0.4211, 0.0715, 0.0943, 0.0650, 0.0387, 0.0295, 0.0379, 0.0364,
        0.0491], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,260][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Jonathan] are: tensor([0.0039, 0.0461, 0.2547, 0.0531, 0.0510, 0.0863, 0.1222, 0.2660, 0.0897,
        0.0270], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,261][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Jonathan] are: tensor([0.1568, 0.0830, 0.0538, 0.0790, 0.0504, 0.0813, 0.1284, 0.1139, 0.1044,
        0.1490], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,262][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Jonathan] are: tensor([0.0337, 0.3512, 0.0707, 0.1970, 0.0843, 0.0628, 0.0529, 0.0521, 0.0360,
        0.0592], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,262][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.2345, 0.4034, 0.0305, 0.1002, 0.0560, 0.0345, 0.0228, 0.0131, 0.0168,
        0.0640, 0.0243], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,263][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.1089, 0.3825, 0.0503, 0.1381, 0.0379, 0.0405, 0.0332, 0.0305, 0.0356,
        0.0997, 0.0428], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,263][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.1442, 0.0708, 0.0688, 0.0576, 0.0497, 0.0842, 0.1167, 0.0765, 0.1584,
        0.1023, 0.0708], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,264][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.3891, 0.1609, 0.0382, 0.0675, 0.0594, 0.0445, 0.0482, 0.0277, 0.0569,
        0.0853, 0.0223], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,264][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.7803, 0.0761, 0.0035, 0.0329, 0.0195, 0.0041, 0.0067, 0.0051, 0.0103,
        0.0583, 0.0033], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,265][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.1024, 0.3292, 0.0613, 0.1118, 0.0448, 0.0566, 0.0455, 0.0663, 0.0523,
        0.0660, 0.0639], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,265][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.8264, 0.0212, 0.0037, 0.0192, 0.0151, 0.0054, 0.0083, 0.0066, 0.0187,
        0.0665, 0.0089], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,265][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.1102, 0.3225, 0.0445, 0.1530, 0.0597, 0.0502, 0.0476, 0.0324, 0.0328,
        0.0940, 0.0531], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,266][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.2791, 0.4062, 0.0357, 0.0772, 0.0552, 0.0214, 0.0154, 0.0146, 0.0220,
        0.0483, 0.0249], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,267][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0156, 0.0981, 0.1487, 0.1085, 0.0682, 0.1101, 0.1127, 0.1437, 0.0964,
        0.0589, 0.0391], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,269][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.3787, 0.0428, 0.0244, 0.0379, 0.0418, 0.0409, 0.0706, 0.0815, 0.0776,
        0.1147, 0.0891], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,271][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0492, 0.4602, 0.0408, 0.1855, 0.0582, 0.0428, 0.0300, 0.0260, 0.0195,
        0.0478, 0.0399], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,272][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1780, 0.2681, 0.0548, 0.1105, 0.0788, 0.0423, 0.0341, 0.0276, 0.0305,
        0.0764, 0.0535, 0.0455], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,273][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0717, 0.2517, 0.0737, 0.1137, 0.0508, 0.0604, 0.0495, 0.0564, 0.0513,
        0.0942, 0.0598, 0.0668], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,275][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0892, 0.0611, 0.0819, 0.0559, 0.0488, 0.0746, 0.1000, 0.0975, 0.1222,
        0.0853, 0.0781, 0.1053], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,277][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1748, 0.1287, 0.0649, 0.0665, 0.0771, 0.0642, 0.0673, 0.0495, 0.0749,
        0.0836, 0.0616, 0.0869], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,278][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.4645, 0.0910, 0.0217, 0.0577, 0.0510, 0.0263, 0.0321, 0.0276, 0.0450,
        0.0849, 0.0206, 0.0776], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,280][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0685, 0.2063, 0.0732, 0.1088, 0.0547, 0.0692, 0.0616, 0.0708, 0.0609,
        0.0807, 0.0838, 0.0616], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,282][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.5878, 0.0303, 0.0111, 0.0336, 0.0286, 0.0206, 0.0252, 0.0253, 0.0490,
        0.0927, 0.0232, 0.0726], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,283][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0669, 0.2039, 0.0659, 0.1301, 0.0686, 0.0687, 0.0658, 0.0509, 0.0515,
        0.0860, 0.0831, 0.0585], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,285][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1440, 0.3391, 0.0635, 0.0958, 0.0674, 0.0407, 0.0263, 0.0278, 0.0340,
        0.0549, 0.0586, 0.0478], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,285][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0058, 0.0675, 0.2565, 0.0711, 0.0434, 0.0841, 0.1116, 0.1493, 0.0609,
        0.0348, 0.0771, 0.0379], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,286][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1933, 0.0609, 0.0462, 0.0553, 0.0506, 0.0643, 0.0882, 0.0754, 0.0898,
        0.0975, 0.0701, 0.1083], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,286][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0459, 0.2555, 0.0729, 0.1587, 0.0810, 0.0696, 0.0471, 0.0459, 0.0361,
        0.0650, 0.0828, 0.0395], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,287][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.1776, 0.3083, 0.0314, 0.1099, 0.0735, 0.0332, 0.0331, 0.0217, 0.0195,
        0.0681, 0.0512, 0.0483, 0.0241], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,287][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.0445, 0.3237, 0.0634, 0.1135, 0.0352, 0.0515, 0.0374, 0.0440, 0.0379,
        0.0861, 0.0521, 0.0544, 0.0565], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,288][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.1011, 0.0490, 0.0761, 0.0467, 0.0401, 0.0669, 0.0866, 0.0677, 0.1173,
        0.0784, 0.0902, 0.1067, 0.0732], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,288][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.1686, 0.1512, 0.0613, 0.0673, 0.0748, 0.0577, 0.0610, 0.0397, 0.0647,
        0.0734, 0.0544, 0.0813, 0.0445], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,288][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.5931, 0.0726, 0.0061, 0.0410, 0.0348, 0.0126, 0.0164, 0.0227, 0.0247,
        0.0735, 0.0136, 0.0611, 0.0280], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,289][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.0679, 0.2239, 0.0681, 0.1123, 0.0514, 0.0619, 0.0518, 0.0585, 0.0519,
        0.0712, 0.0820, 0.0530, 0.0460], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,291][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.6161, 0.0277, 0.0059, 0.0263, 0.0190, 0.0116, 0.0165, 0.0213, 0.0352,
        0.0929, 0.0180, 0.0546, 0.0549], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,293][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.0581, 0.2080, 0.0533, 0.1507, 0.0610, 0.0555, 0.0590, 0.0417, 0.0416,
        0.0896, 0.0957, 0.0495, 0.0363], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,294][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.1485, 0.4092, 0.0390, 0.0886, 0.0523, 0.0306, 0.0185, 0.0288, 0.0262,
        0.0504, 0.0467, 0.0431, 0.0182], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,296][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.0119, 0.0908, 0.1935, 0.0885, 0.0389, 0.0707, 0.0738, 0.1276, 0.0628,
        0.0589, 0.0853, 0.0366, 0.0606], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,297][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.2095, 0.0451, 0.0371, 0.0441, 0.0357, 0.0470, 0.0740, 0.0564, 0.0847,
        0.1091, 0.0781, 0.1135, 0.0657], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,299][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.0271, 0.3434, 0.0428, 0.2128, 0.0725, 0.0485, 0.0333, 0.0316, 0.0182,
        0.0540, 0.0602, 0.0327, 0.0230], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,301][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2520, 0.2131, 0.0356, 0.0954, 0.0717, 0.0277, 0.0286, 0.0197, 0.0245,
        0.0757, 0.0384, 0.0420, 0.0293, 0.0463], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,303][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0427, 0.1854, 0.0876, 0.1132, 0.0454, 0.0693, 0.0468, 0.0544, 0.0558,
        0.0725, 0.0597, 0.0577, 0.0571, 0.0524], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,305][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0756, 0.0472, 0.0731, 0.0444, 0.0408, 0.0664, 0.0809, 0.0828, 0.1069,
        0.0657, 0.0654, 0.0844, 0.0779, 0.0885], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,306][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1813, 0.1002, 0.0520, 0.0564, 0.0652, 0.0504, 0.0522, 0.0406, 0.0593,
        0.0756, 0.0539, 0.0786, 0.0515, 0.0827], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,308][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.4500, 0.0855, 0.0142, 0.0444, 0.0423, 0.0172, 0.0211, 0.0273, 0.0342,
        0.0664, 0.0185, 0.0628, 0.0505, 0.0656], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,308][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0614, 0.1827, 0.0588, 0.0989, 0.0501, 0.0550, 0.0504, 0.0626, 0.0492,
        0.0745, 0.0802, 0.0551, 0.0586, 0.0625], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,309][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.4613, 0.0302, 0.0119, 0.0338, 0.0277, 0.0220, 0.0243, 0.0278, 0.0531,
        0.0891, 0.0245, 0.0633, 0.0520, 0.0792], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,309][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0731, 0.1667, 0.0557, 0.1129, 0.0665, 0.0571, 0.0588, 0.0415, 0.0464,
        0.0770, 0.0902, 0.0526, 0.0414, 0.0602], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,310][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2335, 0.2353, 0.0528, 0.0680, 0.0605, 0.0331, 0.0214, 0.0236, 0.0327,
        0.0521, 0.0546, 0.0476, 0.0204, 0.0645], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,310][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0033, 0.0375, 0.2445, 0.0467, 0.0295, 0.0764, 0.1110, 0.1568, 0.0594,
        0.0249, 0.0854, 0.0286, 0.0645, 0.0314], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,310][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1363, 0.0485, 0.0404, 0.0461, 0.0394, 0.0641, 0.0894, 0.0592, 0.0820,
        0.0838, 0.0566, 0.0816, 0.0641, 0.1084], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,311][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0516, 0.2299, 0.0526, 0.1562, 0.0718, 0.0526, 0.0418, 0.0394, 0.0345,
        0.0666, 0.0707, 0.0419, 0.0402, 0.0502], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,312][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:16:39,314][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 6315],
        [48106],
        [11716],
        [19498],
        [15631],
        [ 3569],
        [ 6258],
        [29239],
        [ 6426],
        [25202],
        [13183],
        [12719],
        [31884],
        [11945]], device='cuda:0')
[2024-07-24 10:16:39,316][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 6853],
        [46506],
        [ 6789],
        [15054],
        [10530],
        [ 1442],
        [ 3166],
        [24186],
        [ 3182],
        [23351],
        [ 7791],
        [ 8749],
        [28698],
        [ 7076]], device='cuda:0')
[2024-07-24 10:16:39,317][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[31573],
        [31620],
        [31620],
        [31487],
        [31447],
        [31517],
        [31530],
        [31544],
        [31562],
        [31567],
        [31554],
        [31575],
        [31610],
        [31584]], device='cuda:0')
[2024-07-24 10:16:39,318][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 5056],
        [ 7348],
        [ 5687],
        [22731],
        [19007],
        [13727],
        [14801],
        [16518],
        [10638],
        [16247],
        [13966],
        [15637],
        [18398],
        [17702]], device='cuda:0')
[2024-07-24 10:16:39,320][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[17936],
        [20416],
        [26936],
        [30245],
        [38966],
        [40033],
        [39850],
        [39075],
        [42400],
        [41851],
        [41073],
        [41770],
        [41778],
        [41734]], device='cuda:0')
[2024-07-24 10:16:39,322][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[17661],
        [16318],
        [15969],
        [14544],
        [13425],
        [14490],
        [14227],
        [15229],
        [16113],
        [15361],
        [14490],
        [14360],
        [14865],
        [15480]], device='cuda:0')
[2024-07-24 10:16:39,323][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 9198],
        [13440],
        [14401],
        [13304],
        [11433],
        [11502],
        [11426],
        [10779],
        [11365],
        [10667],
        [10370],
        [10132],
        [ 9175],
        [ 9194]], device='cuda:0')
[2024-07-24 10:16:39,325][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[17062],
        [25960],
        [31656],
        [34331],
        [37068],
        [37936],
        [38146],
        [38340],
        [38407],
        [37982],
        [38091],
        [38040],
        [37515],
        [37938]], device='cuda:0')
[2024-07-24 10:16:39,326][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[25693],
        [22268],
        [22742],
        [19567],
        [18055],
        [19813],
        [20554],
        [21276],
        [21621],
        [20521],
        [21453],
        [21630],
        [21540],
        [21715]], device='cuda:0')
[2024-07-24 10:16:39,328][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[25031],
        [47260],
        [47256],
        [47689],
        [47454],
        [46536],
        [45475],
        [45879],
        [45084],
        [43450],
        [45699],
        [42848],
        [43212],
        [41352]], device='cuda:0')
[2024-07-24 10:16:39,329][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[25591],
        [21978],
        [15970],
        [14280],
        [12292],
        [13118],
        [10642],
        [10661],
        [10087],
        [ 8566],
        [10849],
        [ 7288],
        [ 8848],
        [ 7087]], device='cuda:0')
[2024-07-24 10:16:39,331][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[39955],
        [50253],
        [48318],
        [49425],
        [48827],
        [47554],
        [46540],
        [45256],
        [40596],
        [40457],
        [46260],
        [44227],
        [46156],
        [40549]], device='cuda:0')
[2024-07-24 10:16:39,332][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 7842],
        [22008],
        [20117],
        [20758],
        [22249],
        [21198],
        [19390],
        [19700],
        [19315],
        [20083],
        [20382],
        [21000],
        [21286],
        [22313]], device='cuda:0')
[2024-07-24 10:16:39,333][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[16211],
        [40501],
        [41954],
        [41918],
        [41324],
        [40671],
        [40819],
        [42387],
        [41917],
        [41480],
        [41921],
        [40629],
        [41891],
        [40982]], device='cuda:0')
[2024-07-24 10:16:39,334][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[35908],
        [24612],
        [40634],
        [24717],
        [31748],
        [38692],
        [39468],
        [29239],
        [41749],
        [15536],
        [36869],
        [33222],
        [16939],
        [32192]], device='cuda:0')
[2024-07-24 10:16:39,335][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[15819],
        [16508],
        [15867],
        [10631],
        [ 8277],
        [ 8213],
        [ 6783],
        [ 8555],
        [ 6394],
        [ 4227],
        [ 6361],
        [ 3366],
        [ 4311],
        [ 3157]], device='cuda:0')
[2024-07-24 10:16:39,336][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[49118],
        [30726],
        [33050],
        [35510],
        [37173],
        [39547],
        [39065],
        [33653],
        [28945],
        [29229],
        [30582],
        [25185],
        [23076],
        [20649]], device='cuda:0')
[2024-07-24 10:16:39,337][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[11760],
        [10192],
        [ 7858],
        [ 6507],
        [ 5845],
        [ 9085],
        [13603],
        [11994],
        [14301],
        [12904],
        [15301],
        [13729],
        [15830],
        [15915]], device='cuda:0')
[2024-07-24 10:16:39,339][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[13451],
        [17525],
        [18285],
        [21372],
        [26304],
        [26384],
        [27952],
        [26068],
        [29961],
        [31655],
        [28504],
        [26796],
        [27558],
        [27939]], device='cuda:0')
[2024-07-24 10:16:39,340][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[26037],
        [16534],
        [22015],
        [17095],
        [15098],
        [18525],
        [19560],
        [22198],
        [21614],
        [30577],
        [22203],
        [36099],
        [37380],
        [38741]], device='cuda:0')
[2024-07-24 10:16:39,342][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[13865],
        [30226],
        [29576],
        [27354],
        [28087],
        [31559],
        [32807],
        [33707],
        [33339],
        [33812],
        [35112],
        [36538],
        [36815],
        [37813]], device='cuda:0')
[2024-07-24 10:16:39,343][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[35065],
        [30234],
        [28941],
        [18246],
        [14353],
        [19423],
        [20125],
        [24288],
        [ 5413],
        [ 6413],
        [15581],
        [ 7132],
        [ 8038],
        [ 9468]], device='cuda:0')
[2024-07-24 10:16:39,345][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[48842],
        [35125],
        [37206],
        [40860],
        [41926],
        [44267],
        [45396],
        [43629],
        [44682],
        [44135],
        [42387],
        [43910],
        [42324],
        [43302]], device='cuda:0')
[2024-07-24 10:16:39,346][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[34976],
        [33779],
        [32682],
        [33281],
        [34094],
        [34252],
        [34086],
        [33252],
        [33369],
        [33013],
        [32811],
        [34776],
        [33520],
        [35108]], device='cuda:0')
[2024-07-24 10:16:39,348][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[33391],
        [ 5433],
        [10380],
        [ 6808],
        [ 7897],
        [ 9641],
        [12052],
        [13212],
        [15882],
        [15468],
        [12118],
        [13623],
        [12081],
        [15007]], device='cuda:0')
[2024-07-24 10:16:39,349][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[30902],
        [39643],
        [42819],
        [47121],
        [48504],
        [47309],
        [47782],
        [45409],
        [47784],
        [48378],
        [47656],
        [48174],
        [47487],
        [47353]], device='cuda:0')
[2024-07-24 10:16:39,351][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[17527],
        [10597],
        [15790],
        [20936],
        [24530],
        [25895],
        [28324],
        [24932],
        [28429],
        [27911],
        [24266],
        [28765],
        [26239],
        [27911]], device='cuda:0')
[2024-07-24 10:16:39,352][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 4280],
        [11796],
        [11144],
        [13334],
        [12542],
        [ 8810],
        [ 7364],
        [ 8453],
        [11730],
        [13852],
        [10979],
        [12998],
        [13758],
        [12781]], device='cuda:0')
[2024-07-24 10:16:39,354][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 8480],
        [36064],
        [13613],
        [20992],
        [12785],
        [ 8126],
        [ 5287],
        [13851],
        [ 2551],
        [ 6951],
        [ 5582],
        [ 3262],
        [10427],
        [ 3488]], device='cuda:0')
[2024-07-24 10:16:39,355][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[15616],
        [15616],
        [15616],
        [15616],
        [15616],
        [15616],
        [15616],
        [15616],
        [15616],
        [15616],
        [15616],
        [15616],
        [15616],
        [15616]], device='cuda:0')
[2024-07-24 10:16:39,403][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:39,404][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,406][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,407][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,408][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,408][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,408][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,408][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,409][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,409][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,409][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,409][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,410][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,410][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.5390, 0.4610], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,410][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.1610, 0.8390], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,410][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.0052, 0.9948], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,411][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.1619, 0.8381], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,411][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.8341, 0.1659], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,411][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.6275, 0.3725], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,412][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.5158, 0.4842], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,414][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.5701, 0.4299], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,415][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.7203, 0.2797], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,417][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.1756, 0.8244], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,418][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.8043, 0.1957], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,420][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.0030, 0.9970], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,421][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2814, 0.5099, 0.2087], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,423][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1909, 0.5608, 0.2483], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,424][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([2.9332e-04, 6.8759e-02, 9.3095e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,425][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0859, 0.4432, 0.4709], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,427][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.9020, 0.0880, 0.0100], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,429][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.7518, 0.2221, 0.0260], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,430][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3482, 0.3322, 0.3197], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,431][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.5115, 0.2642, 0.2243], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,431][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7551, 0.2185, 0.0264], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,431][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0855, 0.5528, 0.3617], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,431][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1793, 0.4206, 0.4001], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,432][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0023, 0.3565, 0.6411], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,432][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Jonathan] are: tensor([0.2876, 0.3036, 0.1969, 0.2119], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,432][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Jonathan] are: tensor([0.0614, 0.3838, 0.2979, 0.2569], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,433][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Jonathan] are: tensor([3.7685e-04, 5.7105e-02, 7.8065e-01, 1.6187e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,433][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Jonathan] are: tensor([0.0431, 0.3403, 0.3789, 0.2376], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,433][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Jonathan] are: tensor([0.8394, 0.1367, 0.0131, 0.0108], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,433][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Jonathan] are: tensor([0.4737, 0.3147, 0.0971, 0.1145], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,434][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Jonathan] are: tensor([0.2856, 0.2518, 0.2324, 0.2302], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,434][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Jonathan] are: tensor([0.4091, 0.2242, 0.1886, 0.1780], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,434][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Jonathan] are: tensor([0.5739, 0.1943, 0.0350, 0.1968], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,435][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Jonathan] are: tensor([0.1146, 0.2933, 0.2937, 0.2983], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,436][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Jonathan] are: tensor([0.3569, 0.2049, 0.2538, 0.1845], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,438][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Jonathan] are: tensor([0.0011, 0.2920, 0.4758, 0.2311], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,440][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.3959, 0.1950, 0.1591, 0.1383, 0.1116], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,441][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0888, 0.2963, 0.2265, 0.2054, 0.1830], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,441][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ went] are: tensor([3.0564e-04, 3.9621e-02, 7.9721e-01, 1.2461e-01, 3.8255e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,443][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0502, 0.2668, 0.2949, 0.1802, 0.2078], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,445][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.8521, 0.0921, 0.0119, 0.0079, 0.0359], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,446][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.4139, 0.2462, 0.0946, 0.1243, 0.1211], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,448][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.2343, 0.2025, 0.1917, 0.1850, 0.1865], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,450][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.3173, 0.1865, 0.1611, 0.1488, 0.1863], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,451][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.4572, 0.1510, 0.0498, 0.1624, 0.1795], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,453][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.0700, 0.2530, 0.2425, 0.2455, 0.1890], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,454][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.1422, 0.2246, 0.2315, 0.1981, 0.2037], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,454][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0015, 0.2100, 0.3679, 0.1861, 0.2345], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,454][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.4183, 0.1306, 0.1406, 0.0956, 0.0838, 0.1310], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,455][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.2041, 0.2773, 0.0751, 0.1720, 0.1461, 0.1254], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,455][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([4.3050e-04, 4.0575e-02, 5.8753e-01, 1.0981e-01, 3.3407e-02, 2.2825e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,455][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0334, 0.2248, 0.2340, 0.1517, 0.1838, 0.1723], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,455][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.7199, 0.0656, 0.0120, 0.0084, 0.0272, 0.1669], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,456][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.6243, 0.1792, 0.0275, 0.0463, 0.0953, 0.0274], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,456][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1983, 0.1726, 0.1602, 0.1627, 0.1607, 0.1456], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,456][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.3298, 0.1650, 0.1336, 0.1206, 0.1482, 0.1027], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,457][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.5368, 0.0870, 0.0363, 0.0919, 0.1688, 0.0791], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,457][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0230, 0.2223, 0.1621, 0.2204, 0.1928, 0.1793], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,457][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0876, 0.2269, 0.1646, 0.1699, 0.1752, 0.1758], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,458][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0020, 0.2120, 0.2526, 0.1518, 0.1801, 0.2014], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,460][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.2967, 0.1009, 0.1135, 0.1025, 0.1067, 0.1765, 0.1032],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,461][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1772, 0.2872, 0.0823, 0.1401, 0.1128, 0.0995, 0.1009],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,463][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0006, 0.0513, 0.5444, 0.1070, 0.0349, 0.1474, 0.1144],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,464][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0254, 0.1869, 0.2047, 0.1238, 0.1633, 0.1521, 0.1437],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,465][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.6711, 0.0739, 0.0085, 0.0070, 0.0268, 0.1987, 0.0141],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,466][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.5919, 0.1782, 0.0322, 0.0533, 0.0817, 0.0285, 0.0343],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,468][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1560, 0.1476, 0.1430, 0.1386, 0.1401, 0.1316, 0.1431],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,470][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.3297, 0.1508, 0.1166, 0.1055, 0.1286, 0.0852, 0.0836],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,471][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.6789, 0.0229, 0.0107, 0.0468, 0.0914, 0.0459, 0.1034],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,473][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0183, 0.1857, 0.1719, 0.1796, 0.1616, 0.1621, 0.1208],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,475][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0713, 0.2070, 0.1370, 0.1450, 0.1450, 0.1404, 0.1543],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,476][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0020, 0.1642, 0.1981, 0.1224, 0.1517, 0.1547, 0.2070],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,477][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.3013, 0.0565, 0.0580, 0.0717, 0.0786, 0.1827, 0.1210, 0.1301],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,477][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([0.2283, 0.2650, 0.0249, 0.1093, 0.0864, 0.0533, 0.1273, 0.1055],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,478][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.0005, 0.0497, 0.3537, 0.1144, 0.0298, 0.1558, 0.0953, 0.2007],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,478][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.0184, 0.1732, 0.1859, 0.1065, 0.1333, 0.1308, 0.1269, 0.1250],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,478][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.6120, 0.0510, 0.0064, 0.0049, 0.0250, 0.1796, 0.0114, 0.1096],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,478][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.7573, 0.1363, 0.0126, 0.0246, 0.0341, 0.0092, 0.0153, 0.0106],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,479][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.1545, 0.1281, 0.1202, 0.1201, 0.1189, 0.1085, 0.1219, 0.1278],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,479][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.3788, 0.1244, 0.0922, 0.0830, 0.1067, 0.0686, 0.0682, 0.0782],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,479][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.7844, 0.0098, 0.0011, 0.0228, 0.0513, 0.0160, 0.0359, 0.0788],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,480][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.0227, 0.1310, 0.1168, 0.1400, 0.1366, 0.1474, 0.1181, 0.1875],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,480][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.0896, 0.1195, 0.1470, 0.1063, 0.1170, 0.1374, 0.1496, 0.1336],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,480][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.0015, 0.0940, 0.2283, 0.0859, 0.0943, 0.1218, 0.1740, 0.2002],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,481][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2175, 0.1078, 0.0739, 0.0770, 0.0678, 0.0951, 0.0782, 0.1365, 0.1461],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,482][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1714, 0.2146, 0.0499, 0.1221, 0.1224, 0.0723, 0.0836, 0.0859, 0.0779],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,484][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0005, 0.0406, 0.3670, 0.0870, 0.0357, 0.1371, 0.1071, 0.1684, 0.0566],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,485][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0233, 0.1449, 0.1495, 0.0941, 0.1258, 0.1163, 0.1228, 0.1033, 0.1200],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,487][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.6137, 0.0499, 0.0057, 0.0055, 0.0213, 0.1709, 0.0111, 0.1189, 0.0030],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,488][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4808, 0.1637, 0.0340, 0.0538, 0.0819, 0.0329, 0.0386, 0.0377, 0.0766],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,489][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1261, 0.1151, 0.1104, 0.1073, 0.1073, 0.1009, 0.1090, 0.1247, 0.0992],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,491][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2219, 0.1199, 0.1064, 0.0929, 0.1150, 0.0787, 0.0786, 0.0900, 0.0966],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,493][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.6001, 0.0249, 0.0070, 0.0492, 0.0796, 0.0254, 0.0455, 0.1103, 0.0580],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,494][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0072, 0.1326, 0.0900, 0.1427, 0.1123, 0.1069, 0.0892, 0.2345, 0.0846],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,496][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0590, 0.1579, 0.1000, 0.1035, 0.1045, 0.1020, 0.1128, 0.1353, 0.1250],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,498][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0024, 0.1007, 0.1252, 0.0730, 0.0963, 0.1041, 0.1299, 0.2320, 0.1365],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,499][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Jonathan] are: tensor([0.0738, 0.1009, 0.0799, 0.0956, 0.0707, 0.0972, 0.0815, 0.2264, 0.1081,
        0.0659], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,500][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Jonathan] are: tensor([0.0201, 0.1097, 0.1074, 0.0711, 0.0664, 0.1924, 0.1023, 0.1862, 0.0949,
        0.0495], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,500][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Jonathan] are: tensor([1.0089e-04, 2.1579e-02, 4.2917e-01, 6.3848e-02, 2.4111e-02, 1.4363e-01,
        1.2298e-01, 1.5372e-01, 2.9445e-02, 1.1409e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,500][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Jonathan] are: tensor([0.0105, 0.1342, 0.1562, 0.0870, 0.1112, 0.1078, 0.1097, 0.1058, 0.1108,
        0.0668], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,501][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Jonathan] are: tensor([0.5243, 0.0653, 0.0073, 0.0070, 0.0287, 0.1968, 0.0124, 0.1505, 0.0036,
        0.0042], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,501][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Jonathan] are: tensor([0.1040, 0.1426, 0.0918, 0.0818, 0.0868, 0.0925, 0.0773, 0.1265, 0.1084,
        0.0883], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,501][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Jonathan] are: tensor([0.1193, 0.1072, 0.0965, 0.0984, 0.0993, 0.0890, 0.0970, 0.1111, 0.0873,
        0.0950], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,502][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Jonathan] are: tensor([0.1625, 0.1098, 0.0986, 0.0905, 0.1091, 0.0803, 0.0796, 0.0842, 0.0928,
        0.0925], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,502][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Jonathan] are: tensor([0.2468, 0.0456, 0.0187, 0.0765, 0.0932, 0.0518, 0.0856, 0.1852, 0.0791,
        0.1176], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,502][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Jonathan] are: tensor([0.0270, 0.1086, 0.0972, 0.1045, 0.1206, 0.1275, 0.0844, 0.1329, 0.1129,
        0.0843], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,503][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Jonathan] are: tensor([0.0897, 0.0978, 0.1036, 0.0798, 0.0888, 0.0937, 0.1033, 0.1118, 0.1190,
        0.1124], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,503][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Jonathan] are: tensor([0.0004, 0.0771, 0.1410, 0.0589, 0.0849, 0.0998, 0.1462, 0.1595, 0.1386,
        0.0935], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,503][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.3000, 0.1491, 0.0401, 0.0630, 0.0428, 0.0659, 0.0476, 0.0558, 0.0726,
        0.0579, 0.1052], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,504][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.1305, 0.2933, 0.0398, 0.1007, 0.0790, 0.0494, 0.0576, 0.0563, 0.0435,
        0.0918, 0.0581], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,506][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0006, 0.0369, 0.3487, 0.0840, 0.0355, 0.1851, 0.1121, 0.0763, 0.0568,
        0.0189, 0.0451], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,507][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0153, 0.1259, 0.1395, 0.0791, 0.1014, 0.1058, 0.0980, 0.0954, 0.1046,
        0.0594, 0.0757], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,509][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.4691, 0.0698, 0.0090, 0.0071, 0.0313, 0.2029, 0.0130, 0.1530, 0.0038,
        0.0041, 0.0370], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,510][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.4281, 0.2063, 0.0198, 0.0510, 0.0489, 0.0239, 0.0282, 0.0323, 0.0502,
        0.0811, 0.0303], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,512][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.1112, 0.0950, 0.0917, 0.0885, 0.0885, 0.0792, 0.0833, 0.0966, 0.0786,
        0.0863, 0.1013], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,513][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.2843, 0.0990, 0.0765, 0.0702, 0.0882, 0.0566, 0.0548, 0.0619, 0.0691,
        0.0737, 0.0656], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,515][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.5884, 0.0180, 0.0013, 0.0238, 0.0331, 0.0093, 0.0151, 0.0659, 0.0176,
        0.0622, 0.1654], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,516][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0143, 0.1037, 0.0866, 0.1028, 0.0899, 0.0986, 0.0735, 0.1415, 0.0861,
        0.1073, 0.0956], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,518][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0718, 0.0889, 0.0961, 0.0743, 0.0820, 0.0839, 0.0941, 0.0997, 0.1125,
        0.1020, 0.0946], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,520][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0004, 0.0501, 0.1037, 0.0543, 0.0676, 0.0966, 0.1285, 0.1674, 0.1367,
        0.0845, 0.1102], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,522][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0930, 0.0953, 0.0548, 0.0629, 0.0545, 0.0692, 0.0524, 0.0843, 0.0727,
        0.0561, 0.2132, 0.0918], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,523][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0560, 0.0929, 0.0705, 0.0624, 0.0743, 0.1215, 0.0877, 0.1206, 0.0839,
        0.0533, 0.0964, 0.0806], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,523][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([2.4823e-04, 2.3967e-02, 4.8355e-01, 5.8480e-02, 2.4064e-02, 1.2455e-01,
        8.8645e-02, 9.1338e-02, 3.5570e-02, 1.0644e-02, 4.8115e-02, 1.0829e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,523][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0148, 0.1249, 0.1276, 0.0756, 0.0954, 0.0902, 0.0852, 0.0882, 0.0972,
        0.0537, 0.0700, 0.0772], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,524][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.3781, 0.1022, 0.0084, 0.0096, 0.0374, 0.2079, 0.0142, 0.1858, 0.0035,
        0.0050, 0.0404, 0.0076], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,524][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.2189, 0.1255, 0.0488, 0.0505, 0.0835, 0.0491, 0.0519, 0.0577, 0.0788,
        0.0793, 0.0793, 0.0767], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,524][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0878, 0.0846, 0.0844, 0.0793, 0.0810, 0.0771, 0.0821, 0.0920, 0.0775,
        0.0791, 0.0917, 0.0834], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,525][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.2136, 0.0967, 0.0797, 0.0714, 0.0859, 0.0584, 0.0592, 0.0644, 0.0697,
        0.0718, 0.0659, 0.0633], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,525][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2025, 0.0209, 0.0087, 0.0341, 0.0568, 0.0250, 0.0391, 0.1145, 0.0464,
        0.0688, 0.2933, 0.0899], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,525][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0102, 0.1002, 0.0859, 0.0951, 0.0893, 0.0916, 0.0623, 0.1399, 0.0841,
        0.0875, 0.1113, 0.0428], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,526][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0503, 0.0946, 0.0699, 0.0723, 0.0775, 0.0715, 0.0778, 0.1056, 0.0873,
        0.0944, 0.0890, 0.1099], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,526][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0012, 0.0704, 0.1290, 0.0612, 0.0814, 0.0841, 0.1235, 0.1390, 0.1225,
        0.0794, 0.0908, 0.0174], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,526][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.0324, 0.0321, 0.0353, 0.0431, 0.0406, 0.0767, 0.0644, 0.1341, 0.0802,
        0.0396, 0.3059, 0.0862, 0.0293], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,528][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.0863, 0.1345, 0.0489, 0.0716, 0.0859, 0.0611, 0.0948, 0.0565, 0.0612,
        0.0734, 0.0673, 0.1003, 0.0581], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,529][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([3.5845e-04, 3.5993e-02, 3.9060e-01, 6.1348e-02, 2.2607e-02, 1.3134e-01,
        8.3868e-02, 1.1868e-01, 4.6215e-02, 1.4785e-02, 5.8676e-02, 1.2225e-02,
        2.3297e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,531][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0157, 0.1134, 0.1265, 0.0665, 0.0881, 0.0906, 0.0814, 0.0738, 0.0940,
        0.0451, 0.0658, 0.0822, 0.0570], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,532][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.3670, 0.0730, 0.0098, 0.0118, 0.0422, 0.2033, 0.0180, 0.1927, 0.0050,
        0.0073, 0.0443, 0.0126, 0.0129], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,533][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.2306, 0.1499, 0.0326, 0.0540, 0.0670, 0.0288, 0.0408, 0.0406, 0.0557,
        0.0755, 0.0814, 0.0789, 0.0642], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,535][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.0907, 0.0807, 0.0767, 0.0745, 0.0736, 0.0695, 0.0760, 0.0828, 0.0684,
        0.0724, 0.0833, 0.0765, 0.0749], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,537][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.2121, 0.0908, 0.0727, 0.0636, 0.0796, 0.0532, 0.0526, 0.0605, 0.0648,
        0.0669, 0.0615, 0.0583, 0.0634], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,538][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.1909, 0.0057, 0.0017, 0.0134, 0.0315, 0.0084, 0.0246, 0.1098, 0.0356,
        0.0553, 0.4000, 0.0870, 0.0363], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,540][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.0083, 0.0776, 0.0739, 0.0822, 0.0804, 0.0853, 0.0642, 0.1160, 0.0901,
        0.0783, 0.0979, 0.0688, 0.0771], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,542][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.0670, 0.0674, 0.0751, 0.0555, 0.0594, 0.0649, 0.0756, 0.0728, 0.0929,
        0.0808, 0.0692, 0.1062, 0.1132], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,543][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0015, 0.0569, 0.1308, 0.0561, 0.0730, 0.0819, 0.1020, 0.1298, 0.1202,
        0.0784, 0.0996, 0.0187, 0.0511], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,545][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1005, 0.0712, 0.0486, 0.0531, 0.0446, 0.0559, 0.0416, 0.0709, 0.0769,
        0.0520, 0.1992, 0.0769, 0.0350, 0.0736], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,545][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0508, 0.0789, 0.0490, 0.0508, 0.0620, 0.1135, 0.0804, 0.0775, 0.0717,
        0.0583, 0.1014, 0.0713, 0.0656, 0.0689], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,546][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([1.5826e-04, 2.0896e-02, 4.7468e-01, 5.1342e-02, 1.8347e-02, 1.1637e-01,
        8.5710e-02, 9.9928e-02, 3.0505e-02, 9.9277e-03, 5.4797e-02, 8.5276e-03,
        1.9417e-02, 9.3949e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,546][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0131, 0.1083, 0.1107, 0.0617, 0.0773, 0.0798, 0.0820, 0.0738, 0.0870,
        0.0451, 0.0587, 0.0774, 0.0550, 0.0700], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,546][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.4988, 0.0613, 0.0059, 0.0072, 0.0241, 0.1654, 0.0132, 0.1611, 0.0039,
        0.0048, 0.0298, 0.0110, 0.0109, 0.0025], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,547][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1411, 0.1129, 0.0390, 0.0457, 0.0791, 0.0430, 0.0413, 0.0569, 0.0718,
        0.0690, 0.0805, 0.0685, 0.0714, 0.0798], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,547][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0716, 0.0735, 0.0705, 0.0694, 0.0690, 0.0665, 0.0700, 0.0829, 0.0657,
        0.0693, 0.0792, 0.0717, 0.0745, 0.0662], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,548][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1678, 0.0839, 0.0746, 0.0640, 0.0759, 0.0539, 0.0549, 0.0598, 0.0637,
        0.0638, 0.0612, 0.0572, 0.0624, 0.0568], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,548][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1859, 0.0207, 0.0094, 0.0333, 0.0514, 0.0238, 0.0371, 0.0719, 0.0556,
        0.0601, 0.2772, 0.0739, 0.0378, 0.0617], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,548][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0077, 0.0846, 0.0648, 0.0824, 0.0708, 0.0691, 0.0567, 0.1368, 0.0657,
        0.0754, 0.0801, 0.0472, 0.0887, 0.0701], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,549][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0383, 0.0851, 0.0551, 0.0599, 0.0637, 0.0552, 0.0592, 0.0906, 0.0659,
        0.0779, 0.0760, 0.0801, 0.1229, 0.0702], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,549][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0028, 0.0684, 0.0821, 0.0600, 0.0736, 0.0772, 0.0914, 0.1635, 0.0895,
        0.0811, 0.0841, 0.0190, 0.0688, 0.0386], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,583][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:39,584][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,584][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,584][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,585][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,585][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,585][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,585][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,586][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,586][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,586][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,587][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,587][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,587][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.3343, 0.6657], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,588][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.1610, 0.8390], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,588][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.0052, 0.9948], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,588][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.5371, 0.4629], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,589][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.4401, 0.5599], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,589][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.6141, 0.3859], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,589][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.8017, 0.1983], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,589][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.1682, 0.8318], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,590][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.3721, 0.6279], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,590][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.2840, 0.7160], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,590][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.0147, 0.9853], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,591][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.6767, 0.3233], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,591][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1035, 0.7986, 0.0979], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,591][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1909, 0.5608, 0.2483], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,592][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([2.9332e-04, 6.8759e-02, 9.3095e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,593][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2515, 0.6172, 0.1313], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,595][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2420, 0.5939, 0.1641], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,596][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.7384, 0.2348, 0.0268], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,598][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.7479, 0.1500, 0.1021], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,600][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0708, 0.5316, 0.3977], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,602][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2499, 0.6875, 0.0626], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,603][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1116, 0.8057, 0.0827], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,603][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([4.2631e-04, 5.8348e-02, 9.4123e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,604][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.3060, 0.2608, 0.4332], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,604][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Jonathan] are: tensor([0.1112, 0.5398, 0.1484, 0.2006], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,604][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Jonathan] are: tensor([0.0614, 0.3838, 0.2979, 0.2569], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,605][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Jonathan] are: tensor([3.7685e-04, 5.7105e-02, 7.8065e-01, 1.6187e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,605][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Jonathan] are: tensor([0.2761, 0.3575, 0.1013, 0.2651], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,605][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Jonathan] are: tensor([0.1947, 0.4290, 0.1919, 0.1845], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,606][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Jonathan] are: tensor([0.4584, 0.3266, 0.0976, 0.1175], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,606][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Jonathan] are: tensor([0.4291, 0.1883, 0.1492, 0.2333], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,606][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Jonathan] are: tensor([0.0758, 0.3372, 0.3180, 0.2690], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,606][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Jonathan] are: tensor([0.1824, 0.5281, 0.0873, 0.2023], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,607][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Jonathan] are: tensor([0.1293, 0.5263, 0.1138, 0.2305], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,607][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Jonathan] are: tensor([0.0009, 0.0730, 0.7593, 0.1669], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,609][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Jonathan] are: tensor([0.2231, 0.1768, 0.3030, 0.2971], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,611][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.1818, 0.3994, 0.1487, 0.1924, 0.0778], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,612][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0888, 0.2963, 0.2265, 0.2054, 0.1830], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,613][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([3.0564e-04, 3.9621e-02, 7.9721e-01, 1.2461e-01, 3.8255e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,614][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.1858, 0.2992, 0.1381, 0.2418, 0.1351], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,616][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.1607, 0.2982, 0.2548, 0.1806, 0.1058], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,617][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.4035, 0.2525, 0.0948, 0.1277, 0.1215], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,619][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.3795, 0.1465, 0.1486, 0.1635, 0.1619], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,620][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0477, 0.2522, 0.3719, 0.1929, 0.1354], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,623][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.1437, 0.4277, 0.1131, 0.1935, 0.1220], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,624][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.0892, 0.4162, 0.1301, 0.2512, 0.1133], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,625][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0009, 0.0472, 0.7682, 0.1164, 0.0672], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,626][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.1327, 0.1058, 0.3351, 0.2155, 0.2108], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,626][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.3026, 0.2669, 0.1346, 0.1387, 0.0692, 0.0880], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,627][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.2041, 0.2773, 0.0751, 0.1720, 0.1461, 0.1254], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,627][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([4.3050e-04, 4.0575e-02, 5.8753e-01, 1.0981e-01, 3.3407e-02, 2.2825e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,627][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1338, 0.3121, 0.1220, 0.2384, 0.1135, 0.0801], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,628][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2653, 0.2642, 0.1908, 0.0795, 0.0722, 0.1280], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,628][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.6070, 0.1880, 0.0283, 0.0496, 0.0989, 0.0282], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,628][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.5304, 0.1055, 0.0827, 0.1151, 0.1071, 0.0592], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,628][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0362, 0.2691, 0.3231, 0.1926, 0.0857, 0.0933], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,629][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2057, 0.3955, 0.0856, 0.1318, 0.1121, 0.0693], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,629][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0647, 0.4263, 0.1020, 0.2465, 0.0770, 0.0835], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,629][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0009, 0.0566, 0.6676, 0.1037, 0.0517, 0.1196], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,630][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1552, 0.1119, 0.2020, 0.1532, 0.1248, 0.2530], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,630][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1511, 0.2430, 0.1536, 0.1700, 0.0902, 0.1375, 0.0545],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,632][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1772, 0.2872, 0.0823, 0.1401, 0.1128, 0.0995, 0.1009],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,634][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0006, 0.0513, 0.5444, 0.1070, 0.0349, 0.1474, 0.1144],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,635][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.1039, 0.2856, 0.1374, 0.2112, 0.1077, 0.0899, 0.0644],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,636][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1484, 0.2442, 0.1837, 0.1152, 0.0761, 0.1463, 0.0862],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,638][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.5795, 0.1839, 0.0327, 0.0560, 0.0836, 0.0288, 0.0354],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,640][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.4602, 0.1100, 0.0850, 0.1150, 0.0978, 0.0603, 0.0715],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,641][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0398, 0.2926, 0.2761, 0.1918, 0.0832, 0.0566, 0.0599],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,643][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1497, 0.3070, 0.1120, 0.1447, 0.1139, 0.1011, 0.0715],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,645][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0427, 0.3663, 0.1359, 0.1929, 0.0740, 0.1151, 0.0731],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,646][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0012, 0.0741, 0.5907, 0.1009, 0.0471, 0.0853, 0.1007],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,648][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1338, 0.1196, 0.1704, 0.1409, 0.1105, 0.1689, 0.1559],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,649][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.0787, 0.1982, 0.1265, 0.1690, 0.0675, 0.2086, 0.0901, 0.0615],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,649][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([0.2283, 0.2650, 0.0249, 0.1093, 0.0864, 0.0533, 0.1273, 0.1055],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,650][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([0.0005, 0.0497, 0.3537, 0.1144, 0.0298, 0.1558, 0.0953, 0.2007],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,650][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.1358, 0.3283, 0.0902, 0.1803, 0.1026, 0.0690, 0.0586, 0.0352],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,650][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.0811, 0.2793, 0.1388, 0.0787, 0.0892, 0.1598, 0.0798, 0.0932],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,651][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.7487, 0.1380, 0.0133, 0.0269, 0.0350, 0.0095, 0.0160, 0.0126],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,651][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.5477, 0.1125, 0.0507, 0.0793, 0.0835, 0.0370, 0.0526, 0.0368],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,651][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.0527, 0.2628, 0.1736, 0.1410, 0.0640, 0.0484, 0.0693, 0.1881],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,651][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.1220, 0.2959, 0.0647, 0.1491, 0.1175, 0.1151, 0.0810, 0.0546],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,652][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.0346, 0.3291, 0.0982, 0.1778, 0.0760, 0.0927, 0.0734, 0.1182],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,652][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.0005, 0.0489, 0.3219, 0.0716, 0.0245, 0.0720, 0.0644, 0.3962],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,652][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.0721, 0.0566, 0.1900, 0.1468, 0.0898, 0.1887, 0.1465, 0.1097],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,653][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1251, 0.2117, 0.1375, 0.1394, 0.0707, 0.1207, 0.0641, 0.0593, 0.0715],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,654][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1714, 0.2146, 0.0499, 0.1221, 0.1224, 0.0723, 0.0836, 0.0859, 0.0779],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,655][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0005, 0.0406, 0.3670, 0.0870, 0.0357, 0.1371, 0.1071, 0.1684, 0.0566],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,657][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0970, 0.2432, 0.1038, 0.1907, 0.1070, 0.0767, 0.0546, 0.0526, 0.0743],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,659][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0970, 0.2073, 0.1629, 0.0836, 0.0818, 0.1312, 0.0773, 0.0870, 0.0720],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,660][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4760, 0.1653, 0.0335, 0.0551, 0.0832, 0.0327, 0.0392, 0.0383, 0.0767],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,662][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3468, 0.0915, 0.0669, 0.0783, 0.0935, 0.0523, 0.0652, 0.0916, 0.1139],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,663][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0276, 0.1706, 0.2279, 0.1247, 0.0767, 0.0564, 0.0660, 0.1656, 0.0846],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,665][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1290, 0.2864, 0.0834, 0.1464, 0.1087, 0.0782, 0.0609, 0.0450, 0.0621],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,666][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0281, 0.2605, 0.0934, 0.1800, 0.0635, 0.0901, 0.0675, 0.1517, 0.0652],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,669][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0006, 0.0348, 0.2734, 0.0602, 0.0323, 0.0548, 0.0610, 0.4319, 0.0509],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,670][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0422, 0.0626, 0.1189, 0.0826, 0.0805, 0.1490, 0.1314, 0.1403, 0.1925],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,671][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Jonathan] are: tensor([0.0253, 0.2231, 0.1455, 0.1513, 0.0653, 0.1145, 0.0657, 0.1166, 0.0572,
        0.0357], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,672][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Jonathan] are: tensor([0.0201, 0.1097, 0.1074, 0.0711, 0.0664, 0.1924, 0.1023, 0.1862, 0.0949,
        0.0495], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,672][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Jonathan] are: tensor([1.0089e-04, 2.1579e-02, 4.2917e-01, 6.3848e-02, 2.4111e-02, 1.4363e-01,
        1.2298e-01, 1.5372e-01, 2.9445e-02, 1.1409e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,673][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Jonathan] are: tensor([0.0558, 0.1706, 0.1057, 0.1593, 0.1071, 0.1038, 0.0783, 0.0707, 0.0723,
        0.0762], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,673][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Jonathan] are: tensor([0.0411, 0.2008, 0.1352, 0.1129, 0.0725, 0.1267, 0.0943, 0.0947, 0.0698,
        0.0518], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,673][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Jonathan] are: tensor([0.1044, 0.1462, 0.0915, 0.0844, 0.0880, 0.0908, 0.0780, 0.1196, 0.1071,
        0.0900], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,674][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Jonathan] are: tensor([0.1040, 0.1082, 0.0888, 0.1019, 0.1019, 0.0916, 0.0757, 0.1256, 0.0969,
        0.1055], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,674][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Jonathan] are: tensor([0.0125, 0.1294, 0.2195, 0.1243, 0.0672, 0.0890, 0.0933, 0.1252, 0.0730,
        0.0665], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,674][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Jonathan] are: tensor([0.0427, 0.2188, 0.1141, 0.1459, 0.0974, 0.1049, 0.0817, 0.0749, 0.0664,
        0.0531], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,675][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Jonathan] are: tensor([0.0232, 0.2277, 0.0978, 0.1330, 0.0687, 0.0875, 0.0642, 0.1686, 0.0695,
        0.0597], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,675][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Jonathan] are: tensor([2.0618e-04, 2.4920e-02, 2.7549e-01, 5.1536e-02, 3.1181e-02, 7.7499e-02,
        8.9524e-02, 3.8846e-01, 4.8480e-02, 1.2703e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,675][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Jonathan] are: tensor([0.0197, 0.0658, 0.1674, 0.1102, 0.0852, 0.1471, 0.1158, 0.0831, 0.1108,
        0.0950], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,676][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0773, 0.3534, 0.0974, 0.1332, 0.0444, 0.1046, 0.0433, 0.0319, 0.0403,
        0.0303, 0.0439], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,676][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.1305, 0.2933, 0.0398, 0.1007, 0.0790, 0.0494, 0.0576, 0.0563, 0.0435,
        0.0918, 0.0581], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,678][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0006, 0.0369, 0.3487, 0.0840, 0.0355, 0.1851, 0.1121, 0.0763, 0.0568,
        0.0189, 0.0451], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,680][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0785, 0.2884, 0.0700, 0.1429, 0.0716, 0.0719, 0.0478, 0.0342, 0.0631,
        0.0650, 0.0668], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,681][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1179, 0.2425, 0.1354, 0.0767, 0.0691, 0.1046, 0.0499, 0.0411, 0.0537,
        0.0343, 0.0749], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,682][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.4257, 0.2039, 0.0196, 0.0525, 0.0493, 0.0236, 0.0286, 0.0326, 0.0497,
        0.0841, 0.0303], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,684][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.2705, 0.0990, 0.0527, 0.0803, 0.0707, 0.0436, 0.0505, 0.0722, 0.0831,
        0.1217, 0.0556], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,686][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0300, 0.1496, 0.1484, 0.1283, 0.0604, 0.0473, 0.0503, 0.1014, 0.0701,
        0.0898, 0.1246], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,687][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.1139, 0.3600, 0.0450, 0.1357, 0.0797, 0.0551, 0.0335, 0.0293, 0.0276,
        0.0407, 0.0796], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,689][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0233, 0.2762, 0.0714, 0.1435, 0.0526, 0.0875, 0.0521, 0.0997, 0.0470,
        0.0551, 0.0917], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,691][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0009, 0.0336, 0.3385, 0.0661, 0.0352, 0.0694, 0.0764, 0.2394, 0.0621,
        0.0209, 0.0575], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,693][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0451, 0.0316, 0.0686, 0.0809, 0.0515, 0.1160, 0.0923, 0.0750, 0.1298,
        0.1316, 0.1776], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,694][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0456, 0.1884, 0.1155, 0.1167, 0.0650, 0.1016, 0.0507, 0.0598, 0.0489,
        0.0395, 0.1201, 0.0482], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,695][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0560, 0.0929, 0.0705, 0.0624, 0.0743, 0.1215, 0.0877, 0.1206, 0.0839,
        0.0533, 0.0964, 0.0806], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,695][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([2.4823e-04, 2.3967e-02, 4.8355e-01, 5.8480e-02, 2.4064e-02, 1.2455e-01,
        8.8645e-02, 9.1338e-02, 3.5570e-02, 1.0644e-02, 4.8115e-02, 1.0829e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,696][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0592, 0.1587, 0.0974, 0.1293, 0.0864, 0.0835, 0.0612, 0.0466, 0.0693,
        0.0673, 0.0834, 0.0578], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,696][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0501, 0.1453, 0.1365, 0.0818, 0.0641, 0.1119, 0.0695, 0.0719, 0.0570,
        0.0419, 0.1077, 0.0624], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,696][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2162, 0.1269, 0.0489, 0.0524, 0.0840, 0.0488, 0.0522, 0.0567, 0.0778,
        0.0809, 0.0787, 0.0766], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,697][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1355, 0.0753, 0.0785, 0.0729, 0.0788, 0.0668, 0.0687, 0.0888, 0.0993,
        0.0955, 0.0692, 0.0708], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,697][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0154, 0.1306, 0.2195, 0.1053, 0.0611, 0.0619, 0.0682, 0.0943, 0.0650,
        0.0579, 0.0882, 0.0324], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,697][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0549, 0.1624, 0.0766, 0.0972, 0.0886, 0.0780, 0.0572, 0.0636, 0.0569,
        0.0450, 0.1649, 0.0547], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,698][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0242, 0.1953, 0.0944, 0.1297, 0.0627, 0.0899, 0.0555, 0.0992, 0.0546,
        0.0578, 0.0947, 0.0421], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,698][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0005, 0.0296, 0.3537, 0.0594, 0.0322, 0.0652, 0.0659, 0.2316, 0.0488,
        0.0167, 0.0776, 0.0189], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,698][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0278, 0.0470, 0.1170, 0.0709, 0.0649, 0.1228, 0.1175, 0.0676, 0.1109,
        0.0807, 0.1236, 0.0492], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,699][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.0149, 0.1257, 0.1039, 0.1185, 0.0541, 0.1305, 0.0623, 0.0889, 0.0524,
        0.0283, 0.1563, 0.0455, 0.0186], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,701][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.0863, 0.1345, 0.0489, 0.0716, 0.0859, 0.0611, 0.0948, 0.0565, 0.0612,
        0.0734, 0.0673, 0.1003, 0.0581], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,702][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([3.5845e-04, 3.5993e-02, 3.9060e-01, 6.1348e-02, 2.2607e-02, 1.3134e-01,
        8.3868e-02, 1.1868e-01, 4.6215e-02, 1.4785e-02, 5.8676e-02, 1.2225e-02,
        2.3297e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,703][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.0483, 0.1700, 0.0809, 0.1226, 0.0800, 0.0736, 0.0570, 0.0405, 0.0652,
        0.0632, 0.1124, 0.0521, 0.0341], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,705][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.0278, 0.1323, 0.1055, 0.0636, 0.0668, 0.1263, 0.0611, 0.0999, 0.0476,
        0.0271, 0.1550, 0.0607, 0.0263], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,706][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.2292, 0.1476, 0.0321, 0.0562, 0.0665, 0.0284, 0.0409, 0.0411, 0.0553,
        0.0791, 0.0800, 0.0792, 0.0644], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,708][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.2040, 0.0699, 0.0486, 0.0613, 0.0625, 0.0377, 0.0503, 0.0680, 0.0792,
        0.0995, 0.0721, 0.0659, 0.0810], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,710][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.0141, 0.1184, 0.1852, 0.0727, 0.0489, 0.0496, 0.0607, 0.1387, 0.0651,
        0.0542, 0.1038, 0.0274, 0.0612], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,711][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.0407, 0.1200, 0.0585, 0.0788, 0.0748, 0.0614, 0.0566, 0.0752, 0.0617,
        0.0418, 0.2387, 0.0547, 0.0371], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,713][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.0147, 0.1554, 0.0942, 0.1124, 0.0513, 0.0944, 0.0601, 0.1132, 0.0549,
        0.0510, 0.1339, 0.0429, 0.0216], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,715][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.0005, 0.0367, 0.2168, 0.0483, 0.0228, 0.0591, 0.0657, 0.2827, 0.0564,
        0.0179, 0.1034, 0.0207, 0.0692], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,717][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.0276, 0.0419, 0.1433, 0.0739, 0.0461, 0.1015, 0.0858, 0.0501, 0.1350,
        0.0868, 0.1168, 0.0395, 0.0518], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,718][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0771, 0.1381, 0.1072, 0.1056, 0.0618, 0.0891, 0.0436, 0.0473, 0.0519,
        0.0415, 0.1159, 0.0453, 0.0242, 0.0515], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,718][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0508, 0.0789, 0.0490, 0.0508, 0.0620, 0.1135, 0.0804, 0.0775, 0.0717,
        0.0583, 0.1014, 0.0713, 0.0656, 0.0689], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,719][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.5826e-04, 2.0896e-02, 4.7468e-01, 5.1342e-02, 1.8347e-02, 1.1637e-01,
        8.5710e-02, 9.9928e-02, 3.0505e-02, 9.9277e-03, 5.4797e-02, 8.5276e-03,
        1.9417e-02, 9.3949e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,719][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0512, 0.1367, 0.0878, 0.1219, 0.0795, 0.0666, 0.0565, 0.0404, 0.0625,
        0.0656, 0.0944, 0.0495, 0.0381, 0.0493], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,719][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0598, 0.1320, 0.1114, 0.0612, 0.0617, 0.1000, 0.0656, 0.0645, 0.0559,
        0.0363, 0.0931, 0.0615, 0.0282, 0.0685], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,720][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1408, 0.1137, 0.0384, 0.0471, 0.0799, 0.0425, 0.0417, 0.0557, 0.0712,
        0.0706, 0.0803, 0.0685, 0.0707, 0.0789], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,720][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1310, 0.0640, 0.0589, 0.0611, 0.0642, 0.0482, 0.0524, 0.0772, 0.0748,
        0.0857, 0.0624, 0.0610, 0.0871, 0.0718], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,720][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0095, 0.0966, 0.2199, 0.0878, 0.0454, 0.0564, 0.0678, 0.0971, 0.0611,
        0.0471, 0.0884, 0.0292, 0.0566, 0.0370], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,721][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0584, 0.1456, 0.0716, 0.0904, 0.0812, 0.0713, 0.0522, 0.0456, 0.0581,
        0.0420, 0.1587, 0.0486, 0.0296, 0.0466], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,721][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0237, 0.1636, 0.0749, 0.1325, 0.0547, 0.0692, 0.0500, 0.1045, 0.0478,
        0.0608, 0.0998, 0.0425, 0.0308, 0.0453], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,721][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0004, 0.0276, 0.3301, 0.0490, 0.0266, 0.0567, 0.0661, 0.2363, 0.0402,
        0.0166, 0.0777, 0.0174, 0.0437, 0.0117], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,722][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0181, 0.0404, 0.1063, 0.0618, 0.0465, 0.1083, 0.1051, 0.0782, 0.1019,
        0.0671, 0.1066, 0.0393, 0.0638, 0.0565], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,723][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:16:39,725][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 5033],
        [38678],
        [  721],
        [ 3909],
        [ 1826],
        [  151],
        [  353],
        [ 3748],
        [  373],
        [ 5449],
        [  528],
        [ 1092],
        [ 5296],
        [  939]], device='cuda:0')
[2024-07-24 10:16:39,726][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 6714],
        [45182],
        [ 6716],
        [14785],
        [ 8569],
        [ 2365],
        [ 4144],
        [19023],
        [ 4164],
        [21509],
        [ 7469],
        [ 9989],
        [24134],
        [ 9851]], device='cuda:0')
[2024-07-24 10:16:39,728][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[29719],
        [27528],
        [23860],
        [24486],
        [24444],
        [23797],
        [23784],
        [21317],
        [20256],
        [18706],
        [20927],
        [18226],
        [15101],
        [18418]], device='cuda:0')
[2024-07-24 10:16:39,729][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[26176],
        [47577],
        [46471],
        [46916],
        [46939],
        [46843],
        [46560],
        [42773],
        [41937],
        [34404],
        [44019],
        [33197],
        [37103],
        [31226]], device='cuda:0')
[2024-07-24 10:16:39,730][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[21090],
        [50240],
        [40070],
        [42469],
        [41566],
        [42325],
        [41621],
        [41458],
        [41034],
        [39342],
        [41563],
        [40163],
        [41203],
        [39978]], device='cuda:0')
[2024-07-24 10:16:39,732][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[2846],
        [7162],
        [3941],
        [4465],
        [3955],
        [3884],
        [3487],
        [3048],
        [2874],
        [2984],
        [2756],
        [2617],
        [2475],
        [2573]], device='cuda:0')
[2024-07-24 10:16:39,733][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[4702],
        [4144],
        [4219],
        [4022],
        [3888],
        [3925],
        [3923],
        [3540],
        [3509],
        [3402],
        [3261],
        [3187],
        [3155],
        [3259]], device='cuda:0')
[2024-07-24 10:16:39,735][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[38450],
        [41532],
        [42268],
        [43269],
        [44554],
        [44956],
        [45344],
        [43844],
        [44772],
        [42620],
        [43750],
        [43598],
        [43188],
        [42482]], device='cuda:0')
[2024-07-24 10:16:39,736][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[12623],
        [11204],
        [ 9632],
        [10268],
        [ 9148],
        [ 9628],
        [10754],
        [10886],
        [11467],
        [11739],
        [11710],
        [11933],
        [12116],
        [12530]], device='cuda:0')
[2024-07-24 10:16:39,738][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[15139],
        [11510],
        [ 8672],
        [10531],
        [11646],
        [ 9788],
        [ 9258],
        [ 8223],
        [ 7182],
        [ 7949],
        [ 7867],
        [ 7565],
        [ 7159],
        [ 6885]], device='cuda:0')
[2024-07-24 10:16:39,739][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[30011],
        [30055],
        [28805],
        [27213],
        [24115],
        [20986],
        [16535],
        [22185],
        [17094],
        [14012],
        [14229],
        [ 8818],
        [ 7505],
        [ 7510]], device='cuda:0')
[2024-07-24 10:16:39,741][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[24138],
        [  536],
        [ 1395],
        [ 4193],
        [ 6288],
        [ 6181],
        [ 6195],
        [ 4968],
        [ 3904],
        [ 4700],
        [ 4980],
        [ 4732],
        [ 4854],
        [ 4537]], device='cuda:0')
[2024-07-24 10:16:39,742][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[1280],
        [2465],
        [7871],
        [6126],
        [8207],
        [7762],
        [7837],
        [7096],
        [7699],
        [7961],
        [8468],
        [9012],
        [8994],
        [9384]], device='cuda:0')
[2024-07-24 10:16:39,743][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[19801],
        [22836],
        [ 3535],
        [ 4203],
        [ 3135],
        [ 2784],
        [ 2135],
        [ 1955],
        [ 2064],
        [ 1845],
        [ 1704],
        [ 1772],
        [ 1725],
        [ 1887]], device='cuda:0')
[2024-07-24 10:16:39,744][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[7037],
        [3350],
        [3102],
        [3037],
        [3704],
        [3109],
        [3320],
        [3804],
        [3852],
        [2322],
        [3510],
        [3581],
        [4575],
        [3407]], device='cuda:0')
[2024-07-24 10:16:39,745][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[31384],
        [40292],
        [39013],
        [39655],
        [40591],
        [41384],
        [39857],
        [38474],
        [39960],
        [38482],
        [39919],
        [37389],
        [35476],
        [37396]], device='cuda:0')
[2024-07-24 10:16:39,746][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[28836],
        [ 5933],
        [ 9853],
        [12550],
        [13593],
        [12868],
        [16254],
        [17484],
        [21008],
        [24661],
        [16926],
        [26424],
        [26055],
        [26167]], device='cuda:0')
[2024-07-24 10:16:39,747][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 7819],
        [26698],
        [22723],
        [23697],
        [23003],
        [22670],
        [22535],
        [25698],
        [24691],
        [24387],
        [25098],
        [24514],
        [25547],
        [24871]], device='cuda:0')
[2024-07-24 10:16:39,748][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[14034],
        [24444],
        [23689],
        [18760],
        [14580],
        [11045],
        [ 8390],
        [10064],
        [ 7585],
        [ 5402],
        [ 7882],
        [ 5638],
        [ 6451],
        [ 6177]], device='cuda:0')
[2024-07-24 10:16:39,749][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[27549],
        [17284],
        [17292],
        [16856],
        [17755],
        [19210],
        [17947],
        [14311],
        [14895],
        [13590],
        [15289],
        [14080],
        [13107],
        [12942]], device='cuda:0')
[2024-07-24 10:16:39,751][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[18681],
        [29040],
        [26240],
        [19387],
        [18086],
        [21404],
        [20882],
        [24944],
        [20816],
        [20024],
        [20664],
        [17373],
        [15831],
        [14623]], device='cuda:0')
[2024-07-24 10:16:39,752][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[21450],
        [35228],
        [40101],
        [45326],
        [45165],
        [44333],
        [45337],
        [44858],
        [45174],
        [44870],
        [44621],
        [44583],
        [43649],
        [43473]], device='cuda:0')
[2024-07-24 10:16:39,754][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[34349],
        [ 7488],
        [23086],
        [18693],
        [22190],
        [24268],
        [22712],
        [25952],
        [31544],
        [31964],
        [29224],
        [32155],
        [34075],
        [34841]], device='cuda:0')
[2024-07-24 10:16:39,755][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[30873],
        [19949],
        [19784],
        [18005],
        [15500],
        [17875],
        [19723],
        [19435],
        [20899],
        [22118],
        [18111],
        [22869],
        [22146],
        [24348]], device='cuda:0')
[2024-07-24 10:16:39,756][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[39801],
        [16290],
        [13156],
        [12972],
        [11329],
        [11782],
        [12351],
        [14317],
        [15619],
        [15676],
        [10979],
        [11777],
        [11855],
        [11650]], device='cuda:0')
[2024-07-24 10:16:39,758][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[47041],
        [19130],
        [40723],
        [38260],
        [39147],
        [38974],
        [39371],
        [40936],
        [41128],
        [41616],
        [41723],
        [41913],
        [42176],
        [41979]], device='cuda:0')
[2024-07-24 10:16:39,759][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[28382],
        [27875],
        [24238],
        [23680],
        [21484],
        [20158],
        [20848],
        [19807],
        [18554],
        [19088],
        [17684],
        [18035],
        [18378],
        [18617]], device='cuda:0')
[2024-07-24 10:16:39,761][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 5108],
        [15792],
        [10324],
        [13958],
        [15472],
        [14189],
        [14523],
        [13263],
        [12654],
        [13684],
        [15860],
        [14896],
        [15646],
        [14857]], device='cuda:0')
[2024-07-24 10:16:39,762][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[38395],
        [44789],
        [44121],
        [42997],
        [42007],
        [43060],
        [42360],
        [41626],
        [40350],
        [42663],
        [40903],
        [39983],
        [38568],
        [40970]], device='cuda:0')
[2024-07-24 10:16:39,764][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[11893],
        [11893],
        [11893],
        [11893],
        [11893],
        [11893],
        [11893],
        [11893],
        [11893],
        [11893],
        [11893],
        [11893],
        [11893],
        [11893]], device='cuda:0')
[2024-07-24 10:16:39,810][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:39,811][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,813][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,814][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,815][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,816][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,817][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,817][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,817][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,818][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,818][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,818][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,818][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,819][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.8595, 0.1405], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,819][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.0035, 0.9965], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,819][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.4596, 0.5404], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,820][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.4217, 0.5783], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,820][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.1820, 0.8180], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,820][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.7766, 0.2234], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,822][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.1261, 0.8739], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,823][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.2385, 0.7615], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,825][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.6207, 0.3793], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,826][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.5146, 0.4854], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,826][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.9802, 0.0198], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,826][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.4732, 0.5268], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,827][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.5733, 0.2631, 0.1635], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,827][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0010, 0.2122, 0.7868], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,827][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1831, 0.4023, 0.4146], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,827][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2476, 0.4306, 0.3218], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,828][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0827, 0.7088, 0.2085], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,828][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.6395, 0.3327, 0.0278], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,828][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1089, 0.3276, 0.5635], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,829][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0881, 0.8679, 0.0440], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,829][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.3703, 0.6150, 0.0147], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,829][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2676, 0.5030, 0.2294], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,829][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.9731, 0.0149, 0.0120], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,830][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0679, 0.3947, 0.5374], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:39,830][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Jonathan] are: tensor([0.6616, 0.1395, 0.1081, 0.0908], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,831][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Jonathan] are: tensor([2.4770e-04, 9.5669e-02, 8.2052e-01, 8.3558e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,833][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Jonathan] are: tensor([0.1406, 0.2689, 0.2688, 0.3217], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,834][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Jonathan] are: tensor([0.2331, 0.3946, 0.1875, 0.1848], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,836][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Jonathan] are: tensor([0.0763, 0.3858, 0.2621, 0.2757], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,837][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Jonathan] are: tensor([0.5052, 0.2619, 0.0898, 0.1431], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,839][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Jonathan] are: tensor([0.0581, 0.1579, 0.5232, 0.2607], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,840][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Jonathan] are: tensor([0.1208, 0.4225, 0.1454, 0.3112], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,842][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Jonathan] are: tensor([0.4066, 0.4307, 0.0354, 0.1273], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,843][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Jonathan] are: tensor([0.1951, 0.3862, 0.2066, 0.2122], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,845][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Jonathan] are: tensor([0.9653, 0.0106, 0.0107, 0.0134], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,847][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Jonathan] are: tensor([0.1200, 0.2562, 0.3847, 0.2391], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:39,848][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.4681, 0.1785, 0.1487, 0.1167, 0.0878], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,849][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ went] are: tensor([2.8580e-04, 7.9316e-02, 7.8198e-01, 7.0679e-02, 6.7741e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,849][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.1099, 0.2080, 0.2059, 0.2378, 0.2384], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,849][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.2173, 0.2864, 0.2233, 0.1650, 0.1080], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,850][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.1377, 0.3616, 0.1793, 0.1856, 0.1357], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,850][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.4072, 0.2212, 0.1176, 0.1364, 0.1176], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,850][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0985, 0.1125, 0.3250, 0.1768, 0.2872], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,851][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.2291, 0.3227, 0.1509, 0.2084, 0.0888], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,851][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.4177, 0.3637, 0.0491, 0.0955, 0.0740], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,851][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.1666, 0.3395, 0.1939, 0.1709, 0.1291], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,851][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.9870, 0.0028, 0.0028, 0.0028, 0.0046], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,852][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.1157, 0.1250, 0.4800, 0.1699, 0.1095], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:39,852][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.3692, 0.2121, 0.1410, 0.1260, 0.0897, 0.0619], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,852][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0008, 0.1152, 0.3294, 0.1661, 0.1203, 0.2682], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,853][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0735, 0.1722, 0.1775, 0.2002, 0.2065, 0.1701], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,854][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1941, 0.3324, 0.1713, 0.1475, 0.0748, 0.0798], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,855][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.2156, 0.2503, 0.1580, 0.1179, 0.1007, 0.1575], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,857][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.5428, 0.1575, 0.0634, 0.0753, 0.0902, 0.0710], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,858][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0223, 0.0835, 0.2244, 0.1834, 0.2358, 0.2506], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,860][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.4691, 0.2024, 0.0921, 0.1132, 0.0695, 0.0537], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,861][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.3285, 0.4981, 0.0215, 0.0945, 0.0436, 0.0138], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,863][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1756, 0.3130, 0.1688, 0.1417, 0.0987, 0.1022], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,865][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.8993, 0.0196, 0.0117, 0.0144, 0.0167, 0.0383], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,866][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0482, 0.1384, 0.4304, 0.1061, 0.0537, 0.2232], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:39,868][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.3518, 0.1829, 0.1284, 0.1085, 0.0825, 0.0558, 0.0902],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,870][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0004, 0.0653, 0.3109, 0.1107, 0.0822, 0.2425, 0.1880],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,871][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0742, 0.1489, 0.1446, 0.1701, 0.1737, 0.1396, 0.1489],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,872][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1202, 0.3226, 0.1821, 0.1120, 0.0660, 0.0906, 0.1065],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,872][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1086, 0.1325, 0.2076, 0.1013, 0.1040, 0.2072, 0.1387],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,872][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.3981, 0.1049, 0.1014, 0.0598, 0.0940, 0.1360, 0.1058],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,873][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0155, 0.0709, 0.1884, 0.1350, 0.1731, 0.2473, 0.1699],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,873][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.2129, 0.1253, 0.1589, 0.1303, 0.0974, 0.1714, 0.1039],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,873][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.2977, 0.4950, 0.0250, 0.1053, 0.0490, 0.0143, 0.0139],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,874][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1603, 0.2869, 0.1520, 0.1321, 0.0901, 0.1016, 0.0772],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,874][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.9718, 0.0032, 0.0032, 0.0030, 0.0043, 0.0097, 0.0048],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,874][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0549, 0.1548, 0.3079, 0.0900, 0.0594, 0.1755, 0.1575],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:39,874][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.3125, 0.1521, 0.1147, 0.0953, 0.0716, 0.0511, 0.0828, 0.1199],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,875][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([1.5477e-04, 5.8346e-02, 2.2195e-01, 6.0077e-02, 3.3777e-02, 1.1406e-01,
        1.1672e-01, 3.9492e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,875][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.0839, 0.1288, 0.1211, 0.1525, 0.1343, 0.1158, 0.1206, 0.1428],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,875][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.0991, 0.2865, 0.1256, 0.0940, 0.0384, 0.0438, 0.1021, 0.2104],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,876][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.0773, 0.1219, 0.1347, 0.0887, 0.1159, 0.2300, 0.1614, 0.0702],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,878][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.3103, 0.1221, 0.0633, 0.0412, 0.0793, 0.1595, 0.1778, 0.0466],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,879][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.0284, 0.0708, 0.1599, 0.1065, 0.1333, 0.1871, 0.1620, 0.1520],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,881][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.0771, 0.0917, 0.1432, 0.1127, 0.1000, 0.2484, 0.1746, 0.0523],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,882][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.3221, 0.4775, 0.0226, 0.0800, 0.0402, 0.0132, 0.0153, 0.0290],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,883][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.1505, 0.2602, 0.1278, 0.1090, 0.0909, 0.0993, 0.0737, 0.0886],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,884][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.9875, 0.0017, 0.0013, 0.0019, 0.0020, 0.0024, 0.0013, 0.0021],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,886][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.0498, 0.0464, 0.3662, 0.0416, 0.0334, 0.1417, 0.2713, 0.0496],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:39,888][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2614, 0.1521, 0.1000, 0.0925, 0.0629, 0.0417, 0.0680, 0.1216, 0.0998],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,889][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0008, 0.0548, 0.1005, 0.0846, 0.0491, 0.1113, 0.1070, 0.3350, 0.1570],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,891][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0537, 0.1121, 0.1051, 0.1264, 0.1349, 0.1062, 0.1144, 0.1253, 0.1219],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,893][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0728, 0.2612, 0.1872, 0.1056, 0.0568, 0.0670, 0.0822, 0.0504, 0.1166],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,894][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0986, 0.1925, 0.1624, 0.1171, 0.0823, 0.0966, 0.1093, 0.0517, 0.0895],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,895][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2451, 0.1099, 0.0819, 0.0597, 0.0938, 0.1142, 0.1030, 0.0535, 0.1390],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,895][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0205, 0.0576, 0.1141, 0.1086, 0.1204, 0.1374, 0.1352, 0.1541, 0.1521],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,895][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1503, 0.1616, 0.1783, 0.1199, 0.0724, 0.0937, 0.0819, 0.0616, 0.0802],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,896][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2057, 0.5258, 0.0273, 0.1132, 0.0472, 0.0151, 0.0132, 0.0275, 0.0250],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,896][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1379, 0.2332, 0.1269, 0.1126, 0.0848, 0.0899, 0.0723, 0.0745, 0.0678],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,896][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9613, 0.0046, 0.0023, 0.0038, 0.0045, 0.0087, 0.0051, 0.0069, 0.0027],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,897][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0296, 0.0916, 0.2075, 0.0767, 0.0449, 0.1508, 0.1666, 0.0394, 0.1928],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:39,897][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Jonathan] are: tensor([0.3991, 0.1146, 0.0818, 0.0676, 0.0466, 0.0323, 0.0541, 0.0700, 0.0772,
        0.0566], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,897][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Jonathan] are: tensor([2.3041e-04, 2.8199e-02, 2.0389e-01, 2.8962e-02, 3.5481e-02, 1.5386e-01,
        1.2692e-01, 1.6706e-01, 2.3094e-01, 2.4453e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,898][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Jonathan] are: tensor([0.0432, 0.1011, 0.0997, 0.1170, 0.1089, 0.0952, 0.0993, 0.1117, 0.0973,
        0.1266], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,898][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Jonathan] are: tensor([0.0210, 0.1505, 0.1404, 0.0738, 0.0411, 0.0880, 0.1107, 0.2142, 0.1128,
        0.0474], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,898][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Jonathan] are: tensor([0.0177, 0.0799, 0.1817, 0.0988, 0.0774, 0.1693, 0.1224, 0.1100, 0.1097,
        0.0330], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,899][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Jonathan] are: tensor([0.0850, 0.0857, 0.0863, 0.0699, 0.0644, 0.1251, 0.1194, 0.1009, 0.1795,
        0.0839], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,901][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Jonathan] are: tensor([0.0117, 0.0301, 0.1415, 0.0596, 0.0822, 0.1728, 0.1212, 0.1102, 0.2115,
        0.0591], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,902][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Jonathan] are: tensor([0.0238, 0.1065, 0.1440, 0.1400, 0.0632, 0.1587, 0.1184, 0.1197, 0.0853,
        0.0405], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,904][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Jonathan] are: tensor([0.0809, 0.2970, 0.0952, 0.1504, 0.0924, 0.0608, 0.0529, 0.0581, 0.0464,
        0.0659], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,905][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Jonathan] are: tensor([0.0641, 0.2091, 0.1432, 0.1253, 0.0900, 0.1079, 0.0752, 0.0674, 0.0568,
        0.0611], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,907][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Jonathan] are: tensor([0.8158, 0.0099, 0.0118, 0.0108, 0.0116, 0.0305, 0.0258, 0.0142, 0.0202,
        0.0496], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,909][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Jonathan] are: tensor([0.0172, 0.0824, 0.2245, 0.0954, 0.0518, 0.1514, 0.1444, 0.0721, 0.1018,
        0.0591], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:39,910][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.2404, 0.1250, 0.0881, 0.0767, 0.0527, 0.0379, 0.0639, 0.0987, 0.0848,
        0.0705, 0.0614], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,911][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([1.3719e-04, 3.6682e-02, 1.7358e-01, 4.5333e-02, 3.0538e-02, 9.4677e-02,
        9.4033e-02, 2.5768e-01, 2.0368e-01, 3.4879e-02, 2.8775e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,913][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0395, 0.0848, 0.0816, 0.0982, 0.0973, 0.0825, 0.0869, 0.0945, 0.0903,
        0.1191, 0.1253], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,915][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0742, 0.2550, 0.0768, 0.0650, 0.0467, 0.0500, 0.0727, 0.0938, 0.1301,
        0.0596, 0.0762], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,916][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0735, 0.2668, 0.1218, 0.1056, 0.0654, 0.1183, 0.0790, 0.0224, 0.0487,
        0.0260, 0.0725], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,918][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.1537, 0.1608, 0.0769, 0.0553, 0.0672, 0.1236, 0.0758, 0.0321, 0.1270,
        0.0395, 0.0880], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,918][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0209, 0.0445, 0.1069, 0.0716, 0.0913, 0.1281, 0.0906, 0.1072, 0.1373,
        0.0698, 0.1320], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,918][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0765, 0.2783, 0.1353, 0.1476, 0.0590, 0.0917, 0.0508, 0.0182, 0.0368,
        0.0270, 0.0789], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,919][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.3134, 0.4476, 0.0145, 0.0649, 0.0304, 0.0110, 0.0094, 0.0170, 0.0179,
        0.0493, 0.0245], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,919][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0962, 0.3090, 0.1045, 0.1024, 0.0718, 0.0757, 0.0510, 0.0501, 0.0437,
        0.0487, 0.0467], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,919][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.9168, 0.0057, 0.0041, 0.0045, 0.0062, 0.0115, 0.0054, 0.0054, 0.0045,
        0.0164, 0.0195], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,920][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0299, 0.0621, 0.1829, 0.0460, 0.0259, 0.1528, 0.1540, 0.0254, 0.2080,
        0.0415, 0.0714], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:39,920][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2321, 0.1122, 0.0840, 0.0632, 0.0475, 0.0338, 0.0570, 0.0973, 0.0838,
        0.0523, 0.0521, 0.0845], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,920][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0005, 0.0362, 0.1977, 0.0410, 0.0391, 0.1130, 0.0996, 0.1616, 0.1713,
        0.0331, 0.0495, 0.0575], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,921][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0399, 0.0744, 0.0719, 0.0837, 0.0839, 0.0721, 0.0773, 0.0848, 0.0811,
        0.1030, 0.1147, 0.1133], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,921][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0496, 0.1564, 0.0952, 0.0644, 0.0418, 0.0661, 0.0967, 0.1094, 0.1102,
        0.0616, 0.0935, 0.0551], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,921][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0275, 0.0897, 0.1604, 0.0715, 0.0676, 0.1324, 0.0769, 0.0675, 0.0758,
        0.0284, 0.1468, 0.0554], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,922][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0900, 0.0948, 0.0821, 0.0550, 0.0684, 0.1195, 0.0781, 0.0492, 0.1046,
        0.0533, 0.1513, 0.0538], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,924][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0126, 0.0278, 0.0998, 0.0589, 0.0823, 0.1247, 0.0763, 0.0974, 0.1419,
        0.0601, 0.1201, 0.0980], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,926][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0460, 0.1236, 0.1776, 0.1167, 0.0697, 0.1080, 0.0654, 0.0409, 0.0590,
        0.0314, 0.1159, 0.0458], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,927][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1540, 0.3293, 0.0580, 0.0922, 0.0682, 0.0303, 0.0264, 0.0378, 0.0389,
        0.0612, 0.0610, 0.0426], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,928][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0747, 0.1988, 0.1217, 0.0992, 0.0708, 0.0881, 0.0685, 0.0621, 0.0523,
        0.0514, 0.0538, 0.0587], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,930][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.9565, 0.0024, 0.0022, 0.0022, 0.0032, 0.0054, 0.0024, 0.0034, 0.0018,
        0.0091, 0.0056, 0.0059], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,932][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0262, 0.0572, 0.2067, 0.0591, 0.0403, 0.1134, 0.1364, 0.0492, 0.1224,
        0.0460, 0.0744, 0.0686], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:39,933][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.3169, 0.0895, 0.0642, 0.0517, 0.0358, 0.0284, 0.0473, 0.0614, 0.0677,
        0.0473, 0.0409, 0.0735, 0.0753], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,935][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.0003, 0.0377, 0.1114, 0.0471, 0.0342, 0.0854, 0.0856, 0.2109, 0.1323,
        0.0432, 0.0490, 0.0805, 0.0824], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,937][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.0359, 0.0656, 0.0664, 0.0768, 0.0737, 0.0671, 0.0714, 0.0756, 0.0745,
        0.0950, 0.1023, 0.1053, 0.0904], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,939][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0178, 0.1536, 0.1044, 0.0424, 0.0290, 0.0455, 0.0676, 0.1861, 0.0886,
        0.0339, 0.1250, 0.0339, 0.0724], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,940][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.0122, 0.0310, 0.0934, 0.0429, 0.0537, 0.1597, 0.0977, 0.0784, 0.0752,
        0.0231, 0.2529, 0.0638, 0.0159], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,942][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.0480, 0.0335, 0.0543, 0.0261, 0.0423, 0.1288, 0.1238, 0.0480, 0.1156,
        0.0415, 0.2633, 0.0573, 0.0176], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,944][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.0071, 0.0298, 0.0891, 0.0525, 0.0648, 0.1101, 0.0915, 0.0880, 0.1366,
        0.0523, 0.1111, 0.1238, 0.0434], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,945][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.0143, 0.0380, 0.1054, 0.0846, 0.0585, 0.1405, 0.1176, 0.0671, 0.0586,
        0.0280, 0.2270, 0.0501, 0.0103], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,946][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.1525, 0.3037, 0.0466, 0.1011, 0.0537, 0.0225, 0.0279, 0.0372, 0.0329,
        0.0776, 0.0693, 0.0453, 0.0298], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,946][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.0530, 0.1860, 0.1301, 0.0857, 0.0697, 0.0917, 0.0614, 0.0742, 0.0520,
        0.0415, 0.0602, 0.0559, 0.0387], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,947][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.9672, 0.0016, 0.0011, 0.0016, 0.0019, 0.0024, 0.0010, 0.0017, 0.0010,
        0.0060, 0.0054, 0.0038, 0.0054], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,947][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0122, 0.0228, 0.1922, 0.0295, 0.0210, 0.1059, 0.1839, 0.0603, 0.1362,
        0.0365, 0.1103, 0.0628, 0.0264], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:39,947][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1743, 0.1158, 0.0731, 0.0660, 0.0420, 0.0314, 0.0520, 0.0814, 0.0699,
        0.0529, 0.0474, 0.0741, 0.0858, 0.0340], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,948][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0008, 0.0347, 0.1376, 0.0438, 0.0428, 0.1052, 0.1064, 0.1467, 0.1299,
        0.0380, 0.0430, 0.0683, 0.0616, 0.0411], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,948][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0388, 0.0662, 0.0635, 0.0691, 0.0718, 0.0624, 0.0665, 0.0737, 0.0704,
        0.0803, 0.0930, 0.0929, 0.0827, 0.0687], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,949][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0322, 0.1370, 0.1147, 0.0650, 0.0407, 0.0617, 0.0834, 0.0844, 0.0915,
        0.0523, 0.0879, 0.0461, 0.0493, 0.0536], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,949][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0357, 0.0663, 0.1252, 0.0618, 0.0648, 0.1325, 0.0815, 0.0533, 0.0854,
        0.0315, 0.1207, 0.0627, 0.0205, 0.0580], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,949][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1220, 0.0584, 0.0612, 0.0420, 0.0636, 0.0937, 0.0654, 0.0357, 0.0966,
        0.0493, 0.1452, 0.0573, 0.0260, 0.0836], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,950][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0047, 0.0209, 0.0703, 0.0535, 0.0671, 0.0883, 0.0827, 0.0898, 0.1156,
        0.0643, 0.1027, 0.1084, 0.0417, 0.0902], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,950][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0829, 0.0746, 0.1236, 0.0862, 0.0621, 0.1044, 0.0637, 0.0484, 0.0653,
        0.0379, 0.1184, 0.0549, 0.0197, 0.0580], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,952][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0980, 0.2503, 0.0607, 0.1000, 0.0671, 0.0372, 0.0306, 0.0556, 0.0497,
        0.0624, 0.0714, 0.0445, 0.0320, 0.0406], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,954][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0579, 0.1659, 0.1182, 0.0895, 0.0649, 0.0804, 0.0640, 0.0650, 0.0509,
        0.0481, 0.0541, 0.0519, 0.0390, 0.0502], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,955][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.8133, 0.0080, 0.0051, 0.0054, 0.0072, 0.0168, 0.0086, 0.0082, 0.0065,
        0.0240, 0.0233, 0.0220, 0.0193, 0.0321], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,957][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0166, 0.0446, 0.1832, 0.0547, 0.0330, 0.1127, 0.1288, 0.0413, 0.1237,
        0.0415, 0.0705, 0.0600, 0.0288, 0.0607], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:39,987][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:39,990][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,991][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,991][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,992][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,993][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,993][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,994][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,994][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,995][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,996][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,996][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,997][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:39,998][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.9777, 0.0223], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:39,998][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.0106, 0.9894], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,002][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.7557, 0.2443], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,005][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.4217, 0.5783], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,005][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.1820, 0.8180], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,006][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.7766, 0.2234], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,007][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.4218, 0.5782], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,007][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.2385, 0.7615], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,008][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.6207, 0.3793], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,012][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.5806, 0.4194], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,016][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.5607, 0.4393], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,019][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.4499, 0.5501], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,019][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9828, 0.0118, 0.0055], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,020][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.2599e-05, 5.5664e-02, 9.4431e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,021][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.7025, 0.1616, 0.1358], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,021][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2476, 0.4306, 0.3218], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,022][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0827, 0.7088, 0.2085], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,025][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.6395, 0.3327, 0.0278], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,030][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1703, 0.5549, 0.2748], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,032][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0881, 0.8679, 0.0440], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,033][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3703, 0.6150, 0.0147], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,034][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.3571, 0.5418, 0.1011], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,034][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.3402, 0.3953, 0.2645], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,035][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0593, 0.4103, 0.5304], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,036][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Jonathan] are: tensor([0.9318, 0.0238, 0.0177, 0.0267], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,038][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Jonathan] are: tensor([6.6854e-04, 1.1333e-01, 7.5514e-01, 1.3087e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,041][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Jonathan] are: tensor([0.3725, 0.2667, 0.1767, 0.1841], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,046][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Jonathan] are: tensor([0.2331, 0.3946, 0.1875, 0.1848], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,047][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Jonathan] are: tensor([0.0763, 0.3858, 0.2621, 0.2757], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,048][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Jonathan] are: tensor([0.5052, 0.2619, 0.0898, 0.1431], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,048][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Jonathan] are: tensor([0.2311, 0.3177, 0.2459, 0.2053], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,049][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Jonathan] are: tensor([0.1208, 0.4225, 0.1454, 0.3112], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,050][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Jonathan] are: tensor([0.4066, 0.4307, 0.0354, 0.1273], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,053][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Jonathan] are: tensor([0.2934, 0.3617, 0.0930, 0.2519], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,058][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Jonathan] are: tensor([0.3411, 0.2614, 0.1616, 0.2359], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,060][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Jonathan] are: tensor([0.1072, 0.2636, 0.3883, 0.2409], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,061][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.9267, 0.0168, 0.0169, 0.0240, 0.0156], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,062][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([6.2141e-04, 9.6512e-02, 7.3986e-01, 1.1311e-01, 4.9893e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,062][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.2423, 0.2098, 0.2182, 0.1542, 0.1754], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,063][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.2173, 0.2864, 0.2233, 0.1650, 0.1080], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,064][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.1377, 0.3616, 0.1793, 0.1856, 0.1357], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,068][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.4072, 0.2212, 0.1176, 0.1364, 0.1176], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,072][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.1703, 0.3171, 0.2421, 0.1563, 0.1141], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,074][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.2291, 0.3227, 0.1509, 0.2084, 0.0888], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,075][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.4177, 0.3637, 0.0491, 0.0955, 0.0740], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,076][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.2702, 0.3352, 0.1060, 0.1749, 0.1137], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,076][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.3560, 0.1984, 0.1872, 0.1323, 0.1260], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,077][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.1029, 0.1238, 0.5029, 0.1679, 0.1025], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,079][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.7763, 0.0161, 0.0130, 0.0170, 0.0125, 0.1651], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,081][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.5719e-04, 1.4074e-01, 6.3989e-01, 1.2326e-01, 2.6390e-02, 6.9468e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,086][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2471, 0.1434, 0.1744, 0.0745, 0.1205, 0.2401], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,088][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1941, 0.3324, 0.1713, 0.1475, 0.0748, 0.0798], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,089][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2156, 0.2503, 0.1580, 0.1179, 0.1007, 0.1575], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,090][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.5428, 0.1575, 0.0634, 0.0753, 0.0902, 0.0710], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,090][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1867, 0.1809, 0.1559, 0.1003, 0.0786, 0.2975], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,091][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.4691, 0.2024, 0.0921, 0.1132, 0.0695, 0.0537], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,094][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.3285, 0.4981, 0.0215, 0.0945, 0.0436, 0.0138], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,098][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.2868, 0.3247, 0.1025, 0.1547, 0.0837, 0.0477], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,102][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.2956, 0.1821, 0.1811, 0.1376, 0.0820, 0.1215], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,102][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0429, 0.1357, 0.4637, 0.1030, 0.0499, 0.2048], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,103][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.4039, 0.0092, 0.0069, 0.0099, 0.0069, 0.0959, 0.4672],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,104][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([3.6377e-04, 1.2855e-01, 6.1424e-01, 1.0864e-01, 2.6930e-02, 6.1432e-02,
        5.9850e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,105][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.2377, 0.1443, 0.1147, 0.0706, 0.0985, 0.1662, 0.1680],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,107][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.1202, 0.3226, 0.1821, 0.1120, 0.0660, 0.0906, 0.1065],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,111][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1086, 0.1325, 0.2076, 0.1013, 0.1040, 0.2072, 0.1387],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,116][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.3981, 0.1049, 0.1014, 0.0598, 0.0940, 0.1360, 0.1058],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,116][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2504, 0.1875, 0.1221, 0.0716, 0.0625, 0.1430, 0.1629],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,117][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.2129, 0.1253, 0.1589, 0.1303, 0.0974, 0.1714, 0.1039],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,118][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.2977, 0.4950, 0.0250, 0.1053, 0.0490, 0.0143, 0.0139],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,119][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.2885, 0.2815, 0.0966, 0.1468, 0.0808, 0.0465, 0.0593],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,121][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.2483, 0.1658, 0.1711, 0.1131, 0.0768, 0.0995, 0.1255],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,125][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0506, 0.1579, 0.3339, 0.0897, 0.0563, 0.1611, 0.1506],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,128][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([6.0378e-01, 1.8163e-03, 2.7944e-03, 1.9979e-03, 2.1887e-03, 5.6585e-02,
        3.3036e-01, 4.7580e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,130][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([1.4703e-04, 1.1311e-01, 3.8608e-01, 5.2019e-02, 1.3704e-02, 4.5569e-02,
        6.5192e-02, 3.2418e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,130][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([0.3658, 0.0880, 0.0835, 0.0630, 0.0562, 0.0839, 0.1147, 0.1448],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,131][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.0991, 0.2865, 0.1256, 0.0940, 0.0384, 0.0438, 0.1021, 0.2104],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,132][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.0773, 0.1219, 0.1347, 0.0887, 0.1159, 0.2300, 0.1614, 0.0702],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,133][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.3103, 0.1221, 0.0633, 0.0412, 0.0793, 0.1595, 0.1778, 0.0466],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,135][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.0733, 0.1604, 0.1305, 0.1001, 0.0500, 0.1036, 0.1461, 0.2358],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,140][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.0771, 0.0917, 0.1432, 0.1127, 0.1000, 0.2484, 0.1746, 0.0523],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,143][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.3221, 0.4775, 0.0226, 0.0800, 0.0402, 0.0132, 0.0153, 0.0290],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,144][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.3091, 0.2820, 0.0447, 0.0827, 0.0868, 0.0276, 0.0535, 0.1136],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,145][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.2060, 0.1472, 0.1130, 0.0929, 0.0783, 0.0845, 0.1209, 0.1571],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,146][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.0450, 0.0452, 0.4008, 0.0408, 0.0312, 0.1318, 0.2604, 0.0448],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,146][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4121, 0.0099, 0.0064, 0.0116, 0.0079, 0.0749, 0.3750, 0.0046, 0.0974],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:40,148][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([1.4996e-04, 7.5762e-02, 3.2505e-01, 6.8367e-02, 1.4795e-02, 4.4365e-02,
        5.2780e-02, 3.8274e-01, 3.5990e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:40,152][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1201, 0.0816, 0.0840, 0.0508, 0.0752, 0.1413, 0.1648, 0.1154, 0.1669],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:40,157][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0728, 0.2612, 0.1872, 0.1056, 0.0568, 0.0670, 0.0822, 0.0504, 0.1166],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:40,158][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0986, 0.1925, 0.1624, 0.1171, 0.0823, 0.0966, 0.1093, 0.0517, 0.0895],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:40,159][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2451, 0.1099, 0.0819, 0.0597, 0.0938, 0.1142, 0.1030, 0.0535, 0.1390],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:40,159][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0461, 0.1416, 0.1127, 0.0635, 0.0573, 0.1466, 0.1345, 0.1394, 0.1583],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:40,160][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1503, 0.1616, 0.1783, 0.1199, 0.0724, 0.0937, 0.0819, 0.0616, 0.0802],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:40,163][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.2057, 0.5258, 0.0273, 0.1132, 0.0472, 0.0151, 0.0132, 0.0275, 0.0250],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:40,168][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2035, 0.2601, 0.0904, 0.1334, 0.0890, 0.0475, 0.0543, 0.0601, 0.0617],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:40,171][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1488, 0.1421, 0.1538, 0.0976, 0.0802, 0.0919, 0.1043, 0.0760, 0.1052],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:40,172][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0271, 0.0941, 0.2325, 0.0780, 0.0436, 0.1445, 0.1647, 0.0360, 0.1795],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:40,173][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Jonathan] are: tensor([0.1755, 0.0122, 0.0177, 0.0143, 0.0116, 0.1330, 0.3607, 0.0050, 0.0976,
        0.1723], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:40,173][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Jonathan] are: tensor([1.5385e-04, 3.9223e-02, 4.4377e-01, 5.6116e-02, 2.4265e-02, 8.3177e-02,
        7.9731e-02, 2.2124e-01, 4.0190e-02, 1.2129e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:40,174][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Jonathan] are: tensor([0.0719, 0.1117, 0.1079, 0.0965, 0.0685, 0.0976, 0.1028, 0.1410, 0.0887,
        0.1133], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:40,177][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Jonathan] are: tensor([0.0210, 0.1505, 0.1404, 0.0738, 0.0411, 0.0880, 0.1107, 0.2142, 0.1128,
        0.0474], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:40,181][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Jonathan] are: tensor([0.0177, 0.0799, 0.1817, 0.0988, 0.0774, 0.1693, 0.1224, 0.1100, 0.1097,
        0.0330], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:40,185][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Jonathan] are: tensor([0.0850, 0.0857, 0.0863, 0.0699, 0.0644, 0.1251, 0.1194, 0.1009, 0.1795,
        0.0839], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:40,186][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Jonathan] are: tensor([0.0156, 0.0934, 0.1267, 0.0758, 0.0455, 0.1842, 0.1401, 0.1503, 0.1225,
        0.0460], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:40,186][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Jonathan] are: tensor([0.0238, 0.1065, 0.1440, 0.1400, 0.0632, 0.1587, 0.1184, 0.1197, 0.0853,
        0.0405], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:40,187][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Jonathan] are: tensor([0.0809, 0.2970, 0.0952, 0.1504, 0.0924, 0.0608, 0.0529, 0.0581, 0.0464,
        0.0659], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:40,188][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Jonathan] are: tensor([0.0954, 0.1943, 0.1110, 0.1465, 0.0963, 0.0700, 0.0757, 0.0686, 0.0565,
        0.0858], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:40,191][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Jonathan] are: tensor([0.0593, 0.1211, 0.1231, 0.1108, 0.0773, 0.1209, 0.1078, 0.1062, 0.0917,
        0.0818], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:40,195][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Jonathan] are: tensor([0.0161, 0.0855, 0.2454, 0.0973, 0.0507, 0.1453, 0.1419, 0.0664, 0.0956,
        0.0558], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:40,199][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.2606, 0.0051, 0.0056, 0.0041, 0.0038, 0.0898, 0.3954, 0.0022, 0.0841,
        0.1381, 0.0112], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:40,200][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([3.5666e-04, 1.1685e-01, 4.3387e-01, 5.8341e-02, 1.7002e-02, 2.7539e-02,
        5.5175e-02, 2.0842e-01, 3.7447e-02, 1.2355e-02, 3.2642e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:40,200][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0948, 0.0655, 0.0576, 0.0435, 0.0430, 0.0888, 0.1064, 0.0926, 0.1247,
        0.1046, 0.1785], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:40,201][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0742, 0.2550, 0.0768, 0.0650, 0.0467, 0.0500, 0.0727, 0.0938, 0.1301,
        0.0596, 0.0762], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:40,202][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0735, 0.2668, 0.1218, 0.1056, 0.0654, 0.1183, 0.0790, 0.0224, 0.0487,
        0.0260, 0.0725], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:40,206][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.1537, 0.1608, 0.0769, 0.0553, 0.0672, 0.1236, 0.0758, 0.0321, 0.1270,
        0.0395, 0.0880], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:40,211][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0463, 0.1366, 0.0599, 0.0545, 0.0265, 0.0911, 0.0939, 0.1543, 0.1635,
        0.0549, 0.1186], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:40,213][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0765, 0.2783, 0.1353, 0.1476, 0.0590, 0.0917, 0.0508, 0.0182, 0.0368,
        0.0270, 0.0789], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:40,213][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.3134, 0.4476, 0.0145, 0.0649, 0.0304, 0.0110, 0.0094, 0.0170, 0.0179,
        0.0493, 0.0245], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:40,214][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.1510, 0.4208, 0.0354, 0.0920, 0.0603, 0.0245, 0.0259, 0.0424, 0.0281,
        0.0591, 0.0604], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:40,215][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.1039, 0.1443, 0.0890, 0.0610, 0.0559, 0.0650, 0.0768, 0.1081, 0.0815,
        0.0573, 0.1574], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:40,216][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0282, 0.0665, 0.2151, 0.0480, 0.0254, 0.1445, 0.1497, 0.0244, 0.1918,
        0.0391, 0.0675], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:40,219][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1810, 0.0039, 0.0062, 0.0054, 0.0046, 0.0784, 0.2683, 0.0018, 0.0652,
        0.1098, 0.0126, 0.2628], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:40,223][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([3.5619e-04, 5.3996e-02, 4.2208e-01, 5.5592e-02, 2.2363e-02, 5.7126e-02,
        7.5428e-02, 2.0660e-01, 4.1717e-02, 1.4111e-02, 3.8432e-02, 1.2203e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:40,226][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0558, 0.0662, 0.0878, 0.0479, 0.0484, 0.0936, 0.0859, 0.1350, 0.0967,
        0.0729, 0.1385, 0.0712], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:40,227][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0496, 0.1564, 0.0952, 0.0644, 0.0418, 0.0661, 0.0967, 0.1094, 0.1102,
        0.0616, 0.0935, 0.0551], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:40,228][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0275, 0.0897, 0.1604, 0.0715, 0.0676, 0.1324, 0.0769, 0.0675, 0.0758,
        0.0284, 0.1468, 0.0554], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:40,229][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0900, 0.0948, 0.0821, 0.0550, 0.0684, 0.1195, 0.0781, 0.0492, 0.1046,
        0.0533, 0.1513, 0.0538], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:40,229][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0280, 0.1041, 0.1233, 0.0698, 0.0373, 0.1101, 0.1163, 0.0931, 0.1056,
        0.0551, 0.0934, 0.0640], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:40,233][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0460, 0.1236, 0.1776, 0.1167, 0.0697, 0.1080, 0.0654, 0.0409, 0.0590,
        0.0314, 0.1159, 0.0458], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:40,237][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1540, 0.3293, 0.0580, 0.0922, 0.0682, 0.0303, 0.0264, 0.0378, 0.0389,
        0.0612, 0.0610, 0.0426], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:40,240][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1008, 0.1987, 0.0975, 0.1105, 0.0708, 0.0546, 0.0686, 0.0571, 0.0478,
        0.0665, 0.0710, 0.0561], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:40,241][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0774, 0.0822, 0.1037, 0.0633, 0.0618, 0.1005, 0.0933, 0.0619, 0.0816,
        0.0598, 0.1255, 0.0890], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:40,242][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0247, 0.0594, 0.2297, 0.0603, 0.0393, 0.1104, 0.1348, 0.0461, 0.1159,
        0.0432, 0.0707, 0.0654], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:40,243][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.1840, 0.0022, 0.0044, 0.0033, 0.0036, 0.0723, 0.2744, 0.0014, 0.0781,
        0.1037, 0.0108, 0.2476, 0.0142], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:40,243][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([1.9854e-04, 8.3816e-02, 3.2580e-01, 5.2134e-02, 1.3523e-02, 3.3742e-02,
        4.4555e-02, 3.0880e-01, 2.8660e-02, 1.1653e-02, 5.0603e-02, 7.4844e-03,
        3.9025e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:40,247][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.0501, 0.0417, 0.0778, 0.0373, 0.0350, 0.0908, 0.0905, 0.1032, 0.0991,
        0.0725, 0.1552, 0.0659, 0.0809], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:40,252][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.0178, 0.1536, 0.1044, 0.0424, 0.0290, 0.0455, 0.0676, 0.1861, 0.0886,
        0.0339, 0.1250, 0.0339, 0.0724], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:40,254][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.0122, 0.0310, 0.0934, 0.0429, 0.0537, 0.1597, 0.0977, 0.0784, 0.0752,
        0.0231, 0.2529, 0.0638, 0.0159], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:40,255][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.0480, 0.0335, 0.0543, 0.0261, 0.0423, 0.1288, 0.1238, 0.0480, 0.1156,
        0.0415, 0.2633, 0.0573, 0.0176], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:40,256][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.0156, 0.0999, 0.0971, 0.0515, 0.0259, 0.0971, 0.1112, 0.1259, 0.1046,
        0.0437, 0.1085, 0.0449, 0.0742], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:40,257][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.0143, 0.0380, 0.1054, 0.0846, 0.0585, 0.1405, 0.1176, 0.0671, 0.0586,
        0.0280, 0.2270, 0.0501, 0.0103], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:40,258][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.1525, 0.3037, 0.0466, 0.1011, 0.0537, 0.0225, 0.0279, 0.0372, 0.0329,
        0.0776, 0.0693, 0.0453, 0.0298], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:40,261][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.0800, 0.1573, 0.0780, 0.0677, 0.0672, 0.0370, 0.0573, 0.1092, 0.0447,
        0.0562, 0.1277, 0.0503, 0.0674], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:40,266][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.0432, 0.0564, 0.0793, 0.0439, 0.0509, 0.0768, 0.0801, 0.0975, 0.0729,
        0.0472, 0.2229, 0.0763, 0.0526], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:40,268][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.0120, 0.0236, 0.2167, 0.0300, 0.0207, 0.1028, 0.1827, 0.0567, 0.1302,
        0.0351, 0.1041, 0.0615, 0.0239], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:40,269][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1495, 0.0051, 0.0061, 0.0072, 0.0062, 0.0622, 0.2073, 0.0026, 0.0541,
        0.1029, 0.0120, 0.2231, 0.0186, 0.1432], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:40,270][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.6059e-04, 5.2523e-02, 3.6601e-01, 5.9706e-02, 1.9790e-02, 5.9049e-02,
        6.6055e-02, 2.3789e-01, 3.7604e-02, 1.4020e-02, 3.5234e-02, 8.4617e-03,
        3.4387e-02, 9.0126e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:40,270][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0526, 0.0566, 0.0706, 0.0413, 0.0444, 0.0877, 0.0725, 0.1055, 0.0947,
        0.0636, 0.1017, 0.0617, 0.0757, 0.0712], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:40,272][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0322, 0.1370, 0.1147, 0.0650, 0.0407, 0.0617, 0.0834, 0.0844, 0.0915,
        0.0523, 0.0879, 0.0461, 0.0493, 0.0536], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:40,277][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0357, 0.0663, 0.1252, 0.0618, 0.0648, 0.1325, 0.0815, 0.0533, 0.0854,
        0.0315, 0.1207, 0.0627, 0.0205, 0.0580], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:40,281][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1220, 0.0584, 0.0612, 0.0420, 0.0636, 0.0937, 0.0654, 0.0357, 0.0966,
        0.0493, 0.1452, 0.0573, 0.0260, 0.0836], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:40,282][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0162, 0.0595, 0.1046, 0.0497, 0.0330, 0.1280, 0.1181, 0.0772, 0.1047,
        0.0381, 0.0962, 0.0502, 0.0569, 0.0676], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:40,283][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0829, 0.0746, 0.1236, 0.0862, 0.0621, 0.1044, 0.0637, 0.0484, 0.0653,
        0.0379, 0.1184, 0.0549, 0.0197, 0.0580], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:40,284][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0980, 0.2503, 0.0607, 0.1000, 0.0671, 0.0372, 0.0306, 0.0556, 0.0497,
        0.0624, 0.0714, 0.0445, 0.0320, 0.0406], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:40,285][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0915, 0.1579, 0.0937, 0.0977, 0.0646, 0.0503, 0.0597, 0.0614, 0.0475,
        0.0630, 0.0764, 0.0486, 0.0418, 0.0460], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:40,288][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0607, 0.0709, 0.0972, 0.0588, 0.0521, 0.0891, 0.0784, 0.0658, 0.0710,
        0.0544, 0.1149, 0.0756, 0.0437, 0.0673], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:40,293][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0159, 0.0467, 0.2040, 0.0560, 0.0325, 0.1102, 0.1279, 0.0390, 0.1185,
        0.0395, 0.0673, 0.0578, 0.0263, 0.0583], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:40,296][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:16:40,297][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[4977],
        [9866],
        [  62],
        [  85],
        [  38],
        [   1],
        [   4],
        [ 357],
        [  11],
        [ 166],
        [  10],
        [  25],
        [ 306],
        [  20]], device='cuda:0')
[2024-07-24 10:16:40,299][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 3986],
        [18123],
        [   66],
        [  266],
        [   54],
        [    5],
        [   13],
        [  375],
        [   18],
        [  587],
        [   19],
        [   83],
        [  479],
        [   99]], device='cuda:0')
[2024-07-24 10:16:40,301][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 672],
        [1155],
        [2984],
        [2292],
        [4519],
        [5882],
        [6086],
        [7147],
        [7869],
        [5567],
        [8382],
        [8517],
        [7103],
        [9736]], device='cuda:0')
[2024-07-24 10:16:40,304][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[44143],
        [49984],
        [42087],
        [39235],
        [37767],
        [32107],
        [26664],
        [23317],
        [22401],
        [22939],
        [23284],
        [23489],
        [21940],
        [22200]], device='cuda:0')
[2024-07-24 10:16:40,307][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[15231],
        [17268],
        [20547],
        [21404],
        [19214],
        [19141],
        [18818],
        [18857],
        [18737],
        [19768],
        [19928],
        [19971],
        [18932],
        [18467]], device='cuda:0')
[2024-07-24 10:16:40,310][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[39740],
        [32298],
        [35618],
        [29961],
        [30807],
        [29869],
        [26871],
        [23470],
        [27642],
        [23338],
        [24341],
        [22682],
        [21987],
        [23049]], device='cuda:0')
[2024-07-24 10:16:40,312][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[31647],
        [16575],
        [18262],
        [25205],
        [25094],
        [29191],
        [31899],
        [33464],
        [30885],
        [33328],
        [28920],
        [31208],
        [31607],
        [32376]], device='cuda:0')
[2024-07-24 10:16:40,313][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 8499],
        [11925],
        [13696],
        [13260],
        [14867],
        [14400],
        [14904],
        [15336],
        [12812],
        [12508],
        [14973],
        [17134],
        [18766],
        [16454]], device='cuda:0')
[2024-07-24 10:16:40,314][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[10322],
        [  178],
        [  357],
        [  331],
        [  565],
        [  411],
        [  238],
        [  312],
        [  332],
        [  304],
        [  274],
        [  257],
        [  263],
        [  244]], device='cuda:0')
[2024-07-24 10:16:40,317][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[26900],
        [23262],
        [21457],
        [21482],
        [20077],
        [20969],
        [15273],
        [13069],
        [13146],
        [12398],
        [13808],
        [10603],
        [ 8044],
        [10200]], device='cuda:0')
[2024-07-24 10:16:40,319][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[35922],
        [46644],
        [46513],
        [47150],
        [47390],
        [47086],
        [47086],
        [46768],
        [46620],
        [45792],
        [46665],
        [45378],
        [44762],
        [43263]], device='cuda:0')
[2024-07-24 10:16:40,323][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[37523],
        [34990],
        [41026],
        [40240],
        [39556],
        [40519],
        [40642],
        [38810],
        [39578],
        [39603],
        [37874],
        [37928],
        [37611],
        [37780]], device='cuda:0')
[2024-07-24 10:16:40,326][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[13385],
        [16294],
        [11947],
        [11942],
        [11808],
        [ 4856],
        [ 8861],
        [11589],
        [ 8310],
        [ 4067],
        [ 7734],
        [ 9050],
        [10617],
        [ 4180]], device='cuda:0')
[2024-07-24 10:16:40,327][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 6328],
        [50253],
        [48449],
        [45943],
        [30564],
        [24727],
        [21090],
        [ 6495],
        [ 9961],
        [10929],
        [ 8166],
        [10369],
        [ 6439],
        [ 9011]], device='cuda:0')
[2024-07-24 10:16:40,328][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[26753],
        [ 3221],
        [ 8571],
        [ 1476],
        [ 4660],
        [ 6049],
        [ 7918],
        [13127],
        [ 7488],
        [ 3769],
        [13664],
        [ 7922],
        [20363],
        [ 6104]], device='cuda:0')
[2024-07-24 10:16:40,329][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[24890],
        [19562],
        [20735],
        [10467],
        [ 9904],
        [ 5121],
        [11117],
        [10995],
        [11822],
        [ 9311],
        [10496],
        [ 8433],
        [ 8714],
        [ 6240]], device='cuda:0')
[2024-07-24 10:16:40,332][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 3143],
        [ 6612],
        [16201],
        [15207],
        [15046],
        [14278],
        [14161],
        [13294],
        [12904],
        [13606],
        [13573],
        [13625],
        [12969],
        [13208]], device='cuda:0')
[2024-07-24 10:16:40,334][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[26204],
        [14545],
        [12985],
        [14139],
        [10404],
        [17969],
        [25274],
        [18767],
        [19059],
        [16387],
        [16649],
        [15680],
        [13206],
        [13467]], device='cuda:0')
[2024-07-24 10:16:40,338][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[38499],
        [10586],
        [ 7442],
        [10129],
        [11336],
        [11101],
        [ 9901],
        [10829],
        [ 9556],
        [ 8714],
        [ 8000],
        [ 7114],
        [ 5876],
        [ 6921]], device='cuda:0')
[2024-07-24 10:16:40,341][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[28715],
        [35674],
        [36940],
        [37108],
        [35896],
        [34517],
        [31966],
        [34631],
        [34425],
        [34585],
        [36601],
        [36991],
        [38102],
        [35052]], device='cuda:0')
[2024-07-24 10:16:40,342][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[39945],
        [35119],
        [31790],
        [31115],
        [27487],
        [31511],
        [26571],
        [20437],
        [16506],
        [10040],
        [14685],
        [11068],
        [ 7879],
        [10086]], device='cuda:0')
[2024-07-24 10:16:40,343][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[7101],
        [1354],
        [3478],
        [1868],
        [2116],
        [5275],
        [4851],
        [4701],
        [6617],
        [6401],
        [4503],
        [5273],
        [5265],
        [6286]], device='cuda:0')
[2024-07-24 10:16:40,345][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 2960],
        [29630],
        [33914],
        [28426],
        [26081],
        [16177],
        [30214],
        [31157],
        [31386],
        [31018],
        [31938],
        [30902],
        [30297],
        [29908]], device='cuda:0')
[2024-07-24 10:16:40,347][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 5557],
        [ 6338],
        [10236],
        [ 8543],
        [ 8413],
        [ 8976],
        [ 9411],
        [ 9839],
        [10602],
        [13462],
        [10268],
        [14213],
        [14721],
        [15816]], device='cuda:0')
[2024-07-24 10:16:40,350][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[16471],
        [ 9918],
        [ 7976],
        [ 6969],
        [ 7557],
        [ 7580],
        [ 7424],
        [ 7905],
        [ 7767],
        [ 7933],
        [ 7185],
        [ 7576],
        [ 7927],
        [ 7731]], device='cuda:0')
[2024-07-24 10:16:40,353][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 4109],
        [34836],
        [32618],
        [36414],
        [34234],
        [35996],
        [35346],
        [32881],
        [33275],
        [33897],
        [30235],
        [30824],
        [26885],
        [29495]], device='cuda:0')
[2024-07-24 10:16:40,356][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[18821],
        [ 9680],
        [14907],
        [14880],
        [13220],
        [12403],
        [11451],
        [12572],
        [10550],
        [11067],
        [10657],
        [10917],
        [10179],
        [10369]], device='cuda:0')
[2024-07-24 10:16:40,357][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[35833],
        [32352],
        [25785],
        [30427],
        [33637],
        [30854],
        [29740],
        [33507],
        [33517],
        [34490],
        [37333],
        [36577],
        [39545],
        [37711]], device='cuda:0')
[2024-07-24 10:16:40,358][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[23240],
        [45565],
        [42680],
        [47790],
        [47439],
        [44797],
        [40886],
        [40234],
        [42249],
        [44859],
        [35611],
        [39531],
        [30494],
        [42720]], device='cuda:0')
[2024-07-24 10:16:40,360][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[15000],
        [15000],
        [15000],
        [15000],
        [15000],
        [15000],
        [15000],
        [15000],
        [15000],
        [15000],
        [15000],
        [15000],
        [15000],
        [15000]], device='cuda:0')
[2024-07-24 10:16:40,450][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:40,451][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:40,452][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:40,452][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:40,453][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:40,454][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:40,454][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:40,455][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:40,456][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:40,456][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:40,457][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:40,458][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:40,458][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:40,459][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.6852, 0.3148], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,460][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.0663, 0.9337], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,460][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.1220, 0.8780], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,461][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.0651, 0.9349], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,462][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.0234, 0.9766], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,462][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.3924, 0.6076], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,465][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.2966, 0.7034], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,465][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.6977, 0.3023], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,466][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.6048, 0.3952], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,467][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.0066, 0.9934], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,467][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.0401, 0.9599], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,468][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.1751, 0.8249], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,471][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.6016, 0.3929, 0.0055], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,475][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0061, 0.3018, 0.6921], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,478][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0625, 0.3765, 0.5611], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,479][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0222, 0.7571, 0.2207], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,480][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0053, 0.3514, 0.6433], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,480][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0938, 0.6489, 0.2574], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,481][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2498, 0.3162, 0.4340], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,482][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2769, 0.3852, 0.3378], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,485][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7850, 0.2137, 0.0013], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,487][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([4.3356e-07, 1.7839e-03, 9.9822e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,492][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0294, 0.7205, 0.2500], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,493][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1122, 0.1829, 0.7049], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,493][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Jonathan] are: tensor([0.5177, 0.3379, 0.0134, 0.1310], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,494][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Jonathan] are: tensor([0.0136, 0.2646, 0.4326, 0.2893], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,495][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Jonathan] are: tensor([0.0183, 0.2012, 0.5398, 0.2407], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,497][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Jonathan] are: tensor([0.0095, 0.5572, 0.2447, 0.1887], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,501][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Jonathan] are: tensor([0.0055, 0.2324, 0.4106, 0.3515], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,505][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Jonathan] are: tensor([0.1620, 0.5980, 0.1441, 0.0960], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,506][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Jonathan] are: tensor([0.0260, 0.1754, 0.5617, 0.2370], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,507][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Jonathan] are: tensor([0.3975, 0.1714, 0.2714, 0.1597], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,508][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Jonathan] are: tensor([0.2302, 0.4099, 0.0099, 0.3501], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,508][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Jonathan] are: tensor([1.8330e-05, 6.1930e-03, 8.8279e-01, 1.1100e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,509][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Jonathan] are: tensor([0.0099, 0.4640, 0.2036, 0.3225], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,513][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Jonathan] are: tensor([0.0318, 0.1386, 0.3399, 0.4897], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,517][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.5401, 0.2920, 0.0188, 0.0745, 0.0745], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,519][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0147, 0.2748, 0.3801, 0.2329, 0.0975], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,520][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0161, 0.2178, 0.3940, 0.1994, 0.1727], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,521][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0068, 0.3322, 0.2388, 0.1255, 0.2967], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,521][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.0048, 0.1428, 0.2807, 0.2089, 0.3628], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,522][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.2083, 0.4423, 0.1755, 0.0571, 0.1168], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,525][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0216, 0.1919, 0.5831, 0.1152, 0.0882], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,529][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.2971, 0.1471, 0.3121, 0.1317, 0.1120], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,533][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.1878, 0.3993, 0.0179, 0.2635, 0.1316], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,533][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ went] are: tensor([9.1448e-06, 3.1888e-03, 9.3027e-01, 5.1605e-02, 1.4931e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,534][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0121, 0.3764, 0.1491, 0.2313, 0.2311], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,535][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0684, 0.0844, 0.2251, 0.3981, 0.2240], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,535][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.4598, 0.4569, 0.0058, 0.0399, 0.0278, 0.0098], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,538][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0105, 0.3029, 0.3605, 0.2272, 0.0493, 0.0497], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,541][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0183, 0.1845, 0.3059, 0.1861, 0.1144, 0.1907], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,546][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0135, 0.2750, 0.1313, 0.1328, 0.2522, 0.1952], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,547][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0039, 0.1200, 0.2491, 0.1835, 0.2260, 0.2176], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,548][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0726, 0.3615, 0.1124, 0.0413, 0.0744, 0.3378], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,548][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0611, 0.1898, 0.1525, 0.3008, 0.1262, 0.1696], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,549][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.2422, 0.1748, 0.1673, 0.0845, 0.0527, 0.2785], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,551][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2254, 0.3494, 0.0034, 0.2969, 0.1214, 0.0034], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,553][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.0701e-06, 2.7872e-03, 9.3039e-01, 2.7016e-02, 4.9795e-03, 3.4824e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,558][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0144, 0.3233, 0.1354, 0.2350, 0.1803, 0.1118], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,560][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0322, 0.0925, 0.2184, 0.3832, 0.2013, 0.0722], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,561][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.3292, 0.5496, 0.0115, 0.0628, 0.0299, 0.0096, 0.0074],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,561][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0171, 0.2815, 0.3341, 0.1974, 0.0427, 0.0440, 0.0833],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,562][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0229, 0.1380, 0.2471, 0.1654, 0.0890, 0.1410, 0.1966],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,563][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0034, 0.1942, 0.1107, 0.0672, 0.2862, 0.2671, 0.0711],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,566][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0015, 0.1037, 0.1850, 0.1532, 0.2673, 0.1781, 0.1112],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,570][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0763, 0.2725, 0.0831, 0.0275, 0.0428, 0.2323, 0.2655],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,574][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.3314, 0.1566, 0.0669, 0.2790, 0.0788, 0.0631, 0.0243],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,574][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1882, 0.1086, 0.1461, 0.0494, 0.0399, 0.2521, 0.2157],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,575][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ the] are: tensor([6.2969e-01, 2.3746e-01, 2.2375e-04, 1.0676e-01, 2.5530e-02, 1.7007e-04,
        1.7052e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,576][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ the] are: tensor([1.9233e-06, 3.3654e-03, 9.1413e-01, 2.3802e-02, 4.6747e-03, 3.5700e-02,
        1.8323e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,576][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0087, 0.2956, 0.1268, 0.1923, 0.1802, 0.1153, 0.0811],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,579][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0457, 0.0582, 0.2222, 0.2877, 0.3121, 0.0635, 0.0106],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,583][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.3191, 0.6062, 0.0052, 0.0384, 0.0178, 0.0038, 0.0052, 0.0043],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,587][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([0.0127, 0.2286, 0.2723, 0.1483, 0.0418, 0.0462, 0.1052, 0.1450],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,588][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.0160, 0.1052, 0.2396, 0.0981, 0.0657, 0.1306, 0.1364, 0.2084],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,589][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.0020, 0.1724, 0.1211, 0.0603, 0.2840, 0.2407, 0.0644, 0.0551],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,590][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.0015, 0.0839, 0.1275, 0.1223, 0.1789, 0.1344, 0.1004, 0.2510],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,590][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.0822, 0.2413, 0.0505, 0.0124, 0.0239, 0.1451, 0.1827, 0.2619],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,593][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.0151, 0.0396, 0.1744, 0.0877, 0.1131, 0.3022, 0.0666, 0.2013],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,598][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.1714, 0.0566, 0.0978, 0.0370, 0.0328, 0.2569, 0.2669, 0.0807],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,601][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.3402, 0.3580, 0.0039, 0.1742, 0.1055, 0.0030, 0.0114, 0.0039],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,602][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([3.9830e-07, 1.2216e-03, 9.1528e-01, 1.4687e-02, 3.3601e-03, 4.6296e-02,
        1.3885e-02, 5.2677e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,603][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.0060, 0.2360, 0.1141, 0.1518, 0.1357, 0.0970, 0.0862, 0.1731],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,604][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.0145, 0.0442, 0.3434, 0.0765, 0.2157, 0.0726, 0.0100, 0.2231],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,604][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2297, 0.6105, 0.0115, 0.0718, 0.0337, 0.0131, 0.0085, 0.0039, 0.0173],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:40,607][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0083, 0.2284, 0.2781, 0.1545, 0.0396, 0.0438, 0.0791, 0.1212, 0.0471],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:40,610][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0086, 0.1011, 0.1822, 0.0957, 0.0549, 0.1158, 0.1912, 0.1623, 0.0880],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:40,611][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0012, 0.1995, 0.0705, 0.0662, 0.2851, 0.2019, 0.0550, 0.0764, 0.0441],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:40,617][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0007, 0.0687, 0.1433, 0.0942, 0.1481, 0.1179, 0.0939, 0.1993, 0.1337],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:40,617][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0220, 0.1438, 0.0762, 0.0211, 0.0335, 0.1877, 0.1776, 0.1541, 0.1840],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:40,618][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0664, 0.1182, 0.0923, 0.1380, 0.0803, 0.1199, 0.0867, 0.2391, 0.0591],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:40,619][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0812, 0.0711, 0.0941, 0.0411, 0.0391, 0.2084, 0.1721, 0.0867, 0.2062],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:40,620][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4728, 0.2803, 0.0016, 0.1584, 0.0661, 0.0020, 0.0060, 0.0106, 0.0021],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:40,621][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([1.0464e-06, 3.2843e-03, 8.7885e-01, 3.0772e-02, 4.5494e-03, 4.5583e-02,
        1.9305e-02, 1.1902e-02, 5.7510e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:40,626][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0082, 0.2503, 0.0823, 0.1611, 0.1242, 0.0743, 0.0629, 0.1796, 0.0571],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:40,630][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0103, 0.0179, 0.0324, 0.1937, 0.1592, 0.0381, 0.0131, 0.5283, 0.0070],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:40,631][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Jonathan] are: tensor([0.1001, 0.3518, 0.0734, 0.1571, 0.0912, 0.0648, 0.0377, 0.0371, 0.0431,
        0.0436], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:40,632][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Jonathan] are: tensor([0.0059, 0.1611, 0.3132, 0.1837, 0.0539, 0.0782, 0.0715, 0.0672, 0.0337,
        0.0314], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:40,633][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Jonathan] are: tensor([0.0018, 0.0620, 0.3127, 0.0489, 0.0194, 0.1218, 0.1788, 0.1851, 0.0671,
        0.0024], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:40,634][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Jonathan] are: tensor([0.0004, 0.1666, 0.1022, 0.0341, 0.3022, 0.2099, 0.0645, 0.0528, 0.0642,
        0.0032], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:40,636][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Jonathan] are: tensor([0.0010, 0.0747, 0.1274, 0.1051, 0.1141, 0.1155, 0.0863, 0.1852, 0.1062,
        0.0844], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:40,641][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Jonathan] are: tensor([0.0181, 0.1704, 0.1041, 0.0478, 0.0356, 0.1444, 0.1101, 0.2748, 0.0794,
        0.0151], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:40,644][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Jonathan] are: tensor([0.0015, 0.0510, 0.1686, 0.0704, 0.0370, 0.1665, 0.1307, 0.2484, 0.1134,
        0.0126], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:40,645][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Jonathan] are: tensor([0.0446, 0.0438, 0.0763, 0.0317, 0.0362, 0.2134, 0.1782, 0.1291, 0.1810,
        0.0659], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:40,646][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Jonathan] are: tensor([0.0766, 0.4534, 0.0230, 0.2141, 0.0750, 0.0191, 0.0240, 0.0368, 0.0071,
        0.0708], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:40,647][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Jonathan] are: tensor([1.0976e-05, 5.7395e-03, 6.9525e-01, 7.0250e-02, 1.7535e-02, 1.1664e-01,
        5.6028e-02, 2.3701e-02, 9.7866e-03, 5.0586e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:40,647][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Jonathan] are: tensor([0.0017, 0.1935, 0.0997, 0.1230, 0.1156, 0.0800, 0.0729, 0.1858, 0.0630,
        0.0648], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:40,650][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Jonathan] are: tensor([0.0036, 0.0545, 0.3083, 0.1216, 0.0954, 0.0888, 0.0307, 0.1409, 0.0980,
        0.0580], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:40,655][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.1901, 0.6813, 0.0058, 0.0446, 0.0213, 0.0059, 0.0049, 0.0021, 0.0091,
        0.0199, 0.0149], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:40,658][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0081, 0.2262, 0.2085, 0.1093, 0.0294, 0.0625, 0.1038, 0.0927, 0.0584,
        0.0309, 0.0702], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:40,659][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0134, 0.1225, 0.1675, 0.1047, 0.0639, 0.1016, 0.1107, 0.1385, 0.0762,
        0.0222, 0.0789], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:40,660][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0012, 0.1895, 0.1158, 0.0531, 0.1899, 0.2263, 0.0598, 0.0598, 0.0699,
        0.0063, 0.0284], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:40,661][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0011, 0.0600, 0.1048, 0.0827, 0.1187, 0.0998, 0.0821, 0.1646, 0.0931,
        0.0744, 0.1185], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:40,661][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0395, 0.4617, 0.0689, 0.0199, 0.0208, 0.1087, 0.0851, 0.0953, 0.0585,
        0.0072, 0.0344], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:40,664][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0224, 0.0729, 0.0904, 0.0683, 0.0503, 0.1646, 0.0668, 0.1279, 0.1149,
        0.0210, 0.2005], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:40,669][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0757, 0.0569, 0.0690, 0.0182, 0.0191, 0.2259, 0.0874, 0.0401, 0.2201,
        0.0292, 0.1584], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:40,672][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.1025, 0.6463, 0.0099, 0.0988, 0.0627, 0.0046, 0.0116, 0.0030, 0.0025,
        0.0326, 0.0255], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:40,673][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([1.3768e-06, 3.4905e-03, 8.8157e-01, 3.1386e-02, 3.2524e-03, 4.4549e-02,
        2.0427e-02, 5.1457e-03, 5.5843e-03, 1.3643e-03, 3.2295e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:40,674][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0037, 0.2123, 0.0948, 0.1231, 0.1162, 0.0790, 0.0582, 0.1324, 0.0593,
        0.0521, 0.0690], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:40,674][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0067, 0.0376, 0.1299, 0.1045, 0.1247, 0.0497, 0.0078, 0.1919, 0.0273,
        0.1262, 0.1938], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:40,675][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1466, 0.4474, 0.0436, 0.0764, 0.0605, 0.0314, 0.0264, 0.0139, 0.0273,
        0.0341, 0.0465, 0.0460], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:40,678][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0075, 0.1101, 0.2382, 0.1168, 0.0494, 0.0763, 0.1021, 0.0985, 0.0536,
        0.0360, 0.0692, 0.0423], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:40,683][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0064, 0.0839, 0.1985, 0.0707, 0.0469, 0.1049, 0.1677, 0.1341, 0.0890,
        0.0086, 0.0608, 0.0285], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:40,686][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0005, 0.1682, 0.1031, 0.0371, 0.2487, 0.2649, 0.0416, 0.0436, 0.0556,
        0.0034, 0.0272, 0.0060], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:40,687][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0008, 0.0465, 0.0967, 0.0648, 0.1164, 0.0936, 0.0733, 0.1849, 0.0946,
        0.0565, 0.1277, 0.0440], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:40,688][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0309, 0.1270, 0.0920, 0.0216, 0.0329, 0.1752, 0.1247, 0.1961, 0.1108,
        0.0114, 0.0550, 0.0227], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:40,688][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0165, 0.0559, 0.1690, 0.0559, 0.0769, 0.1149, 0.0562, 0.2274, 0.0595,
        0.0169, 0.1192, 0.0316], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:40,689][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0460, 0.0421, 0.0704, 0.0240, 0.0244, 0.1506, 0.1115, 0.0749, 0.1249,
        0.0458, 0.1823, 0.1031], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:40,693][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2825, 0.2731, 0.0075, 0.1367, 0.0732, 0.0058, 0.0070, 0.0190, 0.0065,
        0.1138, 0.0382, 0.0366], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:40,696][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([4.2746e-06, 3.9127e-03, 8.3675e-01, 2.5041e-02, 6.7271e-03, 6.3801e-02,
        3.1756e-02, 1.1732e-02, 7.7765e-03, 2.0862e-03, 7.4422e-03, 2.9733e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:40,700][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0030, 0.2214, 0.1100, 0.1086, 0.1142, 0.0934, 0.0502, 0.1198, 0.0591,
        0.0393, 0.0551, 0.0259], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:40,700][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0131, 0.0611, 0.1344, 0.1410, 0.0797, 0.0420, 0.0088, 0.3050, 0.0273,
        0.1440, 0.0308, 0.0129], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:40,701][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.1414, 0.4710, 0.0415, 0.0728, 0.0476, 0.0163, 0.0160, 0.0121, 0.0222,
        0.0307, 0.0760, 0.0403, 0.0120], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:40,702][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.0052, 0.1106, 0.2552, 0.0858, 0.0316, 0.0765, 0.0958, 0.1010, 0.0754,
        0.0317, 0.0733, 0.0336, 0.0242], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:40,703][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.0050, 0.0900, 0.2527, 0.0617, 0.0269, 0.1204, 0.1156, 0.1328, 0.0785,
        0.0050, 0.0502, 0.0174, 0.0438], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:40,707][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0006, 0.1866, 0.0920, 0.0512, 0.2987, 0.1970, 0.0374, 0.0293, 0.0495,
        0.0036, 0.0329, 0.0066, 0.0146], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:40,712][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.0007, 0.0552, 0.0815, 0.0792, 0.1033, 0.0846, 0.0602, 0.1349, 0.0798,
        0.0601, 0.1134, 0.0562, 0.0910], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:40,714][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.0178, 0.0741, 0.0731, 0.0109, 0.0190, 0.1962, 0.1351, 0.2313, 0.0997,
        0.0063, 0.0969, 0.0145, 0.0250], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:40,714][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.0080, 0.0747, 0.1631, 0.0746, 0.0621, 0.1194, 0.0680, 0.0705, 0.0963,
        0.0084, 0.1576, 0.0352, 0.0620], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:40,715][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.0238, 0.0151, 0.0702, 0.0143, 0.0152, 0.1284, 0.1312, 0.0764, 0.1203,
        0.0374, 0.2425, 0.0983, 0.0269], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:40,716][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.1980, 0.2181, 0.0055, 0.1671, 0.1824, 0.0032, 0.0204, 0.0140, 0.0023,
        0.0613, 0.0570, 0.0577, 0.0129], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:40,717][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([2.4146e-06, 3.6142e-03, 8.1809e-01, 2.6536e-02, 7.1349e-03, 7.7833e-02,
        2.8847e-02, 1.4070e-02, 7.3937e-03, 1.3367e-03, 1.0199e-02, 2.3135e-03,
        2.6269e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:40,720][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.0027, 0.1874, 0.0868, 0.1098, 0.0906, 0.0713, 0.0474, 0.1040, 0.0541,
        0.0395, 0.0629, 0.0298, 0.1138], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:40,725][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0075, 0.0419, 0.3320, 0.0523, 0.1168, 0.0781, 0.0186, 0.0432, 0.0842,
        0.0242, 0.1009, 0.0228, 0.0775], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:40,727][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1281, 0.4220, 0.0349, 0.0672, 0.0485, 0.0310, 0.0191, 0.0189, 0.0311,
        0.0376, 0.0629, 0.0421, 0.0173, 0.0394], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:40,728][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0057, 0.1132, 0.2385, 0.1085, 0.0400, 0.0630, 0.0838, 0.1164, 0.0523,
        0.0301, 0.0642, 0.0343, 0.0278, 0.0222], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:40,729][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0023, 0.0683, 0.2382, 0.0525, 0.0253, 0.1177, 0.1920, 0.1357, 0.0754,
        0.0033, 0.0389, 0.0173, 0.0262, 0.0070], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:40,730][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0008, 0.1744, 0.0978, 0.0454, 0.2489, 0.2112, 0.0411, 0.0669, 0.0443,
        0.0029, 0.0288, 0.0059, 0.0233, 0.0082], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:40,732][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0008, 0.0430, 0.0865, 0.0620, 0.0837, 0.0759, 0.0592, 0.1616, 0.0856,
        0.0541, 0.0974, 0.0489, 0.0896, 0.0516], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:40,736][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0209, 0.1179, 0.0891, 0.0180, 0.0292, 0.1654, 0.1211, 0.1710, 0.1172,
        0.0097, 0.0572, 0.0200, 0.0236, 0.0398], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:40,741][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0024, 0.0579, 0.1067, 0.0748, 0.0531, 0.0994, 0.0587, 0.1388, 0.0663,
        0.0179, 0.1108, 0.0226, 0.1782, 0.0125], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:40,742][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0370, 0.0389, 0.0715, 0.0231, 0.0240, 0.1204, 0.0885, 0.0558, 0.1030,
        0.0381, 0.1746, 0.0859, 0.0393, 0.0999], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:40,743][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1062, 0.2286, 0.0150, 0.1716, 0.0900, 0.0093, 0.0098, 0.0308, 0.0120,
        0.1330, 0.0840, 0.0430, 0.0414, 0.0252], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:40,743][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([4.2817e-06, 5.0149e-03, 7.9230e-01, 3.6590e-02, 9.3474e-03, 6.4060e-02,
        3.2120e-02, 2.3261e-02, 8.7813e-03, 2.6952e-03, 1.6090e-02, 3.1014e-03,
        5.2556e-03, 1.3763e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:40,744][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0026, 0.1768, 0.0794, 0.1292, 0.0890, 0.0533, 0.0391, 0.1268, 0.0429,
        0.0455, 0.0442, 0.0187, 0.1275, 0.0250], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:40,748][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0048, 0.0308, 0.1387, 0.0852, 0.0651, 0.0530, 0.0174, 0.1430, 0.0352,
        0.0726, 0.0466, 0.0163, 0.2651, 0.0262], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:40,851][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:40,852][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:40,852][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:40,853][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:40,854][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:40,855][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:40,856][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:40,856][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:40,857][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:40,858][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:40,858][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:40,859][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:40,860][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:40,860][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.6852, 0.3148], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,861][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.0663, 0.9337], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,862][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.7591, 0.2409], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,862][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.8210, 0.1790], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,866][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.2036, 0.7964], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,870][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.5183, 0.4817], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,872][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.0243, 0.9757], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,873][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.6977, 0.3023], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,873][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.7793, 0.2207], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,874][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.0066, 0.9934], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,875][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.3305, 0.6695], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,877][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.0467, 0.9533], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:40,881][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6016, 0.3929, 0.0055], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,885][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0061, 0.3018, 0.6921], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,886][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.7466, 0.2430, 0.0104], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,887][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.7080, 0.2892, 0.0028], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,888][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0360, 0.2504, 0.7136], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,888][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2550, 0.5348, 0.2102], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,889][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([8.7027e-05, 3.0432e-02, 9.6948e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,892][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2769, 0.3852, 0.3378], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,897][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.4495, 0.4974, 0.0531], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,899][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([4.3356e-07, 1.7839e-03, 9.9822e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,900][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1786, 0.7874, 0.0340], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,901][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([7.7262e-04, 1.0486e-01, 8.9437e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:40,901][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Jonathan] are: tensor([0.5177, 0.3379, 0.0134, 0.1310], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,902][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Jonathan] are: tensor([0.0136, 0.2646, 0.4326, 0.2893], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,904][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Jonathan] are: tensor([0.4685, 0.2317, 0.0305, 0.2692], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,908][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Jonathan] are: tensor([0.8309, 0.0841, 0.0133, 0.0717], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,913][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Jonathan] are: tensor([0.0165, 0.1238, 0.6261, 0.2336], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,913][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Jonathan] are: tensor([0.2880, 0.4654, 0.1462, 0.1005], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,914][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Jonathan] are: tensor([2.5027e-04, 1.8413e-02, 8.9215e-01, 8.9189e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,915][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Jonathan] are: tensor([0.3975, 0.1714, 0.2714, 0.1597], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,915][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Jonathan] are: tensor([0.3030, 0.1929, 0.1011, 0.4030], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,916][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Jonathan] are: tensor([1.8330e-05, 6.1930e-03, 8.8279e-01, 1.1100e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,920][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Jonathan] are: tensor([0.2836, 0.2473, 0.1135, 0.3555], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,924][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Jonathan] are: tensor([0.0021, 0.1211, 0.5459, 0.3310], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:40,926][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.5401, 0.2920, 0.0188, 0.0745, 0.0745], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,927][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0147, 0.2748, 0.3801, 0.2329, 0.0975], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,928][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.4532, 0.2461, 0.0263, 0.1625, 0.1119], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,929][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.8111, 0.0493, 0.0221, 0.0484, 0.0691], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,929][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.0261, 0.1416, 0.5948, 0.1482, 0.0893], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,932][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.2943, 0.3640, 0.1575, 0.0701, 0.1141], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,934][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([2.9629e-04, 2.2932e-02, 8.5488e-01, 8.1259e-02, 4.0631e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,940][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.2971, 0.1471, 0.3121, 0.1317, 0.1120], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,941][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.2384, 0.2420, 0.1211, 0.2519, 0.1466], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,941][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([9.1448e-06, 3.1888e-03, 9.3027e-01, 5.1605e-02, 1.4931e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,942][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.4004, 0.2329, 0.0767, 0.1702, 0.1199], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,943][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.0024, 0.0643, 0.5861, 0.2521, 0.0951], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:40,945][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.4598, 0.4569, 0.0058, 0.0399, 0.0278, 0.0098], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,949][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0105, 0.3029, 0.3605, 0.2272, 0.0493, 0.0497], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,953][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.5334, 0.2639, 0.0083, 0.1141, 0.0662, 0.0141], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,954][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.9284, 0.0182, 0.0066, 0.0187, 0.0199, 0.0082], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,955][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0366, 0.1520, 0.5186, 0.1113, 0.0400, 0.1416], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,956][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1853, 0.3376, 0.0951, 0.0527, 0.0825, 0.2468], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,956][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.5165e-04, 5.2327e-02, 6.4560e-01, 8.3238e-02, 2.4593e-02, 1.9409e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,958][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.2422, 0.1748, 0.1673, 0.0845, 0.0527, 0.2785], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,962][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2268, 0.3600, 0.0521, 0.2054, 0.0936, 0.0622], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,965][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.0701e-06, 2.7872e-03, 9.3039e-01, 2.7016e-02, 4.9795e-03, 3.4824e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,967][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.5783, 0.1520, 0.0602, 0.1101, 0.0454, 0.0540], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,968][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0006, 0.0640, 0.5640, 0.1826, 0.0431, 0.1457], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:40,969][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.3292, 0.5496, 0.0115, 0.0628, 0.0299, 0.0096, 0.0074],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,969][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0171, 0.2815, 0.3341, 0.1974, 0.0427, 0.0440, 0.0833],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,970][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.3811, 0.3453, 0.0169, 0.1446, 0.0780, 0.0187, 0.0154],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,973][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.8536, 0.0056, 0.0080, 0.0098, 0.0269, 0.0538, 0.0423],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,977][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0188, 0.2219, 0.3756, 0.1259, 0.0410, 0.0858, 0.1308],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,981][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1636, 0.2613, 0.0870, 0.0400, 0.0575, 0.2009, 0.1897],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,982][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([1.0932e-04, 3.6560e-02, 6.8163e-01, 5.9450e-02, 1.9638e-02, 1.6078e-01,
        4.1831e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,982][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1882, 0.1086, 0.1461, 0.0494, 0.0399, 0.2521, 0.2157],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,983][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1921, 0.3508, 0.0595, 0.2519, 0.0806, 0.0374, 0.0277],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,984][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([1.9233e-06, 3.3654e-03, 9.1413e-01, 2.3802e-02, 4.6747e-03, 3.5700e-02,
        1.8323e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,986][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.4002, 0.0323, 0.0796, 0.0597, 0.0677, 0.1998, 0.1606],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,990][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0009, 0.1104, 0.4864, 0.2089, 0.0432, 0.1038, 0.0463],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:40,995][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.3191, 0.6062, 0.0052, 0.0384, 0.0178, 0.0038, 0.0052, 0.0043],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,995][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([0.0127, 0.2286, 0.2723, 0.1483, 0.0418, 0.0462, 0.1052, 0.1450],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,996][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([0.5044, 0.2428, 0.0081, 0.1300, 0.0738, 0.0149, 0.0164, 0.0096],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,997][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.6422, 0.0013, 0.0036, 0.0050, 0.0317, 0.1084, 0.1577, 0.0501],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:40,998][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.0039, 0.0905, 0.2713, 0.0540, 0.0214, 0.0602, 0.1098, 0.3889],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,001][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.1313, 0.1982, 0.0517, 0.0193, 0.0331, 0.1372, 0.1411, 0.2880],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,003][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([7.3578e-05, 2.1208e-02, 5.5258e-01, 6.3577e-02, 1.7384e-02, 2.8289e-01,
        4.6775e-02, 1.5509e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,009][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.1714, 0.0566, 0.0978, 0.0370, 0.0328, 0.2569, 0.2669, 0.0807],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,009][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.3848, 0.2601, 0.0190, 0.2276, 0.0702, 0.0113, 0.0189, 0.0082],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,010][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([3.9830e-07, 1.2216e-03, 9.1528e-01, 1.4687e-02, 3.3601e-03, 4.6296e-02,
        1.3885e-02, 5.2677e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,011][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.2040, 0.0311, 0.0231, 0.0544, 0.0688, 0.2190, 0.2630, 0.1367],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,012][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([1.7996e-04, 7.0922e-02, 3.6147e-01, 2.5415e-01, 3.2660e-02, 8.1964e-02,
        2.7722e-02, 1.7093e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,014][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2297, 0.6105, 0.0115, 0.0718, 0.0337, 0.0131, 0.0085, 0.0039, 0.0173],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,018][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0083, 0.2284, 0.2781, 0.1545, 0.0396, 0.0438, 0.0791, 0.1212, 0.0471],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,022][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2896, 0.3802, 0.0121, 0.1658, 0.0901, 0.0186, 0.0167, 0.0059, 0.0210],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,023][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6547, 0.0159, 0.0130, 0.0147, 0.0332, 0.0495, 0.0511, 0.0302, 0.1377],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,024][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0051, 0.0838, 0.3572, 0.0551, 0.0224, 0.0873, 0.1107, 0.1396, 0.1387],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,025][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0563, 0.1486, 0.0814, 0.0302, 0.0440, 0.1669, 0.1354, 0.1828, 0.1543],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,026][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([7.5560e-05, 3.9365e-02, 6.2920e-01, 5.4204e-02, 1.8266e-02, 1.8774e-01,
        3.9591e-02, 1.8902e-02, 1.2656e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,028][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0812, 0.0711, 0.0941, 0.0411, 0.0391, 0.2084, 0.1721, 0.0867, 0.2062],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,033][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1840, 0.2951, 0.0485, 0.1862, 0.0798, 0.0654, 0.0609, 0.0277, 0.0524],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,036][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([1.0464e-06, 3.2843e-03, 8.7885e-01, 3.0772e-02, 4.5494e-03, 4.5583e-02,
        1.9305e-02, 1.1902e-02, 5.7510e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,037][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.3017, 0.0943, 0.0942, 0.0989, 0.0654, 0.0937, 0.0989, 0.0439, 0.1090],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,038][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([2.5722e-04, 5.0069e-02, 3.2288e-01, 2.0237e-01, 3.2238e-02, 8.3419e-02,
        4.2697e-02, 2.1606e-01, 5.0009e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,039][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Jonathan] are: tensor([0.1001, 0.3518, 0.0734, 0.1571, 0.0912, 0.0648, 0.0377, 0.0371, 0.0431,
        0.0436], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,039][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Jonathan] are: tensor([0.0059, 0.1611, 0.3132, 0.1837, 0.0539, 0.0782, 0.0715, 0.0672, 0.0337,
        0.0314], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,042][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Jonathan] are: tensor([0.0833, 0.1901, 0.0791, 0.1970, 0.1376, 0.1041, 0.0492, 0.0395, 0.0630,
        0.0570], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,047][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Jonathan] are: tensor([0.1621, 0.0116, 0.0234, 0.0194, 0.0499, 0.0994, 0.1467, 0.1521, 0.2647,
        0.0705], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,050][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Jonathan] are: tensor([0.0017, 0.0624, 0.3603, 0.0796, 0.0250, 0.1081, 0.0876, 0.1773, 0.0793,
        0.0186], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,051][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Jonathan] are: tensor([0.0358, 0.1411, 0.0965, 0.0466, 0.0427, 0.1428, 0.0979, 0.2940, 0.0807,
        0.0218], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,052][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Jonathan] are: tensor([7.8212e-05, 1.7318e-02, 5.2622e-01, 6.0870e-02, 2.1111e-02, 2.6737e-01,
        5.6659e-02, 2.7785e-02, 1.7960e-02, 4.6262e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,053][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Jonathan] are: tensor([0.0446, 0.0438, 0.0763, 0.0317, 0.0362, 0.2134, 0.1782, 0.1291, 0.1810,
        0.0659], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,053][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Jonathan] are: tensor([0.0686, 0.1763, 0.0900, 0.2066, 0.0975, 0.0953, 0.0689, 0.0575, 0.0418,
        0.0974], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,055][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Jonathan] are: tensor([1.0976e-05, 5.7395e-03, 6.9525e-01, 7.0250e-02, 1.7535e-02, 1.1664e-01,
        5.6028e-02, 2.3701e-02, 9.7866e-03, 5.0586e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,059][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Jonathan] are: tensor([0.0377, 0.0214, 0.0896, 0.0580, 0.0569, 0.1568, 0.2178, 0.1555, 0.1529,
        0.0535], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,064][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Jonathan] are: tensor([0.0005, 0.1006, 0.3822, 0.1889, 0.0375, 0.0810, 0.0381, 0.1002, 0.0395,
        0.0316], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,065][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.1901, 0.6813, 0.0058, 0.0446, 0.0213, 0.0059, 0.0049, 0.0021, 0.0091,
        0.0199, 0.0149], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,066][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0081, 0.2262, 0.2085, 0.1093, 0.0294, 0.0625, 0.1038, 0.0927, 0.0584,
        0.0309, 0.0702], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,066][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.2319, 0.5201, 0.0079, 0.1072, 0.0553, 0.0113, 0.0080, 0.0053, 0.0124,
        0.0197, 0.0210], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,067][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.5737, 0.0147, 0.0147, 0.0108, 0.0317, 0.0856, 0.0469, 0.0098, 0.1403,
        0.0200, 0.0519], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,070][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0063, 0.1226, 0.2168, 0.0492, 0.0218, 0.0515, 0.0899, 0.1550, 0.1676,
        0.0288, 0.0905], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,075][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0787, 0.3215, 0.0758, 0.0277, 0.0294, 0.1073, 0.0797, 0.1359, 0.0669,
        0.0137, 0.0636], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,078][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([8.3451e-05, 5.3822e-02, 5.5077e-01, 6.6217e-02, 1.6002e-02, 2.0929e-01,
        4.2050e-02, 1.1850e-02, 1.7638e-02, 2.6322e-03, 2.9648e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,079][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0757, 0.0569, 0.0690, 0.0182, 0.0191, 0.2259, 0.0874, 0.0401, 0.2201,
        0.0292, 0.1584], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,080][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.1161, 0.3848, 0.0471, 0.1388, 0.0686, 0.0435, 0.0399, 0.0119, 0.0270,
        0.0471, 0.0752], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,080][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([1.3768e-06, 3.4905e-03, 8.8157e-01, 3.1386e-02, 3.2524e-03, 4.4549e-02,
        2.0427e-02, 5.1457e-03, 5.5843e-03, 1.3643e-03, 3.2295e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,081][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.2262, 0.0950, 0.0437, 0.0795, 0.0476, 0.1529, 0.0879, 0.0147, 0.0785,
        0.0433, 0.1307], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,083][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([1.8134e-04, 4.7129e-02, 2.1346e-01, 1.6078e-01, 3.5830e-02, 5.0154e-02,
        1.7976e-02, 1.3864e-01, 2.3670e-02, 2.2982e-02, 2.8920e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,087][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1466, 0.4474, 0.0436, 0.0764, 0.0605, 0.0314, 0.0264, 0.0139, 0.0273,
        0.0341, 0.0465, 0.0460], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,092][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0075, 0.1101, 0.2382, 0.1168, 0.0494, 0.0763, 0.1021, 0.0985, 0.0536,
        0.0360, 0.0692, 0.0423], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,092][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1398, 0.2650, 0.0448, 0.1433, 0.0987, 0.0512, 0.0338, 0.0266, 0.0407,
        0.0457, 0.0607, 0.0498], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,093][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.2884, 0.0159, 0.0285, 0.0206, 0.0504, 0.1046, 0.0643, 0.0234, 0.1514,
        0.0433, 0.1126, 0.0965], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,094][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0040, 0.0593, 0.2577, 0.0379, 0.0192, 0.0914, 0.0944, 0.1938, 0.1131,
        0.0199, 0.0880, 0.0215], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,095][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0501, 0.1113, 0.0820, 0.0256, 0.0380, 0.1512, 0.1006, 0.2205, 0.0970,
        0.0168, 0.0765, 0.0303], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,097][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([1.0087e-04, 2.0604e-02, 5.2610e-01, 4.2696e-02, 2.0048e-02, 2.4443e-01,
        5.6682e-02, 2.1642e-02, 2.1068e-02, 2.8560e-03, 3.7581e-02, 6.1872e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,101][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0460, 0.0421, 0.0704, 0.0240, 0.0244, 0.1506, 0.1115, 0.0749, 0.1249,
        0.0458, 0.1823, 0.1031], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,105][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0729, 0.2310, 0.0713, 0.1555, 0.0712, 0.0542, 0.0449, 0.0345, 0.0404,
        0.0752, 0.0926, 0.0564], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,106][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([4.2746e-06, 3.9127e-03, 8.3675e-01, 2.5041e-02, 6.7271e-03, 6.3801e-02,
        3.1756e-02, 1.1732e-02, 7.7765e-03, 2.0862e-03, 7.4422e-03, 2.9733e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,107][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0557, 0.0333, 0.1490, 0.0538, 0.0472, 0.1624, 0.1064, 0.0326, 0.0856,
        0.0287, 0.1796, 0.0657], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,108][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0005, 0.0496, 0.3479, 0.1211, 0.0319, 0.0856, 0.0431, 0.1213, 0.0477,
        0.0218, 0.1162, 0.0133], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,109][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.1414, 0.4710, 0.0415, 0.0728, 0.0476, 0.0163, 0.0160, 0.0121, 0.0222,
        0.0307, 0.0760, 0.0403, 0.0120], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,111][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.0052, 0.1106, 0.2552, 0.0858, 0.0316, 0.0765, 0.0958, 0.1010, 0.0754,
        0.0317, 0.0733, 0.0336, 0.0242], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,116][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.1392, 0.2138, 0.0436, 0.1655, 0.1063, 0.0493, 0.0277, 0.0301, 0.0339,
        0.0416, 0.0871, 0.0454, 0.0166], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,119][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([7.7569e-02, 2.8916e-04, 4.1489e-03, 1.4501e-03, 1.2014e-02, 6.5180e-02,
        9.1289e-02, 5.5719e-02, 1.6025e-01, 2.3585e-02, 3.5870e-01, 1.3475e-01,
        1.5060e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,120][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.0015, 0.0579, 0.2905, 0.0390, 0.0205, 0.1086, 0.0704, 0.1863, 0.1038,
        0.0104, 0.0697, 0.0129, 0.0285], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,121][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.0327, 0.0741, 0.0690, 0.0159, 0.0254, 0.1529, 0.1016, 0.2407, 0.0860,
        0.0115, 0.1240, 0.0224, 0.0437], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,122][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([4.6603e-05, 2.1515e-02, 5.5306e-01, 4.3590e-02, 1.4602e-02, 2.3800e-01,
        4.0985e-02, 2.0014e-02, 1.7774e-02, 1.9475e-03, 4.1336e-02, 3.8994e-03,
        3.2267e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,123][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.0238, 0.0151, 0.0702, 0.0143, 0.0152, 0.1284, 0.1312, 0.0764, 0.1203,
        0.0374, 0.2425, 0.0983, 0.0269], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,126][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.0912, 0.1422, 0.0663, 0.1794, 0.0750, 0.0476, 0.0363, 0.0318, 0.0265,
        0.0773, 0.1295, 0.0615, 0.0353], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,130][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([2.4146e-06, 3.6142e-03, 8.1809e-01, 2.6536e-02, 7.1349e-03, 7.7833e-02,
        2.8847e-02, 1.4070e-02, 7.3937e-03, 1.3367e-03, 1.0199e-02, 2.3135e-03,
        2.6269e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,133][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.0156, 0.0023, 0.0175, 0.0098, 0.0167, 0.0756, 0.0959, 0.0596, 0.0649,
        0.0206, 0.5495, 0.0626, 0.0093], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,134][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([2.1864e-04, 6.9073e-02, 3.7102e-01, 1.1877e-01, 3.0181e-02, 6.7915e-02,
        2.0964e-02, 1.1726e-01, 3.7198e-02, 1.4516e-02, 1.2528e-01, 6.8264e-03,
        2.0787e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,135][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1281, 0.4220, 0.0349, 0.0672, 0.0485, 0.0310, 0.0191, 0.0189, 0.0311,
        0.0376, 0.0629, 0.0421, 0.0173, 0.0394], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:41,136][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0057, 0.1132, 0.2385, 0.1085, 0.0400, 0.0630, 0.0838, 0.1164, 0.0523,
        0.0301, 0.0642, 0.0343, 0.0278, 0.0222], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:41,136][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1265, 0.2173, 0.0354, 0.1288, 0.0896, 0.0573, 0.0344, 0.0272, 0.0482,
        0.0468, 0.0727, 0.0542, 0.0190, 0.0426], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:41,140][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.3675, 0.0068, 0.0164, 0.0124, 0.0323, 0.0629, 0.0365, 0.0183, 0.1200,
        0.0368, 0.0717, 0.0850, 0.0143, 0.1190], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:41,145][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0028, 0.0443, 0.2336, 0.0393, 0.0196, 0.1075, 0.0884, 0.1783, 0.1029,
        0.0187, 0.0894, 0.0189, 0.0363, 0.0201], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:41,147][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0383, 0.1048, 0.0796, 0.0226, 0.0351, 0.1395, 0.0958, 0.1774, 0.0990,
        0.0152, 0.0737, 0.0278, 0.0392, 0.0519], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:41,148][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.0201e-04, 3.5836e-02, 4.8980e-01, 7.1463e-02, 2.4112e-02, 2.0254e-01,
        4.7992e-02, 3.0059e-02, 1.9084e-02, 4.1221e-03, 5.9134e-02, 5.5293e-03,
        5.7200e-03, 4.5129e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:41,149][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0370, 0.0389, 0.0715, 0.0231, 0.0240, 0.1204, 0.0885, 0.0558, 0.1030,
        0.0381, 0.1746, 0.0859, 0.0393, 0.0999], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:41,150][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0628, 0.1661, 0.0676, 0.1337, 0.0752, 0.0560, 0.0432, 0.0362, 0.0407,
        0.0764, 0.0873, 0.0551, 0.0424, 0.0572], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:41,151][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([4.2817e-06, 5.0149e-03, 7.9230e-01, 3.6590e-02, 9.3474e-03, 6.4060e-02,
        3.2120e-02, 2.3261e-02, 8.7813e-03, 2.6952e-03, 1.6090e-02, 3.1014e-03,
        5.2556e-03, 1.3763e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:41,154][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0970, 0.0227, 0.0968, 0.0383, 0.0437, 0.1183, 0.0821, 0.0310, 0.0840,
        0.0348, 0.1735, 0.0795, 0.0133, 0.0851], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:41,159][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0005, 0.0522, 0.2769, 0.1296, 0.0339, 0.0888, 0.0417, 0.1281, 0.0523,
        0.0247, 0.1012, 0.0132, 0.0442, 0.0127], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:41,162][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:16:41,164][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[13625],
        [    3],
        [ 5805],
        [  194],
        [29592],
        [ 1314],
        [ 5946],
        [15223],
        [ 2668],
        [  418],
        [24745],
        [15657],
        [21319],
        [ 3116]], device='cuda:0')
[2024-07-24 10:16:41,166][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[12815],
        [   10],
        [ 9773],
        [  354],
        [34584],
        [ 2624],
        [ 8872],
        [19727],
        [ 3860],
        [  621],
        [32015],
        [18826],
        [25252],
        [ 4129]], device='cuda:0')
[2024-07-24 10:16:41,169][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[39020],
        [41720],
        [40893],
        [39759],
        [38748],
        [38697],
        [37772],
        [38232],
        [36745],
        [28868],
        [37276],
        [32134],
        [33579],
        [30851]], device='cuda:0')
[2024-07-24 10:16:41,172][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[16897],
        [26340],
        [37701],
        [41193],
        [39334],
        [38458],
        [37878],
        [39700],
        [39062],
        [38911],
        [36725],
        [37679],
        [37139],
        [38337]], device='cuda:0')
[2024-07-24 10:16:41,175][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[24634],
        [  224],
        [ 2234],
        [ 3346],
        [ 3193],
        [ 3796],
        [ 5116],
        [ 6200],
        [ 6533],
        [ 8672],
        [ 4816],
        [ 6526],
        [ 5723],
        [ 7048]], device='cuda:0')
[2024-07-24 10:16:41,177][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[39010],
        [10138],
        [13351],
        [13266],
        [22049],
        [21755],
        [24972],
        [25264],
        [24367],
        [26045],
        [23915],
        [25303],
        [25500],
        [25065]], device='cuda:0')
[2024-07-24 10:16:41,178][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[676],
        [ 89],
        [154],
        [ 59],
        [130],
        [128],
        [165],
        [178],
        [235],
        [156],
        [211],
        [306],
        [364],
        [438]], device='cuda:0')
[2024-07-24 10:16:41,179][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[45143],
        [ 3836],
        [ 2320],
        [ 2284],
        [ 2472],
        [ 4633],
        [ 8363],
        [19402],
        [19152],
        [18577],
        [ 7725],
        [19658],
        [24361],
        [20678]], device='cuda:0')
[2024-07-24 10:16:41,181][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[37894],
        [  917],
        [25058],
        [34412],
        [37044],
        [26856],
        [22408],
        [40226],
        [32334],
        [38685],
        [33703],
        [36798],
        [36485],
        [36152]], device='cuda:0')
[2024-07-24 10:16:41,184][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[15366],
        [20916],
        [31179],
        [32490],
        [34765],
        [36095],
        [38318],
        [35486],
        [33012],
        [30520],
        [30854],
        [28121],
        [26292],
        [25617]], device='cuda:0')
[2024-07-24 10:16:41,187][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[727],
        [  2],
        [  3],
        [ 13],
        [ 15],
        [ 15],
        [  8],
        [  9],
        [  9],
        [ 15],
        [  6],
        [ 15],
        [ 40],
        [ 39]], device='cuda:0')
[2024-07-24 10:16:41,190][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[20665],
        [50256],
        [18311],
        [21050],
        [19138],
        [17559],
        [17050],
        [16608],
        [17034],
        [14246],
        [16937],
        [15912],
        [15623],
        [16562]], device='cuda:0')
[2024-07-24 10:16:41,192][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[8796],
        [ 819],
        [1228],
        [1730],
        [1981],
        [2322],
        [2509],
        [3037],
        [2897],
        [3212],
        [2907],
        [2912],
        [3105],
        [3162]], device='cuda:0')
[2024-07-24 10:16:41,193][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[39126],
        [ 7745],
        [27188],
        [14187],
        [21825],
        [22764],
        [29109],
        [34692],
        [30833],
        [30130],
        [32059],
        [25809],
        [35564],
        [33906]], device='cuda:0')
[2024-07-24 10:16:41,194][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[20336],
        [11143],
        [19099],
        [15503],
        [19435],
        [22919],
        [20614],
        [17364],
        [18341],
        [14681],
        [15533],
        [15275],
        [22370],
        [22353]], device='cuda:0')
[2024-07-24 10:16:41,196][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[15660],
        [48533],
        [47561],
        [46672],
        [47059],
        [45942],
        [44403],
        [44340],
        [43331],
        [41285],
        [43242],
        [42306],
        [42326],
        [42042]], device='cuda:0')
[2024-07-24 10:16:41,199][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[39916],
        [ 7807],
        [35472],
        [34025],
        [34162],
        [32342],
        [31260],
        [32393],
        [32359],
        [33136],
        [27960],
        [29849],
        [29666],
        [30352]], device='cuda:0')
[2024-07-24 10:16:41,202][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[29757],
        [18076],
        [18787],
        [13591],
        [15251],
        [15952],
        [17596],
        [15967],
        [18280],
        [17326],
        [21619],
        [21591],
        [22192],
        [23387]], device='cuda:0')
[2024-07-24 10:16:41,205][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 2129],
        [ 3309],
        [ 4764],
        [ 2062],
        [ 1609],
        [ 1736],
        [ 1081],
        [ 1830],
        [ 1821],
        [14618],
        [ 2185],
        [ 9038],
        [17198],
        [ 5636]], device='cuda:0')
[2024-07-24 10:16:41,207][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[17821],
        [19789],
        [24474],
        [26867],
        [25318],
        [25023],
        [23744],
        [27677],
        [24767],
        [26211],
        [24710],
        [24827],
        [25431],
        [24840]], device='cuda:0')
[2024-07-24 10:16:41,208][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[30520],
        [27016],
        [20153],
        [22813],
        [20217],
        [23841],
        [25390],
        [16023],
        [20778],
        [15680],
        [18497],
        [16689],
        [14940],
        [16992]], device='cuda:0')
[2024-07-24 10:16:41,209][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 4669],
        [ 5396],
        [11627],
        [ 9630],
        [ 9691],
        [ 7655],
        [ 8277],
        [ 6936],
        [ 7508],
        [ 6662],
        [ 6418],
        [ 6307],
        [ 6270],
        [ 5240]], device='cuda:0')
[2024-07-24 10:16:41,211][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[11582],
        [  762],
        [   81],
        [  132],
        [  234],
        [ 1248],
        [ 7232],
        [15159],
        [13028],
        [15785],
        [13898],
        [15794],
        [20443],
        [16761]], device='cuda:0')
[2024-07-24 10:16:41,214][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[29331],
        [33500],
        [39414],
        [41075],
        [39033],
        [41534],
        [41533],
        [41140],
        [40874],
        [37267],
        [42964],
        [41070],
        [39754],
        [40744]], device='cuda:0')
[2024-07-24 10:16:41,217][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[40527],
        [  434],
        [17064],
        [18368],
        [17421],
        [16692],
        [16536],
        [16358],
        [16296],
        [15327],
        [16418],
        [16078],
        [15909],
        [16184]], device='cuda:0')
[2024-07-24 10:16:41,220][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 7083],
        [10497],
        [12033],
        [15765],
        [15736],
        [16285],
        [37754],
        [39614],
        [33928],
        [38912],
        [29281],
        [32899],
        [21597],
        [32465]], device='cuda:0')
[2024-07-24 10:16:41,221][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[16862],
        [ 6645],
        [18234],
        [10911],
        [12651],
        [13433],
        [11965],
        [ 9875],
        [10193],
        [10384],
        [ 8356],
        [11026],
        [11099],
        [ 9650]], device='cuda:0')
[2024-07-24 10:16:41,223][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[33426],
        [39102],
        [27986],
        [28645],
        [29065],
        [26690],
        [18758],
        [16213],
        [17939],
        [15631],
        [19572],
        [15895],
        [17643],
        [16785]], device='cuda:0')
[2024-07-24 10:16:41,224][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[24782],
        [45214],
        [17734],
        [26764],
        [24499],
        [13654],
        [16743],
        [22937],
        [20390],
        [28720],
        [18180],
        [27740],
        [15880],
        [23995]], device='cuda:0')
[2024-07-24 10:16:41,226][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[2552],
        [2552],
        [2552],
        [2552],
        [2552],
        [2552],
        [2552],
        [2552],
        [2552],
        [2552],
        [2552],
        [2552],
        [2552],
        [2552]], device='cuda:0')
[2024-07-24 10:16:41,335][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:41,338][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:41,339][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:41,339][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:41,340][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:41,341][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:41,341][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:41,342][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:41,343][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:41,343][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:41,345][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:41,346][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:41,346][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:41,347][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.0774, 0.9226], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:41,348][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.0011, 0.9989], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:41,348][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:41,349][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.7961, 0.2039], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:41,350][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.9189, 0.0811], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:41,350][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.2021, 0.7979], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:41,351][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.0242, 0.9758], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:41,352][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.8698, 0.1302], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:41,353][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.2056, 0.7944], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:41,353][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.5992, 0.4008], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:41,354][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.0051, 0.9949], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:41,355][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.1598, 0.8402], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:41,360][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0377, 0.7788, 0.1835], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:41,360][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0043, 0.9327, 0.0630], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:41,361][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1460, 0.2667, 0.5873], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:41,362][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1128, 0.6761, 0.2112], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:41,362][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.7788, 0.0518, 0.1694], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:41,363][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3349, 0.6380, 0.0271], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:41,366][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0038, 0.9843, 0.0119], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:41,371][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3676, 0.3326, 0.2998], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:41,373][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([5.2994e-04, 2.9412e-02, 9.7006e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:41,374][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.9323, 0.0630, 0.0047], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:41,375][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0015, 0.4393, 0.5592], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:41,376][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0192, 0.2590, 0.7218], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:41,376][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Jonathan] are: tensor([0.0035, 0.5009, 0.1606, 0.3349], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:41,377][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Jonathan] are: tensor([2.7283e-04, 9.1442e-01, 7.3492e-02, 1.1816e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:41,381][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Jonathan] are: tensor([0.2342, 0.1352, 0.2937, 0.3369], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:41,385][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Jonathan] are: tensor([0.2808, 0.2601, 0.1361, 0.3230], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:41,387][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Jonathan] are: tensor([0.2957, 0.0563, 0.3797, 0.2682], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:41,388][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Jonathan] are: tensor([0.2348, 0.0873, 0.0912, 0.5867], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:41,389][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Jonathan] are: tensor([0.0020, 0.8632, 0.0064, 0.1285], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:41,390][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Jonathan] are: tensor([0.6899, 0.1410, 0.0397, 0.1295], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:41,390][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Jonathan] are: tensor([0.0048, 0.1060, 0.6696, 0.2197], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:41,391][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Jonathan] are: tensor([9.9420e-01, 2.5019e-04, 4.4083e-04, 5.1085e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:41,393][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Jonathan] are: tensor([3.2020e-04, 5.5802e-02, 9.2766e-01, 1.6219e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:41,398][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Jonathan] are: tensor([0.0059, 0.2718, 0.3695, 0.3528], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:41,401][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0046, 0.4657, 0.1964, 0.2380, 0.0954], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:41,402][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ went] are: tensor([4.6985e-04, 6.8325e-01, 2.4168e-01, 5.3276e-02, 2.1333e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:41,403][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0728, 0.1072, 0.1855, 0.4063, 0.2282], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:41,403][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.1926, 0.2204, 0.1595, 0.1713, 0.2562], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:41,404][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.1823, 0.0861, 0.3653, 0.1639, 0.2024], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:41,406][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.3699, 0.0612, 0.0904, 0.1550, 0.3235], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:41,410][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0041, 0.7740, 0.0130, 0.1687, 0.0402], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:41,415][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.4225, 0.2294, 0.0928, 0.1013, 0.1540], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:41,416][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0033, 0.0592, 0.7226, 0.1325, 0.0825], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:41,416][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ went] are: tensor([9.9580e-01, 1.5277e-05, 6.5817e-05, 2.7886e-04, 3.8418e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:41,417][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ went] are: tensor([2.9037e-04, 1.4772e-02, 9.6779e-01, 1.3562e-02, 3.5818e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:41,418][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0130, 0.1468, 0.2885, 0.1944, 0.3573], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:41,419][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0048, 0.6029, 0.0567, 0.2501, 0.0606, 0.0248], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:41,422][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0009, 0.6996, 0.0608, 0.1031, 0.1095, 0.0260], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:41,427][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0286, 0.0485, 0.2327, 0.2303, 0.1835, 0.2765], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:41,429][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0624, 0.5520, 0.0830, 0.1265, 0.1380, 0.0381], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:41,430][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.2125, 0.0651, 0.2575, 0.1595, 0.1321, 0.1733], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:41,430][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.5957, 0.0693, 0.0473, 0.0711, 0.1234, 0.0932], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:41,431][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([7.3349e-04, 8.4033e-01, 5.2318e-03, 1.1552e-01, 3.1205e-02, 6.9797e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:41,432][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0570, 0.3664, 0.0777, 0.2821, 0.1019, 0.1149], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:41,434][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([1.3582e-04, 1.3718e-02, 8.6995e-01, 4.5036e-02, 1.6579e-02, 5.4579e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:41,436][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.9902e-01, 8.4575e-06, 1.3445e-05, 3.0923e-05, 2.4068e-04, 6.8334e-04],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:41,441][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0005, 0.2889, 0.2911, 0.1628, 0.0241, 0.2327], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:41,443][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0167, 0.1323, 0.2440, 0.2327, 0.2554, 0.1189], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:41,443][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0835, 0.5196, 0.0715, 0.2314, 0.0477, 0.0305, 0.0159],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:41,444][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0124, 0.6947, 0.0765, 0.0999, 0.0414, 0.0254, 0.0498],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:41,445][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1022, 0.0460, 0.2357, 0.1863, 0.1388, 0.2002, 0.0908],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:41,446][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0445, 0.5499, 0.1028, 0.1094, 0.1323, 0.0373, 0.0238],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:41,448][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1621, 0.0410, 0.3078, 0.1398, 0.0918, 0.1737, 0.0838],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:41,453][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.3565, 0.0008, 0.0158, 0.0063, 0.0538, 0.2233, 0.3435],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:41,456][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0057, 0.7482, 0.0125, 0.1683, 0.0413, 0.0100, 0.0139],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:41,457][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0293, 0.5068, 0.1051, 0.1397, 0.0426, 0.0714, 0.1053],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:41,458][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ the] are: tensor([1.9171e-04, 1.2969e-02, 8.8001e-01, 3.0931e-02, 1.1177e-02, 4.5666e-02,
        1.9053e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:41,459][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ the] are: tensor([9.7740e-01, 4.9237e-09, 3.9151e-07, 3.0113e-07, 1.0350e-05, 4.1490e-04,
        2.2177e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:41,459][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0012, 0.1042, 0.3028, 0.0773, 0.0170, 0.1923, 0.3052],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:41,462][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0066, 0.0966, 0.2307, 0.1706, 0.2416, 0.1481, 0.1057],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:41,465][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.0017, 0.3780, 0.0512, 0.2358, 0.0339, 0.0208, 0.0138, 0.2648],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,470][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([0.0008, 0.4530, 0.0552, 0.1597, 0.0308, 0.0347, 0.0186, 0.2472],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,471][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.1284, 0.0486, 0.0974, 0.1259, 0.0931, 0.0999, 0.0623, 0.3443],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,472][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.0731, 0.3459, 0.1699, 0.1442, 0.1167, 0.0787, 0.0355, 0.0360],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,473][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.0842, 0.0222, 0.2291, 0.1152, 0.0623, 0.1499, 0.0929, 0.2441],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,473][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([5.8404e-02, 3.2386e-05, 1.7579e-03, 6.3464e-04, 1.4681e-02, 1.5432e-01,
        6.9097e-01, 7.9201e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,475][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.0031, 0.6366, 0.0064, 0.1576, 0.0205, 0.0083, 0.0090, 0.1585],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,479][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.0498, 0.3472, 0.0805, 0.1803, 0.0726, 0.0374, 0.0696, 0.1625],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,484][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.0027, 0.1532, 0.4975, 0.0802, 0.0521, 0.1245, 0.0419, 0.0478],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,485][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([4.6008e-01, 1.4433e-09, 1.2245e-06, 3.2435e-07, 2.3873e-05, 3.4445e-03,
        5.2056e-01, 1.5896e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,486][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([5.2446e-05, 5.2367e-03, 1.1915e-01, 2.6639e-03, 8.5398e-04, 1.3358e-01,
        7.3811e-01, 3.5538e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,486][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.0008, 0.1156, 0.2328, 0.0865, 0.1884, 0.1639, 0.1169, 0.0951],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,487][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0075, 0.3444, 0.0355, 0.1653, 0.0429, 0.0207, 0.0273, 0.3426, 0.0137],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,489][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0025, 0.4688, 0.0187, 0.0774, 0.0328, 0.0190, 0.0291, 0.3472, 0.0045],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,493][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0709, 0.0507, 0.1613, 0.1960, 0.1053, 0.1027, 0.0828, 0.1805, 0.0499],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,498][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0435, 0.5773, 0.0728, 0.1277, 0.0974, 0.0261, 0.0180, 0.0182, 0.0190],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,499][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0385, 0.0244, 0.1845, 0.0734, 0.0649, 0.1205, 0.0586, 0.2593, 0.1759],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,500][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1313, 0.0050, 0.0310, 0.0165, 0.0560, 0.1579, 0.2568, 0.0282, 0.3172],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,500][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([1.0812e-03, 7.1908e-01, 2.0282e-03, 7.6504e-02, 1.1646e-02, 2.5036e-03,
        3.7632e-03, 1.8297e-01, 4.2408e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,501][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0164, 0.4460, 0.0485, 0.1569, 0.0566, 0.0538, 0.0813, 0.0611, 0.0794],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,503][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([1.6652e-04, 1.2143e-02, 8.2157e-01, 4.4690e-02, 1.8131e-02, 4.6244e-02,
        1.6543e-02, 1.8987e-02, 2.1524e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,505][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([9.5529e-01, 4.0522e-08, 1.0632e-06, 7.4507e-07, 1.2905e-05, 3.3622e-04,
        8.7305e-03, 3.0496e-04, 3.5326e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,508][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([5.0140e-04, 1.0587e-01, 8.6145e-02, 4.2793e-02, 5.8121e-03, 6.6901e-02,
        1.4422e-01, 1.9135e-02, 5.2862e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,512][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0030, 0.0505, 0.1294, 0.1059, 0.1133, 0.0762, 0.0720, 0.3945, 0.0551],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,513][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Jonathan] are: tensor([2.4489e-04, 3.8586e-01, 6.5966e-02, 1.6291e-01, 3.6668e-02, 2.9167e-02,
        4.6637e-02, 1.6617e-01, 1.8598e-02, 8.7783e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,513][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Jonathan] are: tensor([1.5403e-04, 6.6674e-01, 8.0830e-02, 1.1831e-02, 3.5693e-02, 2.1799e-02,
        5.1889e-02, 1.0587e-01, 2.2414e-02, 2.7777e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,514][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Jonathan] are: tensor([0.0611, 0.0339, 0.1305, 0.0801, 0.0801, 0.1477, 0.0609, 0.3102, 0.0412,
        0.0543], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,515][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Jonathan] are: tensor([0.0223, 0.2961, 0.1145, 0.2372, 0.1679, 0.0732, 0.0254, 0.0182, 0.0185,
        0.0266], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,518][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Jonathan] are: tensor([0.0187, 0.0141, 0.3594, 0.0604, 0.0399, 0.1543, 0.0491, 0.1284, 0.1338,
        0.0421], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,520][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Jonathan] are: tensor([6.3041e-03, 2.2333e-04, 9.5770e-03, 2.9503e-03, 1.6235e-02, 9.1108e-02,
        3.1471e-01, 2.2293e-01, 3.0670e-01, 2.9258e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,523][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Jonathan] are: tensor([4.3549e-04, 7.4777e-01, 3.8974e-03, 6.0706e-02, 1.5038e-02, 5.9051e-03,
        1.9496e-02, 1.2639e-01, 6.2892e-04, 1.9730e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,526][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Jonathan] are: tensor([0.0190, 0.4277, 0.0826, 0.1636, 0.0776, 0.0437, 0.0522, 0.0612, 0.0430,
        0.0294], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,526][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Jonathan] are: tensor([6.0992e-04, 5.2270e-02, 6.2129e-01, 1.0945e-01, 3.1969e-02, 1.0636e-01,
        2.8098e-02, 2.2211e-02, 1.9642e-02, 8.0950e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,527][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Jonathan] are: tensor([1.5944e-01, 1.3104e-08, 3.1959e-06, 1.5653e-06, 6.1867e-05, 2.7286e-03,
        2.2950e-01, 2.3609e-02, 5.7470e-01, 9.9616e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,528][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Jonathan] are: tensor([1.6600e-05, 2.0762e-03, 4.2227e-02, 6.2952e-04, 2.4354e-04, 1.5226e-02,
        1.0334e-01, 8.2357e-05, 8.3559e-01, 5.7475e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,529][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Jonathan] are: tensor([3.4328e-05, 8.7165e-02, 1.7420e-01, 8.2421e-02, 2.0655e-01, 1.4768e-01,
        1.5803e-01, 9.8623e-02, 3.9836e-02, 5.4569e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,532][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0030, 0.2361, 0.0287, 0.1655, 0.0291, 0.0109, 0.0104, 0.3656, 0.0080,
        0.1093, 0.0335], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,536][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0028, 0.5290, 0.0225, 0.1092, 0.0296, 0.0155, 0.0201, 0.1414, 0.0039,
        0.0380, 0.0881], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,540][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.1012, 0.0318, 0.0859, 0.0999, 0.0746, 0.0898, 0.0624, 0.2294, 0.0319,
        0.0856, 0.1075], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,540][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0131, 0.4258, 0.0999, 0.1693, 0.0826, 0.0454, 0.0237, 0.0205, 0.0282,
        0.0260, 0.0653], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,541][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0155, 0.0302, 0.2125, 0.0664, 0.0336, 0.1611, 0.0428, 0.1152, 0.2109,
        0.0370, 0.0749], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,542][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.1802, 0.0011, 0.0076, 0.0035, 0.0260, 0.1410, 0.1290, 0.0076, 0.1739,
        0.0207, 0.3093], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,543][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([1.9516e-03, 5.5171e-01, 1.6356e-03, 1.4670e-01, 1.1766e-02, 1.9116e-03,
        2.4563e-03, 2.0608e-01, 2.9568e-04, 6.5514e-02, 9.9751e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,545][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0158, 0.6136, 0.0476, 0.0594, 0.0263, 0.0182, 0.0280, 0.0340, 0.0572,
        0.0172, 0.0828], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,548][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([5.8105e-04, 7.5564e-02, 6.6600e-01, 6.0300e-02, 2.4826e-02, 7.1261e-02,
        2.2874e-02, 2.0808e-02, 3.5391e-02, 4.5047e-03, 1.7893e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,551][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([7.8603e-01, 6.9854e-09, 8.8609e-07, 3.3080e-07, 1.0783e-05, 1.0739e-03,
        4.4185e-02, 8.8597e-04, 1.1704e-01, 8.3972e-04, 4.9932e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,553][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([5.1006e-05, 7.7846e-04, 4.3288e-02, 7.5077e-04, 4.1988e-04, 2.3711e-02,
        1.2286e-01, 2.4215e-04, 8.0340e-01, 6.0928e-04, 3.8958e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,554][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0017, 0.0670, 0.1137, 0.0789, 0.1888, 0.1025, 0.0707, 0.1582, 0.0808,
        0.0312, 0.1065], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,555][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0363, 0.3739, 0.0333, 0.0904, 0.0208, 0.0141, 0.0086, 0.3024, 0.0083,
        0.0792, 0.0304, 0.0024], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,556][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0022, 0.3997, 0.0254, 0.0652, 0.0160, 0.0103, 0.0171, 0.3301, 0.0073,
        0.0287, 0.0728, 0.0251], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,557][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0745, 0.0309, 0.1356, 0.1129, 0.0567, 0.0945, 0.0668, 0.1626, 0.0311,
        0.1082, 0.0599, 0.0662], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,560][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0369, 0.2642, 0.1199, 0.1186, 0.1110, 0.0848, 0.0434, 0.0311, 0.0432,
        0.0348, 0.0761, 0.0362], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,565][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0147, 0.0148, 0.2740, 0.0482, 0.0352, 0.1451, 0.0506, 0.1254, 0.1281,
        0.0340, 0.1010, 0.0289], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,567][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0255, 0.0008, 0.0225, 0.0041, 0.0258, 0.1290, 0.0947, 0.0195, 0.1252,
        0.0137, 0.4548, 0.0844], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,568][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0020, 0.5686, 0.0051, 0.1128, 0.0149, 0.0055, 0.0081, 0.2210, 0.0012,
        0.0446, 0.0144, 0.0018], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,569][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0238, 0.2648, 0.1064, 0.0696, 0.0498, 0.0673, 0.0896, 0.0935, 0.0801,
        0.0297, 0.0764, 0.0490], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,570][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0008, 0.0185, 0.6176, 0.0567, 0.0313, 0.1152, 0.0481, 0.0292, 0.0357,
        0.0077, 0.0268, 0.0125], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,571][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([5.4683e-01, 4.8394e-08, 1.0457e-05, 1.5056e-06, 3.9973e-05, 3.2563e-03,
        4.5416e-02, 1.6345e-03, 1.1583e-01, 1.1312e-03, 1.2241e-01, 1.6344e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,572][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([7.6849e-05, 9.0203e-03, 6.7179e-02, 7.3495e-03, 1.6882e-03, 3.6706e-02,
        8.5423e-02, 2.7560e-03, 7.2759e-01, 4.9570e-03, 1.3007e-02, 4.4250e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,576][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0039, 0.0645, 0.1495, 0.0872, 0.1812, 0.0929, 0.0494, 0.0978, 0.0848,
        0.0242, 0.0875, 0.0770], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,581][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.0010, 0.1402, 0.0572, 0.1250, 0.0368, 0.0142, 0.0070, 0.1847, 0.0108,
        0.0439, 0.0328, 0.0020, 0.3444], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,582][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.0007, 0.5251, 0.0353, 0.1265, 0.0231, 0.0142, 0.0289, 0.0841, 0.0056,
        0.0364, 0.0935, 0.0133, 0.0133], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,582][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.0489, 0.0262, 0.0938, 0.0943, 0.0832, 0.0698, 0.0501, 0.1548, 0.0240,
        0.0621, 0.0901, 0.0786, 0.1240], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,583][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0274, 0.3448, 0.1737, 0.1369, 0.0703, 0.0624, 0.0259, 0.0184, 0.0253,
        0.0244, 0.0596, 0.0221, 0.0089], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,584][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.0076, 0.0067, 0.3154, 0.0349, 0.0204, 0.1220, 0.0446, 0.1308, 0.1317,
        0.0319, 0.1151, 0.0188, 0.0202], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,586][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([1.6685e-03, 5.1370e-07, 2.9666e-04, 2.9221e-05, 1.0497e-03, 1.4168e-02,
        6.1211e-02, 1.2472e-02, 5.7617e-02, 2.9753e-03, 7.8386e-01, 5.8687e-02,
        5.9638e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,588][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([1.8090e-03, 7.5199e-01, 2.2625e-03, 9.2596e-02, 4.9512e-03, 2.3542e-03,
        3.0208e-03, 1.0143e-01, 2.5680e-04, 2.1084e-02, 1.1187e-02, 5.0500e-04,
        6.5493e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,593][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.0149, 0.3810, 0.0848, 0.0954, 0.0570, 0.0270, 0.0340, 0.0630, 0.0380,
        0.0225, 0.1371, 0.0220, 0.0232], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,595][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.0013, 0.1885, 0.4188, 0.1197, 0.0439, 0.1121, 0.0273, 0.0274, 0.0260,
        0.0061, 0.0148, 0.0066, 0.0075], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,595][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([1.0790e-02, 7.6279e-13, 3.2710e-08, 2.0187e-09, 4.6893e-07, 2.2316e-04,
        6.3964e-02, 2.1501e-03, 1.4917e-01, 4.4618e-04, 4.1483e-01, 3.5758e-01,
        8.4021e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,596][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([7.1486e-06, 8.2793e-04, 5.2894e-02, 3.4287e-04, 1.8769e-04, 2.6300e-02,
        7.2945e-02, 6.8228e-05, 8.0660e-01, 1.9662e-04, 3.9180e-03, 3.4470e-02,
        1.2392e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,597][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([6.6682e-05, 6.9863e-02, 1.8888e-01, 6.4492e-02, 1.6343e-01, 1.3326e-01,
        7.5566e-02, 7.1811e-02, 4.2857e-02, 4.9061e-03, 4.5693e-02, 5.4334e-02,
        8.4836e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,598][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0010, 0.3976, 0.0242, 0.1247, 0.0347, 0.0062, 0.0100, 0.1483, 0.0055,
        0.0964, 0.0223, 0.0064, 0.1189, 0.0038], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:41,600][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.3310e-04, 3.4683e-01, 5.3906e-02, 6.1828e-02, 6.0420e-02, 1.9659e-02,
        4.9372e-02, 2.0740e-01, 1.2590e-02, 3.1664e-02, 6.7225e-02, 1.8017e-02,
        6.9882e-02, 9.8005e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:41,605][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0197, 0.0249, 0.1209, 0.1116, 0.0697, 0.0935, 0.0628, 0.0819, 0.0518,
        0.0813, 0.0730, 0.0927, 0.0819, 0.0344], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:41,608][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0282, 0.3760, 0.0923, 0.1281, 0.0913, 0.0538, 0.0279, 0.0207, 0.0256,
        0.0292, 0.0694, 0.0233, 0.0120, 0.0222], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:41,609][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0201, 0.0198, 0.2411, 0.0585, 0.0349, 0.1341, 0.0419, 0.0981, 0.0926,
        0.0329, 0.1032, 0.0277, 0.0370, 0.0580], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:41,610][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0439, 0.0006, 0.0235, 0.0030, 0.0224, 0.0948, 0.0721, 0.0131, 0.1112,
        0.0140, 0.3625, 0.0916, 0.0103, 0.1368], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:41,610][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([1.8925e-04, 8.0446e-01, 2.6984e-03, 6.7116e-02, 1.1361e-02, 3.1004e-03,
        4.8254e-03, 7.2125e-02, 3.8787e-04, 2.0001e-02, 7.2425e-03, 6.2714e-04,
        5.6535e-03, 2.0838e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:41,611][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0091, 0.3474, 0.0722, 0.1106, 0.0577, 0.0573, 0.0706, 0.0647, 0.0443,
        0.0211, 0.0706, 0.0265, 0.0264, 0.0217], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:41,613][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([5.7906e-04, 2.0834e-02, 6.2566e-01, 6.4348e-02, 2.7784e-02, 9.1938e-02,
        4.3292e-02, 3.5021e-02, 3.1219e-02, 7.0841e-03, 2.2666e-02, 8.9040e-03,
        1.1259e-02, 9.4077e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:41,615][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([6.2577e-01, 1.7731e-08, 6.8055e-06, 7.5841e-07, 1.6677e-05, 9.9013e-04,
        8.0738e-03, 3.1910e-04, 3.2425e-02, 3.9299e-04, 1.9011e-02, 4.3373e-02,
        1.1385e-04, 2.6951e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:41,618][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([3.2124e-05, 2.8646e-02, 5.1051e-02, 1.6992e-02, 3.3134e-03, 3.6096e-02,
        9.0848e-02, 2.1155e-03, 7.0343e-01, 8.8763e-03, 1.0527e-02, 2.1106e-02,
        1.5746e-02, 1.1217e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:41,621][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([9.4422e-05, 2.6377e-02, 7.5853e-02, 5.0056e-02, 9.4667e-02, 3.6534e-02,
        3.1453e-02, 1.5562e-01, 2.7704e-02, 1.5550e-02, 6.8639e-02, 4.2265e-02,
        3.6218e-01, 1.3016e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:41,729][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:41,730][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:41,730][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:41,731][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:41,732][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:41,732][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:41,733][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:41,734][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:41,734][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:41,735][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:41,735][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:41,736][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:41,737][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:41,737][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.0657, 0.9343], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:41,738][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.0151, 0.9849], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:41,739][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.5125, 0.4875], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:41,739][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.7961, 0.2039], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:41,743][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.9189, 0.0811], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:41,743][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.1361, 0.8639], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:41,744][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.1395, 0.8605], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:41,745][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.8698, 0.1302], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:41,745][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.2056, 0.7944], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:41,746][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.0211, 0.9789], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:41,749][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.0041, 0.9959], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:41,754][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.1278, 0.8722], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:41,756][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0018, 0.8790, 0.1192], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:41,757][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([3.9215e-06, 2.8778e-02, 9.7122e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:41,758][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0021, 0.1473, 0.8507], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:41,758][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1128, 0.6761, 0.2112], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:41,759][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.7788, 0.0518, 0.1694], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:41,761][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1568, 0.8182, 0.0250], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:41,764][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0011, 0.4707, 0.5282], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:41,770][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.3676, 0.3326, 0.2998], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:41,771][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([5.2994e-04, 2.9412e-02, 9.7006e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:41,771][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0078, 0.9624, 0.0298], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:41,772][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([1.6858e-05, 9.9985e-01, 1.3751e-04], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:41,773][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0066, 0.6561, 0.3374], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:41,773][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Jonathan] are: tensor([0.0066, 0.4527, 0.1325, 0.4082], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:41,775][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Jonathan] are: tensor([1.0402e-04, 3.3593e-02, 7.5497e-01, 2.1133e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:41,779][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Jonathan] are: tensor([0.0105, 0.0499, 0.6744, 0.2653], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:41,784][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Jonathan] are: tensor([0.2808, 0.2601, 0.1361, 0.3230], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:41,784][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Jonathan] are: tensor([0.2957, 0.0563, 0.3797, 0.2682], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:41,785][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Jonathan] are: tensor([0.1572, 0.1186, 0.0876, 0.6366], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:41,786][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Jonathan] are: tensor([0.0048, 0.1812, 0.1794, 0.6345], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:41,787][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Jonathan] are: tensor([0.6899, 0.1410, 0.0397, 0.1295], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:41,788][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Jonathan] are: tensor([0.0048, 0.1060, 0.6696, 0.2197], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:41,791][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Jonathan] are: tensor([0.0970, 0.2012, 0.2171, 0.4846], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:41,794][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Jonathan] are: tensor([7.4251e-04, 9.9060e-01, 7.8785e-04, 7.8651e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:41,798][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Jonathan] are: tensor([0.0159, 0.5445, 0.1625, 0.2771], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:41,798][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.0039, 0.3765, 0.1802, 0.2736, 0.1659], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:41,799][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([1.0128e-04, 3.5576e-02, 7.2749e-01, 1.6382e-01, 7.3010e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:41,800][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0111, 0.0639, 0.6516, 0.1714, 0.1020], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:41,800][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.1926, 0.2204, 0.1595, 0.1713, 0.2562], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:41,802][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.1823, 0.0861, 0.3653, 0.1639, 0.2024], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:41,807][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.2586, 0.0951, 0.1141, 0.2112, 0.3211], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:41,811][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.0037, 0.1570, 0.4198, 0.2691, 0.1503], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:41,812][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.4225, 0.2294, 0.0928, 0.1013, 0.1540], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:41,813][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.0033, 0.0592, 0.7226, 0.1325, 0.0825], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:41,813][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.2392, 0.1173, 0.2003, 0.1761, 0.2671], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:41,814][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([8.1109e-04, 9.6541e-01, 2.9802e-03, 1.2157e-02, 1.8645e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:41,815][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.0187, 0.3544, 0.3731, 0.1795, 0.0743], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:41,819][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0010, 0.6223, 0.0950, 0.1327, 0.0970, 0.0520], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:41,822][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.0227e-05, 6.0839e-02, 7.3871e-01, 1.3002e-01, 1.5671e-02, 5.4749e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:41,825][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0018, 0.1113, 0.5930, 0.0973, 0.0662, 0.1305], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:41,826][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0624, 0.5520, 0.0830, 0.1265, 0.1380, 0.0381], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:41,827][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2125, 0.0651, 0.2575, 0.1595, 0.1321, 0.1733], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:41,827][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.4625, 0.1193, 0.0650, 0.1106, 0.1359, 0.1067], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:41,828][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0010, 0.6271, 0.1116, 0.1802, 0.0438, 0.0362], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:41,830][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0570, 0.3664, 0.0777, 0.2821, 0.1019, 0.1149], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:41,833][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.3582e-04, 1.3718e-02, 8.6995e-01, 4.5036e-02, 1.6579e-02, 5.4579e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:41,837][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.3169, 0.0775, 0.1882, 0.1095, 0.1206, 0.1874], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:41,839][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([3.6890e-05, 9.8572e-01, 1.1372e-03, 4.4072e-03, 3.7516e-03, 4.9499e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:41,840][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0417, 0.7085, 0.0435, 0.1609, 0.0415, 0.0040], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:41,841][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0008, 0.6093, 0.1257, 0.1625, 0.0563, 0.0327, 0.0127],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:41,841][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([5.3571e-06, 5.2539e-02, 7.6173e-01, 7.6550e-02, 9.6950e-03, 7.5771e-02,
        2.3705e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:41,842][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0008, 0.1021, 0.6807, 0.0679, 0.0333, 0.0784, 0.0369],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:41,845][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0445, 0.5499, 0.1028, 0.1094, 0.1323, 0.0373, 0.0238],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:41,850][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1621, 0.0410, 0.3078, 0.1398, 0.0918, 0.1737, 0.0838],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:41,853][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.2766, 0.0021, 0.0315, 0.0128, 0.0651, 0.2884, 0.3236],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:41,854][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0007, 0.4938, 0.2029, 0.2072, 0.0327, 0.0450, 0.0177],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:41,854][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0293, 0.5068, 0.1051, 0.1397, 0.0426, 0.0714, 0.1053],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:41,855][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([1.9171e-04, 1.2969e-02, 8.8001e-01, 3.0931e-02, 1.1177e-02, 4.5666e-02,
        1.9053e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:41,856][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1156, 0.0007, 0.0270, 0.0052, 0.0286, 0.3867, 0.4361],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:41,857][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([1.3379e-05, 9.9329e-01, 3.7941e-04, 2.2173e-03, 1.4481e-03, 2.2788e-03,
        3.7569e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:41,860][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0057, 0.5531, 0.2552, 0.0967, 0.0232, 0.0184, 0.0475],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:41,863][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([1.4121e-04, 4.7407e-01, 2.3785e-01, 1.7385e-01, 4.0073e-02, 5.2960e-02,
        1.6086e-02, 4.9709e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,867][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([2.5638e-06, 2.2357e-02, 6.7468e-01, 5.6125e-02, 8.9654e-03, 7.9000e-02,
        1.5148e-02, 1.4372e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,868][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([0.0020, 0.1103, 0.5669, 0.0969, 0.0537, 0.1205, 0.0304, 0.0192],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,868][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.0731, 0.3459, 0.1699, 0.1442, 0.1167, 0.0787, 0.0355, 0.0360],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,869][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.0842, 0.0222, 0.2291, 0.1152, 0.0623, 0.1499, 0.0929, 0.2441],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,870][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([4.3470e-02, 9.3742e-05, 3.6860e-03, 1.3380e-03, 1.6865e-02, 1.9582e-01,
        6.6959e-01, 6.9137e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,873][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.0005, 0.3750, 0.3043, 0.2236, 0.0279, 0.0438, 0.0103, 0.0147],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,877][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.0498, 0.3472, 0.0805, 0.1803, 0.0726, 0.0374, 0.0696, 0.1625],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,881][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.0027, 0.1532, 0.4975, 0.0802, 0.0521, 0.1245, 0.0419, 0.0478],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,881][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([2.9087e-03, 3.6198e-06, 1.9853e-03, 8.0086e-05, 1.6232e-03, 1.1072e-01,
        8.4676e-01, 3.5912e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,882][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([7.0632e-06, 9.9575e-01, 1.5040e-04, 8.8507e-04, 1.1793e-03, 1.8746e-03,
        1.3822e-04, 1.1286e-05], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,883][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.0010, 0.4447, 0.1730, 0.0755, 0.0228, 0.0208, 0.0170, 0.2452],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:41,884][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0007, 0.5924, 0.1410, 0.1495, 0.0573, 0.0396, 0.0135, 0.0032, 0.0027],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,886][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([3.0799e-06, 3.1258e-02, 7.5610e-01, 7.4782e-02, 1.0085e-02, 4.5558e-02,
        1.5645e-02, 6.3040e-02, 3.5282e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,890][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0006, 0.1206, 0.5650, 0.0765, 0.0471, 0.0945, 0.0295, 0.0406, 0.0257],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,894][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0435, 0.5773, 0.0728, 0.1277, 0.0974, 0.0261, 0.0180, 0.0182, 0.0190],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,895][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0385, 0.0244, 0.1845, 0.0734, 0.0649, 0.1205, 0.0586, 0.2593, 0.1759],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,896][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0998, 0.0099, 0.0547, 0.0288, 0.0640, 0.1961, 0.2427, 0.0252, 0.2789],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,897][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0005, 0.4655, 0.2083, 0.2221, 0.0367, 0.0379, 0.0127, 0.0131, 0.0032],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,898][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0164, 0.4460, 0.0485, 0.1569, 0.0566, 0.0538, 0.0813, 0.0611, 0.0794],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,899][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([1.6652e-04, 1.2143e-02, 8.2157e-01, 4.4690e-02, 1.8131e-02, 4.6244e-02,
        1.6543e-02, 1.8987e-02, 2.1524e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,903][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0770, 0.0054, 0.0659, 0.0170, 0.0354, 0.2236, 0.2478, 0.0366, 0.2915],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,907][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([1.8541e-05, 9.8299e-01, 1.6859e-03, 5.2407e-03, 3.7939e-03, 5.0290e-03,
        9.2927e-04, 1.9261e-04, 1.2392e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,908][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0029, 0.2479, 0.1925, 0.0544, 0.0224, 0.0256, 0.0346, 0.3793, 0.0406],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:41,909][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Jonathan] are: tensor([0.0006, 0.2061, 0.2708, 0.2798, 0.0700, 0.1082, 0.0393, 0.0067, 0.0082,
        0.0105], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,910][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Jonathan] are: tensor([5.5256e-06, 2.1291e-02, 6.1812e-01, 9.1681e-02, 2.0313e-02, 1.2740e-01,
        3.6717e-02, 7.8103e-02, 5.2394e-03, 1.1262e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,911][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Jonathan] are: tensor([4.9594e-04, 5.3957e-02, 5.6411e-01, 9.2655e-02, 3.1218e-02, 1.6041e-01,
        3.9944e-02, 2.8233e-02, 2.2132e-02, 6.8490e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,912][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Jonathan] are: tensor([0.0223, 0.2961, 0.1145, 0.2372, 0.1679, 0.0732, 0.0254, 0.0182, 0.0185,
        0.0266], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,915][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Jonathan] are: tensor([0.0187, 0.0141, 0.3594, 0.0604, 0.0399, 0.1543, 0.0491, 0.1284, 0.1338,
        0.0421], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,920][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Jonathan] are: tensor([0.0062, 0.0005, 0.0168, 0.0051, 0.0194, 0.1132, 0.3132, 0.2034, 0.2908,
        0.0314], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,922][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Jonathan] are: tensor([0.0004, 0.0820, 0.3666, 0.1874, 0.0517, 0.1695, 0.0492, 0.0767, 0.0101,
        0.0064], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,923][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Jonathan] are: tensor([0.0190, 0.4277, 0.0826, 0.1636, 0.0776, 0.0437, 0.0522, 0.0612, 0.0430,
        0.0294], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,924][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Jonathan] are: tensor([6.0992e-04, 5.2270e-02, 6.2129e-01, 1.0945e-01, 3.1969e-02, 1.0636e-01,
        2.8098e-02, 2.2211e-02, 1.9642e-02, 8.0950e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,924][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Jonathan] are: tensor([4.6877e-03, 2.3723e-04, 1.2328e-02, 2.2640e-03, 9.5706e-03, 1.0310e-01,
        4.2671e-01, 1.9704e-01, 2.2656e-01, 1.7496e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,925][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Jonathan] are: tensor([4.9593e-05, 9.4721e-01, 2.7573e-03, 1.7401e-02, 9.0322e-03, 1.9857e-02,
        3.1343e-03, 2.9558e-04, 2.2047e-04, 3.7819e-05], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,929][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Jonathan] are: tensor([0.0006, 0.1060, 0.3398, 0.0548, 0.0172, 0.1113, 0.0549, 0.2857, 0.0251,
        0.0045], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:41,931][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([5.3695e-05, 5.7905e-01, 1.6535e-01, 1.5675e-01, 2.3310e-02, 5.2852e-02,
        1.0256e-02, 1.1457e-03, 2.9291e-03, 1.1589e-03, 7.1455e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,934][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([2.7367e-06, 9.3714e-02, 6.7178e-01, 5.5402e-02, 9.8851e-03, 7.5970e-02,
        2.7189e-02, 4.8257e-02, 5.5051e-03, 3.8621e-04, 1.1904e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,936][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0010, 0.1956, 0.4904, 0.1068, 0.0403, 0.0770, 0.0203, 0.0150, 0.0199,
        0.0051, 0.0285], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,937][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0131, 0.4258, 0.0999, 0.1693, 0.0826, 0.0454, 0.0237, 0.0205, 0.0282,
        0.0260, 0.0653], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,938][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0155, 0.0302, 0.2125, 0.0664, 0.0336, 0.1611, 0.0428, 0.1152, 0.2109,
        0.0370, 0.0749], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,938][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.1157, 0.0024, 0.0159, 0.0070, 0.0309, 0.1973, 0.1442, 0.0084, 0.1713,
        0.0232, 0.2836], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,939][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([2.3421e-04, 5.8390e-01, 1.6362e-01, 1.3594e-01, 2.4977e-02, 4.8439e-02,
        1.1998e-02, 1.5930e-02, 4.7146e-03, 1.6086e-03, 8.6406e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,943][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0158, 0.6136, 0.0476, 0.0594, 0.0263, 0.0182, 0.0280, 0.0340, 0.0572,
        0.0172, 0.0828], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,946][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([5.8105e-04, 7.5564e-02, 6.6600e-01, 6.0300e-02, 2.4826e-02, 7.1261e-02,
        2.2874e-02, 2.0808e-02, 3.5391e-02, 4.5047e-03, 1.7893e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,950][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0117, 0.0005, 0.0229, 0.0015, 0.0082, 0.2473, 0.1792, 0.0061, 0.1136,
        0.0020, 0.4070], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,950][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([3.4281e-06, 9.9569e-01, 3.2328e-04, 1.5340e-03, 1.0672e-03, 1.0807e-03,
        1.7082e-04, 1.3596e-05, 1.8473e-05, 8.3998e-07, 9.4723e-05],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,951][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0030, 0.6138, 0.0858, 0.0537, 0.0161, 0.0179, 0.0183, 0.1298, 0.0268,
        0.0050, 0.0297], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:41,952][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0008, 0.3432, 0.2705, 0.1468, 0.0611, 0.0841, 0.0361, 0.0109, 0.0083,
        0.0069, 0.0234, 0.0077], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,953][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([6.1485e-06, 2.3992e-02, 7.2548e-01, 4.4718e-02, 1.0767e-02, 9.1955e-02,
        3.0726e-02, 4.9149e-02, 6.1141e-03, 7.6808e-04, 1.3686e-02, 2.6330e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,955][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0010, 0.0571, 0.5431, 0.0817, 0.0306, 0.1207, 0.0470, 0.0387, 0.0338,
        0.0095, 0.0245, 0.0124], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,960][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0369, 0.2642, 0.1199, 0.1186, 0.1110, 0.0848, 0.0434, 0.0311, 0.0432,
        0.0348, 0.0761, 0.0362], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,963][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0147, 0.0148, 0.2740, 0.0482, 0.0352, 0.1451, 0.0506, 0.1254, 0.1281,
        0.0340, 0.1010, 0.0289], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,964][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0259, 0.0017, 0.0417, 0.0074, 0.0322, 0.1632, 0.1006, 0.0195, 0.1250,
        0.0154, 0.3847, 0.0827], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,965][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0008, 0.1309, 0.4310, 0.1289, 0.0401, 0.1119, 0.0375, 0.0653, 0.0141,
        0.0071, 0.0202, 0.0123], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,966][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0238, 0.2648, 0.1064, 0.0696, 0.0498, 0.0673, 0.0896, 0.0935, 0.0801,
        0.0297, 0.0764, 0.0490], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,967][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0008, 0.0185, 0.6176, 0.0567, 0.0313, 0.1152, 0.0481, 0.0292, 0.0357,
        0.0077, 0.0268, 0.0125], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,970][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0144, 0.0012, 0.0517, 0.0030, 0.0117, 0.1610, 0.1239, 0.0108, 0.0909,
        0.0046, 0.4774, 0.0494], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,972][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([6.2711e-05, 9.7197e-01, 2.2746e-03, 6.0540e-03, 6.2595e-03, 9.7844e-03,
        2.3028e-03, 2.2333e-04, 2.2377e-04, 1.7963e-05, 6.5177e-04, 1.7336e-04],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,977][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0018, 0.1569, 0.2836, 0.0703, 0.0313, 0.0763, 0.0523, 0.1805, 0.0257,
        0.0072, 0.0939, 0.0203], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:41,978][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([9.4553e-05, 2.5926e-01, 4.1825e-01, 1.4078e-01, 3.2300e-02, 7.2948e-02,
        2.6629e-02, 7.5594e-03, 5.4563e-03, 3.0256e-03, 2.8986e-02, 3.0871e-03,
        1.6174e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,979][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([1.7893e-06, 3.1182e-02, 6.4956e-01, 4.9330e-02, 8.8505e-03, 1.2571e-01,
        2.6709e-02, 8.7865e-02, 5.9407e-03, 2.7877e-04, 1.1215e-02, 1.5681e-03,
        1.7858e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,980][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([3.5656e-04, 5.7814e-02, 6.5598e-01, 5.6686e-02, 2.1615e-02, 1.2496e-01,
        2.7255e-02, 1.4562e-02, 1.8583e-02, 3.1139e-03, 1.1958e-02, 4.4901e-03,
        2.6320e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,980][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.0274, 0.3448, 0.1737, 0.1369, 0.0703, 0.0624, 0.0259, 0.0184, 0.0253,
        0.0244, 0.0596, 0.0221, 0.0089], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,984][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.0076, 0.0067, 0.3154, 0.0349, 0.0204, 0.1220, 0.0446, 0.1308, 0.1317,
        0.0319, 0.1151, 0.0188, 0.0202], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,986][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([2.1360e-03, 1.4534e-06, 7.0528e-04, 6.7042e-05, 1.5204e-03, 2.1677e-02,
        7.8232e-02, 1.3706e-02, 6.8667e-02, 4.2547e-03, 7.2959e-01, 7.0783e-02,
        8.6630e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,989][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([1.9391e-04, 1.0861e-01, 5.3419e-01, 1.2667e-01, 2.4096e-02, 9.0723e-02,
        2.3971e-02, 5.1386e-02, 1.1471e-02, 3.1047e-03, 1.3107e-02, 7.3515e-03,
        5.1225e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,991][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.0149, 0.3810, 0.0848, 0.0954, 0.0570, 0.0270, 0.0340, 0.0630, 0.0380,
        0.0225, 0.1371, 0.0220, 0.0232], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,992][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.0013, 0.1885, 0.4188, 0.1197, 0.0439, 0.1121, 0.0273, 0.0274, 0.0260,
        0.0061, 0.0148, 0.0066, 0.0075], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,993][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([2.2617e-04, 6.4229e-08, 2.8903e-04, 5.2432e-06, 1.4070e-04, 8.9381e-03,
        7.5864e-02, 9.2752e-03, 2.2227e-02, 5.4659e-04, 8.6472e-01, 1.6536e-02,
        1.2337e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,993][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([1.1819e-05, 9.8376e-01, 1.0420e-03, 3.4390e-03, 3.0347e-03, 7.2834e-03,
        8.3183e-04, 7.4621e-05, 7.3365e-05, 2.8741e-06, 4.0099e-04, 4.6612e-05,
        2.3299e-06], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,995][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.0006, 0.1466, 0.3295, 0.0518, 0.0231, 0.1020, 0.0403, 0.1816, 0.0195,
        0.0037, 0.0728, 0.0121, 0.0162], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:41,998][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0008, 0.2903, 0.2437, 0.1693, 0.0715, 0.0980, 0.0341, 0.0209, 0.0089,
        0.0070, 0.0378, 0.0082, 0.0050, 0.0045], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,001][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([7.2034e-06, 3.1691e-02, 6.1603e-01, 7.6828e-02, 1.3909e-02, 8.9507e-02,
        2.6070e-02, 9.7790e-02, 6.3881e-03, 1.1101e-03, 3.2426e-02, 2.8525e-03,
        4.0567e-03, 1.3336e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,004][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0007, 0.0844, 0.4711, 0.0894, 0.0336, 0.1269, 0.0431, 0.0409, 0.0379,
        0.0084, 0.0350, 0.0105, 0.0085, 0.0094], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,005][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0282, 0.3760, 0.0923, 0.1281, 0.0913, 0.0538, 0.0279, 0.0207, 0.0256,
        0.0292, 0.0694, 0.0233, 0.0120, 0.0222], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,006][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0201, 0.0198, 0.2411, 0.0585, 0.0349, 0.1341, 0.0419, 0.0981, 0.0926,
        0.0329, 0.1032, 0.0277, 0.0370, 0.0580], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,007][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0443, 0.0013, 0.0416, 0.0052, 0.0275, 0.1190, 0.0767, 0.0127, 0.1110,
        0.0157, 0.3104, 0.0904, 0.0117, 0.1324], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,008][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0006, 0.1719, 0.3649, 0.1504, 0.0446, 0.0982, 0.0297, 0.0695, 0.0108,
        0.0063, 0.0295, 0.0097, 0.0073, 0.0065], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,011][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0091, 0.3474, 0.0722, 0.1106, 0.0577, 0.0573, 0.0706, 0.0647, 0.0443,
        0.0211, 0.0706, 0.0265, 0.0264, 0.0217], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,013][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([5.7906e-04, 2.0834e-02, 6.2566e-01, 6.4348e-02, 2.7784e-02, 9.1938e-02,
        4.3292e-02, 3.5021e-02, 3.1219e-02, 7.0841e-03, 2.2666e-02, 8.9040e-03,
        1.1259e-02, 9.4077e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,018][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0260, 0.0005, 0.0451, 0.0027, 0.0127, 0.1226, 0.0838, 0.0110, 0.1063,
        0.0071, 0.4218, 0.0632, 0.0045, 0.0927], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,019][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([3.6409e-05, 9.4706e-01, 4.3347e-03, 1.4909e-02, 9.6882e-03, 1.7968e-02,
        2.9048e-03, 5.7383e-04, 3.6385e-04, 3.8193e-05, 1.7808e-03, 2.2400e-04,
        2.8543e-05, 9.2919e-05], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,020][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0016, 0.1050, 0.2253, 0.0583, 0.0270, 0.0678, 0.0375, 0.2436, 0.0380,
        0.0085, 0.1288, 0.0166, 0.0225, 0.0196], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,023][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:16:42,027][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[12751],
        [    1],
        [  284],
        [    3],
        [ 2297],
        [   39],
        [  149],
        [  163],
        [  145],
        [    5],
        [ 2851],
        [  697],
        [  604],
        [   73]], device='cuda:0')
[2024-07-24 10:16:42,030][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[12825],
        [    1],
        [ 5146],
        [   68],
        [12903],
        [ 1125],
        [ 2503],
        [ 2389],
        [ 1001],
        [   36],
        [14623],
        [ 3978],
        [ 3863],
        [  837]], device='cuda:0')
[2024-07-24 10:16:42,033][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[19340],
        [    1],
        [    2],
        [   12],
        [   18],
        [    4],
        [    6],
        [   21],
        [   52],
        [   21],
        [  164],
        [   35],
        [ 1596],
        [   16]], device='cuda:0')
[2024-07-24 10:16:42,034][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[16377],
        [  160],
        [  200],
        [  215],
        [  570],
        [  441],
        [  405],
        [ 1880],
        [ 2114],
        [  566],
        [ 1158],
        [ 3231],
        [ 1127],
        [ 4005]], device='cuda:0')
[2024-07-24 10:16:42,035][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[16016],
        [   48],
        [ 1063],
        [   82],
        [  144],
        [  305],
        [  359],
        [  625],
        [  396],
        [  580],
        [  359],
        [  295],
        [  425],
        [  309]], device='cuda:0')
[2024-07-24 10:16:42,037][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[16972],
        [19647],
        [26916],
        [35821],
        [38110],
        [31755],
        [31893],
        [36685],
        [31049],
        [38512],
        [36987],
        [40369],
        [38409],
        [37942]], device='cuda:0')
[2024-07-24 10:16:42,039][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[27304],
        [35922],
        [36487],
        [34210],
        [35809],
        [34430],
        [34033],
        [29317],
        [28869],
        [30825],
        [29810],
        [29438],
        [28959],
        [29412]], device='cuda:0')
[2024-07-24 10:16:42,042][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[28403],
        [21481],
        [21097],
        [26278],
        [22760],
        [22851],
        [19953],
        [20299],
        [14008],
        [17313],
        [15932],
        [17302],
        [18072],
        [16915]], device='cuda:0')
[2024-07-24 10:16:42,045][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[11000],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1]], device='cuda:0')
[2024-07-24 10:16:42,048][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[49361],
        [ 5721],
        [ 1183],
        [ 6218],
        [ 3150],
        [ 1287],
        [  260],
        [ 1629],
        [  504],
        [  623],
        [   48],
        [ 8461],
        [ 1254],
        [ 2326]], device='cuda:0')
[2024-07-24 10:16:42,049][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[38890],
        [28047],
        [35847],
        [35484],
        [35872],
        [35627],
        [35609],
        [34535],
        [35420],
        [34722],
        [34689],
        [34425],
        [33778],
        [34897]], device='cuda:0')
[2024-07-24 10:16:42,050][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[46083],
        [36117],
        [45730],
        [46115],
        [46129],
        [46108],
        [46468],
        [43853],
        [47063],
        [43203],
        [47498],
        [45397],
        [38732],
        [46586]], device='cuda:0')
[2024-07-24 10:16:42,052][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[5026],
        [   9],
        [  71],
        [1289],
        [1706],
        [ 267],
        [1820],
        [5580],
        [1137],
        [1875],
        [1948],
        [1875],
        [1899],
        [1665]], device='cuda:0')
[2024-07-24 10:16:42,054][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[15929],
        [ 8144],
        [13391],
        [11559],
        [19447],
        [18540],
        [20022],
        [17860],
        [12110],
        [18522],
        [14929],
        [17127],
        [15631],
        [ 7799]], device='cuda:0')
[2024-07-24 10:16:42,057][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[10957],
        [ 8603],
        [ 4664],
        [ 6057],
        [ 6205],
        [ 3488],
        [ 5245],
        [ 3153],
        [ 7507],
        [ 5681],
        [ 4014],
        [ 6664],
        [ 4650],
        [ 4851]], device='cuda:0')
[2024-07-24 10:16:42,060][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[12824],
        [23127],
        [24358],
        [27274],
        [29042],
        [28087],
        [27773],
        [28431],
        [28042],
        [29365],
        [28065],
        [29604],
        [28637],
        [30231]], device='cuda:0')
[2024-07-24 10:16:42,063][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[39125],
        [24519],
        [18220],
        [18186],
        [18821],
        [18984],
        [18776],
        [17698],
        [18154],
        [18350],
        [18684],
        [18161],
        [18167],
        [17871]], device='cuda:0')
[2024-07-24 10:16:42,064][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[39894],
        [ 7971],
        [30307],
        [29326],
        [29804],
        [27767],
        [28869],
        [26793],
        [26196],
        [27387],
        [23199],
        [26419],
        [28852],
        [24361]], device='cuda:0')
[2024-07-24 10:16:42,065][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[4144],
        [3446],
        [4454],
        [3813],
        [4225],
        [5297],
        [4790],
        [3295],
        [5164],
        [4000],
        [4175],
        [3154],
        [3153],
        [3748]], device='cuda:0')
[2024-07-24 10:16:42,067][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[13183],
        [ 9897],
        [ 7697],
        [ 5157],
        [ 5998],
        [ 6289],
        [ 7157],
        [ 8237],
        [ 9965],
        [ 8954],
        [10299],
        [ 9776],
        [ 9922],
        [ 9716]], device='cuda:0')
[2024-07-24 10:16:42,069][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[17396],
        [21345],
        [20543],
        [ 3520],
        [ 5948],
        [ 7142],
        [ 3843],
        [ 2879],
        [ 3847],
        [ 3115],
        [ 3759],
        [ 3788],
        [ 4557],
        [ 3532]], device='cuda:0')
[2024-07-24 10:16:42,072][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[14776],
        [ 7731],
        [ 8261],
        [ 9733],
        [ 8533],
        [ 7321],
        [ 7230],
        [ 7642],
        [ 7563],
        [ 8154],
        [ 7541],
        [ 8193],
        [ 8483],
        [ 8304]], device='cuda:0')
[2024-07-24 10:16:42,075][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[17055],
        [28002],
        [24400],
        [22532],
        [30889],
        [33400],
        [34768],
        [36985],
        [35723],
        [35234],
        [37680],
        [29658],
        [35241],
        [33600]], device='cuda:0')
[2024-07-24 10:16:42,078][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[10738],
        [10141],
        [24779],
        [23309],
        [24307],
        [24252],
        [24230],
        [22660],
        [24085],
        [22958],
        [23016],
        [22584],
        [21564],
        [22930]], device='cuda:0')
[2024-07-24 10:16:42,079][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[12720],
        [ 3822],
        [ 3641],
        [ 1358],
        [ 1544],
        [ 1603],
        [ 3796],
        [ 4286],
        [ 3674],
        [ 4634],
        [ 3467],
        [ 3043],
        [ 2860],
        [ 3272]], device='cuda:0')
[2024-07-24 10:16:42,080][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[23769],
        [25589],
        [25585],
        [25679],
        [25792],
        [25685],
        [25640],
        [25614],
        [25714],
        [26028],
        [25620],
        [25775],
        [25696],
        [26016]], device='cuda:0')
[2024-07-24 10:16:42,082][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[13554],
        [10136],
        [ 8649],
        [ 9997],
        [ 8217],
        [10406],
        [ 9110],
        [22135],
        [29593],
        [23378],
        [16693],
        [21690],
        [20692],
        [27595]], device='cuda:0')
[2024-07-24 10:16:42,084][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[17778],
        [35790],
        [30650],
        [38021],
        [35115],
        [34243],
        [34951],
        [30562],
        [27061],
        [28487],
        [31774],
        [30518],
        [29412],
        [27968]], device='cuda:0')
[2024-07-24 10:16:42,086][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[35229],
        [34558],
        [27894],
        [38696],
        [36791],
        [27178],
        [24254],
        [40497],
        [22076],
        [40185],
        [43119],
        [30150],
        [46537],
        [35432]], device='cuda:0')
[2024-07-24 10:16:42,090][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[10490],
        [10490],
        [10490],
        [10490],
        [10490],
        [10490],
        [10490],
        [10490],
        [10490],
        [10490],
        [10490],
        [10490],
        [10490],
        [10490]], device='cuda:0')
[2024-07-24 10:16:42,199][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:42,201][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:42,202][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:42,202][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:42,203][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:42,204][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:42,204][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:42,205][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:42,206][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:42,206][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:42,207][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:42,207][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:42,208][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:42,209][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.0500, 0.9500], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:42,209][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.8367, 0.1633], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:42,210][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.4165, 0.5835], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:42,211][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([9.9908e-01, 9.2299e-04], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:42,214][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.0253, 0.9747], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:42,215][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.0067, 0.9933], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:42,215][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([7.6531e-06, 9.9999e-01], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:42,216][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.0032, 0.9968], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:42,217][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([1.0000e+00, 4.6407e-37], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:42,219][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.0733, 0.9267], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:42,222][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.7110, 0.2890], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:42,227][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.0204, 0.9796], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:42,228][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0901, 0.5683, 0.3416], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:42,229][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0475, 0.9460, 0.0065], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:42,229][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0029, 0.9585, 0.0386], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:42,230][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.8167, 0.1817, 0.0016], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:42,231][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([4.6697e-04, 2.0657e-01, 7.9297e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:42,232][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([3.5650e-04, 5.5650e-01, 4.4314e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:42,234][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([6.4145e-06, 8.6316e-01, 1.3683e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:42,236][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([1.2467e-05, 4.1622e-01, 5.8377e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:42,241][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([1.0000e+00, 3.0304e-26, 1.5789e-19], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:42,241][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0021, 0.9097, 0.0881], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:42,242][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([9.9681e-01, 2.3209e-03, 8.6721e-04], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:42,243][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0262, 0.7366, 0.2373], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:42,244][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Jonathan] are: tensor([0.0041, 0.2315, 0.0012, 0.7632], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:42,244][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Jonathan] are: tensor([0.0507, 0.9233, 0.0128, 0.0131], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:42,247][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Jonathan] are: tensor([0.0121, 0.7248, 0.1382, 0.1249], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:42,249][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Jonathan] are: tensor([9.3262e-01, 6.5298e-02, 1.6047e-03, 4.7239e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:42,254][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Jonathan] are: tensor([0.0009, 0.6437, 0.1552, 0.2002], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:42,255][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Jonathan] are: tensor([0.0013, 0.3852, 0.5634, 0.0501], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:42,256][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Jonathan] are: tensor([1.8307e-06, 5.4121e-01, 1.1312e-01, 3.4567e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:42,256][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Jonathan] are: tensor([2.7019e-05, 7.0995e-01, 2.4692e-01, 4.3108e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:42,257][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Jonathan] are: tensor([1.0000e+00, 5.3817e-36, 7.1608e-27, 7.9160e-37], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:42,258][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Jonathan] are: tensor([0.0076, 0.4130, 0.1838, 0.3956], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:42,261][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Jonathan] are: tensor([0.8132, 0.0079, 0.0023, 0.1765], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:42,265][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Jonathan] are: tensor([0.0049, 0.7509, 0.0513, 0.1930], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:42,268][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ went] are: tensor([3.9590e-02, 1.4375e-01, 7.7050e-04, 7.7415e-01, 4.1742e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:42,269][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0891, 0.8403, 0.0208, 0.0228, 0.0269], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:42,269][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0083, 0.3415, 0.1103, 0.4447, 0.0951], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:42,270][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ went] are: tensor([8.8546e-01, 1.1084e-01, 2.1899e-03, 1.3063e-03, 2.0069e-04],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:42,271][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.0006, 0.5329, 0.2521, 0.1951, 0.0193], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:42,272][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ went] are: tensor([4.0147e-04, 6.8309e-01, 2.3447e-01, 6.4384e-02, 1.7657e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:42,274][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ went] are: tensor([1.0142e-05, 5.1838e-01, 7.1768e-02, 4.0130e-01, 8.5393e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:42,276][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ went] are: tensor([1.4173e-04, 7.7822e-01, 1.4287e-01, 5.7863e-02, 2.0910e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:42,280][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ went] are: tensor([1.0000e+00, 8.0334e-40, 9.2087e-30, 1.0007e-40, 2.3822e-44],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:42,281][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.0035, 0.5365, 0.1125, 0.1942, 0.1533], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:42,282][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ went] are: tensor([1.7482e-01, 7.4829e-04, 3.8754e-03, 2.1193e-03, 8.1843e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:42,283][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0032, 0.1957, 0.1263, 0.1201, 0.5547], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:42,284][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0106, 0.1553, 0.0993, 0.5668, 0.0181, 0.1499], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:42,284][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0144, 0.9510, 0.0071, 0.0072, 0.0076, 0.0126], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:42,287][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0006, 0.5350, 0.0097, 0.4164, 0.0267, 0.0116], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:42,291][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.4247, 0.5611, 0.0030, 0.0074, 0.0015, 0.0022], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:42,295][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([3.6790e-04, 2.5466e-01, 4.7858e-01, 2.0159e-01, 1.3227e-02, 5.1571e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:42,295][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([2.8469e-04, 6.4029e-01, 2.9441e-01, 4.6454e-02, 1.0693e-02, 7.8652e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:42,296][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([1.5829e-07, 3.9602e-01, 1.9157e-02, 2.7692e-01, 4.6447e-03, 3.0325e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:42,297][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([1.7223e-05, 6.1934e-01, 2.7308e-01, 2.9963e-02, 8.9621e-03, 6.8631e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:42,298][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([1.0000e+00, 2.9069e-36, 7.3321e-27, 8.6157e-37, 5.3117e-40, 1.1574e-33],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:42,300][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0006, 0.5036, 0.0671, 0.2651, 0.1119, 0.0517], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:42,302][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([8.4493e-01, 2.0813e-03, 6.1091e-04, 5.0223e-03, 1.4677e-01, 5.8779e-04],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:42,306][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0036, 0.2274, 0.0693, 0.1373, 0.4571, 0.1052], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:42,308][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0159, 0.0803, 0.0729, 0.5356, 0.0185, 0.1515, 0.1254],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:42,309][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0063, 0.9600, 0.0078, 0.0065, 0.0058, 0.0102, 0.0033],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:42,310][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0016, 0.2582, 0.0225, 0.6758, 0.0168, 0.0200, 0.0051],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:42,310][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ the] are: tensor([5.0772e-01, 4.8020e-01, 3.7636e-03, 4.8399e-03, 6.6651e-04, 2.3693e-03,
        4.4381e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:42,311][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0005, 0.3438, 0.2493, 0.3392, 0.0147, 0.0386, 0.0139],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:42,314][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0018, 0.4522, 0.3881, 0.0660, 0.0220, 0.0117, 0.0581],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:42,316][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ the] are: tensor([3.7620e-07, 3.8973e-01, 3.1561e-02, 2.8043e-01, 4.7964e-03, 2.9178e-01,
        1.7075e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:42,319][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ the] are: tensor([1.1915e-04, 5.8289e-01, 2.7180e-01, 5.6856e-02, 1.5298e-02, 5.7453e-02,
        1.5585e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:42,321][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ the] are: tensor([1.0000e+00, 1.6048e-37, 8.7753e-28, 3.1892e-38, 1.5245e-41, 7.5262e-35,
        2.0882e-38], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:42,322][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0018, 0.4369, 0.0442, 0.3990, 0.0897, 0.0236, 0.0048],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:42,323][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.6182, 0.0065, 0.0390, 0.0104, 0.2484, 0.0294, 0.0481],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:42,324][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ the] are: tensor([1.1813e-04, 4.5986e-02, 1.5592e-02, 3.4117e-02, 1.0764e-01, 4.6459e-02,
        7.5009e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:42,324][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.0102, 0.1867, 0.0034, 0.6379, 0.0270, 0.0061, 0.0108, 0.1179],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:42,326][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([4.2277e-03, 9.6836e-01, 5.0072e-03, 5.1117e-03, 5.3406e-03, 9.2499e-03,
        2.5252e-03, 1.7636e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:42,330][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.0015, 0.2572, 0.0280, 0.3489, 0.0308, 0.0272, 0.0169, 0.2895],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:42,333][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([4.8683e-01, 4.9882e-01, 7.9328e-03, 2.4614e-03, 7.4819e-04, 2.5578e-03,
        5.3910e-04, 1.0370e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:42,335][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([1.7725e-04, 7.4153e-01, 8.8756e-02, 1.4763e-01, 6.1296e-03, 6.4780e-03,
        1.7501e-03, 7.5428e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:42,336][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.0011, 0.4594, 0.1560, 0.0760, 0.0369, 0.0112, 0.0903, 0.1690],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:42,336][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([8.7689e-07, 3.5549e-01, 2.5514e-02, 2.3995e-01, 3.2209e-03, 3.2816e-01,
        4.7710e-03, 4.2891e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:42,337][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([9.1781e-06, 8.4176e-01, 7.1669e-02, 1.6878e-02, 6.3520e-03, 5.8332e-02,
        3.5122e-03, 1.4835e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:42,338][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([1.0000e+00, 4.0179e-32, 1.2308e-23, 6.3630e-33, 5.7675e-36, 6.2420e-30,
        3.5631e-33, 2.5583e-29], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:42,340][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.0013, 0.4848, 0.0288, 0.3287, 0.0952, 0.0216, 0.0047, 0.0347],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:42,345][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.0672, 0.0028, 0.1217, 0.0444, 0.6289, 0.0636, 0.0659, 0.0055],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:42,348][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([7.1263e-05, 2.6236e-02, 1.7168e-02, 2.3612e-02, 1.1667e-01, 6.7903e-02,
        6.9480e-01, 5.3532e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:42,349][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0129, 0.4683, 0.0234, 0.3180, 0.0116, 0.0360, 0.0365, 0.0318, 0.0616],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:42,350][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0049, 0.9275, 0.0095, 0.0171, 0.0098, 0.0177, 0.0059, 0.0013, 0.0063],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:42,350][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([1.8015e-04, 2.3089e-01, 1.9988e-03, 3.1948e-01, 7.5856e-03, 2.3123e-03,
        1.7473e-03, 4.3567e-01, 1.4093e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:42,351][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([4.6506e-02, 9.3344e-01, 2.8192e-03, 1.1817e-02, 1.8068e-03, 2.2846e-03,
        6.9276e-04, 4.3276e-04, 2.0317e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:42,353][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([2.2893e-04, 1.7817e-01, 4.8422e-01, 2.0961e-01, 1.9702e-02, 4.5024e-02,
        2.9740e-02, 2.6126e-02, 7.1862e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:42,355][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([2.7622e-04, 4.1212e-01, 3.0577e-01, 4.2246e-02, 1.0454e-02, 9.4144e-03,
        7.5711e-02, 8.7256e-02, 5.6759e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:42,358][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([1.1395e-07, 4.0018e-01, 1.2932e-02, 3.1672e-01, 6.4090e-03, 1.5305e-01,
        1.9825e-03, 1.0799e-01, 7.4123e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:42,361][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([6.3560e-05, 5.1569e-01, 2.4262e-01, 4.4391e-02, 1.8093e-02, 8.7719e-02,
        5.7185e-02, 1.3908e-02, 2.0330e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:42,362][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([1.0000e+00, 9.9448e-38, 6.0156e-28, 2.7972e-38, 1.7910e-41, 6.0638e-35,
        1.9550e-38, 7.9096e-34, 2.9466e-38], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:42,363][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([4.8948e-04, 5.5135e-01, 6.3348e-02, 2.3008e-01, 8.8838e-02, 3.8162e-02,
        8.3089e-03, 1.6606e-02, 2.8210e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:42,364][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.5090, 0.0057, 0.0082, 0.0264, 0.1693, 0.0075, 0.0056, 0.0028, 0.2656],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:42,364][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0007, 0.1630, 0.0098, 0.0944, 0.2583, 0.0296, 0.2156, 0.1167, 0.1120],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:42,367][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Jonathan] are: tensor([0.0039, 0.4464, 0.0019, 0.3874, 0.0220, 0.0046, 0.0045, 0.0495, 0.0130,
        0.0668], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:42,369][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Jonathan] are: tensor([1.4198e-03, 8.9715e-01, 2.0056e-02, 2.5957e-02, 1.2086e-02, 2.9618e-02,
        7.5774e-03, 1.2934e-03, 4.2862e-03, 5.5530e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:42,375][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Jonathan] are: tensor([0.0006, 0.3997, 0.0102, 0.0474, 0.0376, 0.0195, 0.0101, 0.4684, 0.0013,
        0.0052], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:42,376][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Jonathan] are: tensor([6.0724e-02, 9.2110e-01, 5.6025e-03, 5.1122e-03, 1.8970e-03, 2.7641e-03,
        4.7084e-04, 7.1582e-04, 7.8606e-04, 8.2436e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:42,377][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Jonathan] are: tensor([9.9897e-05, 5.7726e-01, 1.2988e-01, 2.2563e-01, 1.5436e-02, 2.5705e-02,
        9.3483e-03, 1.0837e-02, 2.1911e-03, 3.6116e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:42,377][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Jonathan] are: tensor([0.0008, 0.3295, 0.2988, 0.0529, 0.0136, 0.0119, 0.1005, 0.0712, 0.0972,
        0.0236], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:42,378][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Jonathan] are: tensor([2.7179e-07, 4.4615e-01, 1.9982e-02, 2.1817e-01, 7.0715e-03, 2.5245e-01,
        3.9868e-03, 4.8165e-02, 1.9440e-03, 2.0807e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:42,380][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Jonathan] are: tensor([2.9877e-05, 7.1924e-01, 8.7905e-02, 4.8554e-02, 1.5507e-02, 1.0488e-01,
        1.0174e-02, 7.5551e-03, 5.6718e-03, 4.8104e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:42,383][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Jonathan] are: tensor([1.0000e+00, 6.8173e-42, 5.8351e-31, 1.6059e-42, 0.0000e+00, 3.2119e-39,
        4.1058e-43, 8.1939e-38, 3.3491e-43, 0.0000e+00], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:42,389][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Jonathan] are: tensor([0.0020, 0.3213, 0.1247, 0.2750, 0.1874, 0.0490, 0.0077, 0.0204, 0.0042,
        0.0082], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:42,390][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Jonathan] are: tensor([0.0238, 0.0027, 0.0464, 0.0737, 0.5898, 0.0169, 0.0116, 0.0016, 0.1537,
        0.0798], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:42,390][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Jonathan] are: tensor([2.6471e-05, 8.4296e-02, 5.2366e-03, 1.3843e-02, 3.6864e-01, 3.7807e-02,
        4.2551e-01, 4.5353e-02, 8.5811e-03, 1.0704e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:42,391][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0117, 0.4483, 0.0007, 0.3476, 0.0367, 0.0029, 0.0030, 0.0252, 0.0076,
        0.0826, 0.0336], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:42,392][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([3.0620e-03, 9.6476e-01, 4.2677e-03, 8.4414e-03, 5.1407e-03, 8.2380e-03,
        1.8817e-03, 2.6738e-04, 2.4377e-03, 1.8616e-04, 1.3209e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:42,395][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0027, 0.4794, 0.0039, 0.2209, 0.0180, 0.0059, 0.0057, 0.1930, 0.0013,
        0.0497, 0.0194], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:42,397][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([5.2585e-01, 4.6929e-01, 1.3601e-03, 1.6933e-03, 2.1935e-04, 6.4806e-04,
        1.1388e-04, 2.4390e-05, 2.6416e-04, 3.6578e-04, 1.6740e-04],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:42,400][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([5.4789e-04, 6.9467e-01, 9.4800e-02, 1.4711e-01, 7.2164e-03, 1.5088e-02,
        3.2234e-03, 5.8555e-03, 2.3419e-03, 4.9950e-03, 2.4158e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:42,403][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([2.7193e-04, 5.5280e-01, 1.6333e-01, 4.9095e-02, 1.2359e-02, 6.0125e-03,
        4.6198e-02, 9.6312e-02, 2.6903e-02, 1.5366e-02, 3.1346e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:42,403][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([2.7747e-06, 4.6829e-01, 1.4708e-02, 2.1346e-01, 4.0076e-03, 2.1622e-01,
        2.8363e-03, 5.9705e-02, 1.0610e-03, 3.3054e-03, 1.6411e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:42,404][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([9.2140e-05, 7.2467e-01, 1.0458e-01, 2.9681e-02, 1.5687e-02, 7.0076e-02,
        1.7943e-02, 8.0629e-03, 1.1903e-02, 5.2704e-04, 1.6782e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:42,405][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([1.0000e+00, 6.8301e-35, 6.8853e-26, 1.0149e-35, 6.5825e-39, 1.2587e-32,
        3.5924e-36, 5.5056e-32, 3.1671e-36, 7.3102e-41, 1.2994e-36],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:42,406][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0009, 0.6817, 0.0213, 0.1620, 0.0507, 0.0206, 0.0052, 0.0077, 0.0028,
        0.0059, 0.0411], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:42,409][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0469, 0.0075, 0.0228, 0.0237, 0.5492, 0.0151, 0.0334, 0.0062, 0.2511,
        0.0420, 0.0021], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:42,411][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([7.8351e-05, 1.0040e-01, 6.2951e-03, 4.4198e-02, 1.2771e-01, 1.7559e-02,
        5.1188e-01, 4.3981e-02, 2.6946e-02, 9.7316e-02, 2.3637e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:42,417][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0263, 0.1776, 0.0199, 0.2673, 0.0352, 0.0454, 0.0311, 0.1450, 0.0727,
        0.0844, 0.0815, 0.0135], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:42,417][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0137, 0.8684, 0.0165, 0.0197, 0.0216, 0.0278, 0.0086, 0.0014, 0.0084,
        0.0016, 0.0069, 0.0054], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:42,418][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([1.0769e-03, 1.6356e-01, 9.6439e-03, 1.3848e-01, 1.2097e-02, 1.0430e-02,
        3.7445e-03, 6.2864e-01, 4.3469e-04, 2.6050e-02, 4.6150e-03, 1.2306e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:42,419][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([1.1985e-01, 8.6609e-01, 4.0756e-03, 5.1498e-03, 4.9749e-04, 1.6216e-03,
        2.1590e-04, 7.0994e-05, 4.9614e-04, 7.5836e-04, 5.1687e-04, 6.5281e-04],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:42,420][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0004, 0.3124, 0.2530, 0.2543, 0.0227, 0.0454, 0.0183, 0.0362, 0.0050,
        0.0094, 0.0362, 0.0067], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:42,422][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0030, 0.3095, 0.2436, 0.0705, 0.0214, 0.0124, 0.0539, 0.1195, 0.0624,
        0.0284, 0.0537, 0.0216], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:42,425][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([4.9011e-07, 3.7099e-01, 2.2772e-02, 3.2842e-01, 4.0251e-03, 1.9293e-01,
        1.7546e-03, 5.8632e-02, 1.0717e-03, 2.8715e-03, 1.4577e-02, 1.9497e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:42,430][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0009, 0.3970, 0.1537, 0.0892, 0.0650, 0.1373, 0.0409, 0.0242, 0.0197,
        0.0046, 0.0447, 0.0227], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:42,431][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([1.0000e+00, 2.3822e-44, 3.6800e-33, 1.4013e-45, 0.0000e+00, 7.3134e-42,
        0.0000e+00, 5.3476e-41, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:42,432][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0026, 0.3954, 0.0793, 0.2734, 0.1133, 0.0308, 0.0082, 0.0132, 0.0053,
        0.0104, 0.0546, 0.0136], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:42,433][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0852, 0.0024, 0.1166, 0.0107, 0.4046, 0.0688, 0.0283, 0.0017, 0.2361,
        0.0153, 0.0046, 0.0257], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:42,434][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([7.2125e-06, 5.3476e-03, 3.3419e-03, 4.8990e-03, 6.6043e-02, 1.0994e-02,
        1.2178e-01, 3.5496e-02, 4.0576e-03, 5.9085e-03, 4.0316e-02, 7.0181e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:42,436][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.0080, 0.1533, 0.0140, 0.2564, 0.0223, 0.0210, 0.0246, 0.0937, 0.0889,
        0.1399, 0.1151, 0.0087, 0.0543], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:42,439][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([1.7928e-03, 9.4433e-01, 1.0242e-02, 1.1340e-02, 7.8518e-03, 1.4218e-02,
        3.8455e-03, 3.7598e-04, 2.3921e-03, 2.7919e-04, 1.8304e-03, 1.3020e-03,
        1.9549e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:42,444][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.0005, 0.2032, 0.0097, 0.3442, 0.0133, 0.0069, 0.0033, 0.2671, 0.0013,
        0.0286, 0.0234, 0.0053, 0.0932], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:42,445][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([6.7230e-02, 9.2330e-01, 3.2278e-03, 2.6738e-03, 3.3432e-04, 7.7974e-04,
        1.1601e-04, 7.6060e-05, 1.9440e-04, 2.1829e-04, 7.2855e-04, 1.0960e-03,
        2.6782e-05], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:42,446][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([6.2008e-05, 7.5401e-01, 8.7266e-02, 1.3265e-01, 6.0087e-03, 6.0593e-03,
        1.4878e-03, 3.1740e-03, 5.9424e-04, 9.8960e-04, 4.6974e-03, 8.3578e-04,
        2.1586e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:42,447][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.0014, 0.2915, 0.1581, 0.0666, 0.0141, 0.0099, 0.0689, 0.1444, 0.0582,
        0.0398, 0.0603, 0.0280, 0.0588], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:42,448][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([4.3610e-07, 5.8964e-01, 1.4408e-02, 1.6779e-01, 2.4388e-03, 2.0002e-01,
        2.9163e-03, 9.7501e-03, 1.3587e-03, 6.1606e-04, 5.3339e-03, 4.3655e-03,
        1.3600e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:42,449][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([1.1538e-05, 8.1634e-01, 8.4707e-02, 2.3452e-02, 9.2636e-03, 5.1234e-02,
        5.8776e-03, 2.0336e-03, 2.5511e-03, 4.7727e-05, 3.4968e-03, 8.1763e-04,
        1.6763e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:42,453][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([1.0000e+00, 3.9586e-39, 6.9962e-29, 5.3752e-40, 6.8664e-44, 1.1336e-36,
        1.6412e-40, 7.5451e-36, 9.9000e-41, 1.4013e-45, 5.3305e-41, 0.0000e+00,
        2.1019e-44], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:42,458][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.0009, 0.6384, 0.0558, 0.1407, 0.0719, 0.0299, 0.0050, 0.0081, 0.0022,
        0.0026, 0.0331, 0.0040, 0.0075], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:42,459][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.0118, 0.0004, 0.3037, 0.0139, 0.1459, 0.0420, 0.0565, 0.0030, 0.3512,
        0.0426, 0.0038, 0.0239, 0.0013], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:42,460][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([2.0885e-06, 4.6521e-04, 2.3144e-03, 2.4398e-03, 1.9018e-02, 1.2532e-02,
        1.2218e-01, 1.4473e-02, 2.0669e-02, 9.8044e-03, 4.6018e-02, 7.2503e-01,
        2.5062e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:42,461][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0257, 0.2737, 0.0113, 0.1572, 0.0275, 0.0402, 0.0196, 0.1037, 0.0730,
        0.0642, 0.0655, 0.0123, 0.0942, 0.0320], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,461][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0042, 0.8565, 0.0211, 0.0344, 0.0168, 0.0299, 0.0093, 0.0025, 0.0070,
        0.0018, 0.0071, 0.0042, 0.0013, 0.0041], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,463][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.3930e-04, 4.6225e-01, 3.8775e-03, 3.0703e-01, 3.3269e-02, 3.7878e-03,
        3.0007e-03, 1.2982e-01, 1.8115e-04, 1.4484e-02, 4.3528e-03, 1.3024e-03,
        3.5980e-02, 4.2562e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,466][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.6029e-02, 9.6505e-01, 2.1246e-03, 1.0918e-02, 7.4123e-04, 1.1446e-03,
        1.6919e-04, 1.1768e-04, 1.4473e-04, 1.5795e-03, 5.5934e-04, 8.1301e-04,
        7.7778e-05, 5.2878e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,469][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.0556e-04, 2.9475e-01, 3.4913e-01, 1.9061e-01, 2.2088e-02, 4.6777e-02,
        2.2123e-02, 2.0242e-02, 4.7671e-03, 4.1585e-03, 2.7602e-02, 4.6900e-03,
        1.0425e-02, 2.5233e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,472][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([3.8920e-04, 4.1504e-01, 2.7392e-01, 4.4545e-02, 6.9192e-03, 7.6331e-03,
        5.2014e-02, 7.8011e-02, 4.0445e-02, 1.2170e-02, 2.1450e-02, 1.2685e-02,
        2.7413e-02, 7.3645e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,473][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([4.0780e-08, 5.2217e-01, 9.1568e-03, 2.7236e-01, 4.4487e-03, 1.5594e-01,
        1.0137e-03, 1.9278e-02, 5.0394e-04, 7.6513e-04, 6.7498e-03, 1.1211e-03,
        6.2879e-03, 2.0136e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,474][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([7.9845e-05, 5.4437e-01, 1.6697e-01, 7.4758e-02, 2.6449e-02, 8.9004e-02,
        3.3184e-02, 1.6204e-02, 8.9575e-03, 1.6631e-03, 2.3330e-02, 7.4137e-03,
        4.6852e-03, 2.9323e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,474][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([1.0000e+00, 1.4013e-45, 6.8727e-34, 0.0000e+00, 0.0000e+00, 1.0370e-42,
        0.0000e+00, 1.1863e-41, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,475][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0011, 0.4829, 0.1299, 0.1027, 0.0938, 0.0878, 0.0151, 0.0096, 0.0052,
        0.0022, 0.0487, 0.0099, 0.0065, 0.0047], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,478][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0859, 0.0037, 0.1088, 0.0192, 0.1367, 0.0712, 0.0142, 0.0066, 0.4392,
        0.0304, 0.0034, 0.0152, 0.0009, 0.0646], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,480][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.9501e-06, 1.4036e-03, 1.2542e-03, 1.4976e-03, 1.8162e-02, 7.3826e-03,
        6.1637e-02, 1.9189e-02, 8.6613e-03, 4.2451e-03, 1.7184e-02, 5.8271e-01,
        1.5196e-01, 1.2471e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,603][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:42,605][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:42,606][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:42,607][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:42,608][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:42,608][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:42,609][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:42,609][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:42,610][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:42,611][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:42,611][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:42,612][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:42,613][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:16:42,613][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.0500, 0.9500], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:42,614][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.0514, 0.9486], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:42,615][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.0283, 0.9717], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:42,619][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.4697, 0.5303], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:42,621][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.0022, 0.9978], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:42,621][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.0663, 0.9337], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:42,622][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.0095, 0.9905], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:42,623][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.8421, 0.1579], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:42,624][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.3658, 0.6342], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:42,626][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.0645, 0.9355], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:42,629][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.7110, 0.2890], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:42,634][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.0346, 0.9654], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:16:42,635][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0901, 0.5683, 0.3416], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:42,636][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([6.9371e-03, 9.9306e-01, 2.8496e-06], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:42,636][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([8.9828e-04, 9.9882e-01, 2.8099e-04], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:42,637][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([6.1195e-02, 9.3876e-01, 4.2063e-05], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:42,638][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([3.6300e-04, 6.5744e-03, 9.9306e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:42,640][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0810, 0.8579, 0.0611], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:42,642][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([6.3633e-04, 9.9936e-01, 1.7764e-07], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:42,645][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([5.5600e-01, 4.4382e-01, 1.8005e-04], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:42,648][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3763, 0.6077, 0.0160], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:42,649][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([1.0258e-02, 9.8974e-01, 1.6184e-06], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:42,649][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([9.9681e-01, 2.3209e-03, 8.6721e-04], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:42,650][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([2.5972e-02, 9.7403e-01, 4.5482e-09], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:16:42,651][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Jonathan] are: tensor([0.0041, 0.2315, 0.0012, 0.7632], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:42,651][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Jonathan] are: tensor([1.3210e-02, 9.5375e-01, 8.3190e-04, 3.2212e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:42,653][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Jonathan] are: tensor([1.1886e-03, 9.9231e-01, 5.3815e-04, 5.9658e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:42,657][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Jonathan] are: tensor([0.7237, 0.1462, 0.0043, 0.1258], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:42,660][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Jonathan] are: tensor([1.5046e-04, 1.8924e-01, 5.2581e-01, 2.8481e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:42,662][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Jonathan] are: tensor([0.0045, 0.9523, 0.0068, 0.0364], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:42,663][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Jonathan] are: tensor([2.5369e-03, 9.8460e-01, 1.6811e-05, 1.2851e-02], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:42,663][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Jonathan] are: tensor([0.4397, 0.5406, 0.0011, 0.0185], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:42,664][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Jonathan] are: tensor([2.9959e-02, 4.4529e-02, 3.9614e-04, 9.2512e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:42,665][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Jonathan] are: tensor([2.4306e-02, 9.7208e-01, 8.9314e-07, 3.6163e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:42,667][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Jonathan] are: tensor([0.8132, 0.0079, 0.0023, 0.1765], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:42,669][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Jonathan] are: tensor([5.0415e-03, 9.9492e-01, 2.3650e-09, 3.7479e-05], device='cuda:0') for source tokens [After Benjamin and Jonathan]
[2024-07-24 10:16:42,672][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([3.9590e-02, 1.4375e-01, 7.7050e-04, 7.7415e-01, 4.1742e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:42,675][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0384, 0.8589, 0.0031, 0.0721, 0.0275], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:42,676][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0064, 0.9450, 0.0103, 0.0110, 0.0273], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:42,677][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.5732, 0.0707, 0.0738, 0.0571, 0.2252], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:42,677][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([3.0568e-04, 5.8273e-02, 8.2037e-01, 6.4073e-02, 5.6982e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:42,678][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.0329, 0.8199, 0.0269, 0.0851, 0.0352], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:42,679][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([4.1366e-03, 9.5364e-01, 4.8598e-04, 1.1301e-02, 3.0439e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:42,683][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.4304, 0.3136, 0.0077, 0.0555, 0.1929], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:42,687][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.0309, 0.0701, 0.0013, 0.3771, 0.5206], device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:42,689][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([1.7218e-01, 7.6624e-01, 1.9304e-04, 1.3282e-02, 4.8103e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:42,690][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([1.7482e-01, 7.4829e-04, 3.8754e-03, 2.1193e-03, 8.1843e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:42,690][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([5.7134e-02, 9.4175e-01, 6.3505e-07, 3.7296e-04, 7.3904e-04],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went]
[2024-07-24 10:16:42,691][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0106, 0.1553, 0.0993, 0.5668, 0.0181, 0.1499], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:42,692][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([5.0968e-03, 9.8829e-01, 4.4524e-05, 5.0406e-03, 1.4497e-03, 7.8670e-05],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:42,694][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([2.7668e-04, 9.8464e-01, 9.1828e-04, 9.2078e-03, 3.1000e-03, 1.8529e-03],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:42,698][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.5287, 0.3521, 0.0011, 0.0273, 0.0897, 0.0011], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:42,701][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([5.9223e-05, 7.1758e-02, 7.8052e-01, 8.1032e-02, 1.8307e-02, 4.8327e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:42,703][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0014, 0.9436, 0.0051, 0.0319, 0.0033, 0.0148], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:42,703][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([2.4152e-04, 9.9857e-01, 1.2354e-06, 8.2678e-04, 3.1880e-04, 4.6193e-05],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:42,704][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.5732, 0.4113, 0.0008, 0.0051, 0.0057, 0.0038], device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:42,705][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([9.9496e-04, 2.2319e-03, 1.3824e-04, 1.8031e-01, 8.0568e-01, 1.0651e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:42,706][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([5.7415e-03, 9.9341e-01, 1.2350e-06, 5.8562e-04, 2.5777e-04, 7.7506e-06],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:42,707][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([8.4493e-01, 2.0813e-03, 6.1091e-04, 5.0223e-03, 1.4677e-01, 5.8779e-04],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:42,710][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.9127e-02, 9.8077e-01, 1.8385e-08, 4.6356e-05, 5.9960e-05, 6.0310e-07],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to]
[2024-07-24 10:16:42,714][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0159, 0.0803, 0.0729, 0.5356, 0.0185, 0.1515, 0.1254],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:42,716][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([4.9780e-04, 9.9724e-01, 6.5090e-05, 1.6392e-03, 4.4251e-04, 8.3864e-05,
        3.5793e-05], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:42,717][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([4.2859e-05, 9.8982e-01, 4.0028e-03, 1.5289e-03, 6.0003e-04, 3.7885e-03,
        2.2124e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:42,718][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.4106, 0.1731, 0.0248, 0.0678, 0.0943, 0.0319, 0.1976],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:42,718][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([1.0435e-06, 1.4919e-02, 9.3970e-01, 1.3686e-02, 3.1170e-03, 1.9767e-02,
        8.8054e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:42,719][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([2.0016e-04, 9.7380e-01, 3.1528e-03, 6.3178e-03, 9.0025e-04, 1.5052e-02,
        5.7267e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:42,721][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([3.1733e-05, 9.9933e-01, 6.9981e-06, 3.6322e-04, 1.7324e-04, 8.4672e-05,
        8.0164e-06], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:42,725][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0917, 0.8558, 0.0049, 0.0061, 0.0045, 0.0175, 0.0195],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:42,728][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([3.0996e-03, 3.7684e-03, 5.1866e-04, 1.5874e-01, 6.0050e-01, 4.1208e-02,
        1.9217e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:42,730][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([4.7930e-04, 9.9916e-01, 1.6916e-06, 1.6591e-04, 1.8693e-04, 7.9426e-06,
        7.1392e-07], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:42,730][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.6182, 0.0065, 0.0390, 0.0104, 0.2484, 0.0294, 0.0481],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:42,731][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([5.7962e-03, 9.9391e-01, 1.1510e-07, 1.3552e-04, 1.1366e-04, 7.0316e-06,
        3.3435e-05], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the]
[2024-07-24 10:16:42,732][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.0102, 0.1867, 0.0034, 0.6379, 0.0270, 0.0061, 0.0108, 0.1179],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:42,733][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([1.0238e-02, 9.7472e-01, 3.4169e-04, 4.4371e-03, 7.9377e-03, 1.2415e-03,
        5.8165e-04, 5.0622e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:42,734][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([2.1600e-05, 9.8780e-01, 3.0922e-03, 4.8081e-03, 1.0770e-03, 1.3325e-03,
        4.9566e-05, 1.8176e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:42,738][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.2905, 0.0042, 0.0030, 0.0098, 0.0190, 0.0856, 0.5759, 0.0120],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:42,741][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([1.6998e-06, 4.4301e-03, 9.5005e-01, 5.8354e-03, 1.9448e-03, 2.7528e-02,
        6.9511e-03, 3.2590e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:42,743][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.0014, 0.6392, 0.0267, 0.0823, 0.0178, 0.1877, 0.0126, 0.0322],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:42,744][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([2.2468e-04, 9.8034e-01, 4.5077e-05, 7.9910e-03, 6.7900e-03, 2.4808e-03,
        1.8455e-04, 1.9458e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:42,745][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.1979, 0.6805, 0.0008, 0.0447, 0.0370, 0.0052, 0.0063, 0.0276],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:42,746][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([6.9482e-04, 2.1431e-02, 2.4803e-04, 2.2274e-01, 4.3812e-01, 1.4977e-02,
        7.9510e-02, 2.2228e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:42,746][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([1.1609e-03, 9.9276e-01, 1.4848e-05, 8.5857e-04, 1.8605e-03, 9.6003e-05,
        3.2003e-06, 3.2431e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:42,749][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.0672, 0.0028, 0.1217, 0.0444, 0.6289, 0.0636, 0.0659, 0.0055],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:42,751][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([2.7374e-03, 9.9656e-01, 4.9469e-07, 2.3014e-04, 2.9655e-04, 4.0815e-05,
        1.2871e-04, 9.9795e-06], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant]
[2024-07-24 10:16:42,757][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0129, 0.4683, 0.0234, 0.3180, 0.0116, 0.0360, 0.0365, 0.0318, 0.0616],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:42,757][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([1.6997e-03, 9.8401e-01, 2.5889e-04, 1.0125e-02, 2.3562e-03, 5.2929e-04,
        1.5507e-04, 6.3530e-04, 2.3481e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:42,758][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([5.6095e-05, 9.8232e-01, 1.4079e-03, 3.9841e-03, 1.8745e-03, 2.2926e-03,
        9.0199e-05, 6.8477e-03, 1.1222e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:42,759][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3848, 0.1716, 0.0067, 0.0508, 0.0768, 0.0212, 0.0398, 0.0297, 0.2188],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:42,760][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([7.5211e-06, 3.0842e-02, 8.5995e-01, 4.2258e-02, 7.6537e-03, 3.5535e-02,
        1.5543e-02, 5.9657e-03, 2.2445e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:42,761][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([6.2099e-04, 7.3645e-01, 5.0601e-02, 2.6691e-02, 1.1708e-02, 8.7944e-02,
        3.7288e-03, 7.3701e-02, 8.5593e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:42,764][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([1.2427e-04, 9.9656e-01, 1.7044e-05, 1.7306e-03, 6.9693e-04, 4.1525e-04,
        3.5897e-05, 4.0809e-04, 1.1077e-05], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:42,769][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0547, 0.7296, 0.0067, 0.0196, 0.0259, 0.0319, 0.0398, 0.0787, 0.0132],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:42,771][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([3.9309e-04, 1.1698e-03, 1.0699e-04, 7.2502e-02, 3.1368e-01, 6.3600e-03,
        3.8133e-02, 3.0220e-01, 2.6546e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:42,771][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([4.4853e-04, 9.9677e-01, 9.3822e-06, 8.4331e-04, 7.3244e-04, 3.5904e-05,
        2.4621e-06, 1.1493e-03, 1.0081e-05], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:42,772][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.5090, 0.0057, 0.0082, 0.0264, 0.1693, 0.0075, 0.0056, 0.0028, 0.2656],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:42,773][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([4.6740e-03, 9.9487e-01, 1.4887e-07, 2.1655e-04, 2.0502e-04, 4.7959e-06,
        6.4124e-06, 1.9128e-05, 3.5061e-06], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant,]
[2024-07-24 10:16:42,774][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Jonathan] are: tensor([0.0039, 0.4464, 0.0019, 0.3874, 0.0220, 0.0046, 0.0045, 0.0495, 0.0130,
        0.0668], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:42,776][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Jonathan] are: tensor([0.0016, 0.8327, 0.0259, 0.0594, 0.0482, 0.0127, 0.0054, 0.0068, 0.0035,
        0.0037], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:42,779][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Jonathan] are: tensor([6.0925e-05, 8.8404e-01, 3.1564e-02, 2.4729e-02, 2.2111e-02, 2.3164e-02,
        1.6426e-03, 6.7945e-03, 5.3956e-03, 4.9915e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:42,784][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Jonathan] are: tensor([0.0513, 0.0128, 0.0301, 0.0362, 0.0688, 0.0785, 0.0700, 0.0093, 0.6141,
        0.0289], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:42,785][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Jonathan] are: tensor([2.7931e-06, 1.3851e-01, 6.5813e-01, 1.1689e-01, 1.7328e-02, 4.6901e-02,
        9.4738e-03, 1.1639e-02, 4.1266e-04, 7.1694e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:42,786][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Jonathan] are: tensor([1.6361e-04, 7.1857e-01, 5.2389e-02, 2.5408e-02, 1.1416e-02, 1.4426e-01,
        1.4130e-02, 2.1133e-02, 1.0727e-02, 1.8059e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:42,787][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Jonathan] are: tensor([1.3987e-04, 8.4106e-01, 2.3637e-03, 5.6723e-02, 3.0098e-02, 5.3373e-02,
        3.5150e-03, 1.1188e-02, 7.1319e-04, 8.2343e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:42,787][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Jonathan] are: tensor([0.0094, 0.4006, 0.0407, 0.0661, 0.0598, 0.1212, 0.0920, 0.1770, 0.0257,
        0.0076], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:42,790][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Jonathan] are: tensor([0.0051, 0.0061, 0.0009, 0.0504, 0.0640, 0.0126, 0.0327, 0.3473, 0.1321,
        0.3488], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:42,793][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Jonathan] are: tensor([9.6497e-04, 9.8204e-01, 1.3884e-04, 6.6805e-03, 5.2315e-03, 4.7816e-04,
        9.9162e-05, 4.0458e-03, 1.1404e-04, 2.0554e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:42,798][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Jonathan] are: tensor([0.0238, 0.0027, 0.0464, 0.0737, 0.5898, 0.0169, 0.0116, 0.0016, 0.1537,
        0.0798], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:42,799][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Jonathan] are: tensor([8.5174e-04, 9.9767e-01, 7.7222e-07, 2.2204e-04, 1.0643e-03, 6.0241e-05,
        6.2348e-05, 3.0318e-05, 2.6368e-06, 3.5921e-05], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan]
[2024-07-24 10:16:42,800][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0117, 0.4483, 0.0007, 0.3476, 0.0367, 0.0029, 0.0030, 0.0252, 0.0076,
        0.0826, 0.0336], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:42,801][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([7.6298e-04, 9.8403e-01, 1.2923e-04, 1.0558e-02, 2.1291e-03, 4.5726e-04,
        2.3198e-04, 8.2676e-04, 9.7541e-05, 3.2328e-04, 4.5143e-04],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:42,801][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([4.7481e-06, 9.7314e-01, 1.9855e-03, 8.1446e-03, 3.6916e-03, 3.6462e-03,
        2.8557e-04, 7.5712e-03, 1.4372e-03, 6.0155e-05, 3.4616e-05],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:42,804][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.1357, 0.0528, 0.0233, 0.0215, 0.0392, 0.0307, 0.1459, 0.0172, 0.5189,
        0.0106, 0.0042], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:42,806][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([4.1533e-06, 4.8104e-02, 7.5632e-01, 7.6256e-02, 1.4919e-02, 3.1864e-02,
        2.4196e-02, 1.6536e-02, 7.9280e-04, 9.0215e-04, 3.0109e-02],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:42,810][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([1.1717e-04, 9.4051e-01, 6.0042e-03, 1.7831e-02, 1.8908e-03, 2.0331e-02,
        1.9937e-03, 9.1879e-03, 1.1688e-03, 6.3133e-04, 3.3801e-04],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:42,812][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([4.0378e-05, 9.9253e-01, 4.2810e-05, 2.8793e-03, 1.8593e-03, 7.3281e-04,
        1.1052e-04, 1.6581e-03, 1.1319e-05, 1.8072e-05, 1.2093e-04],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:42,813][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0091, 0.6821, 0.0081, 0.0567, 0.0333, 0.0421, 0.0739, 0.0781, 0.0083,
        0.0030, 0.0052], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:42,814][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([2.6888e-04, 3.8092e-03, 6.2716e-05, 4.5545e-02, 1.5753e-01, 5.4267e-03,
        2.1697e-02, 1.5268e-01, 2.8685e-02, 4.6355e-01, 1.2074e-01],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:42,815][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([2.3951e-05, 9.9882e-01, 2.3467e-06, 2.5000e-04, 2.5368e-04, 8.0678e-06,
        9.0844e-07, 6.2929e-04, 1.7238e-06, 1.9272e-06, 3.3544e-06],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:42,815][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0469, 0.0075, 0.0228, 0.0237, 0.5492, 0.0151, 0.0334, 0.0062, 0.2511,
        0.0420, 0.0021], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:42,817][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([3.7000e-04, 9.9948e-01, 1.5356e-08, 8.9694e-05, 4.0683e-05, 6.8455e-07,
        5.4728e-06, 6.1683e-07, 1.4638e-07, 1.3115e-05, 5.1704e-07],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave]
[2024-07-24 10:16:42,821][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0263, 0.1776, 0.0199, 0.2673, 0.0352, 0.0454, 0.0311, 0.1450, 0.0727,
        0.0844, 0.0815, 0.0135], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:42,824][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([3.5388e-03, 9.7800e-01, 5.3908e-04, 9.8088e-03, 3.6073e-03, 1.2960e-03,
        6.0356e-04, 9.7535e-04, 3.2452e-04, 6.5116e-04, 4.3659e-04, 2.2096e-04],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:42,826][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([1.0789e-04, 9.3546e-01, 1.2423e-02, 5.4427e-03, 5.1616e-03, 1.8358e-02,
        1.5683e-03, 1.4600e-02, 6.4047e-03, 1.9376e-04, 1.3731e-04, 1.4326e-04],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:42,827][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0933, 0.0068, 0.0596, 0.0123, 0.0458, 0.0757, 0.0783, 0.0974, 0.4150,
        0.0151, 0.0557, 0.0451], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:42,828][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([7.2487e-06, 6.2517e-02, 7.6419e-01, 5.6718e-02, 1.2573e-02, 5.5655e-02,
        1.9839e-02, 1.3817e-02, 7.6621e-04, 5.9086e-04, 1.2888e-02, 4.3862e-04],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:42,829][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0008, 0.7679, 0.0122, 0.0183, 0.0121, 0.1379, 0.0066, 0.0340, 0.0065,
        0.0014, 0.0012, 0.0013], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:42,829][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([2.9520e-04, 9.8156e-01, 2.1879e-04, 5.4632e-03, 4.0185e-03, 4.5081e-03,
        5.4662e-04, 2.8491e-03, 7.4279e-05, 8.7162e-05, 3.3761e-04, 4.1742e-05],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:42,833][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0540, 0.5465, 0.0136, 0.0353, 0.0259, 0.0735, 0.0889, 0.1264, 0.0123,
        0.0075, 0.0053, 0.0106], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:42,837][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0065, 0.0192, 0.0017, 0.0955, 0.1454, 0.0218, 0.0212, 0.0661, 0.0761,
        0.2356, 0.1914, 0.1195], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:42,840][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([3.1549e-03, 9.8810e-01, 5.0640e-05, 1.9664e-03, 3.3866e-03, 3.2234e-04,
        2.5986e-05, 2.8327e-03, 4.3591e-05, 6.8131e-05, 3.4497e-05, 1.1097e-05],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:42,841][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0852, 0.0024, 0.1166, 0.0107, 0.4046, 0.0688, 0.0283, 0.0017, 0.2361,
        0.0153, 0.0046, 0.0257], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:42,842][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([9.8117e-03, 9.8348e-01, 1.0225e-05, 1.0387e-03, 3.3778e-03, 2.5385e-04,
        2.2026e-04, 1.8874e-04, 1.3862e-05, 2.7314e-04, 6.6883e-04, 6.6403e-04],
       device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a]
[2024-07-24 10:16:42,842][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.0080, 0.1533, 0.0140, 0.2564, 0.0223, 0.0210, 0.0246, 0.0937, 0.0889,
        0.1399, 0.1151, 0.0087, 0.0543], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:42,843][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.0028, 0.9189, 0.0052, 0.0264, 0.0155, 0.0087, 0.0026, 0.0029, 0.0036,
        0.0031, 0.0054, 0.0013, 0.0036], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:42,845][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([1.4052e-04, 7.9066e-01, 7.0516e-02, 1.4808e-02, 1.2275e-02, 6.4435e-02,
        1.9177e-03, 2.5461e-02, 1.8610e-02, 3.1371e-04, 5.0860e-04, 2.2612e-04,
        1.2568e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:42,847][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([1.3004e-02, 3.5162e-05, 3.3465e-03, 1.3655e-03, 4.7591e-03, 2.3469e-02,
        3.2255e-01, 6.4805e-02, 3.7881e-01, 1.6425e-02, 2.7237e-02, 1.4108e-01,
        3.1073e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:42,850][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([4.8317e-07, 9.5398e-03, 9.1501e-01, 1.3976e-02, 2.0145e-03, 4.0452e-02,
        7.8834e-03, 4.3132e-03, 7.4090e-04, 1.5909e-04, 5.7134e-03, 1.6613e-04,
        2.6610e-05], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:42,854][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([7.7867e-05, 3.6788e-01, 4.4820e-02, 3.1108e-02, 7.8522e-03, 3.4774e-01,
        1.6659e-02, 1.4903e-01, 1.9216e-02, 1.9163e-03, 1.0251e-02, 1.3859e-03,
        2.0691e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:42,855][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([3.4200e-05, 8.8007e-01, 1.3063e-03, 2.2887e-02, 1.5925e-02, 5.7251e-02,
        1.9515e-03, 1.6490e-02, 2.3794e-04, 1.9850e-04, 3.4566e-03, 5.2276e-05,
        1.4360e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:42,855][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.0059, 0.4365, 0.0195, 0.0419, 0.0245, 0.1299, 0.0990, 0.1715, 0.0367,
        0.0062, 0.0140, 0.0097, 0.0047], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:42,856][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([3.3756e-04, 3.5343e-03, 1.8409e-04, 2.9567e-02, 4.6186e-02, 3.4443e-03,
        6.8832e-03, 7.9404e-02, 1.8206e-02, 1.3585e-01, 2.3133e-01, 6.5177e-02,
        3.7990e-01], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:42,857][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([5.0283e-04, 9.7799e-01, 9.8429e-05, 2.0534e-03, 5.8297e-03, 5.8499e-04,
        3.6420e-05, 1.2563e-02, 1.2529e-04, 3.1614e-05, 1.4735e-04, 1.2723e-05,
        2.1425e-05], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:42,861][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.0118, 0.0004, 0.3037, 0.0139, 0.1459, 0.0420, 0.0565, 0.0030, 0.3512,
        0.0426, 0.0038, 0.0239, 0.0013], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:42,863][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([8.6304e-03, 9.5228e-01, 5.4236e-05, 4.2678e-03, 6.7984e-03, 3.1621e-03,
        3.6317e-03, 2.3693e-03, 3.7158e-04, 2.5164e-03, 8.6962e-03, 4.9728e-03,
        2.2517e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace]
[2024-07-24 10:16:42,868][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0257, 0.2737, 0.0113, 0.1572, 0.0275, 0.0402, 0.0196, 0.1037, 0.0730,
        0.0642, 0.0655, 0.0123, 0.0942, 0.0320], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,868][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.9260e-03, 9.1631e-01, 7.6527e-03, 2.9453e-02, 1.2959e-02, 7.8765e-03,
        2.7071e-03, 7.1107e-03, 3.4167e-03, 2.2104e-03, 1.9100e-03, 6.6121e-04,
        3.0319e-03, 1.7735e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,869][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.5748e-04, 7.0145e-01, 8.1431e-02, 5.8362e-02, 1.9516e-02, 6.8502e-02,
        3.9591e-03, 3.4905e-02, 2.2263e-02, 2.2217e-03, 1.2915e-03, 5.8070e-04,
        7.1586e-04, 4.6401e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,870][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0805, 0.0076, 0.0327, 0.0122, 0.0366, 0.0532, 0.0405, 0.1119, 0.3723,
        0.0159, 0.0425, 0.0494, 0.0145, 0.1302], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,871][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([4.2421e-06, 5.8198e-02, 8.0761e-01, 4.9328e-02, 8.2697e-03, 3.8619e-02,
        9.5917e-03, 1.0254e-02, 1.0521e-03, 5.9685e-04, 1.5449e-02, 3.3536e-04,
        8.5325e-05, 6.0318e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,873][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([3.2571e-04, 6.7535e-01, 3.8692e-02, 2.4300e-02, 5.5944e-03, 1.8483e-01,
        8.0042e-03, 3.7074e-02, 1.3510e-02, 1.6817e-03, 1.8928e-03, 1.0911e-03,
        8.2042e-04, 6.8323e-03], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,875][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([2.7565e-04, 9.6627e-01, 4.4331e-04, 1.4774e-02, 5.1955e-03, 6.6335e-03,
        5.1239e-04, 4.6468e-03, 1.7616e-04, 2.3478e-04, 3.9714e-04, 4.8310e-05,
        9.3093e-05, 3.0199e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,880][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0368, 0.4766, 0.0243, 0.0457, 0.0381, 0.0873, 0.0696, 0.1245, 0.0205,
        0.0094, 0.0097, 0.0097, 0.0102, 0.0376], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,882][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0017, 0.0051, 0.0010, 0.0434, 0.0595, 0.0111, 0.0144, 0.0628, 0.0543,
        0.1415, 0.1092, 0.0757, 0.3705, 0.0498], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,883][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.4231e-03, 9.8638e-01, 1.8160e-04, 2.7894e-03, 2.8697e-03, 5.7476e-04,
        4.3052e-05, 4.1842e-03, 1.2101e-04, 8.6872e-05, 6.3548e-05, 2.0945e-05,
        1.2361e-05, 2.4818e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,883][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0859, 0.0037, 0.1088, 0.0192, 0.1367, 0.0712, 0.0142, 0.0066, 0.4392,
        0.0304, 0.0034, 0.0152, 0.0009, 0.0646], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,884][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([9.9967e-03, 9.8075e-01, 1.5249e-05, 9.8351e-04, 2.7760e-03, 5.3342e-04,
        2.7693e-04, 4.6102e-04, 5.0793e-05, 3.5253e-04, 6.6633e-04, 9.6163e-04,
        1.4929e-03, 6.8726e-04], device='cuda:0') for source tokens [After Benjamin and Jonathan went to the restaurant, Jonathan gave a necklace to]
[2024-07-24 10:16:42,888][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:16:42,892][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[12822],
        [    1],
        [  170],
        [    4],
        [  515],
        [   34],
        [   58],
        [    6],
        [   60],
        [    1],
        [  259],
        [   21],
        [   27],
        [    1]], device='cuda:0')
[2024-07-24 10:16:42,894][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[13058],
        [    9],
        [ 2517],
        [   37],
        [ 1909],
        [  466],
        [  531],
        [   50],
        [  426],
        [    2],
        [ 1595],
        [  219],
        [  129],
        [   34]], device='cuda:0')
[2024-07-24 10:16:42,897][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[10460],
        [ 2243],
        [ 3490],
        [ 1270],
        [ 1366],
        [ 1713],
        [ 1808],
        [ 1378],
        [ 1478],
        [ 1342],
        [ 1392],
        [ 2097],
        [ 2210],
        [ 2158]], device='cuda:0')
[2024-07-24 10:16:42,899][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 2841],
        [19983],
        [47658],
        [47477],
        [46811],
        [47530],
        [47562],
        [47650],
        [47298],
        [46867],
        [47627],
        [46613],
        [47384],
        [46464]], device='cuda:0')
[2024-07-24 10:16:42,900][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 9600],
        [    1],
        [    1],
        [    3],
        [  477],
        [   38],
        [  562],
        [ 2925],
        [ 5548],
        [ 4258],
        [  219],
        [24404],
        [ 4969],
        [  195]], device='cuda:0')
[2024-07-24 10:16:42,901][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[23939],
        [23642],
        [ 1847],
        [ 6969],
        [ 3497],
        [  777],
        [  837],
        [  826],
        [  671],
        [  673],
        [  825],
        [  680],
        [  662],
        [  662]], device='cuda:0')
[2024-07-24 10:16:42,903][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[14838],
        [22202],
        [17878],
        [20596],
        [19700],
        [18532],
        [19190],
        [21110],
        [18131],
        [20339],
        [20752],
        [18542],
        [21088],
        [18435]], device='cuda:0')
[2024-07-24 10:16:42,906][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 512],
        [1009],
        [ 643],
        [ 617],
        [ 741],
        [ 703],
        [ 653],
        [ 891],
        [ 722],
        [ 716],
        [ 796],
        [ 752],
        [ 819],
        [ 701]], device='cuda:0')
[2024-07-24 10:16:42,909][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[16882],
        [    6],
        [   10],
        [   88],
        [  124],
        [  169],
        [  177],
        [  258],
        [  266],
        [  130],
        [  117],
        [  292],
        [   45],
        [   74]], device='cuda:0')
[2024-07-24 10:16:42,912][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[43117],
        [43652],
        [45292],
        [44999],
        [44610],
        [45134],
        [45228],
        [44312],
        [45262],
        [44665],
        [44758],
        [45068],
        [44417],
        [45104]], device='cuda:0')
[2024-07-24 10:16:42,914][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[9543],
        [9543],
        [9543],
        [9543],
        [9543],
        [9543],
        [9543],
        [9543],
        [9543],
        [9543],
        [9543],
        [9543],
        [9543],
        [9543]], device='cuda:0')
[2024-07-24 10:16:42,915][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[25476],
        [ 3677],
        [ 3509],
        [ 5403],
        [ 5043],
        [ 5351],
        [ 6225],
        [ 5667],
        [ 4952],
        [ 6332],
        [ 4498],
        [ 5857],
        [ 4481],
        [ 4705]], device='cuda:0')
[2024-07-24 10:16:42,916][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[25480],
        [    1],
        [22944],
        [  702],
        [18313],
        [18091],
        [16068],
        [15685],
        [ 6390],
        [ 7220],
        [ 8885],
        [12297],
        [10520],
        [ 7734]], device='cuda:0')
[2024-07-24 10:16:42,919][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[32888],
        [40901],
        [37417],
        [38668],
        [ 6956],
        [ 9463],
        [ 8916],
        [ 9006],
        [10530],
        [ 6084],
        [10239],
        [ 5425],
        [ 5493],
        [ 5696]], device='cuda:0')
[2024-07-24 10:16:42,921][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[10241],
        [ 4337],
        [ 6588],
        [ 6037],
        [ 8692],
        [ 4002],
        [ 7931],
        [ 5057],
        [ 7328],
        [ 6537],
        [ 7516],
        [ 8508],
        [ 7407],
        [ 5001]], device='cuda:0')
[2024-07-24 10:16:42,925][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[15587],
        [21186],
        [21424],
        [20565],
        [20774],
        [22302],
        [22725],
        [21385],
        [21160],
        [21134],
        [20932],
        [21346],
        [21325],
        [20219]], device='cuda:0')
[2024-07-24 10:16:42,928][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[20820],
        [ 9348],
        [ 9328],
        [ 9426],
        [ 9642],
        [ 9342],
        [ 9336],
        [ 9358],
        [ 9364],
        [ 9600],
        [ 9369],
        [ 9369],
        [ 9479],
        [ 9474]], device='cuda:0')
[2024-07-24 10:16:42,929][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[35594],
        [24276],
        [24215],
        [24336],
        [25083],
        [24479],
        [24432],
        [24433],
        [24454],
        [26390],
        [24592],
        [25249],
        [28367],
        [30015]], device='cuda:0')
[2024-07-24 10:16:42,930][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[20584],
        [ 5819],
        [ 5465],
        [ 7601],
        [ 8416],
        [ 5813],
        [ 7703],
        [12257],
        [ 9031],
        [12349],
        [12154],
        [13778],
        [14720],
        [14553]], device='cuda:0')
[2024-07-24 10:16:42,932][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[15894],
        [37580],
        [28339],
        [37972],
        [31071],
        [32122],
        [29169],
        [28894],
        [30344],
        [34611],
        [31698],
        [31822],
        [29416],
        [31270]], device='cuda:0')
[2024-07-24 10:16:42,934][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 8668],
        [12716],
        [11945],
        [11976],
        [10317],
        [11872],
        [12434],
        [ 7533],
        [ 9752],
        [ 9098],
        [12021],
        [ 9898],
        [ 5893],
        [ 8554]], device='cuda:0')
[2024-07-24 10:16:42,936][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[13189],
        [ 6003],
        [ 6010],
        [ 5912],
        [ 5797],
        [ 6005],
        [ 6006],
        [ 5885],
        [ 5989],
        [ 5043],
        [ 5964],
        [ 5883],
        [ 5280],
        [ 5766]], device='cuda:0')
[2024-07-24 10:16:42,940][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[23823],
        [12038],
        [ 7407],
        [ 7014],
        [ 8180],
        [ 7711],
        [ 6368],
        [ 6898],
        [ 7334],
        [10898],
        [ 7638],
        [ 8940],
        [10464],
        [ 9638]], device='cuda:0')
[2024-07-24 10:16:42,943][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[21939],
        [22063],
        [22046],
        [22621],
        [22184],
        [21973],
        [21643],
        [21582],
        [21197],
        [21253],
        [21526],
        [21358],
        [21256],
        [21369]], device='cuda:0')
[2024-07-24 10:16:42,946][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[13401],
        [14835],
        [14855],
        [14832],
        [14484],
        [14856],
        [14855],
        [14838],
        [14852],
        [14806],
        [14857],
        [14823],
        [14821],
        [14824]], device='cuda:0')
[2024-07-24 10:16:42,947][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[11046],
        [17921],
        [10921],
        [15704],
        [19838],
        [ 8709],
        [ 7979],
        [12207],
        [ 6794],
        [14956],
        [11854],
        [ 8135],
        [ 5773],
        [ 6047]], device='cuda:0')
[2024-07-24 10:16:42,949][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[4281],
        [3660],
        [3662],
        [3667],
        [3655],
        [3664],
        [3667],
        [3667],
        [3667],
        [3666],
        [3668],
        [3647],
        [3565],
        [3638]], device='cuda:0')
[2024-07-24 10:16:42,950][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[22052],
        [35196],
        [39304],
        [37027],
        [37004],
        [39564],
        [39668],
        [37878],
        [39103],
        [34101],
        [36224],
        [36481],
        [36959],
        [36330]], device='cuda:0')
[2024-07-24 10:16:42,952][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[33422],
        [38855],
        [30017],
        [38829],
        [34771],
        [37089],
        [30922],
        [38122],
        [32479],
        [38678],
        [35397],
        [30652],
        [33046],
        [36056]], device='cuda:0')
[2024-07-24 10:16:42,955][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[7659],
        [7659],
        [7659],
        [7659],
        [7659],
        [7659],
        [7659],
        [7659],
        [7659],
        [7659],
        [7659],
        [7659],
        [7659],
        [7659]], device='cuda:0')
