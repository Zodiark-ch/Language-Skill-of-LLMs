[2024-07-24 10:23:17,026][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isAfter Anthony and Mary went to the restaurant, Anthony gave a computer to
[2024-07-24 10:23:17,026][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Mary
[2024-07-24 10:23:17,026][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:23:17,027][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:23:17,027][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:23:17,027][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,027][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:23:17,027][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,027][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:23:17,027][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,028][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:23:17,028][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:23:17,028][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:23:17,028][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit19', 'circuit27']
[2024-07-24 10:23:17,028][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:23:17,028][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,028][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:23:17,029][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,029][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:23:17,029][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,029][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:23:17,029][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,029][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:23:17,029][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,029][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:23:17,030][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,030][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:23:17,030][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,030][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:23:17,030][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,030][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:23:17,030][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,031][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:23:17,031][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,031][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:23:17,031][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:23:17,031][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:23:17,031][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit22', 'circuit24']
[2024-07-24 10:23:17,031][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:23:17,031][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,031][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:23:17,031][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,031][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:23:17,031][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit4', 'circuit5', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:17,032][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:23:17,032][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit26']
[2024-07-24 10:23:17,032][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:23:17,032][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,032][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:23:17,032][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,032][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:23:17,032][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,032][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:23:17,032][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:23:17,032][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:23:17,032][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,032][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:23:17,032][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,032][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:23:17,033][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,033][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:23:17,033][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,033][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:23:17,033][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,033][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,033][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:23:17,033][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:17,033][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,033][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:23:17,033][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,033][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,033][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:23:17,033][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:23:17,033][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,033][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:23:17,034][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,034][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16']
[2024-07-24 10:23:17,034][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:23:17,034][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit9']
[2024-07-24 10:23:17,034][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,034][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:23:17,034][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit20', 'circuit22']
[2024-07-24 10:23:17,034][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:23:17,034][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:23:17,034][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,034][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,034][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:23:17,034][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11']
[2024-07-24 10:23:17,034][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit26']
[2024-07-24 10:23:17,034][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:23:17,035][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,035][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,035][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:23:17,035][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,035][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:23:17,035][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:23:17,035][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:23:17,035][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,035][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:23:17,035][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,035][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit18']
[2024-07-24 10:23:17,035][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:23:17,035][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,035][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,035][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:23:17,036][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,036][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,036][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:23:17,036][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:23:17,036][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit20']
[2024-07-24 10:23:17,036][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:23:17,036][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,036][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8', 'circuit15', 'circuit26']
[2024-07-24 10:23:17,036][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:23:17,036][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,036][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:17,036][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:23:17,036][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:23:17,036][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,036][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:23:17,037][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit17', 'circuit20', 'circuit22']
[2024-07-24 10:23:17,037][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,037][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:23:17,037][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,037][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,037][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:23:17,037][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,037][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit14', 'circuit17']
[2024-07-24 10:23:17,037][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:23:17,037][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:17,037][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:23:17,037][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:23:17,037][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17']
[2024-07-24 10:23:17,037][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit22', 'circuit23']
[2024-07-24 10:23:17,037][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:23:17,037][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:23:17,037][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,037][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:23:17,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,038][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,038][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:23:17,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,038][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,038][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:23:17,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,038][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,038][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:23:17,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,038][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,038][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:23:17,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,038][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,038][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,038][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:23:17,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,038][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,038][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,038][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:23:17,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:23:17,038][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit26']
[2024-07-24 10:23:17,039][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit20', 'circuit23']
[2024-07-24 10:23:17,039][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:23:17,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,039][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,039][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,039][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:23:17,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,039][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:23:17,039][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:23:17,039][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:23:17,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,039][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:17,039][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,039][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:23:17,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,039][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,039][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,039][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:23:17,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,039][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,039][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,039][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:23:17,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,039][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,040][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,040][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:23:17,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:23:17,040][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,040][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,040][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:23:17,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,040][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21']
[2024-07-24 10:23:17,040][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit9', 'circuit13', 'circuit14', 'circuit16']
[2024-07-24 10:23:17,040][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:23:17,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,040][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,040][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,040][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:23:17,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,040][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,040][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:23:17,040][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:23:17,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,040][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,040][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,040][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:23:17,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:23:17,041][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,041][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:23:17,041][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:23:17,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:23:17,041][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,041][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,041][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:23:17,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,041][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,041][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,041][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:23:17,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,041][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,041][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,041][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:23:17,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,041][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit7', 'circuit8', 'circuit9', 'circuit15', 'circuit20', 'circuit26']
[2024-07-24 10:23:17,041][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit20']
[2024-07-24 10:23:17,041][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:23:17,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit19', 'circuit20', 'circuit27']
[2024-07-24 10:23:17,041][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,041][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,042][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:23:17,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:23:17,042][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,042][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,042][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:23:17,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,042][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,042][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,042][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:23:17,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:23:17,042][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,042][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,042][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:23:17,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,042][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,042][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,042][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:23:17,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:17,042][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:23:17,042][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit12', 'circuit13', 'circuit23', 'circuit26']
[2024-07-24 10:23:17,042][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:23:17,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,042][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,042][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,043][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:23:17,043][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,043][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,043][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,043][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:23:17,043][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,043][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,043][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,043][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:23:17,043][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,043][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,043][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,043][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:23:17,043][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,043][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,043][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,043][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,043][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:23:17,043][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:23:17,043][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,043][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,043][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,043][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:23:17,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,044][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit3', 'circuit4', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:23:17,044][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit24']
[2024-07-24 10:23:17,044][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,044][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:23:17,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,044][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit24']
[2024-07-24 10:23:17,044][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,044][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15']
[2024-07-24 10:23:17,044][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:23:17,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit27']
[2024-07-24 10:23:17,044][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,044][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,044][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,044][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:23:17,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,044][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,044][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit26']
[2024-07-24 10:23:17,044][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,044][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:23:17,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,044][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,044][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18']
[2024-07-24 10:23:17,045][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,045][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:23:17,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,045][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,045][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17']
[2024-07-24 10:23:17,045][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,045][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:23:17,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit24', 'circuit27']
[2024-07-24 10:23:17,045][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:23:17,045][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23']
[2024-07-24 10:23:17,045][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,045][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:23:17,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:23:17,045][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit21', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,045][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit1', 'circuit4', 'circuit13', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,045][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit23']
[2024-07-24 10:23:17,045][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:23:17,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:23:17,045][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,045][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,045][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:23:17,045][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:23:17,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit20']
[2024-07-24 10:23:17,046][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,046][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:23:17,046][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit19']
[2024-07-24 10:23:17,046][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:23:17,046][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,046][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,046][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22']
[2024-07-24 10:23:17,046][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit20']
[2024-07-24 10:23:17,046][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:23:17,046][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,046][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,046][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,046][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,046][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:23:17,046][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23']
[2024-07-24 10:23:17,046][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,046][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit16']
[2024-07-24 10:23:17,046][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit25']
[2024-07-24 10:23:17,046][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:23:17,046][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,046][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15']
[2024-07-24 10:23:17,046][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,046][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20']
[2024-07-24 10:23:17,047][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:23:17,047][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,047][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,047][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,047][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,047][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:23:17,047][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,047][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8', 'circuit10', 'circuit27']
[2024-07-24 10:23:17,047][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit4', 'circuit8']
[2024-07-24 10:23:17,047][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit23']
[2024-07-24 10:23:17,047][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:23:17,047][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,047][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,047][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,047][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,047][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:23:17,047][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,047][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,047][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,047][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,047][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:23:17,047][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,047][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,047][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,048][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,048][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:23:17,048][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,048][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,048][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,048][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,048][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:23:17,048][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,048][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,048][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,048][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit1']
[2024-07-24 10:23:17,048][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:23:17,048][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:23:17,048][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,048][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,048][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,048][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:23:17,048][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,048][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,048][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,048][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,048][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:23:17,048][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,048][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,049][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,049][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,049][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:23:17,049][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,049][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,049][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,049][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,049][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:23:17,049][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,049][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,049][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,049][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,049][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:23:17,049][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,049][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,049][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,049][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,049][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:23:17,049][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,049][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,049][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,049][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,049][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,050][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:23:17,050][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,050][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:17,050][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit1', 'circuit5', 'circuit7', 'circuit12', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,050][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,050][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,050][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:23:17,050][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit26']
[2024-07-24 10:23:17,050][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:23:17,050][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit19', 'circuit27']
[2024-07-24 10:23:17,050][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit19', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,050][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit24']
[2024-07-24 10:23:17,050][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:23:17,050][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:23:17,050][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,050][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20']
[2024-07-24 10:23:17,050][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:23:17,050][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:23:17,050][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:23:17,050][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:17,050][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit18']
[2024-07-24 10:23:17,050][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,050][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,051][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,051][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:23:17,051][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,051][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit3', 'circuit27']
[2024-07-24 10:23:17,051][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2']
[2024-07-24 10:23:17,051][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:23:17,051][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,051][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:23:17,051][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,051][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit17', 'circuit24']
[2024-07-24 10:23:17,051][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,051][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,051][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,051][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:23:17,051][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,051][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,051][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,051][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,051][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,051][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:23:17,051][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:23:17,051][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,051][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,051][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:23:17,052][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,052][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:23:17,052][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,052][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21']
[2024-07-24 10:23:17,052][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,052][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,052][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,052][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:23:17,052][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,052][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,052][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:23:17,052][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,052][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:23:17,052][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:23:17,052][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:23:17,052][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:23:17,052][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,052][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:23:17,052][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit8', 'circuit9', 'circuit11', 'circuit14', 'circuit18', 'circuit19', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,052][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:23:17,052][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,052][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,052][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22']
[2024-07-24 10:23:17,052][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22']
[2024-07-24 10:23:17,053][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:23:17,053][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:23:17,053][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,053][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,053][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,053][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,053][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit5', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,053][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:23:17,053][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,053][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,053][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,053][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,053][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,053][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:23:17,053][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,053][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,053][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,053][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,053][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,053][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:23:17,053][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,053][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,053][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,054][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,054][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,054][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:23:17,054][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,054][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,054][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,054][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,054][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,054][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:23:17,054][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,054][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,054][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,054][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,054][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,054][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:23:17,054][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,054][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,054][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,054][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,054][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,054][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:23:17,054][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,054][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,054][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,055][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,055][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,055][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:23:17,055][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,055][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,055][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,055][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,055][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,055][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:23:17,055][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,055][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,055][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,055][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,055][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,055][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:23:17,055][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,055][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit20', 'circuit24']
[2024-07-24 10:23:17,055][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,055][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23']
[2024-07-24 10:23:17,055][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,055][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:23:17,055][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,055][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,055][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,056][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,056][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,056][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:23:17,056][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,056][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,056][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,056][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,056][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,056][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:23:17,056][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,056][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,056][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,056][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,056][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,056][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:23:17,056][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,056][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,056][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,056][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,056][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,056][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:23:17,056][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,056][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,057][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,057][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,057][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,057][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:23:17,057][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,057][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,057][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,057][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,057][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,057][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,057][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:23:17,057][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit27']
[2024-07-24 10:23:17,057][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit21']
[2024-07-24 10:23:17,057][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,057][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,057][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14']
[2024-07-24 10:23:17,057][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,057][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:23:17,057][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit23', 'circuit26']
[2024-07-24 10:23:17,057][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,057][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:23:17,057][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23']
[2024-07-24 10:23:17,057][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,057][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23']
[2024-07-24 10:23:17,058][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:23:17,058][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,058][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit12', 'circuit13', 'circuit14', 'circuit21', 'circuit26']
[2024-07-24 10:23:17,058][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit8', 'circuit12', 'circuit13', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,058][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,058][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15']
[2024-07-24 10:23:17,058][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit10', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:23:17,058][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:23:17,058][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,058][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,058][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,058][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:23:17,058][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit20', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,058][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,058][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:23:17,058][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,058][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,058][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,058][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,058][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,058][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,058][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:23:17,058][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,059][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,059][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit4', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:17,059][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,059][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,059][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,059][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:23:17,059][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,059][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17']
[2024-07-24 10:23:17,059][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:23:17,059][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,059][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,059][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,059][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:23:17,059][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit10', 'circuit13', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,059][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,059][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,059][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:23:17,059][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,059][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,059][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:23:17,059][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit27']
[2024-07-24 10:23:17,059][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,059][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,059][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,060][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,060][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,060][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:23:17,060][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,060][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:23:17,060][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:17,060][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,060][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit25']
[2024-07-24 10:23:17,060][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24', 'circuit27']
[2024-07-24 10:23:17,060][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:23:17,060][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,060][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,060][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,060][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,060][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,060][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,060][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:23:17,060][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:23:17,060][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,060][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,060][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,060][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,060][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,061][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:23:17,061][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,061][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit6', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,061][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,061][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,061][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,061][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,061][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:23:17,061][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,061][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:23:17,061][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit20']
[2024-07-24 10:23:17,061][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,061][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit17']
[2024-07-24 10:23:17,061][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit1', 'circuit2', 'circuit9']
[2024-07-24 10:23:17,061][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:23:17,061][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit9', 'circuit11', 'circuit12', 'circuit28']
[2024-07-24 10:23:17,061][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit14', 'circuit15', 'circuit16', 'circuit18']
[2024-07-24 10:23:17,061][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,061][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:23:17,061][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,061][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,061][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:23:17,061][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:23:17,061][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,062][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit10']
[2024-07-24 10:23:17,062][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit20', 'circuit27']
[2024-07-24 10:23:17,062][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit18', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:23:17,062][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit16', 'circuit25']
[2024-07-24 10:23:17,062][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:23:17,062][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,062][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,062][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,062][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23']
[2024-07-24 10:23:17,062][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,062][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,062][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:23:17,062][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,062][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17']
[2024-07-24 10:23:17,062][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,062][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,062][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,062][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22']
[2024-07-24 10:23:17,062][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:23:17,062][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,062][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6', 'circuit7', 'circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:23:17,062][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,062][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,063][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit19', 'circuit26']
[2024-07-24 10:23:17,063][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit18']
[2024-07-24 10:23:17,063][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:23:17,063][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit24', 'circuit26']
[2024-07-24 10:23:17,063][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,063][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,063][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,063][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,063][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,063][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:23:17,063][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,063][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,063][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,063][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,063][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,063][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,063][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:23:17,063][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23']
[2024-07-24 10:23:17,063][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,063][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,063][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,063][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,063][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,063][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:23:17,064][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:23:17,064][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,064][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:23:17,064][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22']
[2024-07-24 10:23:17,064][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,064][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:23:17,064][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:23:17,064][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,064][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit6', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,064][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit15', 'circuit26']
[2024-07-24 10:23:17,064][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,064][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,064][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,064][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:23:17,064][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:23:17,064][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,064][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,064][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,064][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,064][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:23:17,064][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:23:17,064][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,064][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,064][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,065][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,065][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,065][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,065][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:23:17,065][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,065][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,065][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,065][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,065][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,065][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,065][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:23:17,065][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,065][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,065][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,065][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,065][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,065][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,065][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:23:17,065][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,065][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,065][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,065][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,065][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,066][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,066][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,066][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:23:17,066][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,066][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit27']
[2024-07-24 10:23:17,066][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,066][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,066][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,066][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,066][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,066][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:23:17,066][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit22', 'circuit23']
[2024-07-24 10:23:17,066][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,066][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,066][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,066][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,066][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,066][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,066][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:23:17,066][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,066][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,066][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,066][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,066][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,067][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit16', 'circuit19', 'circuit24']
[2024-07-24 10:23:17,067][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,067][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:23:17,067][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:23:17,067][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,067][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,067][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,067][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,067][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,067][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,067][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:23:17,067][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,067][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,067][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,067][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,067][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,067][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,067][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,067][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:23:17,067][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,067][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8', 'circuit13', 'circuit24']
[2024-07-24 10:23:17,067][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,067][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,067][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:23:17,068][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit21']
[2024-07-24 10:23:17,068][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit14', 'circuit16', 'circuit20', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,068][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:23:17,068][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit20', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:23:17,068][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,068][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:23:17,068][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit20', 'circuit22']
[2024-07-24 10:23:17,068][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,068][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,068][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,068][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:23:17,068][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,068][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,068][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,068][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,068][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,068][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,068][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:23:17,068][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:23:17,068][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,068][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit13', 'circuit18']
[2024-07-24 10:23:17,068][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:23:17,068][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,068][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,069][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,069][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3']
[2024-07-24 10:23:17,069][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:23:17,069][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,069][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit5', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:17,069][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,069][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:23:17,069][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit25', 'circuit27']
[2024-07-24 10:23:17,069][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit6', 'circuit8', 'circuit9']
[2024-07-24 10:23:17,069][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit17', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,069][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:23:17,069][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,069][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:23:17,069][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,069][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:23:17,069][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,069][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,069][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,069][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:23:17,069][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,069][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,069][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,069][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit17', 'circuit18']
[2024-07-24 10:23:17,069][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,070][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:23:17,070][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:23:17,070][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:23:17,070][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,070][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,070][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,070][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,070][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,070][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,070][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,070][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:23:17,070][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,070][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,070][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,070][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,070][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,070][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,070][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,070][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:23:17,070][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,070][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,070][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,070][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,070][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,071][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,071][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,071][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:23:17,071][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,071][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,071][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,071][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,071][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,071][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,071][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,071][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:23:17,071][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,071][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,071][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,071][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,071][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,071][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,071][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,071][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:23:17,071][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,071][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,071][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,071][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,071][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,072][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,072][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,072][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:23:17,072][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,072][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,072][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,072][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,072][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,072][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,072][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,072][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:23:17,072][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,072][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,072][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,072][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,072][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,072][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,072][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,072][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:23:17,072][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,072][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,072][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,072][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,072][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,073][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,073][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,073][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:23:17,073][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,073][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,073][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,073][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,073][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,073][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,073][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,073][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:23:17,073][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit24']
[2024-07-24 10:23:17,073][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,073][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,073][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,073][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,073][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,073][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,073][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:23:17,073][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit24']
[2024-07-24 10:23:17,073][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit18']
[2024-07-24 10:23:17,073][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:23:17,073][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,073][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit25']
[2024-07-24 10:23:17,074][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,074][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit21', 'circuit25']
[2024-07-24 10:23:17,074][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:23:17,074][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:23:17,074][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit27']
[2024-07-24 10:23:17,074][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,074][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,074][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,074][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,074][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,074][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:23:17,074][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,074][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,074][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,074][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,074][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,074][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,074][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,074][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:23:17,074][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,074][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,074][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,074][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,075][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,075][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,075][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,075][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:23:17,075][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,075][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,075][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,075][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,075][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,075][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,075][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,075][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:23:17,075][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,075][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,075][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,075][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,075][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,075][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,075][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit26']
[2024-07-24 10:23:17,075][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,075][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:23:17,075][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,075][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,075][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,076][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,076][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,076][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,076][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,076][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,076][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:23:17,076][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,076][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,076][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,076][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,076][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,076][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,076][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,076][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,076][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:23:17,076][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,076][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:23:17,076][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,076][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,076][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,076][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,076][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,076][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,076][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:23:17,077][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,077][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,077][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,077][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,077][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,077][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,077][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,077][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,077][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:23:17,077][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,077][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,077][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,077][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,077][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,077][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,077][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,077][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,077][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:23:17,077][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,077][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,077][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,077][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,077][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,077][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,077][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,078][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,078][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:23:17,078][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,078][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,078][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,078][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,078][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,078][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,078][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,078][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,078][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:23:17,078][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,078][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,078][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,078][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,078][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,078][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,078][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,078][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,078][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:23:17,078][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,078][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,078][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,078][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,079][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,079][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,079][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,079][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,079][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:23:17,079][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,079][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,079][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,079][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,079][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,079][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,079][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,079][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,079][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:23:17,079][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,079][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,079][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,079][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,079][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,079][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,079][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,079][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,079][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:23:17,079][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,080][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit8', 'circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:17,080][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,080][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,080][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,080][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,080][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:23:17,080][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:23:17,080][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:23:17,080][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit27']
[2024-07-24 10:23:17,080][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,080][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,080][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:23:17,080][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,080][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,080][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,080][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,080][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:23:17,080][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,080][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,080][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,080][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,080][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,080][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,080][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,081][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,081][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:23:17,081][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,081][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,081][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,081][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,081][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,081][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,081][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,081][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,081][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:23:17,081][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,081][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,081][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,081][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,081][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,081][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,081][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,081][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,081][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:23:17,081][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,081][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,081][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,081][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,082][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,082][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,082][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,082][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,082][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:23:17,082][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,082][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,082][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,082][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,082][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,082][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,082][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,082][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,082][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:23:17,082][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,082][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,082][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,082][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,082][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,082][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,082][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,082][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,082][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:23:17,082][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,083][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,083][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,083][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,083][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,083][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,083][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,083][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,083][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:23:17,083][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,083][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,083][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,083][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,083][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,083][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,083][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,083][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,083][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:23:17,083][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,083][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,083][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,083][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,083][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,083][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,083][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,083][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,084][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:23:17,084][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,084][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,084][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,084][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,084][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,084][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,084][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,084][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,084][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:23:17,084][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,084][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,084][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,084][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,084][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,084][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,084][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,084][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,084][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:23:17,084][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,084][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,084][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,084][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,084][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,085][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,085][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,085][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,085][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:23:17,085][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,085][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,085][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,085][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,085][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,085][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,085][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,085][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,085][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:23:17,085][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,085][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,085][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,085][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,085][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,085][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,085][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,085][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,085][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:23:17,085][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,086][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,086][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,086][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,086][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,086][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,086][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,086][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,086][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:23:17,086][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,086][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:17,086][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit7', 'circuit8', 'circuit10', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,086][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,086][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,086][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit21', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:23:17,086][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit11', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,086][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,086][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,086][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:23:17,086][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,086][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,086][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,086][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,086][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,086][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,087][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,087][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,087][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,087][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:23:17,087][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,087][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,087][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,087][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,087][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,087][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,087][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,087][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,087][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,087][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:23:17,087][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,087][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,087][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,087][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,087][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,087][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,087][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,087][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,087][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,087][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:23:17,088][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,088][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,088][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,088][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,088][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,088][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,088][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,088][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,088][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,088][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:23:17,088][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,088][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,088][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,088][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,088][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,088][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,088][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,088][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,088][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,088][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:23:17,088][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,088][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,088][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,088][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,088][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,089][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,089][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,089][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,089][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,089][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:23:17,089][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,089][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,089][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,089][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,089][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,089][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,089][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,089][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,089][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,089][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:23:17,089][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,089][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,089][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,089][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,089][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,089][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,089][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,089][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,089][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,090][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:23:17,090][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,090][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,090][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,090][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,090][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,090][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,090][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,090][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,090][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:23:17,090][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:23:17,090][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit22', 'circuit24']
[2024-07-24 10:23:17,090][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,090][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,090][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,090][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,090][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,090][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,090][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,090][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,090][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:23:17,090][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,090][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,090][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,091][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,091][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,091][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,091][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,091][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,091][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,091][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:23:17,091][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,091][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,091][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,091][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,091][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,091][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,091][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,091][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,091][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,091][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:23:17,091][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,091][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,091][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,091][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,091][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,091][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,091][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,091][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,092][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,092][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:23:17,092][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,092][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,092][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,092][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,092][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,092][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,092][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,092][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,092][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,092][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:23:17,092][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,092][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,092][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,092][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,092][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,092][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,092][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,092][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,092][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,092][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:23:17,092][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,092][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,093][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,093][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,093][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,093][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,093][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,093][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,093][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,093][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:23:17,093][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,093][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,093][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,093][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,093][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,093][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,093][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,093][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,093][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,093][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:23:17,093][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,093][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,093][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,093][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,093][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,093][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,094][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,094][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,094][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,094][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:23:17,094][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,094][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,094][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,094][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,094][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,094][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,094][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,094][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,094][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,094][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:23:17,094][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,094][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,094][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,094][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,094][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,094][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,094][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,094][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,094][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,094][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:23:17,095][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,095][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,095][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,095][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,095][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,095][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,095][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,095][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,095][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,095][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:23:17,095][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,095][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,095][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,095][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,095][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,095][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,095][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,095][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,095][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,095][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:23:17,095][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,095][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,095][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,095][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,095][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,096][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,096][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,096][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,096][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,096][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:23:17,096][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,096][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,096][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,096][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,096][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,096][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,096][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,096][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,096][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,096][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:23:17,096][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,096][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,096][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,096][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,096][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,096][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,096][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,096][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,096][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,097][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:23:17,097][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,097][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,097][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,097][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,097][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,097][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,097][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,097][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,097][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,097][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:23:17,097][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,097][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,097][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,097][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,097][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,097][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,097][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,097][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,097][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,097][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:23:17,097][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,097][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,098][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,098][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,098][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,098][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,098][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,098][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,098][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,098][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:23:17,098][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:17,098][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit24']
[2024-07-24 10:23:17,098][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,098][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit17', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,098][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit9', 'circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,098][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit26']
[2024-07-24 10:23:17,098][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,098][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,098][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit23', 'circuit26']
[2024-07-24 10:23:17,098][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:23:17,098][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:23:17,098][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,098][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,098][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,098][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,098][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,099][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,099][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,099][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,099][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,099][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit13']
[2024-07-24 10:23:17,099][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:23:17,099][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,099][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,099][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,099][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,099][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,099][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,099][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,099][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,099][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,099][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,099][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:23:17,099][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,099][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,099][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,099][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,099][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,099][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,099][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,100][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,100][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,100][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit14']
[2024-07-24 10:23:17,100][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:23:17,100][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,100][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,100][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,100][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,100][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,100][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,100][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,100][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,100][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,100][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,100][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:23:17,100][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,100][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,100][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,100][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,100][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,100][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,100][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,100][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,100][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,101][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,101][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:23:17,101][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,101][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,101][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,101][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,101][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,101][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,101][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,101][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,101][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,101][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,101][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:23:17,101][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,101][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,101][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,101][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,101][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,101][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,101][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,101][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,101][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,101][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,101][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:23:17,102][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,102][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,102][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,102][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,102][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,102][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,102][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,102][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,102][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,102][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,102][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:23:17,102][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,102][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,102][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,102][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,102][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,102][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,102][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,102][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,102][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,102][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,102][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:23:17,102][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,102][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,102][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,103][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,103][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,103][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,103][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,103][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,103][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,103][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,103][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:23:17,103][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,103][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,103][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,103][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,103][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,103][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,103][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,103][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,103][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,103][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:23:17,103][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:23:17,103][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,103][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,103][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,103][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,103][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,104][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,104][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,104][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,104][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,104][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,104][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:23:17,104][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:23:17,104][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,104][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,104][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,104][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,104][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,104][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,104][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,104][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,104][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,104][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:23:17,104][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,104][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,104][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,104][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,104][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,104][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,104][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,104][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,105][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,105][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,105][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:23:17,105][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,105][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,105][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,105][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,105][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,105][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,105][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,105][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,105][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,105][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,105][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:23:17,105][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,105][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,105][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,105][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,105][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,105][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,105][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,105][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,105][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,105][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,106][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:23:17,106][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,106][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,106][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,106][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,106][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,106][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,106][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,106][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,106][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,106][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,106][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:23:17,106][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,106][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,106][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,106][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,106][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,106][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,106][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,106][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,106][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,106][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,106][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:23:17,106][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,107][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,107][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,107][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,107][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,107][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,107][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,107][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,107][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,107][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,107][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:23:17,107][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,107][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,107][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,107][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,107][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,107][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,107][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,107][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,107][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,107][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,107][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:23:17,107][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,107][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,107][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,107][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,108][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,108][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,108][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,108][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,108][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,108][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,108][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:23:17,108][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,108][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,108][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,108][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,108][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,108][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,108][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,108][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,108][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,108][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,108][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:23:17,108][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,108][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,108][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,108][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,108][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,108][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,109][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,109][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,109][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,109][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,109][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:23:17,109][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,109][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,109][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,109][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,109][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,109][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,109][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,109][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,109][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,109][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,109][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:23:17,109][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,109][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,109][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,109][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,109][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,109][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,109][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,109][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,109][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,110][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,110][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:23:17,110][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,110][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,110][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,110][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,110][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,110][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,110][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,110][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,110][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,110][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,110][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:23:17,110][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,110][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,110][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,110][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,110][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,110][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,110][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,110][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,110][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,110][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,111][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:23:17,111][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,111][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,111][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,111][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,111][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,111][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,111][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,111][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,111][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,111][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,111][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:23:17,111][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit21', 'circuit23', 'circuit27']
[2024-07-24 10:23:17,111][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,111][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,111][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,111][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,111][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit6', 'circuit12', 'circuit13', 'circuit15', 'circuit21', 'circuit23']
[2024-07-24 10:23:17,111][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,111][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:23:17,111][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit12', 'circuit13', 'circuit15', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:23:17,111][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,111][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:23:17,112][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:23:17,112][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:23:17,112][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,112][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,112][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,112][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,112][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,112][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,112][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,112][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit24']
[2024-07-24 10:23:17,112][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit25']
[2024-07-24 10:23:17,112][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit25']
[2024-07-24 10:23:17,112][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:23:17,112][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,112][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,112][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,112][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,112][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,112][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,112][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,112][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,112][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,112][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:23:17,112][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit2', 'circuit13', 'circuit27']
[2024-07-24 10:23:17,112][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:23:17,113][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,113][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,113][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,113][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,113][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,113][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,113][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,113][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,113][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,113][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,113][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:17,113][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:23:17,113][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,113][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,113][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,113][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,113][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,113][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,113][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,113][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,113][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:23:17,113][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit24']
[2024-07-24 10:23:17,113][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:23:17,113][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:23:17,114][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-24 10:23:17,114][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17']
[2024-07-24 10:23:17,114][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,114][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,114][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,114][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,114][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14']
[2024-07-24 10:23:17,114][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:23:17,114][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21']
[2024-07-24 10:23:17,114][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,114][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:17,114][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:23:17,114][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,114][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,114][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,114][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,114][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,114][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,114][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,114][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,114][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,114][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:23:17,114][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:23:17,114][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:23:17,115][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,115][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,115][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,115][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,115][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,115][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,115][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,115][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,115][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,115][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,115][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:17,115][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:23:17,115][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,115][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,115][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,115][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,115][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,115][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,115][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,115][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,115][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,115][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,115][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:17,115][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:23:17,115][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,116][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit23', 'circuit24']
[2024-07-24 10:23:17,116][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,116][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,116][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,116][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,116][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,116][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,116][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,116][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,116][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:23:17,116][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:23:17,116][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,116][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,116][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,116][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,116][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,116][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,116][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,116][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,116][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,116][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,116][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:17,116][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:23:17,116][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,117][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,117][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,117][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,117][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,117][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,117][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,117][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,117][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,117][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,117][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:17,117][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:23:17,117][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,117][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,117][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,117][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,117][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,117][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,117][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,117][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,117][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,117][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:23:17,117][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:23:17,117][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:23:17,117][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:17,117][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:23:17,118][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,118][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,118][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,118][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,118][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,118][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,118][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,118][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:23:17,118][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:23:17,118][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:23:17,118][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,118][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,118][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,118][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,118][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,118][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,118][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,118][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,118][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,118][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,118][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:17,118][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:23:17,118][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,118][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,119][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,119][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,119][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,119][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,119][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,119][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,119][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,119][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,119][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:17,119][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:23:17,119][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,119][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,119][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,119][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,119][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,119][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,119][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,119][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,119][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,119][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,119][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:17,119][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:23:17,119][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,119][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,119][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,120][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,120][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,120][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,120][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,120][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,120][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,120][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,120][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:17,120][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:23:17,120][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,120][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,120][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,120][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,120][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,120][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,120][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,120][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,120][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,120][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,120][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:17,120][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:23:17,120][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,120][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,120][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,121][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,121][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,121][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,121][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,121][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,121][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,121][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,121][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:17,121][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:23:17,121][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,121][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,121][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,121][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,121][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,121][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,121][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,121][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,121][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,121][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,121][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:17,121][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:23:17,121][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,121][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,121][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,121][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,122][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,122][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,122][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,122][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,122][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,122][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,122][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:17,122][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:23:17,122][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,122][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,122][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,122][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,122][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,122][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,122][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,122][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,122][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,122][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,122][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:17,122][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:23:17,122][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,122][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,122][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,122][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,123][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,123][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,123][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,123][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,123][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,123][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,123][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:17,123][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:23:17,123][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,123][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,123][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,123][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,123][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,123][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,123][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,123][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,123][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,123][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,123][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:17,123][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:23:17,123][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:17,123][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:17,123][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:17,123][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:17,123][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:17,124][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:17,124][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:17,124][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:17,124][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:17,124][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:17,124][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:17,124][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:23:17,124][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,124][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,124][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,124][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,124][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,124][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,124][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,124][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,124][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,124][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,124][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,124][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:23:17,124][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,124][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,124][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,124][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,124][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,125][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,125][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,125][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,125][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,125][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,125][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,125][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:23:17,125][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,125][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,125][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,125][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,125][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,125][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,125][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,125][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,125][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,125][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:17,125][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:18,575][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:18,577][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:18,577][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:18,578][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:18,579][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:18,580][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:18,581][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:18,581][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:18,582][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:18,583][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:18,583][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:18,584][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:18,585][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:18,586][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.7675, 0.2325], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:18,587][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([3.8066e-04, 9.9962e-01], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:18,591][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.9482, 0.0518], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:18,595][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.1057, 0.8943], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:18,598][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.3573, 0.6427], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:18,598][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.0964, 0.9036], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:18,599][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.7283, 0.2717], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:18,600][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.9513, 0.0487], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:18,601][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.7801, 0.2199], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:18,602][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.9414, 0.0586], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:18,605][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.7059, 0.2941], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:18,609][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.7077, 0.2923], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:18,613][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.7815, 0.1522, 0.0662], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:18,616][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([4.4108e-03, 2.7918e-04, 9.9531e-01], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:18,619][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4095, 0.0618, 0.5288], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:18,623][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2259, 0.1120, 0.6621], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:18,624][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.5981, 0.2269, 0.1751], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:18,624][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1827, 0.0140, 0.8033], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:18,625][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6490, 0.3274, 0.0236], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:18,626][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.4517, 0.3162, 0.2321], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:18,628][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2512, 0.0493, 0.6994], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:18,630][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.6103, 0.1381, 0.2516], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:18,634][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.6656, 0.1018, 0.2327], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:18,638][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.5538, 0.0987, 0.3475], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:18,642][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Mary] are: tensor([0.3587, 0.2577, 0.2664, 0.1172], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:18,644][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Mary] are: tensor([7.3197e-05, 1.5041e-04, 1.4913e-04, 9.9963e-01], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:18,648][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Mary] are: tensor([0.5206, 0.1761, 0.1055, 0.1977], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:18,649][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Mary] are: tensor([1.5185e-02, 8.1145e-04, 1.5251e-04, 9.8385e-01], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:18,649][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Mary] are: tensor([0.0133, 0.0225, 0.0012, 0.9630], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:18,650][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Mary] are: tensor([1.4138e-03, 1.4551e-05, 7.0409e-07, 9.9857e-01], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:18,651][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Mary] are: tensor([0.3301, 0.2582, 0.1102, 0.3016], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:18,653][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Mary] are: tensor([0.2703, 0.2530, 0.3896, 0.0871], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:18,655][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Mary] are: tensor([0.4264, 0.2651, 0.1355, 0.1729], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:18,659][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Mary] are: tensor([0.5326, 0.2052, 0.2267, 0.0355], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:18,663][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Mary] are: tensor([0.3820, 0.1291, 0.1798, 0.3091], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:18,667][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Mary] are: tensor([0.4067, 0.2515, 0.2120, 0.1299], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:18,671][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.4781, 0.1090, 0.0846, 0.0645, 0.2638], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:18,673][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ went] are: tensor([1.1712e-03, 1.8048e-03, 1.7618e-03, 4.6969e-04, 9.9479e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:18,674][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.5962, 0.0829, 0.1886, 0.0469, 0.0855], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:18,674][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ went] are: tensor([3.0723e-02, 8.7619e-04, 2.0130e-03, 3.6389e-03, 9.6275e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:18,675][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.3945, 0.0832, 0.0578, 0.0713, 0.3933], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:18,676][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ went] are: tensor([2.6715e-02, 1.4230e-04, 6.5623e-05, 5.9954e-05, 9.7302e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:18,678][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.2226, 0.3656, 0.0338, 0.3449, 0.0331], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:18,682][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.2187, 0.2204, 0.2325, 0.1347, 0.1936], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:18,685][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.3639, 0.1201, 0.3544, 0.1023, 0.0593], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:18,689][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.4347, 0.1355, 0.2125, 0.1006, 0.1168], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:18,693][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.4122, 0.1007, 0.1856, 0.0422, 0.2593], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:18,696][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.4769, 0.0949, 0.2374, 0.0707, 0.1201], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:18,698][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.4140, 0.1573, 0.0557, 0.1192, 0.2240, 0.0297], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:18,699][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([5.9643e-03, 1.2380e-04, 6.7602e-02, 2.2140e-04, 8.4874e-04, 9.2524e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:18,700][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.3883, 0.0579, 0.1749, 0.0503, 0.0788, 0.2498], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:18,700][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0327, 0.0047, 0.0213, 0.0046, 0.4634, 0.4733], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:18,702][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1614, 0.0218, 0.0272, 0.0084, 0.6447, 0.1365], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:18,705][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0849, 0.0044, 0.1477, 0.0012, 0.0158, 0.7461], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:18,709][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.3150, 0.1178, 0.0173, 0.0826, 0.0820, 0.3853], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:18,713][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1359, 0.0919, 0.1157, 0.1199, 0.2951, 0.2415], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:18,717][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0604, 0.0153, 0.3491, 0.0158, 0.0653, 0.4940], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:18,721][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.3529, 0.1052, 0.1889, 0.0796, 0.0887, 0.1847], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:18,723][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.3452, 0.0769, 0.2381, 0.0572, 0.0892, 0.1935], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:18,724][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.3480, 0.0793, 0.1849, 0.0703, 0.1278, 0.1897], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:18,724][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.4538, 0.1396, 0.0399, 0.1919, 0.1217, 0.0210, 0.0321],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:18,725][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ the] are: tensor([9.0979e-03, 1.0376e-03, 6.6667e-02, 1.9136e-03, 1.9101e-04, 8.7204e-02,
        8.3389e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:18,727][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.3323, 0.0548, 0.1416, 0.0497, 0.1093, 0.2725, 0.0399],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:18,730][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0503, 0.0089, 0.0232, 0.0178, 0.0849, 0.1815, 0.6335],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:18,734][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2850, 0.0766, 0.0396, 0.0701, 0.2750, 0.1180, 0.1356],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:18,738][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1795, 0.0200, 0.1521, 0.0084, 0.0411, 0.1353, 0.4635],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:18,741][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2692, 0.3157, 0.0062, 0.3200, 0.0753, 0.0099, 0.0037],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:18,745][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1179, 0.0291, 0.0821, 0.0951, 0.1457, 0.2279, 0.3022],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:18,748][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0305, 0.0126, 0.1958, 0.0100, 0.0524, 0.2097, 0.4890],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:18,748][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.3217, 0.0905, 0.1568, 0.0738, 0.0787, 0.1524, 0.1262],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:18,749][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.3503, 0.0802, 0.1682, 0.0610, 0.0445, 0.1143, 0.1815],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:18,750][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.2813, 0.0830, 0.1473, 0.0779, 0.1071, 0.1430, 0.1603],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:18,752][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.2588, 0.1678, 0.1442, 0.1316, 0.0451, 0.0792, 0.0731, 0.1003],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:18,754][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([4.9783e-04, 1.9749e-03, 3.7060e-04, 4.8970e-04, 1.3708e-03, 3.2963e-04,
        9.3226e-05, 9.9487e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:18,758][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.3277, 0.1089, 0.0532, 0.1029, 0.0541, 0.0516, 0.0852, 0.2165],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:18,761][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([3.5546e-03, 6.3478e-04, 6.1259e-05, 5.5669e-03, 3.8944e-03, 8.8564e-04,
        5.8200e-04, 9.8482e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:18,764][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.0385, 0.0454, 0.0128, 0.0178, 0.0444, 0.0281, 0.0354, 0.7776],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:18,766][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([8.1032e-03, 6.6464e-04, 3.7222e-06, 4.8740e-05, 1.7408e-05, 2.2743e-07,
        9.5375e-07, 9.9116e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:18,770][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.1915, 0.2114, 0.0575, 0.1225, 0.0199, 0.0149, 0.0410, 0.3413],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:18,772][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.0851, 0.0416, 0.0653, 0.0565, 0.1622, 0.1664, 0.2598, 0.1632],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:18,773][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.3105, 0.0837, 0.1367, 0.0608, 0.0456, 0.1095, 0.1379, 0.1151],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:18,774][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.3546, 0.0810, 0.1398, 0.1083, 0.0652, 0.1148, 0.1122, 0.0241],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:18,775][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.2395, 0.0761, 0.1484, 0.0494, 0.0493, 0.1009, 0.0812, 0.2552],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:18,777][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.2612, 0.0786, 0.1620, 0.0647, 0.0853, 0.1112, 0.0630, 0.1740],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:18,780][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4569, 0.1013, 0.0210, 0.0947, 0.1235, 0.0193, 0.0610, 0.1081, 0.0141],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:18,782][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([3.4299e-03, 4.9336e-05, 2.5566e-02, 1.1887e-03, 5.2678e-04, 9.1259e-03,
        1.2513e-03, 2.2966e-05, 9.5884e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:18,786][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2722, 0.0315, 0.1190, 0.0298, 0.0469, 0.0601, 0.0137, 0.0157, 0.4111],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:18,790][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0533, 0.0019, 0.0084, 0.0049, 0.0762, 0.0461, 0.1217, 0.0297, 0.6579],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:18,795][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5134, 0.0273, 0.0152, 0.0301, 0.0713, 0.0514, 0.0281, 0.0894, 0.1738],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:18,797][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1380, 0.0249, 0.1985, 0.0127, 0.0596, 0.0986, 0.1472, 0.0292, 0.2913],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:18,798][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2316, 0.2005, 0.0081, 0.1641, 0.0498, 0.0160, 0.0053, 0.3198, 0.0049],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:18,799][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0475, 0.0225, 0.0302, 0.0513, 0.0614, 0.0808, 0.1591, 0.2373, 0.3098],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:18,800][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0343, 0.0076, 0.1784, 0.0063, 0.0216, 0.1585, 0.2319, 0.0099, 0.3515],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:18,801][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2661, 0.0784, 0.1350, 0.0665, 0.0722, 0.1252, 0.0992, 0.0555, 0.1019],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:18,804][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2268, 0.0597, 0.1632, 0.0795, 0.0694, 0.1352, 0.0985, 0.0577, 0.1100],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:18,808][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2539, 0.0657, 0.1248, 0.0678, 0.0940, 0.1142, 0.0649, 0.0756, 0.1391],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:18,812][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.1443, 0.1657, 0.0952, 0.0834, 0.0175, 0.0697, 0.0589, 0.1412, 0.0844,
        0.1397], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:18,815][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([1.0353e-04, 4.8718e-01, 3.4115e-05, 5.8733e-05, 5.4182e-05, 6.8315e-06,
        2.4894e-05, 7.2790e-05, 1.6321e-06, 5.1246e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:18,818][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.2729, 0.0642, 0.0496, 0.1131, 0.0400, 0.0295, 0.0815, 0.2666, 0.0486,
        0.0340], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:18,820][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([1.4113e-03, 3.8590e-03, 1.5151e-05, 4.5599e-04, 6.7400e-05, 1.2330e-04,
        4.6255e-04, 9.8303e-04, 4.7169e-04, 9.9215e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:18,822][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.0139, 0.0873, 0.0021, 0.0203, 0.0051, 0.0043, 0.0048, 0.0174, 0.0140,
        0.8307], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:18,823][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([6.8757e-03, 6.1333e-01, 2.5117e-07, 1.1706e-05, 4.9295e-07, 9.7002e-09,
        8.8058e-08, 1.0550e-05, 1.7430e-08, 3.7977e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:18,824][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.1289, 0.1986, 0.0632, 0.1840, 0.0160, 0.0098, 0.0564, 0.1382, 0.0632,
        0.1418], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:18,825][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0637, 0.0172, 0.0350, 0.0441, 0.0654, 0.1113, 0.1218, 0.1151, 0.2607,
        0.1657], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:18,827][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.2176, 0.1506, 0.0796, 0.1541, 0.0232, 0.0428, 0.0853, 0.0500, 0.0652,
        0.1316], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:18,829][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.2929, 0.0246, 0.1281, 0.1061, 0.0784, 0.1037, 0.0957, 0.0554, 0.1007,
        0.0145], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:18,833][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.1664, 0.2675, 0.0945, 0.0481, 0.0316, 0.0693, 0.0609, 0.0348, 0.0527,
        0.1742], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:18,837][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.1314, 0.0985, 0.1081, 0.0676, 0.1299, 0.0754, 0.0519, 0.1154, 0.1061,
        0.1156], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:18,840][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.2561, 0.0677, 0.0309, 0.0410, 0.2073, 0.0202, 0.0190, 0.0693, 0.0221,
        0.0791, 0.1874], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:18,843][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([9.4694e-04, 3.8203e-04, 2.3591e-03, 9.1758e-04, 8.8458e-03, 1.1981e-03,
        3.2221e-04, 1.3290e-04, 3.6775e-04, 1.1290e-04, 9.8441e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:18,847][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.2993, 0.0690, 0.0726, 0.0266, 0.0838, 0.1106, 0.0716, 0.0832, 0.0449,
        0.0545, 0.0839], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:18,847][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([2.3860e-03, 1.1648e-05, 2.9798e-05, 6.4130e-05, 1.0952e-03, 1.3026e-04,
        1.9876e-04, 3.9764e-04, 1.7820e-03, 8.5830e-04, 9.9305e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:18,848][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1348, 0.0130, 0.0140, 0.0132, 0.0386, 0.0317, 0.0209, 0.0839, 0.0454,
        0.0546, 0.5500], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:18,849][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([4.7299e-02, 2.3990e-04, 3.9505e-05, 1.8124e-04, 1.0252e-02, 4.1297e-06,
        1.4026e-05, 4.8301e-05, 1.9010e-06, 2.2820e-05, 9.4190e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:18,851][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.1160, 0.1749, 0.0161, 0.1814, 0.0255, 0.0117, 0.0154, 0.1814, 0.0129,
        0.2373, 0.0275], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:18,854][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0495, 0.0114, 0.0221, 0.0189, 0.0250, 0.0501, 0.0839, 0.0527, 0.2060,
        0.2194, 0.2610], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:18,858][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.1267, 0.0227, 0.1378, 0.0470, 0.0462, 0.1311, 0.1792, 0.0817, 0.1605,
        0.0225, 0.0448], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:18,862][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.1967, 0.0640, 0.1044, 0.0571, 0.0854, 0.1017, 0.0833, 0.0801, 0.0921,
        0.0601, 0.0751], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:18,865][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.1670, 0.0545, 0.0988, 0.0449, 0.1053, 0.0941, 0.0664, 0.0441, 0.0719,
        0.0376, 0.2156], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:18,869][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.3054, 0.0483, 0.1286, 0.0303, 0.0516, 0.1091, 0.0484, 0.0490, 0.1060,
        0.0450, 0.0783], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:18,871][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2460, 0.0775, 0.0232, 0.0961, 0.0605, 0.0149, 0.0276, 0.1956, 0.0238,
        0.0931, 0.1194, 0.0222], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:18,872][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([3.0327e-03, 1.5241e-03, 3.7276e-03, 1.3616e-03, 1.0816e-04, 9.8320e-03,
        3.0956e-02, 8.7597e-05, 1.0086e-03, 5.5194e-04, 2.1872e-04, 9.4759e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:18,873][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1791, 0.0564, 0.1167, 0.0422, 0.0807, 0.1892, 0.0267, 0.0517, 0.0770,
        0.0522, 0.1030, 0.0248], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:18,874][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([1.1768e-02, 9.4817e-04, 9.2382e-04, 6.9698e-04, 1.9407e-03, 4.0065e-03,
        1.5780e-02, 3.4038e-03, 4.8307e-02, 5.5406e-02, 1.3132e-01, 7.2550e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:18,876][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0587, 0.0099, 0.0059, 0.0076, 0.0601, 0.0156, 0.0168, 0.0391, 0.0303,
        0.0719, 0.5103, 0.1736], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:18,878][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0653, 0.0072, 0.1042, 0.0046, 0.0110, 0.0923, 0.2241, 0.0040, 0.0313,
        0.0013, 0.0075, 0.4473], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:18,882][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1370, 0.1299, 0.0039, 0.1464, 0.0567, 0.0073, 0.0029, 0.2448, 0.0027,
        0.1905, 0.0729, 0.0049], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:18,886][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0342, 0.0066, 0.0111, 0.0090, 0.0231, 0.0223, 0.0389, 0.0443, 0.1147,
        0.1340, 0.2829, 0.2789], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:18,890][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0159, 0.0040, 0.0799, 0.0050, 0.0220, 0.0966, 0.2268, 0.0106, 0.1532,
        0.0070, 0.0279, 0.3510], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:18,894][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1848, 0.0625, 0.1054, 0.0535, 0.0528, 0.1008, 0.0859, 0.0615, 0.0830,
        0.0546, 0.0688, 0.0864], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:18,896][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1738, 0.0533, 0.1112, 0.0483, 0.0385, 0.1035, 0.1107, 0.0520, 0.0727,
        0.0348, 0.0402, 0.1611], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:18,897][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.2045, 0.0538, 0.0895, 0.0412, 0.0705, 0.0992, 0.0539, 0.0553, 0.1023,
        0.0575, 0.0984, 0.0738], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:18,898][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.1716, 0.1526, 0.0541, 0.0602, 0.0565, 0.0313, 0.0251, 0.0841, 0.0539,
        0.1544, 0.0485, 0.0339, 0.0740], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:18,899][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([1.9969e-04, 6.1479e-04, 6.3570e-04, 1.5864e-05, 2.8556e-04, 5.0114e-04,
        4.1060e-04, 5.7692e-04, 2.4272e-04, 1.7375e-04, 5.4676e-05, 1.2973e-04,
        9.9616e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:18,900][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.2711, 0.0506, 0.0776, 0.0535, 0.0465, 0.0802, 0.0879, 0.0169, 0.0368,
        0.0334, 0.0548, 0.0781, 0.1124], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:18,902][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([4.7137e-04, 4.4486e-06, 1.0523e-06, 1.1158e-05, 8.5991e-06, 8.1358e-06,
        1.3774e-05, 4.6763e-04, 2.9242e-05, 5.7696e-04, 9.5800e-04, 3.6189e-04,
        9.9709e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:18,907][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0500, 0.0024, 0.0017, 0.0041, 0.0019, 0.0029, 0.0043, 0.0098, 0.0072,
        0.0062, 0.0167, 0.0224, 0.8704], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:18,909][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([1.7287e-03, 1.0700e-04, 8.3498e-06, 7.3512e-06, 8.1834e-06, 1.3760e-06,
        1.3585e-05, 1.9271e-04, 3.0488e-06, 1.0510e-05, 1.4653e-07, 6.0265e-06,
        9.9791e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:18,912][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.1535, 0.0993, 0.0230, 0.0815, 0.0325, 0.0217, 0.0179, 0.1757, 0.0208,
        0.0695, 0.0317, 0.0194, 0.2535], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:18,916][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0465, 0.0044, 0.0141, 0.0052, 0.0187, 0.0235, 0.0353, 0.1436, 0.0809,
        0.0439, 0.2183, 0.2603, 0.1051], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:18,920][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.1842, 0.0430, 0.0896, 0.0281, 0.0546, 0.0682, 0.1004, 0.1051, 0.0680,
        0.0338, 0.0346, 0.0726, 0.1178], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:18,921][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.1899, 0.0970, 0.0864, 0.0432, 0.0378, 0.0725, 0.0818, 0.0647, 0.0729,
        0.0873, 0.0611, 0.0885, 0.0168], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:18,922][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.1580, 0.0460, 0.0871, 0.0201, 0.0364, 0.0710, 0.0806, 0.0323, 0.0613,
        0.0291, 0.0331, 0.0605, 0.2844], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:18,923][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.2755, 0.0469, 0.0962, 0.0386, 0.0529, 0.0850, 0.0357, 0.0421, 0.1184,
        0.0406, 0.0752, 0.0372, 0.0559], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:18,925][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2101, 0.0787, 0.0221, 0.0600, 0.1236, 0.0119, 0.0268, 0.0847, 0.0234,
        0.1044, 0.1326, 0.0268, 0.0789, 0.0158], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:18,927][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.8458e-03, 2.7826e-05, 2.1804e-02, 6.5405e-05, 2.6971e-04, 4.6082e-01,
        1.1720e-03, 2.5528e-05, 4.8528e-03, 6.8010e-06, 3.8296e-04, 7.0108e-04,
        3.6341e-05, 5.0699e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:18,930][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1968, 0.0356, 0.0972, 0.0316, 0.0543, 0.1475, 0.0288, 0.0297, 0.0581,
        0.0282, 0.0669, 0.0258, 0.0299, 0.1696], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:18,932][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([4.3681e-03, 6.7934e-05, 2.0918e-04, 3.2224e-05, 3.0424e-03, 2.1455e-03,
        2.6729e-03, 8.1993e-04, 7.1195e-03, 1.6527e-03, 2.6937e-01, 7.5036e-02,
        1.8156e-02, 6.1531e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:18,936][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0371, 0.0019, 0.0032, 0.0006, 0.0618, 0.0121, 0.0073, 0.0137, 0.0106,
        0.0111, 0.3426, 0.0768, 0.1849, 0.2362], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:18,938][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([2.2114e-02, 1.9530e-03, 6.2304e-02, 4.0350e-04, 8.8487e-03, 3.8492e-01,
        1.4285e-01, 1.2841e-03, 1.3914e-02, 3.6348e-04, 4.4089e-03, 9.7065e-02,
        4.0000e-03, 2.5557e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:18,943][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1169, 0.0474, 0.0052, 0.0353, 0.0346, 0.1550, 0.0033, 0.0566, 0.0040,
        0.0564, 0.0530, 0.0057, 0.1434, 0.2833], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:18,945][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0264, 0.0055, 0.0063, 0.0063, 0.0126, 0.0087, 0.0195, 0.0191, 0.0498,
        0.0828, 0.1210, 0.1646, 0.1866, 0.2908], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:18,946][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0132, 0.0034, 0.0875, 0.0035, 0.0194, 0.1193, 0.1613, 0.0120, 0.1377,
        0.0050, 0.0187, 0.1892, 0.0111, 0.2187], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:18,947][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1556, 0.0537, 0.0890, 0.0408, 0.0475, 0.0850, 0.0760, 0.0482, 0.0711,
        0.0489, 0.0628, 0.0808, 0.0400, 0.1005], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:18,948][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1245, 0.0344, 0.1071, 0.0380, 0.0662, 0.1199, 0.0834, 0.0402, 0.0765,
        0.0245, 0.0588, 0.0820, 0.0331, 0.1113], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:18,950][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1804, 0.0464, 0.0821, 0.0358, 0.0675, 0.0813, 0.0396, 0.0446, 0.0856,
        0.0466, 0.0906, 0.0529, 0.0624, 0.0840], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:18,962][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:18,963][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:18,964][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:18,965][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:18,965][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:18,966][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:18,967][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:18,967][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:18,968][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:18,969][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:18,969][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:18,970][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:18,971][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:18,971][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.7675, 0.2325], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:18,972][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([3.8066e-04, 9.9962e-01], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:18,973][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.9482, 0.0518], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:18,977][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.1057, 0.8943], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:18,980][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.3573, 0.6427], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:18,984][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.0964, 0.9036], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:18,988][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.7283, 0.2717], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:18,991][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.9513, 0.0487], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:18,991][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.7801, 0.2199], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:18,992][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.9414, 0.0586], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:18,993][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.7059, 0.2941], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:18,994][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.7077, 0.2923], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:18,996][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.7815, 0.1522, 0.0662], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:18,997][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([4.4108e-03, 2.7918e-04, 9.9531e-01], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,001][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4095, 0.0618, 0.5288], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,004][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2259, 0.1120, 0.6621], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,008][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.5981, 0.2269, 0.1751], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,013][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1827, 0.0140, 0.8033], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,017][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6490, 0.3274, 0.0236], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,018][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4517, 0.3162, 0.2321], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,018][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2512, 0.0493, 0.6994], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,019][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.6103, 0.1381, 0.2516], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,020][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.6656, 0.1018, 0.2327], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,022][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.5538, 0.0987, 0.3475], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,024][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Mary] are: tensor([0.3587, 0.2577, 0.2664, 0.1172], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,027][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Mary] are: tensor([7.3197e-05, 1.5041e-04, 1.4913e-04, 9.9963e-01], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,031][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Mary] are: tensor([0.5206, 0.1761, 0.1055, 0.1977], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,033][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Mary] are: tensor([1.5185e-02, 8.1145e-04, 1.5251e-04, 9.8385e-01], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,037][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Mary] are: tensor([0.0133, 0.0225, 0.0012, 0.9630], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,040][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Mary] are: tensor([1.4138e-03, 1.4551e-05, 7.0409e-07, 9.9857e-01], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,042][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Mary] are: tensor([0.3301, 0.2582, 0.1102, 0.3016], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,043][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Mary] are: tensor([0.2703, 0.2530, 0.3896, 0.0871], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,044][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Mary] are: tensor([0.4264, 0.2651, 0.1355, 0.1729], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,044][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Mary] are: tensor([0.5326, 0.2052, 0.2267, 0.0355], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,046][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Mary] are: tensor([0.3820, 0.1291, 0.1798, 0.3091], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,049][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Mary] are: tensor([0.4067, 0.2515, 0.2120, 0.1299], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,053][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.4781, 0.1090, 0.0846, 0.0645, 0.2638], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,055][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([1.1712e-03, 1.8048e-03, 1.7618e-03, 4.6969e-04, 9.9479e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,059][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.5962, 0.0829, 0.1886, 0.0469, 0.0855], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,062][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([3.0723e-02, 8.7619e-04, 2.0130e-03, 3.6389e-03, 9.6275e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,065][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.3945, 0.0832, 0.0578, 0.0713, 0.3933], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,067][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([2.6715e-02, 1.4230e-04, 6.5623e-05, 5.9954e-05, 9.7302e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,068][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.2226, 0.3656, 0.0338, 0.3449, 0.0331], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,068][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.2187, 0.2204, 0.2325, 0.1347, 0.1936], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,069][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.3639, 0.1201, 0.3544, 0.1023, 0.0593], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,071][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.4347, 0.1355, 0.2125, 0.1006, 0.1168], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,074][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.4122, 0.1007, 0.1856, 0.0422, 0.2593], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,078][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.4769, 0.0949, 0.2374, 0.0707, 0.1201], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,082][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.4140, 0.1573, 0.0557, 0.1192, 0.2240, 0.0297], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,084][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([5.9643e-03, 1.2380e-04, 6.7602e-02, 2.2140e-04, 8.4874e-04, 9.2524e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,089][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3883, 0.0579, 0.1749, 0.0503, 0.0788, 0.2498], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,091][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0327, 0.0047, 0.0213, 0.0046, 0.4634, 0.4733], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,092][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1614, 0.0218, 0.0272, 0.0084, 0.6447, 0.1365], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,093][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0849, 0.0044, 0.1477, 0.0012, 0.0158, 0.7461], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,094][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.3150, 0.1178, 0.0173, 0.0826, 0.0820, 0.3853], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,096][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1359, 0.0919, 0.1157, 0.1199, 0.2951, 0.2415], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,099][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0604, 0.0153, 0.3491, 0.0158, 0.0653, 0.4940], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,103][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.3529, 0.1052, 0.1889, 0.0796, 0.0887, 0.1847], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,107][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.3452, 0.0769, 0.2381, 0.0572, 0.0892, 0.1935], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,111][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.3480, 0.0793, 0.1849, 0.0703, 0.1278, 0.1897], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,114][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.4538, 0.1396, 0.0399, 0.1919, 0.1217, 0.0210, 0.0321],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:19,116][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([9.0979e-03, 1.0376e-03, 6.6667e-02, 1.9136e-03, 1.9101e-04, 8.7204e-02,
        8.3389e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:19,117][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.3323, 0.0548, 0.1416, 0.0497, 0.1093, 0.2725, 0.0399],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:19,117][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0503, 0.0089, 0.0232, 0.0178, 0.0849, 0.1815, 0.6335],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:19,118][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.2850, 0.0766, 0.0396, 0.0701, 0.2750, 0.1180, 0.1356],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:19,120][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1795, 0.0200, 0.1521, 0.0084, 0.0411, 0.1353, 0.4635],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:19,123][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2692, 0.3157, 0.0062, 0.3200, 0.0753, 0.0099, 0.0037],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:19,127][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1179, 0.0291, 0.0821, 0.0951, 0.1457, 0.2279, 0.3022],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:19,131][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0305, 0.0126, 0.1958, 0.0100, 0.0524, 0.2097, 0.4890],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:19,134][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.3217, 0.0905, 0.1568, 0.0738, 0.0787, 0.1524, 0.1262],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:19,138][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.3503, 0.0802, 0.1682, 0.0610, 0.0445, 0.1143, 0.1815],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:19,141][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2813, 0.0830, 0.1473, 0.0779, 0.1071, 0.1430, 0.1603],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:19,142][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.2588, 0.1678, 0.1442, 0.1316, 0.0451, 0.0792, 0.0731, 0.1003],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:19,142][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([4.9783e-04, 1.9749e-03, 3.7060e-04, 4.8970e-04, 1.3708e-03, 3.2963e-04,
        9.3226e-05, 9.9487e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:19,143][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([0.3277, 0.1089, 0.0532, 0.1029, 0.0541, 0.0516, 0.0852, 0.2165],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:19,144][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([3.5546e-03, 6.3478e-04, 6.1259e-05, 5.5669e-03, 3.8944e-03, 8.8564e-04,
        5.8200e-04, 9.8482e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:19,147][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.0385, 0.0454, 0.0128, 0.0178, 0.0444, 0.0281, 0.0354, 0.7776],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:19,150][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([8.1032e-03, 6.6464e-04, 3.7222e-06, 4.8740e-05, 1.7408e-05, 2.2743e-07,
        9.5375e-07, 9.9116e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:19,154][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.1915, 0.2114, 0.0575, 0.1225, 0.0199, 0.0149, 0.0410, 0.3413],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:19,158][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.0851, 0.0416, 0.0653, 0.0565, 0.1622, 0.1664, 0.2598, 0.1632],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:19,163][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.3105, 0.0837, 0.1367, 0.0608, 0.0456, 0.1095, 0.1379, 0.1151],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:19,165][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.3546, 0.0810, 0.1398, 0.1083, 0.0652, 0.1148, 0.1122, 0.0241],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:19,166][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.2395, 0.0761, 0.1484, 0.0494, 0.0493, 0.1009, 0.0812, 0.2552],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:19,166][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.2612, 0.0786, 0.1620, 0.0647, 0.0853, 0.1112, 0.0630, 0.1740],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:19,167][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4569, 0.1013, 0.0210, 0.0947, 0.1235, 0.0193, 0.0610, 0.1081, 0.0141],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:19,169][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([3.4299e-03, 4.9336e-05, 2.5566e-02, 1.1887e-03, 5.2678e-04, 9.1259e-03,
        1.2513e-03, 2.2966e-05, 9.5884e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:19,172][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2722, 0.0315, 0.1190, 0.0298, 0.0469, 0.0601, 0.0137, 0.0157, 0.4111],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:19,176][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0533, 0.0019, 0.0084, 0.0049, 0.0762, 0.0461, 0.1217, 0.0297, 0.6579],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:19,180][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5134, 0.0273, 0.0152, 0.0301, 0.0713, 0.0514, 0.0281, 0.0894, 0.1738],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:19,183][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1380, 0.0249, 0.1985, 0.0127, 0.0596, 0.0986, 0.1472, 0.0292, 0.2913],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:19,187][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2316, 0.2005, 0.0081, 0.1641, 0.0498, 0.0160, 0.0053, 0.3198, 0.0049],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:19,189][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0475, 0.0225, 0.0302, 0.0513, 0.0614, 0.0808, 0.1591, 0.2373, 0.3098],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:19,190][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0343, 0.0076, 0.1784, 0.0063, 0.0216, 0.1585, 0.2319, 0.0099, 0.3515],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:19,191][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2661, 0.0784, 0.1350, 0.0665, 0.0722, 0.1252, 0.0992, 0.0555, 0.1019],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:19,192][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2268, 0.0597, 0.1632, 0.0795, 0.0694, 0.1352, 0.0985, 0.0577, 0.1100],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:19,194][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2539, 0.0657, 0.1248, 0.0678, 0.0940, 0.1142, 0.0649, 0.0756, 0.1391],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:19,198][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.1443, 0.1657, 0.0952, 0.0834, 0.0175, 0.0697, 0.0589, 0.1412, 0.0844,
        0.1397], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:19,200][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([1.0353e-04, 4.8718e-01, 3.4115e-05, 5.8733e-05, 5.4182e-05, 6.8315e-06,
        2.4894e-05, 7.2790e-05, 1.6321e-06, 5.1246e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:19,203][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.2729, 0.0642, 0.0496, 0.1131, 0.0400, 0.0295, 0.0815, 0.2666, 0.0486,
        0.0340], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:19,205][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([1.4113e-03, 3.8590e-03, 1.5151e-05, 4.5599e-04, 6.7400e-05, 1.2330e-04,
        4.6255e-04, 9.8303e-04, 4.7169e-04, 9.9215e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:19,210][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.0139, 0.0873, 0.0021, 0.0203, 0.0051, 0.0043, 0.0048, 0.0174, 0.0140,
        0.8307], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:19,212][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([6.8757e-03, 6.1333e-01, 2.5117e-07, 1.1706e-05, 4.9295e-07, 9.7002e-09,
        8.8058e-08, 1.0550e-05, 1.7430e-08, 3.7977e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:19,214][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.1289, 0.1986, 0.0632, 0.1840, 0.0160, 0.0098, 0.0564, 0.1382, 0.0632,
        0.1418], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:19,215][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0637, 0.0172, 0.0350, 0.0441, 0.0654, 0.1113, 0.1218, 0.1151, 0.2607,
        0.1657], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:19,216][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.2176, 0.1506, 0.0796, 0.1541, 0.0232, 0.0428, 0.0853, 0.0500, 0.0652,
        0.1316], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:19,216][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.2929, 0.0246, 0.1281, 0.1061, 0.0784, 0.1037, 0.0957, 0.0554, 0.1007,
        0.0145], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:19,218][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.1664, 0.2675, 0.0945, 0.0481, 0.0316, 0.0693, 0.0609, 0.0348, 0.0527,
        0.1742], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:19,221][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.1314, 0.0985, 0.1081, 0.0676, 0.1299, 0.0754, 0.0519, 0.1154, 0.1061,
        0.1156], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:19,225][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.2561, 0.0677, 0.0309, 0.0410, 0.2073, 0.0202, 0.0190, 0.0693, 0.0221,
        0.0791, 0.1874], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:19,227][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([9.4694e-04, 3.8203e-04, 2.3591e-03, 9.1758e-04, 8.8458e-03, 1.1981e-03,
        3.2221e-04, 1.3290e-04, 3.6775e-04, 1.1290e-04, 9.8441e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:19,231][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.2993, 0.0690, 0.0726, 0.0266, 0.0838, 0.1106, 0.0716, 0.0832, 0.0449,
        0.0545, 0.0839], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:19,234][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([2.3860e-03, 1.1648e-05, 2.9798e-05, 6.4130e-05, 1.0952e-03, 1.3026e-04,
        1.9876e-04, 3.9764e-04, 1.7820e-03, 8.5830e-04, 9.9305e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:19,237][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1348, 0.0130, 0.0140, 0.0132, 0.0386, 0.0317, 0.0209, 0.0839, 0.0454,
        0.0546, 0.5500], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:19,239][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([4.7299e-02, 2.3990e-04, 3.9505e-05, 1.8124e-04, 1.0252e-02, 4.1297e-06,
        1.4026e-05, 4.8301e-05, 1.9010e-06, 2.2820e-05, 9.4190e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:19,240][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.1160, 0.1749, 0.0161, 0.1814, 0.0255, 0.0117, 0.0154, 0.1814, 0.0129,
        0.2373, 0.0275], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:19,241][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0495, 0.0114, 0.0221, 0.0189, 0.0250, 0.0501, 0.0839, 0.0527, 0.2060,
        0.2194, 0.2610], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:19,242][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.1267, 0.0227, 0.1378, 0.0470, 0.0462, 0.1311, 0.1792, 0.0817, 0.1605,
        0.0225, 0.0448], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:19,245][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.1967, 0.0640, 0.1044, 0.0571, 0.0854, 0.1017, 0.0833, 0.0801, 0.0921,
        0.0601, 0.0751], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:19,249][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.1670, 0.0545, 0.0988, 0.0449, 0.1053, 0.0941, 0.0664, 0.0441, 0.0719,
        0.0376, 0.2156], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:19,253][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.3054, 0.0483, 0.1286, 0.0303, 0.0516, 0.1091, 0.0484, 0.0490, 0.1060,
        0.0450, 0.0783], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:19,256][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2460, 0.0775, 0.0232, 0.0961, 0.0605, 0.0149, 0.0276, 0.1956, 0.0238,
        0.0931, 0.1194, 0.0222], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:19,259][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([3.0327e-03, 1.5241e-03, 3.7276e-03, 1.3616e-03, 1.0816e-04, 9.8320e-03,
        3.0956e-02, 8.7597e-05, 1.0086e-03, 5.5194e-04, 2.1872e-04, 9.4759e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:19,263][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1791, 0.0564, 0.1167, 0.0422, 0.0807, 0.1892, 0.0267, 0.0517, 0.0770,
        0.0522, 0.1030, 0.0248], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:19,264][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.1768e-02, 9.4817e-04, 9.2382e-04, 6.9698e-04, 1.9407e-03, 4.0065e-03,
        1.5780e-02, 3.4038e-03, 4.8307e-02, 5.5406e-02, 1.3132e-01, 7.2550e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:19,264][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0587, 0.0099, 0.0059, 0.0076, 0.0601, 0.0156, 0.0168, 0.0391, 0.0303,
        0.0719, 0.5103, 0.1736], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:19,265][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0653, 0.0072, 0.1042, 0.0046, 0.0110, 0.0923, 0.2241, 0.0040, 0.0313,
        0.0013, 0.0075, 0.4473], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:19,267][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1370, 0.1299, 0.0039, 0.1464, 0.0567, 0.0073, 0.0029, 0.2448, 0.0027,
        0.1905, 0.0729, 0.0049], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:19,270][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0342, 0.0066, 0.0111, 0.0090, 0.0231, 0.0223, 0.0389, 0.0443, 0.1147,
        0.1340, 0.2829, 0.2789], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:19,274][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0159, 0.0040, 0.0799, 0.0050, 0.0220, 0.0966, 0.2268, 0.0106, 0.1532,
        0.0070, 0.0279, 0.3510], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:19,278][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1848, 0.0625, 0.1054, 0.0535, 0.0528, 0.1008, 0.0859, 0.0615, 0.0830,
        0.0546, 0.0688, 0.0864], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:19,281][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1738, 0.0533, 0.1112, 0.0483, 0.0385, 0.1035, 0.1107, 0.0520, 0.0727,
        0.0348, 0.0402, 0.1611], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:19,285][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.2045, 0.0538, 0.0895, 0.0412, 0.0705, 0.0992, 0.0539, 0.0553, 0.1023,
        0.0575, 0.0984, 0.0738], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:19,287][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.1716, 0.1526, 0.0541, 0.0602, 0.0565, 0.0313, 0.0251, 0.0841, 0.0539,
        0.1544, 0.0485, 0.0339, 0.0740], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:19,288][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([1.9969e-04, 6.1479e-04, 6.3570e-04, 1.5864e-05, 2.8556e-04, 5.0114e-04,
        4.1060e-04, 5.7692e-04, 2.4272e-04, 1.7375e-04, 5.4676e-05, 1.2973e-04,
        9.9616e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:19,289][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.2711, 0.0506, 0.0776, 0.0535, 0.0465, 0.0802, 0.0879, 0.0169, 0.0368,
        0.0334, 0.0548, 0.0781, 0.1124], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:19,290][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([4.7137e-04, 4.4486e-06, 1.0523e-06, 1.1158e-05, 8.5991e-06, 8.1358e-06,
        1.3774e-05, 4.6763e-04, 2.9242e-05, 5.7696e-04, 9.5800e-04, 3.6189e-04,
        9.9709e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:19,293][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.0500, 0.0024, 0.0017, 0.0041, 0.0019, 0.0029, 0.0043, 0.0098, 0.0072,
        0.0062, 0.0167, 0.0224, 0.8704], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:19,296][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([1.7287e-03, 1.0700e-04, 8.3498e-06, 7.3512e-06, 8.1834e-06, 1.3760e-06,
        1.3585e-05, 1.9271e-04, 3.0488e-06, 1.0510e-05, 1.4653e-07, 6.0265e-06,
        9.9791e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:19,300][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.1535, 0.0993, 0.0230, 0.0815, 0.0325, 0.0217, 0.0179, 0.1757, 0.0208,
        0.0695, 0.0317, 0.0194, 0.2535], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:19,304][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0465, 0.0044, 0.0141, 0.0052, 0.0187, 0.0235, 0.0353, 0.1436, 0.0809,
        0.0439, 0.2183, 0.2603, 0.1051], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:19,307][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.1842, 0.0430, 0.0896, 0.0281, 0.0546, 0.0682, 0.1004, 0.1051, 0.0680,
        0.0338, 0.0346, 0.0726, 0.1178], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:19,311][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.1899, 0.0970, 0.0864, 0.0432, 0.0378, 0.0725, 0.0818, 0.0647, 0.0729,
        0.0873, 0.0611, 0.0885, 0.0168], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:19,312][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.1580, 0.0460, 0.0871, 0.0201, 0.0364, 0.0710, 0.0806, 0.0323, 0.0613,
        0.0291, 0.0331, 0.0605, 0.2844], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:19,313][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.2755, 0.0469, 0.0962, 0.0386, 0.0529, 0.0850, 0.0357, 0.0421, 0.1184,
        0.0406, 0.0752, 0.0372, 0.0559], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:19,314][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2101, 0.0787, 0.0221, 0.0600, 0.1236, 0.0119, 0.0268, 0.0847, 0.0234,
        0.1044, 0.1326, 0.0268, 0.0789, 0.0158], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:19,315][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.8458e-03, 2.7826e-05, 2.1804e-02, 6.5405e-05, 2.6971e-04, 4.6082e-01,
        1.1720e-03, 2.5528e-05, 4.8528e-03, 6.8010e-06, 3.8296e-04, 7.0108e-04,
        3.6341e-05, 5.0699e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:19,318][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1968, 0.0356, 0.0972, 0.0316, 0.0543, 0.1475, 0.0288, 0.0297, 0.0581,
        0.0282, 0.0669, 0.0258, 0.0299, 0.1696], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:19,321][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([4.3681e-03, 6.7934e-05, 2.0918e-04, 3.2224e-05, 3.0424e-03, 2.1455e-03,
        2.6729e-03, 8.1993e-04, 7.1195e-03, 1.6527e-03, 2.6937e-01, 7.5036e-02,
        1.8156e-02, 6.1531e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:19,325][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0371, 0.0019, 0.0032, 0.0006, 0.0618, 0.0121, 0.0073, 0.0137, 0.0106,
        0.0111, 0.3426, 0.0768, 0.1849, 0.2362], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:19,327][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.2114e-02, 1.9530e-03, 6.2304e-02, 4.0350e-04, 8.8487e-03, 3.8492e-01,
        1.4285e-01, 1.2841e-03, 1.3914e-02, 3.6348e-04, 4.4089e-03, 9.7065e-02,
        4.0000e-03, 2.5557e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:19,331][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1169, 0.0474, 0.0052, 0.0353, 0.0346, 0.1550, 0.0033, 0.0566, 0.0040,
        0.0564, 0.0530, 0.0057, 0.1434, 0.2833], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:19,336][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0264, 0.0055, 0.0063, 0.0063, 0.0126, 0.0087, 0.0195, 0.0191, 0.0498,
        0.0828, 0.1210, 0.1646, 0.1866, 0.2908], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:19,336][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0132, 0.0034, 0.0875, 0.0035, 0.0194, 0.1193, 0.1613, 0.0120, 0.1377,
        0.0050, 0.0187, 0.1892, 0.0111, 0.2187], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:19,337][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1556, 0.0537, 0.0890, 0.0408, 0.0475, 0.0850, 0.0760, 0.0482, 0.0711,
        0.0489, 0.0628, 0.0808, 0.0400, 0.1005], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:19,339][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1245, 0.0344, 0.1071, 0.0380, 0.0662, 0.1199, 0.0834, 0.0402, 0.0765,
        0.0245, 0.0588, 0.0820, 0.0331, 0.1113], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:19,342][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1804, 0.0464, 0.0821, 0.0358, 0.0675, 0.0813, 0.0396, 0.0446, 0.0856,
        0.0466, 0.0906, 0.0529, 0.0624, 0.0840], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:19,346][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:23:19,348][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[  813],
        [10616],
        [ 4778],
        [    1],
        [20847],
        [ 4159],
        [ 7127],
        [28617],
        [ 3256],
        [12590],
        [12948],
        [10090],
        [16661],
        [ 6872]], device='cuda:0')
[2024-07-24 10:23:19,350][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[41115],
        [14505],
        [42895],
        [    1],
        [45629],
        [44736],
        [39449],
        [46132],
        [44706],
        [12116],
        [44511],
        [39197],
        [46403],
        [43494]], device='cuda:0')
[2024-07-24 10:23:19,353][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[4039],
        [4891],
        [3552],
        [2424],
        [3344],
        [3555],
        [2239],
        [3793],
        [2656],
        [4477],
        [6415],
        [4048],
        [4786],
        [5530]], device='cuda:0')
[2024-07-24 10:23:19,356][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[38729],
        [29054],
        [13658],
        [  108],
        [23508],
        [21932],
        [26351],
        [30863],
        [ 5090],
        [34551],
        [19351],
        [32874],
        [40722],
        [21432]], device='cuda:0')
[2024-07-24 10:23:19,358][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 5545],
        [ 5244],
        [ 6367],
        [ 2216],
        [ 5636],
        [ 7550],
        [ 8106],
        [11459],
        [ 9588],
        [15983],
        [ 9366],
        [ 9873],
        [ 7941],
        [10562]], device='cuda:0')
[2024-07-24 10:23:19,361][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[10234],
        [20556],
        [14386],
        [22731],
        [46157],
        [40107],
        [36092],
        [23249],
        [36154],
        [19176],
        [22538],
        [30855],
        [29736],
        [23962]], device='cuda:0')
[2024-07-24 10:23:19,363][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 1893],
        [ 1766],
        [ 1134],
        [  157],
        [  644],
        [ 2284],
        [  602],
        [30832],
        [ 1063],
        [ 4705],
        [ 3658],
        [ 3022],
        [12918],
        [ 3222]], device='cuda:0')
[2024-07-24 10:23:19,365][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[31786],
        [11927],
        [11567],
        [  318],
        [ 5352],
        [ 3321],
        [11784],
        [15620],
        [ 6572],
        [11134],
        [16395],
        [ 6968],
        [11776],
        [ 3496]], device='cuda:0')
[2024-07-24 10:23:19,366][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[36112],
        [18785],
        [15252],
        [ 1398],
        [  350],
        [ 1840],
        [  393],
        [11251],
        [ 7072],
        [ 2964],
        [ 1134],
        [ 2466],
        [16594],
        [ 1582]], device='cuda:0')
[2024-07-24 10:23:19,368][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[17556],
        [16912],
        [23009],
        [27804],
        [15674],
        [22311],
        [21656],
        [14675],
        [10291],
        [11563],
        [10002],
        [12130],
        [12507],
        [28176]], device='cuda:0')
[2024-07-24 10:23:19,370][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[10417],
        [ 6446],
        [ 8004],
        [ 2548],
        [ 3938],
        [ 9595],
        [13474],
        [ 6181],
        [16251],
        [ 2416],
        [11270],
        [18480],
        [11544],
        [15008]], device='cuda:0')
[2024-07-24 10:23:19,373][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[18758],
        [16575],
        [20897],
        [16097],
        [17967],
        [25456],
        [25079],
        [21149],
        [25776],
        [25280],
        [23404],
        [24380],
        [17816],
        [25027]], device='cuda:0')
[2024-07-24 10:23:19,376][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 5414],
        [15874],
        [ 3618],
        [26918],
        [ 8012],
        [ 4273],
        [ 9960],
        [27156],
        [ 7313],
        [33269],
        [ 8645],
        [16986],
        [42378],
        [ 9909]], device='cuda:0')
[2024-07-24 10:23:19,378][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[31174],
        [30077],
        [25940],
        [21344],
        [21759],
        [19401],
        [19429],
        [10685],
        [16022],
        [ 9102],
        [15873],
        [10844],
        [11406],
        [ 7003]], device='cuda:0')
[2024-07-24 10:23:19,381][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[22742],
        [38555],
        [29601],
        [   19],
        [45015],
        [19338],
        [39668],
        [44106],
        [21739],
        [40594],
        [26636],
        [38884],
        [27468],
        [18686]], device='cuda:0')
[2024-07-24 10:23:19,383][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[34200],
        [29866],
        [27793],
        [ 9723],
        [17531],
        [18086],
        [18130],
        [12476],
        [18724],
        [11276],
        [17089],
        [18844],
        [14505],
        [17821]], device='cuda:0')
[2024-07-24 10:23:19,386][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 1503],
        [16331],
        [ 5836],
        [23761],
        [11999],
        [ 3749],
        [ 2934],
        [ 7949],
        [12730],
        [10380],
        [13665],
        [ 2133],
        [ 5260],
        [ 3517]], device='cuda:0')
[2024-07-24 10:23:19,389][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[47564],
        [47536],
        [44100],
        [46361],
        [46390],
        [42361],
        [42064],
        [45794],
        [41450],
        [45243],
        [45150],
        [42700],
        [41975],
        [38614]], device='cuda:0')
[2024-07-24 10:23:19,391][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[37753],
        [ 7748],
        [25779],
        [ 6969],
        [ 3156],
        [11599],
        [16828],
        [10407],
        [25063],
        [ 9823],
        [11193],
        [20180],
        [ 7376],
        [24488]], device='cuda:0')
[2024-07-24 10:23:19,392][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[22936],
        [11632],
        [26037],
        [ 8903],
        [18827],
        [19744],
        [22973],
        [ 8800],
        [32458],
        [10108],
        [24665],
        [24142],
        [14779],
        [25826]], device='cuda:0')
[2024-07-24 10:23:19,394][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 8962],
        [29951],
        [37256],
        [40478],
        [41249],
        [38381],
        [34819],
        [17836],
        [34667],
        [29237],
        [26226],
        [38020],
        [12065],
        [38736]], device='cuda:0')
[2024-07-24 10:23:19,395][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[39806],
        [26911],
        [22031],
        [ 3753],
        [ 2597],
        [29901],
        [ 2583],
        [11270],
        [ 7349],
        [ 8324],
        [ 5462],
        [ 6224],
        [ 8489],
        [38230]], device='cuda:0')
[2024-07-24 10:23:19,398][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[3357],
        [3567],
        [5615],
        [3647],
        [2910],
        [ 424],
        [ 339],
        [ 881],
        [3276],
        [2942],
        [2149],
        [1503],
        [2088],
        [ 645]], device='cuda:0')
[2024-07-24 10:23:19,400][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[36703],
        [40591],
        [34432],
        [41981],
        [39175],
        [30431],
        [28986],
        [37299],
        [22813],
        [41127],
        [32762],
        [25776],
        [35979],
        [25712]], device='cuda:0')
[2024-07-24 10:23:19,403][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[35267],
        [34959],
        [37010],
        [36833],
        [36964],
        [36789],
        [35954],
        [35902],
        [36019],
        [36043],
        [37064],
        [35878],
        [36193],
        [36050]], device='cuda:0')
[2024-07-24 10:23:19,406][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[42415],
        [40132],
        [44227],
        [43914],
        [44747],
        [45675],
        [42502],
        [43995],
        [44728],
        [40775],
        [46594],
        [41700],
        [42730],
        [43903]], device='cuda:0')
[2024-07-24 10:23:19,408][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 3347],
        [12721],
        [13689],
        [46747],
        [33280],
        [39288],
        [35366],
        [39672],
        [42264],
        [47717],
        [44216],
        [45850],
        [44408],
        [45006]], device='cuda:0')
[2024-07-24 10:23:19,411][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[1650],
        [3384],
        [2802],
        [4639],
        [5061],
        [3855],
        [9147],
        [4721],
        [3792],
        [5006],
        [3902],
        [6159],
        [5791],
        [3843]], device='cuda:0')
[2024-07-24 10:23:19,413][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 9398],
        [ 3870],
        [ 7650],
        [50042],
        [ 1964],
        [14986],
        [ 2557],
        [ 2364],
        [13089],
        [ 3027],
        [11604],
        [ 3388],
        [11151],
        [15709]], device='cuda:0')
[2024-07-24 10:23:19,416][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[21256],
        [21256],
        [21256],
        [21256],
        [21256],
        [21256],
        [21256],
        [21256],
        [21256],
        [21256],
        [21256],
        [21256],
        [21256],
        [21256]], device='cuda:0')
[2024-07-24 10:23:19,438][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:19,441][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:19,442][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:19,443][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:19,443][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:19,444][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:19,445][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:19,445][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:19,446][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:19,447][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:19,447][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:19,448][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:19,449][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:19,449][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.5002, 0.4998], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:19,450][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.5002, 0.4998], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:19,451][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.6527, 0.3473], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:19,455][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.7479, 0.2521], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:19,458][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.8640, 0.1360], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:19,462][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.8959, 0.1041], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:19,463][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.6821, 0.3179], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:19,463][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0586, 0.9414], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:19,464][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.8012, 0.1988], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:19,465][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.0886, 0.9114], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:19,467][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0267, 0.9733], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:19,469][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.1326, 0.8674], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:19,473][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3331, 0.3329, 0.3340], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,477][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.3331, 0.3329, 0.3340], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,480][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4648, 0.2570, 0.2782], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,484][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.6281, 0.1888, 0.1831], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,486][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4853, 0.1738, 0.3410], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,487][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.9303, 0.0538, 0.0159], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,488][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.8628, 0.0660, 0.0712], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,489][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1243, 0.7035, 0.1722], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,490][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.6228, 0.2296, 0.1476], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,493][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0679, 0.6575, 0.2746], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,497][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0220, 0.6149, 0.3631], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,501][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2548, 0.0015, 0.7436], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,504][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Mary] are: tensor([0.2498, 0.2497, 0.2505, 0.2500], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,508][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Mary] are: tensor([0.2499, 0.2497, 0.2505, 0.2499], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,510][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Mary] are: tensor([0.3580, 0.2056, 0.2205, 0.2159], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,511][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Mary] are: tensor([0.4511, 0.1759, 0.1784, 0.1947], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,512][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Mary] are: tensor([0.3551, 0.1049, 0.3450, 0.1950], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,513][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Mary] are: tensor([9.8110e-01, 1.6861e-02, 1.7804e-03, 2.6225e-04], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,514][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Mary] are: tensor([0.3239, 0.1473, 0.1376, 0.3912], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,516][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Mary] are: tensor([0.0410, 0.7813, 0.0819, 0.0959], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,519][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Mary] are: tensor([0.6378, 0.1713, 0.1053, 0.0856], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,523][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Mary] are: tensor([0.0524, 0.5433, 0.2950, 0.1093], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,526][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Mary] are: tensor([0.0219, 0.3877, 0.2696, 0.3209], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,530][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Mary] are: tensor([0.0515, 0.0117, 0.1291, 0.8078], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,534][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.1999, 0.1998, 0.2004, 0.2000, 0.1998], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,535][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.2000, 0.1998, 0.2005, 0.2000, 0.1998], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,536][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.3012, 0.1634, 0.1747, 0.1779, 0.1828], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,536][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.4218, 0.1389, 0.1381, 0.1632, 0.1379], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,538][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.2214, 0.0811, 0.2606, 0.2056, 0.2312], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,540][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ went] are: tensor([9.7520e-01, 2.1415e-02, 2.8455e-03, 2.1233e-04, 3.2576e-04],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,543][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.6100, 0.0574, 0.0866, 0.2210, 0.0250], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,547][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0177, 0.2399, 0.0579, 0.4232, 0.2613], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,550][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.5388, 0.1642, 0.1044, 0.0850, 0.1076], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,554][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.0513, 0.4873, 0.2241, 0.0907, 0.1466], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,558][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0118, 0.2861, 0.1610, 0.2589, 0.2822], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,559][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ went] are: tensor([4.0019e-03, 1.3656e-04, 3.2977e-02, 6.8550e-05, 9.6282e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,560][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1666, 0.1665, 0.1670, 0.1667, 0.1665, 0.1668], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,560][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1666, 0.1665, 0.1670, 0.1666, 0.1665, 0.1668], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,561][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2398, 0.1411, 0.1455, 0.1592, 0.1586, 0.1557], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,563][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.3969, 0.1229, 0.1157, 0.1388, 0.1192, 0.1065], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,566][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1257, 0.0607, 0.1500, 0.1452, 0.1766, 0.3418], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,568][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([9.8086e-01, 1.6630e-02, 1.9430e-03, 1.3839e-04, 2.3694e-04, 1.9349e-04],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,572][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.5219, 0.1396, 0.1564, 0.1042, 0.0414, 0.0364], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,576][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0404, 0.2000, 0.0609, 0.2431, 0.4118, 0.0439], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,579][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.4634, 0.1668, 0.1139, 0.0832, 0.1091, 0.0635], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,583][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0594, 0.5003, 0.1868, 0.0848, 0.1260, 0.0427], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,584][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0102, 0.2434, 0.1326, 0.2397, 0.2523, 0.1219], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,584][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.0703e-01, 6.9004e-04, 2.6704e-01, 5.2762e-04, 8.3658e-04, 6.2388e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,585][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1428, 0.1427, 0.1431, 0.1429, 0.1427, 0.1430, 0.1429],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:19,587][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1428, 0.1427, 0.1431, 0.1428, 0.1427, 0.1430, 0.1429],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:19,590][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.2070, 0.1256, 0.1303, 0.1369, 0.1416, 0.1328, 0.1258],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:19,593][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.3803, 0.1067, 0.1058, 0.1193, 0.1080, 0.0964, 0.0836],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:19,597][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0968, 0.0431, 0.1264, 0.1028, 0.1392, 0.2388, 0.2529],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:19,600][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ the] are: tensor([9.8653e-01, 1.1927e-02, 1.1789e-03, 1.1350e-04, 1.3335e-04, 9.2717e-05,
        2.8852e-05], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:19,603][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.5392, 0.0857, 0.0437, 0.2491, 0.0180, 0.0227, 0.0416],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:19,607][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0203, 0.2566, 0.0197, 0.2138, 0.4068, 0.0124, 0.0704],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:19,608][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.4291, 0.1436, 0.1080, 0.0667, 0.0953, 0.0578, 0.0996],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:19,608][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0539, 0.4243, 0.1578, 0.0665, 0.1027, 0.0338, 0.1610],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:19,609][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0106, 0.2163, 0.1224, 0.2108, 0.2125, 0.0993, 0.1281],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:19,610][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ the] are: tensor([5.2604e-02, 7.7609e-04, 9.9422e-02, 1.4212e-03, 2.7621e-03, 2.7796e-02,
        8.1522e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:19,613][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.1249, 0.1248, 0.1252, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:19,617][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([0.1249, 0.1248, 0.1252, 0.1249, 0.1248, 0.1251, 0.1250, 0.1251],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:19,621][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.1982, 0.1092, 0.1144, 0.1165, 0.1182, 0.1162, 0.1028, 0.1246],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:19,625][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.2933, 0.1026, 0.1020, 0.1157, 0.1027, 0.0918, 0.0734, 0.1185],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:19,629][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.1263, 0.0521, 0.1108, 0.1134, 0.1185, 0.2013, 0.1747, 0.1030],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:19,631][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([9.3046e-01, 4.2315e-02, 1.0940e-02, 2.0983e-03, 1.4767e-03, 1.3021e-03,
        6.8267e-04, 1.0720e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:19,632][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.5161, 0.0952, 0.0237, 0.1079, 0.0631, 0.0221, 0.0227, 0.1492],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:19,633][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.0098, 0.3175, 0.0202, 0.2256, 0.3201, 0.0221, 0.0604, 0.0242],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:19,634][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.4201, 0.1267, 0.0826, 0.0688, 0.0925, 0.0492, 0.1221, 0.0381],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:19,636][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.0308, 0.3219, 0.1743, 0.0763, 0.1158, 0.0430, 0.1828, 0.0549],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:19,639][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.0082, 0.1805, 0.1080, 0.1780, 0.1767, 0.0941, 0.0882, 0.1664],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:19,642][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([1.4988e-02, 9.0432e-04, 4.1097e-02, 8.1787e-04, 2.3115e-03, 1.7122e-02,
        2.0355e-03, 9.2072e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:19,645][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1111, 0.1110, 0.1113, 0.1111, 0.1110, 0.1112, 0.1111, 0.1112, 0.1110],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:19,649][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1111, 0.1110, 0.1113, 0.1111, 0.1110, 0.1112, 0.1112, 0.1112, 0.1110],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:19,653][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1625, 0.0955, 0.0982, 0.1056, 0.1087, 0.1017, 0.0936, 0.1150, 0.1193],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:19,656][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3257, 0.0859, 0.0829, 0.0966, 0.0846, 0.0745, 0.0619, 0.1027, 0.0852],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:19,656][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0690, 0.0372, 0.0941, 0.0756, 0.1049, 0.1474, 0.1371, 0.0971, 0.2375],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:19,657][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([9.8916e-01, 9.2961e-03, 9.2622e-04, 8.1441e-05, 9.6093e-05, 7.1951e-05,
        2.1295e-05, 3.3279e-04, 1.1514e-05], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:19,658][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.6237, 0.0083, 0.0428, 0.0306, 0.0459, 0.0231, 0.0809, 0.0162, 0.1286],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:19,660][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0204, 0.2272, 0.0382, 0.1764, 0.2048, 0.0283, 0.0691, 0.1929, 0.0426],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:19,663][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3678, 0.1506, 0.1042, 0.0695, 0.0908, 0.0550, 0.0897, 0.0361, 0.0362],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:19,667][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0422, 0.3512, 0.1324, 0.0626, 0.0877, 0.0310, 0.1279, 0.0364, 0.1285],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:19,671][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0073, 0.1577, 0.0935, 0.1510, 0.1768, 0.0784, 0.0819, 0.1785, 0.0748],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:19,674][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1670, 0.0094, 0.3976, 0.0217, 0.0196, 0.1562, 0.0754, 0.0271, 0.1259],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:19,678][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.1000, 0.0999, 0.1002, 0.1000, 0.0999, 0.1001, 0.1000, 0.1001, 0.0999,
        0.0999], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:19,681][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.1000, 0.0999, 0.1002, 0.1000, 0.0999, 0.1001, 0.1001, 0.1001, 0.0999,
        0.0999], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:19,681][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.1508, 0.0851, 0.0920, 0.0916, 0.0965, 0.0913, 0.0824, 0.1011, 0.1083,
        0.1009], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:19,682][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.3180, 0.0752, 0.0760, 0.0791, 0.0716, 0.0669, 0.0511, 0.0878, 0.0784,
        0.0959], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:19,683][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.0636, 0.0214, 0.1118, 0.0431, 0.0729, 0.1525, 0.1423, 0.0524, 0.2884,
        0.0518], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:19,685][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([9.7729e-01, 1.7860e-02, 2.6743e-03, 3.1525e-04, 2.7125e-04, 1.9869e-04,
        7.4526e-05, 1.1526e-03, 4.4951e-05, 1.2135e-04], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:19,687][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.0071, 0.1051, 0.0635, 0.0560, 0.0413, 0.1007, 0.0624, 0.3369, 0.1672,
        0.0598], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:19,692][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0044, 0.1552, 0.0304, 0.1783, 0.0982, 0.0169, 0.0508, 0.3282, 0.0292,
        0.1083], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:19,696][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.3858, 0.1084, 0.0690, 0.0594, 0.0840, 0.0446, 0.1209, 0.0350, 0.0465,
        0.0465], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:19,700][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.0241, 0.2424, 0.1399, 0.0532, 0.0903, 0.0321, 0.1557, 0.0351, 0.1832,
        0.0440], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:19,705][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0080, 0.1374, 0.0953, 0.1285, 0.1405, 0.0750, 0.0787, 0.1505, 0.0741,
        0.1120], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:19,706][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([2.3636e-04, 2.8450e-01, 8.8222e-04, 3.8256e-04, 2.2747e-05, 3.7520e-04,
        1.1583e-04, 4.2839e-05, 1.6731e-02, 6.9671e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:19,706][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0909, 0.0908, 0.0911, 0.0909, 0.0908, 0.0910, 0.0909, 0.0910, 0.0908,
        0.0908, 0.0909], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:19,707][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0909, 0.0908, 0.0911, 0.0909, 0.0908, 0.0910, 0.0910, 0.0910, 0.0908,
        0.0908, 0.0909], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:19,709][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.1355, 0.0777, 0.0811, 0.0839, 0.0863, 0.0830, 0.0731, 0.0923, 0.0973,
        0.0926, 0.0974], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:19,713][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.2486, 0.0711, 0.0729, 0.0846, 0.0740, 0.0650, 0.0514, 0.0880, 0.0769,
        0.0926, 0.0749], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:19,716][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0729, 0.0285, 0.0912, 0.0547, 0.0740, 0.1422, 0.1081, 0.0558, 0.2178,
        0.0682, 0.0867], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:19,718][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([9.8791e-01, 1.0491e-02, 8.5626e-04, 9.2500e-05, 1.0049e-04, 8.0313e-05,
        2.4995e-05, 3.7942e-04, 1.2919e-05, 3.5186e-05, 1.8713e-05],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:19,722][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0364, 0.0277, 0.1386, 0.0965, 0.0482, 0.0442, 0.1083, 0.0353, 0.2751,
        0.1468, 0.0430], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:19,727][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0042, 0.1226, 0.0162, 0.0918, 0.2270, 0.0096, 0.0170, 0.3541, 0.0101,
        0.0916, 0.0558], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:19,729][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.3767, 0.1183, 0.0822, 0.0562, 0.0817, 0.0467, 0.1018, 0.0328, 0.0394,
        0.0389, 0.0254], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:19,730][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0272, 0.2561, 0.1180, 0.0530, 0.0782, 0.0284, 0.1223, 0.0337, 0.1366,
        0.0433, 0.1032], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:19,731][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0058, 0.1278, 0.0722, 0.1145, 0.1368, 0.0658, 0.0625, 0.1310, 0.0621,
        0.1096, 0.1119], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:19,732][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([1.0353e-02, 8.3144e-04, 3.1053e-02, 2.0114e-04, 1.9685e-03, 1.0967e-02,
        3.6785e-04, 1.9289e-03, 2.0370e-02, 7.7472e-05, 9.2188e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:19,734][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0833, 0.0833, 0.0835, 0.0834, 0.0832, 0.0834, 0.0834, 0.0835, 0.0833,
        0.0832, 0.0833, 0.0832], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:19,737][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0833, 0.0833, 0.0835, 0.0833, 0.0833, 0.0834, 0.0834, 0.0834, 0.0833,
        0.0832, 0.0833, 0.0832], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:19,741][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1176, 0.0712, 0.0747, 0.0777, 0.0784, 0.0764, 0.0712, 0.0882, 0.0901,
        0.0871, 0.0892, 0.0782], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:19,745][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2643, 0.0680, 0.0652, 0.0758, 0.0666, 0.0592, 0.0495, 0.0800, 0.0679,
        0.0853, 0.0656, 0.0527], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:19,749][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0447, 0.0169, 0.0700, 0.0392, 0.0568, 0.1218, 0.1206, 0.0636, 0.2068,
        0.0479, 0.0839, 0.1277], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:19,752][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([9.9506e-01, 4.4203e-03, 2.8851e-04, 2.7851e-05, 2.4775e-05, 2.1223e-05,
        5.5979e-06, 1.3634e-04, 2.8647e-06, 1.1442e-05, 3.8860e-06, 3.0208e-07],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:19,756][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1530, 0.0556, 0.1144, 0.0797, 0.0354, 0.0498, 0.1023, 0.0073, 0.1911,
        0.1473, 0.0175, 0.0466], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:19,757][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0136, 0.1326, 0.0168, 0.1130, 0.2090, 0.0124, 0.0373, 0.1954, 0.0164,
        0.1208, 0.0939, 0.0386], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:19,758][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.3828, 0.1236, 0.0798, 0.0547, 0.0787, 0.0448, 0.0832, 0.0304, 0.0343,
        0.0361, 0.0216, 0.0299], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:19,758][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0286, 0.2525, 0.1062, 0.0468, 0.0700, 0.0246, 0.1095, 0.0275, 0.1152,
        0.0374, 0.0905, 0.0911], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:19,760][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0060, 0.1156, 0.0666, 0.1110, 0.1176, 0.0550, 0.0648, 0.1337, 0.0555,
        0.1028, 0.1107, 0.0605], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:19,762][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.7318e-02, 7.7838e-04, 2.4353e-02, 2.6281e-04, 2.3912e-03, 2.0885e-02,
        2.8624e-03, 3.8176e-03, 1.2498e-02, 1.2302e-04, 2.3873e-04, 9.1447e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:19,767][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0769, 0.0769, 0.0771, 0.0770, 0.0769, 0.0770, 0.0770, 0.0770, 0.0769,
        0.0769, 0.0769, 0.0768, 0.0767], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:19,770][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0769, 0.0769, 0.0771, 0.0769, 0.0769, 0.0770, 0.0770, 0.0770, 0.0769,
        0.0768, 0.0769, 0.0768, 0.0767], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:19,774][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.1175, 0.0653, 0.0697, 0.0704, 0.0717, 0.0719, 0.0637, 0.0784, 0.0849,
        0.0787, 0.0838, 0.0694, 0.0744], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:19,778][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.2132, 0.0671, 0.0648, 0.0764, 0.0675, 0.0568, 0.0454, 0.0773, 0.0685,
        0.0819, 0.0690, 0.0489, 0.0632], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:19,781][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0560, 0.0198, 0.0801, 0.0436, 0.0528, 0.1226, 0.0952, 0.0487, 0.2024,
        0.0540, 0.0696, 0.1090, 0.0462], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:19,781][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([9.8847e-01, 9.2890e-03, 9.9846e-04, 1.3561e-04, 9.0457e-05, 9.4320e-05,
        2.9251e-05, 7.3257e-04, 1.6391e-05, 5.3934e-05, 1.8643e-05, 2.2612e-06,
        6.7342e-05], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:19,782][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0241, 0.1617, 0.0418, 0.0116, 0.0093, 0.0190, 0.0191, 0.0014, 0.0614,
        0.5399, 0.0063, 0.0087, 0.0954], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:19,783][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0033, 0.0714, 0.0118, 0.1928, 0.2141, 0.0070, 0.0169, 0.2493, 0.0083,
        0.0601, 0.1209, 0.0250, 0.0191], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:19,785][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.3658, 0.0995, 0.0741, 0.0485, 0.0738, 0.0428, 0.1059, 0.0298, 0.0419,
        0.0384, 0.0249, 0.0466, 0.0080], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:19,788][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0167, 0.1771, 0.0991, 0.0456, 0.0674, 0.0251, 0.1062, 0.0328, 0.1288,
        0.0390, 0.0960, 0.0888, 0.0773], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:19,792][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0053, 0.1078, 0.0637, 0.1059, 0.1079, 0.0553, 0.0538, 0.1130, 0.0536,
        0.0922, 0.0967, 0.0501, 0.0947], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:19,795][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([1.3450e-02, 7.0168e-04, 5.1343e-02, 2.0836e-04, 1.5446e-03, 2.2215e-02,
        1.2882e-03, 1.6217e-02, 3.5570e-02, 9.0959e-05, 1.6691e-04, 6.6717e-04,
        8.5654e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:19,799][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0714, 0.0714, 0.0716, 0.0715, 0.0714, 0.0715, 0.0715, 0.0715, 0.0714,
        0.0714, 0.0714, 0.0713, 0.0713, 0.0714], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:19,803][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0714, 0.0714, 0.0716, 0.0715, 0.0714, 0.0715, 0.0715, 0.0715, 0.0714,
        0.0714, 0.0714, 0.0713, 0.0712, 0.0714], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:19,805][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0978, 0.0619, 0.0619, 0.0697, 0.0688, 0.0661, 0.0604, 0.0761, 0.0762,
        0.0760, 0.0805, 0.0665, 0.0716, 0.0666], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:19,806][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.2388, 0.0616, 0.0570, 0.0675, 0.0582, 0.0521, 0.0424, 0.0714, 0.0583,
        0.0756, 0.0567, 0.0455, 0.0626, 0.0522], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:19,807][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0362, 0.0166, 0.0537, 0.0378, 0.0486, 0.1082, 0.0844, 0.0478, 0.1420,
        0.0420, 0.0779, 0.0964, 0.0486, 0.1598], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:19,808][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([9.9333e-01, 5.7526e-03, 4.7437e-04, 3.9948e-05, 4.7827e-05, 4.2153e-05,
        1.1670e-05, 2.3748e-04, 6.2405e-06, 2.0340e-05, 8.7308e-06, 7.0204e-07,
        2.1158e-05, 2.8832e-06], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:19,810][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1301, 0.0249, 0.2074, 0.0104, 0.0350, 0.0388, 0.1122, 0.0045, 0.2162,
        0.0787, 0.0287, 0.0412, 0.0573, 0.0147], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:19,814][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0161, 0.0783, 0.0261, 0.0942, 0.1512, 0.0187, 0.0242, 0.1152, 0.0415,
        0.0718, 0.1265, 0.0295, 0.1871, 0.0196], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:19,817][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.3641, 0.1250, 0.0838, 0.0554, 0.0795, 0.0458, 0.0791, 0.0319, 0.0331,
        0.0363, 0.0218, 0.0276, 0.0073, 0.0095], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:19,821][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0274, 0.2401, 0.0943, 0.0438, 0.0642, 0.0229, 0.0970, 0.0264, 0.0990,
        0.0356, 0.0814, 0.0831, 0.0515, 0.0334], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:19,825][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0054, 0.1000, 0.0557, 0.1019, 0.1064, 0.0524, 0.0524, 0.1117, 0.0488,
        0.0867, 0.0946, 0.0485, 0.0895, 0.0460], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:19,828][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([3.9074e-02, 2.9052e-04, 1.5944e-01, 1.8659e-04, 4.9253e-04, 3.9228e-01,
        6.4733e-04, 1.7144e-03, 1.7168e-02, 3.8226e-05, 3.2792e-04, 1.3290e-03,
        1.2157e-03, 3.8579e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:19,846][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:19,847][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:19,847][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:19,848][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:19,849][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:19,849][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:19,850][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:19,851][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:19,851][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:19,852][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:19,853][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:19,853][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:19,854][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:19,855][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.0424, 0.9576], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:19,855][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.1917, 0.8083], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:19,858][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.7055, 0.2945], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:19,861][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.6501, 0.3499], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:19,861][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.9083, 0.0917], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:19,862][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.8709, 0.1291], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:19,863][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.1162, 0.8838], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:19,863][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0771, 0.9229], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:19,864][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.7242, 0.2758], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:19,865][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([4.2482e-04, 9.9958e-01], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:19,865][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.3233, 0.6767], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:19,866][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.6615, 0.3385], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:19,869][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0256, 0.8357, 0.1387], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,875][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0939, 0.5050, 0.4011], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,879][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.5009, 0.2259, 0.2733], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,880][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.4720, 0.2584, 0.2696], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,881][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.7831, 0.1071, 0.1099], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,881][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([2.0504e-04, 3.7400e-05, 9.9976e-01], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,882][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0697, 0.8118, 0.1185], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,886][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2188, 0.5974, 0.1838], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,891][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1930, 0.0687, 0.7383], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,894][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([1.1118e-05, 1.0573e-01, 8.9425e-01], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,900][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2004, 0.4453, 0.3543], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,902][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1296, 0.0036, 0.8668], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:19,902][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Mary] are: tensor([0.0052, 0.4041, 0.0441, 0.5466], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,903][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Mary] are: tensor([0.0396, 0.2670, 0.2919, 0.4015], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,904][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Mary] are: tensor([0.3879, 0.1892, 0.2254, 0.1975], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,906][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Mary] are: tensor([0.3997, 0.2011, 0.2238, 0.1754], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,910][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Mary] are: tensor([0.6491, 0.1020, 0.1219, 0.1270], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,916][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Mary] are: tensor([0.0007, 0.0158, 0.6689, 0.3147], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,920][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Mary] are: tensor([0.0992, 0.0130, 0.7210, 0.1668], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,924][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Mary] are: tensor([0.0523, 0.7717, 0.0807, 0.0952], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,925][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Mary] are: tensor([0.1838, 0.1174, 0.6726, 0.0262], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,926][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Mary] are: tensor([1.0618e-05, 7.2875e-02, 9.1149e-01, 1.5628e-02], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,926][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Mary] are: tensor([0.1420, 0.3027, 0.2421, 0.3132], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,927][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Mary] are: tensor([0.1189, 0.0034, 0.8395, 0.0382], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:19,930][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.0124, 0.1126, 0.0449, 0.3505, 0.4796], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,936][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0375, 0.1972, 0.2044, 0.3440, 0.2168], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,941][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.3315, 0.1521, 0.1805, 0.1677, 0.1682], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,946][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.3145, 0.1556, 0.1677, 0.1622, 0.2000], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,947][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.5408, 0.0894, 0.1036, 0.1351, 0.1312], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,948][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([6.4709e-03, 1.6678e-04, 9.0010e-03, 2.6788e-04, 9.8409e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,949][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([1.4231e-01, 3.8411e-04, 8.3728e-01, 4.9754e-03, 1.5052e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,949][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0228, 0.2275, 0.0576, 0.4783, 0.2138], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,953][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.2218, 0.1267, 0.6239, 0.0236, 0.0040], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,956][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([2.4584e-05, 1.1003e-01, 8.3863e-01, 4.5898e-02, 5.4207e-03],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,961][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.1059, 0.2310, 0.1847, 0.2422, 0.2362], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,967][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.1109, 0.0021, 0.8107, 0.0015, 0.0749], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:19,969][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0045, 0.0332, 0.0166, 0.0843, 0.8432, 0.0182], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,970][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0291, 0.1458, 0.1608, 0.2733, 0.1995, 0.1914], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,970][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2709, 0.1303, 0.1462, 0.1515, 0.1462, 0.1550], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,971][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2637, 0.1316, 0.1302, 0.1436, 0.1781, 0.1529], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,975][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.4403, 0.0808, 0.0875, 0.1209, 0.1185, 0.1521], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,979][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0101, 0.0052, 0.3146, 0.0028, 0.1002, 0.5670], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,983][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([6.2443e-04, 6.3808e-04, 1.0487e-02, 1.0230e-05, 9.7839e-01, 9.8489e-03],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,987][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0638, 0.1739, 0.0641, 0.2567, 0.4127, 0.0287], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,991][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2995, 0.0981, 0.3339, 0.0269, 0.0011, 0.2404], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,992][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([9.6001e-06, 1.1357e-01, 8.1518e-01, 1.9921e-02, 6.1339e-03, 4.5186e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,993][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0877, 0.1935, 0.1554, 0.2070, 0.2017, 0.1547], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,993][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0603, 0.0010, 0.2685, 0.0007, 0.0020, 0.6676], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:19,995][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0098, 0.1182, 0.0421, 0.2325, 0.3439, 0.1394, 0.1142],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,001][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0275, 0.0961, 0.1252, 0.1732, 0.1947, 0.2135, 0.1698],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,006][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.2313, 0.1164, 0.1327, 0.1277, 0.1307, 0.1314, 0.1298],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,011][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.2277, 0.1183, 0.1201, 0.1294, 0.1465, 0.1184, 0.1397],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,014][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.3877, 0.0692, 0.0790, 0.1009, 0.1047, 0.1272, 0.1312],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,014][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([3.0719e-03, 9.5429e-03, 3.8814e-01, 5.1762e-01, 3.9507e-02, 2.5673e-05,
        4.2094e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,015][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0044, 0.0096, 0.4211, 0.1984, 0.1643, 0.2017, 0.0005],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,016][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0272, 0.2427, 0.0163, 0.2158, 0.4443, 0.0061, 0.0476],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,017][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([3.0639e-02, 7.1609e-03, 7.4620e-02, 2.5660e-03, 1.2833e-04, 1.7484e-02,
        8.6740e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,020][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([5.9373e-06, 6.9378e-02, 5.9179e-01, 1.6208e-02, 3.9581e-03, 4.0642e-02,
        2.7802e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,026][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0766, 0.1682, 0.1350, 0.1789, 0.1744, 0.1334, 0.1335],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,030][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0588, 0.0026, 0.4329, 0.0022, 0.0031, 0.2240, 0.2765],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,036][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.0015, 0.1553, 0.0220, 0.1147, 0.4225, 0.0561, 0.1195, 0.1085],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,037][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([0.0136, 0.0842, 0.0860, 0.1360, 0.1877, 0.1555, 0.2254, 0.1117],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,038][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([0.2194, 0.1037, 0.1182, 0.1110, 0.1101, 0.1158, 0.1021, 0.1197],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,039][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.2169, 0.0970, 0.1164, 0.1063, 0.1242, 0.1173, 0.1050, 0.1169],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,042][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.3426, 0.0683, 0.0718, 0.0974, 0.0911, 0.1059, 0.0994, 0.1235],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,045][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([3.6201e-07, 1.1280e-06, 4.8689e-06, 2.0898e-05, 3.3902e-05, 4.5871e-07,
        2.3166e-05, 9.9992e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,048][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([1.9865e-03, 1.7854e-05, 4.2634e-02, 8.5815e-05, 1.0635e-02, 7.9717e-02,
        4.1571e-03, 8.6077e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,053][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.0126, 0.3237, 0.0173, 0.2513, 0.3267, 0.0121, 0.0395, 0.0168],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,057][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([3.0823e-02, 2.0165e-02, 5.6572e-02, 9.9105e-03, 6.3232e-04, 2.2298e-02,
        8.5752e-01, 2.0821e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,059][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([6.3068e-05, 8.9138e-02, 5.0306e-01, 7.2152e-02, 7.2725e-03, 7.7408e-02,
        2.5046e-01, 4.5167e-04], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,060][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.0663, 0.1453, 0.1167, 0.1520, 0.1484, 0.1147, 0.1150, 0.1416],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,060][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.0846, 0.0019, 0.4776, 0.0015, 0.0024, 0.3826, 0.0235, 0.0259],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,061][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0099, 0.1132, 0.0295, 0.1796, 0.2133, 0.0734, 0.1220, 0.1997, 0.0594],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,065][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0158, 0.0723, 0.0812, 0.1450, 0.1330, 0.1286, 0.1402, 0.1306, 0.1534],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,069][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1812, 0.0888, 0.0995, 0.0994, 0.1021, 0.1005, 0.0937, 0.1107, 0.1241],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,075][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1924, 0.0866, 0.0969, 0.0948, 0.1160, 0.1002, 0.0920, 0.1113, 0.1099],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,080][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2934, 0.0555, 0.0604, 0.0815, 0.0846, 0.0921, 0.0884, 0.1262, 0.1179],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,082][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([8.7042e-04, 6.1570e-04, 4.7446e-01, 2.2656e-01, 5.0666e-02, 1.5284e-06,
        4.2777e-02, 2.0188e-01, 2.1790e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,082][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([2.0088e-04, 2.2181e-04, 1.9479e-03, 1.3167e-03, 1.1327e-02, 2.6826e-03,
        5.1708e-05, 9.7924e-01, 3.0133e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,083][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0293, 0.2428, 0.0434, 0.2072, 0.2088, 0.0196, 0.0510, 0.1729, 0.0251],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,084][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([2.1231e-02, 1.2357e-02, 3.8118e-02, 4.4848e-03, 1.2274e-04, 1.4097e-02,
        7.2693e-01, 1.2249e-03, 1.8144e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,086][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([3.4578e-06, 6.2888e-02, 4.3844e-01, 1.0314e-02, 3.9117e-03, 3.6032e-02,
        2.1071e-01, 1.7090e-04, 2.3753e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,092][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0574, 0.1284, 0.1036, 0.1378, 0.1345, 0.1026, 0.1030, 0.1297, 0.1030],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,096][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0553, 0.0019, 0.1886, 0.0020, 0.0024, 0.1367, 0.0379, 0.0043, 0.5708],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,102][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.0014, 0.0555, 0.0131, 0.4268, 0.1742, 0.0281, 0.0839, 0.0756, 0.0710,
        0.0703], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:20,104][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.0083, 0.0462, 0.0595, 0.1088, 0.1164, 0.1249, 0.1634, 0.1415, 0.1666,
        0.0644], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:20,105][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.1634, 0.0810, 0.0959, 0.0876, 0.0911, 0.0909, 0.0833, 0.0986, 0.1136,
        0.0947], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:20,106][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.1822, 0.0734, 0.0952, 0.0775, 0.1043, 0.0953, 0.0889, 0.0934, 0.1115,
        0.0783], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:20,107][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.2625, 0.0552, 0.0648, 0.0647, 0.0780, 0.0903, 0.0899, 0.0941, 0.1127,
        0.0877], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:20,108][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([3.2014e-02, 5.2238e-03, 5.2965e-01, 2.1425e-01, 2.9922e-02, 7.1693e-05,
        8.8340e-02, 7.6010e-02, 1.1756e-02, 1.2759e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:20,112][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([8.4168e-06, 2.7776e-03, 2.7938e-02, 8.8106e-02, 9.9733e-05, 6.0649e-02,
        5.7762e-04, 7.4689e-01, 5.8297e-02, 1.4652e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:20,117][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0052, 0.1506, 0.0332, 0.2308, 0.0970, 0.0103, 0.0332, 0.3261, 0.0198,
        0.0938], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:20,120][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([1.3834e-02, 5.5313e-03, 4.4990e-02, 2.9255e-03, 3.8997e-04, 3.5188e-02,
        7.3237e-01, 4.6969e-03, 1.4767e-01, 1.2406e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:20,123][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([1.1309e-05, 6.2412e-02, 4.6040e-01, 2.5645e-02, 3.6239e-03, 5.8276e-02,
        8.9905e-02, 4.7839e-05, 2.9935e-01, 3.2196e-04], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:20,127][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.0529, 0.1143, 0.0916, 0.1201, 0.1168, 0.0897, 0.0902, 0.1121, 0.0898,
        0.1227], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:20,128][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([2.3807e-02, 4.5075e-03, 1.5487e-01, 3.2659e-04, 3.2049e-04, 8.5104e-02,
        5.5132e-03, 5.4976e-04, 7.2273e-01, 2.2656e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:20,128][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0026, 0.0638, 0.0202, 0.0867, 0.3305, 0.0546, 0.0713, 0.1020, 0.0700,
        0.0824, 0.1159], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:20,129][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0087, 0.0633, 0.0544, 0.1138, 0.0756, 0.0953, 0.1433, 0.1179, 0.1520,
        0.0941, 0.0815], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:20,133][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.1497, 0.0722, 0.0841, 0.0795, 0.0809, 0.0835, 0.0737, 0.0896, 0.1043,
        0.0863, 0.0961], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:20,139][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.1670, 0.0654, 0.0804, 0.0723, 0.0946, 0.0896, 0.0744, 0.0907, 0.1020,
        0.0711, 0.0924], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:20,144][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.2362, 0.0471, 0.0550, 0.0642, 0.0673, 0.0840, 0.0724, 0.0841, 0.1057,
        0.0899, 0.0942], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:20,147][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([6.5646e-03, 6.6643e-04, 5.4758e-03, 9.4197e-04, 3.5435e-01, 5.4730e-05,
        4.7631e-03, 3.2714e-01, 4.3952e-04, 2.8435e-03, 2.9676e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:20,149][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([1.5247e-05, 9.9066e-07, 1.6280e-02, 4.6936e-04, 2.7227e-04, 1.3243e-03,
        5.3084e-07, 9.7999e-01, 3.5314e-04, 5.1922e-05, 1.2381e-03],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:20,150][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0051, 0.1161, 0.0171, 0.1012, 0.2310, 0.0052, 0.0108, 0.3961, 0.0055,
        0.0678, 0.0441], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:20,151][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([1.6318e-02, 4.3986e-03, 5.0103e-02, 6.2635e-04, 1.5592e-04, 1.9274e-02,
        7.3360e-01, 8.3195e-04, 1.6540e-01, 9.1969e-03, 9.4605e-05],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:20,152][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([8.7034e-06, 3.6230e-02, 3.4051e-01, 1.7280e-02, 2.7165e-03, 3.8090e-02,
        2.1476e-01, 1.3977e-04, 3.4588e-01, 3.0210e-04, 4.0716e-03],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:20,156][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0458, 0.1025, 0.0824, 0.1093, 0.1063, 0.0816, 0.0820, 0.1027, 0.0819,
        0.1125, 0.0930], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:20,159][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([2.8943e-02, 8.1453e-04, 1.5305e-01, 4.1686e-04, 1.2733e-03, 1.4981e-01,
        6.8749e-03, 1.4421e-03, 6.3699e-01, 5.9479e-04, 1.9796e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:20,165][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0026, 0.0363, 0.0181, 0.1205, 0.2325, 0.0432, 0.0847, 0.0660, 0.0699,
        0.0626, 0.1658, 0.0978], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:20,170][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0115, 0.0415, 0.0493, 0.0913, 0.0809, 0.0966, 0.1174, 0.1036, 0.1326,
        0.0621, 0.1160, 0.0972], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:20,172][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1321, 0.0659, 0.0774, 0.0726, 0.0718, 0.0771, 0.0735, 0.0859, 0.0962,
        0.0814, 0.0864, 0.0798], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:20,173][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1436, 0.0647, 0.0689, 0.0770, 0.0834, 0.0726, 0.0809, 0.0853, 0.0885,
        0.0690, 0.0860, 0.0801], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:20,174][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1958, 0.0379, 0.0477, 0.0522, 0.0554, 0.0776, 0.0782, 0.0947, 0.1003,
        0.0794, 0.0903, 0.0905], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:20,175][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.1064e-03, 1.4846e-04, 1.4533e-01, 2.8243e-02, 2.9222e-02, 1.9917e-05,
        8.4039e-03, 7.5190e-01, 4.2404e-04, 7.0033e-04, 3.0837e-02, 3.6731e-03],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:20,176][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([2.1272e-06, 5.7314e-05, 3.0601e-04, 1.0037e-03, 3.0193e-04, 2.5373e-04,
        2.1798e-06, 9.9665e-01, 1.0106e-04, 7.2073e-04, 5.9525e-04, 4.4004e-06],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:20,182][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0167, 0.1330, 0.0161, 0.1362, 0.2321, 0.0073, 0.0292, 0.1994, 0.0098,
        0.1032, 0.0930, 0.0239], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:20,185][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.3656e-02, 5.7191e-03, 4.1887e-02, 1.5661e-03, 6.8755e-05, 1.0513e-02,
        6.8139e-01, 2.5003e-04, 1.5275e-01, 1.0262e-02, 7.0386e-05, 8.1871e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:20,188][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([3.7880e-06, 6.6583e-02, 3.9519e-01, 1.4012e-02, 6.0008e-03, 2.4866e-02,
        2.6029e-01, 2.3281e-04, 2.1320e-01, 2.1878e-04, 9.4673e-03, 9.9344e-03],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:20,194][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0425, 0.0936, 0.0756, 0.1006, 0.0982, 0.0746, 0.0748, 0.0948, 0.0748,
        0.1036, 0.0853, 0.0816], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:20,195][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0212, 0.0013, 0.1200, 0.0007, 0.0012, 0.1212, 0.0290, 0.0017, 0.5177,
        0.0012, 0.0018, 0.1829], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:20,196][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.0007, 0.0711, 0.0103, 0.0959, 0.1147, 0.0302, 0.0575, 0.1417, 0.0396,
        0.0823, 0.0995, 0.2211, 0.0354], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:20,197][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0072, 0.0360, 0.0502, 0.0705, 0.0702, 0.0895, 0.1049, 0.0833, 0.1410,
        0.0540, 0.0967, 0.1580, 0.0386], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:20,200][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.1333, 0.0618, 0.0726, 0.0668, 0.0664, 0.0725, 0.0640, 0.0760, 0.0901,
        0.0739, 0.0830, 0.0692, 0.0704], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:20,205][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.1476, 0.0568, 0.0706, 0.0679, 0.0818, 0.0733, 0.0678, 0.0763, 0.0897,
        0.0598, 0.0814, 0.0670, 0.0600], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:20,211][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.1916, 0.0377, 0.0517, 0.0503, 0.0509, 0.0759, 0.0663, 0.0725, 0.0986,
        0.0727, 0.0760, 0.0796, 0.0761], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:20,215][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([5.9335e-06, 5.3856e-06, 5.9091e-04, 1.0523e-04, 5.3158e-04, 1.3072e-06,
        2.9958e-03, 6.1669e-02, 6.0401e-05, 1.2076e-05, 1.8883e-04, 1.2678e-04,
        9.3371e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:20,217][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([1.9540e-03, 2.6159e-05, 6.5091e-01, 1.9204e-04, 1.3525e-04, 1.0795e-01,
        4.0965e-03, 9.1746e-04, 6.3881e-02, 2.9120e-04, 3.5119e-04, 1.0186e-03,
        1.6828e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:20,218][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0033, 0.0673, 0.0106, 0.2601, 0.2194, 0.0035, 0.0094, 0.2552, 0.0048,
        0.0483, 0.0989, 0.0109, 0.0085], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:20,219][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([2.2746e-02, 2.0403e-02, 6.4788e-02, 4.8054e-03, 4.0517e-04, 4.5317e-02,
        4.6985e-01, 4.8589e-03, 2.0414e-01, 4.4532e-02, 2.2816e-04, 9.2618e-02,
        2.5311e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:20,220][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([1.5671e-05, 5.7363e-02, 3.0882e-01, 4.7664e-02, 4.3786e-03, 3.3606e-02,
        1.9788e-01, 1.7183e-04, 3.1702e-01, 5.6106e-04, 6.6569e-03, 1.4115e-02,
        1.1750e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:20,223][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0388, 0.0860, 0.0698, 0.0912, 0.0892, 0.0688, 0.0690, 0.0855, 0.0688,
        0.0933, 0.0778, 0.0749, 0.0870], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:20,227][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([1.8289e-02, 2.8499e-04, 1.8191e-01, 1.2514e-04, 4.7777e-04, 1.0384e-01,
        9.0114e-03, 1.2838e-03, 6.7257e-01, 1.9202e-04, 3.1208e-04, 5.0057e-03,
        6.6902e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:20,233][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0022, 0.0168, 0.0090, 0.0416, 0.4121, 0.0079, 0.0395, 0.0622, 0.0341,
        0.0258, 0.2251, 0.0900, 0.0281, 0.0057], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:20,239][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0095, 0.0481, 0.0506, 0.0893, 0.0639, 0.0599, 0.0890, 0.0767, 0.1056,
        0.0653, 0.0821, 0.1263, 0.0635, 0.0702], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:20,240][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1115, 0.0578, 0.0623, 0.0668, 0.0644, 0.0667, 0.0618, 0.0742, 0.0804,
        0.0717, 0.0795, 0.0670, 0.0676, 0.0683], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:20,241][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1273, 0.0566, 0.0579, 0.0658, 0.0804, 0.0687, 0.0626, 0.0779, 0.0757,
        0.0610, 0.0789, 0.0622, 0.0614, 0.0635], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:20,241][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1509, 0.0325, 0.0384, 0.0474, 0.0457, 0.0669, 0.0599, 0.0727, 0.0779,
        0.0679, 0.0788, 0.0730, 0.0777, 0.1103], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:20,243][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.3759e-03, 4.5425e-04, 1.7473e-02, 1.8491e-04, 2.3542e-02, 6.8887e-02,
        4.9467e-04, 6.2025e-01, 4.3007e-06, 6.1333e-03, 7.6537e-03, 6.8867e-05,
        8.9959e-02, 1.6352e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:20,247][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([2.5964e-05, 5.1872e-05, 1.2915e-03, 1.0810e-06, 8.7718e-02, 7.3489e-04,
        1.3788e-06, 4.6410e-01, 1.3797e-04, 1.2677e-03, 1.9405e-01, 2.0431e-05,
        2.4927e-01, 1.3228e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:20,253][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0285, 0.0806, 0.0315, 0.1066, 0.1746, 0.0150, 0.0176, 0.1372, 0.0342,
        0.0635, 0.1558, 0.0171, 0.1233, 0.0146], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:20,257][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.1936e-02, 8.4173e-03, 1.6904e-02, 1.5596e-03, 6.6615e-05, 9.6026e-03,
        6.3955e-01, 6.1625e-04, 1.2934e-01, 1.7019e-02, 6.6609e-05, 1.3672e-01,
        2.3843e-02, 4.3616e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:20,261][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([3.1930e-06, 6.7875e-02, 3.7196e-01, 1.2479e-02, 6.0012e-03, 1.9624e-02,
        2.8482e-01, 1.9025e-04, 1.8927e-01, 1.4163e-04, 1.0672e-02, 9.6563e-03,
        1.8522e-02, 8.7866e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:20,261][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0356, 0.0791, 0.0639, 0.0859, 0.0835, 0.0634, 0.0637, 0.0814, 0.0637,
        0.0891, 0.0729, 0.0698, 0.0831, 0.0649], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:20,262][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.0163e-02, 3.3524e-04, 9.2480e-02, 2.3622e-04, 6.5096e-04, 2.2195e-01,
        1.0021e-02, 8.9622e-04, 3.1416e-01, 3.4494e-04, 8.1918e-04, 1.1845e-02,
        7.4897e-04, 3.2535e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:20,266][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:23:20,268][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 2448],
        [ 7513],
        [ 4188],
        [   10],
        [18078],
        [ 3630],
        [ 4792],
        [10785],
        [ 1340],
        [ 2724],
        [ 4611],
        [ 3941],
        [ 1464],
        [ 6171]], device='cuda:0')
[2024-07-24 10:23:20,271][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[  469],
        [14632],
        [ 8216],
        [    1],
        [32199],
        [ 7621],
        [11602],
        [27328],
        [ 8807],
        [17610],
        [20979],
        [12174],
        [ 9514],
        [14214]], device='cuda:0')
[2024-07-24 10:23:20,273][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[22954],
        [22969],
        [22960],
        [22960],
        [22955],
        [22951],
        [22951],
        [22942],
        [22936],
        [22932],
        [22930],
        [22926],
        [22928],
        [22925]], device='cuda:0')
[2024-07-24 10:23:20,276][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[12772],
        [12792],
        [12763],
        [12762],
        [12750],
        [12750],
        [12753],
        [12754],
        [12753],
        [12754],
        [12751],
        [12749],
        [12750],
        [12752]], device='cuda:0')
[2024-07-24 10:23:20,278][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[11456],
        [15511],
        [17278],
        [20061],
        [19900],
        [20269],
        [20233],
        [19334],
        [19437],
        [19767],
        [19410],
        [19690],
        [19827],
        [19961]], device='cuda:0')
[2024-07-24 10:23:20,281][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[32791],
        [24390],
        [20130],
        [16634],
        [16260],
        [15867],
        [15740],
        [14872],
        [15132],
        [15306],
        [14845],
        [14988],
        [14880],
        [15130]], device='cuda:0')
[2024-07-24 10:23:20,283][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[2526],
        [1573],
        [1548],
        [1155],
        [ 757],
        [1537],
        [3090],
        [2650],
        [1739],
        [1685],
        [1695],
        [2634],
        [2616],
        [4216]], device='cuda:0')
[2024-07-24 10:23:20,286][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[14252],
        [11014],
        [12136],
        [13618],
        [13451],
        [13609],
        [13806],
        [12125],
        [13889],
        [13512],
        [13852],
        [14076],
        [13868],
        [14016]], device='cuda:0')
[2024-07-24 10:23:20,288][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[7571],
        [ 755],
        [4942],
        [  64],
        [ 461],
        [ 954],
        [ 239],
        [ 298],
        [6023],
        [2720],
        [2292],
        [1883],
        [ 429],
        [5034]], device='cuda:0')
[2024-07-24 10:23:20,290][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[46748],
        [ 8779],
        [19667],
        [ 7292],
        [ 1710],
        [ 9433],
        [ 9421],
        [ 6168],
        [ 3204],
        [  994],
        [ 2193],
        [ 5334],
        [ 1909],
        [11090]], device='cuda:0')
[2024-07-24 10:23:20,291][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[2055],
        [3109],
        [3391],
        [3709],
        [4235],
        [4384],
        [3956],
        [4083],
        [4366],
        [4062],
        [4164],
        [4211],
        [4111],
        [4340]], device='cuda:0')
[2024-07-24 10:23:20,292][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[6721],
        [6341],
        [5580],
        [5255],
        [5015],
        [5057],
        [4654],
        [4365],
        [4326],
        [3919],
        [4051],
        [4088],
        [3959],
        [4159]], device='cuda:0')
[2024-07-24 10:23:20,295][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[8524],
        [5770],
        [6295],
        [8095],
        [6986],
        [7498],
        [6528],
        [7541],
        [7008],
        [6466],
        [6310],
        [5681],
        [5564],
        [5830]], device='cuda:0')
[2024-07-24 10:23:20,297][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[10218],
        [21288],
        [11081],
        [33998],
        [38508],
        [19627],
        [37757],
        [35430],
        [14244],
        [26861],
        [32009],
        [32457],
        [18123],
        [26050]], device='cuda:0')
[2024-07-24 10:23:20,300][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 3169],
        [35828],
        [ 3529],
        [  187],
        [33864],
        [ 5336],
        [ 8131],
        [11316],
        [ 4722],
        [31512],
        [ 6917],
        [ 6654],
        [21994],
        [ 4417]], device='cuda:0')
[2024-07-24 10:23:20,303][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 6498],
        [16710],
        [15368],
        [18922],
        [26205],
        [30443],
        [19890],
        [20399],
        [14865],
        [21161],
        [16382],
        [13224],
        [10781],
        [17737]], device='cuda:0')
[2024-07-24 10:23:20,305][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[3946],
        [6608],
        [4768],
        [6777],
        [5763],
        [4913],
        [3297],
        [3259],
        [4289],
        [4209],
        [4174],
        [3329],
        [3093],
        [3386]], device='cuda:0')
[2024-07-24 10:23:20,308][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[7494],
        [7874],
        [7995],
        [7474],
        [7351],
        [7707],
        [7560],
        [7409],
        [7437],
        [7482],
        [7172],
        [7140],
        [7059],
        [7199]], device='cuda:0')
[2024-07-24 10:23:20,310][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[1691],
        [1974],
        [1590],
        [1636],
        [1908],
        [1735],
        [1702],
        [1798],
        [1680],
        [1689],
        [1765],
        [1786],
        [1788],
        [1792]], device='cuda:0')
[2024-07-24 10:23:20,313][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[17774],
        [21035],
        [21665],
        [25225],
        [25262],
        [24872],
        [25381],
        [24301],
        [23793],
        [22906],
        [21825],
        [21605],
        [20813],
        [20088]], device='cuda:0')
[2024-07-24 10:23:20,315][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 4748],
        [ 4406],
        [ 2909],
        [ 1623],
        [14558],
        [ 2033],
        [ 1858],
        [26543],
        [ 4009],
        [ 4744],
        [23168],
        [24308],
        [ 1160],
        [ 9643]], device='cuda:0')
[2024-07-24 10:23:20,316][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[21107],
        [45595],
        [41416],
        [14940],
        [17704],
        [26811],
        [12941],
        [18591],
        [14885],
        [21553],
        [15422],
        [14787],
        [15053],
        [11882]], device='cuda:0')
[2024-07-24 10:23:20,318][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 2354],
        [32826],
        [19803],
        [32200],
        [29950],
        [18986],
        [24016],
        [30462],
        [31073],
        [36146],
        [32495],
        [29382],
        [31038],
        [21738]], device='cuda:0')
[2024-07-24 10:23:20,319][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[17444],
        [ 5974],
        [ 3182],
        [ 2772],
        [ 2941],
        [ 2862],
        [19596],
        [18522],
        [16041],
        [14957],
        [15996],
        [14379],
        [ 7122],
        [12141]], device='cuda:0')
[2024-07-24 10:23:20,322][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 1799],
        [ 4002],
        [23109],
        [23066],
        [22541],
        [22602],
        [15591],
        [13620],
        [17988],
        [20448],
        [17935],
        [15026],
        [16099],
        [13402]], device='cuda:0')
[2024-07-24 10:23:20,324][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[2078],
        [2163],
        [2033],
        [2145],
        [2164],
        [2098],
        [2025],
        [2128],
        [2089],
        [2160],
        [2162],
        [2143],
        [2171],
        [2150]], device='cuda:0')
[2024-07-24 10:23:20,327][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 7460],
        [ 5297],
        [10739],
        [10169],
        [ 9758],
        [ 9172],
        [ 7671],
        [ 9151],
        [10939],
        [11751],
        [11225],
        [ 8864],
        [11542],
        [ 9700]], device='cuda:0')
[2024-07-24 10:23:20,329][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[44313],
        [28015],
        [31111],
        [33974],
        [31964],
        [34139],
        [36376],
        [28162],
        [33795],
        [30355],
        [30780],
        [33012],
        [38282],
        [35833]], device='cuda:0')
[2024-07-24 10:23:20,332][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[15784],
        [ 1311],
        [29188],
        [46428],
        [ 3511],
        [25741],
        [16476],
        [14728],
        [28099],
        [ 2655],
        [13266],
        [20252],
        [16565],
        [29359]], device='cuda:0')
[2024-07-24 10:23:20,334][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[8516],
        [8516],
        [8516],
        [8516],
        [8516],
        [8516],
        [8516],
        [8516],
        [8516],
        [8516],
        [8516],
        [8516],
        [8516],
        [8516]], device='cuda:0')
[2024-07-24 10:23:20,365][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:20,366][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:20,366][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:20,367][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:20,368][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:20,370][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:20,370][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:20,371][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:20,372][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:20,372][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:20,373][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:20,374][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:20,374][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:20,375][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.7771, 0.2229], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:20,376][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.5832, 0.4168], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:20,379][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.5298, 0.4702], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:20,383][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.0843, 0.9157], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:20,384][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.0508, 0.9492], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:20,384][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.5003, 0.4997], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:20,385][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.4115, 0.5885], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:20,386][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.5478, 0.4522], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:20,387][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.8269, 0.1731], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:20,389][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.2532, 0.7468], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:20,392][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.2572, 0.7428], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:20,396][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.4059, 0.5941], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:20,399][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.4607, 0.2967, 0.2426], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:20,403][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.3539, 0.2195, 0.4266], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:20,407][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0453, 0.9505, 0.0042], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:20,408][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0448, 0.5352, 0.4199], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:20,409][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0117, 0.3636, 0.6246], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:20,410][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2295, 0.3724, 0.3981], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:20,410][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0907, 0.2688, 0.6404], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:20,411][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2199, 0.1874, 0.5928], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:20,413][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.4829, 0.1854, 0.3317], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:20,416][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0533, 0.6463, 0.3004], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:20,420][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.5831, 0.2784, 0.1385], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:20,424][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1799, 0.2417, 0.5785], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:20,428][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Mary] are: tensor([0.2859, 0.2368, 0.3340, 0.1433], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:20,431][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Mary] are: tensor([0.2188, 0.2290, 0.2976, 0.2546], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:20,433][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Mary] are: tensor([0.1352, 0.4166, 0.4275, 0.0207], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:20,434][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Mary] are: tensor([0.0286, 0.3269, 0.2519, 0.3926], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:20,434][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Mary] are: tensor([4.4358e-04, 2.1441e-01, 2.6902e-01, 5.1613e-01], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:20,435][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Mary] are: tensor([0.0615, 0.3116, 0.5905, 0.0364], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:20,436][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Mary] are: tensor([0.0800, 0.2665, 0.4721, 0.1814], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:20,438][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Mary] are: tensor([0.1365, 0.1089, 0.3292, 0.4253], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:20,442][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Mary] are: tensor([0.3841, 0.1236, 0.3875, 0.1048], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:20,445][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Mary] are: tensor([0.0231, 0.3554, 0.2145, 0.4070], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:20,449][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Mary] are: tensor([0.1465, 0.5343, 0.1472, 0.1721], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:20,453][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Mary] are: tensor([0.0711, 0.0875, 0.2162, 0.6253], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:20,458][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.2376, 0.1801, 0.3797, 0.1661, 0.0364], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:20,458][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.2153, 0.0980, 0.1948, 0.1920, 0.2998], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:20,459][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ went] are: tensor([3.4158e-01, 8.9933e-02, 5.0608e-01, 6.1929e-02, 4.7828e-04],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:20,460][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0247, 0.2318, 0.1761, 0.3072, 0.2602], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:20,461][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.0010, 0.0147, 0.2194, 0.2840, 0.4809], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:20,463][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0468, 0.1784, 0.5299, 0.1890, 0.0558], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:20,467][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0426, 0.2961, 0.3790, 0.1143, 0.1680], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:20,471][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0571, 0.0333, 0.1198, 0.1561, 0.6337], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:20,475][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.3283, 0.0941, 0.2429, 0.1270, 0.2077], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:20,478][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.0154, 0.1834, 0.1722, 0.4710, 0.1580], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:20,482][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.1746, 0.2572, 0.1518, 0.1843, 0.2321], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:20,484][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0400, 0.0444, 0.1102, 0.3310, 0.4745], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:20,485][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2909, 0.0694, 0.2617, 0.1368, 0.0795, 0.1617], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:20,486][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1513, 0.0908, 0.1822, 0.1368, 0.2006, 0.2383], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:20,487][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.3205e-01, 5.8867e-02, 7.6201e-02, 7.0050e-02, 5.6280e-01, 3.4579e-05],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:20,487][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0191, 0.2198, 0.1582, 0.2832, 0.1873, 0.1324], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:20,489][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([9.4395e-05, 1.5711e-03, 5.6618e-03, 1.6450e-02, 8.0655e-01, 1.6967e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:20,492][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0810, 0.1788, 0.4722, 0.1795, 0.0574, 0.0310], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:20,496][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2852, 0.1258, 0.2865, 0.1023, 0.1260, 0.0742], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:20,500][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0351, 0.0342, 0.0905, 0.1222, 0.4849, 0.2330], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:20,503][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0724, 0.0649, 0.1059, 0.0637, 0.6281, 0.0650], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:20,507][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0171, 0.1915, 0.1149, 0.4429, 0.1992, 0.0344], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:20,509][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.3202, 0.1512, 0.1912, 0.0760, 0.1563, 0.1051], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:20,510][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0277, 0.0273, 0.0648, 0.1943, 0.2748, 0.4111], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:20,511][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1624, 0.0722, 0.2004, 0.1109, 0.0910, 0.3295, 0.0337],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,512][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1102, 0.0727, 0.1394, 0.1128, 0.1458, 0.1581, 0.2610],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,513][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ the] are: tensor([1.1353e-01, 2.8299e-01, 1.1173e-01, 4.2339e-02, 3.9676e-01, 5.2504e-02,
        1.4767e-04], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,516][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0127, 0.1742, 0.1309, 0.2163, 0.1525, 0.1116, 0.2019],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,518][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ the] are: tensor([9.3788e-05, 3.1028e-03, 9.5621e-03, 5.3407e-02, 2.2025e-01, 4.5036e-01,
        2.6323e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,522][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0422, 0.1495, 0.4709, 0.1195, 0.0788, 0.1072, 0.0319],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,526][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1293, 0.0588, 0.4697, 0.1081, 0.1467, 0.0542, 0.0333],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,530][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0316, 0.0255, 0.0621, 0.0832, 0.3264, 0.1506, 0.3207],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,534][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.1222, 0.0736, 0.1513, 0.0924, 0.2626, 0.2320, 0.0659],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,534][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0232, 0.1678, 0.1236, 0.3266, 0.1787, 0.0678, 0.1122],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,535][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.3475, 0.1200, 0.1872, 0.0716, 0.1046, 0.1169, 0.0521],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,536][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0209, 0.0195, 0.0454, 0.1360, 0.1869, 0.2762, 0.3153],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,537][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.2095, 0.0612, 0.1663, 0.1276, 0.0678, 0.2653, 0.0477, 0.0546],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,539][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([0.1033, 0.0590, 0.0912, 0.0932, 0.1935, 0.0626, 0.1683, 0.2288],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,542][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.0656, 0.1978, 0.0627, 0.2989, 0.2612, 0.0152, 0.0975, 0.0012],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,545][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.0106, 0.1369, 0.1040, 0.1737, 0.1162, 0.0834, 0.1753, 0.1998],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,548][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([4.4668e-05, 1.6027e-03, 7.2815e-03, 3.7668e-03, 1.2551e-01, 2.4743e-01,
        3.4316e-01, 2.7122e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,552][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.0582, 0.1223, 0.2619, 0.3013, 0.0645, 0.0837, 0.0874, 0.0207],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,556][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.0806, 0.0873, 0.4301, 0.1172, 0.1607, 0.0672, 0.0270, 0.0300],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,558][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.0299, 0.0264, 0.0620, 0.0802, 0.2995, 0.1315, 0.2633, 0.1073],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,559][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.1888, 0.0297, 0.1130, 0.0276, 0.1936, 0.1861, 0.0956, 0.1656],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,560][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.0060, 0.0870, 0.0641, 0.3225, 0.1366, 0.0283, 0.1192, 0.2362],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,561][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.1419, 0.1922, 0.1068, 0.1017, 0.1724, 0.0815, 0.0582, 0.1452],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,563][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.0169, 0.0150, 0.0351, 0.1048, 0.1415, 0.2089, 0.2365, 0.2414],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,566][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1461, 0.0663, 0.1519, 0.0823, 0.1225, 0.2560, 0.0570, 0.0533, 0.0646],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,570][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0782, 0.0499, 0.0969, 0.0722, 0.1035, 0.1054, 0.2247, 0.1260, 0.1432],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,572][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([5.3813e-02, 4.2850e-01, 5.1182e-02, 3.3197e-02, 3.1159e-01, 1.6072e-02,
        1.5453e-02, 9.0094e-02, 1.0146e-04], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,576][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0110, 0.1094, 0.0823, 0.1425, 0.1083, 0.0857, 0.1569, 0.1831, 0.1209],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,579][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([3.0140e-05, 3.7631e-04, 1.2778e-03, 5.4324e-03, 9.4367e-03, 5.4033e-02,
        1.2357e-01, 2.7802e-01, 5.2783e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,583][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0404, 0.0812, 0.3381, 0.1423, 0.0811, 0.0685, 0.0659, 0.0809, 0.1016],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,583][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1997, 0.0586, 0.3435, 0.0973, 0.1221, 0.0502, 0.0464, 0.0456, 0.0365],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,584][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0188, 0.0233, 0.0488, 0.0692, 0.2717, 0.1186, 0.2723, 0.1095, 0.0679],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,585][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1017, 0.0387, 0.0851, 0.0465, 0.2019, 0.1259, 0.0792, 0.2342, 0.0868],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,587][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0105, 0.0894, 0.0700, 0.1917, 0.1161, 0.0362, 0.1224, 0.3090, 0.0547],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,590][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2433, 0.1467, 0.1423, 0.0958, 0.1106, 0.0632, 0.0454, 0.0963, 0.0564],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,594][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0145, 0.0121, 0.0272, 0.0809, 0.1092, 0.1625, 0.1874, 0.1925, 0.2137],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,598][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.0991, 0.0156, 0.1279, 0.0999, 0.0844, 0.3061, 0.0891, 0.0560, 0.1104,
        0.0116], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:20,601][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.0713, 0.0568, 0.0855, 0.0887, 0.1332, 0.0580, 0.1712, 0.1569, 0.1166,
        0.0616], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:20,605][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.0303, 0.0140, 0.1019, 0.2624, 0.2606, 0.0220, 0.0640, 0.2351, 0.0065,
        0.0032], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:20,607][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.0073, 0.0915, 0.0722, 0.1153, 0.0891, 0.0711, 0.1287, 0.1512, 0.1033,
        0.1701], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:20,608][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([3.1904e-06, 4.2336e-05, 1.4234e-04, 2.1087e-03, 8.0644e-04, 8.0983e-03,
        9.8925e-03, 3.6698e-02, 1.8427e-01, 7.5794e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:20,609][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.0329, 0.0325, 0.2681, 0.1200, 0.1093, 0.0688, 0.0707, 0.1498, 0.1346,
        0.0133], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:20,610][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.3616, 0.0427, 0.1811, 0.1043, 0.1110, 0.0506, 0.0404, 0.0354, 0.0347,
        0.0382], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:20,612][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0204, 0.0242, 0.0513, 0.0707, 0.2614, 0.1153, 0.2500, 0.1010, 0.0632,
        0.0426], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:20,615][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.1011, 0.0228, 0.0919, 0.0388, 0.1197, 0.1360, 0.0918, 0.1997, 0.1246,
        0.0735], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:20,619][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.0039, 0.0222, 0.0685, 0.2351, 0.0993, 0.0280, 0.0971, 0.2891, 0.0607,
        0.0960], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:20,623][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0818, 0.2290, 0.0641, 0.1111, 0.1035, 0.0447, 0.0458, 0.1296, 0.0445,
        0.1459], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:20,627][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.0126, 0.0105, 0.0234, 0.0676, 0.0892, 0.1311, 0.1507, 0.1522, 0.1695,
        0.1933], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:20,630][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0651, 0.0801, 0.0932, 0.0609, 0.1415, 0.2075, 0.0505, 0.1244, 0.0798,
        0.0881, 0.0088], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:20,632][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0606, 0.0450, 0.0846, 0.0759, 0.1398, 0.0549, 0.1319, 0.1216, 0.0861,
        0.0578, 0.1420], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:20,633][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0423, 0.1752, 0.2924, 0.1351, 0.0262, 0.0270, 0.1061, 0.0973, 0.0415,
        0.0534, 0.0034], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:20,633][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0090, 0.0850, 0.0648, 0.1007, 0.0719, 0.0583, 0.1004, 0.1287, 0.0888,
        0.1550, 0.1375], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:20,634][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([6.2557e-06, 3.6703e-05, 2.5119e-04, 2.1975e-04, 7.7258e-04, 8.0976e-03,
        1.0662e-02, 2.3397e-02, 2.2112e-01, 2.7934e-01, 4.5609e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:20,636][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0277, 0.0804, 0.2274, 0.0677, 0.0433, 0.0700, 0.1042, 0.1647, 0.1695,
        0.0335, 0.0115], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:20,639][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.3472, 0.0412, 0.2656, 0.0715, 0.0849, 0.0383, 0.0347, 0.0329, 0.0283,
        0.0212, 0.0341], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:20,643][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0182, 0.0217, 0.0468, 0.0645, 0.2610, 0.1079, 0.2416, 0.0971, 0.0585,
        0.0384, 0.0443], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:20,647][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0960, 0.0377, 0.0810, 0.0350, 0.0815, 0.1610, 0.0823, 0.1178, 0.1253,
        0.0969, 0.0854], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:20,650][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0065, 0.0620, 0.0427, 0.1371, 0.0748, 0.0227, 0.0947, 0.2731, 0.0560,
        0.1976, 0.0329], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:20,654][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0828, 0.1704, 0.0604, 0.1020, 0.1486, 0.0468, 0.0326, 0.0993, 0.0376,
        0.1124, 0.1071], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:20,656][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0112, 0.0090, 0.0196, 0.0559, 0.0741, 0.1100, 0.1259, 0.1281, 0.1451,
        0.1659, 0.1552], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:20,657][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1180, 0.0440, 0.1904, 0.0457, 0.0436, 0.2170, 0.0484, 0.0736, 0.1059,
        0.0500, 0.0410, 0.0223], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:20,658][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0662, 0.0365, 0.0791, 0.0536, 0.0759, 0.0767, 0.1291, 0.1005, 0.0944,
        0.0648, 0.0983, 0.1249], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:20,659][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([9.1638e-02, 8.1644e-02, 2.7590e-01, 1.8159e-02, 2.2378e-01, 2.7872e-02,
        1.6877e-02, 6.7652e-02, 8.9793e-03, 3.6390e-02, 1.5092e-01, 1.8641e-04],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:20,661][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0065, 0.0792, 0.0580, 0.0939, 0.0637, 0.0476, 0.0858, 0.1123, 0.0766,
        0.1390, 0.1191, 0.1182], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:20,663][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([3.1748e-06, 1.1099e-05, 3.9464e-05, 6.1574e-05, 5.4873e-04, 1.5510e-03,
        1.4480e-03, 2.7817e-03, 4.4534e-02, 5.9099e-02, 5.8243e-01, 3.0749e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:20,666][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0253, 0.1015, 0.2097, 0.0966, 0.0620, 0.0763, 0.0577, 0.0952, 0.1482,
        0.0562, 0.0643, 0.0071], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:20,670][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3401, 0.0398, 0.1994, 0.0762, 0.0821, 0.0431, 0.0456, 0.0414, 0.0346,
        0.0291, 0.0443, 0.0243], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:20,674][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0164, 0.0196, 0.0415, 0.0574, 0.2444, 0.0977, 0.2286, 0.0905, 0.0522,
        0.0340, 0.0402, 0.0774], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:20,678][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0548, 0.0280, 0.0581, 0.0282, 0.1077, 0.0742, 0.0380, 0.1569, 0.0647,
        0.0707, 0.2838, 0.0349], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:20,680][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0091, 0.0611, 0.0515, 0.1354, 0.0774, 0.0271, 0.0525, 0.2329, 0.0581,
        0.1655, 0.0844, 0.0450], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:20,681][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1574, 0.1029, 0.0937, 0.0660, 0.0800, 0.0789, 0.0456, 0.0881, 0.0530,
        0.0819, 0.0889, 0.0637], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:20,682][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0103, 0.0078, 0.0166, 0.0473, 0.0618, 0.0916, 0.1052, 0.1079, 0.1207,
        0.1403, 0.1308, 0.1598], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:20,683][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0982, 0.0848, 0.0934, 0.0748, 0.0516, 0.1622, 0.0356, 0.0877, 0.0742,
        0.0890, 0.0680, 0.0351, 0.0454], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:20,685][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0549, 0.0317, 0.0512, 0.0431, 0.1279, 0.0398, 0.1113, 0.0907, 0.0638,
        0.0426, 0.1298, 0.0831, 0.1301], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:20,687][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0241, 0.2403, 0.0180, 0.1003, 0.3109, 0.0140, 0.0077, 0.0353, 0.0031,
        0.0990, 0.1367, 0.0088, 0.0017], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:20,691][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0048, 0.0621, 0.0477, 0.0767, 0.0533, 0.0388, 0.0733, 0.0909, 0.0647,
        0.1132, 0.1041, 0.1113, 0.1592], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:20,694][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([6.3247e-07, 6.1906e-06, 1.3965e-05, 3.3874e-05, 1.7443e-04, 7.8101e-04,
        7.5115e-04, 2.3351e-03, 2.0641e-02, 6.6385e-02, 1.3100e-01, 3.0253e-01,
        4.7534e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:20,698][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0227, 0.0696, 0.1757, 0.1487, 0.0485, 0.0665, 0.0476, 0.0559, 0.1503,
        0.0329, 0.1368, 0.0380, 0.0069], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:20,701][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0723, 0.1145, 0.3054, 0.0898, 0.1300, 0.0575, 0.0396, 0.0421, 0.0424,
        0.0201, 0.0429, 0.0176, 0.0260], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:20,705][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0164, 0.0157, 0.0392, 0.0531, 0.2314, 0.0940, 0.2194, 0.0798, 0.0483,
        0.0295, 0.0353, 0.0702, 0.0679], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:20,706][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.0680, 0.0199, 0.0578, 0.0239, 0.1382, 0.0886, 0.0438, 0.1330, 0.0649,
        0.0545, 0.1781, 0.0669, 0.0623], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:20,706][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0022, 0.0611, 0.0298, 0.1435, 0.0678, 0.0136, 0.0693, 0.2285, 0.0309,
        0.1898, 0.0657, 0.0730, 0.0248], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:20,707][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0750, 0.1357, 0.0629, 0.0662, 0.0962, 0.0462, 0.0330, 0.1001, 0.0437,
        0.0935, 0.0935, 0.0599, 0.0941], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:20,709][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0095, 0.0070, 0.0149, 0.0417, 0.0538, 0.0797, 0.0904, 0.0924, 0.1037,
        0.1200, 0.1117, 0.1363, 0.1388], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:20,713][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1767, 0.0339, 0.1486, 0.0688, 0.0444, 0.0782, 0.0349, 0.0580, 0.0922,
        0.0311, 0.0521, 0.0389, 0.1053, 0.0369], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:20,716][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0469, 0.0266, 0.0554, 0.0402, 0.0589, 0.0767, 0.1174, 0.0776, 0.0813,
        0.0621, 0.0857, 0.1179, 0.0760, 0.0773], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:20,718][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([1.5289e-01, 2.8878e-02, 5.3395e-02, 4.3972e-02, 4.1935e-01, 1.9879e-05,
        4.5774e-02, 9.4048e-03, 3.7778e-03, 1.4422e-02, 1.7214e-01, 4.4272e-02,
        1.1691e-02, 1.1115e-05], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:20,722][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0050, 0.0636, 0.0449, 0.0771, 0.0467, 0.0323, 0.0641, 0.0841, 0.0594,
        0.1104, 0.0880, 0.0927, 0.1462, 0.0856], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:20,725][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([7.9566e-07, 1.1847e-06, 3.8334e-06, 7.8877e-06, 4.4134e-04, 8.7749e-05,
        2.3223e-04, 7.1023e-04, 3.6586e-03, 6.0863e-03, 2.4564e-01, 8.4836e-02,
        1.6291e-01, 4.9539e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:20,729][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0385, 0.0862, 0.2501, 0.0898, 0.0285, 0.0137, 0.0503, 0.0841, 0.1008,
        0.0400, 0.1114, 0.0223, 0.0775, 0.0069], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:20,730][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2183, 0.0450, 0.2121, 0.0829, 0.0918, 0.0487, 0.0533, 0.0482, 0.0428,
        0.0306, 0.0510, 0.0279, 0.0230, 0.0245], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:20,731][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0137, 0.0160, 0.0353, 0.0487, 0.2229, 0.0827, 0.1980, 0.0768, 0.0411,
        0.0268, 0.0319, 0.0612, 0.0623, 0.0827], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:20,731][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0238, 0.0259, 0.0391, 0.0217, 0.2078, 0.0194, 0.0274, 0.1078, 0.0476,
        0.0827, 0.2695, 0.0447, 0.0602, 0.0222], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:20,733][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0056, 0.0636, 0.0354, 0.1351, 0.0581, 0.0096, 0.0644, 0.1798, 0.0383,
        0.1751, 0.0719, 0.0799, 0.0744, 0.0088], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:20,736][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1413, 0.0649, 0.1068, 0.0441, 0.0930, 0.0704, 0.0414, 0.0566, 0.0686,
        0.0484, 0.0862, 0.0509, 0.0589, 0.0684], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:20,740][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0084, 0.0059, 0.0120, 0.0340, 0.0445, 0.0656, 0.0766, 0.0790, 0.0883,
        0.1039, 0.0968, 0.1187, 0.1226, 0.1437], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:20,767][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:20,768][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:20,769][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:20,769][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:20,770][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:20,771][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:20,771][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:20,772][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:20,773][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:20,773][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:20,774][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:20,775][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:20,775][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:20,777][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.5747, 0.4253], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:20,777][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([9.9933e-01, 6.6638e-04], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:20,778][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.0077, 0.9923], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:20,779][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.1648, 0.8352], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:20,779][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.7847, 0.2153], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:20,780][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.1571, 0.8429], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:20,781][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.3941, 0.6059], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:20,781][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.2798, 0.7202], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:20,782][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.8310, 0.1690], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:20,783][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.6495, 0.3505], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:20,786][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.5336, 0.4664], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:20,789][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.0480, 0.9520], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:20,793][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3131, 0.4063, 0.2806], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:20,797][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.9338, 0.0150, 0.0512], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:20,801][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0092, 0.6906, 0.3002], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:20,803][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.4137, 0.5702, 0.0161], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:20,804][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2666, 0.2417, 0.4917], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:20,805][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1315, 0.5621, 0.3063], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:20,805][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2888, 0.4335, 0.2777], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:20,806][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1583, 0.3886, 0.4531], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:20,808][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3578, 0.4071, 0.2351], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:20,812][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.3033, 0.5737, 0.1230], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:20,815][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4117, 0.3869, 0.2015], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:20,819][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0336, 0.6517, 0.3147], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:20,823][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Mary] are: tensor([0.2285, 0.3298, 0.2493, 0.1923], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:20,826][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Mary] are: tensor([0.0852, 0.4348, 0.4498, 0.0302], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:20,828][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Mary] are: tensor([0.0062, 0.4219, 0.2010, 0.3709], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:20,829][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Mary] are: tensor([0.2640, 0.3422, 0.0295, 0.3642], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:20,830][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Mary] are: tensor([0.3321, 0.3813, 0.1707, 0.1159], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:20,830][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Mary] are: tensor([0.0634, 0.2985, 0.1614, 0.4767], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:20,833][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Mary] are: tensor([0.1499, 0.2826, 0.1803, 0.3872], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:20,836][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Mary] are: tensor([0.1069, 0.2658, 0.3114, 0.3159], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:20,839][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Mary] are: tensor([0.1205, 0.0794, 0.7813, 0.0187], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:20,843][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Mary] are: tensor([0.2361, 0.4128, 0.1602, 0.1908], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:20,848][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Mary] are: tensor([0.2952, 0.2414, 0.1161, 0.3473], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:20,852][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Mary] are: tensor([0.0164, 0.3613, 0.2015, 0.4207], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:20,853][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.1897, 0.2564, 0.2378, 0.1978, 0.1183], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:20,854][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0720, 0.3290, 0.4515, 0.0305, 0.1171], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:20,854][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0040, 0.1991, 0.1084, 0.1945, 0.4940], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:20,855][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.1282, 0.2200, 0.0238, 0.3060, 0.3220], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:20,857][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.4606, 0.0127, 0.3445, 0.1477, 0.0345], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:20,861][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.0387, 0.1906, 0.1060, 0.3259, 0.3389], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:20,864][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.1247, 0.1579, 0.1113, 0.2814, 0.3248], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:20,868][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0866, 0.2038, 0.2447, 0.2516, 0.2133], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:20,872][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.4684, 0.1222, 0.2770, 0.1023, 0.0301], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:20,877][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.1338, 0.2905, 0.1238, 0.3815, 0.0705], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:20,877][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.2065, 0.1827, 0.0927, 0.2658, 0.2523], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:20,878][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.0190, 0.2479, 0.1580, 0.2704, 0.3047], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:20,879][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1926, 0.1506, 0.1783, 0.1592, 0.1213, 0.1981], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:20,881][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.6520, 0.0129, 0.0368, 0.0898, 0.1495, 0.0591], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:20,883][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0026, 0.1043, 0.0569, 0.1172, 0.2914, 0.4276], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:20,887][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2395, 0.1579, 0.0148, 0.2210, 0.3034, 0.0635], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:20,892][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0515, 0.1918, 0.2099, 0.1097, 0.3855, 0.0516], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:20,895][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0263, 0.1572, 0.0785, 0.3371, 0.3489, 0.0520], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:20,899][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1273, 0.1556, 0.1235, 0.2344, 0.2615, 0.0976], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:20,901][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0727, 0.1677, 0.2002, 0.2044, 0.1704, 0.1847], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:20,902][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.5710e-04, 1.0211e-03, 3.9854e-04, 9.1614e-05, 9.9833e-01, 2.2392e-07],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:20,903][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1341, 0.2923, 0.1107, 0.3319, 0.0898, 0.0413], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:20,903][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1880, 0.1729, 0.0869, 0.2500, 0.2329, 0.0693], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:20,904][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0166, 0.1933, 0.1111, 0.1775, 0.2188, 0.2827], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:20,906][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1354, 0.1526, 0.1462, 0.1390, 0.1203, 0.2104, 0.0961],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,910][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1064, 0.2313, 0.2221, 0.0491, 0.1096, 0.1238, 0.1578],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,913][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0014, 0.0469, 0.0287, 0.0477, 0.1279, 0.2454, 0.5021],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,917][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.2358, 0.1025, 0.0126, 0.1768, 0.2663, 0.0615, 0.1445],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,921][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1423, 0.2003, 0.1533, 0.3924, 0.0247, 0.0583, 0.0287],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,924][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0266, 0.1539, 0.0775, 0.2871, 0.3066, 0.0568, 0.0914],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,926][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.1051, 0.1418, 0.1086, 0.2059, 0.2621, 0.0843, 0.0923],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,927][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0605, 0.1403, 0.1653, 0.1682, 0.1390, 0.1506, 0.1759],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,928][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([9.3302e-03, 1.2168e-02, 1.5251e-01, 3.9143e-02, 7.2092e-01, 6.5861e-02,
        6.6394e-05], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,929][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1560, 0.2598, 0.1183, 0.2611, 0.0806, 0.0839, 0.0404],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,931][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1754, 0.1586, 0.0812, 0.2271, 0.2117, 0.0654, 0.0805],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,934][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0145, 0.1490, 0.0834, 0.1510, 0.1791, 0.2166, 0.2064],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:20,937][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.1066, 0.1132, 0.1102, 0.1118, 0.0911, 0.1718, 0.0877, 0.2076],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,942][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([0.6901, 0.0068, 0.0162, 0.0752, 0.1178, 0.0307, 0.0557, 0.0074],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,944][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([3.1399e-04, 9.8704e-03, 6.6456e-03, 1.3576e-02, 3.8954e-02, 7.6466e-02,
        1.5890e-01, 6.9527e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,948][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.2006, 0.0543, 0.0128, 0.1402, 0.2746, 0.0641, 0.1461, 0.1074],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,950][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.1648, 0.1178, 0.2547, 0.0453, 0.1877, 0.0667, 0.1540, 0.0090],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,951][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.0241, 0.1075, 0.0589, 0.1925, 0.2005, 0.0417, 0.0816, 0.2932],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,952][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.0751, 0.1081, 0.0706, 0.1577, 0.2402, 0.0600, 0.0683, 0.2200],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,953][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.0508, 0.1198, 0.1416, 0.1446, 0.1194, 0.1290, 0.1506, 0.1442],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,955][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.1497, 0.0109, 0.4005, 0.0006, 0.1911, 0.1686, 0.0754, 0.0031],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,958][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.0892, 0.1813, 0.0841, 0.3438, 0.1021, 0.0551, 0.0638, 0.0804],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,962][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.1472, 0.1311, 0.0674, 0.1887, 0.1751, 0.0513, 0.0643, 0.1749],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,966][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.0133, 0.1040, 0.0793, 0.1192, 0.1345, 0.1888, 0.1697, 0.1911],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:20,969][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0900, 0.1085, 0.1035, 0.0926, 0.0963, 0.1434, 0.0855, 0.1785, 0.1018],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,973][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.6131, 0.0048, 0.0125, 0.0953, 0.1445, 0.0289, 0.0831, 0.0081, 0.0096],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,975][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([2.8084e-04, 7.4699e-03, 4.7640e-03, 8.7052e-03, 2.3959e-02, 4.6186e-02,
        9.2751e-02, 4.2057e-01, 3.9531e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,976][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3392, 0.0600, 0.0084, 0.1231, 0.1875, 0.0396, 0.1043, 0.0790, 0.0590],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,977][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0882, 0.1288, 0.1476, 0.2075, 0.0277, 0.0621, 0.1898, 0.0626, 0.0857],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,978][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0195, 0.0936, 0.0456, 0.1816, 0.2055, 0.0333, 0.0602, 0.3218, 0.0389],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,980][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0743, 0.0997, 0.0724, 0.1391, 0.1736, 0.0597, 0.0699, 0.1891, 0.1221],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,983][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0442, 0.1061, 0.1242, 0.1266, 0.1035, 0.1113, 0.1297, 0.1240, 0.1305],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,986][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([2.2491e-02, 1.9617e-03, 2.2678e-02, 1.5568e-03, 9.1475e-01, 5.9907e-03,
        1.1137e-02, 1.9343e-02, 9.1972e-05], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,989][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0969, 0.1777, 0.0932, 0.2150, 0.0788, 0.0581, 0.0778, 0.1601, 0.0426],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,993][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1385, 0.1264, 0.0652, 0.1771, 0.1633, 0.0521, 0.0630, 0.1586, 0.0558],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:20,997][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0122, 0.0972, 0.0570, 0.1021, 0.1022, 0.1266, 0.1234, 0.1448, 0.2346],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:21,000][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.0855, 0.0665, 0.0889, 0.0922, 0.0800, 0.1378, 0.0903, 0.1686, 0.0993,
        0.0909], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,000][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.7322, 0.0038, 0.0100, 0.0564, 0.1128, 0.0196, 0.0523, 0.0047, 0.0057,
        0.0026], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,001][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([1.6073e-04, 5.0411e-03, 3.0684e-03, 5.8279e-03, 1.6509e-02, 3.1411e-02,
        6.9110e-02, 3.1145e-01, 3.0256e-01, 2.5486e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,002][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.2372, 0.0106, 0.0042, 0.0646, 0.1742, 0.0342, 0.0828, 0.0947, 0.0469,
        0.2505], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,004][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.1574, 0.0602, 0.1636, 0.2535, 0.0208, 0.0891, 0.0897, 0.0195, 0.1189,
        0.0273], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,007][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.0124, 0.0508, 0.0295, 0.0887, 0.1033, 0.0221, 0.0406, 0.1812, 0.0362,
        0.4351], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,011][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.0473, 0.0741, 0.0583, 0.1171, 0.1848, 0.0403, 0.0521, 0.1787, 0.1089,
        0.1384], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,015][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0388, 0.0946, 0.1102, 0.1118, 0.0903, 0.0972, 0.1129, 0.1086, 0.1142,
        0.1214], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,018][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.0733, 0.0080, 0.1714, 0.0661, 0.1171, 0.0922, 0.1769, 0.2433, 0.0414,
        0.0103], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,022][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.0795, 0.0505, 0.1169, 0.2819, 0.0888, 0.0727, 0.0737, 0.1468, 0.0623,
        0.0269], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,024][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.1259, 0.0991, 0.0501, 0.1471, 0.1354, 0.0386, 0.0483, 0.1373, 0.0422,
        0.1760], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,025][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.0060, 0.0484, 0.0356, 0.0588, 0.0626, 0.0851, 0.0845, 0.0845, 0.1860,
        0.3485], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,026][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0560, 0.0968, 0.0769, 0.0664, 0.0887, 0.1242, 0.0689, 0.1684, 0.0856,
        0.1270, 0.0411], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,027][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.6273, 0.0069, 0.0191, 0.0758, 0.1346, 0.0349, 0.0683, 0.0092, 0.0113,
        0.0059, 0.0067], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,028][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([1.0978e-04, 4.0245e-03, 2.2641e-03, 4.5123e-03, 1.3067e-02, 2.4016e-02,
        5.6397e-02, 2.4604e-01, 2.4698e-01, 2.0894e-01, 1.9365e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,031][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.1439, 0.0264, 0.0063, 0.0892, 0.1103, 0.0319, 0.0804, 0.0849, 0.0521,
        0.2662, 0.1085], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,035][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1473, 0.0416, 0.1795, 0.1415, 0.0341, 0.0739, 0.1132, 0.0433, 0.1753,
        0.0453, 0.0050], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,039][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0074, 0.0372, 0.0198, 0.0760, 0.0785, 0.0130, 0.0259, 0.1542, 0.0191,
        0.4613, 0.1076], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,042][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0504, 0.0670, 0.0487, 0.1115, 0.1466, 0.0393, 0.0463, 0.1477, 0.0960,
        0.1251, 0.1213], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,046][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0356, 0.0828, 0.0974, 0.0993, 0.0825, 0.0890, 0.1033, 0.0987, 0.1036,
        0.1088, 0.0991], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,048][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.1484, 0.0646, 0.0736, 0.0154, 0.0103, 0.4683, 0.1051, 0.0080, 0.0844,
        0.0202, 0.0017], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,049][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0772, 0.1764, 0.0566, 0.1785, 0.0576, 0.0419, 0.0706, 0.1731, 0.0462,
        0.1095, 0.0123], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,050][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.1001, 0.0907, 0.0486, 0.1329, 0.1272, 0.0373, 0.0473, 0.1271, 0.0408,
        0.1650, 0.0831], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,051][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0072, 0.0472, 0.0337, 0.0423, 0.0532, 0.0836, 0.0691, 0.0653, 0.1733,
        0.2494, 0.1757], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,053][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0649, 0.0708, 0.0874, 0.0620, 0.0602, 0.1184, 0.0666, 0.1559, 0.0937,
        0.1112, 0.0553, 0.0536], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,055][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.6240, 0.0064, 0.0158, 0.0727, 0.1284, 0.0332, 0.0749, 0.0101, 0.0117,
        0.0059, 0.0073, 0.0096], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,058][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([1.1379e-04, 2.9290e-03, 1.8606e-03, 3.6220e-03, 1.0207e-02, 1.9688e-02,
        4.1369e-02, 1.7321e-01, 1.6760e-01, 1.4447e-01, 1.4646e-01, 2.8846e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,062][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1863, 0.0182, 0.0045, 0.0681, 0.0967, 0.0249, 0.0638, 0.0629, 0.0438,
        0.1910, 0.1038, 0.1361], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,066][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1250, 0.0655, 0.2355, 0.1288, 0.0339, 0.0706, 0.0689, 0.0121, 0.1571,
        0.0592, 0.0141, 0.0293], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,069][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0083, 0.0417, 0.0193, 0.0807, 0.0869, 0.0127, 0.0239, 0.1572, 0.0169,
        0.4219, 0.1038, 0.0268], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,073][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0484, 0.0645, 0.0526, 0.0898, 0.1298, 0.0428, 0.0478, 0.1420, 0.0942,
        0.1151, 0.1222, 0.0507], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,074][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0322, 0.0760, 0.0888, 0.0903, 0.0738, 0.0797, 0.0927, 0.0886, 0.0931,
        0.0986, 0.0889, 0.0974], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,074][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([2.8714e-04, 1.4279e-04, 7.0975e-04, 3.7365e-04, 1.1836e-02, 2.2513e-04,
        1.2457e-04, 1.2719e-02, 1.2194e-04, 4.2655e-04, 9.7303e-01, 3.7198e-06],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,075][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0740, 0.1401, 0.0700, 0.1943, 0.0565, 0.0547, 0.0420, 0.1665, 0.0527,
        0.0826, 0.0456, 0.0209], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,077][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1014, 0.0912, 0.0462, 0.1295, 0.1192, 0.0367, 0.0449, 0.1178, 0.0394,
        0.1561, 0.0783, 0.0393], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,081][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0080, 0.0429, 0.0280, 0.0375, 0.0421, 0.0631, 0.0553, 0.0589, 0.1217,
        0.2076, 0.1489, 0.1860], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,084][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.0505, 0.0810, 0.0618, 0.0587, 0.0563, 0.0916, 0.0524, 0.1407, 0.0711,
        0.1099, 0.0606, 0.0485, 0.1167], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,088][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0346, 0.1656, 0.1549, 0.0084, 0.0267, 0.0706, 0.0405, 0.1191, 0.1485,
        0.0553, 0.0498, 0.1071, 0.0188], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,091][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([1.0748e-04, 3.6836e-03, 1.8576e-03, 3.2072e-03, 8.4236e-03, 1.6121e-02,
        3.7299e-02, 1.7120e-01, 1.6230e-01, 1.3927e-01, 1.3473e-01, 2.6958e-01,
        5.2217e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,095][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.1166, 0.0145, 0.0057, 0.0574, 0.0984, 0.0296, 0.0678, 0.0599, 0.0421,
        0.1672, 0.0964, 0.1227, 0.1217], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,097][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.0436, 0.2048, 0.1073, 0.0734, 0.0400, 0.0600, 0.0720, 0.0313, 0.1014,
        0.1144, 0.0186, 0.0958, 0.0373], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,098][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.0112, 0.0391, 0.0215, 0.0699, 0.0770, 0.0134, 0.0304, 0.1139, 0.0231,
        0.3222, 0.1076, 0.0365, 0.1342], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,099][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0373, 0.0562, 0.0408, 0.0834, 0.1404, 0.0328, 0.0366, 0.1246, 0.0845,
        0.1072, 0.1249, 0.0404, 0.0908], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,099][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0287, 0.0698, 0.0816, 0.0831, 0.0675, 0.0725, 0.0843, 0.0807, 0.0852,
        0.0901, 0.0809, 0.0885, 0.0872], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,101][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.0422, 0.0103, 0.0420, 0.0223, 0.5079, 0.0330, 0.0087, 0.1210, 0.0077,
        0.0144, 0.1782, 0.0058, 0.0066], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,104][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0437, 0.1464, 0.0448, 0.1954, 0.0664, 0.0345, 0.0611, 0.1576, 0.0345,
        0.1094, 0.0414, 0.0400, 0.0249], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,108][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0950, 0.0816, 0.0439, 0.1181, 0.1106, 0.0335, 0.0419, 0.1088, 0.0364,
        0.1366, 0.0714, 0.0365, 0.0856], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,112][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0083, 0.0362, 0.0278, 0.0297, 0.0320, 0.0591, 0.0447, 0.0468, 0.1038,
        0.1624, 0.1160, 0.1523, 0.1806], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,116][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0722, 0.0571, 0.0685, 0.0582, 0.0479, 0.0727, 0.0475, 0.1259, 0.0745,
        0.0854, 0.0483, 0.0506, 0.1280, 0.0631], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,120][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.6013, 0.0052, 0.0118, 0.0656, 0.1066, 0.0234, 0.0594, 0.0067, 0.0072,
        0.0041, 0.0049, 0.0064, 0.0916, 0.0057], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,121][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.4783e-04, 3.1869e-03, 1.8637e-03, 3.3326e-03, 8.2870e-03, 1.5327e-02,
        3.2515e-02, 1.2620e-01, 1.2348e-01, 1.0834e-01, 1.0950e-01, 2.0862e-01,
        5.0903e-02, 2.0829e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,122][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1693, 0.0074, 0.0028, 0.0414, 0.0480, 0.0157, 0.0406, 0.0493, 0.0321,
        0.1463, 0.0744, 0.1052, 0.1257, 0.1418], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,123][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0302, 0.1213, 0.1375, 0.0791, 0.2324, 0.0341, 0.0379, 0.0183, 0.0766,
        0.0969, 0.0635, 0.0365, 0.0165, 0.0194], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,125][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0071, 0.0325, 0.0150, 0.0672, 0.0720, 0.0087, 0.0224, 0.1258, 0.0157,
        0.3588, 0.0936, 0.0264, 0.1440, 0.0105], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,128][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0468, 0.0576, 0.0494, 0.0836, 0.0981, 0.0383, 0.0466, 0.1141, 0.0859,
        0.1109, 0.0995, 0.0511, 0.0869, 0.0315], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,132][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0275, 0.0629, 0.0739, 0.0753, 0.0617, 0.0670, 0.0780, 0.0743, 0.0782,
        0.0825, 0.0749, 0.0821, 0.0802, 0.0814], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,134][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([5.5989e-05, 4.1323e-04, 4.9515e-05, 3.5473e-05, 1.9459e-01, 3.3858e-08,
        3.6157e-05, 2.0836e-04, 2.2712e-05, 4.2026e-04, 8.0412e-01, 1.5916e-05,
        3.1904e-05, 3.1631e-08], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,139][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0588, 0.1638, 0.0539, 0.2075, 0.0417, 0.0196, 0.0531, 0.1182, 0.0365,
        0.0909, 0.0384, 0.0378, 0.0682, 0.0115], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,143][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0924, 0.0804, 0.0400, 0.1153, 0.1053, 0.0320, 0.0397, 0.1031, 0.0352,
        0.1409, 0.0698, 0.0352, 0.0835, 0.0270], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,145][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0071, 0.0301, 0.0188, 0.0229, 0.0300, 0.0376, 0.0363, 0.0383, 0.0774,
        0.1196, 0.0928, 0.1131, 0.1642, 0.2117], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,148][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:23:21,152][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[2619],
        [6537],
        [2743],
        [  32],
        [8979],
        [1328],
        [3012],
        [3907],
        [ 797],
        [1673],
        [ 987],
        [2821],
        [1253],
        [2853]], device='cuda:0')
[2024-07-24 10:23:21,154][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 2126],
        [16663],
        [ 8910],
        [   69],
        [35220],
        [11643],
        [12174],
        [20227],
        [ 6851],
        [13013],
        [16360],
        [ 9817],
        [ 5337],
        [14072]], device='cuda:0')
[2024-07-24 10:23:21,157][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[32653],
        [33848],
        [33622],
        [35373],
        [35628],
        [33516],
        [31532],
        [31488],
        [30572],
        [29837],
        [29435],
        [30121],
        [30409],
        [28849]], device='cuda:0')
[2024-07-24 10:23:21,159][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[26949],
        [13195],
        [13541],
        [ 2148],
        [ 2516],
        [ 4606],
        [ 3743],
        [ 2162],
        [ 3127],
        [ 2299],
        [ 2683],
        [ 4010],
        [ 3920],
        [ 5405]], device='cuda:0')
[2024-07-24 10:23:21,162][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[38607],
        [36991],
        [27246],
        [28516],
        [29397],
        [27712],
        [28673],
        [14249],
        [27482],
        [13691],
        [18117],
        [33499],
        [28248],
        [31716]], device='cuda:0')
[2024-07-24 10:23:21,165][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[11045],
        [ 7678],
        [ 7488],
        [ 7128],
        [ 6824],
        [ 7088],
        [ 7301],
        [ 7234],
        [ 7226],
        [ 7091],
        [ 6942],
        [ 6908],
        [ 6896],
        [ 6950]], device='cuda:0')
[2024-07-24 10:23:21,167][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[19725],
        [21986],
        [22216],
        [20202],
        [15175],
        [15230],
        [24395],
        [27433],
        [25189],
        [25087],
        [12928],
        [ 9235],
        [ 1356],
        [ 9797]], device='cuda:0')
[2024-07-24 10:23:21,170][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[13485],
        [21870],
        [17221],
        [15917],
        [19860],
        [19504],
        [16719],
        [24562],
        [18230],
        [18093],
        [17784],
        [21022],
        [23826],
        [21565]], device='cuda:0')
[2024-07-24 10:23:21,172][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[2105],
        [ 890],
        [1991],
        [2257],
        [2294],
        [2141],
        [2794],
        [3017],
        [3490],
        [3668],
        [3693],
        [4525],
        [4278],
        [5375]], device='cuda:0')
[2024-07-24 10:23:21,174][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[5007],
        [2251],
        [2780],
        [2119],
        [1395],
        [1344],
        [1307],
        [1329],
        [1349],
        [1396],
        [1412],
        [1440],
        [1483],
        [1518]], device='cuda:0')
[2024-07-24 10:23:21,175][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[20396],
        [17351],
        [16149],
        [15954],
        [14848],
        [13653],
        [17402],
        [18566],
        [17372],
        [17868],
        [17921],
        [16214],
        [17266],
        [15138]], device='cuda:0')
[2024-07-24 10:23:21,176][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[22871],
        [16166],
        [20227],
        [10864],
        [ 9227],
        [ 9145],
        [11128],
        [ 7694],
        [10117],
        [ 9341],
        [10327],
        [11643],
        [10038],
        [10424]], device='cuda:0')
[2024-07-24 10:23:21,179][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[41417],
        [41287],
        [43890],
        [43885],
        [41617],
        [42447],
        [41892],
        [42861],
        [43657],
        [44137],
        [41854],
        [41563],
        [41355],
        [40785]], device='cuda:0')
[2024-07-24 10:23:21,182][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[4914],
        [5275],
        [4654],
        [3376],
        [3233],
        [3040],
        [2896],
        [2993],
        [2930],
        [2952],
        [2960],
        [2955],
        [2991],
        [2967]], device='cuda:0')
[2024-07-24 10:23:21,184][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 3070],
        [15165],
        [10840],
        [14226],
        [10508],
        [20633],
        [27375],
        [16935],
        [20402],
        [ 9867],
        [16678],
        [23244],
        [27688],
        [20289]], device='cuda:0')
[2024-07-24 10:23:21,187][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[15945],
        [15511],
        [13527],
        [12979],
        [12933],
        [13742],
        [14487],
        [14367],
        [13642],
        [13905],
        [13859],
        [13907],
        [13763],
        [13756]], device='cuda:0')
[2024-07-24 10:23:21,190][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[1381],
        [1378],
        [1308],
        [5668],
        [4104],
        [1019],
        [1767],
        [1049],
        [ 990],
        [1087],
        [1012],
        [1008],
        [5998],
        [1028]], device='cuda:0')
[2024-07-24 10:23:21,192][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 6202],
        [16012],
        [14651],
        [14575],
        [12144],
        [11756],
        [10365],
        [12654],
        [12640],
        [13415],
        [12413],
        [12126],
        [12371],
        [12657]], device='cuda:0')
[2024-07-24 10:23:21,195][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[2887],
        [7925],
        [3429],
        [2826],
        [4496],
        [4116],
        [3866],
        [3968],
        [3570],
        [3351],
        [3181],
        [2770],
        [3112],
        [2879]], device='cuda:0')
[2024-07-24 10:23:21,197][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[15130],
        [18075],
        [16934],
        [22893],
        [14834],
        [20042],
        [18606],
        [16396],
        [15364],
        [15105],
        [14566],
        [15275],
        [18858],
        [18769]], device='cuda:0')
[2024-07-24 10:23:21,200][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[12210],
        [ 7946],
        [ 7242],
        [ 5507],
        [ 4625],
        [ 4567],
        [ 4358],
        [ 4063],
        [ 3868],
        [ 3751],
        [ 3568],
        [ 3547],
        [ 3743],
        [ 3801]], device='cuda:0')
[2024-07-24 10:23:21,201][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[8824],
        [8438],
        [8036],
        [9742],
        [6690],
        [6445],
        [6893],
        [7543],
        [7323],
        [7290],
        [7157],
        [7239],
        [7355],
        [7508]], device='cuda:0')
[2024-07-24 10:23:21,202][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[17220],
        [16558],
        [16632],
        [16710],
        [16726],
        [16657],
        [16734],
        [16801],
        [16834],
        [16870],
        [16901],
        [16949],
        [16959],
        [16984]], device='cuda:0')
[2024-07-24 10:23:21,204][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[23390],
        [20281],
        [14063],
        [18652],
        [18267],
        [ 1245],
        [ 1886],
        [14137],
        [ 1288],
        [20014],
        [16753],
        [ 8925],
        [ 2905],
        [ 7115]], device='cuda:0')
[2024-07-24 10:23:21,207][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[32608],
        [33077],
        [32422],
        [31210],
        [30207],
        [30369],
        [30468],
        [29672],
        [29646],
        [29027],
        [29878],
        [29460],
        [29395],
        [29427]], device='cuda:0')
[2024-07-24 10:23:21,208][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 5811],
        [10660],
        [11979],
        [15461],
        [16676],
        [16781],
        [16997],
        [17170],
        [17237],
        [17626],
        [17798],
        [17853],
        [17505],
        [17550]], device='cuda:0')
[2024-07-24 10:23:21,209][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[10569],
        [13780],
        [13360],
        [11362],
        [10633],
        [10433],
        [10305],
        [ 9554],
        [11118],
        [ 9597],
        [ 9525],
        [ 9925],
        [ 8080],
        [ 7605]], device='cuda:0')
[2024-07-24 10:23:21,212][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[3479],
        [1731],
        [2896],
        [2833],
        [3164],
        [4269],
        [4662],
        [3571],
        [4889],
        [3417],
        [3726],
        [4194],
        [5017],
        [3971]], device='cuda:0')
[2024-07-24 10:23:21,214][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[21205],
        [14561],
        [17592],
        [23388],
        [27091],
        [ 9872],
        [15237],
        [26521],
        [10374],
        [27579],
        [16648],
        [ 4765],
        [11154],
        [ 4483]], device='cuda:0')
[2024-07-24 10:23:21,217][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[15111],
        [15111],
        [15111],
        [15111],
        [15111],
        [15111],
        [15111],
        [15111],
        [15111],
        [15111],
        [15111],
        [15111],
        [15111],
        [15111]], device='cuda:0')
[2024-07-24 10:23:21,249][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:21,250][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,250][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,251][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,252][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,252][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,253][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,254][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,254][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,255][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,256][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,256][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,257][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,258][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.8638, 0.1362], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,258][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.2704, 0.7296], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,259][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,260][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.7376, 0.2624], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,261][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.9840, 0.0160], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,261][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.5247, 0.4753], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,262][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.5047, 0.4953], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,263][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.5140, 0.4860], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,264][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.3954, 0.6046], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,267][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.7681, 0.2319], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,270][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.2743, 0.7257], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,274][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.8840, 0.1160], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,278][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.7460, 0.0922, 0.1618], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:21,279][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1860, 0.4436, 0.3704], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:21,280][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0109, 0.9878, 0.0012], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:21,281][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.5851, 0.2454, 0.1695], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:21,281][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.9899, 0.0026, 0.0075], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:21,283][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3272, 0.3848, 0.2880], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:21,286][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3846, 0.5666, 0.0488], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:21,289][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3691, 0.3413, 0.2896], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:21,293][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2182, 0.2671, 0.5148], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:21,297][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.5561, 0.2108, 0.2332], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:21,301][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1509, 0.3741, 0.4751], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:21,303][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.7237, 0.1636, 0.1126], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:21,304][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Mary] are: tensor([0.8072, 0.0574, 0.0903, 0.0450], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:21,305][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Mary] are: tensor([0.1270, 0.2452, 0.2487, 0.3791], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:21,305][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Mary] are: tensor([0.0069, 0.9785, 0.0113, 0.0032], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:21,306][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Mary] are: tensor([0.3502, 0.2983, 0.2186, 0.1329], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:21,307][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Mary] are: tensor([9.9609e-01, 8.5677e-04, 2.7931e-03, 2.5882e-04], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:21,310][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Mary] are: tensor([0.2538, 0.2514, 0.2205, 0.2743], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:21,314][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Mary] are: tensor([0.1681, 0.5350, 0.0477, 0.2491], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:21,317][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Mary] are: tensor([0.3057, 0.2886, 0.2509, 0.1548], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:21,321][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Mary] are: tensor([0.1355, 0.1846, 0.3783, 0.3016], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:21,325][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Mary] are: tensor([0.4522, 0.1433, 0.1785, 0.2260], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:21,328][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Mary] are: tensor([0.0946, 0.2764, 0.3673, 0.2617], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:21,328][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Mary] are: tensor([0.7910, 0.0780, 0.0445, 0.0865], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:21,329][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.7996, 0.0395, 0.0925, 0.0209, 0.0474], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:21,330][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0948, 0.1600, 0.1851, 0.2708, 0.2893], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:21,331][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0396, 0.9326, 0.0027, 0.0040, 0.0211], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:21,333][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.5105, 0.1734, 0.1594, 0.1067, 0.0500], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:21,334][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ went] are: tensor([9.7521e-01, 7.4686e-03, 1.4302e-02, 2.0915e-03, 9.2846e-04],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:21,338][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.2058, 0.1802, 0.1930, 0.1903, 0.2306], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:21,341][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.1088, 0.1815, 0.0328, 0.6658, 0.0110], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:21,345][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.2638, 0.2427, 0.2077, 0.1300, 0.1558], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:21,349][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.1084, 0.1380, 0.2720, 0.2157, 0.2658], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:21,352][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.3231, 0.1158, 0.1298, 0.1719, 0.2593], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:21,353][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0741, 0.2159, 0.2907, 0.2074, 0.2119], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:21,354][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.8245, 0.0148, 0.0564, 0.0902, 0.0142], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:21,354][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.6067, 0.0558, 0.1028, 0.0293, 0.0418, 0.1636], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:21,355][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0789, 0.1198, 0.1320, 0.1924, 0.2113, 0.2656], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:21,356][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([4.9333e-01, 4.1864e-01, 2.8215e-04, 1.5336e-03, 4.1580e-02, 4.4639e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:21,359][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.3365, 0.1827, 0.1266, 0.0840, 0.1526, 0.1176], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:21,361][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([9.8702e-01, 2.6148e-03, 4.5604e-03, 6.2723e-04, 4.4248e-04, 4.7306e-03],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:21,365][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1798, 0.1916, 0.1540, 0.1499, 0.1981, 0.1267], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:21,368][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0541, 0.1481, 0.0479, 0.6778, 0.0587, 0.0135], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:21,372][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.2233, 0.2019, 0.1734, 0.1141, 0.1393, 0.1480], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:21,376][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0919, 0.1086, 0.2036, 0.1607, 0.1979, 0.2372], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:21,377][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.2956, 0.0969, 0.1002, 0.1219, 0.1789, 0.2066], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:21,378][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0703, 0.1665, 0.2269, 0.1694, 0.1713, 0.1957], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:21,378][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0656, 0.0407, 0.0921, 0.5846, 0.1646, 0.0524], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:21,379][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.5166, 0.0575, 0.0948, 0.0317, 0.0354, 0.1145, 0.1496],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:21,381][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0566, 0.1033, 0.1083, 0.1690, 0.1859, 0.2186, 0.1582],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:21,384][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0174, 0.2968, 0.0008, 0.0012, 0.0550, 0.5924, 0.0363],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:21,388][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.3308, 0.1297, 0.0959, 0.0865, 0.0930, 0.1356, 0.1286],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:21,390][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ the] are: tensor([9.8356e-01, 2.7676e-03, 6.1451e-03, 7.4340e-04, 4.5097e-04, 5.0029e-03,
        1.3282e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:21,394][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1506, 0.1840, 0.1337, 0.1487, 0.1609, 0.1108, 0.1114],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:21,397][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0898, 0.1400, 0.0505, 0.6326, 0.0513, 0.0238, 0.0121],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:21,401][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1980, 0.1798, 0.1552, 0.0989, 0.1196, 0.1299, 0.1187],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:21,402][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0709, 0.0913, 0.1723, 0.1381, 0.1680, 0.1985, 0.1609],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:21,403][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.2439, 0.0778, 0.0799, 0.1019, 0.1593, 0.1775, 0.1597],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:21,403][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0538, 0.1481, 0.2018, 0.1482, 0.1493, 0.1730, 0.1258],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:21,405][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1733, 0.0339, 0.0927, 0.3991, 0.1055, 0.1456, 0.0499],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:21,408][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.6425, 0.0270, 0.0717, 0.0147, 0.0187, 0.1056, 0.0968, 0.0229],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:21,412][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([0.0476, 0.0808, 0.0865, 0.1301, 0.1490, 0.1907, 0.1341, 0.1813],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:21,416][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.0032, 0.1722, 0.0008, 0.0007, 0.0208, 0.6097, 0.1850, 0.0076],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:21,419][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.2432, 0.1069, 0.1048, 0.0601, 0.0754, 0.1694, 0.1567, 0.0834],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:21,422][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([9.8584e-01, 1.8779e-03, 3.6625e-03, 4.6332e-04, 3.7081e-04, 4.2820e-03,
        9.1426e-04, 2.5917e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:21,426][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.1200, 0.1466, 0.1160, 0.1362, 0.1538, 0.0995, 0.1088, 0.1192],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:21,426][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.2545, 0.1053, 0.1046, 0.3411, 0.0577, 0.0283, 0.0256, 0.0830],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:21,427][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.1950, 0.1724, 0.1457, 0.0853, 0.1040, 0.1188, 0.1087, 0.0701],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:21,428][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.0547, 0.0764, 0.1546, 0.1241, 0.1500, 0.1777, 0.1402, 0.1223],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:21,429][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.1987, 0.0627, 0.0741, 0.1004, 0.1489, 0.1664, 0.1477, 0.1012],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:21,431][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.0493, 0.1265, 0.1695, 0.1250, 0.1266, 0.1456, 0.1084, 0.1492],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:21,434][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.3577, 0.0830, 0.0806, 0.2271, 0.1039, 0.0608, 0.0480, 0.0389],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:21,438][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4212, 0.0458, 0.0857, 0.0276, 0.0319, 0.1066, 0.1175, 0.0257, 0.1381],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:21,442][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0440, 0.0728, 0.0776, 0.1166, 0.1291, 0.1573, 0.1130, 0.1528, 0.1368],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:21,446][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0660, 0.3241, 0.0004, 0.0007, 0.0371, 0.2724, 0.1458, 0.0080, 0.1456],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:21,449][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.2779, 0.0900, 0.0689, 0.0504, 0.0647, 0.0987, 0.1277, 0.0904, 0.1313],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:21,451][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([9.9237e-01, 7.6063e-04, 2.4899e-03, 2.0414e-04, 1.1931e-04, 2.3775e-03,
        3.8679e-04, 9.8263e-04, 3.0894e-04], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:21,452][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1156, 0.1450, 0.1037, 0.1125, 0.1477, 0.0848, 0.1009, 0.1127, 0.0770],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:21,452][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0562, 0.1150, 0.0298, 0.5259, 0.0240, 0.0184, 0.0400, 0.1792, 0.0115],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:21,453][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1686, 0.1512, 0.1306, 0.0820, 0.1002, 0.1108, 0.1014, 0.0695, 0.0857],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:21,455][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0557, 0.0683, 0.1308, 0.1037, 0.1273, 0.1533, 0.1232, 0.1022, 0.1356],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:21,458][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2206, 0.0612, 0.0610, 0.0784, 0.1138, 0.1349, 0.1243, 0.0739, 0.1318],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:21,462][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0435, 0.1094, 0.1486, 0.1094, 0.1109, 0.1262, 0.0931, 0.1300, 0.1289],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:21,466][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0891, 0.0147, 0.0422, 0.0885, 0.0507, 0.0725, 0.0634, 0.5583, 0.0206],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:21,469][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.5973, 0.0551, 0.0577, 0.0159, 0.0132, 0.0669, 0.0745, 0.0110, 0.0941,
        0.0144], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,474][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.0389, 0.0635, 0.0649, 0.0967, 0.1114, 0.1333, 0.1007, 0.1389, 0.1196,
        0.1321], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,476][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([5.7927e-03, 7.3440e-02, 2.6698e-04, 2.3533e-04, 4.6852e-03, 1.2283e-01,
        6.3815e-02, 1.1317e-02, 7.0821e-01, 9.4083e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,476][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.1644, 0.0531, 0.0718, 0.0612, 0.0649, 0.1335, 0.1161, 0.0959, 0.1577,
        0.0814], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,477][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([9.8726e-01, 1.2507e-03, 4.4612e-03, 4.1732e-04, 1.8723e-04, 3.1899e-03,
        5.6554e-04, 1.3727e-03, 5.2030e-04, 7.7277e-04], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,478][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.1073, 0.1010, 0.0981, 0.0928, 0.1366, 0.0939, 0.1023, 0.1000, 0.0842,
        0.0839], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,480][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.1422, 0.1027, 0.0410, 0.3597, 0.0228, 0.0142, 0.0127, 0.0837, 0.0185,
        0.2025], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,483][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.1621, 0.1453, 0.1257, 0.0744, 0.0902, 0.1041, 0.0939, 0.0606, 0.0821,
        0.0617], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,487][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.0430, 0.0581, 0.1199, 0.0947, 0.1180, 0.1398, 0.1094, 0.0963, 0.1230,
        0.0978], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,491][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.1807, 0.0478, 0.0567, 0.0764, 0.1172, 0.1304, 0.1161, 0.0789, 0.1171,
        0.0787], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,494][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0389, 0.0971, 0.1300, 0.0952, 0.0965, 0.1100, 0.0822, 0.1145, 0.1133,
        0.1223], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,498][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.4089, 0.0154, 0.0385, 0.0665, 0.0336, 0.0396, 0.0586, 0.2840, 0.0222,
        0.0328], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,501][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.5096, 0.0277, 0.0709, 0.0174, 0.0212, 0.1042, 0.0860, 0.0165, 0.1126,
        0.0092, 0.0248], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,501][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0314, 0.0509, 0.0559, 0.0830, 0.0939, 0.1180, 0.0864, 0.1146, 0.1049,
        0.1151, 0.1460], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,502][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([3.8681e-02, 2.0801e-01, 1.3241e-04, 7.6505e-04, 4.8298e-03, 1.3256e-01,
        7.1777e-02, 5.3919e-03, 3.1753e-01, 1.1990e-02, 2.0834e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,503][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.2193, 0.0724, 0.0743, 0.0468, 0.0386, 0.1099, 0.0915, 0.0577, 0.1348,
        0.1158, 0.0390], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,504][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([9.8759e-01, 1.2329e-03, 3.7780e-03, 3.3112e-04, 1.6933e-04, 3.2257e-03,
        6.0957e-04, 1.6728e-03, 4.1770e-04, 6.8761e-04, 2.8425e-04],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,507][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0986, 0.1135, 0.0865, 0.0975, 0.1127, 0.0688, 0.0778, 0.0960, 0.0670,
        0.0939, 0.0877], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,512][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0503, 0.1062, 0.0246, 0.2774, 0.0117, 0.0113, 0.0238, 0.1154, 0.0199,
        0.3552, 0.0042], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,516][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.1486, 0.1327, 0.1163, 0.0707, 0.0858, 0.0989, 0.0899, 0.0600, 0.0782,
        0.0598, 0.0590], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,519][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0409, 0.0539, 0.1081, 0.0856, 0.1055, 0.1255, 0.0982, 0.0861, 0.1108,
        0.0888, 0.0966], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,523][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.1660, 0.0521, 0.0547, 0.0711, 0.0988, 0.1165, 0.1034, 0.0668, 0.1071,
        0.0687, 0.0947], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,525][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0333, 0.0864, 0.1160, 0.0845, 0.0862, 0.0989, 0.0731, 0.1024, 0.1012,
        0.1090, 0.1090], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,526][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.2018, 0.0075, 0.0436, 0.0529, 0.0238, 0.0481, 0.0569, 0.4785, 0.0336,
        0.0363, 0.0170], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,527][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.4082, 0.0487, 0.0644, 0.0225, 0.0232, 0.0847, 0.0969, 0.0194, 0.1041,
        0.0189, 0.0163, 0.0927], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,528][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0295, 0.0452, 0.0496, 0.0717, 0.0811, 0.1019, 0.0750, 0.1002, 0.0912,
        0.1004, 0.1280, 0.1262], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,529][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([9.3208e-02, 5.3249e-02, 3.1514e-05, 1.4352e-04, 4.2017e-03, 2.8630e-02,
        1.0513e-02, 1.8423e-03, 5.8947e-02, 1.3863e-03, 1.5977e-01, 5.8808e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,532][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1497, 0.0628, 0.0619, 0.0506, 0.0585, 0.0903, 0.0877, 0.0719, 0.1303,
        0.0986, 0.0716, 0.0662], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,535][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([9.8259e-01, 1.6789e-03, 4.9180e-03, 4.6727e-04, 2.7074e-04, 3.9968e-03,
        9.7614e-04, 2.5140e-03, 6.2828e-04, 9.1321e-04, 5.1235e-04, 5.2943e-04],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,539][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0878, 0.1061, 0.0788, 0.0800, 0.0996, 0.0666, 0.0733, 0.0859, 0.0676,
        0.0945, 0.0796, 0.0800], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,543][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0696, 0.0832, 0.0470, 0.3044, 0.0310, 0.0179, 0.0118, 0.1214, 0.0235,
        0.2582, 0.0237, 0.0083], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,546][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1378, 0.1229, 0.1065, 0.0678, 0.0822, 0.0889, 0.0827, 0.0578, 0.0700,
        0.0560, 0.0551, 0.0722], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,550][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0402, 0.0510, 0.0976, 0.0780, 0.0957, 0.1133, 0.0909, 0.0775, 0.1007,
        0.0807, 0.0884, 0.0859], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,551][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1526, 0.0490, 0.0480, 0.0615, 0.0893, 0.1054, 0.0963, 0.0563, 0.1023,
        0.0594, 0.0945, 0.0854], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,552][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0314, 0.0779, 0.1048, 0.0765, 0.0780, 0.0888, 0.0656, 0.0918, 0.0911,
        0.0981, 0.0977, 0.0982], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,553][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0686, 0.0082, 0.0449, 0.1349, 0.0654, 0.0421, 0.0514, 0.4177, 0.0367,
        0.0535, 0.0679, 0.0088], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,555][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.4806, 0.0300, 0.0665, 0.0131, 0.0184, 0.0777, 0.0938, 0.0129, 0.1048,
        0.0092, 0.0107, 0.0499, 0.0324], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,557][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0241, 0.0355, 0.0417, 0.0575, 0.0651, 0.0856, 0.0636, 0.0840, 0.0793,
        0.0829, 0.1106, 0.1093, 0.1610], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,560][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([1.1187e-02, 6.2718e-03, 3.8710e-06, 9.6837e-06, 4.6836e-04, 5.5204e-03,
        3.0188e-03, 1.3936e-04, 7.8311e-03, 2.2049e-04, 3.8113e-02, 8.5288e-01,
        7.4337e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,564][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.1398, 0.0747, 0.0544, 0.0578, 0.0319, 0.0759, 0.0886, 0.0690, 0.1030,
        0.0997, 0.0609, 0.0916, 0.0526], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,566][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([9.8376e-01, 1.6439e-03, 4.5595e-03, 4.5949e-04, 2.5188e-04, 3.9464e-03,
        8.1722e-04, 2.1592e-03, 5.6940e-04, 8.6591e-04, 4.5176e-04, 4.4934e-04,
        6.7694e-05], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,571][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0705, 0.0917, 0.0678, 0.0782, 0.1040, 0.0617, 0.0760, 0.0877, 0.0609,
        0.0772, 0.0854, 0.0810, 0.0578], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,575][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.1379, 0.1260, 0.0318, 0.1850, 0.0157, 0.0097, 0.0112, 0.1180, 0.0085,
        0.2582, 0.0174, 0.0097, 0.0710], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,576][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.1310, 0.1183, 0.0996, 0.0606, 0.0736, 0.0809, 0.0748, 0.0530, 0.0655,
        0.0532, 0.0524, 0.0685, 0.0685], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,577][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.0337, 0.0447, 0.0913, 0.0715, 0.0877, 0.1058, 0.0836, 0.0703, 0.0938,
        0.0728, 0.0804, 0.0801, 0.0844], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,577][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.1240, 0.0414, 0.0461, 0.0606, 0.0876, 0.1012, 0.0910, 0.0616, 0.0931,
        0.0593, 0.0834, 0.0768, 0.0739], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,580][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0247, 0.0732, 0.0983, 0.0696, 0.0710, 0.0828, 0.0606, 0.0854, 0.0849,
        0.0921, 0.0928, 0.0928, 0.0721], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,582][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.2122, 0.0330, 0.0490, 0.1429, 0.0499, 0.0355, 0.0591, 0.0821, 0.0238,
        0.1703, 0.0743, 0.0296, 0.0384], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,586][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.3599, 0.0329, 0.0610, 0.0170, 0.0234, 0.0945, 0.0858, 0.0179, 0.0979,
        0.0131, 0.0179, 0.0623, 0.0206, 0.0958], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,591][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0237, 0.0385, 0.0391, 0.0546, 0.0611, 0.0763, 0.0575, 0.0790, 0.0693,
        0.0773, 0.0997, 0.0970, 0.1436, 0.0833], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,593][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([6.6044e-02, 7.7621e-03, 1.3589e-06, 1.1220e-05, 3.6574e-04, 4.0306e-04,
        2.0810e-03, 8.1889e-05, 5.0943e-03, 1.2583e-04, 3.4123e-02, 4.6916e-01,
        1.1380e-01, 3.0095e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,597][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1378, 0.0746, 0.0499, 0.0374, 0.0592, 0.0443, 0.0832, 0.0570, 0.0961,
        0.1044, 0.0673, 0.0776, 0.0588, 0.0524], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,600][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([9.8889e-01, 1.1581e-03, 2.7390e-03, 2.6401e-04, 1.8953e-04, 2.5466e-03,
        5.6317e-04, 1.2903e-03, 3.6092e-04, 6.0630e-04, 3.1597e-04, 3.0956e-04,
        6.8291e-05, 6.9380e-04], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,601][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0792, 0.0859, 0.0708, 0.0678, 0.0854, 0.0583, 0.0666, 0.0664, 0.0593,
        0.0754, 0.0767, 0.0770, 0.0683, 0.0630], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,601][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0295, 0.0680, 0.0232, 0.2507, 0.0246, 0.0049, 0.0187, 0.0978, 0.0204,
        0.2562, 0.0089, 0.0151, 0.1737, 0.0082], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,602][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1216, 0.1074, 0.0914, 0.0586, 0.0710, 0.0760, 0.0718, 0.0504, 0.0602,
        0.0487, 0.0480, 0.0625, 0.0673, 0.0651], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,604][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0360, 0.0442, 0.0822, 0.0657, 0.0809, 0.0944, 0.0770, 0.0651, 0.0845,
        0.0682, 0.0753, 0.0733, 0.0785, 0.0747], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,607][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1410, 0.0417, 0.0403, 0.0472, 0.0693, 0.0852, 0.0845, 0.0423, 0.0909,
        0.0462, 0.0810, 0.0777, 0.0563, 0.0963], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,611][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0271, 0.0670, 0.0891, 0.0654, 0.0666, 0.0757, 0.0563, 0.0784, 0.0777,
        0.0839, 0.0838, 0.0841, 0.0669, 0.0780], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,615][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0235, 0.0122, 0.0352, 0.1411, 0.0533, 0.0143, 0.0506, 0.1348, 0.0306,
        0.1256, 0.1095, 0.0321, 0.2212, 0.0161], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,650][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:21,652][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,653][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,654][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,656][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,656][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,657][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,658][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,658][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,659][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,660][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,660][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,661][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,662][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([9.9969e-01, 3.1236e-04], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,663][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.5648, 0.4352], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,663][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,664][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.0970, 0.9030], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,665][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.6884, 0.3116], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,666][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.7256, 0.2744], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,666][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.9745, 0.0255], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,668][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.7761, 0.2239], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,669][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.9740, 0.0260], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,671][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.4996, 0.5004], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,672][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.0539, 0.9461], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,674][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.9776, 0.0224], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,675][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([9.9896e-01, 3.6732e-04, 6.6934e-04], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:21,676][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.3292, 0.2616, 0.4091], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:21,678][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0109, 0.9878, 0.0012], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:21,679][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0207, 0.7293, 0.2500], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:21,681][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3694, 0.2021, 0.4285], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:21,683][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1823, 0.7940, 0.0237], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:21,684][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.8167, 0.0925, 0.0908], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:21,686][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0025, 0.9964, 0.0010], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:21,687][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.5842, 0.4068, 0.0090], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:21,688][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1317, 0.1924, 0.6758], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:21,689][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0368, 0.5884, 0.3748], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:21,690][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.3881, 0.5861, 0.0258], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:21,690][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Mary] are: tensor([9.9884e-01, 2.2433e-04, 4.2207e-04, 5.1175e-04], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:21,691][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Mary] are: tensor([0.2272, 0.1907, 0.3369, 0.2453], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:21,693][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Mary] are: tensor([0.0069, 0.9785, 0.0113, 0.0032], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:21,694][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Mary] are: tensor([0.0194, 0.6277, 0.2305, 0.1224], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:21,696][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Mary] are: tensor([0.2685, 0.1383, 0.2979, 0.2954], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:21,697][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Mary] are: tensor([0.3159, 0.1342, 0.0768, 0.4730], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:21,699][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Mary] are: tensor([0.6732, 0.1429, 0.1551, 0.0287], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:21,700][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Mary] are: tensor([8.4644e-04, 9.9458e-01, 4.1649e-03, 4.1166e-04], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:21,701][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Mary] are: tensor([0.6097, 0.1804, 0.1818, 0.0281], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:21,703][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Mary] are: tensor([0.1029, 0.1241, 0.6278, 0.1453], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:21,705][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Mary] are: tensor([0.0236, 0.5163, 0.2631, 0.1970], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:21,706][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Mary] are: tensor([0.2311, 0.6979, 0.0476, 0.0234], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:21,707][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([9.9858e-01, 1.8956e-04, 3.4787e-04, 4.4817e-04, 4.3491e-04],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:21,709][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.1928, 0.1396, 0.2750, 0.2031, 0.1895], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:21,711][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0396, 0.9326, 0.0027, 0.0040, 0.0211], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:21,712][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.0396, 0.4592, 0.2627, 0.1752, 0.0633], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:21,714][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.2307, 0.0942, 0.2145, 0.2103, 0.2504], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:21,715][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.2291, 0.0603, 0.2547, 0.2242, 0.2317], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:21,717][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.5489, 0.1255, 0.0970, 0.0329, 0.1958], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:21,718][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0074, 0.9527, 0.0026, 0.0043, 0.0330], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:21,720][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.4780, 0.0497, 0.1391, 0.3231, 0.0101], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:21,722][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.1218, 0.0551, 0.4112, 0.1051, 0.3068], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:21,723][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0216, 0.4018, 0.2190, 0.1578, 0.1998], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:21,725][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.7494, 0.1426, 0.0241, 0.0063, 0.0775], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:21,726][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.9705e-01, 2.5732e-04, 4.6534e-04, 6.1786e-04, 6.4699e-04, 9.5850e-04],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:21,728][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1463, 0.1347, 0.2020, 0.1656, 0.1604, 0.1912], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:21,729][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([4.9333e-01, 4.1864e-01, 2.8215e-04, 1.5336e-03, 4.1580e-02, 4.4639e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:21,730][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0087, 0.3786, 0.1304, 0.0946, 0.3260, 0.0617], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:21,732][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1720, 0.0844, 0.1803, 0.1754, 0.2052, 0.1827], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:21,734][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.3193, 0.3074, 0.0737, 0.1013, 0.1719, 0.0263], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:21,735][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.7308, 0.0437, 0.0259, 0.0087, 0.0669, 0.1239], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:21,736][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.4509e-01, 6.9420e-01, 2.1270e-04, 1.0224e-03, 3.1509e-02, 1.2796e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:21,738][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2066, 0.2341, 0.1635, 0.3007, 0.0830, 0.0120], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:21,739][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0458, 0.0961, 0.3152, 0.0616, 0.3311, 0.1501], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:21,741][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0255, 0.2922, 0.1685, 0.1065, 0.1495, 0.2578], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:21,743][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.7091, 0.1452, 0.0039, 0.0024, 0.0504, 0.0890], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:21,744][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([9.9253e-01, 4.0734e-04, 7.9863e-04, 1.0824e-03, 1.1214e-03, 1.6031e-03,
        2.4566e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:21,745][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1133, 0.1031, 0.1598, 0.1274, 0.1265, 0.1558, 0.2142],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:21,745][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0174, 0.2968, 0.0008, 0.0012, 0.0550, 0.5924, 0.0363],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:21,746][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0129, 0.2914, 0.1186, 0.1362, 0.1674, 0.1154, 0.1581],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:21,747][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1397, 0.0697, 0.1484, 0.1507, 0.1843, 0.1577, 0.1495],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:21,748][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1514, 0.4383, 0.0364, 0.2236, 0.0989, 0.0237, 0.0279],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:21,749][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.3823, 0.0530, 0.0278, 0.0105, 0.0869, 0.2265, 0.2129],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:21,750][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([2.2472e-03, 4.8864e-01, 3.9332e-04, 5.7597e-04, 2.2697e-02, 4.7393e-01,
        1.1513e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:21,752][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.3364, 0.1122, 0.0469, 0.1942, 0.1407, 0.1648, 0.0048],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:21,754][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0666, 0.0643, 0.2419, 0.0589, 0.2392, 0.2378, 0.0913],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:21,755][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0126, 0.2766, 0.1415, 0.1038, 0.1526, 0.1912, 0.1218],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:21,757][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2129, 0.2041, 0.0074, 0.0049, 0.0695, 0.4583, 0.0429],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:21,758][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([9.9892e-01, 6.4760e-05, 1.0661e-04, 1.4264e-04, 1.3398e-04, 2.6039e-04,
        3.5888e-04, 8.9209e-06], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:21,760][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([0.1058, 0.0768, 0.1519, 0.1023, 0.1141, 0.1414, 0.2074, 0.1002],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:21,761][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([0.0032, 0.1722, 0.0008, 0.0007, 0.0208, 0.6097, 0.1850, 0.0076],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:21,763][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.0190, 0.2049, 0.1403, 0.0640, 0.1096, 0.1821, 0.2059, 0.0742],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:21,765][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.1305, 0.0581, 0.1319, 0.1373, 0.1672, 0.1380, 0.1305, 0.1065],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:21,766][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.0982, 0.2668, 0.0309, 0.2512, 0.1640, 0.0263, 0.0638, 0.0988],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:21,768][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.1328, 0.0259, 0.0349, 0.0071, 0.0716, 0.2529, 0.4567, 0.0180],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:21,769][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([1.0370e-03, 3.0408e-01, 6.2670e-04, 5.2527e-04, 2.2217e-02, 6.2259e-01,
        4.3298e-02, 5.6281e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:21,771][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.4137, 0.0994, 0.0669, 0.1224, 0.0857, 0.1939, 0.0154, 0.0026],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:21,772][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.0253, 0.0453, 0.1541, 0.0391, 0.2315, 0.1562, 0.1140, 0.2345],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:21,774][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.0177, 0.2222, 0.1271, 0.0908, 0.1154, 0.1623, 0.0898, 0.1747],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:21,776][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.0678, 0.2350, 0.0097, 0.0044, 0.0575, 0.4838, 0.1006, 0.0411],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:21,777][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([9.9536e-01, 2.3482e-04, 4.4112e-04, 5.5271e-04, 5.7604e-04, 8.9239e-04,
        1.2879e-03, 5.5715e-05, 5.9667e-04], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:21,778][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0915, 0.0700, 0.1231, 0.0916, 0.0915, 0.1203, 0.1718, 0.0878, 0.1524],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:21,780][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0660, 0.3241, 0.0004, 0.0007, 0.0371, 0.2724, 0.1458, 0.0080, 0.1456],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:21,782][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0077, 0.1817, 0.0854, 0.0699, 0.1312, 0.0885, 0.2151, 0.1107, 0.1098],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:21,783][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0884, 0.0525, 0.1140, 0.1122, 0.1402, 0.1217, 0.1164, 0.1001, 0.1545],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:21,785][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1216, 0.3478, 0.0293, 0.0826, 0.2197, 0.0107, 0.0840, 0.0968, 0.0074],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:21,787][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.4363, 0.0366, 0.0216, 0.0064, 0.0515, 0.1320, 0.1463, 0.0155, 0.1539],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:21,788][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([1.9861e-02, 3.0549e-01, 1.1840e-04, 4.3837e-04, 1.4970e-02, 1.7783e-01,
        2.3108e-02, 2.2696e-02, 4.3549e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:21,790][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0867, 0.0884, 0.0179, 0.1254, 0.1935, 0.0353, 0.0657, 0.3752, 0.0119],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:21,791][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0450, 0.0369, 0.1625, 0.0355, 0.1055, 0.1177, 0.1013, 0.2673, 0.1283],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:21,793][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0117, 0.1881, 0.1222, 0.0713, 0.0908, 0.1503, 0.0883, 0.1502, 0.1271],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:21,795][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1917, 0.1268, 0.0047, 0.0018, 0.0581, 0.2291, 0.0466, 0.1079, 0.2333],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:21,796][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([9.9869e-01, 8.2566e-05, 1.3147e-04, 1.4565e-04, 1.4022e-04, 2.6775e-04,
        3.6830e-04, 8.7352e-06, 1.4853e-04, 1.1804e-05], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,798][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.0779, 0.0585, 0.1098, 0.0842, 0.0868, 0.1137, 0.1623, 0.0918, 0.1473,
        0.0676], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,799][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([5.7927e-03, 7.3440e-02, 2.6698e-04, 2.3533e-04, 4.6852e-03, 1.2283e-01,
        6.3815e-02, 1.1317e-02, 7.0821e-01, 9.4083e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,800][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.0060, 0.0823, 0.0942, 0.0879, 0.0994, 0.1481, 0.1661, 0.0999, 0.1529,
        0.0631], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,801][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.0791, 0.0453, 0.1026, 0.0999, 0.1262, 0.1084, 0.1030, 0.0883, 0.1376,
        0.1096], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,802][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.1981, 0.0462, 0.0375, 0.0444, 0.2210, 0.0887, 0.1521, 0.1217, 0.0404,
        0.0500], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,803][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.0570, 0.0146, 0.0204, 0.0040, 0.0423, 0.2175, 0.3111, 0.0101, 0.3126,
        0.0102], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,804][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([3.2373e-04, 2.2928e-02, 4.0026e-05, 6.3084e-05, 3.8649e-03, 6.5370e-02,
        1.4054e-02, 9.8606e-03, 8.8143e-01, 2.0615e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,805][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.1137, 0.0020, 0.0197, 0.0940, 0.0215, 0.0210, 0.0046, 0.7035, 0.0155,
        0.0044], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,807][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.0197, 0.0192, 0.1367, 0.0340, 0.0982, 0.1383, 0.0827, 0.2228, 0.1882,
        0.0602], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,809][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.0113, 0.1821, 0.0946, 0.0827, 0.0963, 0.1178, 0.0748, 0.1285, 0.0912,
        0.1206], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,810][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.0463, 0.0607, 0.0029, 0.0023, 0.0422, 0.1826, 0.0751, 0.1196, 0.4514,
        0.0169], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:21,811][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([9.9735e-01, 1.4153e-04, 2.3817e-04, 3.0001e-04, 2.8878e-04, 5.2846e-04,
        7.3964e-04, 2.2602e-05, 3.1220e-04, 2.8341e-05, 5.2581e-05],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,813][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0743, 0.0545, 0.1047, 0.0780, 0.0820, 0.1043, 0.1560, 0.0684, 0.1386,
        0.0610, 0.0782], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,814][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([3.8681e-02, 2.0801e-01, 1.3241e-04, 7.6505e-04, 4.8298e-03, 1.3256e-01,
        7.1777e-02, 5.3919e-03, 3.1753e-01, 1.1990e-02, 2.0834e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,816][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0105, 0.1477, 0.1110, 0.0644, 0.0578, 0.1211, 0.1268, 0.0612, 0.1333,
        0.1373, 0.0288], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,818][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0729, 0.0387, 0.0893, 0.0894, 0.1187, 0.0969, 0.0925, 0.0772, 0.1233,
        0.0971, 0.1041], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,819][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0745, 0.1789, 0.0402, 0.1230, 0.1168, 0.0218, 0.0471, 0.1546, 0.0137,
        0.1699, 0.0593], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,821][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.2121, 0.0308, 0.0151, 0.0057, 0.0323, 0.1172, 0.1501, 0.0110, 0.1706,
        0.0126, 0.2425], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,823][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([4.1591e-03, 6.8673e-02, 3.7135e-05, 1.1616e-04, 2.9863e-03, 5.1184e-02,
        4.7123e-03, 3.1938e-03, 7.6201e-01, 4.2406e-03, 9.8684e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,824][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0593, 0.0164, 0.0310, 0.0406, 0.1133, 0.0481, 0.0123, 0.5397, 0.0729,
        0.0653, 0.0013], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,826][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0247, 0.0310, 0.1196, 0.0276, 0.1042, 0.1549, 0.0887, 0.1266, 0.1701,
        0.0744, 0.0783], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,828][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0105, 0.1416, 0.0870, 0.0579, 0.0890, 0.1213, 0.0668, 0.1212, 0.0955,
        0.0961, 0.1132], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,829][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.2419, 0.0272, 0.0019, 0.0007, 0.0188, 0.1400, 0.0190, 0.0449, 0.3515,
        0.0036, 0.1505], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:21,830][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([9.9663e-01, 1.6588e-04, 3.0151e-04, 3.7369e-04, 3.8510e-04, 6.3689e-04,
        8.9314e-04, 3.0090e-05, 4.0142e-04, 3.8577e-05, 7.0081e-05, 7.7373e-05],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,832][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0634, 0.0550, 0.0922, 0.0705, 0.0711, 0.0911, 0.1211, 0.0777, 0.1199,
        0.0591, 0.0803, 0.0985], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,834][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([9.3208e-02, 5.3249e-02, 3.1514e-05, 1.4352e-04, 4.2017e-03, 2.8630e-02,
        1.0513e-02, 1.8423e-03, 5.8947e-02, 1.3863e-03, 1.5977e-01, 5.8808e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,835][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0067, 0.1069, 0.0774, 0.0750, 0.1188, 0.0825, 0.1158, 0.0827, 0.1221,
        0.1009, 0.0733, 0.0379], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,837][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0725, 0.0353, 0.0811, 0.0820, 0.1036, 0.0875, 0.0828, 0.0678, 0.1105,
        0.0879, 0.0926, 0.0962], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,839][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0584, 0.1983, 0.0197, 0.0504, 0.0850, 0.0143, 0.0597, 0.1130, 0.0242,
        0.3082, 0.0395, 0.0291], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,840][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2796, 0.0281, 0.0114, 0.0046, 0.0281, 0.0727, 0.0620, 0.0109, 0.0935,
        0.0081, 0.1468, 0.2542], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,841][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([2.3664e-02, 5.8562e-02, 8.0083e-06, 5.2591e-05, 2.5844e-03, 1.3770e-02,
        1.5697e-03, 2.3986e-03, 9.0521e-02, 1.5115e-03, 1.9445e-01, 6.1091e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,843][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([4.3837e-02, 3.1896e-02, 2.2546e-02, 8.2411e-02, 5.8837e-02, 5.1165e-02,
        1.7247e-03, 5.2216e-01, 6.2339e-02, 1.1122e-01, 1.1475e-02, 3.9294e-04],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,844][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0320, 0.0286, 0.1301, 0.0268, 0.1178, 0.1119, 0.0468, 0.1421, 0.1004,
        0.0577, 0.1555, 0.0504], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,846][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0082, 0.1401, 0.0758, 0.0527, 0.0772, 0.1010, 0.0592, 0.1119, 0.0769,
        0.0998, 0.0987, 0.0986], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,848][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.4270, 0.0368, 0.0005, 0.0005, 0.0097, 0.0381, 0.0083, 0.0089, 0.0783,
        0.0024, 0.1349, 0.2547], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:21,849][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([9.9614e-01, 1.5643e-04, 3.1760e-04, 3.8199e-04, 3.5939e-04, 7.3254e-04,
        1.0086e-03, 3.3652e-05, 4.5597e-04, 3.8394e-05, 6.6986e-05, 8.0733e-05,
        2.2933e-04], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,851][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0550, 0.0477, 0.0835, 0.0602, 0.0643, 0.0796, 0.1223, 0.0671, 0.1121,
        0.0515, 0.0742, 0.0966, 0.0861], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,852][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([1.1187e-02, 6.2718e-03, 3.8710e-06, 9.6837e-06, 4.6836e-04, 5.5204e-03,
        3.0188e-03, 1.3936e-04, 7.8311e-03, 2.2049e-04, 3.8113e-02, 8.5288e-01,
        7.4337e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,854][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0078, 0.1491, 0.0643, 0.0868, 0.0429, 0.0690, 0.1201, 0.0819, 0.0917,
        0.1126, 0.0610, 0.0744, 0.0383], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,856][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.0674, 0.0365, 0.0737, 0.0746, 0.0921, 0.0807, 0.0756, 0.0673, 0.0974,
        0.0801, 0.0862, 0.0905, 0.0779], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,856][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.0543, 0.1098, 0.0082, 0.0790, 0.2028, 0.0145, 0.0881, 0.1890, 0.0151,
        0.0946, 0.0971, 0.0316, 0.0159], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,857][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0440, 0.0095, 0.0084, 0.0016, 0.0151, 0.0653, 0.0928, 0.0049, 0.1003,
        0.0051, 0.1833, 0.4591, 0.0105], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,858][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([3.5077e-03, 1.8900e-02, 4.3786e-06, 1.1703e-05, 5.7766e-04, 6.0311e-03,
        6.1105e-04, 5.7953e-04, 3.2459e-02, 4.3752e-04, 8.5234e-02, 7.6012e-01,
        9.1529e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,859][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.1892, 0.0496, 0.0320, 0.1567, 0.0152, 0.1287, 0.0105, 0.0799, 0.0540,
        0.1805, 0.0841, 0.0164, 0.0033], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,861][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0144, 0.0245, 0.0910, 0.0264, 0.0896, 0.0851, 0.0596, 0.2151, 0.1054,
        0.0543, 0.0774, 0.0657, 0.0915], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,863][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0078, 0.1137, 0.0774, 0.0504, 0.0675, 0.0976, 0.0564, 0.1089, 0.0754,
        0.0788, 0.0950, 0.0770, 0.0940], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,864][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([2.1226e-01, 3.1460e-02, 3.2715e-04, 4.0772e-04, 4.8546e-03, 2.4564e-02,
        4.8422e-03, 3.0996e-03, 5.2627e-02, 3.4733e-03, 1.1924e-01, 3.8872e-01,
        1.5412e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:21,865][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.9489e-01, 2.1909e-04, 3.9754e-04, 4.9620e-04, 5.2726e-04, 8.0909e-04,
        1.1313e-03, 4.0591e-05, 4.8346e-04, 5.2508e-05, 9.6806e-05, 1.0162e-04,
        2.7534e-04, 4.7680e-04], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,866][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0546, 0.0507, 0.0770, 0.0606, 0.0598, 0.0724, 0.1030, 0.0624, 0.0993,
        0.0530, 0.0679, 0.0856, 0.0780, 0.0758], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,868][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([6.6044e-02, 7.7621e-03, 1.3589e-06, 1.1220e-05, 3.6574e-04, 4.0306e-04,
        2.0810e-03, 8.1889e-05, 5.0943e-03, 1.2583e-04, 3.4123e-02, 4.6916e-01,
        1.1380e-01, 3.0095e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,869][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0029, 0.1557, 0.0551, 0.0458, 0.1423, 0.0231, 0.1241, 0.0621, 0.0751,
        0.1230, 0.0707, 0.0603, 0.0447, 0.0151], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,871][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0608, 0.0311, 0.0681, 0.0687, 0.0859, 0.0744, 0.0704, 0.0590, 0.0916,
        0.0728, 0.0763, 0.0824, 0.0751, 0.0833], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,873][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1570, 0.1191, 0.0315, 0.0441, 0.0737, 0.0107, 0.1117, 0.0314, 0.0351,
        0.1745, 0.0805, 0.0787, 0.0379, 0.0140], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,875][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.3532, 0.0182, 0.0077, 0.0026, 0.0168, 0.0380, 0.0374, 0.0058, 0.0496,
        0.0044, 0.0735, 0.1494, 0.0122, 0.2311], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,876][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([9.3661e-03, 2.6248e-03, 1.8911e-07, 1.6568e-06, 6.2836e-05, 2.0681e-04,
        9.9736e-05, 9.9543e-05, 4.2354e-03, 2.4537e-05, 1.0916e-02, 1.1992e-01,
        2.2762e-01, 6.2482e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,878][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0362, 0.0439, 0.0261, 0.0624, 0.0140, 0.0016, 0.0382, 0.3929, 0.1199,
        0.1207, 0.0144, 0.0047, 0.1225, 0.0025], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,879][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0149, 0.0350, 0.1211, 0.0204, 0.1160, 0.0529, 0.0608, 0.1196, 0.0891,
        0.0620, 0.0987, 0.0721, 0.0732, 0.0645], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,881][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0086, 0.1173, 0.0634, 0.0441, 0.0579, 0.0963, 0.0457, 0.0900, 0.0679,
        0.0805, 0.0866, 0.0714, 0.0661, 0.1043], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,882][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.6742e-01, 1.1077e-02, 1.2892e-04, 8.9506e-05, 2.2383e-03, 4.8726e-03,
        2.9939e-03, 1.9840e-03, 2.3350e-02, 6.3359e-04, 6.1385e-02, 2.1126e-01,
        1.1164e-01, 4.0093e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:21,886][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:23:21,888][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 2763],
        [ 9169],
        [ 5146],
        [  293],
        [12158],
        [ 5129],
        [ 5076],
        [10322],
        [ 2929],
        [ 4749],
        [ 3207],
        [ 5028],
        [ 6399],
        [ 5925]], device='cuda:0')
[2024-07-24 10:23:21,890][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 2595],
        [ 8340],
        [ 3760],
        [  527],
        [12041],
        [ 1956],
        [ 3450],
        [ 4224],
        [ 1536],
        [ 2728],
        [ 1650],
        [ 3336],
        [  956],
        [ 4272]], device='cuda:0')
[2024-07-24 10:23:21,892][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[14444],
        [14308],
        [14101],
        [13278],
        [13597],
        [12960],
        [12664],
        [12987],
        [11725],
        [12431],
        [11990],
        [11276],
        [11740],
        [11282]], device='cuda:0')
[2024-07-24 10:23:21,893][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[38366],
        [43136],
        [42397],
        [37833],
        [35645],
        [38210],
        [38091],
        [39126],
        [38510],
        [39148],
        [39670],
        [39783],
        [38586],
        [38903]], device='cuda:0')
[2024-07-24 10:23:21,895][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[30806],
        [30075],
        [12454],
        [12211],
        [12537],
        [17723],
        [ 6151],
        [ 6884],
        [10071],
        [14976],
        [ 8107],
        [ 6502],
        [ 8139],
        [ 6410]], device='cuda:0')
[2024-07-24 10:23:21,896][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[33051],
        [33185],
        [32510],
        [30891],
        [30720],
        [30100],
        [30556],
        [31580],
        [31502],
        [30873],
        [30752],
        [30108],
        [30652],
        [30449]], device='cuda:0')
[2024-07-24 10:23:21,898][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[33366],
        [34028],
        [34125],
        [33643],
        [35065],
        [34336],
        [34580],
        [34326],
        [33921],
        [34299],
        [34261],
        [34633],
        [34529],
        [34170]], device='cuda:0')
[2024-07-24 10:23:21,900][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[38338],
        [33012],
        [32112],
        [27526],
        [27124],
        [28875],
        [30256],
        [28199],
        [28582],
        [28445],
        [25295],
        [26521],
        [26463],
        [28070]], device='cuda:0')
[2024-07-24 10:23:21,901][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[12304],
        [ 1502],
        [  970],
        [ 1058],
        [ 5208],
        [ 5351],
        [ 5350],
        [ 5497],
        [ 6010],
        [ 2286],
        [ 1155],
        [ 1831],
        [ 1278],
        [ 1652]], device='cuda:0')
[2024-07-24 10:23:21,903][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[42692],
        [42418],
        [42385],
        [42590],
        [42691],
        [42690],
        [42715],
        [42728],
        [42728],
        [42710],
        [42676],
        [42652],
        [42678],
        [42594]], device='cuda:0')
[2024-07-24 10:23:21,904][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[12033],
        [13085],
        [14505],
        [14793],
        [15247],
        [16123],
        [16358],
        [16660],
        [16680],
        [16727],
        [16609],
        [16598],
        [17024],
        [17143]], device='cuda:0')
[2024-07-24 10:23:21,906][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[14212],
        [16831],
        [19837],
        [22213],
        [21926],
        [21391],
        [21577],
        [22437],
        [22045],
        [22914],
        [22647],
        [22244],
        [22815],
        [22426]], device='cuda:0')
[2024-07-24 10:23:21,908][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[28662],
        [24359],
        [21395],
        [20499],
        [20853],
        [20578],
        [20268],
        [19334],
        [18822],
        [18552],
        [18177],
        [17831],
        [17983],
        [17607]], device='cuda:0')
[2024-07-24 10:23:21,909][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[13364],
        [13926],
        [15703],
        [17131],
        [17266],
        [43948],
        [40859],
        [32635],
        [34220],
        [27568],
        [31566],
        [36603],
        [34772],
        [39947]], device='cuda:0')
[2024-07-24 10:23:21,911][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[12090],
        [27368],
        [26443],
        [ 3459],
        [ 4066],
        [27956],
        [18652],
        [28288],
        [16684],
        [24126],
        [20093],
        [25389],
        [21039],
        [18237]], device='cuda:0')
[2024-07-24 10:23:21,912][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[4484],
        [4484],
        [4495],
        [4501],
        [4505],
        [4528],
        [4597],
        [4497],
        [4562],
        [4504],
        [4528],
        [4538],
        [4545],
        [4567]], device='cuda:0')
[2024-07-24 10:23:21,914][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[28436],
        [35388],
        [34594],
        [36210],
        [37921],
        [37076],
        [36453],
        [36920],
        [34713],
        [35701],
        [35862],
        [36179],
        [37216],
        [36989]], device='cuda:0')
[2024-07-24 10:23:21,915][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[25440],
        [25419],
        [14721],
        [14849],
        [15331],
        [23726],
        [26087],
        [27724],
        [24777],
        [17826],
        [22823],
        [18528],
        [17688],
        [23363]], device='cuda:0')
[2024-07-24 10:23:21,917][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[17644],
        [ 5030],
        [ 7067],
        [ 8321],
        [10701],
        [11073],
        [13272],
        [14525],
        [14334],
        [15113],
        [13076],
        [13843],
        [13179],
        [12384]], device='cuda:0')
[2024-07-24 10:23:21,918][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[2373],
        [2773],
        [3538],
        [4202],
        [4704],
        [5390],
        [5860],
        [5987],
        [6060],
        [6151],
        [5907],
        [5789],
        [5653],
        [5749]], device='cuda:0')
[2024-07-24 10:23:21,920][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[20167],
        [16550],
        [14266],
        [ 4774],
        [10551],
        [17756],
        [15143],
        [11411],
        [15571],
        [20521],
        [12068],
        [17388],
        [11143],
        [18864]], device='cuda:0')
[2024-07-24 10:23:21,921][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[27158],
        [27004],
        [20058],
        [11634],
        [ 9200],
        [15196],
        [ 6057],
        [ 4785],
        [ 6738],
        [ 4652],
        [ 4982],
        [ 4940],
        [ 4001],
        [ 4874]], device='cuda:0')
[2024-07-24 10:23:21,923][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[14350],
        [13954],
        [11067],
        [11055],
        [10951],
        [10279],
        [ 5908],
        [ 5995],
        [ 5126],
        [ 6694],
        [ 5419],
        [14867],
        [18461],
        [ 9634]], device='cuda:0')
[2024-07-24 10:23:21,925][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[33529],
        [33660],
        [32657],
        [29790],
        [33799],
        [34830],
        [32679],
        [30422],
        [40605],
        [37341],
        [37757],
        [40712],
        [32133],
        [41853]], device='cuda:0')
[2024-07-24 10:23:21,926][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[26301],
        [26744],
        [17404],
        [17218],
        [18581],
        [20077],
        [19632],
        [17702],
        [16637],
        [16764],
        [18286],
        [19300],
        [17451],
        [18063]], device='cuda:0')
[2024-07-24 10:23:21,928][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[17761],
        [11011],
        [11409],
        [10106],
        [ 9496],
        [10175],
        [10437],
        [10477],
        [10893],
        [10551],
        [11049],
        [10594],
        [ 9468],
        [ 9866]], device='cuda:0')
[2024-07-24 10:23:21,930][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 7101],
        [ 7142],
        [14020],
        [15268],
        [ 7691],
        [ 7622],
        [ 8950],
        [ 9729],
        [ 7151],
        [ 6437],
        [ 5929],
        [ 4021],
        [ 4026],
        [ 3900]], device='cuda:0')
[2024-07-24 10:23:21,931][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[4259],
        [4555],
        [5886],
        [7541],
        [7492],
        [5464],
        [6945],
        [7907],
        [6809],
        [8130],
        [8587],
        [7563],
        [9605],
        [6776]], device='cuda:0')
[2024-07-24 10:23:21,933][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 2885],
        [ 7220],
        [10809],
        [17603],
        [17646],
        [ 7120],
        [ 6486],
        [ 5017],
        [ 8769],
        [ 7451],
        [ 8407],
        [ 3184],
        [ 6053],
        [ 7070]], device='cuda:0')
[2024-07-24 10:23:21,934][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[3743],
        [3743],
        [3743],
        [3743],
        [3743],
        [3743],
        [3743],
        [3743],
        [3743],
        [3743],
        [3743],
        [3743],
        [3743],
        [3743]], device='cuda:0')
[2024-07-24 10:23:21,984][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:21,985][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,986][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,987][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,988][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,988][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,989][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,990][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,990][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,991][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,992][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,992][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,993][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:21,994][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.5324, 0.4676], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,994][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.6161, 0.3839], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,995][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.3900, 0.6100], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,996][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.5852, 0.4148], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,996][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.8265, 0.1735], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,998][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.3209, 0.6791], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,999][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.2511, 0.7489], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:21,999][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.8476, 0.1524], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,000][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.4462, 0.5538], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,001][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.2731, 0.7269], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,001][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.2690, 0.7310], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,002][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([1.0000e+00, 1.4152e-09], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,003][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.4456, 0.3820, 0.1723], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,004][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.4365, 0.5133, 0.0503], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,004][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2457, 0.4185, 0.3358], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,005][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0681, 0.9267, 0.0052], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,006][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.7196, 0.1469, 0.1335], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,007][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2648, 0.3530, 0.3821], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,009][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1429, 0.2520, 0.6050], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,010][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([1.4987e-02, 4.2811e-04, 9.8458e-01], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,011][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.4820, 0.3609, 0.1572], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,013][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1438, 0.4438, 0.4123], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,015][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1335, 0.4279, 0.4386], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,016][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([1.0000e+00, 1.2445e-07, 6.8914e-09], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,017][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Mary] are: tensor([0.0884, 0.4056, 0.3920, 0.1140], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,019][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Mary] are: tensor([0.1732, 0.5189, 0.0817, 0.2262], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,021][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Mary] are: tensor([0.1956, 0.3205, 0.2402, 0.2437], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,022][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Mary] are: tensor([0.1878, 0.4691, 0.0923, 0.2508], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,024][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Mary] are: tensor([0.6407, 0.1253, 0.1135, 0.1205], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,026][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Mary] are: tensor([0.1125, 0.2813, 0.2843, 0.3220], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,027][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Mary] are: tensor([0.0629, 0.1659, 0.4829, 0.2883], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,029][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Mary] are: tensor([0.0308, 0.0102, 0.1095, 0.8495], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,030][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Mary] are: tensor([0.3316, 0.4156, 0.0838, 0.1690], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,032][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Mary] are: tensor([0.1139, 0.3119, 0.2814, 0.2928], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,034][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Mary] are: tensor([0.0589, 0.2246, 0.2968, 0.4197], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,035][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Mary] are: tensor([1.0000e+00, 9.4634e-10, 1.5000e-08, 5.3120e-11], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,036][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.1145, 0.1919, 0.3211, 0.0946, 0.2779], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,038][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.3248, 0.3612, 0.1018, 0.1757, 0.0365], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,039][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.1556, 0.2503, 0.1876, 0.1953, 0.2112], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,041][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0219, 0.2006, 0.0557, 0.7132, 0.0085], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,043][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.5665, 0.1138, 0.1032, 0.1098, 0.1067], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,044][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.1306, 0.2231, 0.2507, 0.2378, 0.1578], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,046][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0430, 0.1119, 0.3574, 0.2185, 0.2691], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,048][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0137, 0.0008, 0.0948, 0.0850, 0.8058], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,049][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.2325, 0.2990, 0.0777, 0.1061, 0.2848], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,050][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.0814, 0.2194, 0.2053, 0.2179, 0.2759], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,051][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0630, 0.2382, 0.1741, 0.1745, 0.3502], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,052][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ went] are: tensor([1.0000e+00, 2.7567e-09, 2.8473e-08, 7.8199e-10, 8.9942e-09],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,052][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1213, 0.1753, 0.0708, 0.0801, 0.4943, 0.0582], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,054][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1465, 0.4559, 0.0507, 0.2075, 0.1216, 0.0179], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,055][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1321, 0.2150, 0.1570, 0.1624, 0.1915, 0.1420], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,057][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0210, 0.1848, 0.0097, 0.7572, 0.0115, 0.0157], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,059][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.4741, 0.1002, 0.0911, 0.0996, 0.0956, 0.1394], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,060][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1131, 0.1801, 0.2124, 0.2385, 0.1485, 0.1074], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,062][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0397, 0.0823, 0.2450, 0.1913, 0.2270, 0.2148], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,063][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([1.2427e-02, 5.1922e-04, 1.5487e-01, 2.5811e-02, 6.0747e-02, 7.4563e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,065][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2020, 0.2151, 0.1037, 0.1223, 0.2135, 0.1434], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,066][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0604, 0.1785, 0.1674, 0.1740, 0.2290, 0.1907], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,068][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0479, 0.1654, 0.1878, 0.1633, 0.2611, 0.1745], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,069][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.0000e+00, 1.7398e-07, 2.1858e-08, 1.3256e-08, 3.6744e-07, 6.1101e-08],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,071][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.2161, 0.1840, 0.0803, 0.0469, 0.2501, 0.1378, 0.0848],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,072][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1144, 0.2744, 0.0482, 0.2025, 0.2871, 0.0583, 0.0152],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,074][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0945, 0.1885, 0.1449, 0.1507, 0.1719, 0.1099, 0.1396],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,076][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0384, 0.1615, 0.0430, 0.6120, 0.0158, 0.1270, 0.0022],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,077][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.4299, 0.0869, 0.0792, 0.0848, 0.0822, 0.1215, 0.1155],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,079][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0682, 0.1148, 0.1427, 0.1509, 0.1225, 0.1243, 0.2767],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,081][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0252, 0.0694, 0.2230, 0.1467, 0.1883, 0.2007, 0.1467],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,082][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0032, 0.0013, 0.0155, 0.1343, 0.1097, 0.3037, 0.4324],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,084][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.1622, 0.1663, 0.0726, 0.0856, 0.2176, 0.1111, 0.1845],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,085][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0525, 0.1488, 0.1386, 0.1464, 0.1892, 0.1597, 0.1648],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,087][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0361, 0.1162, 0.1424, 0.1667, 0.2835, 0.1254, 0.1297],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,088][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ the] are: tensor([9.9999e-01, 2.1456e-07, 2.1508e-07, 2.4612e-08, 1.4990e-06, 1.4552e-06,
        1.9414e-06], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,090][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.0669, 0.0648, 0.1294, 0.0294, 0.2381, 0.2619, 0.1316, 0.0779],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,092][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([0.2312, 0.0643, 0.0427, 0.0969, 0.3832, 0.0435, 0.0464, 0.0917],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,093][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.0604, 0.1361, 0.1290, 0.1414, 0.1669, 0.1130, 0.1582, 0.0950],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,095][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.0866, 0.1413, 0.0457, 0.3743, 0.0282, 0.1800, 0.0552, 0.0887],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,097][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.3996, 0.0799, 0.0729, 0.0791, 0.0760, 0.1103, 0.1052, 0.0770],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,098][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.0590, 0.1062, 0.1346, 0.0937, 0.1145, 0.1088, 0.2477, 0.1355],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,100][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.0175, 0.0534, 0.1787, 0.1325, 0.1746, 0.1794, 0.1427, 0.1213],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,102][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.0158, 0.0021, 0.0809, 0.1396, 0.0847, 0.4404, 0.1377, 0.0987],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,103][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.1662, 0.2243, 0.0425, 0.0807, 0.1178, 0.0717, 0.1268, 0.1700],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,105][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.0491, 0.1295, 0.1167, 0.1230, 0.1622, 0.1373, 0.1425, 0.1397],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,106][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.0187, 0.0984, 0.1002, 0.1581, 0.1642, 0.1080, 0.0930, 0.2594],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,107][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([1.0000e+00, 4.1846e-09, 6.6618e-08, 8.4081e-10, 6.9036e-08, 1.5417e-07,
        8.9737e-07, 2.1708e-08], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,107][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1575, 0.1152, 0.0519, 0.0444, 0.2570, 0.0738, 0.1173, 0.1222, 0.0607],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,108][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0913, 0.1488, 0.0279, 0.1670, 0.1419, 0.0485, 0.0523, 0.3167, 0.0056],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,110][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0662, 0.1259, 0.1133, 0.1207, 0.1520, 0.0963, 0.1330, 0.0988, 0.0937],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,111][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([2.9879e-03, 7.8023e-02, 1.0485e-03, 3.3163e-01, 4.5994e-03, 8.0449e-03,
        3.7442e-03, 5.6981e-01, 1.1786e-04], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,112][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3513, 0.0730, 0.0664, 0.0734, 0.0702, 0.1020, 0.0978, 0.0703, 0.0954],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,114][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0769, 0.0876, 0.1205, 0.1020, 0.1002, 0.0944, 0.2200, 0.1138, 0.0845],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,116][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0173, 0.0481, 0.1654, 0.1215, 0.1567, 0.1539, 0.1209, 0.1045, 0.1118],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,117][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([1.3885e-03, 6.3666e-05, 1.0366e-01, 8.7709e-03, 1.3073e-02, 2.9887e-01,
        4.5651e-02, 7.8664e-03, 5.2066e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,118][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1245, 0.1131, 0.0544, 0.0825, 0.1020, 0.0614, 0.1311, 0.1947, 0.1363],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,120][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0378, 0.1167, 0.1044, 0.1109, 0.1442, 0.1195, 0.1275, 0.1249, 0.1141],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,122][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0258, 0.1208, 0.0911, 0.1178, 0.1437, 0.0910, 0.0869, 0.1568, 0.1660],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,123][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([1.0000e+00, 8.3470e-08, 5.8732e-09, 4.9699e-09, 1.8179e-07, 7.2399e-08,
        2.4646e-06, 4.0173e-07, 3.4261e-08], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,124][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.0371, 0.0545, 0.0993, 0.0276, 0.1380, 0.1570, 0.1402, 0.0910, 0.1825,
        0.0729], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,126][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.0901, 0.0839, 0.0657, 0.0743, 0.1457, 0.0738, 0.0379, 0.2637, 0.0442,
        0.1207], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,128][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.0633, 0.1068, 0.0965, 0.1035, 0.1442, 0.0924, 0.1220, 0.0991, 0.0927,
        0.0795], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,130][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.0333, 0.0273, 0.0225, 0.0693, 0.0082, 0.3367, 0.0125, 0.3930, 0.0078,
        0.0895], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,131][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.3374, 0.0680, 0.0619, 0.0678, 0.0647, 0.0935, 0.0896, 0.0654, 0.0872,
        0.0645], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,133][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.0319, 0.0686, 0.1074, 0.0919, 0.0901, 0.0999, 0.2377, 0.1070, 0.0937,
        0.0718], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,135][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.0159, 0.0456, 0.1458, 0.1109, 0.1377, 0.1405, 0.1140, 0.0991, 0.1093,
        0.0812], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,136][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0028, 0.0006, 0.0284, 0.0663, 0.0314, 0.2833, 0.3796, 0.0209, 0.1610,
        0.0257], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,138][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.1313, 0.1348, 0.0545, 0.0745, 0.1242, 0.0836, 0.1222, 0.1181, 0.0941,
        0.0627], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,140][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.0398, 0.1074, 0.0896, 0.0998, 0.1288, 0.1050, 0.1159, 0.1122, 0.0987,
        0.1028], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,142][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0220, 0.0752, 0.1045, 0.1118, 0.1308, 0.0890, 0.0988, 0.1193, 0.1759,
        0.0727], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,143][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([1.0000e+00, 1.1515e-10, 1.1326e-08, 1.0189e-10, 1.0533e-08, 3.9369e-08,
        4.6823e-07, 3.4740e-08, 5.1400e-08, 5.8029e-11], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,144][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0231, 0.0599, 0.0954, 0.0299, 0.1441, 0.1563, 0.1389, 0.0680, 0.1375,
        0.0847, 0.0622], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,146][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.1892, 0.1011, 0.0556, 0.0830, 0.0349, 0.0647, 0.0335, 0.0686, 0.0402,
        0.3035, 0.0257], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,148][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0690, 0.1030, 0.0941, 0.0988, 0.1115, 0.0821, 0.1101, 0.0821, 0.0777,
        0.0717, 0.0998], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,150][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0027, 0.1112, 0.0024, 0.4354, 0.0028, 0.0201, 0.0029, 0.1888, 0.0012,
        0.2319, 0.0007], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,151][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.3146, 0.0644, 0.0585, 0.0641, 0.0612, 0.0881, 0.0844, 0.0614, 0.0822,
        0.0606, 0.0605], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,153][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0493, 0.0884, 0.1014, 0.0862, 0.0505, 0.0797, 0.1988, 0.1026, 0.0841,
        0.0954, 0.0635], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,155][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0143, 0.0398, 0.1361, 0.1024, 0.1304, 0.1291, 0.1026, 0.0842, 0.0937,
        0.0707, 0.0967], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,156][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([2.2292e-03, 7.6496e-05, 3.5263e-02, 1.4341e-02, 4.7287e-02, 2.6077e-01,
        6.5434e-02, 1.0215e-02, 3.9605e-01, 4.7927e-03, 1.6353e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,158][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0973, 0.1171, 0.0343, 0.0567, 0.1280, 0.0569, 0.1026, 0.1533, 0.0798,
        0.0843, 0.0896], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,159][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0329, 0.0965, 0.0832, 0.0914, 0.1169, 0.0957, 0.1046, 0.1011, 0.0915,
        0.0949, 0.0914], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,161][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0225, 0.0846, 0.0722, 0.0997, 0.1559, 0.0655, 0.0719, 0.1241, 0.1242,
        0.0857, 0.0937], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,162][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([9.9999e-01, 3.4537e-08, 8.8195e-08, 4.8486e-09, 1.6709e-07, 5.1095e-07,
        4.4564e-06, 3.7141e-07, 5.0554e-07, 9.5427e-09, 8.8537e-08],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,163][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0688, 0.0736, 0.0572, 0.0224, 0.1439, 0.0960, 0.0805, 0.0948, 0.0910,
        0.0807, 0.1651, 0.0259], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,163][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0398, 0.0755, 0.0463, 0.0786, 0.1027, 0.0582, 0.0097, 0.3187, 0.0422,
        0.1313, 0.0902, 0.0068], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,165][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0677, 0.0911, 0.0909, 0.0924, 0.0977, 0.0738, 0.0985, 0.0766, 0.0733,
        0.0686, 0.0894, 0.0799], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,166][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0104, 0.0265, 0.0311, 0.2457, 0.0068, 0.0990, 0.0031, 0.4697, 0.0071,
        0.0854, 0.0141, 0.0012], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,168][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2870, 0.0603, 0.0546, 0.0600, 0.0571, 0.0831, 0.0793, 0.0573, 0.0777,
        0.0563, 0.0568, 0.0706], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,170][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0294, 0.0584, 0.0717, 0.0827, 0.0603, 0.0700, 0.1688, 0.0911, 0.0754,
        0.0708, 0.0718, 0.1496], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,171][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0129, 0.0365, 0.1257, 0.0963, 0.1248, 0.1156, 0.0937, 0.0751, 0.0851,
        0.0643, 0.0890, 0.0810], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,172][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([1.8583e-03, 2.1751e-04, 2.2210e-02, 2.5506e-02, 3.9711e-02, 1.4927e-01,
        3.0382e-01, 1.2798e-02, 2.1493e-01, 9.4336e-03, 1.1206e-01, 1.0819e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,174][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0945, 0.1212, 0.0482, 0.0714, 0.0735, 0.0517, 0.0882, 0.1434, 0.0988,
        0.0608, 0.0649, 0.0834], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,176][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0275, 0.0860, 0.0757, 0.0806, 0.1033, 0.0876, 0.0931, 0.0904, 0.0840,
        0.0869, 0.0845, 0.1003], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,178][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0185, 0.0771, 0.0660, 0.1092, 0.1339, 0.0607, 0.0665, 0.1129, 0.1193,
        0.0840, 0.0801, 0.0718], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,179][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([9.9999e-01, 1.0164e-07, 1.1875e-07, 9.0871e-09, 5.5195e-07, 6.5229e-07,
        1.5279e-06, 1.7731e-06, 7.0989e-07, 4.8100e-08, 1.3810e-06, 8.4073e-08],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,181][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0508, 0.0775, 0.0717, 0.0266, 0.1191, 0.1448, 0.0843, 0.0485, 0.1131,
        0.1010, 0.0678, 0.0384, 0.0564], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,182][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.1734, 0.0398, 0.0543, 0.1029, 0.1487, 0.0649, 0.0324, 0.0731, 0.0387,
        0.0676, 0.1467, 0.0338, 0.0236], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,184][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0764, 0.1202, 0.0905, 0.0780, 0.0871, 0.0641, 0.0709, 0.0824, 0.0581,
        0.0640, 0.0778, 0.0524, 0.0782], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,186][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0051, 0.0778, 0.0039, 0.3368, 0.0037, 0.0382, 0.0127, 0.1855, 0.0010,
        0.2744, 0.0077, 0.0168, 0.0364], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,188][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.2743, 0.0548, 0.0498, 0.0532, 0.0516, 0.0766, 0.0725, 0.0522, 0.0719,
        0.0515, 0.0514, 0.0649, 0.0754], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,189][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0303, 0.0681, 0.0810, 0.0685, 0.0598, 0.0683, 0.1356, 0.0754, 0.0741,
        0.0768, 0.0600, 0.1440, 0.0580], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,191][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0135, 0.0370, 0.1183, 0.0759, 0.0990, 0.1085, 0.0792, 0.0701, 0.0791,
        0.0608, 0.0864, 0.0776, 0.0947], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,193][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0015, 0.0005, 0.0428, 0.0080, 0.0126, 0.1748, 0.1763, 0.0238, 0.3221,
        0.0312, 0.0618, 0.1047, 0.0399], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,195][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.1059, 0.0708, 0.0285, 0.0480, 0.1150, 0.0598, 0.0846, 0.1280, 0.0729,
        0.0374, 0.0756, 0.1138, 0.0597], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,196][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0275, 0.0769, 0.0671, 0.0718, 0.0925, 0.0808, 0.0836, 0.0806, 0.0789,
        0.0843, 0.0788, 0.0921, 0.0851], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,198][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0127, 0.0525, 0.0494, 0.0483, 0.1054, 0.0587, 0.0550, 0.1269, 0.0874,
        0.0568, 0.0651, 0.0629, 0.2187], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,199][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([1.0000e+00, 2.1897e-09, 2.2151e-08, 4.2711e-10, 1.5750e-08, 5.9959e-08,
        8.1688e-07, 1.7812e-08, 9.6770e-08, 5.4250e-10, 3.6329e-08, 7.9373e-08,
        3.9821e-10], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,201][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0345, 0.0628, 0.0266, 0.0302, 0.2088, 0.0190, 0.0996, 0.0779, 0.0422,
        0.1060, 0.1277, 0.0473, 0.1022, 0.0152], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,203][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1191, 0.1596, 0.0202, 0.0530, 0.0688, 0.0094, 0.0138, 0.1558, 0.0116,
        0.2796, 0.0183, 0.0178, 0.0585, 0.0144], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,204][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0659, 0.0881, 0.0764, 0.0702, 0.0820, 0.0633, 0.0729, 0.0625, 0.0603,
        0.0584, 0.0782, 0.0657, 0.0810, 0.0751], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,206][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0057, 0.0546, 0.0034, 0.2602, 0.0037, 0.0046, 0.0050, 0.2545, 0.0031,
        0.2111, 0.0110, 0.0055, 0.1687, 0.0090], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,208][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.2452, 0.0520, 0.0472, 0.0519, 0.0495, 0.0719, 0.0686, 0.0495, 0.0671,
        0.0487, 0.0491, 0.0610, 0.0720, 0.0664], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,210][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0351, 0.0531, 0.0668, 0.0694, 0.0489, 0.0320, 0.1481, 0.0761, 0.0567,
        0.0621, 0.0544, 0.1803, 0.0782, 0.0388], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,212][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0134, 0.0323, 0.1021, 0.0833, 0.1030, 0.0911, 0.0788, 0.0618, 0.0702,
        0.0552, 0.0725, 0.0665, 0.0993, 0.0706], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,213][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([3.6507e-03, 2.1834e-04, 4.9992e-02, 1.4340e-02, 2.0511e-02, 2.3972e-01,
        4.2954e-02, 8.3561e-03, 1.3789e-01, 6.4890e-03, 5.8740e-02, 2.4150e-02,
        2.7717e-02, 3.6528e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,215][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0852, 0.0972, 0.0516, 0.0618, 0.0811, 0.0544, 0.0783, 0.1222, 0.0830,
        0.0583, 0.0482, 0.0610, 0.0550, 0.0627], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,216][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0238, 0.0730, 0.0634, 0.0675, 0.0878, 0.0738, 0.0785, 0.0767, 0.0699,
        0.0733, 0.0708, 0.0842, 0.0844, 0.0729], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,217][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0191, 0.0625, 0.0705, 0.0658, 0.1077, 0.0672, 0.0709, 0.0702, 0.1023,
        0.0717, 0.0592, 0.0721, 0.0924, 0.0685], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,218][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([9.9997e-01, 8.9739e-07, 7.8001e-08, 7.1394e-08, 1.1171e-06, 1.9822e-07,
        1.7098e-05, 5.1075e-06, 7.7434e-07, 2.8894e-07, 1.1295e-06, 1.6267e-06,
        4.6644e-07, 2.7142e-07], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,266][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:22,267][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,268][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,269][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,269][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,270][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,271][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,271][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,272][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,273][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,273][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,274][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,274][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,275][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.1136, 0.8864], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,276][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.1006, 0.8994], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,277][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.4766, 0.5234], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,279][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.2536, 0.7464], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,281][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.9989, 0.0011], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,282][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.8892, 0.1108], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,284][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.4796, 0.5204], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,285][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.4532, 0.5468], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,287][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.9635, 0.0365], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,288][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.9073, 0.0927], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,290][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.7831, 0.2169], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,291][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([9.9995e-01, 4.8358e-05], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,292][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0700, 0.5173, 0.4127], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,293][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0483, 0.4597, 0.4921], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,293][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2363, 0.2423, 0.5214], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,294][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2886, 0.3115, 0.4000], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,295][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([9.9919e-01, 5.2396e-04, 2.9092e-04], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,296][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.5859, 0.3466, 0.0675], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,298][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.3359, 0.3853, 0.2788], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,299][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2958, 0.3610, 0.3432], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,301][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9382, 0.0235, 0.0382], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,303][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.5226, 0.4066, 0.0708], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,304][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4955, 0.2518, 0.2526], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,305][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([9.0871e-03, 9.9091e-01, 9.7351e-07], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,307][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Mary] are: tensor([0.0592, 0.4046, 0.3038, 0.2324], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,309][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Mary] are: tensor([0.0295, 0.3114, 0.3331, 0.3260], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,310][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Mary] are: tensor([0.1143, 0.1577, 0.2961, 0.4319], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,312][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Mary] are: tensor([0.0543, 0.2049, 0.6861, 0.0546], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,313][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Mary] are: tensor([0.9926, 0.0024, 0.0012, 0.0037], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,315][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Mary] are: tensor([0.4312, 0.2447, 0.1373, 0.1869], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,316][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Mary] are: tensor([0.1456, 0.4171, 0.3365, 0.1008], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,318][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Mary] are: tensor([0.1035, 0.3310, 0.1416, 0.4240], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,320][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Mary] are: tensor([0.9251, 0.0376, 0.0192, 0.0181], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,321][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Mary] are: tensor([0.4224, 0.1442, 0.1134, 0.3200], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,323][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Mary] are: tensor([0.1993, 0.1525, 0.2462, 0.4020], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,325][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Mary] are: tensor([0.1045, 0.8928, 0.0014, 0.0013], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,326][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.0505, 0.2681, 0.2372, 0.1764, 0.2678], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,328][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0241, 0.2264, 0.2516, 0.2419, 0.2560], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,330][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.1149, 0.0659, 0.2228, 0.2742, 0.3222], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,331][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([3.1980e-04, 1.5319e-01, 4.8513e-01, 1.3112e-01, 2.3024e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,332][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([9.9313e-01, 1.3094e-03, 8.5644e-04, 1.3362e-03, 3.3707e-03],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,333][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.3189, 0.2301, 0.1174, 0.1574, 0.1762], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,335][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.1516, 0.2875, 0.2639, 0.1632, 0.1337], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,336][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0403, 0.1180, 0.0585, 0.1487, 0.6344], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,338][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.8139, 0.0321, 0.0700, 0.0355, 0.0485], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,340][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.3680, 0.1022, 0.1063, 0.1360, 0.2875], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,341][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.1315, 0.1401, 0.1019, 0.1195, 0.5070], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,342][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([2.0618e-03, 9.2276e-01, 4.5208e-05, 6.7373e-02, 7.7624e-03],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,344][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0310, 0.1971, 0.1746, 0.1440, 0.2222, 0.2311], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,346][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0259, 0.1737, 0.1912, 0.1873, 0.1989, 0.2230], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,347][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0719, 0.0620, 0.1520, 0.1752, 0.2924, 0.2465], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,348][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1412, 0.0066, 0.0289, 0.0085, 0.0645, 0.7503], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,349][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.9785e-01, 3.9432e-04, 2.7770e-04, 3.3018e-04, 4.6174e-04, 6.8335e-04],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,350][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.3241, 0.0903, 0.0207, 0.0640, 0.1135, 0.3874], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,350][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1804, 0.1803, 0.1886, 0.1458, 0.1614, 0.1435], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,352][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0714, 0.0565, 0.0280, 0.0721, 0.3047, 0.4672], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,353][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.8634, 0.0152, 0.0285, 0.0160, 0.0231, 0.0538], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,355][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1325, 0.0584, 0.0071, 0.0973, 0.6800, 0.0247], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,356][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.2175, 0.1250, 0.1196, 0.0974, 0.2570, 0.1835], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,357][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([4.3140e-01, 1.1527e-01, 3.1682e-08, 6.2713e-03, 4.4323e-01, 3.8277e-03],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,359][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0315, 0.1874, 0.1453, 0.1151, 0.1840, 0.1864, 0.1502],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,361][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0210, 0.1438, 0.1563, 0.1508, 0.1576, 0.1823, 0.1880],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,362][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0578, 0.0546, 0.1090, 0.1653, 0.2226, 0.1590, 0.2319],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,364][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0213, 0.0122, 0.0305, 0.0033, 0.0243, 0.8842, 0.0241],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,365][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([9.9553e-01, 6.4704e-04, 4.5508e-04, 6.1562e-04, 7.6971e-04, 9.9510e-04,
        9.8522e-04], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,367][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1326, 0.0619, 0.0154, 0.0348, 0.0824, 0.4967, 0.1762],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,368][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.1271, 0.1469, 0.1484, 0.1333, 0.1444, 0.1347, 0.1653],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,370][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0534, 0.0496, 0.0182, 0.0597, 0.2484, 0.3328, 0.2379],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,372][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.8442, 0.0124, 0.0219, 0.0118, 0.0247, 0.0513, 0.0335],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,373][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1550, 0.1174, 0.0184, 0.1221, 0.4129, 0.1471, 0.0271],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,375][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1841, 0.0608, 0.0874, 0.0961, 0.3385, 0.1170, 0.1161],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,376][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([2.7119e-01, 2.2021e-01, 4.8663e-07, 5.1945e-04, 1.9822e-01, 3.0251e-01,
        7.3528e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,378][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.0257, 0.1729, 0.1291, 0.1007, 0.1643, 0.1634, 0.1343, 0.1096],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,379][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([0.0135, 0.1261, 0.1312, 0.1268, 0.1366, 0.1654, 0.1702, 0.1301],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,381][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([0.0410, 0.0510, 0.1052, 0.1554, 0.2411, 0.1322, 0.1946, 0.0796],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,382][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([7.4386e-04, 1.1642e-02, 1.0029e-02, 3.1642e-03, 5.9259e-02, 8.2320e-01,
        8.8561e-02, 3.4038e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,383][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([9.9003e-01, 1.0104e-03, 7.2932e-04, 8.2313e-04, 2.0066e-03, 1.6539e-03,
        1.6994e-03, 2.0427e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,385][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.1056, 0.0537, 0.0101, 0.0183, 0.0437, 0.3575, 0.3281, 0.0830],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,387][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.0758, 0.1747, 0.1568, 0.0730, 0.1372, 0.1258, 0.1757, 0.0809],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,389][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.0114, 0.0409, 0.0227, 0.0431, 0.1195, 0.3371, 0.2201, 0.2051],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,390][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.7316, 0.0185, 0.0318, 0.0239, 0.0336, 0.0632, 0.0559, 0.0414],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,392][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.0864, 0.1462, 0.0310, 0.1253, 0.2074, 0.1180, 0.0814, 0.2042],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,393][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.1196, 0.0462, 0.0544, 0.0933, 0.1270, 0.0858, 0.0766, 0.3972],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,395][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([8.5592e-04, 1.9377e-02, 1.1946e-07, 3.3659e-04, 1.7935e-02, 4.4637e-02,
        8.9000e-01, 2.6859e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,396][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0239, 0.1250, 0.1162, 0.0838, 0.1391, 0.1581, 0.1255, 0.0971, 0.1313],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,398][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0169, 0.1057, 0.1151, 0.1122, 0.1169, 0.1355, 0.1404, 0.1123, 0.1450],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,400][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0462, 0.0463, 0.0914, 0.1286, 0.1798, 0.1129, 0.1575, 0.0649, 0.1724],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,401][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0773, 0.0046, 0.0188, 0.0020, 0.0215, 0.4025, 0.0359, 0.0120, 0.4253],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,403][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([9.9037e-01, 9.9390e-04, 6.0044e-04, 9.7488e-04, 9.2369e-04, 1.2304e-03,
        1.1693e-03, 6.7500e-04, 3.0656e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,404][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1534, 0.0331, 0.0068, 0.0189, 0.0369, 0.2044, 0.1683, 0.1039, 0.2742],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,404][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1135, 0.1055, 0.1033, 0.0858, 0.1028, 0.1037, 0.1406, 0.1191, 0.1256],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,405][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0180, 0.0164, 0.0114, 0.0226, 0.0889, 0.1818, 0.1049, 0.0814, 0.4747],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,406][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.6353, 0.0172, 0.0374, 0.0145, 0.0222, 0.0744, 0.0458, 0.0530, 0.1003],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,407][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0437, 0.0196, 0.0047, 0.0330, 0.4829, 0.0304, 0.0281, 0.3544, 0.0032],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,409][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1319, 0.1107, 0.0584, 0.0616, 0.1208, 0.0860, 0.0676, 0.2261, 0.1369],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,410][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([4.3237e-03, 4.1878e-03, 4.8764e-11, 4.2127e-05, 1.6183e-03, 1.7547e-05,
        2.9990e-04, 1.0586e-01, 8.8365e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,411][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.0215, 0.1112, 0.1061, 0.0714, 0.1148, 0.1352, 0.1137, 0.0875, 0.1171,
        0.1215], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,413][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.0087, 0.0935, 0.0989, 0.0960, 0.1024, 0.1249, 0.1308, 0.0995, 0.1368,
        0.1085], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,415][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.0322, 0.0366, 0.0851, 0.1105, 0.1487, 0.1050, 0.1669, 0.0702, 0.1651,
        0.0797], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,416][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([1.3335e-04, 1.7340e-03, 5.4079e-03, 6.2214e-04, 1.8527e-02, 3.8877e-01,
        3.7061e-02, 4.3206e-03, 5.3740e-01, 6.0150e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,418][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.9647, 0.0020, 0.0016, 0.0027, 0.0024, 0.0036, 0.0032, 0.0033, 0.0077,
        0.0087], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,419][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.0443, 0.0124, 0.0035, 0.0104, 0.0318, 0.1110, 0.1869, 0.1719, 0.3754,
        0.0524], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,421][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.0560, 0.0606, 0.0950, 0.0731, 0.1036, 0.0996, 0.1246, 0.1574, 0.1546,
        0.0756], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,423][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0061, 0.0216, 0.0078, 0.0274, 0.0765, 0.1332, 0.1244, 0.1096, 0.3884,
        0.1050], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,424][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.3542, 0.0228, 0.0445, 0.0535, 0.0649, 0.1089, 0.0849, 0.0899, 0.1338,
        0.0427], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,426][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.1821, 0.0179, 0.0121, 0.0844, 0.2379, 0.0835, 0.0607, 0.2744, 0.0208,
        0.0261], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,428][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.1281, 0.0362, 0.0709, 0.0782, 0.1157, 0.0866, 0.1113, 0.1450, 0.1903,
        0.0377], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,429][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([6.3208e-07, 4.3424e-07, 3.1146e-12, 7.9445e-08, 4.3895e-05, 1.0601e-06,
        5.5992e-04, 2.2142e-02, 9.7722e-01, 3.1012e-05], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,431][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0240, 0.1040, 0.0943, 0.0637, 0.1030, 0.1211, 0.0996, 0.0765, 0.1038,
        0.1038, 0.1062], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,432][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0081, 0.0830, 0.0896, 0.0860, 0.0917, 0.1148, 0.1199, 0.0896, 0.1254,
        0.0963, 0.0955], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,434][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0331, 0.0336, 0.0772, 0.0987, 0.1126, 0.1137, 0.1636, 0.0555, 0.1563,
        0.0730, 0.0827], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,435][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([5.5138e-05, 1.6574e-03, 6.3311e-03, 1.1831e-03, 1.5986e-02, 5.4689e-01,
        3.0998e-02, 1.3829e-03, 3.6091e-01, 5.1132e-03, 2.9487e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,437][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.9601, 0.0027, 0.0016, 0.0025, 0.0030, 0.0026, 0.0032, 0.0021, 0.0074,
        0.0093, 0.0054], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,439][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0372, 0.0201, 0.0048, 0.0083, 0.0099, 0.0804, 0.1176, 0.0461, 0.4103,
        0.0519, 0.2135], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,441][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0665, 0.1042, 0.0861, 0.0635, 0.0752, 0.0771, 0.1106, 0.1126, 0.1190,
        0.1175, 0.0678], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,442][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0036, 0.0096, 0.0062, 0.0098, 0.0740, 0.0918, 0.0712, 0.0604, 0.3567,
        0.0336, 0.2830], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,444][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.4242, 0.0158, 0.0407, 0.0179, 0.0411, 0.0910, 0.0592, 0.0869, 0.1109,
        0.0479, 0.0644], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,446][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.1123, 0.0272, 0.0208, 0.0896, 0.2493, 0.1317, 0.1407, 0.1103, 0.0427,
        0.0479, 0.0275], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,448][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0848, 0.0433, 0.0456, 0.0624, 0.2015, 0.0708, 0.0694, 0.1603, 0.1033,
        0.0469, 0.1116], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,449][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([2.4046e-06, 4.3438e-05, 9.3110e-12, 6.6467e-07, 1.7532e-05, 9.6131e-06,
        1.0191e-04, 6.8387e-03, 9.2172e-01, 7.9721e-04, 7.0472e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,451][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0172, 0.0912, 0.0808, 0.0584, 0.0961, 0.1092, 0.0887, 0.0701, 0.0947,
        0.1004, 0.0996, 0.0933], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,452][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0120, 0.0755, 0.0800, 0.0788, 0.0830, 0.0975, 0.1006, 0.0809, 0.1041,
        0.0867, 0.0857, 0.1150], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,454][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0279, 0.0336, 0.0667, 0.0980, 0.1200, 0.0855, 0.1305, 0.0551, 0.1375,
        0.0822, 0.0831, 0.0799], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,456][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0117, 0.0012, 0.0084, 0.0011, 0.0070, 0.2836, 0.0161, 0.0017, 0.3984,
        0.0061, 0.0437, 0.2210], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,457][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([9.7968e-01, 1.2778e-03, 6.1324e-04, 7.8219e-04, 1.2312e-03, 1.0850e-03,
        1.0980e-03, 5.5911e-04, 3.4655e-03, 4.5650e-03, 2.3996e-03, 3.2404e-03],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,458][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1118, 0.0146, 0.0015, 0.0079, 0.0079, 0.0677, 0.0597, 0.0274, 0.1973,
        0.0267, 0.1577, 0.3198], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,459][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0573, 0.0655, 0.0807, 0.0593, 0.0711, 0.0706, 0.1082, 0.1071, 0.1150,
        0.0897, 0.1002, 0.0753], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,460][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0096, 0.0094, 0.0036, 0.0101, 0.0511, 0.0632, 0.0524, 0.0410, 0.1930,
        0.0293, 0.1416, 0.3957], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,461][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.3826, 0.0100, 0.0282, 0.0088, 0.0224, 0.0578, 0.0435, 0.0370, 0.0813,
        0.0330, 0.1025, 0.1930], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,462][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0703, 0.0389, 0.0096, 0.0478, 0.2841, 0.0788, 0.0216, 0.2450, 0.0167,
        0.0804, 0.0939, 0.0129], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,463][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0721, 0.0696, 0.0458, 0.0792, 0.1290, 0.0664, 0.0558, 0.1552, 0.0973,
        0.0671, 0.0799, 0.0827], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,464][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([2.6578e-03, 1.7924e-04, 1.5770e-12, 4.1211e-07, 9.7323e-05, 1.1007e-06,
        5.5814e-07, 2.4628e-04, 6.3462e-02, 2.5119e-04, 6.1139e-01, 3.2172e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,466][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.0206, 0.0917, 0.0736, 0.0550, 0.0920, 0.0954, 0.0795, 0.0633, 0.0829,
        0.0865, 0.0936, 0.0851, 0.0810], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,467][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0120, 0.0679, 0.0725, 0.0707, 0.0739, 0.0867, 0.0902, 0.0721, 0.0940,
        0.0778, 0.0790, 0.1053, 0.0980], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,469][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0274, 0.0332, 0.0642, 0.0964, 0.1132, 0.0787, 0.1288, 0.0460, 0.1214,
        0.0728, 0.0876, 0.0720, 0.0583], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,471][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([1.6437e-04, 4.7426e-03, 3.3688e-03, 1.0799e-03, 3.3386e-03, 2.1372e-01,
        1.1521e-02, 1.2500e-03, 3.6022e-01, 8.2885e-03, 2.6371e-02, 2.8114e-01,
        8.4792e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,472][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([9.8510e-01, 9.2348e-04, 5.4935e-04, 6.6249e-04, 8.9846e-04, 1.2469e-03,
        1.1367e-03, 5.0171e-04, 2.4836e-03, 2.6295e-03, 1.1510e-03, 1.3562e-03,
        1.3588e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,474][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.0503, 0.0046, 0.0006, 0.0015, 0.0046, 0.0222, 0.0269, 0.0121, 0.0886,
        0.0146, 0.1013, 0.4809, 0.1918], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,475][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0579, 0.0868, 0.0647, 0.0526, 0.0759, 0.0574, 0.0807, 0.1145, 0.0946,
        0.0952, 0.0932, 0.0771, 0.0495], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,477][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0051, 0.0052, 0.0020, 0.0048, 0.0215, 0.0410, 0.0372, 0.0423, 0.1276,
        0.0203, 0.1051, 0.2657, 0.3221], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,479][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.8209, 0.0062, 0.0081, 0.0071, 0.0160, 0.0166, 0.0187, 0.0147, 0.0147,
        0.0097, 0.0190, 0.0301, 0.0182], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,481][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0714, 0.0654, 0.0254, 0.0646, 0.1057, 0.0451, 0.0691, 0.1951, 0.0268,
        0.1130, 0.0966, 0.0960, 0.0258], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,482][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0997, 0.0285, 0.0345, 0.0317, 0.1366, 0.0440, 0.0509, 0.1862, 0.0637,
        0.0317, 0.0639, 0.0709, 0.1578], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,484][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([9.4464e-08, 3.3500e-07, 4.7930e-14, 2.6372e-10, 1.0737e-07, 4.9680e-08,
        9.2825e-07, 4.2357e-06, 5.3510e-03, 3.2104e-06, 2.0677e-02, 8.7932e-01,
        9.4647e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,485][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0152, 0.0730, 0.0661, 0.0465, 0.0780, 0.0889, 0.0740, 0.0566, 0.0764,
        0.0810, 0.0821, 0.0767, 0.0742, 0.1113], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,487][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0103, 0.0627, 0.0653, 0.0639, 0.0682, 0.0788, 0.0818, 0.0659, 0.0841,
        0.0709, 0.0698, 0.0933, 0.0891, 0.0959], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,489][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0236, 0.0253, 0.0579, 0.0680, 0.1032, 0.0905, 0.1043, 0.0443, 0.1310,
        0.0599, 0.0758, 0.0725, 0.0576, 0.0859], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,491][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0535, 0.0011, 0.0065, 0.0011, 0.0088, 0.1441, 0.0137, 0.0019, 0.2401,
        0.0049, 0.0335, 0.2201, 0.0522, 0.2186], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,492][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.8432e-01, 6.2701e-04, 4.6742e-04, 4.8825e-04, 9.4284e-04, 1.0459e-03,
        8.1312e-04, 4.3092e-04, 2.6213e-03, 2.5661e-03, 1.5782e-03, 1.8552e-03,
        9.4369e-04, 1.2953e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,494][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0371, 0.0038, 0.0004, 0.0017, 0.0033, 0.0103, 0.0169, 0.0082, 0.0583,
        0.0066, 0.0604, 0.2210, 0.2629, 0.3092], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,496][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0542, 0.0544, 0.0593, 0.0449, 0.0512, 0.0446, 0.0834, 0.0929, 0.0860,
        0.0795, 0.0826, 0.0821, 0.1151, 0.0697], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,497][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0050, 0.0040, 0.0014, 0.0036, 0.0172, 0.0236, 0.0194, 0.0171, 0.0851,
        0.0128, 0.0676, 0.1819, 0.1728, 0.3885], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,499][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2972, 0.0086, 0.0217, 0.0074, 0.0191, 0.0469, 0.0291, 0.0348, 0.0694,
        0.0247, 0.0770, 0.1720, 0.0382, 0.1538], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,501][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0608, 0.0266, 0.0027, 0.0469, 0.3048, 0.0122, 0.0179, 0.1632, 0.0050,
        0.0844, 0.0458, 0.0508, 0.1606, 0.0185], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,503][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0984, 0.0557, 0.0505, 0.0409, 0.0982, 0.0767, 0.0537, 0.1039, 0.0894,
        0.0574, 0.0568, 0.0862, 0.0516, 0.0806], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,504][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.2783e-06, 4.7079e-08, 2.5219e-17, 1.5566e-10, 1.1290e-08, 9.1303e-12,
        6.6197e-10, 2.6501e-07, 1.5312e-05, 1.3490e-07, 9.3094e-05, 2.6774e-03,
        9.7286e-01, 2.4352e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,508][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:23:22,510][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[2517],
        [1025],
        [1547],
        [ 411],
        [8574],
        [2891],
        [2826],
        [3329],
        [ 661],
        [1145],
        [ 869],
        [1619],
        [1896],
        [1525]], device='cuda:0')
[2024-07-24 10:23:22,511][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 2608],
        [ 8922],
        [ 5042],
        [ 2635],
        [13387],
        [ 4518],
        [ 4669],
        [ 9877],
        [ 2296],
        [ 4950],
        [ 3260],
        [ 4668],
        [ 5784],
        [ 5972]], device='cuda:0')
[2024-07-24 10:23:22,512][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[18934],
        [10967],
        [13830],
        [15197],
        [20563],
        [21688],
        [19389],
        [21227],
        [20337],
        [19678],
        [19899],
        [20192],
        [18824],
        [19741]], device='cuda:0')
[2024-07-24 10:23:22,514][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[16274],
        [ 8614],
        [ 8466],
        [14909],
        [17441],
        [17933],
        [25172],
        [30292],
        [27549],
        [24048],
        [13152],
        [20821],
        [20737],
        [14577]], device='cuda:0')
[2024-07-24 10:23:22,516][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[20111],
        [ 3232],
        [ 2896],
        [ 3429],
        [ 3714],
        [ 4037],
        [ 4026],
        [ 4644],
        [ 4800],
        [ 5092],
        [ 5057],
        [ 5134],
        [ 4510],
        [ 4727]], device='cuda:0')
[2024-07-24 10:23:22,517][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[13096],
        [10478],
        [ 9807],
        [33781],
        [48856],
        [49129],
        [48046],
        [42564],
        [41647],
        [19432],
        [45554],
        [36570],
        [41434],
        [37210]], device='cuda:0')
[2024-07-24 10:23:22,519][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 7193],
        [ 9528],
        [11578],
        [11298],
        [12371],
        [13352],
        [14043],
        [14769],
        [15386],
        [15689],
        [16308],
        [16845],
        [17264],
        [17772]], device='cuda:0')
[2024-07-24 10:23:22,521][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[33437],
        [34065],
        [39686],
        [37499],
        [37841],
        [39178],
        [39028],
        [37944],
        [38220],
        [38053],
        [37513],
        [38324],
        [38241],
        [38222]], device='cuda:0')
[2024-07-24 10:23:22,522][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[31171],
        [33375],
        [38244],
        [40531],
        [42506],
        [43226],
        [43671],
        [44003],
        [43936],
        [44000],
        [43786],
        [43692],
        [43892],
        [43984]], device='cuda:0')
[2024-07-24 10:23:22,524][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 4333],
        [ 4112],
        [26929],
        [27398],
        [30196],
        [21148],
        [17526],
        [21499],
        [16077],
        [15475],
        [14697],
        [12917],
        [13328],
        [15728]], device='cuda:0')
[2024-07-24 10:23:22,526][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[10840],
        [ 6460],
        [ 7656],
        [ 6336],
        [ 5755],
        [ 5882],
        [ 6690],
        [ 5409],
        [ 5365],
        [ 5612],
        [ 5047],
        [ 5059],
        [ 5055],
        [ 5190]], device='cuda:0')
[2024-07-24 10:23:22,527][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[16642],
        [15097],
        [11826],
        [10935],
        [10063],
        [ 9305],
        [ 8908],
        [ 8783],
        [ 8601],
        [ 8629],
        [ 8467],
        [ 8265],
        [ 8211],
        [ 8028]], device='cuda:0')
[2024-07-24 10:23:22,529][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 9298],
        [20507],
        [18310],
        [26345],
        [26362],
        [25613],
        [26315],
        [29259],
        [26833],
        [26533],
        [27812],
        [27532],
        [31429],
        [27941]], device='cuda:0')
[2024-07-24 10:23:22,531][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[33752],
        [33752],
        [33752],
        [33752],
        [33752],
        [33752],
        [33752],
        [33752],
        [33752],
        [33752],
        [33752],
        [33752],
        [33752],
        [33752]], device='cuda:0')
[2024-07-24 10:23:22,532][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[8776],
        [1557],
        [3693],
        [2490],
        [9076],
        [3228],
        [8622],
        [2407],
        [1445],
        [1300],
        [2083],
        [3195],
        [6618],
        [1099]], device='cuda:0')
[2024-07-24 10:23:22,534][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[11312],
        [ 7092],
        [ 6343],
        [ 6079],
        [ 6662],
        [ 6648],
        [ 6574],
        [ 6605],
        [ 6661],
        [ 6795],
        [ 6705],
        [ 6740],
        [ 6831],
        [ 6795]], device='cuda:0')
[2024-07-24 10:23:22,535][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 3097],
        [ 5011],
        [ 6067],
        [ 7574],
        [ 7322],
        [ 7790],
        [ 8511],
        [ 8817],
        [ 9219],
        [ 9631],
        [ 9767],
        [ 9956],
        [ 9866],
        [10097]], device='cuda:0')
[2024-07-24 10:23:22,537][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[6586],
        [3306],
        [5812],
        [6345],
        [6704],
        [6813],
        [7192],
        [6901],
        [7156],
        [6841],
        [6867],
        [6868],
        [6716],
        [6851]], device='cuda:0')
[2024-07-24 10:23:22,539][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 6159],
        [25955],
        [30263],
        [30541],
        [25823],
        [29390],
        [30151],
        [29461],
        [30469],
        [30765],
        [30808],
        [31439],
        [29773],
        [30585]], device='cuda:0')
[2024-07-24 10:23:22,540][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[31479],
        [31424],
        [31423],
        [31274],
        [31125],
        [31392],
        [31217],
        [30899],
        [30988],
        [29226],
        [29062],
        [30169],
        [30775],
        [30570]], device='cuda:0')
[2024-07-24 10:23:22,542][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 8962],
        [10197],
        [14638],
        [16475],
        [20334],
        [13791],
        [12042],
        [10402],
        [10089],
        [10886],
        [ 9834],
        [14726],
        [15932],
        [13983]], device='cuda:0')
[2024-07-24 10:23:22,543][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[3547],
        [3663],
        [4226],
        [4094],
        [4031],
        [3548],
        [3633],
        [3939],
        [3664],
        [3683],
        [3760],
        [3855],
        [3929],
        [3751]], device='cuda:0')
[2024-07-24 10:23:22,545][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[24795],
        [16627],
        [20520],
        [12133],
        [11682],
        [16894],
        [16534],
        [17971],
        [21474],
        [20734],
        [20702],
        [18573],
        [16766],
        [18718]], device='cuda:0')
[2024-07-24 10:23:22,546][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 2626],
        [ 3502],
        [ 4489],
        [ 4721],
        [ 8322],
        [ 6915],
        [ 7941],
        [10243],
        [11342],
        [13967],
        [12228],
        [ 9464],
        [ 6819],
        [ 9465]], device='cuda:0')
[2024-07-24 10:23:22,548][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[15937],
        [17572],
        [11558],
        [17640],
        [ 8287],
        [ 8744],
        [ 8401],
        [12937],
        [14209],
        [15338],
        [ 6842],
        [ 8538],
        [ 7098],
        [ 7412]], device='cuda:0')
[2024-07-24 10:23:22,550][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 3869],
        [ 4144],
        [ 3331],
        [ 4144],
        [10883],
        [ 4407],
        [ 6221],
        [ 5727],
        [ 4518],
        [ 3949],
        [ 5991],
        [ 5440],
        [ 6864],
        [ 4397]], device='cuda:0')
[2024-07-24 10:23:22,551][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[26783],
        [26782],
        [30138],
        [28714],
        [30226],
        [27627],
        [27318],
        [25383],
        [12588],
        [12000],
        [12892],
        [15228],
        [17207],
        [16914]], device='cuda:0')
[2024-07-24 10:23:22,553][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[26437],
        [20528],
        [14970],
        [13323],
        [11888],
        [15419],
        [14202],
        [13395],
        [14551],
        [14055],
        [15220],
        [14622],
        [14081],
        [15090]], device='cuda:0')
[2024-07-24 10:23:22,554][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[27848],
        [47452],
        [47443],
        [41093],
        [36311],
        [46834],
        [41585],
        [43348],
        [46726],
        [46823],
        [45957],
        [44020],
        [42476],
        [46666]], device='cuda:0')
[2024-07-24 10:23:22,556][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[1265],
        [1265],
        [1265],
        [1265],
        [1265],
        [1265],
        [1265],
        [1265],
        [1265],
        [1265],
        [1265],
        [1265],
        [1265],
        [1265]], device='cuda:0')
[2024-07-24 10:23:22,608][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:22,609][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,610][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,612][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,613][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,614][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,615][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,616][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,617][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,619][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,619][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,619][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,619][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,620][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.3305, 0.6695], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,620][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.0966, 0.9034], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,620][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.7129, 0.2871], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,621][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.7974, 0.2026], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,621][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.9169, 0.0831], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,621][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.0947, 0.9053], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,622][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.9794, 0.0206], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,623][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0456, 0.9544], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,624][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.0836, 0.9164], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,626][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.9984, 0.0016], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,627][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0671, 0.9329], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,628][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.1353, 0.8647], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,630][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2160, 0.2390, 0.5450], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,631][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0140, 0.8988, 0.0872], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,633][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2795, 0.6240, 0.0965], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,634][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.6242, 0.3423, 0.0334], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,635][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.8319, 0.0778, 0.0902], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,637][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0533, 0.5113, 0.4354], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,638][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.9531, 0.0326, 0.0144], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,639][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0186, 0.3280, 0.6533], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,641][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0555, 0.5350, 0.4095], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,642][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.9937, 0.0016, 0.0047], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,643][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0264, 0.5321, 0.4415], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,645][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0921, 0.3966, 0.5113], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,646][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Mary] are: tensor([0.1161, 0.1198, 0.4337, 0.3305], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,647][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Mary] are: tensor([0.0213, 0.6396, 0.2425, 0.0966], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,649][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Mary] are: tensor([0.1438, 0.2961, 0.3231, 0.2370], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,650][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Mary] are: tensor([0.4944, 0.3235, 0.1237, 0.0583], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,651][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Mary] are: tensor([0.5137, 0.1595, 0.2077, 0.1190], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,653][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Mary] are: tensor([0.0201, 0.3769, 0.3326, 0.2705], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,654][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Mary] are: tensor([0.9618, 0.0239, 0.0072, 0.0071], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,656][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Mary] are: tensor([0.0082, 0.2079, 0.4635, 0.3204], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,657][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Mary] are: tensor([0.0285, 0.3170, 0.3287, 0.3257], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,658][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Mary] are: tensor([0.9933, 0.0011, 0.0036, 0.0020], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,660][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Mary] are: tensor([0.0210, 0.3749, 0.3078, 0.2963], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,661][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Mary] are: tensor([0.0624, 0.3163, 0.2671, 0.3542], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,662][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0815, 0.0959, 0.1869, 0.3156, 0.3202], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,663][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0098, 0.2117, 0.2235, 0.4485, 0.1066], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,665][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0920, 0.2906, 0.2367, 0.3100, 0.0706], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,666][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.2553, 0.1941, 0.2409, 0.0853, 0.2244], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,667][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.3661, 0.1333, 0.1923, 0.1154, 0.1928], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,667][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0174, 0.2636, 0.2388, 0.2321, 0.2481], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,668][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.6824, 0.1012, 0.0359, 0.0872, 0.0933], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,668][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0073, 0.1634, 0.4060, 0.2320, 0.1914], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,668][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0230, 0.2282, 0.2290, 0.2781, 0.2418], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,669][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ went] are: tensor([9.9402e-01, 8.1763e-04, 2.6855e-03, 1.4635e-03, 1.0162e-03],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,669][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0161, 0.2819, 0.2298, 0.2220, 0.2502], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,669][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0529, 0.2217, 0.1988, 0.1607, 0.3658], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,670][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0844, 0.0970, 0.1832, 0.2246, 0.2017, 0.2092], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,671][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0044, 0.4783, 0.0301, 0.2374, 0.2431, 0.0066], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,672][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1451, 0.2381, 0.1155, 0.3249, 0.1268, 0.0497], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,674][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0607, 0.1492, 0.0340, 0.0304, 0.7037, 0.0221], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,675][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.8420, 0.0032, 0.0032, 0.0049, 0.0223, 0.1245], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,676][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0210, 0.2008, 0.1831, 0.1764, 0.2171, 0.2015], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,678][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.9029, 0.0080, 0.0021, 0.0144, 0.0565, 0.0161], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,679][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0056, 0.1371, 0.2495, 0.1775, 0.1523, 0.2780], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,681][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0163, 0.1916, 0.1633, 0.2333, 0.2297, 0.1659], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,681][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.8997e-01, 9.7112e-04, 2.9536e-03, 2.0773e-03, 1.4066e-03, 2.6193e-03],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,683][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0114, 0.2326, 0.1904, 0.1808, 0.2010, 0.1837], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,684][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0426, 0.1630, 0.1979, 0.1550, 0.2791, 0.1624], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,686][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0525, 0.0755, 0.2004, 0.1732, 0.1590, 0.1653, 0.1740],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,687][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0104, 0.3972, 0.0917, 0.2068, 0.2364, 0.0304, 0.0271],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,689][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1023, 0.1357, 0.1527, 0.1569, 0.0830, 0.3288, 0.0406],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,690][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1265, 0.0782, 0.0165, 0.0263, 0.6759, 0.0214, 0.0551],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,691][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.3346, 0.0151, 0.0109, 0.0087, 0.0420, 0.5538, 0.0348],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,693][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0166, 0.1679, 0.1555, 0.1363, 0.1766, 0.1934, 0.1537],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,694][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.8696, 0.0188, 0.0034, 0.0148, 0.0487, 0.0336, 0.0112],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,696][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0048, 0.1007, 0.2178, 0.1408, 0.1206, 0.2432, 0.1721],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,697][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0174, 0.1623, 0.1394, 0.1789, 0.1962, 0.1587, 0.1472],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,698][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ the] are: tensor([9.9101e-01, 7.9553e-04, 2.5743e-03, 1.4920e-03, 9.8463e-04, 2.1674e-03,
        9.7863e-04], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,699][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0103, 0.1995, 0.1620, 0.1547, 0.1733, 0.1587, 0.1416],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,701][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0376, 0.1546, 0.1566, 0.1558, 0.2424, 0.1075, 0.1456],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,702][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.0440, 0.0621, 0.1397, 0.2070, 0.1666, 0.1236, 0.1613, 0.0957],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,704][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([0.0137, 0.3111, 0.0944, 0.2264, 0.2315, 0.0456, 0.0498, 0.0274],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,705][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.1423, 0.1130, 0.0734, 0.2272, 0.0919, 0.2060, 0.0683, 0.0779],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,707][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.0354, 0.0745, 0.0776, 0.0320, 0.2033, 0.0754, 0.4219, 0.0799],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,708][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.0288, 0.0121, 0.0095, 0.0048, 0.0296, 0.8225, 0.0805, 0.0121],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,709][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.0098, 0.1449, 0.1253, 0.1194, 0.1584, 0.1460, 0.1316, 0.1645],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,711][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.5321, 0.0453, 0.0123, 0.0366, 0.1203, 0.0995, 0.1089, 0.0449],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,712][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.0021, 0.0772, 0.1928, 0.1072, 0.1073, 0.2250, 0.1497, 0.1387],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,714][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.0085, 0.1292, 0.1138, 0.1529, 0.1712, 0.1288, 0.1436, 0.1520],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,714][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([9.8958e-01, 7.4805e-04, 2.4630e-03, 1.6385e-03, 1.1004e-03, 2.2322e-03,
        1.0521e-03, 1.1828e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,714][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.0094, 0.1677, 0.1407, 0.1348, 0.1499, 0.1357, 0.1202, 0.1415],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,715][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.0295, 0.1489, 0.1156, 0.1186, 0.1864, 0.0763, 0.0849, 0.2399],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,715][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0721, 0.0511, 0.1572, 0.0947, 0.1036, 0.1487, 0.1469, 0.1153, 0.1105],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,716][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0098, 0.4924, 0.0384, 0.2027, 0.1277, 0.0118, 0.0366, 0.0714, 0.0090],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,716][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0537, 0.1181, 0.0366, 0.1584, 0.1073, 0.1036, 0.1371, 0.2572, 0.0281],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,716][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0355, 0.0544, 0.0043, 0.0120, 0.4518, 0.0113, 0.1299, 0.2985, 0.0025],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,718][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.8107, 0.0023, 0.0016, 0.0012, 0.0125, 0.0827, 0.0128, 0.0019, 0.0745],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,719][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0127, 0.1202, 0.1111, 0.1024, 0.1399, 0.1316, 0.1180, 0.1537, 0.1103],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,720][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.8259, 0.0096, 0.0019, 0.0098, 0.0309, 0.0174, 0.0231, 0.0305, 0.0509],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,722][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0035, 0.0754, 0.1586, 0.1046, 0.0876, 0.1740, 0.1289, 0.1110, 0.1563],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,723][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0108, 0.1130, 0.0948, 0.1410, 0.1492, 0.1094, 0.1236, 0.1600, 0.0982],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,725][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9853, 0.0010, 0.0031, 0.0020, 0.0014, 0.0028, 0.0013, 0.0014, 0.0018],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,726][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0073, 0.1519, 0.1239, 0.1179, 0.1333, 0.1207, 0.1070, 0.1254, 0.1126],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,727][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0250, 0.1119, 0.1278, 0.1105, 0.1672, 0.0875, 0.0894, 0.1900, 0.0906],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,729][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.0415, 0.0375, 0.1339, 0.0897, 0.1235, 0.1317, 0.1301, 0.1033, 0.0934,
        0.1153], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,730][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.0104, 0.1149, 0.1120, 0.2372, 0.1980, 0.0549, 0.0521, 0.0854, 0.0815,
        0.0536], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,731][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.1385, 0.0351, 0.0787, 0.1250, 0.0984, 0.1937, 0.0776, 0.1219, 0.0652,
        0.0660], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,733][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.0283, 0.0201, 0.0212, 0.0070, 0.1225, 0.0665, 0.5620, 0.1271, 0.0292,
        0.0163], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,734][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.0328, 0.0032, 0.0024, 0.0023, 0.0145, 0.2096, 0.0423, 0.0104, 0.6693,
        0.0132], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,736][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.0069, 0.0882, 0.0917, 0.1049, 0.1306, 0.1109, 0.0988, 0.1479, 0.0984,
        0.1217], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,737][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.3845, 0.0279, 0.0051, 0.0296, 0.0669, 0.0324, 0.0857, 0.1116, 0.2167,
        0.0397], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,739][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0018, 0.0568, 0.1461, 0.0926, 0.0733, 0.1561, 0.1170, 0.1166, 0.1574,
        0.0822], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,740][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.0056, 0.0757, 0.0880, 0.1105, 0.1369, 0.1057, 0.1110, 0.1288, 0.1053,
        0.1324], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,741][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([9.8659e-01, 8.2895e-04, 2.6196e-03, 1.6496e-03, 1.1211e-03, 2.3087e-03,
        1.0548e-03, 1.1758e-03, 1.4976e-03, 1.1511e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,742][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0072, 0.1353, 0.1102, 0.1059, 0.1194, 0.1082, 0.0950, 0.1126, 0.1000,
        0.1060], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,744][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.0153, 0.1162, 0.0963, 0.1151, 0.1640, 0.0613, 0.0805, 0.1812, 0.0645,
        0.1056], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,745][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0640, 0.0433, 0.1152, 0.1389, 0.1039, 0.1022, 0.1176, 0.0705, 0.0858,
        0.0794, 0.0792], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,747][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0051, 0.2011, 0.0754, 0.3161, 0.0835, 0.0167, 0.0564, 0.1010, 0.0297,
        0.0984, 0.0165], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,748][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0375, 0.0794, 0.0642, 0.1422, 0.0478, 0.1228, 0.0962, 0.2202, 0.0658,
        0.1056, 0.0184], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,750][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0469, 0.0458, 0.0348, 0.0094, 0.0674, 0.0357, 0.5654, 0.1035, 0.0310,
        0.0294, 0.0308], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,751][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1263, 0.0093, 0.0055, 0.0039, 0.0228, 0.2810, 0.0443, 0.0079, 0.4511,
        0.0120, 0.0359], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,752][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0083, 0.0874, 0.0820, 0.0774, 0.1006, 0.1000, 0.0924, 0.1380, 0.0948,
        0.1114, 0.1078], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,754][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.4202, 0.0280, 0.0058, 0.0261, 0.0557, 0.0561, 0.0475, 0.0580, 0.1883,
        0.0310, 0.0834], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,755][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0014, 0.0574, 0.1394, 0.0770, 0.0722, 0.1569, 0.1069, 0.0931, 0.1543,
        0.0769, 0.0645], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,756][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0072, 0.0825, 0.0740, 0.1039, 0.1112, 0.0895, 0.0963, 0.1142, 0.0904,
        0.1322, 0.0986], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,757][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([9.8670e-01, 7.5491e-04, 2.4591e-03, 1.5812e-03, 1.0546e-03, 2.0994e-03,
        9.5856e-04, 1.0434e-03, 1.3754e-03, 1.0638e-03, 9.0826e-04],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,759][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0067, 0.1217, 0.0995, 0.0956, 0.1073, 0.0973, 0.0865, 0.1008, 0.0908,
        0.0955, 0.0983], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,760][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0179, 0.0951, 0.0979, 0.0996, 0.1409, 0.0662, 0.0744, 0.1620, 0.0640,
        0.0786, 0.1034], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,761][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0329, 0.0345, 0.1144, 0.0957, 0.0861, 0.1003, 0.1254, 0.0840, 0.0907,
        0.0845, 0.0826, 0.0689], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,761][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0074, 0.3037, 0.0653, 0.1552, 0.1222, 0.0235, 0.0284, 0.1001, 0.0381,
        0.0889, 0.0403, 0.0268], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,761][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0589, 0.0549, 0.0743, 0.1216, 0.0627, 0.1425, 0.0584, 0.2112, 0.0698,
        0.0958, 0.0252, 0.0245], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,762][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0546, 0.0316, 0.0152, 0.0170, 0.1811, 0.0196, 0.0592, 0.3248, 0.0123,
        0.0253, 0.2415, 0.0179], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,762][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.7199, 0.0035, 0.0016, 0.0021, 0.0157, 0.0730, 0.0119, 0.0020, 0.0846,
        0.0032, 0.0143, 0.0682], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,763][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0097, 0.0819, 0.0787, 0.0709, 0.0906, 0.0935, 0.0791, 0.1099, 0.0869,
        0.1011, 0.1082, 0.0895], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,763][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.7698, 0.0102, 0.0016, 0.0118, 0.0304, 0.0179, 0.0079, 0.0203, 0.0469,
        0.0125, 0.0524, 0.0182], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,763][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0020, 0.0520, 0.1205, 0.0763, 0.0746, 0.1315, 0.0947, 0.0905, 0.1315,
        0.0673, 0.0773, 0.0819], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,764][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0071, 0.0797, 0.0715, 0.0912, 0.1053, 0.0834, 0.0807, 0.1054, 0.0812,
        0.1166, 0.1112, 0.0668], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,765][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([9.8329e-01, 8.3789e-04, 2.7608e-03, 1.8261e-03, 1.2522e-03, 2.4603e-03,
        1.1439e-03, 1.2528e-03, 1.6046e-03, 1.2477e-03, 1.0771e-03, 1.2471e-03],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,766][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0061, 0.1097, 0.0912, 0.0865, 0.0969, 0.0887, 0.0789, 0.0916, 0.0830,
        0.0866, 0.0898, 0.0911], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,768][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0200, 0.0877, 0.0838, 0.0885, 0.1416, 0.0633, 0.0784, 0.1498, 0.0610,
        0.0777, 0.0794, 0.0689], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,769][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0241, 0.0318, 0.0945, 0.0880, 0.0802, 0.0867, 0.1010, 0.0824, 0.0640,
        0.0836, 0.0774, 0.0606, 0.1257], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,770][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0143, 0.1751, 0.0698, 0.2414, 0.1793, 0.0355, 0.0547, 0.0347, 0.0325,
        0.0567, 0.0654, 0.0280, 0.0128], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,771][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0473, 0.0630, 0.0376, 0.1740, 0.0817, 0.1494, 0.0452, 0.0833, 0.0891,
        0.1311, 0.0230, 0.0445, 0.0308], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,773][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0390, 0.0214, 0.0278, 0.0133, 0.0741, 0.0532, 0.3605, 0.0290, 0.0261,
        0.0220, 0.0821, 0.2444, 0.0069], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,774][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0492, 0.0039, 0.0017, 0.0015, 0.0054, 0.1491, 0.0146, 0.0040, 0.2673,
        0.0079, 0.0393, 0.4285, 0.0277], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,776][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0069, 0.0741, 0.0659, 0.0702, 0.0850, 0.0833, 0.0712, 0.1002, 0.0699,
        0.0906, 0.1078, 0.0820, 0.0929], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,777][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.7161, 0.0216, 0.0015, 0.0069, 0.0239, 0.0114, 0.0115, 0.0125, 0.0537,
        0.0210, 0.0411, 0.0420, 0.0367], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,778][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0024, 0.0506, 0.1040, 0.0713, 0.0582, 0.1189, 0.0910, 0.0815, 0.1131,
        0.0701, 0.0567, 0.0840, 0.0981], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,780][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.0068, 0.0692, 0.0631, 0.0926, 0.0949, 0.0688, 0.0764, 0.0928, 0.0688,
        0.1019, 0.1033, 0.0706, 0.0907], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,781][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.9732, 0.0015, 0.0042, 0.0024, 0.0016, 0.0035, 0.0016, 0.0019, 0.0023,
        0.0018, 0.0015, 0.0018, 0.0025], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,783][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0066, 0.0979, 0.0821, 0.0789, 0.0875, 0.0803, 0.0714, 0.0847, 0.0753,
        0.0797, 0.0817, 0.0827, 0.0914], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,784][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0225, 0.0988, 0.0783, 0.0732, 0.1417, 0.0523, 0.0704, 0.1377, 0.0550,
        0.0721, 0.0722, 0.0468, 0.0790], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,786][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0329, 0.0353, 0.0958, 0.0894, 0.0806, 0.0810, 0.0978, 0.0750, 0.0698,
        0.0734, 0.0671, 0.0515, 0.0793, 0.0714], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,787][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0034, 0.3799, 0.0192, 0.1324, 0.1499, 0.0039, 0.0342, 0.0535, 0.0105,
        0.0734, 0.0359, 0.0473, 0.0526, 0.0038], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,788][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0388, 0.0694, 0.0317, 0.1234, 0.0552, 0.0191, 0.0964, 0.1596, 0.0483,
        0.1343, 0.0155, 0.0555, 0.1393, 0.0135], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,790][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0202, 0.0525, 0.0103, 0.0068, 0.2400, 0.0058, 0.0448, 0.2256, 0.0159,
        0.0260, 0.1537, 0.0547, 0.1226, 0.0210], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,791][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([7.4019e-01, 1.3276e-03, 6.2654e-04, 6.8979e-04, 5.6115e-03, 2.6782e-02,
        6.0926e-03, 9.0199e-04, 4.3418e-02, 1.1887e-03, 7.0126e-03, 6.2390e-02,
        1.0249e-02, 9.3524e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,792][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0069, 0.0692, 0.0634, 0.0611, 0.0779, 0.0701, 0.0725, 0.0892, 0.0702,
        0.0870, 0.0865, 0.0828, 0.0966, 0.0666], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,794][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.6263, 0.0050, 0.0008, 0.0065, 0.0236, 0.0080, 0.0122, 0.0122, 0.0430,
        0.0078, 0.0383, 0.0339, 0.1180, 0.0643], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,795][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0016, 0.0493, 0.0944, 0.0642, 0.0596, 0.1053, 0.0791, 0.0666, 0.0982,
        0.0612, 0.0545, 0.0714, 0.0857, 0.1088], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,797][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0055, 0.0684, 0.0548, 0.0832, 0.0849, 0.0577, 0.0725, 0.0940, 0.0632,
        0.1044, 0.0899, 0.0690, 0.1013, 0.0512], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,798][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.9697, 0.0013, 0.0037, 0.0026, 0.0018, 0.0034, 0.0017, 0.0018, 0.0023,
        0.0018, 0.0016, 0.0018, 0.0030, 0.0035], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,799][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0050, 0.0934, 0.0768, 0.0725, 0.0810, 0.0743, 0.0660, 0.0771, 0.0695,
        0.0729, 0.0754, 0.0766, 0.0848, 0.0749], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,801][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0187, 0.0670, 0.0830, 0.0712, 0.1212, 0.0724, 0.0629, 0.1128, 0.0594,
        0.0577, 0.0731, 0.0563, 0.0749, 0.0693], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,824][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:22,825][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,825][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,826][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,826][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,826][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,827][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,827][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,827][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,827][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,828][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,828][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,828][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:22,829][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.9713, 0.0287], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,829][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([9.9929e-01, 7.0677e-04], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,829][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.9640, 0.0360], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,830][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.8721, 0.1279], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,830][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.9685, 0.0315], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,830][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.9902, 0.0098], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,831][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.9794, 0.0206], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,831][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.9468, 0.0532], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,831][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.9872, 0.0128], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,832][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.4628, 0.5372], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,832][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.9779, 0.0221], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,832][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.9792, 0.0208], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:22,833][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9365, 0.0304, 0.0331], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,833][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([9.9961e-01, 3.5143e-04, 3.6041e-05], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,833][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.6578, 0.2882, 0.0540], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,834][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.6925, 0.2271, 0.0804], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,834][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.8529, 0.0871, 0.0600], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,834][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9681, 0.0290, 0.0029], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,835][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.9531, 0.0326, 0.0144], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,835][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.8106, 0.1519, 0.0375], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,836][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9687, 0.0229, 0.0085], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,838][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4380, 0.4027, 0.1593], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,839][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9801, 0.0132, 0.0066], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,840][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.9834, 0.0031, 0.0135], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:22,842][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Mary] are: tensor([0.9219, 0.0248, 0.0207, 0.0326], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,842][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Mary] are: tensor([9.9713e-01, 1.7927e-03, 3.4770e-04, 7.3416e-04], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,844][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Mary] are: tensor([0.5430, 0.2952, 0.0417, 0.1202], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,845][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Mary] are: tensor([0.4568, 0.2617, 0.0969, 0.1846], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,847][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Mary] are: tensor([0.6254, 0.1422, 0.0984, 0.1340], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,848][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Mary] are: tensor([0.9818, 0.0128, 0.0027, 0.0027], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,849][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Mary] are: tensor([0.9618, 0.0239, 0.0072, 0.0071], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,851][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Mary] are: tensor([0.5087, 0.2338, 0.0362, 0.2213], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,852][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Mary] are: tensor([0.9683, 0.0140, 0.0092, 0.0086], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,854][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Mary] are: tensor([0.3567, 0.5023, 0.0893, 0.0517], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,855][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Mary] are: tensor([0.9318, 0.0071, 0.0060, 0.0551], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,856][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Mary] are: tensor([0.9404, 0.0086, 0.0257, 0.0253], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:22,858][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.6729, 0.1149, 0.0492, 0.1486, 0.0144], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,859][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([9.8625e-01, 5.8529e-03, 6.7752e-04, 5.6752e-03, 1.5459e-03],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,860][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.3875, 0.3082, 0.0446, 0.1516, 0.1082], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,861][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.3381, 0.2401, 0.0928, 0.2385, 0.0904], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,863][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.5791, 0.0811, 0.0435, 0.0835, 0.2129], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,864][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.7421, 0.1459, 0.0193, 0.0762, 0.0165], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,866][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.6824, 0.1012, 0.0359, 0.0872, 0.0933], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,866][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.7641, 0.0407, 0.0284, 0.0567, 0.1101], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,866][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.8662, 0.0403, 0.0137, 0.0508, 0.0290], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,867][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.5013, 0.2033, 0.0693, 0.1640, 0.0621], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,867][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.9406, 0.0193, 0.0078, 0.0278, 0.0045], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,867][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.8668, 0.0129, 0.0380, 0.0158, 0.0665], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:22,868][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.9116, 0.0165, 0.0163, 0.0276, 0.0064, 0.0215], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,868][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([9.9789e-01, 4.5899e-04, 5.3959e-05, 6.4633e-04, 9.1624e-04, 3.4812e-05],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,868][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.6401, 0.0698, 0.0118, 0.0657, 0.0700, 0.1426], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,869][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.6175, 0.0767, 0.0215, 0.1023, 0.0573, 0.1247], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,869][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.7070, 0.0183, 0.0080, 0.0347, 0.1255, 0.1064], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,869][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.9200, 0.0252, 0.0039, 0.0242, 0.0241, 0.0026], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,871][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.9029, 0.0080, 0.0021, 0.0144, 0.0565, 0.0161], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,872][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.6204, 0.0560, 0.0121, 0.0584, 0.0669, 0.1862], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,873][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.9463, 0.0063, 0.0018, 0.0131, 0.0241, 0.0084], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,875][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1935, 0.1266, 0.0806, 0.2666, 0.1995, 0.1332], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,876][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.9640, 0.0111, 0.0039, 0.0110, 0.0021, 0.0079], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,877][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.9509, 0.0028, 0.0088, 0.0082, 0.0138, 0.0154], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:22,879][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.8468, 0.0346, 0.0220, 0.0458, 0.0111, 0.0315, 0.0083],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,879][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([9.9561e-01, 1.1779e-03, 1.3399e-04, 1.5842e-03, 1.3583e-03, 8.4272e-05,
        5.2742e-05], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,881][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.3535, 0.1509, 0.0189, 0.0532, 0.0673, 0.2531, 0.1032],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,882][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.3873, 0.1105, 0.0275, 0.1003, 0.0568, 0.1668, 0.1507],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,884][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.4747, 0.0344, 0.0135, 0.0303, 0.1471, 0.2484, 0.0517],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,885][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.9164, 0.0246, 0.0040, 0.0322, 0.0127, 0.0055, 0.0045],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,886][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.8696, 0.0188, 0.0034, 0.0148, 0.0487, 0.0336, 0.0112],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,888][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.5973, 0.0457, 0.0160, 0.0265, 0.0540, 0.1823, 0.0782],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,889][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.8124, 0.0225, 0.0063, 0.0323, 0.0585, 0.0499, 0.0182],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,891][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.3557, 0.2110, 0.0583, 0.1001, 0.0582, 0.1106, 0.1060],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,892][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.9763, 0.0057, 0.0027, 0.0065, 0.0012, 0.0052, 0.0025],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,893][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.8752, 0.0052, 0.0141, 0.0108, 0.0243, 0.0243, 0.0462],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:22,894][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.6014, 0.0937, 0.0570, 0.1063, 0.0165, 0.0841, 0.0285, 0.0125],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,895][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([9.9475e-01, 1.5154e-03, 1.3360e-04, 1.6336e-03, 1.1312e-03, 1.3545e-04,
        1.3375e-04, 5.6224e-04], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,897][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([0.2435, 0.0957, 0.0103, 0.0455, 0.0894, 0.1892, 0.1926, 0.1338],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,898][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.1058, 0.1180, 0.0332, 0.0933, 0.0503, 0.2151, 0.2481, 0.1362],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,900][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.3371, 0.0288, 0.0093, 0.0206, 0.1990, 0.1658, 0.1141, 0.1253],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,901][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.8371, 0.0483, 0.0059, 0.0527, 0.0159, 0.0066, 0.0168, 0.0167],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,902][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.5321, 0.0453, 0.0123, 0.0366, 0.1203, 0.0995, 0.1089, 0.0449],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,904][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.5985, 0.0606, 0.0085, 0.0229, 0.0576, 0.1071, 0.0777, 0.0672],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,905][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.7841, 0.0261, 0.0050, 0.0310, 0.0380, 0.0358, 0.0516, 0.0283],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,907][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.2241, 0.1020, 0.0460, 0.1571, 0.1802, 0.1045, 0.1563, 0.0298],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,908][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.9662, 0.0082, 0.0020, 0.0051, 0.0019, 0.0045, 0.0036, 0.0085],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,909][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.8889, 0.0050, 0.0168, 0.0058, 0.0152, 0.0288, 0.0258, 0.0138],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:22,910][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.6377, 0.0518, 0.0446, 0.0622, 0.0201, 0.0845, 0.0305, 0.0175, 0.0512],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,911][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([9.9078e-01, 1.8032e-03, 2.4516e-04, 2.1556e-03, 3.4908e-03, 1.8612e-04,
        1.6999e-04, 9.9765e-04, 1.6936e-04], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,913][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2418, 0.0723, 0.0106, 0.0493, 0.0590, 0.1273, 0.1138, 0.1233, 0.2025],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,913][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.2041, 0.0736, 0.0124, 0.0663, 0.0410, 0.0869, 0.1176, 0.1307, 0.2673],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,914][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3090, 0.0145, 0.0065, 0.0183, 0.1257, 0.1005, 0.0792, 0.1551, 0.1913],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,914][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.7108, 0.0413, 0.0114, 0.0651, 0.0732, 0.0102, 0.0198, 0.0558, 0.0124],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,914][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.8259, 0.0096, 0.0019, 0.0098, 0.0309, 0.0174, 0.0231, 0.0305, 0.0509],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,915][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4960, 0.0326, 0.0081, 0.0293, 0.0289, 0.1023, 0.0532, 0.0864, 0.1632],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,915][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8027, 0.0130, 0.0036, 0.0233, 0.0565, 0.0228, 0.0247, 0.0292, 0.0242],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,915][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1273, 0.1092, 0.0402, 0.1609, 0.1565, 0.1104, 0.1415, 0.0559, 0.0981],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,916][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.8838, 0.0176, 0.0051, 0.0162, 0.0030, 0.0078, 0.0053, 0.0123, 0.0488],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,916][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.8730, 0.0039, 0.0132, 0.0089, 0.0241, 0.0187, 0.0187, 0.0088, 0.0307],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:22,917][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.4159, 0.0665, 0.0570, 0.0401, 0.0258, 0.0951, 0.0313, 0.0227, 0.0717,
        0.1739], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,918][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([9.8692e-01, 1.6357e-03, 5.0846e-04, 2.0586e-03, 4.9585e-03, 3.0841e-04,
        2.9150e-04, 1.7992e-03, 4.6666e-04, 1.0507e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,919][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.1466, 0.0373, 0.0069, 0.0294, 0.0550, 0.0748, 0.0955, 0.1868, 0.2023,
        0.1655], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,920][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.0530, 0.0385, 0.0094, 0.0683, 0.0385, 0.0605, 0.1318, 0.1339, 0.3123,
        0.1538], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,922][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.1225, 0.0099, 0.0043, 0.0133, 0.1334, 0.0685, 0.1222, 0.2089, 0.2716,
        0.0453], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,923][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.8029, 0.0254, 0.0082, 0.0333, 0.0643, 0.0039, 0.0129, 0.0351, 0.0082,
        0.0057], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,924][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.3845, 0.0279, 0.0051, 0.0296, 0.0669, 0.0324, 0.0857, 0.1116, 0.2167,
        0.0397], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,926][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.4833, 0.0260, 0.0044, 0.0298, 0.0328, 0.0405, 0.0516, 0.1552, 0.1268,
        0.0497], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,927][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.6071, 0.0133, 0.0076, 0.0189, 0.0817, 0.0299, 0.0457, 0.0882, 0.0778,
        0.0299], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,928][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.1246, 0.0896, 0.0350, 0.1300, 0.1399, 0.0634, 0.1152, 0.0643, 0.0848,
        0.1532], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,930][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.8085, 0.0237, 0.0067, 0.0246, 0.0092, 0.0096, 0.0121, 0.0393, 0.0362,
        0.0302], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,931][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.7720, 0.0115, 0.0230, 0.0246, 0.0454, 0.0246, 0.0325, 0.0185, 0.0277,
        0.0202], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:22,933][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.4120, 0.1201, 0.0430, 0.0679, 0.0206, 0.0777, 0.0276, 0.0126, 0.0466,
        0.1420, 0.0298], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,934][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([9.8084e-01, 5.8486e-03, 3.9560e-04, 4.3320e-03, 4.6537e-03, 2.0115e-04,
        2.3858e-04, 1.0276e-03, 1.7701e-04, 1.5659e-03, 7.2009e-04],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,935][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0597, 0.0615, 0.0063, 0.0266, 0.0331, 0.1087, 0.0953, 0.1114, 0.1391,
        0.1379, 0.2204], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,936][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0738, 0.0479, 0.0078, 0.0358, 0.0202, 0.0602, 0.1312, 0.0801, 0.2090,
        0.1528, 0.1812], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,938][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.2412, 0.0211, 0.0053, 0.0171, 0.0897, 0.0733, 0.0779, 0.1076, 0.1896,
        0.0380, 0.1392], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,939][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.6284, 0.0788, 0.0062, 0.0916, 0.0844, 0.0040, 0.0186, 0.0491, 0.0058,
        0.0236, 0.0095], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,941][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.4202, 0.0280, 0.0058, 0.0261, 0.0557, 0.0561, 0.0475, 0.0580, 0.1883,
        0.0310, 0.0834], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,942][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.3847, 0.0236, 0.0047, 0.0184, 0.0209, 0.0830, 0.0385, 0.0711, 0.1859,
        0.0382, 0.1310], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,943][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.8419, 0.0206, 0.0020, 0.0147, 0.0204, 0.0089, 0.0155, 0.0189, 0.0168,
        0.0194, 0.0210], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,945][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.1246, 0.0619, 0.0300, 0.0987, 0.1122, 0.0862, 0.1212, 0.0488, 0.0837,
        0.1519, 0.0807], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,946][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.6754, 0.0307, 0.0104, 0.0323, 0.0038, 0.0165, 0.0104, 0.0136, 0.0793,
        0.0404, 0.0872], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,948][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.7698, 0.0060, 0.0195, 0.0074, 0.0365, 0.0206, 0.0267, 0.0141, 0.0351,
        0.0136, 0.0508], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:22,949][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4742, 0.0474, 0.0455, 0.0383, 0.0192, 0.0828, 0.0221, 0.0149, 0.0536,
        0.1402, 0.0423, 0.0193], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,950][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([9.7119e-01, 4.1724e-03, 9.1409e-04, 4.5695e-03, 6.3410e-03, 4.3217e-04,
        3.6851e-04, 2.5896e-03, 5.7908e-04, 2.9599e-03, 5.5912e-03, 2.9487e-04],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,952][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1446, 0.0486, 0.0051, 0.0229, 0.0234, 0.0600, 0.0463, 0.0509, 0.0837,
        0.0967, 0.1668, 0.2509], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,953][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1298, 0.0389, 0.0065, 0.0388, 0.0201, 0.0454, 0.0589, 0.0479, 0.1453,
        0.1106, 0.1814, 0.1765], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,955][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.4339, 0.0133, 0.0027, 0.0160, 0.0655, 0.0355, 0.0279, 0.0626, 0.0852,
        0.0238, 0.1087, 0.1249], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,956][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.6533, 0.0518, 0.0118, 0.0481, 0.0551, 0.0080, 0.0182, 0.0483, 0.0122,
        0.0146, 0.0691, 0.0094], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,957][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.7698, 0.0102, 0.0016, 0.0118, 0.0304, 0.0179, 0.0079, 0.0203, 0.0469,
        0.0125, 0.0524, 0.0182], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,959][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.6040, 0.0159, 0.0020, 0.0108, 0.0143, 0.0274, 0.0155, 0.0391, 0.0665,
        0.0199, 0.1007, 0.0840], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,960][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.7583, 0.0124, 0.0023, 0.0131, 0.0235, 0.0086, 0.0132, 0.0180, 0.0188,
        0.0152, 0.0879, 0.0287], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,961][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1024, 0.0487, 0.0266, 0.0709, 0.1054, 0.0844, 0.0876, 0.0404, 0.0727,
        0.1230, 0.1245, 0.1134], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,961][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.7839, 0.0109, 0.0054, 0.0116, 0.0019, 0.0077, 0.0042, 0.0059, 0.0511,
        0.0204, 0.0629, 0.0339], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,961][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.7733, 0.0031, 0.0146, 0.0059, 0.0186, 0.0166, 0.0186, 0.0084, 0.0231,
        0.0096, 0.0208, 0.0875], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:22,962][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.6652, 0.0428, 0.0224, 0.0465, 0.0081, 0.0324, 0.0116, 0.0042, 0.0217,
        0.1006, 0.0271, 0.0090, 0.0084], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,962][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([9.8424e-01, 2.0046e-03, 3.4908e-04, 2.8083e-03, 3.0382e-03, 2.8024e-04,
        2.2152e-04, 4.6186e-04, 4.2680e-04, 2.0127e-03, 3.3629e-03, 5.3743e-04,
        2.5383e-04], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,963][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.1404, 0.0134, 0.0009, 0.0066, 0.0088, 0.0256, 0.0231, 0.0312, 0.0615,
        0.0680, 0.1348, 0.3443, 0.1413], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,963][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0664, 0.0238, 0.0036, 0.0166, 0.0082, 0.0338, 0.0428, 0.0366, 0.1158,
        0.0739, 0.1662, 0.2484, 0.1638], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,963][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.2346, 0.0059, 0.0008, 0.0033, 0.0147, 0.0193, 0.0116, 0.0358, 0.0637,
        0.0145, 0.1356, 0.2999, 0.1604], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,964][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.6677, 0.0336, 0.0060, 0.0426, 0.0260, 0.0094, 0.0160, 0.0166, 0.0222,
        0.0264, 0.0945, 0.0274, 0.0116], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,965][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.7161, 0.0216, 0.0015, 0.0069, 0.0239, 0.0114, 0.0115, 0.0125, 0.0537,
        0.0210, 0.0411, 0.0420, 0.0367], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,966][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.4512, 0.0168, 0.0018, 0.0091, 0.0079, 0.0305, 0.0220, 0.0168, 0.1023,
        0.0214, 0.0717, 0.1616, 0.0869], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,968][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.5921, 0.0108, 0.0009, 0.0081, 0.0130, 0.0135, 0.0107, 0.0095, 0.0330,
        0.0311, 0.1417, 0.1133, 0.0223], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,969][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.1360, 0.1103, 0.0420, 0.0691, 0.0305, 0.0672, 0.0645, 0.0467, 0.1068,
        0.1323, 0.0826, 0.0935, 0.0183], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,970][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([9.2934e-01, 2.3236e-03, 1.4004e-03, 3.3266e-03, 5.3324e-04, 3.7964e-03,
        1.7432e-03, 2.2079e-03, 2.3088e-02, 1.1799e-02, 1.2881e-02, 6.1119e-03,
        1.4523e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,971][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.7546, 0.0038, 0.0100, 0.0048, 0.0162, 0.0161, 0.0326, 0.0121, 0.0249,
        0.0158, 0.0246, 0.0477, 0.0366], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:22,973][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.5169, 0.0334, 0.0259, 0.0357, 0.0130, 0.0527, 0.0223, 0.0109, 0.0414,
        0.1324, 0.0277, 0.0215, 0.0278, 0.0385], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,973][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([9.8444e-01, 2.5587e-03, 3.3875e-04, 2.8108e-03, 3.6881e-03, 1.7867e-04,
        2.0871e-04, 1.0237e-03, 2.1127e-04, 9.8701e-04, 2.4232e-03, 2.5270e-04,
        6.8164e-04, 1.9489e-04], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,975][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0768, 0.0175, 0.0016, 0.0085, 0.0105, 0.0184, 0.0233, 0.0247, 0.0452,
        0.0381, 0.0738, 0.1989, 0.3021, 0.1604], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,976][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0651, 0.0155, 0.0025, 0.0145, 0.0111, 0.0195, 0.0310, 0.0246, 0.0830,
        0.0459, 0.1050, 0.1224, 0.1605, 0.2996], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,978][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2299, 0.0046, 0.0010, 0.0052, 0.0193, 0.0124, 0.0151, 0.0339, 0.0486,
        0.0102, 0.0583, 0.1325, 0.2339, 0.1952], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,979][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.6960, 0.0456, 0.0061, 0.0473, 0.0497, 0.0037, 0.0137, 0.0290, 0.0057,
        0.0080, 0.0296, 0.0072, 0.0550, 0.0034], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,981][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.6263, 0.0050, 0.0008, 0.0065, 0.0236, 0.0080, 0.0122, 0.0122, 0.0430,
        0.0078, 0.0383, 0.0339, 0.1180, 0.0643], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,982][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.2246, 0.0134, 0.0016, 0.0091, 0.0100, 0.0304, 0.0191, 0.0215, 0.0715,
        0.0256, 0.0822, 0.1151, 0.1717, 0.2041], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,984][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.7037, 0.0081, 0.0010, 0.0089, 0.0148, 0.0048, 0.0099, 0.0125, 0.0107,
        0.0094, 0.0514, 0.0351, 0.0982, 0.0315], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,985][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0832, 0.0387, 0.0231, 0.0645, 0.0801, 0.0616, 0.0696, 0.0312, 0.0607,
        0.0928, 0.0974, 0.0883, 0.1016, 0.1072], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,987][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.8103, 0.0061, 0.0030, 0.0059, 0.0018, 0.0053, 0.0033, 0.0058, 0.0312,
        0.0151, 0.0586, 0.0190, 0.0066, 0.0279], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,988][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.8200, 0.0017, 0.0089, 0.0037, 0.0127, 0.0133, 0.0117, 0.0049, 0.0161,
        0.0063, 0.0163, 0.0369, 0.0051, 0.0426], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:22,989][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:23:22,990][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[2641],
        [ 853],
        [1238],
        [2407],
        [2550],
        [ 818],
        [1013],
        [1129],
        [ 153],
        [ 475],
        [ 517],
        [ 972],
        [1166],
        [1272]], device='cuda:0')
[2024-07-24 10:23:22,992][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[2392],
        [1757],
        [2063],
        [3332],
        [8589],
        [2656],
        [3292],
        [3740],
        [ 534],
        [1906],
        [1237],
        [2094],
        [2904],
        [2360]], device='cuda:0')
[2024-07-24 10:23:22,993][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[28405],
        [37586],
        [20028],
        [31191],
        [35220],
        [30927],
        [29755],
        [30860],
        [25908],
        [27980],
        [29667],
        [28375],
        [30694],
        [30304]], device='cuda:0')
[2024-07-24 10:23:22,994][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[28517],
        [21201],
        [19235],
        [ 8308],
        [  149],
        [ 2513],
        [ 3165],
        [ 2747],
        [ 4470],
        [ 3232],
        [ 1628],
        [ 7826],
        [ 2788],
        [ 9601]], device='cuda:0')
[2024-07-24 10:23:22,996][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 7800],
        [ 7678],
        [11548],
        [15226],
        [13453],
        [10853],
        [10332],
        [ 9543],
        [11118],
        [11770],
        [12473],
        [12912],
        [12304],
        [13916]], device='cuda:0')
[2024-07-24 10:23:22,997][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 8310],
        [19188],
        [23205],
        [20621],
        [12150],
        [10120],
        [ 9776],
        [19999],
        [15402],
        [23344],
        [23854],
        [14742],
        [20095],
        [15911]], device='cuda:0')
[2024-07-24 10:23:22,998][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[21019],
        [20710],
        [19070],
        [21641],
        [18663],
        [19673],
        [16682],
        [15859],
        [18441],
        [12696],
        [13618],
        [15957],
        [ 9596],
        [16632]], device='cuda:0')
[2024-07-24 10:23:23,000][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[709],
        [ 55],
        [ 43],
        [ 32],
        [ 45],
        [ 54],
        [ 52],
        [ 58],
        [ 57],
        [ 50],
        [ 51],
        [ 52],
        [ 57],
        [ 56]], device='cuda:0')
[2024-07-24 10:23:23,001][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[42632],
        [42872],
        [43000],
        [43050],
        [40384],
        [41806],
        [42042],
        [33671],
        [40825],
        [26045],
        [26352],
        [38211],
        [36628],
        [32612]], device='cuda:0')
[2024-07-24 10:23:23,002][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[18957],
        [36021],
        [40281],
        [34556],
        [33860],
        [34935],
        [36582],
        [33722],
        [32152],
        [32358],
        [31947],
        [32284],
        [31034],
        [32144]], device='cuda:0')
[2024-07-24 10:23:23,004][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[15111],
        [ 8498],
        [11155],
        [12441],
        [12194],
        [12377],
        [12456],
        [12250],
        [12580],
        [12568],
        [12561],
        [12538],
        [12964],
        [13009]], device='cuda:0')
[2024-07-24 10:23:23,005][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[36901],
        [36888],
        [36902],
        [36903],
        [36904],
        [36897],
        [36906],
        [36890],
        [36878],
        [36882],
        [36883],
        [36870],
        [36812],
        [36806]], device='cuda:0')
[2024-07-24 10:23:23,006][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[15361],
        [17277],
        [14482],
        [13931],
        [13463],
        [13560],
        [13155],
        [12704],
        [12318],
        [12239],
        [12103],
        [11987],
        [12065],
        [12237]], device='cuda:0')
[2024-07-24 10:23:23,008][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[2239],
        [1562],
        [1522],
        [6832],
        [3883],
        [3503],
        [4509],
        [4492],
        [4584],
        [4901],
        [5311],
        [4990],
        [4265],
        [3971]], device='cuda:0')
[2024-07-24 10:23:23,009][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 5065],
        [35272],
        [17677],
        [26820],
        [33605],
        [28875],
        [26510],
        [28531],
        [12388],
        [20968],
        [31485],
        [21358],
        [27907],
        [19542]], device='cuda:0')
[2024-07-24 10:23:23,011][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[33905],
        [35573],
        [37467],
        [36924],
        [37629],
        [38145],
        [40474],
        [41939],
        [43910],
        [41901],
        [40876],
        [42618],
        [42048],
        [43416]], device='cuda:0')
[2024-07-24 10:23:23,011][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[14185],
        [14189],
        [14190],
        [14256],
        [14548],
        [14242],
        [14293],
        [14296],
        [14375],
        [14432],
        [14619],
        [14786],
        [14531],
        [14525]], device='cuda:0')
[2024-07-24 10:23:23,012][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[27113],
        [25898],
        [29187],
        [31516],
        [30116],
        [36055],
        [36575],
        [34966],
        [36411],
        [35450],
        [35286],
        [38218],
        [39643],
        [41060]], device='cuda:0')
[2024-07-24 10:23:23,013][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 1140],
        [ 2433],
        [16538],
        [36732],
        [40206],
        [32250],
        [38803],
        [39561],
        [37041],
        [36423],
        [34991],
        [33855],
        [35256],
        [34036]], device='cuda:0')
[2024-07-24 10:23:23,014][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 5164],
        [ 4405],
        [ 3914],
        [ 7210],
        [11103],
        [ 9655],
        [23078],
        [27918],
        [32430],
        [36712],
        [32055],
        [25814],
        [35651],
        [36162]], device='cuda:0')
[2024-07-24 10:23:23,016][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[13282],
        [13758],
        [14849],
        [14155],
        [28415],
        [16694],
        [17265],
        [22564],
        [29167],
        [23581],
        [33169],
        [33252],
        [32878],
        [30321]], device='cuda:0')
[2024-07-24 10:23:23,017][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[26533],
        [26164],
        [26959],
        [26647],
        [35923],
        [32321],
        [33368],
        [43025],
        [36221],
        [41831],
        [43510],
        [38320],
        [39802],
        [43500]], device='cuda:0')
[2024-07-24 10:23:23,018][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[41301],
        [40778],
        [33331],
        [19155],
        [25511],
        [ 8858],
        [ 7532],
        [11686],
        [ 6416],
        [ 9360],
        [ 5279],
        [ 8626],
        [ 3802],
        [ 2240]], device='cuda:0')
[2024-07-24 10:23:23,020][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[42487],
        [42706],
        [43021],
        [42963],
        [44156],
        [43308],
        [44016],
        [43268],
        [43713],
        [31516],
        [43984],
        [43395],
        [34034],
        [41623]], device='cuda:0')
[2024-07-24 10:23:23,021][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[33295],
        [11132],
        [12126],
        [12536],
        [15177],
        [15701],
        [14196],
        [16019],
        [15629],
        [15938],
        [16053],
        [16189],
        [15969],
        [16733]], device='cuda:0')
[2024-07-24 10:23:23,022][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[31851],
        [32405],
        [32949],
        [37798],
        [36324],
        [34600],
        [33810],
        [34593],
        [39325],
        [43464],
        [46607],
        [44137],
        [37695],
        [44333]], device='cuda:0')
[2024-07-24 10:23:23,024][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[12650],
        [14028],
        [12973],
        [18424],
        [20086],
        [14966],
        [18096],
        [17993],
        [19936],
        [29051],
        [29771],
        [30350],
        [31103],
        [25892]], device='cuda:0')
[2024-07-24 10:23:23,025][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[4118],
        [3965],
        [3221],
        [2408],
        [1069],
        [2436],
        [1682],
        [ 852],
        [ 787],
        [ 824],
        [ 490],
        [ 554],
        [1067],
        [ 783]], device='cuda:0')
[2024-07-24 10:23:23,026][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[3141],
        [6114],
        [7639],
        [3837],
        [ 691],
        [6173],
        [3338],
        [1785],
        [6301],
        [2952],
        [1770],
        [4294],
        [2481],
        [3557]], device='cuda:0')
[2024-07-24 10:23:23,028][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[5889],
        [5889],
        [5889],
        [5889],
        [5889],
        [5889],
        [5889],
        [5889],
        [5889],
        [5889],
        [5889],
        [5889],
        [5889],
        [5889]], device='cuda:0')
[2024-07-24 10:23:23,059][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:23,059][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,059][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,060][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,060][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,060][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,061][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,061][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,062][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,063][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,064][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,066][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,067][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,067][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.5990, 0.4010], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,069][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.2150, 0.7850], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,070][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.3704, 0.6296], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,072][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.1157, 0.8843], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,082][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.2663, 0.7337], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,083][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.8549, 0.1451], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,085][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.9978, 0.0022], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,086][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.5518, 0.4482], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,088][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.7393, 0.2607], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,089][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.0983, 0.9017], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,090][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.1821, 0.8179], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,091][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.8971, 0.1029], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,093][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1861, 0.2697, 0.5442], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,094][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.4967, 0.4850, 0.0183], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,095][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2744, 0.4084, 0.3172], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,097][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0609, 0.4780, 0.4611], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,098][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2090, 0.6667, 0.1242], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,100][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.7280, 0.0984, 0.1736], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,101][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.9772, 0.0085, 0.0143], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,102][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3075, 0.3582, 0.3343], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,104][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1065, 0.8543, 0.0391], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,105][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0566, 0.7710, 0.1723], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,105][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1644, 0.1231, 0.7125], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,106][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.8371, 0.1375, 0.0254], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,106][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Mary] are: tensor([0.0454, 0.3012, 0.5903, 0.0632], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,107][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Mary] are: tensor([0.0547, 0.3694, 0.0645, 0.5113], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,107][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Mary] are: tensor([0.2196, 0.2917, 0.2285, 0.2601], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,107][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Mary] are: tensor([0.0397, 0.3453, 0.3302, 0.2848], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,108][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Mary] are: tensor([0.1821, 0.5132, 0.1218, 0.1828], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,108][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Mary] are: tensor([0.5588, 0.0965, 0.1450, 0.1996], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,109][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Mary] are: tensor([0.7448, 0.0749, 0.0842, 0.0961], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,110][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Mary] are: tensor([0.2132, 0.2623, 0.3414, 0.1831], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,111][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Mary] are: tensor([0.2736, 0.3475, 0.2940, 0.0850], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,113][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Mary] are: tensor([0.0929, 0.5116, 0.2633, 0.1322], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,114][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Mary] are: tensor([0.0360, 0.0521, 0.4098, 0.5021], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,116][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Mary] are: tensor([0.7855, 0.1301, 0.0628, 0.0216], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,117][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0715, 0.2221, 0.5279, 0.0584, 0.1202], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,118][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0848, 0.2265, 0.2047, 0.4480, 0.0360], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,120][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.1706, 0.2190, 0.1733, 0.2092, 0.2277], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,121][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0314, 0.2713, 0.2608, 0.2236, 0.2129], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,123][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.1352, 0.4831, 0.1122, 0.1451, 0.1245], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,124][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.5073, 0.0592, 0.0888, 0.1444, 0.2003], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,125][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.6991, 0.0456, 0.0556, 0.0927, 0.1070], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,127][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.1368, 0.2451, 0.3118, 0.1774, 0.1289], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,128][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0580, 0.1345, 0.4009, 0.3921, 0.0145], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,130][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.0467, 0.3814, 0.2478, 0.2093, 0.1148], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,131][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0309, 0.0447, 0.3559, 0.3849, 0.1836], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,132][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.6453, 0.1120, 0.0835, 0.0311, 0.1281], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,134][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0457, 0.2314, 0.4026, 0.0600, 0.1107, 0.1496], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,135][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.3526, 0.2052, 0.0132, 0.2874, 0.1293, 0.0123], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,137][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1512, 0.1984, 0.1536, 0.1629, 0.1841, 0.1497], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,138][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0281, 0.2169, 0.2066, 0.1810, 0.1719, 0.1954], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,140][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1633, 0.3716, 0.0837, 0.1099, 0.1008, 0.1706], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,141][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.3813, 0.0292, 0.0477, 0.1003, 0.1530, 0.2884], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,142][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.8422, 0.0145, 0.0228, 0.0486, 0.0402, 0.0317], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,144][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1208, 0.2292, 0.2239, 0.1463, 0.1103, 0.1695], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,145][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0690, 0.3719, 0.0331, 0.3675, 0.1419, 0.0165], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,147][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0610, 0.3811, 0.1033, 0.1348, 0.2312, 0.0885], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,148][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0787, 0.0616, 0.3046, 0.2565, 0.1376, 0.1611], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,149][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.7399, 0.0763, 0.0191, 0.0166, 0.1308, 0.0173], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,151][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0466, 0.1631, 0.3151, 0.0340, 0.0832, 0.1258, 0.2322],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,152][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.2008, 0.3319, 0.0517, 0.2192, 0.1024, 0.0620, 0.0320],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,153][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1329, 0.1560, 0.1245, 0.1462, 0.1635, 0.1227, 0.1541],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,153][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0229, 0.1811, 0.1739, 0.1511, 0.1450, 0.1635, 0.1625],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,154][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0887, 0.3730, 0.0810, 0.1362, 0.1154, 0.1577, 0.0481],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,154][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.3129, 0.0342, 0.0528, 0.0906, 0.1205, 0.2324, 0.1566],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,154][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.6860, 0.0256, 0.0386, 0.0619, 0.0636, 0.0485, 0.0757],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,155][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1197, 0.1848, 0.2002, 0.1249, 0.0933, 0.1525, 0.1245],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,155][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0613, 0.1359, 0.1175, 0.2196, 0.1818, 0.2669, 0.0170],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,155][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0245, 0.3385, 0.1236, 0.0863, 0.1375, 0.1674, 0.1222],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,156][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0211, 0.0175, 0.2104, 0.1978, 0.0794, 0.0921, 0.3816],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,157][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.7692, 0.0523, 0.0208, 0.0105, 0.1046, 0.0240, 0.0186],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,159][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.0407, 0.1494, 0.3179, 0.0259, 0.0763, 0.1094, 0.1987, 0.0816],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,160][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([0.0117, 0.4012, 0.0411, 0.0955, 0.4319, 0.0105, 0.0042, 0.0039],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,162][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.1042, 0.1435, 0.1120, 0.1212, 0.1394, 0.1134, 0.1349, 0.1314],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,163][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.0169, 0.1591, 0.1536, 0.1325, 0.1276, 0.1451, 0.1452, 0.1199],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,164][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.0512, 0.3118, 0.0835, 0.1555, 0.1343, 0.1640, 0.0559, 0.0438],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,166][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.3493, 0.0156, 0.0275, 0.0738, 0.0944, 0.1560, 0.1292, 0.1543],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,167][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.8141, 0.0114, 0.0171, 0.0365, 0.0336, 0.0235, 0.0333, 0.0304],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,169][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.0747, 0.1581, 0.1996, 0.1138, 0.0883, 0.1486, 0.1293, 0.0875],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,170][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.1027, 0.1022, 0.1224, 0.2843, 0.0696, 0.1666, 0.1075, 0.0446],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,172][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.0037, 0.2481, 0.1095, 0.1611, 0.1883, 0.1350, 0.0949, 0.0593],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,173][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.0137, 0.0108, 0.1023, 0.1308, 0.0439, 0.1039, 0.3921, 0.2025],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,174][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.3521, 0.1156, 0.0841, 0.0298, 0.1664, 0.0736, 0.0759, 0.1025],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,176][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0279, 0.1348, 0.2591, 0.0359, 0.0731, 0.1027, 0.1760, 0.0792, 0.1113],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,177][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.5129, 0.0618, 0.0062, 0.1182, 0.1349, 0.0159, 0.0336, 0.1050, 0.0115],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,179][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0961, 0.1323, 0.1007, 0.1049, 0.1206, 0.1027, 0.1189, 0.1215, 0.1023],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,180][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0154, 0.1419, 0.1358, 0.1179, 0.1117, 0.1296, 0.1279, 0.1051, 0.1147],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,182][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0531, 0.3063, 0.0740, 0.1259, 0.1068, 0.1552, 0.0550, 0.0344, 0.0894],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,183][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.3099, 0.0114, 0.0199, 0.0511, 0.0716, 0.1223, 0.0961, 0.1191, 0.1987],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,185][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.6251, 0.0211, 0.0334, 0.0608, 0.0521, 0.0432, 0.0554, 0.0418, 0.0671],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,186][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0875, 0.1554, 0.1588, 0.1036, 0.0800, 0.1263, 0.1058, 0.0724, 0.1102],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,188][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0264, 0.1865, 0.0321, 0.2941, 0.0873, 0.0766, 0.0626, 0.2279, 0.0065],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,189][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0141, 0.2619, 0.0645, 0.1005, 0.1670, 0.0897, 0.0867, 0.1576, 0.0581],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,190][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0144, 0.0132, 0.1220, 0.1400, 0.0467, 0.0723, 0.2472, 0.1274, 0.2169],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,192][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6671, 0.0647, 0.0147, 0.0146, 0.0902, 0.0193, 0.0308, 0.0865, 0.0121],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,193][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.0139, 0.1090, 0.2139, 0.0298, 0.0614, 0.0816, 0.1930, 0.1173, 0.1568,
        0.0233], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,195][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.0248, 0.0965, 0.0396, 0.4796, 0.0266, 0.0080, 0.0388, 0.0591, 0.0403,
        0.1866], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,196][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.0933, 0.1234, 0.0941, 0.0903, 0.1016, 0.0937, 0.1018, 0.1107, 0.0931,
        0.0979], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,198][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.0123, 0.1298, 0.1240, 0.1072, 0.1015, 0.1184, 0.1168, 0.0958, 0.1051,
        0.0891], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,199][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.0317, 0.2352, 0.0753, 0.1305, 0.1231, 0.1646, 0.0480, 0.0320, 0.0803,
        0.0793], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,200][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.2588, 0.0108, 0.0183, 0.0477, 0.0646, 0.1035, 0.0814, 0.1016, 0.1524,
        0.1610], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,200][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.7087, 0.0157, 0.0221, 0.0381, 0.0333, 0.0284, 0.0373, 0.0344, 0.0466,
        0.0354], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,201][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0782, 0.1351, 0.1621, 0.0884, 0.0682, 0.1224, 0.1081, 0.0639, 0.1157,
        0.0580], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,201][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.1182, 0.0530, 0.1182, 0.1493, 0.0786, 0.1098, 0.0284, 0.1599, 0.0654,
        0.1192], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,202][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.0087, 0.0700, 0.1193, 0.1730, 0.1639, 0.1034, 0.0906, 0.1684, 0.0608,
        0.0418], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,202][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0053, 0.0094, 0.0717, 0.0668, 0.0258, 0.1044, 0.2371, 0.1456, 0.2429,
        0.0910], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,202][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.3251, 0.0913, 0.0556, 0.0319, 0.1150, 0.0649, 0.1012, 0.1380, 0.0419,
        0.0351], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,204][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0169, 0.1073, 0.2404, 0.0290, 0.0700, 0.0936, 0.1669, 0.0764, 0.1261,
        0.0158, 0.0577], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,205][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0217, 0.2136, 0.0198, 0.2314, 0.0206, 0.0107, 0.0337, 0.0500, 0.0749,
        0.3007, 0.0230], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,206][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0803, 0.1093, 0.0836, 0.0888, 0.1009, 0.0851, 0.0996, 0.1013, 0.0855,
        0.0911, 0.0744], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,208][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0115, 0.1173, 0.1129, 0.0978, 0.0926, 0.1093, 0.1080, 0.0874, 0.0968,
        0.0825, 0.0840], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,209][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0455, 0.2642, 0.0578, 0.0973, 0.0802, 0.1350, 0.0516, 0.0279, 0.0818,
        0.0722, 0.0865], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,211][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.1882, 0.0082, 0.0140, 0.0366, 0.0495, 0.0882, 0.0664, 0.0916, 0.1398,
        0.1569, 0.1606], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,212][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.5263, 0.0254, 0.0324, 0.0651, 0.0552, 0.0408, 0.0508, 0.0437, 0.0578,
        0.0473, 0.0551], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,213][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0581, 0.1327, 0.1651, 0.0923, 0.0676, 0.1172, 0.0984, 0.0604, 0.1003,
        0.0580, 0.0501], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,215][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0150, 0.1015, 0.0705, 0.1956, 0.0231, 0.0499, 0.0535, 0.2154, 0.0520,
        0.2191, 0.0043], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,216][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0032, 0.1524, 0.0473, 0.1001, 0.0848, 0.0579, 0.0527, 0.2399, 0.0542,
        0.1281, 0.0794], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,218][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0028, 0.0071, 0.0744, 0.0962, 0.0345, 0.0759, 0.2201, 0.1102, 0.2363,
        0.0552, 0.0874], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,219][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.2742, 0.0988, 0.0543, 0.0247, 0.0864, 0.0499, 0.0902, 0.1465, 0.0508,
        0.0496, 0.0746], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,221][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0146, 0.1140, 0.2247, 0.0297, 0.0629, 0.0914, 0.1486, 0.0687, 0.1118,
        0.0167, 0.0535, 0.0634], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,222][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0570, 0.0774, 0.0176, 0.0844, 0.0350, 0.0277, 0.0501, 0.0877, 0.1060,
        0.3864, 0.0607, 0.0101], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,224][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0796, 0.1006, 0.0778, 0.0810, 0.0906, 0.0781, 0.0895, 0.0923, 0.0776,
        0.0825, 0.0669, 0.0834], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,225][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0115, 0.1076, 0.1037, 0.0896, 0.0847, 0.0991, 0.0973, 0.0799, 0.0877,
        0.0750, 0.0766, 0.0874], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,227][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0504, 0.2335, 0.0550, 0.0892, 0.0755, 0.1149, 0.0470, 0.0282, 0.0767,
        0.0728, 0.0778, 0.0788], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,228][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1622, 0.0063, 0.0110, 0.0305, 0.0395, 0.0707, 0.0524, 0.0686, 0.1148,
        0.1307, 0.1320, 0.1811], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,230][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.5061, 0.0179, 0.0311, 0.0547, 0.0465, 0.0409, 0.0529, 0.0370, 0.0621,
        0.0369, 0.0479, 0.0659], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,231][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0636, 0.1419, 0.1427, 0.0886, 0.0650, 0.1040, 0.0831, 0.0529, 0.0854,
        0.0584, 0.0456, 0.0688], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,232][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0232, 0.1002, 0.0724, 0.1630, 0.0691, 0.0642, 0.0153, 0.1930, 0.0434,
        0.2264, 0.0242, 0.0056], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,234][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0073, 0.1105, 0.0583, 0.0465, 0.0592, 0.0674, 0.0430, 0.3057, 0.0799,
        0.0752, 0.1039, 0.0431], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,236][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0057, 0.0056, 0.0682, 0.0700, 0.0229, 0.0686, 0.2024, 0.1241, 0.2073,
        0.0542, 0.0607, 0.1104], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,237][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.6049, 0.0379, 0.0151, 0.0083, 0.0682, 0.0177, 0.0200, 0.0907, 0.0149,
        0.0231, 0.0871, 0.0121], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,239][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0153, 0.0890, 0.1785, 0.0219, 0.0524, 0.0846, 0.1506, 0.0649, 0.1345,
        0.0148, 0.0538, 0.0821, 0.0576], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,240][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0153, 0.1110, 0.0582, 0.1343, 0.0827, 0.0198, 0.0100, 0.0580, 0.0933,
        0.1122, 0.1743, 0.0669, 0.0640], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,242][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0709, 0.0979, 0.0752, 0.0838, 0.0909, 0.0680, 0.0870, 0.0820, 0.0667,
        0.0720, 0.0579, 0.0729, 0.0749], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,243][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0111, 0.0982, 0.0948, 0.0822, 0.0782, 0.0897, 0.0888, 0.0740, 0.0799,
        0.0691, 0.0702, 0.0798, 0.0842], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,245][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0583, 0.1943, 0.0653, 0.0818, 0.0726, 0.1043, 0.0394, 0.0316, 0.0604,
        0.0671, 0.0632, 0.0604, 0.1012], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,246][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.1612, 0.0104, 0.0138, 0.0305, 0.0347, 0.0615, 0.0433, 0.0685, 0.0869,
        0.1016, 0.1089, 0.1433, 0.1354], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,247][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.2489, 0.0424, 0.0531, 0.0622, 0.0697, 0.0583, 0.0679, 0.0561, 0.0777,
        0.0590, 0.0676, 0.0725, 0.0646], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,247][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0594, 0.1251, 0.1427, 0.0807, 0.0619, 0.0984, 0.0795, 0.0522, 0.0851,
        0.0513, 0.0439, 0.0695, 0.0504], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,248][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.0276, 0.0838, 0.0530, 0.2688, 0.0215, 0.0723, 0.0222, 0.0543, 0.0598,
        0.2293, 0.0169, 0.0213, 0.0693], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,248][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0162, 0.0985, 0.0726, 0.0848, 0.1070, 0.0912, 0.0777, 0.0570, 0.0649,
        0.0702, 0.1728, 0.0440, 0.0431], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,248][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0047, 0.0034, 0.0562, 0.0592, 0.0220, 0.0455, 0.2029, 0.1018, 0.1794,
        0.0331, 0.0466, 0.1058, 0.1395], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,249][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.3943, 0.0574, 0.0471, 0.0209, 0.0804, 0.0408, 0.0513, 0.1061, 0.0346,
        0.0307, 0.0676, 0.0225, 0.0463], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,249][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0190, 0.1208, 0.1906, 0.0265, 0.0539, 0.0794, 0.1258, 0.0576, 0.0961,
        0.0162, 0.0523, 0.0580, 0.0564, 0.0474], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,250][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0877, 0.0509, 0.0067, 0.0651, 0.0331, 0.0031, 0.0163, 0.0437, 0.0416,
        0.2360, 0.0795, 0.0378, 0.2926, 0.0059], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,251][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0646, 0.0907, 0.0686, 0.0672, 0.0764, 0.0698, 0.0767, 0.0821, 0.0694,
        0.0731, 0.0600, 0.0759, 0.0663, 0.0592], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,253][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0098, 0.0911, 0.0873, 0.0764, 0.0723, 0.0837, 0.0826, 0.0681, 0.0740,
        0.0636, 0.0651, 0.0741, 0.0777, 0.0742], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,254][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0394, 0.1691, 0.0485, 0.0801, 0.0696, 0.0990, 0.0440, 0.0283, 0.0655,
        0.0617, 0.0676, 0.0668, 0.0788, 0.0815], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,256][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1380, 0.0052, 0.0080, 0.0222, 0.0291, 0.0390, 0.0342, 0.0441, 0.0625,
        0.0798, 0.0821, 0.1057, 0.1227, 0.2274], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,256][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.4870, 0.0150, 0.0255, 0.0479, 0.0376, 0.0337, 0.0415, 0.0319, 0.0520,
        0.0320, 0.0433, 0.0552, 0.0429, 0.0544], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,258][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0559, 0.1301, 0.1201, 0.0777, 0.0577, 0.0912, 0.0744, 0.0475, 0.0759,
        0.0530, 0.0417, 0.0624, 0.0497, 0.0628], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,259][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0126, 0.1159, 0.0081, 0.1284, 0.0296, 0.0037, 0.0142, 0.1732, 0.0071,
        0.2971, 0.0120, 0.0200, 0.1726, 0.0054], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,261][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0102, 0.1300, 0.0284, 0.0426, 0.0733, 0.0236, 0.0625, 0.1331, 0.0424,
        0.0909, 0.1692, 0.0682, 0.1057, 0.0200], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,262][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0070, 0.0043, 0.0488, 0.0471, 0.0159, 0.0492, 0.1346, 0.0896, 0.1766,
        0.0432, 0.0514, 0.0934, 0.0822, 0.1568], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,264][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.4050, 0.0714, 0.0161, 0.0129, 0.0849, 0.0138, 0.0258, 0.1123, 0.0164,
        0.0387, 0.0755, 0.0231, 0.0869, 0.0172], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,317][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:23,319][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,320][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,320][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,320][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,321][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,321][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,321][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,322][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,322][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,322][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,323][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,323][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,323][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.2303, 0.7697], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,324][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.1919, 0.8081], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,324][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.6896, 0.3104], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,324][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.5925, 0.4075], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,325][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.9485, 0.0515], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,325][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.5156, 0.4844], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,325][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.9887, 0.0113], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,326][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.9422, 0.0578], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,326][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.9988, 0.0012], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,326][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.0816, 0.9184], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,327][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.6240, 0.3760], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,328][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.9345, 0.0655], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,329][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0940, 0.4003, 0.5058], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,331][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0930, 0.4739, 0.4330], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,332][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.6611, 0.1986, 0.1403], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,334][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.5321, 0.1929, 0.2750], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,335][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.7106, 0.1474, 0.1420], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,336][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4287, 0.3421, 0.2292], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,338][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.9811, 0.0055, 0.0134], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,339][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.8535, 0.1082, 0.0383], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,341][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9657, 0.0220, 0.0123], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,342][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0270, 0.4118, 0.5611], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,343][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4576, 0.2720, 0.2704], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,345][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.9064, 0.0738, 0.0198], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,346][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Mary] are: tensor([0.0590, 0.3222, 0.4288, 0.1899], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,348][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Mary] are: tensor([0.0630, 0.3528, 0.3217, 0.2625], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,348][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Mary] are: tensor([0.6635, 0.1504, 0.0990, 0.0871], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,349][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Mary] are: tensor([0.3628, 0.2217, 0.2563, 0.1592], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,349][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Mary] are: tensor([0.4733, 0.2142, 0.1596, 0.1528], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,349][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Mary] are: tensor([0.3267, 0.2609, 0.1841, 0.2284], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,350][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Mary] are: tensor([0.9541, 0.0143, 0.0092, 0.0225], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,350][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Mary] are: tensor([0.8513, 0.0654, 0.0335, 0.0498], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,350][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Mary] are: tensor([0.9820, 0.0070, 0.0065, 0.0044], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,351][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Mary] are: tensor([0.0339, 0.2934, 0.3643, 0.3084], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,351][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Mary] are: tensor([0.3627, 0.2116, 0.2093, 0.2163], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,351][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Mary] are: tensor([0.8578, 0.0727, 0.0337, 0.0358], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,353][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.0543, 0.2480, 0.3188, 0.1569, 0.2219], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,354][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0350, 0.2698, 0.2551, 0.2032, 0.2369], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,355][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.5532, 0.1470, 0.1001, 0.0870, 0.1128], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,357][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.3619, 0.1392, 0.2076, 0.0981, 0.1932], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,358][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.4407, 0.1605, 0.1370, 0.1526, 0.1093], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,359][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.2545, 0.2092, 0.1502, 0.1837, 0.2025], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,361][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.8449, 0.0130, 0.0106, 0.0118, 0.1197], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,362][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.6999, 0.1024, 0.0618, 0.0826, 0.0534], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,364][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.9614, 0.0065, 0.0065, 0.0106, 0.0149], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,365][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.0132, 0.2105, 0.2637, 0.2507, 0.2619], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,366][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.2873, 0.1747, 0.1738, 0.1778, 0.1865], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,368][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.7628, 0.0720, 0.0442, 0.0482, 0.0728], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,369][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0442, 0.1891, 0.2399, 0.1179, 0.1703, 0.2385], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,370][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0346, 0.2209, 0.2068, 0.1679, 0.1898, 0.1800], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,372][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.4261, 0.1413, 0.0941, 0.0786, 0.1025, 0.1575], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,373][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.3098, 0.1089, 0.1399, 0.0753, 0.1662, 0.1999], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,375][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.3674, 0.1487, 0.1532, 0.1401, 0.1142, 0.0765], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,376][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.2032, 0.1703, 0.1228, 0.1503, 0.1666, 0.1868], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,378][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.9129, 0.0094, 0.0117, 0.0119, 0.0146, 0.0394], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,379][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.6977, 0.0603, 0.0190, 0.0802, 0.0406, 0.1021], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,381][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.8980, 0.0045, 0.0031, 0.0092, 0.0173, 0.0678], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,382][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0069, 0.1415, 0.1925, 0.1958, 0.2527, 0.2106], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,383][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.2392, 0.1458, 0.1470, 0.1494, 0.1584, 0.1601], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,385][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.8239, 0.0521, 0.0150, 0.0266, 0.0554, 0.0270], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,386][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0288, 0.1511, 0.1925, 0.0913, 0.1359, 0.1947, 0.2056],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,387][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0275, 0.1949, 0.1730, 0.1399, 0.1616, 0.1497, 0.1533],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,389][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.4527, 0.1072, 0.0738, 0.0600, 0.0812, 0.1296, 0.0955],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,390][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.2398, 0.0817, 0.1085, 0.0578, 0.1455, 0.1712, 0.1954],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,391][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.2394, 0.1931, 0.1525, 0.1543, 0.1115, 0.0724, 0.0766],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,393][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1667, 0.1388, 0.0991, 0.1223, 0.1360, 0.1555, 0.1816],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,394][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.9246, 0.0049, 0.0049, 0.0047, 0.0130, 0.0054, 0.0425],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,395][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.5684, 0.0779, 0.0242, 0.0660, 0.0450, 0.1247, 0.0938],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,396][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.8261, 0.0060, 0.0044, 0.0058, 0.0220, 0.0859, 0.0497],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,396][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0057, 0.1199, 0.1584, 0.1553, 0.1917, 0.1763, 0.1926],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,397][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1951, 0.1265, 0.1262, 0.1301, 0.1370, 0.1363, 0.1488],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,397][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.8463, 0.0310, 0.0126, 0.0175, 0.0397, 0.0261, 0.0267],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,397][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.0292, 0.1290, 0.1678, 0.0737, 0.1199, 0.1650, 0.1788, 0.1366],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,398][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([0.0246, 0.1678, 0.1517, 0.1233, 0.1420, 0.1303, 0.1370, 0.1234],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,398][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([0.4074, 0.0963, 0.0700, 0.0572, 0.0751, 0.1158, 0.0899, 0.0883],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,400][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.1245, 0.0771, 0.1034, 0.0568, 0.1353, 0.1688, 0.1985, 0.1357],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,401][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.1482, 0.1818, 0.1523, 0.1503, 0.1156, 0.0817, 0.0697, 0.1004],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,402][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.1464, 0.1107, 0.0811, 0.1015, 0.1130, 0.1353, 0.1567, 0.1553],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,404][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.2035, 0.0067, 0.0097, 0.0058, 0.0243, 0.0118, 0.0180, 0.7202],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,405][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.3651, 0.0856, 0.0300, 0.0516, 0.0524, 0.1642, 0.1347, 0.1164],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,406][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.7808, 0.0062, 0.0029, 0.0067, 0.0196, 0.0599, 0.0721, 0.0518],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,408][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.0041, 0.0938, 0.1343, 0.1383, 0.1571, 0.1411, 0.1632, 0.1683],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,409][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.1885, 0.1104, 0.1088, 0.1114, 0.1174, 0.1182, 0.1285, 0.1167],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,411][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.5294, 0.0652, 0.0326, 0.0397, 0.0623, 0.0581, 0.0824, 0.1303],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,412][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0201, 0.1157, 0.1463, 0.0675, 0.1041, 0.1411, 0.1567, 0.1275, 0.1210],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,413][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0207, 0.1459, 0.1354, 0.1101, 0.1273, 0.1185, 0.1229, 0.1108, 0.1084],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,415][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.3839, 0.0886, 0.0616, 0.0498, 0.0662, 0.1051, 0.0769, 0.0762, 0.0918],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,416][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.2764, 0.0568, 0.0737, 0.0369, 0.0943, 0.1209, 0.1374, 0.1050, 0.0985],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,418][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0946, 0.2382, 0.1637, 0.1573, 0.1197, 0.0632, 0.0618, 0.0708, 0.0307],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,419][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1219, 0.1016, 0.0735, 0.0897, 0.0991, 0.1136, 0.1329, 0.1352, 0.1326],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,421][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.8359, 0.0043, 0.0080, 0.0049, 0.0069, 0.0123, 0.0127, 0.1035, 0.0115],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,422][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4064, 0.0787, 0.0172, 0.0762, 0.0485, 0.0746, 0.0668, 0.0856, 0.1460],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,423][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.5320, 0.0070, 0.0041, 0.0089, 0.0219, 0.0749, 0.0748, 0.0686, 0.2079],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,425][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0027, 0.0811, 0.1075, 0.1132, 0.1440, 0.1235, 0.1328, 0.1557, 0.1395],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,426][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1559, 0.0989, 0.0986, 0.1007, 0.1066, 0.1071, 0.1160, 0.1045, 0.1117],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,428][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6782, 0.0445, 0.0129, 0.0243, 0.0453, 0.0285, 0.0484, 0.1016, 0.0164],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,429][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.0190, 0.0994, 0.1277, 0.0595, 0.0896, 0.1216, 0.1445, 0.1212, 0.1132,
        0.1041], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,431][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.0148, 0.1345, 0.1219, 0.0979, 0.1168, 0.1071, 0.1166, 0.1046, 0.0994,
        0.0863], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,432][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.3587, 0.0799, 0.0551, 0.0446, 0.0595, 0.0942, 0.0733, 0.0729, 0.0833,
        0.0783], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,433][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.1030, 0.0576, 0.0777, 0.0454, 0.1094, 0.1179, 0.1494, 0.1455, 0.1261,
        0.0682], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,435][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.0583, 0.2451, 0.1669, 0.1540, 0.1181, 0.0783, 0.0569, 0.0791, 0.0274,
        0.0159], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,436][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.1142, 0.0844, 0.0635, 0.0784, 0.0866, 0.1015, 0.1170, 0.1161, 0.1183,
        0.1200], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,438][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.5204, 0.0192, 0.0087, 0.0138, 0.0295, 0.0119, 0.0447, 0.1981, 0.0087,
        0.1450], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,439][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.3249, 0.0496, 0.0127, 0.0423, 0.0257, 0.0511, 0.0714, 0.0987, 0.1603,
        0.1631], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,441][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.5628, 0.0070, 0.0027, 0.0056, 0.0163, 0.0289, 0.0507, 0.0982, 0.1617,
        0.0660], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,442][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.0040, 0.0686, 0.1063, 0.1027, 0.1325, 0.1197, 0.1186, 0.1383, 0.1252,
        0.0840], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,443][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.1543, 0.0890, 0.0877, 0.0891, 0.0939, 0.0953, 0.1030, 0.0940, 0.0996,
        0.0941], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,443][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.4266, 0.0589, 0.0283, 0.0441, 0.0557, 0.0563, 0.1047, 0.1457, 0.0406,
        0.0390], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,444][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0182, 0.0889, 0.1159, 0.0547, 0.0841, 0.1138, 0.1275, 0.1054, 0.1005,
        0.0903, 0.1008], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,444][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0166, 0.1202, 0.1135, 0.0899, 0.1073, 0.0977, 0.1045, 0.0948, 0.0892,
        0.0770, 0.0892], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,445][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.3341, 0.0750, 0.0508, 0.0419, 0.0561, 0.0877, 0.0671, 0.0675, 0.0794,
        0.0765, 0.0639], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,445][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.1435, 0.0598, 0.0701, 0.0409, 0.0823, 0.1022, 0.1388, 0.0952, 0.1091,
        0.0678, 0.0903], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,445][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0672, 0.2247, 0.1556, 0.1566, 0.1254, 0.0611, 0.0637, 0.0740, 0.0293,
        0.0156, 0.0269], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,446][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0971, 0.0780, 0.0569, 0.0695, 0.0771, 0.0906, 0.1048, 0.1059, 0.1057,
        0.1089, 0.1054], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,447][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.6759, 0.0101, 0.0104, 0.0080, 0.0203, 0.0102, 0.0284, 0.0969, 0.0110,
        0.0672, 0.0617], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,448][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.2132, 0.0317, 0.0134, 0.0287, 0.0182, 0.0790, 0.0695, 0.0666, 0.1918,
        0.1418, 0.1461], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,450][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.4950, 0.0047, 0.0023, 0.0056, 0.0114, 0.0422, 0.0577, 0.0420, 0.1697,
        0.0403, 0.1291], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,451][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0026, 0.0730, 0.0888, 0.1041, 0.1136, 0.0902, 0.1001, 0.1257, 0.1058,
        0.0983, 0.0978], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,452][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.1358, 0.0811, 0.0805, 0.0820, 0.0864, 0.0868, 0.0941, 0.0859, 0.0908,
        0.0859, 0.0907], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,454][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.3509, 0.0671, 0.0314, 0.0346, 0.0497, 0.0539, 0.1091, 0.1340, 0.0510,
        0.0461, 0.0723], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,455][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0171, 0.0828, 0.1059, 0.0486, 0.0748, 0.1017, 0.1094, 0.0907, 0.0881,
        0.0822, 0.0897, 0.1090], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,457][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0144, 0.1132, 0.1041, 0.0846, 0.0981, 0.0901, 0.0948, 0.0853, 0.0812,
        0.0710, 0.0825, 0.0807], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,458][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.3312, 0.0663, 0.0460, 0.0386, 0.0522, 0.0826, 0.0625, 0.0623, 0.0738,
        0.0672, 0.0581, 0.0592], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,460][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1394, 0.0532, 0.0642, 0.0350, 0.0836, 0.0940, 0.1149, 0.1050, 0.0822,
        0.0601, 0.0980, 0.0704], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,461][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0654, 0.2347, 0.1595, 0.1536, 0.1141, 0.0649, 0.0575, 0.0693, 0.0261,
        0.0132, 0.0235, 0.0181], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,463][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0824, 0.0707, 0.0519, 0.0634, 0.0697, 0.0806, 0.0931, 0.0943, 0.0933,
        0.0961, 0.0937, 0.1109], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,464][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.6191, 0.0053, 0.0044, 0.0064, 0.0114, 0.0058, 0.0255, 0.1920, 0.0044,
        0.0641, 0.0167, 0.0451], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,465][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.2780, 0.0351, 0.0116, 0.0392, 0.0279, 0.0527, 0.0475, 0.0490, 0.1229,
        0.1180, 0.1113, 0.1068], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,467][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.4258, 0.0031, 0.0015, 0.0038, 0.0069, 0.0240, 0.0230, 0.0209, 0.0843,
        0.0268, 0.0891, 0.2908], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,468][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0012, 0.0561, 0.0807, 0.0790, 0.0995, 0.0898, 0.0958, 0.1085, 0.1114,
        0.0788, 0.1070, 0.0923], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,470][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1130, 0.0750, 0.0749, 0.0762, 0.0804, 0.0801, 0.0867, 0.0791, 0.0837,
        0.0792, 0.0839, 0.0877], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,471][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.6090, 0.0318, 0.0133, 0.0163, 0.0367, 0.0265, 0.0369, 0.0847, 0.0206,
        0.0242, 0.0721, 0.0280], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,473][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.0193, 0.0748, 0.0905, 0.0429, 0.0670, 0.0915, 0.1000, 0.0809, 0.0795,
        0.0727, 0.0814, 0.1008, 0.0987], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,474][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0128, 0.1076, 0.0946, 0.0740, 0.0923, 0.0839, 0.0859, 0.0774, 0.0762,
        0.0674, 0.0785, 0.0772, 0.0722], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,476][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.3257, 0.0612, 0.0429, 0.0384, 0.0518, 0.0780, 0.0603, 0.0596, 0.0695,
        0.0620, 0.0552, 0.0556, 0.0397], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,477][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0957, 0.0488, 0.0572, 0.0362, 0.0782, 0.0829, 0.1178, 0.0915, 0.0868,
        0.0544, 0.0948, 0.0899, 0.0655], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,479][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.0603, 0.1685, 0.1518, 0.1349, 0.1097, 0.0749, 0.0591, 0.1040, 0.0324,
        0.0164, 0.0281, 0.0239, 0.0359], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,480][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.0709, 0.0619, 0.0458, 0.0563, 0.0624, 0.0726, 0.0833, 0.0842, 0.0837,
        0.0863, 0.0835, 0.0999, 0.1092], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,482][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.3199, 0.0052, 0.0093, 0.0101, 0.0140, 0.0141, 0.0179, 0.3571, 0.0068,
        0.0384, 0.0134, 0.0240, 0.1698], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,483][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.3548, 0.0189, 0.0057, 0.0165, 0.0124, 0.0360, 0.0321, 0.0389, 0.1029,
        0.0912, 0.0954, 0.1324, 0.0628], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,484][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([4.4577e-01, 1.0264e-03, 2.6492e-04, 1.3835e-03, 2.2629e-03, 7.8709e-03,
        1.0396e-02, 1.2265e-02, 4.2376e-02, 1.2638e-02, 7.0675e-02, 2.8455e-01,
        1.0852e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,486][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0021, 0.0603, 0.0822, 0.0834, 0.1014, 0.0886, 0.0965, 0.0998, 0.0868,
        0.0661, 0.0842, 0.0771, 0.0714], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,487][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.1076, 0.0678, 0.0680, 0.0701, 0.0734, 0.0737, 0.0800, 0.0726, 0.0774,
        0.0729, 0.0766, 0.0807, 0.0791], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,489][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.5011, 0.0385, 0.0208, 0.0239, 0.0318, 0.0342, 0.0596, 0.0769, 0.0330,
        0.0278, 0.0645, 0.0414, 0.0464], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,490][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0160, 0.0683, 0.0847, 0.0381, 0.0597, 0.0812, 0.0891, 0.0747, 0.0714,
        0.0666, 0.0735, 0.0893, 0.0908, 0.0966], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,491][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0122, 0.0989, 0.0911, 0.0726, 0.0835, 0.0784, 0.0823, 0.0735, 0.0696,
        0.0591, 0.0697, 0.0694, 0.0672, 0.0725], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,491][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2538, 0.0621, 0.0444, 0.0389, 0.0523, 0.0770, 0.0603, 0.0601, 0.0719,
        0.0678, 0.0567, 0.0564, 0.0398, 0.0585], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,492][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1064, 0.0419, 0.0508, 0.0270, 0.0647, 0.0793, 0.1134, 0.0767, 0.0762,
        0.0472, 0.0807, 0.0774, 0.0597, 0.0986], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,492][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0440, 0.2513, 0.1721, 0.1444, 0.1096, 0.0721, 0.0514, 0.0591, 0.0205,
        0.0104, 0.0202, 0.0151, 0.0229, 0.0071], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,492][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0676, 0.0586, 0.0420, 0.0517, 0.0571, 0.0651, 0.0748, 0.0767, 0.0747,
        0.0772, 0.0757, 0.0890, 0.0983, 0.0916], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,493][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.5159, 0.0073, 0.0100, 0.0097, 0.0116, 0.0330, 0.0144, 0.1881, 0.0079,
        0.0702, 0.0159, 0.0186, 0.0318, 0.0657], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,493][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.2049, 0.0245, 0.0062, 0.0262, 0.0175, 0.0292, 0.0315, 0.0367, 0.0749,
        0.0809, 0.0754, 0.0746, 0.1587, 0.1589], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,495][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2532, 0.0016, 0.0006, 0.0017, 0.0028, 0.0097, 0.0114, 0.0119, 0.0417,
        0.0152, 0.0444, 0.2075, 0.1318, 0.2664], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,496][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0014, 0.0537, 0.0703, 0.0699, 0.0901, 0.0779, 0.0785, 0.0924, 0.0867,
        0.0672, 0.0868, 0.0730, 0.0803, 0.0719], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,498][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0961, 0.0637, 0.0644, 0.0647, 0.0688, 0.0689, 0.0744, 0.0677, 0.0716,
        0.0677, 0.0716, 0.0752, 0.0727, 0.0724], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,499][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.3784, 0.0561, 0.0155, 0.0237, 0.0466, 0.0248, 0.0507, 0.1120, 0.0245,
        0.0395, 0.0613, 0.0492, 0.0795, 0.0381], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,500][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:23:23,502][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[2333],
        [3370],
        [2246],
        [8973],
        [2664],
        [ 382],
        [1222],
        [ 299],
        [ 220],
        [ 905],
        [ 388],
        [ 210],
        [ 632],
        [ 191]], device='cuda:0')
[2024-07-24 10:23:23,503][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 2432],
        [ 5126],
        [ 6610],
        [28019],
        [13953],
        [ 2985],
        [ 5013],
        [ 6561],
        [ 2012],
        [ 5940],
        [ 5684],
        [ 3692],
        [ 7420],
        [ 4895]], device='cuda:0')
[2024-07-24 10:23:23,505][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[11679],
        [12977],
        [12118],
        [12487],
        [11504],
        [10287],
        [ 9608],
        [ 9426],
        [ 9104],
        [ 8770],
        [ 8583],
        [ 8622],
        [ 8423],
        [ 8415]], device='cuda:0')
[2024-07-24 10:23:23,506][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[12500],
        [24264],
        [21623],
        [ 1645],
        [ 1116],
        [ 1949],
        [ 3206],
        [ 6527],
        [ 1714],
        [  963],
        [ 3535],
        [ 4537],
        [ 3251],
        [ 2703]], device='cuda:0')
[2024-07-24 10:23:23,507][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[13064],
        [17176],
        [15070],
        [14799],
        [14343],
        [13621],
        [13024],
        [13092],
        [12883],
        [12674],
        [12628],
        [12430],
        [12581],
        [12323]], device='cuda:0')
[2024-07-24 10:23:23,509][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[33522],
        [28340],
        [29492],
        [29655],
        [30361],
        [30312],
        [29783],
        [29475],
        [29478],
        [29401],
        [29574],
        [29537],
        [29050],
        [29058]], device='cuda:0')
[2024-07-24 10:23:23,510][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[17762],
        [13741],
        [13368],
        [14438],
        [14872],
        [13801],
        [12972],
        [12021],
        [ 9710],
        [ 9495],
        [ 7825],
        [ 6632],
        [ 5664],
        [ 5071]], device='cuda:0')
[2024-07-24 10:23:23,512][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[1797],
        [1137],
        [1070],
        [1225],
        [1556],
        [2332],
        [2286],
        [1990],
        [1698],
        [1571],
        [1536],
        [1718],
        [1629],
        [1681]], device='cuda:0')
[2024-07-24 10:23:23,513][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 1735],
        [ 1712],
        [ 1823],
        [ 5403],
        [11458],
        [ 6131],
        [16647],
        [10368],
        [21378],
        [16719],
        [25270],
        [27281],
        [33626],
        [29783]], device='cuda:0')
[2024-07-24 10:23:23,514][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 1529],
        [10943],
        [17810],
        [22772],
        [23914],
        [22754],
        [23266],
        [24058],
        [23999],
        [24343],
        [24489],
        [24040],
        [23269],
        [22289]], device='cuda:0')
[2024-07-24 10:23:23,516][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[28268],
        [36159],
        [39913],
        [36558],
        [33045],
        [33123],
        [26570],
        [27939],
        [26468],
        [26499],
        [28472],
        [28171],
        [32093],
        [31708]], device='cuda:0')
[2024-07-24 10:23:23,517][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[14264],
        [ 4450],
        [ 4167],
        [ 1301],
        [  586],
        [ 1107],
        [ 1743],
        [  828],
        [ 1288],
        [  688],
        [ 1169],
        [ 1674],
        [ 1781],
        [ 2282]], device='cuda:0')
[2024-07-24 10:23:23,519][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 3276],
        [ 8657],
        [ 7690],
        [10158],
        [ 8992],
        [ 7920],
        [ 6060],
        [ 5458],
        [ 5329],
        [ 5090],
        [ 5045],
        [ 4553],
        [ 4400],
        [ 4313]], device='cuda:0')
[2024-07-24 10:23:23,520][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[34890],
        [26687],
        [21202],
        [16427],
        [10216],
        [14214],
        [16074],
        [ 6526],
        [12962],
        [ 7991],
        [ 8545],
        [13316],
        [ 9558],
        [10591]], device='cuda:0')
[2024-07-24 10:23:23,521][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[24017],
        [ 8512],
        [ 4962],
        [ 5249],
        [ 3695],
        [ 3525],
        [ 8258],
        [ 6546],
        [ 8152],
        [13816],
        [ 4209],
        [ 6383],
        [ 7914],
        [ 7626]], device='cuda:0')
[2024-07-24 10:23:23,523][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[15544],
        [10893],
        [12696],
        [12817],
        [14538],
        [15798],
        [17392],
        [18198],
        [18009],
        [18035],
        [18067],
        [17954],
        [18008],
        [18434]], device='cuda:0')
[2024-07-24 10:23:23,524][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[30701],
        [19546],
        [21835],
        [21527],
        [20970],
        [21272],
        [21019],
        [20976],
        [21146],
        [21144],
        [21222],
        [21039],
        [20972],
        [21013]], device='cuda:0')
[2024-07-24 10:23:23,525][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[3142],
        [2703],
        [2380],
        [2575],
        [2700],
        [3707],
        [4392],
        [4439],
        [4619],
        [4400],
        [4389],
        [4464],
        [4475],
        [4464]], device='cuda:0')
[2024-07-24 10:23:23,527][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[24535],
        [30981],
        [33400],
        [34712],
        [34058],
        [32730],
        [31321],
        [30486],
        [30094],
        [29939],
        [29654],
        [29843],
        [30084],
        [29870]], device='cuda:0')
[2024-07-24 10:23:23,528][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[22066],
        [26632],
        [37270],
        [37522],
        [37031],
        [38314],
        [38485],
        [38631],
        [38767],
        [38874],
        [38349],
        [38435],
        [38196],
        [38793]], device='cuda:0')
[2024-07-24 10:23:23,530][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[23484],
        [18853],
        [18645],
        [17988],
        [17645],
        [16746],
        [15657],
        [15624],
        [15177],
        [15472],
        [15644],
        [14846],
        [14543],
        [14466]], device='cuda:0')
[2024-07-24 10:23:23,531][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[28828],
        [27939],
        [24916],
        [21902],
        [26055],
        [18423],
        [20320],
        [11085],
        [17614],
        [11616],
        [15478],
        [13109],
        [11495],
        [11809]], device='cuda:0')
[2024-07-24 10:23:23,532][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[42021],
        [40469],
        [40649],
        [42196],
        [43445],
        [44196],
        [43560],
        [41018],
        [40390],
        [37526],
        [35207],
        [36832],
        [38385],
        [39993]], device='cuda:0')
[2024-07-24 10:23:23,534][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[10284],
        [10252],
        [ 9553],
        [ 9929],
        [ 9540],
        [ 9493],
        [10561],
        [11935],
        [31017],
        [28233],
        [34378],
        [40044],
        [38891],
        [44938]], device='cuda:0')
[2024-07-24 10:23:23,535][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[21805],
        [20171],
        [24215],
        [22712],
        [24820],
        [25466],
        [24556],
        [25457],
        [24837],
        [24341],
        [24312],
        [23290],
        [24049],
        [23399]], device='cuda:0')
[2024-07-24 10:23:23,537][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[38300],
        [34160],
        [31178],
        [29484],
        [29135],
        [28719],
        [28703],
        [29004],
        [29105],
        [29278],
        [29172],
        [29127],
        [29360],
        [29325]], device='cuda:0')
[2024-07-24 10:23:23,538][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[18516],
        [22778],
        [23748],
        [23462],
        [25548],
        [27305],
        [27268],
        [25198],
        [23749],
        [25865],
        [25485],
        [22184],
        [24435],
        [26103]], device='cuda:0')
[2024-07-24 10:23:23,539][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[4146],
        [5960],
        [5169],
        [5211],
        [4463],
        [4492],
        [4610],
        [5570],
        [3889],
        [4577],
        [4206],
        [4087],
        [4033],
        [3177]], device='cuda:0')
[2024-07-24 10:23:23,541][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[14944],
        [33721],
        [25837],
        [22493],
        [28996],
        [27000],
        [24458],
        [22024],
        [21302],
        [24835],
        [28269],
        [25026],
        [25764],
        [18180]], device='cuda:0')
[2024-07-24 10:23:23,542][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[8415],
        [8415],
        [8415],
        [8415],
        [8415],
        [8415],
        [8415],
        [8415],
        [8415],
        [8415],
        [8415],
        [8415],
        [8415],
        [8415]], device='cuda:0')
[2024-07-24 10:23:23,600][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:23,600][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,600][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,601][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,601][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,603][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,604][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,605][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,606][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,607][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,608][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,609][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,610][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,611][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.6993, 0.3007], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,613][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.0047, 0.9953], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,614][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.0011, 0.9989], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,615][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.5775, 0.4225], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,617][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.7948, 0.2052], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,618][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.1818, 0.8182], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,620][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.1382, 0.8618], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,621][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.3895, 0.6105], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,622][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.5592, 0.4408], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,624][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.1524, 0.8476], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,625][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0211, 0.9789], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,627][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.4747, 0.5253], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,628][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.4435, 0.2466, 0.3099], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,629][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0722, 0.8126, 0.1152], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,630][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([2.5549e-04, 4.3187e-01, 5.6787e-01], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,631][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.4529, 0.3367, 0.2105], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,633][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.7965, 0.0738, 0.1296], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,634][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1378, 0.4896, 0.3726], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,636][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0777, 0.4881, 0.4343], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,637][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3490, 0.3206, 0.3305], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,639][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0114, 0.9355, 0.0531], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,640][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1290, 0.5415, 0.3295], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,641][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0089, 0.4468, 0.5443], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,642][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.3190, 0.3592, 0.3218], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,644][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Mary] are: tensor([0.2962, 0.1772, 0.2924, 0.2343], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,645][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Mary] are: tensor([0.2113, 0.3881, 0.0737, 0.3269], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,646][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Mary] are: tensor([0.0012, 0.3444, 0.5421, 0.1124], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,646][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Mary] are: tensor([0.2676, 0.4018, 0.2541, 0.0765], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,647][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Mary] are: tensor([0.4612, 0.1452, 0.2283, 0.1653], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,647][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Mary] are: tensor([0.0853, 0.3064, 0.2489, 0.3595], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,647][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Mary] are: tensor([0.1092, 0.3147, 0.2629, 0.3132], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,648][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Mary] are: tensor([0.2163, 0.1999, 0.3250, 0.2589], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,648][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Mary] are: tensor([0.0296, 0.8718, 0.0752, 0.0233], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,648][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Mary] are: tensor([0.0878, 0.4186, 0.2430, 0.2507], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,649][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Mary] are: tensor([0.0064, 0.3222, 0.3826, 0.2888], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,649][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Mary] are: tensor([0.2597, 0.2275, 0.2308, 0.2820], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,651][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0993, 0.1197, 0.1912, 0.3154, 0.2744], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,652][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0528, 0.4954, 0.0768, 0.2435, 0.1314], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,653][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0006, 0.2336, 0.4255, 0.1104, 0.2299], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,655][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.4369, 0.2326, 0.1512, 0.0427, 0.1366], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,655][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.3823, 0.0485, 0.1206, 0.1191, 0.3296], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,657][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0681, 0.1910, 0.1915, 0.2616, 0.2878], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,658][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0416, 0.2055, 0.2513, 0.2302, 0.2715], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,660][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0888, 0.1947, 0.1680, 0.1668, 0.3816], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,661][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0100, 0.9361, 0.0245, 0.0056, 0.0238], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,662][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.0717, 0.3475, 0.1958, 0.2033, 0.1816], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,664][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0039, 0.2471, 0.2941, 0.2239, 0.2311], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,665][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.2510, 0.1729, 0.2085, 0.2068, 0.1608], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,666][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.3030, 0.0031, 0.0043, 0.0384, 0.0403, 0.6109], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,668][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0434, 0.2270, 0.0844, 0.2543, 0.2492, 0.1417], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,668][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([7.9561e-05, 1.2351e-01, 1.4094e-01, 9.5665e-02, 2.9724e-01, 3.4256e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,670][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.3191, 0.2253, 0.1514, 0.0572, 0.1545, 0.0925], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,671][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.7479, 0.0059, 0.0133, 0.0284, 0.0430, 0.1614], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,673][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0427, 0.1585, 0.1447, 0.2304, 0.2824, 0.1413], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,674][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0387, 0.1798, 0.1784, 0.1942, 0.1849, 0.2240], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,676][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1385, 0.1191, 0.1050, 0.1592, 0.3675, 0.1107], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,677][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0049, 0.8147, 0.0360, 0.0064, 0.0832, 0.0547], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,678][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0828, 0.2578, 0.1711, 0.1973, 0.1864, 0.1046], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,680][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0046, 0.1930, 0.2353, 0.1764, 0.1919, 0.1989], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,681][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1553, 0.1639, 0.1676, 0.2038, 0.1705, 0.1390], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,683][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0542, 0.0091, 0.0089, 0.0177, 0.0282, 0.8473, 0.0346],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,684][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0251, 0.1543, 0.0839, 0.2825, 0.1684, 0.1953, 0.0905],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,685][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ the] are: tensor([2.1804e-05, 1.4954e-01, 1.1761e-01, 6.6211e-02, 1.3340e-01, 2.3879e-01,
        2.9442e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,687][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.2937, 0.1676, 0.1405, 0.0327, 0.1314, 0.0923, 0.1418],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,688][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.3424, 0.0116, 0.0326, 0.0326, 0.0917, 0.3572, 0.1319],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,689][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0412, 0.1503, 0.1324, 0.1997, 0.2287, 0.1270, 0.1207],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,691][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0412, 0.1527, 0.1658, 0.1688, 0.1407, 0.1876, 0.1432],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,692][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0904, 0.0889, 0.1118, 0.1443, 0.3376, 0.1335, 0.0935],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,693][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0102, 0.8540, 0.0155, 0.0019, 0.0380, 0.0290, 0.0514],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,693][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0589, 0.2341, 0.1503, 0.1575, 0.1483, 0.0994, 0.1514],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,694][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0020, 0.1739, 0.2100, 0.1537, 0.1630, 0.1714, 0.1260],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,694][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1549, 0.1429, 0.1564, 0.1687, 0.1329, 0.1294, 0.1149],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,694][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.0068, 0.0158, 0.0079, 0.0103, 0.0281, 0.8114, 0.0796, 0.0401],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,695][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([0.0834, 0.2074, 0.0373, 0.2008, 0.0854, 0.0697, 0.0508, 0.2651],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,695][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([3.6024e-05, 8.3607e-02, 9.5767e-02, 4.8254e-02, 6.3750e-02, 1.7822e-01,
        3.5947e-01, 1.7089e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,695][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.1516, 0.1577, 0.1516, 0.0253, 0.0948, 0.0964, 0.2317, 0.0907],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,697][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.1136, 0.0252, 0.0349, 0.0227, 0.1143, 0.3023, 0.1910, 0.1960],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,698][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.0345, 0.1152, 0.1065, 0.1361, 0.1453, 0.1036, 0.0945, 0.2643],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,700][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.0403, 0.1064, 0.1245, 0.1364, 0.1136, 0.1376, 0.1638, 0.1775],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,701][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.0296, 0.0727, 0.0770, 0.0843, 0.1391, 0.1029, 0.0839, 0.4106],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,702][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.0287, 0.3763, 0.0087, 0.0020, 0.0343, 0.0291, 0.0877, 0.4333],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,704][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.0488, 0.1926, 0.1333, 0.1456, 0.1320, 0.0870, 0.1342, 0.1264],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,705][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.0015, 0.1563, 0.1932, 0.1391, 0.1401, 0.1530, 0.1131, 0.1038],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,706][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.1102, 0.1333, 0.1293, 0.1610, 0.1368, 0.1102, 0.1069, 0.1124],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,708][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1488, 0.0065, 0.0031, 0.0139, 0.0193, 0.2830, 0.0288, 0.0356, 0.4609],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,709][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0092, 0.0890, 0.0680, 0.1256, 0.1564, 0.0979, 0.0630, 0.3006, 0.0904],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,710][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([2.8577e-05, 6.1737e-02, 6.8725e-02, 3.1588e-02, 1.2807e-01, 1.5460e-01,
        2.1973e-01, 8.7472e-02, 2.4805e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,712][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.2282, 0.1480, 0.1035, 0.0281, 0.1143, 0.0743, 0.1434, 0.0793, 0.0810],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,713][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1771, 0.0107, 0.0188, 0.0236, 0.0662, 0.2098, 0.1162, 0.1000, 0.2776],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,714][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0311, 0.0978, 0.0807, 0.1299, 0.1670, 0.0894, 0.0840, 0.2285, 0.0917],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,716][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0212, 0.1006, 0.0995, 0.1428, 0.1089, 0.1284, 0.1006, 0.1803, 0.1176],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,717][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0198, 0.0533, 0.0822, 0.0670, 0.1981, 0.0908, 0.0686, 0.3354, 0.0850],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,719][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0007, 0.3752, 0.0083, 0.0017, 0.0338, 0.0188, 0.0706, 0.4533, 0.0376],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,720][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0554, 0.1818, 0.1180, 0.1342, 0.1304, 0.0762, 0.1257, 0.1192, 0.0591],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,722][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0025, 0.1417, 0.1633, 0.1219, 0.1266, 0.1354, 0.1000, 0.0993, 0.1092],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,723][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1417, 0.1167, 0.1016, 0.1406, 0.1114, 0.0926, 0.0938, 0.1071, 0.0945],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,725][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.0094, 0.0134, 0.0035, 0.0079, 0.0159, 0.0978, 0.0526, 0.0868, 0.6508,
        0.0619], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,726][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.0314, 0.1552, 0.0487, 0.1553, 0.1459, 0.0487, 0.0352, 0.1594, 0.0298,
        0.1903], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,727][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([1.2969e-05, 3.2261e-02, 6.6927e-02, 1.4189e-02, 8.2765e-02, 1.4816e-01,
        2.2903e-01, 7.8703e-02, 3.2065e-01, 2.7299e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,728][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.0866, 0.1518, 0.1132, 0.0245, 0.0781, 0.0767, 0.1962, 0.0800, 0.1242,
        0.0688], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,730][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.1108, 0.0257, 0.0178, 0.0272, 0.0644, 0.0945, 0.1282, 0.1990, 0.2519,
        0.0805], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,731][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.0214, 0.0793, 0.0796, 0.1093, 0.1277, 0.0797, 0.0802, 0.2265, 0.0872,
        0.1091], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,733][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.0208, 0.0918, 0.0664, 0.1261, 0.0956, 0.0905, 0.0877, 0.2584, 0.0762,
        0.0866], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,734][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0143, 0.0581, 0.0840, 0.0628, 0.1804, 0.0986, 0.0610, 0.2639, 0.1075,
        0.0694], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,735][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.0015, 0.1705, 0.0037, 0.0025, 0.0253, 0.0126, 0.0807, 0.6553, 0.0382,
        0.0098], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,737][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.0696, 0.1802, 0.1144, 0.1248, 0.1039, 0.0703, 0.1128, 0.1156, 0.0566,
        0.0519], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,738][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0014, 0.1357, 0.1527, 0.1107, 0.1165, 0.1212, 0.0886, 0.0882, 0.0926,
        0.0923], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,740][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.0998, 0.0995, 0.1044, 0.1250, 0.1057, 0.0895, 0.0841, 0.0858, 0.1059,
        0.1005], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,740][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0102, 0.0052, 0.0020, 0.0057, 0.0087, 0.2568, 0.0268, 0.0270, 0.5783,
        0.0430, 0.0364], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,741][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0137, 0.2468, 0.0325, 0.2048, 0.1312, 0.0521, 0.0281, 0.0946, 0.0228,
        0.1245, 0.0488], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,741][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([7.0214e-05, 7.5717e-02, 6.4845e-02, 3.1354e-02, 6.6253e-02, 1.0488e-01,
        1.8503e-01, 8.7812e-02, 2.3507e-01, 3.7225e-02, 1.1174e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,741][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.1323, 0.1291, 0.1139, 0.0206, 0.0789, 0.0856, 0.1610, 0.0837, 0.0866,
        0.0450, 0.0633], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,742][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1438, 0.0144, 0.0174, 0.0168, 0.0481, 0.1065, 0.1198, 0.0978, 0.2308,
        0.0655, 0.1391], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,742][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0245, 0.0752, 0.0725, 0.1074, 0.1327, 0.0670, 0.0680, 0.1780, 0.0680,
        0.1011, 0.1055], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,742][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0145, 0.0698, 0.0921, 0.0896, 0.0785, 0.1259, 0.0795, 0.1580, 0.1157,
        0.0797, 0.0967], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,743][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0254, 0.0772, 0.0744, 0.0534, 0.1230, 0.0918, 0.0675, 0.2265, 0.0843,
        0.0629, 0.1138], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,744][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0024, 0.3323, 0.0096, 0.0018, 0.0218, 0.0188, 0.0590, 0.3754, 0.0356,
        0.0039, 0.1396], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,745][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0409, 0.1769, 0.1084, 0.1200, 0.1065, 0.0675, 0.1088, 0.1140, 0.0522,
        0.0526, 0.0520], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,746][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0017, 0.1209, 0.1410, 0.1047, 0.1074, 0.1122, 0.0836, 0.0789, 0.0866,
        0.0817, 0.0812], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,748][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0945, 0.0906, 0.0989, 0.1094, 0.0887, 0.0801, 0.0794, 0.0824, 0.0942,
        0.0904, 0.0914], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,749][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1139, 0.0052, 0.0019, 0.0118, 0.0121, 0.1866, 0.0172, 0.0231, 0.3520,
        0.0685, 0.0351, 0.1727], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,750][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0098, 0.0373, 0.0350, 0.0933, 0.1035, 0.0778, 0.0666, 0.1214, 0.1105,
        0.1260, 0.1066, 0.1123], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,751][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([1.1337e-05, 1.9362e-02, 3.1994e-02, 1.4497e-02, 4.6760e-02, 6.5501e-02,
        1.2679e-01, 5.0282e-02, 1.5921e-01, 2.4893e-02, 1.5212e-01, 3.0858e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,752][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1563, 0.1117, 0.0957, 0.0204, 0.0785, 0.0672, 0.1198, 0.0688, 0.0838,
        0.0421, 0.0534, 0.1022], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,754][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2224, 0.0043, 0.0088, 0.0125, 0.0276, 0.0890, 0.0592, 0.0472, 0.1443,
        0.0525, 0.1059, 0.2264], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,755][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0240, 0.0743, 0.0656, 0.0841, 0.1085, 0.0674, 0.0588, 0.1701, 0.0718,
        0.1030, 0.1099, 0.0625], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,757][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0130, 0.0643, 0.0819, 0.0855, 0.0814, 0.1023, 0.0623, 0.1189, 0.1308,
        0.0767, 0.1269, 0.0559], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,758][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0133, 0.0431, 0.0649, 0.0498, 0.1297, 0.0804, 0.0585, 0.2252, 0.0837,
        0.0610, 0.1524, 0.0380], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,759][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0016, 0.4362, 0.0112, 0.0014, 0.0238, 0.0172, 0.0367, 0.2105, 0.0248,
        0.0032, 0.1025, 0.1308], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,761][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0433, 0.1591, 0.1004, 0.1133, 0.1023, 0.0648, 0.0987, 0.1032, 0.0485,
        0.0533, 0.0507, 0.0624], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,762][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0020, 0.1075, 0.1250, 0.0931, 0.0979, 0.1025, 0.0751, 0.0746, 0.0815,
        0.0794, 0.0790, 0.0824], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,764][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0929, 0.0773, 0.0944, 0.0997, 0.0795, 0.0744, 0.0729, 0.0780, 0.0949,
        0.0840, 0.0854, 0.0667], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,765][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0061, 0.0037, 0.0006, 0.0044, 0.0040, 0.1165, 0.0146, 0.0124, 0.4120,
        0.0387, 0.0420, 0.2884, 0.0564], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,767][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0291, 0.0890, 0.0263, 0.1264, 0.0753, 0.0448, 0.0192, 0.1656, 0.0328,
        0.1515, 0.0912, 0.0259, 0.1229], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,767][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([1.9123e-05, 2.4177e-02, 2.9214e-02, 1.0112e-02, 3.5037e-02, 5.2484e-02,
        7.3549e-02, 5.0020e-02, 1.4628e-01, 2.0499e-02, 1.1997e-01, 3.7707e-01,
        6.1573e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,769][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.1210, 0.1063, 0.0978, 0.0193, 0.0546, 0.0627, 0.1167, 0.0537, 0.0839,
        0.0379, 0.0479, 0.1091, 0.0889], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,770][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0848, 0.0024, 0.0030, 0.0061, 0.0135, 0.0510, 0.0501, 0.0395, 0.0815,
        0.0171, 0.1110, 0.3113, 0.2287], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,772][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0214, 0.0641, 0.0595, 0.0799, 0.0854, 0.0608, 0.0578, 0.1580, 0.0624,
        0.0841, 0.0839, 0.0631, 0.1195], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,773][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0209, 0.0526, 0.0673, 0.0748, 0.0729, 0.0785, 0.1137, 0.1728, 0.0659,
        0.0531, 0.1021, 0.0651, 0.0602], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,775][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0184, 0.0351, 0.0434, 0.0470, 0.0725, 0.0487, 0.0460, 0.2104, 0.0646,
        0.0605, 0.1405, 0.0374, 0.1754], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,776][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.0164, 0.5032, 0.0035, 0.0009, 0.0074, 0.0052, 0.0156, 0.1194, 0.0085,
        0.0020, 0.0834, 0.0851, 0.1495], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,778][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0352, 0.1650, 0.0888, 0.1052, 0.0910, 0.0627, 0.0923, 0.0960, 0.0445,
        0.0461, 0.0465, 0.0547, 0.0718], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,779][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0017, 0.1020, 0.1155, 0.0857, 0.0922, 0.0960, 0.0698, 0.0686, 0.0746,
        0.0719, 0.0716, 0.0747, 0.0757], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,780][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.1031, 0.0844, 0.0785, 0.0967, 0.0798, 0.0652, 0.0609, 0.0716, 0.0768,
        0.0771, 0.0778, 0.0615, 0.0664], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,782][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0731, 0.0042, 0.0008, 0.0067, 0.0076, 0.0832, 0.0106, 0.0139, 0.2143,
        0.0396, 0.0213, 0.1384, 0.0681, 0.3183], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,783][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0308, 0.0276, 0.0325, 0.0837, 0.1299, 0.0498, 0.0549, 0.1338, 0.0543,
        0.0907, 0.0680, 0.0488, 0.1440, 0.0511], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,784][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([3.0695e-06, 9.7660e-03, 1.4155e-02, 6.7134e-03, 2.5005e-02, 3.4317e-02,
        6.8033e-02, 1.8891e-02, 8.1338e-02, 1.0640e-02, 9.8672e-02, 1.9738e-01,
        4.3375e-02, 3.9171e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,786][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1019, 0.0923, 0.0723, 0.0186, 0.0635, 0.0467, 0.1222, 0.0538, 0.0616,
        0.0374, 0.0531, 0.1070, 0.0868, 0.0828], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,787][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1472, 0.0034, 0.0041, 0.0074, 0.0126, 0.0383, 0.0291, 0.0313, 0.0890,
        0.0266, 0.0677, 0.1447, 0.1417, 0.2570], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,787][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0142, 0.0578, 0.0527, 0.0807, 0.1048, 0.0511, 0.0533, 0.1329, 0.0557,
        0.0821, 0.0839, 0.0567, 0.1210, 0.0533], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,788][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0153, 0.0598, 0.0627, 0.0720, 0.0672, 0.0793, 0.0613, 0.1257, 0.1013,
        0.0703, 0.0944, 0.0429, 0.0754, 0.0722], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,788][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0147, 0.0370, 0.0427, 0.0442, 0.1080, 0.0479, 0.0416, 0.1519, 0.0525,
        0.0510, 0.1009, 0.0296, 0.2267, 0.0512], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,789][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0011, 0.2370, 0.0054, 0.0006, 0.0114, 0.0089, 0.0205, 0.1213, 0.0137,
        0.0017, 0.0578, 0.0775, 0.1971, 0.2460], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,789][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0385, 0.1434, 0.0908, 0.1026, 0.0952, 0.0546, 0.0919, 0.0907, 0.0422,
        0.0418, 0.0421, 0.0501, 0.0753, 0.0409], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,789][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0018, 0.0937, 0.1068, 0.0775, 0.0840, 0.0876, 0.0633, 0.0639, 0.0686,
        0.0680, 0.0674, 0.0698, 0.0703, 0.0771], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,790][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0781, 0.0725, 0.0739, 0.0874, 0.0740, 0.0611, 0.0655, 0.0662, 0.0751,
        0.0747, 0.0806, 0.0667, 0.0617, 0.0625], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,824][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:23,825][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,825][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,825][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,826][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,826][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,826][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,826][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,827][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,827][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,827][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,828][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,828][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:23,828][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.9078, 0.0922], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,829][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.0238, 0.9762], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,829][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([7.6880e-04, 9.9923e-01], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,829][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.9281, 0.0719], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,830][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.7948, 0.2052], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,830][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.9538, 0.0462], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,830][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.7756, 0.2244], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,831][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.3196, 0.6804], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,831][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.9670, 0.0330], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,831][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.8601, 0.1399], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,832][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.0435, 0.9565], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,832][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.9612, 0.0388], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:23,832][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.4202, 0.4349, 0.1449], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,833][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.2484, 0.6068, 0.1449], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,833][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([8.1268e-05, 2.1065e-01, 7.8927e-01], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,833][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.9237, 0.0479, 0.0284], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,834][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.7965, 0.0738, 0.1296], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,834][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9820, 0.0163, 0.0017], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,834][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.8934, 0.0396, 0.0671], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,835][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1604, 0.3011, 0.5385], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,835][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.8026, 0.1186, 0.0788], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,835][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.8397, 0.1358, 0.0246], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,837][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0336, 0.5887, 0.3777], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,838][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.8297, 0.0641, 0.1062], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:23,839][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Mary] are: tensor([0.3539, 0.2600, 0.2353, 0.1508], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,841][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Mary] are: tensor([0.2834, 0.3158, 0.0968, 0.3040], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,841][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Mary] are: tensor([1.5106e-04, 1.4921e-01, 7.9879e-01, 5.1846e-02], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,843][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Mary] are: tensor([0.8803, 0.0450, 0.0188, 0.0558], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,844][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Mary] are: tensor([0.4612, 0.1452, 0.2283, 0.1653], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,845][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Mary] are: tensor([0.9513, 0.0223, 0.0033, 0.0231], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,845][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Mary] are: tensor([0.8214, 0.0450, 0.0386, 0.0951], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,846][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Mary] are: tensor([0.1031, 0.1557, 0.4960, 0.2453], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,846][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Mary] are: tensor([0.7311, 0.1012, 0.1185, 0.0491], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,846][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Mary] are: tensor([0.4163, 0.3231, 0.2216, 0.0389], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,846][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Mary] are: tensor([0.0094, 0.4008, 0.2655, 0.3242], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,847][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Mary] are: tensor([0.7366, 0.0774, 0.0829, 0.1031], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:23,847][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.2460, 0.1444, 0.0909, 0.1914, 0.3273], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,847][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0751, 0.4216, 0.1410, 0.2575, 0.1046], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,848][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([3.6769e-05, 1.3046e-01, 7.5074e-01, 5.3700e-02, 6.5064e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,848][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.4569, 0.0447, 0.0422, 0.0853, 0.3710], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,849][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.3823, 0.0485, 0.1206, 0.1191, 0.3296], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,850][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.8264, 0.0773, 0.0069, 0.0805, 0.0088], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,851][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.6785, 0.0358, 0.0668, 0.1214, 0.0975], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,853][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0349, 0.1500, 0.2218, 0.1333, 0.4600], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,854][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.4327, 0.0964, 0.1006, 0.1416, 0.2287], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,854][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.6668, 0.1253, 0.1205, 0.0223, 0.0652], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,856][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0064, 0.2652, 0.2017, 0.2305, 0.2962], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,857][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.2276, 0.1826, 0.1985, 0.2287, 0.1626], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:23,858][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.3715, 0.0228, 0.0083, 0.0588, 0.1369, 0.4018], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,860][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1723, 0.1837, 0.1003, 0.2167, 0.1322, 0.1949], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,861][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.0079e-05, 6.0592e-02, 1.9965e-01, 5.1770e-02, 1.6374e-01, 5.2424e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,862][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.7359, 0.0107, 0.0075, 0.0372, 0.1211, 0.0876], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,863][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.7479, 0.0059, 0.0133, 0.0284, 0.0430, 0.1614], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,864][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.5626e-01, 1.1466e-02, 7.2754e-04, 2.7682e-02, 2.0828e-03, 1.7858e-03],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,866][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.7121, 0.0198, 0.0421, 0.0615, 0.0703, 0.0943], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,867][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0450, 0.0855, 0.1161, 0.1418, 0.4778, 0.1338], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,868][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.4386, 0.0116, 0.0181, 0.0671, 0.1510, 0.3137], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,870][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.7069, 0.1150, 0.0428, 0.0210, 0.0798, 0.0345], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,871][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0127, 0.2076, 0.1520, 0.1723, 0.2213, 0.2340], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,872][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.6550, 0.0435, 0.0618, 0.0920, 0.0886, 0.0592], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:23,873][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1370, 0.0353, 0.0141, 0.0307, 0.1080, 0.6078, 0.0671],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,875][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1131, 0.1516, 0.1007, 0.2530, 0.0922, 0.2009, 0.0885],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,876][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([7.1178e-06, 8.4489e-02, 2.6922e-01, 5.6592e-02, 8.6106e-02, 3.9678e-01,
        1.0680e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,877][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.4134, 0.0200, 0.0135, 0.0332, 0.1578, 0.1739, 0.1882],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,878][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.3424, 0.0116, 0.0326, 0.0326, 0.0917, 0.3572, 0.1319],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,880][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.9437, 0.0145, 0.0019, 0.0300, 0.0025, 0.0034, 0.0041],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,881][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.6728, 0.0179, 0.0401, 0.0617, 0.0560, 0.0911, 0.0605],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,883][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0257, 0.0615, 0.1243, 0.1228, 0.3910, 0.1612, 0.1135],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,884][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.2570, 0.0277, 0.0305, 0.0358, 0.1322, 0.3886, 0.1282],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,885][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.7460, 0.0793, 0.0418, 0.0087, 0.0433, 0.0284, 0.0525],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,887][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0101, 0.1787, 0.1242, 0.1378, 0.1832, 0.2164, 0.1496],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,888][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.5590, 0.0683, 0.0670, 0.1031, 0.0795, 0.0606, 0.0625],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:23,889][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.0802, 0.0392, 0.0094, 0.0173, 0.1000, 0.4316, 0.1240, 0.1983],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,891][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([0.1527, 0.1808, 0.0579, 0.1932, 0.0612, 0.1182, 0.1045, 0.1314],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,892][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([6.3068e-06, 7.0699e-02, 3.0052e-01, 4.7040e-02, 4.0473e-02, 3.1888e-01,
        1.6068e-01, 6.1698e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,893][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.2255, 0.0266, 0.0123, 0.0262, 0.1424, 0.1463, 0.2277, 0.1930],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,894][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.1136, 0.0252, 0.0349, 0.0227, 0.1143, 0.3023, 0.1910, 0.1960],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,896][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.9159, 0.0249, 0.0035, 0.0219, 0.0027, 0.0058, 0.0069, 0.0184],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,897][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.5759, 0.0220, 0.0313, 0.0721, 0.0566, 0.0639, 0.0529, 0.1253],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,898][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.0098, 0.0597, 0.0871, 0.0787, 0.1260, 0.0928, 0.0840, 0.4618],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,898][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.1501, 0.0214, 0.0161, 0.0258, 0.1057, 0.2641, 0.1735, 0.2434],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,898][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.3722, 0.1319, 0.0779, 0.0086, 0.0707, 0.0883, 0.2094, 0.0408],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,899][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.0025, 0.1499, 0.1035, 0.1268, 0.1644, 0.2051, 0.1282, 0.1196],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,899][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.1522, 0.0872, 0.1376, 0.1513, 0.0774, 0.0918, 0.1046, 0.1978],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:23,899][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1167, 0.0308, 0.0052, 0.0200, 0.0577, 0.1600, 0.0519, 0.2231, 0.3346],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,900][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0608, 0.1675, 0.0786, 0.1675, 0.1064, 0.1314, 0.0748, 0.0828, 0.1302],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,900][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([1.2795e-06, 5.7129e-02, 1.9724e-01, 3.2268e-02, 1.3126e-01, 3.5162e-01,
        1.2317e-01, 4.4911e-02, 6.2405e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,900][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.2603, 0.0206, 0.0090, 0.0327, 0.1017, 0.0802, 0.1360, 0.1282, 0.2312],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,901][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1771, 0.0107, 0.0188, 0.0236, 0.0662, 0.2098, 0.1162, 0.1000, 0.2776],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,901][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.8704, 0.0294, 0.0015, 0.0631, 0.0027, 0.0025, 0.0033, 0.0184, 0.0088],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,903][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.4149, 0.0256, 0.0409, 0.0627, 0.0567, 0.0841, 0.0373, 0.1254, 0.1524],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,904][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0063, 0.0384, 0.0939, 0.0574, 0.2148, 0.0890, 0.0661, 0.3593, 0.0749],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,905][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1238, 0.0211, 0.0103, 0.0324, 0.0818, 0.1266, 0.0960, 0.1650, 0.3430],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,907][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7008, 0.0569, 0.0270, 0.0106, 0.0382, 0.0267, 0.0675, 0.0448, 0.0276],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,907][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0089, 0.1327, 0.0910, 0.1098, 0.1408, 0.1606, 0.1216, 0.1241, 0.1104],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,909][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.3235, 0.0596, 0.0651, 0.0931, 0.0640, 0.0605, 0.0725, 0.2022, 0.0597],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:23,910][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.0249, 0.0407, 0.0044, 0.0124, 0.0494, 0.0418, 0.0710, 0.3843, 0.2961,
        0.0749], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,912][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.0273, 0.2093, 0.0743, 0.1806, 0.1135, 0.0771, 0.0631, 0.0784, 0.0658,
        0.1106], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,912][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([6.4156e-07, 2.6139e-02, 2.2794e-01, 1.4548e-02, 8.0672e-02, 3.7500e-01,
        1.3389e-01, 3.6058e-02, 9.0836e-02, 1.4908e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,914][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.1165, 0.0302, 0.0062, 0.0272, 0.1220, 0.0339, 0.1446, 0.2740, 0.1705,
        0.0749], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,915][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.1108, 0.0257, 0.0178, 0.0272, 0.0644, 0.0945, 0.1282, 0.1990, 0.2519,
        0.0805], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,917][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.7904, 0.0441, 0.0032, 0.0532, 0.0044, 0.0040, 0.0104, 0.0291, 0.0147,
        0.0466], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,918][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.2606, 0.0371, 0.0307, 0.0726, 0.0801, 0.0706, 0.0504, 0.1474, 0.1280,
        0.1225], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,919][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0073, 0.0604, 0.1092, 0.0590, 0.1957, 0.0831, 0.0578, 0.2804, 0.0855,
        0.0615], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,921][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.0764, 0.0437, 0.0070, 0.0248, 0.0341, 0.0457, 0.0895, 0.3191, 0.2440,
        0.1157], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,922][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.1951, 0.1056, 0.0773, 0.0122, 0.0975, 0.0685, 0.2351, 0.0468, 0.1327,
        0.0291], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,924][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.0033, 0.1023, 0.0956, 0.1175, 0.1362, 0.1497, 0.0975, 0.1151, 0.1069,
        0.0760], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,925][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.1250, 0.0683, 0.0861, 0.0658, 0.0590, 0.0715, 0.0700, 0.1423, 0.0814,
        0.2304], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:23,926][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0518, 0.0151, 0.0020, 0.0109, 0.0285, 0.1269, 0.0453, 0.1729, 0.3458,
        0.0709, 0.1297], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,928][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0194, 0.2455, 0.0462, 0.2295, 0.1102, 0.0976, 0.0490, 0.0363, 0.0596,
        0.0688, 0.0379], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,929][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([2.3987e-06, 9.5114e-02, 2.7264e-01, 4.7493e-02, 6.3620e-02, 2.3761e-01,
        1.2304e-01, 4.6052e-02, 6.7829e-02, 2.1938e-02, 2.4666e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,930][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0740, 0.0213, 0.0060, 0.0188, 0.0564, 0.0634, 0.1135, 0.1211, 0.1891,
        0.0465, 0.2901], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,931][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1438, 0.0144, 0.0174, 0.0168, 0.0481, 0.1065, 0.1198, 0.0978, 0.2308,
        0.0655, 0.1391], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,933][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.7480, 0.0537, 0.0028, 0.0576, 0.0042, 0.0066, 0.0078, 0.0275, 0.0190,
        0.0591, 0.0136], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,934][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.1847, 0.0268, 0.0362, 0.0572, 0.0524, 0.0788, 0.0463, 0.1104, 0.1532,
        0.1115, 0.1426], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,935][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0123, 0.0597, 0.0846, 0.0472, 0.1188, 0.1194, 0.0783, 0.2470, 0.0859,
        0.0584, 0.0885], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,937][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0307, 0.0110, 0.0061, 0.0138, 0.0210, 0.0894, 0.0762, 0.1347, 0.3355,
        0.0611, 0.2204], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,938][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.3813, 0.0695, 0.0665, 0.0081, 0.0449, 0.0617, 0.1261, 0.0347, 0.0917,
        0.0174, 0.0981], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,939][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0037, 0.1032, 0.0706, 0.0819, 0.1105, 0.1411, 0.0987, 0.1014, 0.1068,
        0.0882, 0.0938], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,941][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.1699, 0.0902, 0.0699, 0.0646, 0.0588, 0.0500, 0.0764, 0.1487, 0.0455,
        0.1689, 0.0572], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:23,942][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1442, 0.0183, 0.0019, 0.0172, 0.0265, 0.0845, 0.0216, 0.1044, 0.1995,
        0.0952, 0.0966, 0.1900], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,944][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0374, 0.0677, 0.0637, 0.1321, 0.0891, 0.1167, 0.0772, 0.0506, 0.1212,
        0.0823, 0.0666, 0.0954], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,945][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([1.1422e-06, 3.7475e-02, 1.9217e-01, 2.9647e-02, 7.8914e-02, 2.6949e-01,
        1.3607e-01, 4.0446e-02, 7.6546e-02, 2.1210e-02, 6.0812e-02, 5.7215e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,945][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1091, 0.0094, 0.0051, 0.0178, 0.0451, 0.0492, 0.0751, 0.0646, 0.1365,
        0.0403, 0.1786, 0.2691], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,945][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.2224, 0.0043, 0.0088, 0.0125, 0.0276, 0.0890, 0.0592, 0.0472, 0.1443,
        0.0525, 0.1059, 0.2264], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,946][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.8496, 0.0125, 0.0016, 0.0424, 0.0021, 0.0041, 0.0035, 0.0142, 0.0143,
        0.0330, 0.0175, 0.0053], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,946][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2010, 0.0123, 0.0335, 0.0358, 0.0422, 0.0752, 0.0386, 0.0919, 0.1513,
        0.0823, 0.1733, 0.0626], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,946][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0078, 0.0324, 0.0713, 0.0520, 0.1370, 0.0868, 0.0659, 0.2483, 0.0843,
        0.0581, 0.1285, 0.0276], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,947][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0510, 0.0085, 0.0054, 0.0146, 0.0276, 0.0561, 0.0429, 0.0758, 0.1790,
        0.0566, 0.2562, 0.2262], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,947][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.3900, 0.0804, 0.0339, 0.0087, 0.0479, 0.0407, 0.0760, 0.0340, 0.0543,
        0.0210, 0.1760, 0.0372], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,948][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0048, 0.1045, 0.0706, 0.0793, 0.1026, 0.1169, 0.0812, 0.1038, 0.0946,
        0.0752, 0.0806, 0.0860], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,948][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1969, 0.0408, 0.0676, 0.0686, 0.0485, 0.0521, 0.0592, 0.1413, 0.0597,
        0.1642, 0.0640, 0.0370], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:23,949][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.0412, 0.0076, 0.0003, 0.0061, 0.0075, 0.0305, 0.0140, 0.0544, 0.1691,
        0.0534, 0.1152, 0.3178, 0.1829], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,951][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0503, 0.1161, 0.0431, 0.1673, 0.0539, 0.0809, 0.0421, 0.0781, 0.0939,
        0.1016, 0.0698, 0.0685, 0.0346], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,951][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([4.6202e-06, 5.4520e-02, 2.2790e-01, 2.6927e-02, 6.8904e-02, 2.0568e-01,
        7.7614e-02, 4.9465e-02, 6.7972e-02, 2.0989e-02, 5.8085e-02, 7.8196e-02,
        6.3744e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,953][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0789, 0.0029, 0.0013, 0.0046, 0.0160, 0.0171, 0.0343, 0.0466, 0.0901,
        0.0198, 0.1717, 0.2165, 0.3002], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,954][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.0848, 0.0024, 0.0030, 0.0061, 0.0135, 0.0510, 0.0501, 0.0395, 0.0815,
        0.0171, 0.1110, 0.3113, 0.2287], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,956][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.9057, 0.0116, 0.0010, 0.0127, 0.0014, 0.0022, 0.0028, 0.0102, 0.0081,
        0.0243, 0.0106, 0.0043, 0.0052], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,957][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.3607, 0.0101, 0.0176, 0.0334, 0.0284, 0.0369, 0.0379, 0.1046, 0.0906,
        0.0691, 0.1149, 0.0594, 0.0363], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,958][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0120, 0.0370, 0.0570, 0.0493, 0.0815, 0.0463, 0.0543, 0.2728, 0.0591,
        0.0591, 0.1099, 0.0228, 0.1391], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,960][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.0693, 0.0040, 0.0010, 0.0036, 0.0054, 0.0172, 0.0237, 0.0434, 0.1018,
        0.0269, 0.2487, 0.2583, 0.1966], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,961][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.4514, 0.0525, 0.0386, 0.0072, 0.0308, 0.0349, 0.1015, 0.0344, 0.0599,
        0.0161, 0.0921, 0.0469, 0.0339], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,962][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0080, 0.0883, 0.0670, 0.0877, 0.0962, 0.1024, 0.0725, 0.0894, 0.0735,
        0.0736, 0.0836, 0.0745, 0.0834], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,964][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.1847, 0.0632, 0.0627, 0.0610, 0.0499, 0.0501, 0.0605, 0.1072, 0.0499,
        0.1191, 0.0781, 0.0625, 0.0511], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:23,965][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0670, 0.0132, 0.0007, 0.0077, 0.0122, 0.0258, 0.0105, 0.0566, 0.0919,
        0.0457, 0.0473, 0.1232, 0.1813, 0.3169], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,966][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1056, 0.0506, 0.0509, 0.1286, 0.1022, 0.0908, 0.0739, 0.0434, 0.0834,
        0.0654, 0.0411, 0.0648, 0.0267, 0.0727], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,967][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([7.9292e-07, 3.2735e-02, 1.4777e-01, 2.4706e-02, 7.4981e-02, 2.2996e-01,
        1.1649e-01, 2.3146e-02, 5.4458e-02, 1.3647e-02, 5.7204e-02, 5.4885e-02,
        6.6528e-02, 1.0349e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,969][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0791, 0.0054, 0.0020, 0.0099, 0.0234, 0.0215, 0.0416, 0.0339, 0.0700,
        0.0209, 0.1167, 0.1355, 0.2327, 0.2072], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,970][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1472, 0.0034, 0.0041, 0.0074, 0.0126, 0.0383, 0.0291, 0.0313, 0.0890,
        0.0266, 0.0677, 0.1447, 0.1417, 0.2570], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,972][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.8693, 0.0119, 0.0009, 0.0366, 0.0018, 0.0025, 0.0028, 0.0125, 0.0080,
        0.0248, 0.0108, 0.0035, 0.0092, 0.0054], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,973][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.2578, 0.0105, 0.0208, 0.0307, 0.0326, 0.0491, 0.0328, 0.0670, 0.1081,
        0.0726, 0.1296, 0.0491, 0.0537, 0.0857], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,974][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0082, 0.0332, 0.0531, 0.0517, 0.1250, 0.0487, 0.0455, 0.1746, 0.0496,
        0.0496, 0.0914, 0.0213, 0.1966, 0.0514], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,976][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0241, 0.0038, 0.0018, 0.0063, 0.0109, 0.0204, 0.0227, 0.0401, 0.0906,
        0.0228, 0.1328, 0.1257, 0.3066, 0.1913], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,977][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.4461, 0.0526, 0.0223, 0.0062, 0.0380, 0.0165, 0.0787, 0.0354, 0.0322,
        0.0129, 0.1032, 0.0491, 0.0428, 0.0639], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,979][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0039, 0.0834, 0.0554, 0.0639, 0.0818, 0.0891, 0.0801, 0.0787, 0.0750,
        0.0653, 0.0715, 0.0873, 0.0851, 0.0795], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,980][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1726, 0.0395, 0.0509, 0.0467, 0.0454, 0.0441, 0.0600, 0.1390, 0.0455,
        0.1361, 0.0664, 0.0368, 0.0763, 0.0407], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:23,981][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:23:23,983][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[2264],
        [ 695],
        [ 703],
        [3619],
        [1756],
        [ 172],
        [ 407],
        [ 100],
        [  93],
        [ 253],
        [ 362],
        [ 182],
        [ 327],
        [ 102]], device='cuda:0')
[2024-07-24 10:23:23,984][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[2296],
        [3788],
        [3183],
        [9588],
        [4413],
        [ 748],
        [1787],
        [ 609],
        [ 453],
        [1586],
        [1247],
        [ 500],
        [1378],
        [ 442]], device='cuda:0')
[2024-07-24 10:23:23,985][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[45318],
        [42597],
        [40397],
        [40039],
        [40905],
        [38493],
        [35037],
        [34367],
        [40923],
        [40630],
        [40192],
        [40167],
        [39601],
        [38390]], device='cuda:0')
[2024-07-24 10:23:23,987][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[40049],
        [37006],
        [35897],
        [49056],
        [46205],
        [42400],
        [41729],
        [39536],
        [29750],
        [36799],
        [41066],
        [29797],
        [33932],
        [28418]], device='cuda:0')
[2024-07-24 10:23:23,988][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[23868],
        [ 5575],
        [ 4357],
        [ 9700],
        [12391],
        [10768],
        [ 7287],
        [ 5278],
        [ 5284],
        [ 4148],
        [ 4825],
        [ 5852],
        [ 5824],
        [ 4126]], device='cuda:0')
[2024-07-24 10:23:23,989][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[2815],
        [ 621],
        [ 437],
        [ 673],
        [ 443],
        [ 495],
        [ 470],
        [ 479],
        [ 475],
        [ 484],
        [ 490],
        [ 416],
        [ 308],
        [ 301]], device='cuda:0')
[2024-07-24 10:23:23,991][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[24741],
        [20734],
        [20544],
        [15165],
        [13216],
        [14739],
        [12021],
        [12045],
        [13028],
        [13826],
        [12975],
        [13128],
        [14410],
        [13160]], device='cuda:0')
[2024-07-24 10:23:23,992][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[31038],
        [36087],
        [37313],
        [20283],
        [25282],
        [27592],
        [28651],
        [27203],
        [27797],
        [29590],
        [29537],
        [31063],
        [33534],
        [34269]], device='cuda:0')
[2024-07-24 10:23:23,993][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[9063],
        [1492],
        [3489],
        [1993],
        [3640],
        [3521],
        [5269],
        [6889],
        [5888],
        [5204],
        [5733],
        [6382],
        [8565],
        [6940]], device='cuda:0')
[2024-07-24 10:23:23,994][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[30911],
        [46416],
        [45432],
        [46927],
        [42278],
        [41611],
        [40392],
        [29145],
        [30120],
        [33048],
        [35454],
        [34165],
        [30307],
        [29167]], device='cuda:0')
[2024-07-24 10:23:23,995][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 7602],
        [21012],
        [25377],
        [25299],
        [24851],
        [21558],
        [22423],
        [ 9180],
        [ 9311],
        [ 5412],
        [ 9375],
        [13435],
        [14840],
        [ 9491]], device='cuda:0')
[2024-07-24 10:23:23,996][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[29354],
        [20254],
        [17971],
        [15355],
        [16112],
        [16575],
        [16874],
        [17311],
        [17529],
        [18022],
        [18336],
        [18382],
        [18443],
        [18340]], device='cuda:0')
[2024-07-24 10:23:23,997][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[1752],
        [3768],
        [3635],
        [5645],
        [4739],
        [4511],
        [4568],
        [4292],
        [4113],
        [4149],
        [4078],
        [3988],
        [3821],
        [3812]], device='cuda:0')
[2024-07-24 10:23:23,998][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[9344],
        [4662],
        [6698],
        [4029],
        [5346],
        [6073],
        [6396],
        [6805],
        [7636],
        [7235],
        [7701],
        [8035],
        [8640],
        [9394]], device='cuda:0')
[2024-07-24 10:23:23,999][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[2957],
        [4675],
        [2529],
        [4380],
        [4238],
        [4614],
        [3975],
        [5113],
        [5294],
        [5947],
        [6073],
        [6199],
        [5459],
        [5643]], device='cuda:0')
[2024-07-24 10:23:24,001][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 2623],
        [ 2643],
        [15270],
        [17969],
        [18827],
        [18182],
        [26985],
        [28081],
        [29226],
        [31503],
        [31640],
        [30569],
        [31544],
        [29800]], device='cuda:0')
[2024-07-24 10:23:24,002][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 7131],
        [ 3894],
        [ 5040],
        [ 7171],
        [ 8750],
        [10697],
        [11598],
        [12368],
        [11460],
        [11110],
        [10306],
        [10574],
        [10617],
        [10741]], device='cuda:0')
[2024-07-24 10:23:24,003][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[1202],
        [2949],
        [6173],
        [7190],
        [6463],
        [3580],
        [4790],
        [5797],
        [4409],
        [4217],
        [4757],
        [4368],
        [4535],
        [4388]], device='cuda:0')
[2024-07-24 10:23:24,004][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 7263],
        [ 7112],
        [ 8530],
        [ 4577],
        [13720],
        [10296],
        [23130],
        [31134],
        [28750],
        [32279],
        [29264],
        [26682],
        [24829],
        [23412]], device='cuda:0')
[2024-07-24 10:23:24,006][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[15512],
        [18140],
        [11886],
        [ 8533],
        [11055],
        [13756],
        [13202],
        [11110],
        [ 8277],
        [ 7706],
        [ 6091],
        [10123],
        [ 9742],
        [11639]], device='cuda:0')
[2024-07-24 10:23:24,007][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[24273],
        [23545],
        [24089],
        [22206],
        [10318],
        [22307],
        [21664],
        [19329],
        [13466],
        [ 6512],
        [ 4136],
        [10259],
        [17646],
        [13867]], device='cuda:0')
[2024-07-24 10:23:24,008][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 8392],
        [ 2466],
        [11842],
        [ 5048],
        [ 3038],
        [ 6483],
        [ 5164],
        [ 4759],
        [ 3337],
        [ 2135],
        [ 1777],
        [ 1948],
        [ 2349],
        [ 2161]], device='cuda:0')
[2024-07-24 10:23:24,010][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[25073],
        [ 1874],
        [ 1913],
        [  743],
        [  881],
        [ 1030],
        [ 1156],
        [ 3317],
        [ 2802],
        [ 2074],
        [ 1846],
        [ 1788],
        [ 2004],
        [ 1746]], device='cuda:0')
[2024-07-24 10:23:24,011][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[22332],
        [20077],
        [13878],
        [13638],
        [25744],
        [31877],
        [34590],
        [30848],
        [26862],
        [24971],
        [19917],
        [14572],
        [16455],
        [20973]], device='cuda:0')
[2024-07-24 10:23:24,012][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 3661],
        [ 6532],
        [ 7097],
        [14348],
        [ 9790],
        [ 8903],
        [ 8170],
        [12486],
        [ 8473],
        [14584],
        [13923],
        [14204],
        [13339],
        [13757]], device='cuda:0')
[2024-07-24 10:23:24,014][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[17297],
        [11186],
        [ 6977],
        [10591],
        [ 6907],
        [ 5375],
        [ 4998],
        [ 4997],
        [ 4635],
        [ 5339],
        [ 6368],
        [ 7013],
        [ 6280],
        [ 5828]], device='cuda:0')
[2024-07-24 10:23:24,015][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 5380],
        [ 5392],
        [ 8114],
        [ 7935],
        [11091],
        [ 9044],
        [ 9813],
        [12999],
        [12252],
        [12282],
        [13452],
        [12807],
        [12937],
        [13905]], device='cuda:0')
[2024-07-24 10:23:24,016][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[35643],
        [43212],
        [37241],
        [37481],
        [36400],
        [32444],
        [25892],
        [21240],
        [29045],
        [29593],
        [32972],
        [31296],
        [27787],
        [28276]], device='cuda:0')
[2024-07-24 10:23:24,018][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[37995],
        [42002],
        [44987],
        [42254],
        [43007],
        [42968],
        [42571],
        [39352],
        [40582],
        [39105],
        [39080],
        [38023],
        [39861],
        [39414]], device='cuda:0')
[2024-07-24 10:23:24,019][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[3259],
        [3259],
        [3259],
        [3259],
        [3259],
        [3259],
        [3259],
        [3259],
        [3259],
        [3259],
        [3259],
        [3259],
        [3259],
        [3259]], device='cuda:0')
[2024-07-24 10:23:24,049][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:24,050][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,050][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,050][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,051][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,051][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,051][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,052][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,053][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,054][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,055][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,056][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,057][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,058][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([9.9989e-01, 1.1390e-04], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,058][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.0112, 0.9888], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,059][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.8615, 0.1385], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,059][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.1836, 0.8164], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,059][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.8036, 0.1964], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,059][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.9901, 0.0099], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,060][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.7857, 0.2143], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,060][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.7429, 0.2571], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,060][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.9452, 0.0548], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,061][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.9546, 0.0454], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,061][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.8331, 0.1669], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,061][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.0272, 0.9728], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,062][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([9.9702e-01, 1.8022e-05, 2.9621e-03], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,062][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0094, 0.6724, 0.3182], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,062][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.7984, 0.1169, 0.0847], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,063][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3576, 0.2425, 0.3999], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,063][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.9279, 0.0328, 0.0393], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,063][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.9733, 0.0106, 0.0161], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,064][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.8431, 0.1262, 0.0307], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,064][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.8200, 0.0335, 0.1465], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,064][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.9720, 0.0221, 0.0059], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,065][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.9358, 0.0339, 0.0303], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,065][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.8183, 0.0527, 0.1290], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,065][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0206, 0.6380, 0.3414], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,066][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Mary] are: tensor([9.7569e-01, 2.7086e-04, 1.6202e-02, 7.8413e-03], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,066][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Mary] are: tensor([0.0061, 0.5546, 0.3156, 0.1237], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,066][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Mary] are: tensor([0.7481, 0.1044, 0.0217, 0.1258], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,067][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Mary] are: tensor([0.5110, 0.1761, 0.1413, 0.1715], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,068][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Mary] are: tensor([0.4448, 0.2572, 0.1998, 0.0982], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,069][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Mary] are: tensor([0.8722, 0.0268, 0.0418, 0.0592], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,071][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Mary] are: tensor([0.6140, 0.1395, 0.0348, 0.2117], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,072][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Mary] are: tensor([0.4538, 0.1449, 0.3417, 0.0596], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,073][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Mary] are: tensor([0.9402, 0.0281, 0.0038, 0.0279], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,075][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Mary] are: tensor([0.9066, 0.0231, 0.0096, 0.0608], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,076][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Mary] are: tensor([0.7380, 0.0517, 0.1054, 0.1049], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,077][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Mary] are: tensor([0.0091, 0.5363, 0.2565, 0.1980], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,078][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ went] are: tensor([9.7546e-01, 2.2885e-04, 1.5768e-02, 7.3976e-03, 1.1457e-03],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,080][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0018, 0.4838, 0.3085, 0.1482, 0.0576], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,081][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.2531, 0.0855, 0.0941, 0.3075, 0.2597], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,082][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.1737, 0.1369, 0.1595, 0.1840, 0.3458], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,084][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.2991, 0.0431, 0.0882, 0.0622, 0.5074], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,085][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.7067, 0.0123, 0.0263, 0.1087, 0.1460], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,087][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.3444, 0.1406, 0.0693, 0.2489, 0.1967], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,088][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.4669, 0.0528, 0.1660, 0.0692, 0.2451], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,089][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.8912, 0.0209, 0.0122, 0.0462, 0.0295], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,091][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.8449, 0.0152, 0.0162, 0.0558, 0.0680], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,092][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.5098, 0.0338, 0.0795, 0.0641, 0.3128], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,094][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0103, 0.3822, 0.2114, 0.1700, 0.2262], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,094][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([8.2820e-01, 2.1108e-05, 2.7168e-03, 1.6737e-03, 1.1300e-04, 1.6728e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,096][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0046, 0.3521, 0.1364, 0.1115, 0.1995, 0.1959], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,097][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.6391, 0.0327, 0.0323, 0.0589, 0.0672, 0.1699], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,099][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1004, 0.0830, 0.0711, 0.1999, 0.3037, 0.2418], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,100][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.5812, 0.0030, 0.0058, 0.0312, 0.0770, 0.3019], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,101][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([9.1987e-01, 8.4754e-04, 1.9350e-03, 2.0719e-02, 2.1727e-02, 3.4898e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,102][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.7126, 0.0304, 0.0201, 0.1310, 0.0480, 0.0579], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,104][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.5164, 0.0010, 0.0052, 0.0148, 0.0329, 0.4298], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,104][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.9375, 0.0050, 0.0019, 0.0212, 0.0063, 0.0281], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,105][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.7613, 0.0114, 0.0170, 0.0610, 0.0439, 0.1054], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,105][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.4761, 0.0109, 0.0316, 0.0373, 0.1233, 0.3207], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,105][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0093, 0.3399, 0.1702, 0.1147, 0.1659, 0.2000], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,106][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ the] are: tensor([2.2548e-01, 4.7381e-06, 9.3599e-04, 3.1804e-04, 2.4329e-05, 5.5055e-02,
        7.1818e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,106][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0010, 0.3392, 0.1478, 0.1002, 0.0720, 0.1664, 0.1734],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,106][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.4742, 0.0178, 0.0291, 0.0404, 0.0480, 0.1506, 0.2399],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,107][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0764, 0.0605, 0.0994, 0.1414, 0.1557, 0.2296, 0.2371],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,107][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1221, 0.0167, 0.0156, 0.0247, 0.1159, 0.5295, 0.1755],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,108][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.7995, 0.0055, 0.0076, 0.0278, 0.0467, 0.0866, 0.0264],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,109][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.6172, 0.0444, 0.0185, 0.1648, 0.0554, 0.0408, 0.0588],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,111][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1699, 0.0052, 0.0154, 0.0067, 0.0518, 0.6845, 0.0664],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,112][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.8965, 0.0114, 0.0042, 0.0201, 0.0069, 0.0357, 0.0251],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,114][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.7075, 0.0111, 0.0138, 0.0395, 0.0511, 0.0807, 0.0963],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,115][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.3669, 0.0140, 0.0346, 0.0300, 0.1423, 0.2470, 0.1652],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,116][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0057, 0.3402, 0.1479, 0.0968, 0.1440, 0.1797, 0.0858],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,117][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([1.6933e-01, 8.9036e-06, 1.1804e-03, 3.4030e-04, 4.6578e-05, 7.3606e-02,
        7.5494e-01, 5.4687e-04], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,119][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([0.0020, 0.1918, 0.1015, 0.0559, 0.0533, 0.1094, 0.2002, 0.2859],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,120][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.1972, 0.0206, 0.0212, 0.0275, 0.0535, 0.1273, 0.1847, 0.3681],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,121][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.0989, 0.0327, 0.0548, 0.0609, 0.0810, 0.1173, 0.1593, 0.3951],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,123][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.0415, 0.0164, 0.0137, 0.0130, 0.1212, 0.4991, 0.1781, 0.1170],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,124][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.4410, 0.0186, 0.0168, 0.0315, 0.1204, 0.1696, 0.0897, 0.1124],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,126][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.1839, 0.0549, 0.0244, 0.0981, 0.0918, 0.0502, 0.1225, 0.3742],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,127][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.0878, 0.0074, 0.0082, 0.0041, 0.0579, 0.5855, 0.1055, 0.1435],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,129][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.5521, 0.0252, 0.0054, 0.0279, 0.0184, 0.0348, 0.0512, 0.2850],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,130][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.7212, 0.0082, 0.0100, 0.0238, 0.0374, 0.0423, 0.0554, 0.1018],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,131][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.2814, 0.0165, 0.0268, 0.0215, 0.1396, 0.1734, 0.1445, 0.1963],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,133][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.0054, 0.2584, 0.1455, 0.1047, 0.1397, 0.1663, 0.0879, 0.0920],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,134][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([2.6912e-01, 1.0210e-05, 1.3030e-03, 4.2947e-04, 4.8411e-05, 4.6705e-02,
        5.7407e-01, 8.5287e-04, 1.0746e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,135][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0004, 0.2267, 0.0655, 0.0539, 0.0803, 0.0538, 0.0996, 0.3452, 0.0746],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,137][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0682, 0.0134, 0.0160, 0.0172, 0.0161, 0.0897, 0.1479, 0.3288, 0.3026],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,138][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0400, 0.0602, 0.0648, 0.1260, 0.1577, 0.1072, 0.1147, 0.1400, 0.1893],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,140][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2129, 0.0288, 0.0085, 0.0318, 0.0765, 0.1932, 0.1195, 0.1055, 0.2233],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,141][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.5636, 0.0072, 0.0067, 0.0355, 0.0423, 0.0651, 0.0318, 0.0708, 0.1770],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,142][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1046, 0.0623, 0.0198, 0.1629, 0.0495, 0.0446, 0.0667, 0.3348, 0.1548],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,144][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1651, 0.0056, 0.0054, 0.0127, 0.0331, 0.2559, 0.0619, 0.1813, 0.2790],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,145][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.7522, 0.0100, 0.0016, 0.0215, 0.0042, 0.0134, 0.0117, 0.1341, 0.0513],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,147][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3437, 0.0225, 0.0217, 0.0831, 0.0550, 0.1096, 0.1011, 0.0841, 0.1792],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,148][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1476, 0.0157, 0.0234, 0.0277, 0.0905, 0.1692, 0.1098, 0.0791, 0.3371],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,150][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0069, 0.3258, 0.1385, 0.0835, 0.1148, 0.1354, 0.0733, 0.0766, 0.0451],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,151][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([1.5551e-01, 3.7940e-05, 1.9363e-03, 9.9308e-04, 2.0150e-04, 5.4049e-02,
        6.4769e-01, 1.1682e-03, 1.2360e-01, 1.4817e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,151][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([1.8070e-04, 2.0728e-01, 7.3136e-02, 4.0042e-02, 5.5221e-02, 6.9982e-02,
        9.7739e-02, 3.0307e-01, 1.0115e-01, 5.2204e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,152][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.1330, 0.0345, 0.0112, 0.0319, 0.0296, 0.0348, 0.0699, 0.3442, 0.0960,
        0.2149], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,152][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.0271, 0.0684, 0.0507, 0.0605, 0.1099, 0.0778, 0.0987, 0.3001, 0.1413,
        0.0657], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,153][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.0446, 0.1193, 0.0107, 0.0278, 0.0526, 0.0703, 0.1381, 0.2625, 0.1965,
        0.0777], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,153][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.2179, 0.0360, 0.0143, 0.0461, 0.0464, 0.0282, 0.0586, 0.2328, 0.2390,
        0.0807], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,153][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.0536, 0.1136, 0.0239, 0.1273, 0.0830, 0.0489, 0.0684, 0.2376, 0.0972,
        0.1465], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,154][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0121, 0.0522, 0.0075, 0.0131, 0.0173, 0.0505, 0.0754, 0.4682, 0.2518,
        0.0520], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,155][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.4778, 0.0330, 0.0029, 0.0295, 0.0115, 0.0137, 0.0232, 0.2114, 0.0651,
        0.1319], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,156][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.3577, 0.0400, 0.0203, 0.0754, 0.0590, 0.0525, 0.0857, 0.1144, 0.1163,
        0.0787], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,157][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.1022, 0.0280, 0.0246, 0.0276, 0.1338, 0.1038, 0.1142, 0.1351, 0.2489,
        0.0819], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,159][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.0040, 0.2995, 0.1387, 0.0918, 0.1012, 0.1419, 0.0734, 0.0695, 0.0459,
        0.0341], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,160][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([1.1884e-01, 9.0653e-06, 1.5921e-03, 4.6661e-04, 5.7546e-05, 8.3221e-02,
        6.4065e-01, 8.3184e-04, 1.3938e-01, 9.4877e-03, 5.4658e-03],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,161][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0010, 0.1652, 0.0622, 0.0513, 0.1118, 0.0441, 0.1328, 0.2470, 0.0725,
        0.0276, 0.0844], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,162][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0430, 0.0161, 0.0129, 0.0225, 0.0217, 0.0672, 0.1156, 0.2365, 0.1791,
        0.1381, 0.1473], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,164][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0360, 0.0406, 0.0297, 0.0456, 0.0754, 0.0955, 0.1261, 0.1415, 0.2156,
        0.0777, 0.1163], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,165][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0540, 0.0177, 0.0034, 0.0099, 0.0219, 0.2071, 0.1066, 0.0832, 0.2444,
        0.0318, 0.2202], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,166][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.2525, 0.0130, 0.0055, 0.0314, 0.0428, 0.0615, 0.0426, 0.0819, 0.1810,
        0.0472, 0.2406], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,168][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0600, 0.0453, 0.0153, 0.0762, 0.0325, 0.0518, 0.0647, 0.2358, 0.1444,
        0.1394, 0.1348], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,169][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0836, 0.0053, 0.0020, 0.0040, 0.0129, 0.1833, 0.0475, 0.1261, 0.2584,
        0.0309, 0.2460], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,171][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.4495, 0.0208, 0.0018, 0.0145, 0.0059, 0.0157, 0.0133, 0.1680, 0.0640,
        0.0898, 0.1567], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,172][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.3594, 0.0244, 0.0110, 0.0473, 0.0579, 0.0764, 0.0649, 0.0797, 0.1093,
        0.0637, 0.1061], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,174][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0970, 0.0115, 0.0120, 0.0153, 0.0634, 0.1185, 0.0800, 0.0643, 0.2082,
        0.0453, 0.2844], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,175][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0041, 0.2698, 0.1245, 0.0851, 0.1051, 0.1373, 0.0670, 0.0719, 0.0493,
        0.0417, 0.0441], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,176][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([2.8407e-02, 3.7990e-07, 1.2085e-04, 3.3111e-05, 3.6873e-06, 6.9855e-03,
        6.9174e-02, 5.7716e-05, 1.6258e-02, 1.6395e-03, 4.8232e-04, 8.7684e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,177][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0005, 0.2400, 0.0663, 0.0475, 0.0497, 0.0463, 0.0840, 0.2273, 0.0677,
        0.0395, 0.1019, 0.0293], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,179][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0201, 0.0029, 0.0069, 0.0060, 0.0126, 0.0454, 0.0746, 0.2391, 0.1400,
        0.0523, 0.0999, 0.3004], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,180][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0355, 0.0322, 0.0483, 0.0875, 0.0815, 0.0767, 0.1003, 0.1156, 0.1586,
        0.0731, 0.0908, 0.0998], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,182][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1383, 0.0129, 0.0042, 0.0172, 0.0409, 0.1069, 0.0634, 0.0692, 0.1649,
        0.0487, 0.1815, 0.1518], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,183][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.4472, 0.0056, 0.0039, 0.0324, 0.0222, 0.0406, 0.0183, 0.0412, 0.1210,
        0.0663, 0.1357, 0.0658], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,185][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1191, 0.0315, 0.0141, 0.0712, 0.0231, 0.0366, 0.0505, 0.1773, 0.1155,
        0.1226, 0.1098, 0.1285], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,186][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0920, 0.0048, 0.0021, 0.0065, 0.0088, 0.0933, 0.0196, 0.0775, 0.1368,
        0.0516, 0.1260, 0.3809], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,188][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.5971, 0.0051, 0.0019, 0.0140, 0.0034, 0.0136, 0.0103, 0.0905, 0.0524,
        0.0845, 0.0846, 0.0425], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,189][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1824, 0.0120, 0.0196, 0.0501, 0.0390, 0.0890, 0.0970, 0.0620, 0.1575,
        0.0531, 0.1055, 0.1327], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,191][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1175, 0.0055, 0.0120, 0.0115, 0.0395, 0.0804, 0.0615, 0.0404, 0.1708,
        0.0426, 0.1794, 0.2389], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,192][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0066, 0.2766, 0.1235, 0.0788, 0.0983, 0.1246, 0.0650, 0.0677, 0.0438,
        0.0361, 0.0397, 0.0393], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,193][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([4.1494e-02, 1.4514e-06, 1.9488e-04, 1.3350e-04, 9.8618e-06, 9.2465e-03,
        1.1747e-01, 1.3039e-04, 1.6733e-02, 2.1401e-03, 1.0140e-03, 8.1128e-01,
        1.4867e-04], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,195][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0005, 0.0876, 0.0786, 0.0250, 0.0155, 0.0437, 0.0564, 0.1263, 0.0799,
        0.0225, 0.1356, 0.0517, 0.2769], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,196][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0735, 0.0170, 0.0159, 0.0203, 0.0236, 0.0675, 0.0785, 0.1815, 0.1039,
        0.0783, 0.0868, 0.1180, 0.1352], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,198][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0520, 0.0130, 0.0115, 0.0346, 0.0333, 0.0531, 0.0663, 0.1246, 0.1193,
        0.0463, 0.1036, 0.0639, 0.2784], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,198][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0394, 0.0047, 0.0011, 0.0053, 0.0126, 0.0444, 0.0361, 0.0438, 0.1023,
        0.0134, 0.2381, 0.2539, 0.2049], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,199][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.2757, 0.0025, 0.0014, 0.0099, 0.0085, 0.0193, 0.0169, 0.0360, 0.1170,
        0.0311, 0.1708, 0.1422, 0.1686], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,199][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.1030, 0.0238, 0.0092, 0.0548, 0.0324, 0.0289, 0.0390, 0.2301, 0.0591,
        0.0885, 0.0702, 0.0830, 0.1779], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,199][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([2.6314e-02, 9.0332e-04, 2.4019e-04, 9.8152e-04, 2.0516e-03, 3.0943e-02,
        1.0146e-02, 2.8990e-02, 8.2273e-02, 1.2830e-02, 1.3545e-01, 5.4174e-01,
        1.2715e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,200][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.4062, 0.0070, 0.0023, 0.0073, 0.0059, 0.0224, 0.0157, 0.1363, 0.0835,
        0.0683, 0.1321, 0.0754, 0.0377], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,200][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.2976, 0.0052, 0.0073, 0.0309, 0.0428, 0.0584, 0.0716, 0.0580, 0.1022,
        0.0362, 0.0763, 0.1069, 0.1068], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,201][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.1221, 0.0028, 0.0060, 0.0068, 0.0314, 0.0572, 0.0453, 0.0385, 0.1324,
        0.0296, 0.1362, 0.2022, 0.1894], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,201][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0045, 0.2257, 0.0925, 0.0735, 0.0920, 0.1159, 0.0656, 0.0713, 0.0438,
        0.0413, 0.0419, 0.0455, 0.0866], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,202][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([3.0957e-02, 5.5780e-07, 1.1147e-04, 4.3979e-05, 5.1815e-06, 7.0337e-03,
        7.0884e-02, 5.8973e-05, 1.5170e-02, 1.8331e-03, 5.5823e-04, 7.9700e-01,
        6.9049e-05, 7.6274e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,202][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([3.0410e-04, 1.5770e-01, 4.6464e-02, 3.3627e-02, 4.1396e-02, 2.5380e-02,
        5.2790e-02, 1.4397e-01, 3.2584e-02, 2.3273e-02, 4.6626e-02, 1.6562e-02,
        3.4816e-01, 3.1176e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,203][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0139, 0.0037, 0.0069, 0.0056, 0.0109, 0.0298, 0.0531, 0.1682, 0.0957,
        0.0569, 0.0691, 0.2298, 0.1267, 0.1299], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,205][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0167, 0.0199, 0.0283, 0.0577, 0.0606, 0.0555, 0.0605, 0.0688, 0.0882,
        0.0443, 0.0625, 0.0557, 0.2603, 0.1211], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,206][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0970, 0.0083, 0.0019, 0.0118, 0.0207, 0.0418, 0.0341, 0.0366, 0.0809,
        0.0248, 0.0972, 0.1129, 0.1778, 0.2542], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,208][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.3245, 0.0043, 0.0019, 0.0187, 0.0120, 0.0197, 0.0117, 0.0302, 0.0797,
        0.0467, 0.0974, 0.0559, 0.1402, 0.1571], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,209][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0549, 0.0173, 0.0081, 0.0455, 0.0168, 0.0227, 0.0447, 0.0984, 0.0816,
        0.0713, 0.0968, 0.1053, 0.2021, 0.1343], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,210][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0489, 0.0020, 0.0005, 0.0030, 0.0022, 0.0227, 0.0067, 0.0351, 0.0503,
        0.0184, 0.0562, 0.2039, 0.1225, 0.4277], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,211][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.5258, 0.0043, 0.0013, 0.0139, 0.0030, 0.0118, 0.0101, 0.0785, 0.0446,
        0.0753, 0.0754, 0.0435, 0.0421, 0.0702], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,213][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1429, 0.0099, 0.0151, 0.0455, 0.0323, 0.0732, 0.0764, 0.0411, 0.1296,
        0.0457, 0.0665, 0.1066, 0.1073, 0.1078], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,215][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0551, 0.0032, 0.0066, 0.0065, 0.0234, 0.0525, 0.0372, 0.0234, 0.1038,
        0.0251, 0.1311, 0.1402, 0.1375, 0.2545], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,216][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0071, 0.2411, 0.1087, 0.0647, 0.0880, 0.1099, 0.0610, 0.0650, 0.0405,
        0.0329, 0.0365, 0.0365, 0.0673, 0.0407], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,267][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:24,268][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,269][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,270][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,270][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,270][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,271][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,271][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,271][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,272][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,272][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,272][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,273][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,273][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([9.9989e-01, 1.1390e-04], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,273][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.0112, 0.9888], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,274][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.9246, 0.0754], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,274][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.1836, 0.8164], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,274][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.8036, 0.1964], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,275][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.9901, 0.0099], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,275][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.7857, 0.2143], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,275][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.7429, 0.2571], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,275][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.9452, 0.0548], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,276][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.9546, 0.0454], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,278][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.8331, 0.1669], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,279][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.0543, 0.9457], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,280][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([9.9702e-01, 1.8022e-05, 2.9621e-03], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,281][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0094, 0.6724, 0.3182], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,282][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.9374, 0.0561, 0.0065], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,284][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3576, 0.2425, 0.3999], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,285][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.9279, 0.0328, 0.0393], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,287][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9733, 0.0106, 0.0161], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,288][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.8431, 0.1262, 0.0307], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,289][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.8200, 0.0335, 0.1465], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,291][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9720, 0.0221, 0.0059], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,292][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.9358, 0.0339, 0.0303], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,293][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.8183, 0.0527, 0.1290], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,295][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0975, 0.2399, 0.6626], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,296][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Mary] are: tensor([9.7569e-01, 2.7086e-04, 1.6202e-02, 7.8413e-03], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,297][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Mary] are: tensor([0.0061, 0.5546, 0.3156, 0.1237], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,299][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Mary] are: tensor([0.8496, 0.0859, 0.0032, 0.0613], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,300][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Mary] are: tensor([0.5110, 0.1761, 0.1413, 0.1715], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,301][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Mary] are: tensor([0.4448, 0.2572, 0.1998, 0.0982], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,303][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Mary] are: tensor([0.8722, 0.0268, 0.0418, 0.0592], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,304][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Mary] are: tensor([0.6140, 0.1395, 0.0348, 0.2117], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,306][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Mary] are: tensor([0.4538, 0.1449, 0.3417, 0.0596], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,307][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Mary] are: tensor([0.9402, 0.0281, 0.0038, 0.0279], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,309][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Mary] are: tensor([0.9066, 0.0231, 0.0096, 0.0608], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,309][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Mary] are: tensor([0.7380, 0.0517, 0.1054, 0.1049], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,309][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Mary] are: tensor([0.0934, 0.1963, 0.5861, 0.1241], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,310][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([9.7546e-01, 2.2885e-04, 1.5768e-02, 7.3976e-03, 1.1457e-03],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,310][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0018, 0.4838, 0.3085, 0.1482, 0.0576], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,310][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.6689, 0.1048, 0.0133, 0.1372, 0.0757], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,311][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.1737, 0.1369, 0.1595, 0.1840, 0.3458], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,311][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.2991, 0.0431, 0.0882, 0.0622, 0.5074], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,311][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.7067, 0.0123, 0.0263, 0.1087, 0.1460], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,312][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.3444, 0.1406, 0.0693, 0.2489, 0.1967], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,313][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.4669, 0.0528, 0.1660, 0.0692, 0.2451], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,314][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.8912, 0.0209, 0.0122, 0.0462, 0.0295], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,315][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.8449, 0.0152, 0.0162, 0.0558, 0.0680], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,317][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.5098, 0.0338, 0.0795, 0.0641, 0.3128], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,318][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.0895, 0.0445, 0.4802, 0.0822, 0.3036], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,319][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([8.2820e-01, 2.1108e-05, 2.7168e-03, 1.6737e-03, 1.1300e-04, 1.6728e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,320][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0046, 0.3521, 0.1364, 0.1115, 0.1995, 0.1959], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,321][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.8390, 0.0461, 0.0090, 0.0542, 0.0359, 0.0157], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,323][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1004, 0.0830, 0.0711, 0.1999, 0.3037, 0.2418], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,324][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.5812, 0.0030, 0.0058, 0.0312, 0.0770, 0.3019], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,325][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.1987e-01, 8.4754e-04, 1.9350e-03, 2.0719e-02, 2.1727e-02, 3.4898e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,326][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.7126, 0.0304, 0.0201, 0.1310, 0.0480, 0.0579], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,328][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.5164, 0.0010, 0.0052, 0.0148, 0.0329, 0.4298], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,329][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.9375, 0.0050, 0.0019, 0.0212, 0.0063, 0.0281], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,331][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.7613, 0.0114, 0.0170, 0.0610, 0.0439, 0.1054], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,332][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.4761, 0.0109, 0.0316, 0.0373, 0.1233, 0.3207], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,334][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0988, 0.0483, 0.1790, 0.0517, 0.0631, 0.5591], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,334][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([2.2548e-01, 4.7381e-06, 9.3599e-04, 3.1804e-04, 2.4329e-05, 5.5055e-02,
        7.1818e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,336][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0010, 0.3392, 0.1478, 0.1002, 0.0720, 0.1664, 0.1734],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,337][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.8352, 0.0283, 0.0086, 0.0365, 0.0302, 0.0149, 0.0464],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,339][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0764, 0.0605, 0.0994, 0.1414, 0.1557, 0.2296, 0.2371],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,340][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1221, 0.0167, 0.0156, 0.0247, 0.1159, 0.5295, 0.1755],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,341][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.7995, 0.0055, 0.0076, 0.0278, 0.0467, 0.0866, 0.0264],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,343][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.6172, 0.0444, 0.0185, 0.1648, 0.0554, 0.0408, 0.0588],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,344][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1699, 0.0052, 0.0154, 0.0067, 0.0518, 0.6845, 0.0664],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,346][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.8965, 0.0114, 0.0042, 0.0201, 0.0069, 0.0357, 0.0251],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,347][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.7075, 0.0111, 0.0138, 0.0395, 0.0511, 0.0807, 0.0963],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,349][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.3669, 0.0140, 0.0346, 0.0300, 0.1423, 0.2470, 0.1652],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,350][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0493, 0.0390, 0.1380, 0.0294, 0.0463, 0.3819, 0.3161],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,351][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([1.6933e-01, 8.9036e-06, 1.1804e-03, 3.4030e-04, 4.6578e-05, 7.3606e-02,
        7.5494e-01, 5.4687e-04], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,352][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([0.0020, 0.1918, 0.1015, 0.0559, 0.0533, 0.1094, 0.2002, 0.2859],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,354][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([0.6797, 0.0445, 0.0078, 0.0310, 0.0347, 0.0143, 0.0415, 0.1465],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,355][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.0989, 0.0327, 0.0548, 0.0609, 0.0810, 0.1173, 0.1593, 0.3951],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,356][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.0415, 0.0164, 0.0137, 0.0130, 0.1212, 0.4991, 0.1781, 0.1170],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,356][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.4410, 0.0186, 0.0168, 0.0315, 0.1204, 0.1696, 0.0897, 0.1124],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,357][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.1839, 0.0549, 0.0244, 0.0981, 0.0918, 0.0502, 0.1225, 0.3742],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,357][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.0878, 0.0074, 0.0082, 0.0041, 0.0579, 0.5855, 0.1055, 0.1435],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,357][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.5521, 0.0252, 0.0054, 0.0279, 0.0184, 0.0348, 0.0512, 0.2850],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,358][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.7212, 0.0082, 0.0100, 0.0238, 0.0374, 0.0423, 0.0554, 0.1018],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,358][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.2814, 0.0165, 0.0268, 0.0215, 0.1396, 0.1734, 0.1445, 0.1963],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,359][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.0171, 0.0254, 0.0730, 0.0112, 0.0409, 0.2652, 0.2781, 0.2892],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,359][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([2.6912e-01, 1.0210e-05, 1.3030e-03, 4.2947e-04, 4.8411e-05, 4.6705e-02,
        5.7407e-01, 8.5287e-04, 1.0746e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,359][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0004, 0.2267, 0.0655, 0.0539, 0.0803, 0.0538, 0.0996, 0.3452, 0.0746],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,361][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.3775, 0.0505, 0.0175, 0.0425, 0.0323, 0.0231, 0.0755, 0.2694, 0.1117],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,362][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0400, 0.0602, 0.0648, 0.1260, 0.1577, 0.1072, 0.1147, 0.1400, 0.1893],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,363][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2129, 0.0288, 0.0085, 0.0318, 0.0765, 0.1932, 0.1195, 0.1055, 0.2233],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,364][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.5636, 0.0072, 0.0067, 0.0355, 0.0423, 0.0651, 0.0318, 0.0708, 0.1770],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,366][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1046, 0.0623, 0.0198, 0.1629, 0.0495, 0.0446, 0.0667, 0.3348, 0.1548],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,367][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1651, 0.0056, 0.0054, 0.0127, 0.0331, 0.2559, 0.0619, 0.1813, 0.2790],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,369][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.7522, 0.0100, 0.0016, 0.0215, 0.0042, 0.0134, 0.0117, 0.1341, 0.0513],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,370][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.3437, 0.0225, 0.0217, 0.0831, 0.0550, 0.1096, 0.1011, 0.0841, 0.1792],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,372][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1476, 0.0157, 0.0234, 0.0277, 0.0905, 0.1692, 0.1098, 0.0791, 0.3371],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,373][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0410, 0.0247, 0.0745, 0.0166, 0.0215, 0.1313, 0.1532, 0.1666, 0.3707],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,374][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([1.5551e-01, 3.7940e-05, 1.9363e-03, 9.9308e-04, 2.0150e-04, 5.4049e-02,
        6.4769e-01, 1.1682e-03, 1.2360e-01, 1.4817e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,375][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([1.8070e-04, 2.0728e-01, 7.3136e-02, 4.0042e-02, 5.5221e-02, 6.9982e-02,
        9.7739e-02, 3.0307e-01, 1.0115e-01, 5.2204e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,376][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.3482, 0.1045, 0.0110, 0.0633, 0.0544, 0.0117, 0.0394, 0.2149, 0.0345,
        0.1182], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,378][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.0271, 0.0684, 0.0507, 0.0605, 0.1099, 0.0778, 0.0987, 0.3001, 0.1413,
        0.0657], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,379][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.0446, 0.1193, 0.0107, 0.0278, 0.0526, 0.0703, 0.1381, 0.2625, 0.1965,
        0.0777], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,381][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.2179, 0.0360, 0.0143, 0.0461, 0.0464, 0.0282, 0.0586, 0.2328, 0.2390,
        0.0807], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,382][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.0536, 0.1136, 0.0239, 0.1273, 0.0830, 0.0489, 0.0684, 0.2376, 0.0972,
        0.1465], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,383][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0121, 0.0522, 0.0075, 0.0131, 0.0173, 0.0505, 0.0754, 0.4682, 0.2518,
        0.0520], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,385][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.4778, 0.0330, 0.0029, 0.0295, 0.0115, 0.0137, 0.0232, 0.2114, 0.0651,
        0.1319], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,386][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.3577, 0.0400, 0.0203, 0.0754, 0.0590, 0.0525, 0.0857, 0.1144, 0.1163,
        0.0787], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,388][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.1022, 0.0280, 0.0246, 0.0276, 0.1338, 0.1038, 0.1142, 0.1351, 0.2489,
        0.0819], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,389][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.0182, 0.0286, 0.0502, 0.0208, 0.0386, 0.0966, 0.1502, 0.2544, 0.2809,
        0.0614], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,390][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([1.1884e-01, 9.0653e-06, 1.5921e-03, 4.6661e-04, 5.7546e-05, 8.3221e-02,
        6.4065e-01, 8.3184e-04, 1.3938e-01, 9.4877e-03, 5.4658e-03],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,392][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0010, 0.1652, 0.0622, 0.0513, 0.1118, 0.0441, 0.1328, 0.2470, 0.0725,
        0.0276, 0.0844], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,393][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.2483, 0.0607, 0.0133, 0.0512, 0.0377, 0.0188, 0.0615, 0.2053, 0.0682,
        0.1038, 0.1311], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,395][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0360, 0.0406, 0.0297, 0.0456, 0.0754, 0.0955, 0.1261, 0.1415, 0.2156,
        0.0777, 0.1163], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,396][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0540, 0.0177, 0.0034, 0.0099, 0.0219, 0.2071, 0.1066, 0.0832, 0.2444,
        0.0318, 0.2202], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,398][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.2525, 0.0130, 0.0055, 0.0314, 0.0428, 0.0615, 0.0426, 0.0819, 0.1810,
        0.0472, 0.2406], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,399][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0600, 0.0453, 0.0153, 0.0762, 0.0325, 0.0518, 0.0647, 0.2358, 0.1444,
        0.1394, 0.1348], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,400][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0836, 0.0053, 0.0020, 0.0040, 0.0129, 0.1833, 0.0475, 0.1261, 0.2584,
        0.0309, 0.2460], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,402][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.4495, 0.0208, 0.0018, 0.0145, 0.0059, 0.0157, 0.0133, 0.1680, 0.0640,
        0.0898, 0.1567], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,404][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.3594, 0.0244, 0.0110, 0.0473, 0.0579, 0.0764, 0.0649, 0.0797, 0.1093,
        0.0637, 0.1061], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,404][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0970, 0.0115, 0.0120, 0.0153, 0.0634, 0.1185, 0.0800, 0.0643, 0.2082,
        0.0453, 0.2844], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,404][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0142, 0.0163, 0.0349, 0.0082, 0.0126, 0.1263, 0.1073, 0.0933, 0.3255,
        0.0473, 0.2142], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,405][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([2.8407e-02, 3.7990e-07, 1.2085e-04, 3.3111e-05, 3.6873e-06, 6.9855e-03,
        6.9174e-02, 5.7716e-05, 1.6258e-02, 1.6395e-03, 4.8232e-04, 8.7684e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,405][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0005, 0.2400, 0.0663, 0.0475, 0.0497, 0.0463, 0.0840, 0.2273, 0.0677,
        0.0395, 0.1019, 0.0293], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,406][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1943, 0.0251, 0.0130, 0.0308, 0.0390, 0.0193, 0.0602, 0.2495, 0.0814,
        0.0787, 0.1354, 0.0735], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,406][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0355, 0.0322, 0.0483, 0.0875, 0.0815, 0.0767, 0.1003, 0.1156, 0.1586,
        0.0731, 0.0908, 0.0998], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,407][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1383, 0.0129, 0.0042, 0.0172, 0.0409, 0.1069, 0.0634, 0.0692, 0.1649,
        0.0487, 0.1815, 0.1518], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,408][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.4472, 0.0056, 0.0039, 0.0324, 0.0222, 0.0406, 0.0183, 0.0412, 0.1210,
        0.0663, 0.1357, 0.0658], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,409][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1191, 0.0315, 0.0141, 0.0712, 0.0231, 0.0366, 0.0505, 0.1773, 0.1155,
        0.1226, 0.1098, 0.1285], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,411][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0920, 0.0048, 0.0021, 0.0065, 0.0088, 0.0933, 0.0196, 0.0775, 0.1368,
        0.0516, 0.1260, 0.3809], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,412][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.5971, 0.0051, 0.0019, 0.0140, 0.0034, 0.0136, 0.0103, 0.0905, 0.0524,
        0.0845, 0.0846, 0.0425], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,413][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1824, 0.0120, 0.0196, 0.0501, 0.0390, 0.0890, 0.0970, 0.0620, 0.1575,
        0.0531, 0.1055, 0.1327], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,414][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1175, 0.0055, 0.0120, 0.0115, 0.0395, 0.0804, 0.0615, 0.0404, 0.1708,
        0.0426, 0.1794, 0.2389], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,416][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0209, 0.0046, 0.0329, 0.0059, 0.0108, 0.0837, 0.0633, 0.0759, 0.1970,
        0.0371, 0.1182, 0.3496], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,417][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([4.1494e-02, 1.4514e-06, 1.9488e-04, 1.3350e-04, 9.8618e-06, 9.2465e-03,
        1.1747e-01, 1.3039e-04, 1.6733e-02, 2.1401e-03, 1.0140e-03, 8.1128e-01,
        1.4867e-04], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,418][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0005, 0.0876, 0.0786, 0.0250, 0.0155, 0.0437, 0.0564, 0.1263, 0.0799,
        0.0225, 0.1356, 0.0517, 0.2769], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,420][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.4884, 0.0304, 0.0081, 0.0238, 0.0188, 0.0115, 0.0318, 0.1086, 0.0343,
        0.0542, 0.0634, 0.0255, 0.1010], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,421][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0520, 0.0130, 0.0115, 0.0346, 0.0333, 0.0531, 0.0663, 0.1246, 0.1193,
        0.0463, 0.1036, 0.0639, 0.2784], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,423][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.0394, 0.0047, 0.0011, 0.0053, 0.0126, 0.0444, 0.0361, 0.0438, 0.1023,
        0.0134, 0.2381, 0.2539, 0.2049], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,424][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.2757, 0.0025, 0.0014, 0.0099, 0.0085, 0.0193, 0.0169, 0.0360, 0.1170,
        0.0311, 0.1708, 0.1422, 0.1686], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,426][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.1030, 0.0238, 0.0092, 0.0548, 0.0324, 0.0289, 0.0390, 0.2301, 0.0591,
        0.0885, 0.0702, 0.0830, 0.1779], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,426][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([2.6314e-02, 9.0332e-04, 2.4019e-04, 9.8152e-04, 2.0516e-03, 3.0943e-02,
        1.0146e-02, 2.8990e-02, 8.2273e-02, 1.2830e-02, 1.3545e-01, 5.4174e-01,
        1.2715e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,428][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.4062, 0.0070, 0.0023, 0.0073, 0.0059, 0.0224, 0.0157, 0.1363, 0.0835,
        0.0683, 0.1321, 0.0754, 0.0377], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,430][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.2976, 0.0052, 0.0073, 0.0309, 0.0428, 0.0584, 0.0716, 0.0580, 0.1022,
        0.0362, 0.0763, 0.1069, 0.1068], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,431][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.1221, 0.0028, 0.0060, 0.0068, 0.0314, 0.0572, 0.0453, 0.0385, 0.1324,
        0.0296, 0.1362, 0.2022, 0.1894], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,433][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0174, 0.0019, 0.0144, 0.0024, 0.0066, 0.0864, 0.0570, 0.0530, 0.1914,
        0.0158, 0.1036, 0.3727, 0.0773], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,434][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([3.0957e-02, 5.5780e-07, 1.1147e-04, 4.3979e-05, 5.1815e-06, 7.0337e-03,
        7.0884e-02, 5.8973e-05, 1.5170e-02, 1.8331e-03, 5.5823e-04, 7.9700e-01,
        6.9049e-05, 7.6274e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,434][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([3.0410e-04, 1.5770e-01, 4.6464e-02, 3.3627e-02, 4.1396e-02, 2.5380e-02,
        5.2790e-02, 1.4397e-01, 3.2584e-02, 2.3273e-02, 4.6626e-02, 1.6562e-02,
        3.4816e-01, 3.1176e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,436][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1530, 0.0307, 0.0107, 0.0260, 0.0296, 0.0131, 0.0441, 0.1816, 0.0595,
        0.0792, 0.0913, 0.0538, 0.1607, 0.0669], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,437][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0167, 0.0199, 0.0283, 0.0577, 0.0606, 0.0555, 0.0605, 0.0688, 0.0882,
        0.0443, 0.0625, 0.0557, 0.2603, 0.1211], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,439][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0970, 0.0083, 0.0019, 0.0118, 0.0207, 0.0418, 0.0341, 0.0366, 0.0809,
        0.0248, 0.0972, 0.1129, 0.1778, 0.2542], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,440][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.3245, 0.0043, 0.0019, 0.0187, 0.0120, 0.0197, 0.0117, 0.0302, 0.0797,
        0.0467, 0.0974, 0.0559, 0.1402, 0.1571], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,442][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0549, 0.0173, 0.0081, 0.0455, 0.0168, 0.0227, 0.0447, 0.0984, 0.0816,
        0.0713, 0.0968, 0.1053, 0.2021, 0.1343], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,443][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0489, 0.0020, 0.0005, 0.0030, 0.0022, 0.0227, 0.0067, 0.0351, 0.0503,
        0.0184, 0.0562, 0.2039, 0.1225, 0.4277], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,445][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.5258, 0.0043, 0.0013, 0.0139, 0.0030, 0.0118, 0.0101, 0.0785, 0.0446,
        0.0753, 0.0754, 0.0435, 0.0421, 0.0702], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,446][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1429, 0.0099, 0.0151, 0.0455, 0.0323, 0.0732, 0.0764, 0.0411, 0.1296,
        0.0457, 0.0665, 0.1066, 0.1073, 0.1078], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,448][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0551, 0.0032, 0.0066, 0.0065, 0.0234, 0.0525, 0.0372, 0.0234, 0.1038,
        0.0251, 0.1311, 0.1402, 0.1375, 0.2545], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,449][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0110, 0.0029, 0.0142, 0.0033, 0.0058, 0.0438, 0.0361, 0.0374, 0.1062,
        0.0227, 0.0610, 0.2113, 0.0956, 0.3489], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,451][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:23:24,452][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[66],
        [18],
        [ 5],
        [15],
        [ 2],
        [ 5],
        [ 4],
        [ 3],
        [ 2],
        [ 3],
        [ 1],
        [ 2],
        [ 3],
        [ 2]], device='cuda:0')
[2024-07-24 10:23:24,453][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[105],
        [ 31],
        [  6],
        [ 19],
        [  2],
        [  8],
        [  7],
        [  3],
        [  3],
        [  4],
        [  1],
        [  4],
        [  4],
        [  2]], device='cuda:0')
[2024-07-24 10:23:24,454][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[19656],
        [19667],
        [19873],
        [21276],
        [21264],
        [33377],
        [35919],
        [36184],
        [36959],
        [37403],
        [37835],
        [38313],
        [38276],
        [38390]], device='cuda:0')
[2024-07-24 10:23:24,455][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 5277],
        [44286],
        [44374],
        [46760],
        [47297],
        [44779],
        [40795],
        [34097],
        [37665],
        [35379],
        [34172],
        [35633],
        [28493],
        [33717]], device='cuda:0')
[2024-07-24 10:23:24,456][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 7620],
        [ 9882],
        [10496],
        [16020],
        [23755],
        [11402],
        [10409],
        [10126],
        [ 7424],
        [ 7345],
        [ 7248],
        [ 5978],
        [ 7479],
        [ 5938]], device='cuda:0')
[2024-07-24 10:23:24,457][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[19210],
        [ 7021],
        [10511],
        [13312],
        [15161],
        [13909],
        [12878],
        [23617],
        [18310],
        [21585],
        [17278],
        [16584],
        [17881],
        [16933]], device='cuda:0')
[2024-07-24 10:23:24,458][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[43886],
        [45060],
        [46863],
        [46042],
        [37556],
        [45740],
        [42609],
        [42397],
        [42896],
        [42120],
        [40372],
        [39602],
        [35254],
        [35884]], device='cuda:0')
[2024-07-24 10:23:24,460][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[15697],
        [16231],
        [16747],
        [19408],
        [19073],
        [17081],
        [18531],
        [18523],
        [19905],
        [20236],
        [25265],
        [24007],
        [21488],
        [19300]], device='cuda:0')
[2024-07-24 10:23:24,461][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[34507],
        [48889],
        [47110],
        [49488],
        [46536],
        [47044],
        [46915],
        [27544],
        [35151],
        [40240],
        [36211],
        [35492],
        [33037],
        [31898]], device='cuda:0')
[2024-07-24 10:23:24,463][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[22655],
        [29368],
        [25825],
        [30684],
        [25068],
        [18067],
        [15946],
        [14939],
        [18288],
        [17783],
        [16619],
        [15925],
        [13246],
        [ 8594]], device='cuda:0')
[2024-07-24 10:23:24,464][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[12068],
        [16392],
        [13589],
        [21732],
        [26333],
        [17006],
        [15903],
        [20505],
        [18894],
        [21229],
        [20793],
        [18429],
        [19519],
        [17904]], device='cuda:0')
[2024-07-24 10:23:24,465][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[10144],
        [16082],
        [20431],
        [18178],
        [30901],
        [40381],
        [42507],
        [43472],
        [45957],
        [45804],
        [45993],
        [45296],
        [45418],
        [45372]], device='cuda:0')
[2024-07-24 10:23:24,467][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[19223],
        [ 4232],
        [ 4187],
        [  568],
        [ 3639],
        [ 3758],
        [ 5242],
        [ 7162],
        [ 3643],
        [ 4013],
        [ 4868],
        [ 7262],
        [11106],
        [13489]], device='cuda:0')
[2024-07-24 10:23:24,468][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[3419],
        [ 750],
        [ 314],
        [ 427],
        [ 286],
        [ 216],
        [ 216],
        [ 197],
        [ 225],
        [ 234],
        [ 233],
        [ 236],
        [ 265],
        [ 247]], device='cuda:0')
[2024-07-24 10:23:24,470][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[9677],
        [  74],
        [2586],
        [ 357],
        [4593],
        [1289],
        [4190],
        [1745],
        [1004],
        [ 319],
        [1711],
        [3821],
        [7484],
        [1894]], device='cuda:0')
[2024-07-24 10:23:24,471][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[22526],
        [22507],
        [22169],
        [18735],
        [18550],
        [10534],
        [ 6587],
        [ 6442],
        [ 6860],
        [ 6593],
        [ 6481],
        [ 9500],
        [ 9315],
        [ 9055]], device='cuda:0')
[2024-07-24 10:23:24,473][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[1482],
        [ 179],
        [ 246],
        [ 315],
        [ 379],
        [ 645],
        [ 713],
        [2119],
        [1804],
        [1752],
        [2736],
        [1727],
        [4689],
        [2919]], device='cuda:0')
[2024-07-24 10:23:24,474][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[14183],
        [15098],
        [14881],
        [16798],
        [21042],
        [18240],
        [19319],
        [20851],
        [22641],
        [22337],
        [21026],
        [22135],
        [21373],
        [22475]], device='cuda:0')
[2024-07-24 10:23:24,475][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 2941],
        [30083],
        [31528],
        [25856],
        [26151],
        [29664],
        [32716],
        [27265],
        [32356],
        [29785],
        [28925],
        [29391],
        [17859],
        [20202]], device='cuda:0')
[2024-07-24 10:23:24,477][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[14794],
        [ 4883],
        [11533],
        [ 1363],
        [ 4238],
        [ 5875],
        [ 6953],
        [ 5775],
        [ 5320],
        [ 2785],
        [12936],
        [13830],
        [24745],
        [22515]], device='cuda:0')
[2024-07-24 10:23:24,478][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[28126],
        [27275],
        [26441],
        [23257],
        [27762],
        [27134],
        [26626],
        [29444],
        [24780],
        [23791],
        [18208],
        [18602],
        [22439],
        [26145]], device='cuda:0')
[2024-07-24 10:23:24,479][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 3957],
        [  294],
        [  396],
        [  457],
        [ 1985],
        [  713],
        [ 1078],
        [12615],
        [ 9925],
        [ 7495],
        [10411],
        [ 9917],
        [11548],
        [11852]], device='cuda:0')
[2024-07-24 10:23:24,481][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[  276],
        [ 4510],
        [ 1860],
        [ 9638],
        [ 7295],
        [16152],
        [26543],
        [29569],
        [24076],
        [29294],
        [24572],
        [18915],
        [17842],
        [19042]], device='cuda:0')
[2024-07-24 10:23:24,482][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[20766],
        [21156],
        [22226],
        [22478],
        [20397],
        [25175],
        [27646],
        [16075],
        [21179],
        [13804],
        [11035],
        [14099],
        [14436],
        [17491]], device='cuda:0')
[2024-07-24 10:23:24,484][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[38172],
        [27904],
        [28324],
        [25756],
        [20909],
        [17949],
        [17565],
        [14302],
        [20618],
        [17662],
        [18309],
        [20675],
        [16879],
        [17828]], device='cuda:0')
[2024-07-24 10:23:24,485][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 4714],
        [ 4180],
        [ 4646],
        [ 8873],
        [15633],
        [17971],
        [17508],
        [13592],
        [22528],
        [21676],
        [18595],
        [17953],
        [17770],
        [20398]], device='cuda:0')
[2024-07-24 10:23:24,486][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[12491],
        [ 3564],
        [  903],
        [ 2583],
        [ 7141],
        [ 1711],
        [ 2429],
        [ 2072],
        [ 1785],
        [ 2238],
        [ 6478],
        [ 5593],
        [ 6074],
        [ 4219]], device='cuda:0')
[2024-07-24 10:23:24,488][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[38078],
        [37627],
        [37561],
        [40664],
        [29772],
        [30620],
        [29337],
        [24991],
        [20305],
        [26269],
        [22775],
        [23181],
        [21535],
        [19566]], device='cuda:0')
[2024-07-24 10:23:24,489][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[31594],
        [50243],
        [49993],
        [50163],
        [48979],
        [49730],
        [46869],
        [47412],
        [49542],
        [50002],
        [48155],
        [45694],
        [43964],
        [48004]], device='cuda:0')
[2024-07-24 10:23:24,491][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[2509],
        [2509],
        [2509],
        [2509],
        [2509],
        [2509],
        [2509],
        [2509],
        [2509],
        [2509],
        [2509],
        [2509],
        [2509],
        [2509]], device='cuda:0')
[2024-07-24 10:23:24,548][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:24,549][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,549][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,549][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,550][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,550][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,550][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,551][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,551][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,552][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,553][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,554][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,555][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,556][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.3776, 0.6224], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,557][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([4.2263e-04, 9.9958e-01], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,558][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.6396, 0.3604], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,559][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.9783, 0.0217], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,561][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.0860, 0.9140], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,562][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.4603, 0.5397], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,564][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.0012, 0.9988], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,565][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.1320, 0.8680], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,566][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.0366, 0.9635], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,567][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.6419, 0.3581], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,569][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.6298, 0.3702], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,570][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.1473, 0.8527], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,571][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.8333, 0.1229, 0.0438], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,573][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0039, 0.7956, 0.2005], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,574][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.9074, 0.0768, 0.0158], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,576][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.9569, 0.0017, 0.0414], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,577][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4500, 0.2688, 0.2811], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,578][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.9608, 0.0317, 0.0075], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,579][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([2.8016e-04, 7.3235e-01, 2.6737e-01], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,581][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.6771, 0.0693, 0.2536], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,582][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0578, 0.3517, 0.5906], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,584][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.6240, 0.2858, 0.0902], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,585][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.6150, 0.0312, 0.3538], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,586][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0248, 0.1779, 0.7974], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,587][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Mary] are: tensor([0.5865, 0.1951, 0.0609, 0.1574], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,589][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Mary] are: tensor([0.0056, 0.7961, 0.0441, 0.1543], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,590][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Mary] are: tensor([0.8809, 0.0308, 0.0123, 0.0760], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,591][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Mary] are: tensor([0.7577, 0.0364, 0.1827, 0.0231], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,593][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Mary] are: tensor([0.2654, 0.2316, 0.1318, 0.3711], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,594][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Mary] are: tensor([0.7288, 0.1546, 0.0505, 0.0661], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,595][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Mary] are: tensor([4.3956e-04, 3.5692e-01, 4.9963e-01, 1.4301e-01], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,596][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Mary] are: tensor([0.2383, 0.1264, 0.4729, 0.1624], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,596][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Mary] are: tensor([0.0594, 0.2595, 0.3244, 0.3568], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,596][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Mary] are: tensor([0.4351, 0.1961, 0.0289, 0.3400], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,597][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Mary] are: tensor([0.2736, 0.1538, 0.4788, 0.0937], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,597][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Mary] are: tensor([0.0257, 0.0927, 0.5243, 0.3573], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,597][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.7390, 0.0402, 0.0701, 0.0736, 0.0771], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,598][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0015, 0.6326, 0.0995, 0.1822, 0.0841], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,598][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.7920, 0.0403, 0.0347, 0.0576, 0.0753], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,598][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.8552, 0.0024, 0.0521, 0.0394, 0.0509], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,599][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.1070, 0.1020, 0.1580, 0.2925, 0.3405], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,600][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.6669, 0.0505, 0.0206, 0.0432, 0.2188], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,601][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ went] are: tensor([8.0464e-05, 8.1296e-02, 2.6555e-01, 1.2187e-01, 5.3121e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,602][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0445, 0.0402, 0.2263, 0.0963, 0.5928], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,603][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0726, 0.1620, 0.2361, 0.2775, 0.2518], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,605][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.3745, 0.0774, 0.0366, 0.2382, 0.2733], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,606][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0977, 0.0125, 0.1089, 0.0725, 0.7084], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,607][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0018, 0.0407, 0.0984, 0.0978, 0.7614], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,608][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.7030, 0.0920, 0.0289, 0.0641, 0.0426, 0.0694], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,610][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0039, 0.4121, 0.0975, 0.2702, 0.0959, 0.1203], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,611][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.8706, 0.0281, 0.0074, 0.0522, 0.0145, 0.0273], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,612][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([9.5643e-01, 1.7013e-05, 7.0700e-04, 9.1329e-03, 2.7390e-03, 3.0975e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,613][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1367, 0.0677, 0.0881, 0.1837, 0.2070, 0.3168], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,615][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.8819, 0.0173, 0.0032, 0.0092, 0.0676, 0.0209], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,616][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([1.1219e-04, 2.0618e-01, 8.2788e-02, 9.0507e-02, 2.3997e-01, 3.8044e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,617][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.4170, 0.0049, 0.0377, 0.0674, 0.1007, 0.3724], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,619][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0489, 0.1736, 0.2315, 0.1975, 0.1915, 0.1570], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,620][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0559, 0.0767, 0.0221, 0.2821, 0.4133, 0.1500], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,621][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([2.1217e-01, 3.1958e-04, 6.6213e-03, 1.9114e-02, 5.3923e-02, 7.0785e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,622][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0111, 0.0535, 0.1569, 0.0797, 0.4542, 0.2446], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,624][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.6699, 0.0702, 0.0319, 0.0806, 0.0356, 0.0499, 0.0619],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,625][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0015, 0.3657, 0.0901, 0.1944, 0.1093, 0.0965, 0.1426],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,627][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.8607, 0.0165, 0.0063, 0.0388, 0.0154, 0.0289, 0.0334],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,628][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.7783, 0.0012, 0.0098, 0.0135, 0.0203, 0.1583, 0.0186],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,630][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1259, 0.0504, 0.0664, 0.2488, 0.1608, 0.1644, 0.1834],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,631][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.8142, 0.0177, 0.0060, 0.0125, 0.0755, 0.0307, 0.0434],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,632][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ the] are: tensor([3.5313e-05, 2.1115e-01, 1.1269e-01, 7.2473e-02, 1.6063e-01, 3.5732e-01,
        8.5697e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,633][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.2179, 0.0072, 0.0577, 0.0483, 0.0875, 0.3529, 0.2285],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,635][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0382, 0.2435, 0.2013, 0.1942, 0.1331, 0.1124, 0.0773],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,636][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.3483, 0.0840, 0.0202, 0.2519, 0.1837, 0.0697, 0.0422],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,638][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0367, 0.0030, 0.0138, 0.0093, 0.0989, 0.7230, 0.1151],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,639][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0027, 0.0719, 0.1251, 0.0980, 0.4132, 0.1375, 0.1515],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,640][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.6503, 0.0746, 0.0176, 0.0423, 0.0336, 0.0209, 0.0229, 0.1378],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,642][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([0.0016, 0.1554, 0.0508, 0.1336, 0.1143, 0.0884, 0.1811, 0.2749],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,643][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.6103, 0.0202, 0.0111, 0.0197, 0.0221, 0.0389, 0.0602, 0.2175],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,643][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.4984, 0.0046, 0.0140, 0.0105, 0.0239, 0.3293, 0.0508, 0.0685],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,644][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.0403, 0.0559, 0.0853, 0.0980, 0.0924, 0.1373, 0.1564, 0.3344],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,644][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.6273, 0.0262, 0.0097, 0.0113, 0.0679, 0.0363, 0.0471, 0.1743],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,644][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([3.1378e-05, 7.0410e-02, 8.8490e-02, 8.2334e-02, 1.7017e-01, 3.7351e-01,
        1.7491e-01, 4.0143e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,645][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.0615, 0.0171, 0.0500, 0.0261, 0.1709, 0.2349, 0.2211, 0.2184],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,645][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.0650, 0.1561, 0.1859, 0.1720, 0.1145, 0.1132, 0.0982, 0.0950],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,646][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.2393, 0.0749, 0.0218, 0.1937, 0.1268, 0.1288, 0.0484, 0.1663],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,646][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.0092, 0.0143, 0.0143, 0.0085, 0.0964, 0.6374, 0.1226, 0.0973],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,647][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.0010, 0.0245, 0.0583, 0.0496, 0.3241, 0.0989, 0.1381, 0.3054],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,648][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4402, 0.1046, 0.0216, 0.0883, 0.0308, 0.0394, 0.0377, 0.1400, 0.0975],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,650][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0012, 0.2296, 0.0766, 0.2228, 0.0775, 0.0652, 0.0770, 0.1854, 0.0645],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,651][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.7099, 0.0272, 0.0042, 0.0679, 0.0115, 0.0123, 0.0193, 0.0821, 0.0656],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,652][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([8.2531e-01, 8.1092e-04, 2.3243e-03, 2.2346e-02, 6.7193e-03, 2.8326e-02,
        1.2340e-02, 4.2332e-02, 5.9496e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,654][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0374, 0.0732, 0.0495, 0.1114, 0.0843, 0.1015, 0.1228, 0.0959, 0.3241],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,655][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.6616, 0.0306, 0.0053, 0.0145, 0.0719, 0.0263, 0.0371, 0.1201, 0.0326],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,656][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([3.6317e-05, 2.2214e-01, 7.3249e-02, 6.7039e-02, 1.2938e-01, 2.9448e-01,
        8.9975e-02, 2.0995e-02, 1.0271e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,657][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1856, 0.0073, 0.0181, 0.0304, 0.0429, 0.1047, 0.1104, 0.1645, 0.3362],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,658][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0307, 0.1857, 0.1859, 0.1580, 0.1178, 0.0910, 0.0709, 0.0783, 0.0817],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,660][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1112, 0.0615, 0.0154, 0.2843, 0.1806, 0.0783, 0.0633, 0.1797, 0.0259],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,661][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0427, 0.0027, 0.0076, 0.0157, 0.0508, 0.3149, 0.0889, 0.0928, 0.3839],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,663][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0009, 0.0296, 0.0726, 0.0491, 0.3056, 0.0896, 0.0899, 0.3005, 0.0622],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,664][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.3018, 0.2678, 0.0277, 0.0606, 0.0399, 0.0200, 0.0395, 0.0999, 0.0526,
        0.0903], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,665][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.0008, 0.3686, 0.0425, 0.1011, 0.0732, 0.0492, 0.0841, 0.1532, 0.0737,
        0.0536], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,667][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.4742, 0.0291, 0.0071, 0.0510, 0.0251, 0.0210, 0.0316, 0.1111, 0.0964,
        0.1535], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,668][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.4005, 0.0930, 0.0181, 0.0586, 0.0095, 0.0085, 0.0391, 0.2591, 0.0916,
        0.0221], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,670][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.0126, 0.0899, 0.0472, 0.0661, 0.0602, 0.0730, 0.0682, 0.1109, 0.2214,
        0.2504], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,671][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.2498, 0.0693, 0.0133, 0.0281, 0.1337, 0.0320, 0.0627, 0.2358, 0.0406,
        0.1348], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,672][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([4.8562e-05, 7.9378e-02, 7.4736e-02, 6.6292e-02, 1.5243e-01, 2.7153e-01,
        1.6449e-01, 2.5461e-02, 1.4428e-01, 2.1360e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,674][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0877, 0.0460, 0.0474, 0.0373, 0.0741, 0.0656, 0.1593, 0.2105, 0.2349,
        0.0372], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,675][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.0462, 0.1204, 0.1197, 0.1333, 0.1427, 0.0871, 0.0958, 0.0906, 0.0734,
        0.0908], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,677][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.0793, 0.0539, 0.0350, 0.2518, 0.1233, 0.1055, 0.0323, 0.1875, 0.0401,
        0.0914], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,678][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0115, 0.0616, 0.0126, 0.0148, 0.0368, 0.0555, 0.1175, 0.3542, 0.2972,
        0.0382], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,679][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.0010, 0.0279, 0.0502, 0.0588, 0.3936, 0.0930, 0.1013, 0.1886, 0.0619,
        0.0238], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,681][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.2552, 0.1566, 0.0177, 0.0607, 0.0215, 0.0272, 0.0177, 0.0821, 0.0675,
        0.0944, 0.1994], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,682][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0010, 0.2224, 0.0642, 0.1438, 0.0525, 0.0658, 0.0879, 0.1450, 0.0792,
        0.0385, 0.0998], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,684][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.4273, 0.0420, 0.0042, 0.0454, 0.0174, 0.0147, 0.0242, 0.0916, 0.0686,
        0.0860, 0.1787], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,685][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.4118, 0.0048, 0.0034, 0.0179, 0.0088, 0.0863, 0.0322, 0.1042, 0.2113,
        0.0327, 0.0866], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,687][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0117, 0.0608, 0.0249, 0.0636, 0.0394, 0.0609, 0.0662, 0.0742, 0.1762,
        0.1531, 0.2689], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,688][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.5202, 0.0175, 0.0065, 0.0105, 0.0726, 0.0253, 0.0304, 0.1280, 0.0312,
        0.0507, 0.1071], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,689][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([1.3285e-05, 2.8830e-01, 6.6647e-02, 6.5109e-02, 1.1199e-01, 2.1170e-01,
        6.7263e-02, 1.8091e-02, 1.0075e-01, 2.7581e-02, 4.2556e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,690][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0464, 0.0119, 0.0159, 0.0136, 0.0644, 0.1306, 0.1075, 0.0895, 0.2796,
        0.0187, 0.2218], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,691][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0556, 0.1854, 0.1096, 0.1419, 0.1053, 0.0635, 0.0661, 0.0701, 0.0547,
        0.0774, 0.0706], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,691][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.1291, 0.0455, 0.0153, 0.1460, 0.1059, 0.1284, 0.0574, 0.1363, 0.0390,
        0.0975, 0.0994], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,692][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0172, 0.0027, 0.0033, 0.0031, 0.0235, 0.2369, 0.0819, 0.1017, 0.3508,
        0.0221, 0.1568], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,692][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0007, 0.0326, 0.0422, 0.0399, 0.2767, 0.0577, 0.0858, 0.1720, 0.0416,
        0.0140, 0.2367], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,692][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.4200, 0.0322, 0.0231, 0.0577, 0.0121, 0.0288, 0.0267, 0.0647, 0.0852,
        0.0772, 0.1260, 0.0463], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,693][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0020, 0.0984, 0.0659, 0.1312, 0.0805, 0.0626, 0.0897, 0.2071, 0.0656,
        0.0333, 0.1089, 0.0547], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,693][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.5128, 0.0122, 0.0053, 0.0290, 0.0065, 0.0150, 0.0236, 0.0502, 0.0766,
        0.1345, 0.0836, 0.0508], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,694][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([7.9657e-01, 4.7165e-04, 7.0090e-04, 1.7079e-02, 2.7066e-03, 1.3412e-02,
        6.7612e-03, 2.8263e-02, 4.6757e-02, 2.3992e-02, 2.6200e-02, 3.7083e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,695][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0348, 0.0197, 0.0307, 0.0299, 0.0220, 0.0502, 0.0779, 0.0528, 0.2057,
        0.1042, 0.2907, 0.0814], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,696][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.6288, 0.0111, 0.0063, 0.0106, 0.0419, 0.0169, 0.0250, 0.0878, 0.0243,
        0.0542, 0.0489, 0.0443], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,697][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([2.3245e-05, 9.4070e-02, 8.9405e-02, 5.6910e-02, 1.1073e-01, 2.5029e-01,
        9.6580e-02, 2.1932e-02, 1.1862e-01, 2.0064e-02, 7.5077e-02, 6.6301e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,699][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1877, 0.0045, 0.0110, 0.0252, 0.0299, 0.0557, 0.0676, 0.0946, 0.1946,
        0.0241, 0.1618, 0.1435], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,700][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0242, 0.1573, 0.1484, 0.1299, 0.0860, 0.0804, 0.0572, 0.0688, 0.0656,
        0.0790, 0.0658, 0.0373], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,701][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0387, 0.0577, 0.0187, 0.1868, 0.1202, 0.0734, 0.0276, 0.1997, 0.0432,
        0.0825, 0.1250, 0.0265], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,703][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0443, 0.0017, 0.0037, 0.0107, 0.0152, 0.1497, 0.0433, 0.0504, 0.2240,
        0.0435, 0.0742, 0.3392], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,704][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0011, 0.0346, 0.0420, 0.0430, 0.1827, 0.0634, 0.0894, 0.1983, 0.0627,
        0.0174, 0.2020, 0.0633], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,706][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.1549, 0.0189, 0.0156, 0.0243, 0.0156, 0.0525, 0.0397, 0.1708, 0.1287,
        0.0541, 0.1639, 0.0393, 0.1218], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,707][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0006, 0.2109, 0.0336, 0.1097, 0.0975, 0.0328, 0.0490, 0.1027, 0.0474,
        0.0267, 0.1283, 0.0249, 0.1359], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,709][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.2709, 0.0145, 0.0055, 0.0226, 0.0134, 0.0288, 0.0335, 0.1169, 0.1386,
        0.1274, 0.1311, 0.0482, 0.0487], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,710][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.3387, 0.0014, 0.0011, 0.0113, 0.0021, 0.0216, 0.0131, 0.0837, 0.1357,
        0.0247, 0.0846, 0.1964, 0.0855], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,712][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0189, 0.0302, 0.0259, 0.0574, 0.0518, 0.0628, 0.0568, 0.0826, 0.1450,
        0.0942, 0.1949, 0.0547, 0.1250], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,713][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.3383, 0.0096, 0.0071, 0.0081, 0.0494, 0.0226, 0.0393, 0.1321, 0.0382,
        0.0457, 0.0633, 0.0622, 0.1840], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,714][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([1.2025e-05, 8.8553e-02, 6.5774e-02, 4.4261e-02, 1.4953e-01, 1.3200e-01,
        4.2119e-02, 2.0188e-02, 9.3728e-02, 1.4055e-02, 1.3419e-01, 5.9209e-02,
        1.5637e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,716][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0215, 0.0052, 0.0112, 0.0101, 0.0260, 0.0703, 0.0787, 0.0899, 0.2104,
        0.0175, 0.1667, 0.2047, 0.0877], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,717][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.0321, 0.1486, 0.0987, 0.1162, 0.0879, 0.0597, 0.0536, 0.0834, 0.0519,
        0.0821, 0.0810, 0.0385, 0.0663], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,718][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.2902, 0.0402, 0.0182, 0.1568, 0.0560, 0.0686, 0.0240, 0.0861, 0.0249,
        0.0591, 0.0547, 0.0209, 0.1004], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,720][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0047, 0.0023, 0.0010, 0.0032, 0.0056, 0.0459, 0.0277, 0.0509, 0.1362,
        0.0166, 0.0930, 0.3672, 0.2457], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,721][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0005, 0.0224, 0.0341, 0.0394, 0.2130, 0.0421, 0.0765, 0.1682, 0.0337,
        0.0089, 0.1655, 0.0542, 0.1416], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,723][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.3575, 0.0430, 0.0213, 0.0479, 0.0110, 0.0322, 0.0251, 0.0505, 0.0735,
        0.0892, 0.0836, 0.0368, 0.0495, 0.0791], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,724][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0011, 0.1860, 0.0436, 0.1352, 0.0595, 0.0397, 0.0598, 0.0995, 0.0308,
        0.0329, 0.0404, 0.0236, 0.2272, 0.0206], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,726][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.5486, 0.0084, 0.0035, 0.0291, 0.0060, 0.0113, 0.0193, 0.0378, 0.0532,
        0.1152, 0.0586, 0.0390, 0.0198, 0.0500], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,727][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([7.3791e-01, 5.9649e-04, 5.4505e-04, 1.5624e-02, 2.1468e-03, 8.2012e-03,
        6.2889e-03, 2.6445e-02, 3.6324e-02, 1.4995e-02, 1.8910e-02, 3.6441e-02,
        4.7208e-02, 4.8368e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,728][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0117, 0.0168, 0.0246, 0.0312, 0.0240, 0.0648, 0.0572, 0.0379, 0.1733,
        0.0799, 0.2198, 0.0520, 0.0920, 0.1149], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,729][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.5770, 0.0077, 0.0030, 0.0077, 0.0381, 0.0136, 0.0190, 0.0694, 0.0177,
        0.0484, 0.0430, 0.0335, 0.0779, 0.0439], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,731][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([1.4719e-05, 1.2697e-01, 7.1185e-02, 5.7913e-02, 9.4711e-02, 2.0185e-01,
        7.0804e-02, 1.2369e-02, 7.9903e-02, 1.8412e-02, 4.6161e-02, 3.8298e-02,
        1.1708e-01, 6.4334e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,732][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1263, 0.0035, 0.0060, 0.0143, 0.0201, 0.0390, 0.0463, 0.0645, 0.1601,
        0.0196, 0.1253, 0.1231, 0.1077, 0.1443], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,733][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0360, 0.1202, 0.1074, 0.1077, 0.0950, 0.0672, 0.0532, 0.0693, 0.0604,
        0.0808, 0.0698, 0.0446, 0.0408, 0.0478], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,735][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0042, 0.0253, 0.0094, 0.1499, 0.1477, 0.0653, 0.0382, 0.1235, 0.0309,
        0.0452, 0.1082, 0.0339, 0.1188, 0.0997], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,736][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0343, 0.0019, 0.0015, 0.0081, 0.0070, 0.0525, 0.0228, 0.0364, 0.1019,
        0.0199, 0.0347, 0.1791, 0.2307, 0.2693], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,738][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0010, 0.0278, 0.0364, 0.0314, 0.1315, 0.0544, 0.0593, 0.1777, 0.0490,
        0.0187, 0.1945, 0.0384, 0.1275, 0.0523], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,795][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:24,796][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,797][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,799][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,800][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,801][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,802][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,803][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,804][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,805][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,807][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,808][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,809][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:24,810][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.3776, 0.6224], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,811][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([4.2263e-04, 9.9958e-01], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,812][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.6396, 0.3604], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,814][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.9783, 0.0217], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,815][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.0860, 0.9140], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,817][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.4603, 0.5397], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,818][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.0012, 0.9988], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,819][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.1320, 0.8680], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,821][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.0036, 0.9964], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,821][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([1.7047e-04, 9.9983e-01], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,823][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.6298, 0.3702], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,824][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.1473, 0.8527], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:24,826][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.8333, 0.1229, 0.0438], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,827][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0039, 0.7956, 0.2005], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,828][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.9074, 0.0768, 0.0158], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,830][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.9569, 0.0017, 0.0414], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,831][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.4500, 0.2688, 0.2811], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,833][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9608, 0.0317, 0.0075], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,833][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([2.8016e-04, 7.3235e-01, 2.6737e-01], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,833][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.6771, 0.0693, 0.2536], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,834][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0237, 0.8937, 0.0826], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,834][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([7.0169e-06, 5.9168e-01, 4.0831e-01], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,834][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.6150, 0.0312, 0.3538], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,835][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0248, 0.1779, 0.7974], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:24,835][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Mary] are: tensor([0.5865, 0.1951, 0.0609, 0.1574], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,835][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Mary] are: tensor([0.0056, 0.7961, 0.0441, 0.1543], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,836][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Mary] are: tensor([0.8809, 0.0308, 0.0123, 0.0760], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,836][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Mary] are: tensor([0.7577, 0.0364, 0.1827, 0.0231], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,838][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Mary] are: tensor([0.2654, 0.2316, 0.1318, 0.3711], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,839][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Mary] are: tensor([0.7288, 0.1546, 0.0505, 0.0661], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,840][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Mary] are: tensor([4.3956e-04, 3.5692e-01, 4.9963e-01, 1.4301e-01], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,841][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Mary] are: tensor([0.2383, 0.1264, 0.4729, 0.1624], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,842][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Mary] are: tensor([0.0194, 0.7706, 0.0776, 0.1324], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,843][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Mary] are: tensor([7.5106e-05, 4.1571e-01, 3.4656e-01, 2.3766e-01], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,845][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Mary] are: tensor([0.2736, 0.1538, 0.4788, 0.0937], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,846][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Mary] are: tensor([0.0257, 0.0927, 0.5243, 0.3573], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:24,848][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.7390, 0.0402, 0.0701, 0.0736, 0.0771], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,849][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0015, 0.6326, 0.0995, 0.1822, 0.0841], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,850][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.7920, 0.0403, 0.0347, 0.0576, 0.0753], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,852][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.8552, 0.0024, 0.0521, 0.0394, 0.0509], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,853][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.1070, 0.1020, 0.1580, 0.2925, 0.3405], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,855][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.6669, 0.0505, 0.0206, 0.0432, 0.2188], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,855][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([8.0464e-05, 8.1296e-02, 2.6555e-01, 1.2187e-01, 5.3121e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,857][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0445, 0.0402, 0.2263, 0.0963, 0.5928], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,858][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.1115, 0.4170, 0.0814, 0.2469, 0.1432], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,859][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([1.0394e-05, 2.1602e-01, 5.6175e-01, 7.9177e-02, 1.4305e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,861][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0977, 0.0125, 0.1089, 0.0725, 0.7084], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,862][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.0018, 0.0407, 0.0984, 0.0978, 0.7614], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:24,864][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.7030, 0.0920, 0.0289, 0.0641, 0.0426, 0.0694], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,865][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0039, 0.4121, 0.0975, 0.2702, 0.0959, 0.1203], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,866][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.8706, 0.0281, 0.0074, 0.0522, 0.0145, 0.0273], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,867][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([9.5643e-01, 1.7013e-05, 7.0700e-04, 9.1329e-03, 2.7390e-03, 3.0975e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,869][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1367, 0.0677, 0.0881, 0.1837, 0.2070, 0.3168], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,870][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.8819, 0.0173, 0.0032, 0.0092, 0.0676, 0.0209], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,871][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.1219e-04, 2.0618e-01, 8.2788e-02, 9.0507e-02, 2.3997e-01, 3.8044e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,872][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.4170, 0.0049, 0.0377, 0.0674, 0.1007, 0.3724], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,874][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0782, 0.5534, 0.0673, 0.1352, 0.1229, 0.0430], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,875][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([6.0684e-06, 1.8575e-01, 1.3483e-01, 9.3541e-02, 2.1215e-01, 3.7371e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,876][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([2.1217e-01, 3.1958e-04, 6.6213e-03, 1.9114e-02, 5.3923e-02, 7.0785e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,877][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0111, 0.0535, 0.1569, 0.0797, 0.4542, 0.2446], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:24,879][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.6699, 0.0702, 0.0319, 0.0806, 0.0356, 0.0499, 0.0619],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,880][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0015, 0.3657, 0.0901, 0.1944, 0.1093, 0.0965, 0.1426],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,880][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.8607, 0.0165, 0.0063, 0.0388, 0.0154, 0.0289, 0.0334],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,880][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.7783, 0.0012, 0.0098, 0.0135, 0.0203, 0.1583, 0.0186],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,881][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1259, 0.0504, 0.0664, 0.2488, 0.1608, 0.1644, 0.1834],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,881][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.8142, 0.0177, 0.0060, 0.0125, 0.0755, 0.0307, 0.0434],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,882][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([3.5313e-05, 2.1115e-01, 1.1269e-01, 7.2473e-02, 1.6063e-01, 3.5732e-01,
        8.5697e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,882][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.2179, 0.0072, 0.0577, 0.0483, 0.0875, 0.3529, 0.2285],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,882][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0643, 0.6108, 0.0650, 0.1441, 0.0679, 0.0259, 0.0221],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,883][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([1.5307e-06, 1.5518e-01, 1.4616e-01, 1.1402e-01, 1.1798e-01, 3.4532e-01,
        1.2134e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,883][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0367, 0.0030, 0.0138, 0.0093, 0.0989, 0.7230, 0.1151],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,885][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0027, 0.0719, 0.1251, 0.0980, 0.4132, 0.1375, 0.1515],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:24,886][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.6503, 0.0746, 0.0176, 0.0423, 0.0336, 0.0209, 0.0229, 0.1378],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,888][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([0.0016, 0.1554, 0.0508, 0.1336, 0.1143, 0.0884, 0.1811, 0.2749],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,889][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([0.6103, 0.0202, 0.0111, 0.0197, 0.0221, 0.0389, 0.0602, 0.2175],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,890][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.4984, 0.0046, 0.0140, 0.0105, 0.0239, 0.3293, 0.0508, 0.0685],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,892][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.0403, 0.0559, 0.0853, 0.0980, 0.0924, 0.1373, 0.1564, 0.3344],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,893][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.6273, 0.0262, 0.0097, 0.0113, 0.0679, 0.0363, 0.0471, 0.1743],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,894][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([3.1378e-05, 7.0410e-02, 8.8490e-02, 8.2334e-02, 1.7017e-01, 3.7351e-01,
        1.7491e-01, 4.0143e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,896][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.0615, 0.0171, 0.0500, 0.0261, 0.1709, 0.2349, 0.2211, 0.2184],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,897][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.0318, 0.3761, 0.1156, 0.1182, 0.0611, 0.0395, 0.0445, 0.2133],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,898][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([3.3252e-06, 1.2469e-01, 1.3551e-01, 9.7211e-02, 1.4520e-01, 2.6294e-01,
        1.4595e-01, 8.8498e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,899][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.0092, 0.0143, 0.0143, 0.0085, 0.0964, 0.6374, 0.1226, 0.0973],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,901][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.0010, 0.0245, 0.0583, 0.0496, 0.3241, 0.0989, 0.1381, 0.3054],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:24,902][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4402, 0.1046, 0.0216, 0.0883, 0.0308, 0.0394, 0.0377, 0.1400, 0.0975],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,903][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0012, 0.2296, 0.0766, 0.2228, 0.0775, 0.0652, 0.0770, 0.1854, 0.0645],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,905][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.7099, 0.0272, 0.0042, 0.0679, 0.0115, 0.0123, 0.0193, 0.0821, 0.0656],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,906][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([8.2531e-01, 8.1092e-04, 2.3243e-03, 2.2346e-02, 6.7193e-03, 2.8326e-02,
        1.2340e-02, 4.2332e-02, 5.9496e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,907][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0374, 0.0732, 0.0495, 0.1114, 0.0843, 0.1015, 0.1228, 0.0959, 0.3241],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,909][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.6616, 0.0306, 0.0053, 0.0145, 0.0719, 0.0263, 0.0371, 0.1201, 0.0326],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,910][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([3.6317e-05, 2.2214e-01, 7.3249e-02, 6.7039e-02, 1.2938e-01, 2.9448e-01,
        8.9975e-02, 2.0995e-02, 1.0271e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,911][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1856, 0.0073, 0.0181, 0.0304, 0.0429, 0.1047, 0.1104, 0.1645, 0.3362],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,912][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0266, 0.5156, 0.0525, 0.1194, 0.0547, 0.0167, 0.0136, 0.1277, 0.0732],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,913][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([1.1153e-06, 1.4359e-01, 1.0748e-01, 8.7817e-02, 8.4750e-02, 3.2342e-01,
        1.0693e-01, 5.0160e-02, 9.5851e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,915][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0427, 0.0027, 0.0076, 0.0157, 0.0508, 0.3149, 0.0889, 0.0928, 0.3839],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,916][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0009, 0.0296, 0.0726, 0.0491, 0.3056, 0.0896, 0.0899, 0.3005, 0.0622],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:24,917][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.3018, 0.2678, 0.0277, 0.0606, 0.0399, 0.0200, 0.0395, 0.0999, 0.0526,
        0.0903], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,919][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.0008, 0.3686, 0.0425, 0.1011, 0.0732, 0.0492, 0.0841, 0.1532, 0.0737,
        0.0536], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,920][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.4742, 0.0291, 0.0071, 0.0510, 0.0251, 0.0210, 0.0316, 0.1111, 0.0964,
        0.1535], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,922][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.4005, 0.0930, 0.0181, 0.0586, 0.0095, 0.0085, 0.0391, 0.2591, 0.0916,
        0.0221], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,923][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.0126, 0.0899, 0.0472, 0.0661, 0.0602, 0.0730, 0.0682, 0.1109, 0.2214,
        0.2504], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,925][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.2498, 0.0693, 0.0133, 0.0281, 0.1337, 0.0320, 0.0627, 0.2358, 0.0406,
        0.1348], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,926][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([4.8562e-05, 7.9378e-02, 7.4736e-02, 6.6292e-02, 1.5243e-01, 2.7153e-01,
        1.6449e-01, 2.5461e-02, 1.4428e-01, 2.1360e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,927][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0877, 0.0460, 0.0474, 0.0373, 0.0741, 0.0656, 0.1593, 0.2105, 0.2349,
        0.0372], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,927][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.0145, 0.3738, 0.0477, 0.0858, 0.0762, 0.0231, 0.0343, 0.1200, 0.0723,
        0.1523], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,928][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([2.5723e-06, 7.2663e-02, 4.0082e-02, 1.0838e-01, 1.0650e-01, 2.7198e-01,
        1.4339e-01, 6.0148e-02, 1.0236e-01, 9.4491e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,928][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.0115, 0.0616, 0.0126, 0.0148, 0.0368, 0.0555, 0.1175, 0.3542, 0.2972,
        0.0382], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,928][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.0010, 0.0279, 0.0502, 0.0588, 0.3936, 0.0930, 0.1013, 0.1886, 0.0619,
        0.0238], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:24,929][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.2552, 0.1566, 0.0177, 0.0607, 0.0215, 0.0272, 0.0177, 0.0821, 0.0675,
        0.0944, 0.1994], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,929][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0010, 0.2224, 0.0642, 0.1438, 0.0525, 0.0658, 0.0879, 0.1450, 0.0792,
        0.0385, 0.0998], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,930][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.4273, 0.0420, 0.0042, 0.0454, 0.0174, 0.0147, 0.0242, 0.0916, 0.0686,
        0.0860, 0.1787], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,930][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.4118, 0.0048, 0.0034, 0.0179, 0.0088, 0.0863, 0.0322, 0.1042, 0.2113,
        0.0327, 0.0866], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,931][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0117, 0.0608, 0.0249, 0.0636, 0.0394, 0.0609, 0.0662, 0.0742, 0.1762,
        0.1531, 0.2689], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,933][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.5202, 0.0175, 0.0065, 0.0105, 0.0726, 0.0253, 0.0304, 0.1280, 0.0312,
        0.0507, 0.1071], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,934][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([1.3285e-05, 2.8830e-01, 6.6647e-02, 6.5109e-02, 1.1199e-01, 2.1170e-01,
        6.7263e-02, 1.8091e-02, 1.0075e-01, 2.7581e-02, 4.2556e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,935][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0464, 0.0119, 0.0159, 0.0136, 0.0644, 0.1306, 0.1075, 0.0895, 0.2796,
        0.0187, 0.2218], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,936][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0078, 0.5689, 0.0283, 0.0763, 0.0275, 0.0090, 0.0098, 0.0688, 0.0373,
        0.0947, 0.0716], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,937][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([4.9715e-07, 1.6987e-01, 1.0260e-01, 8.2773e-02, 6.1259e-02, 2.3790e-01,
        9.6165e-02, 3.3359e-02, 9.3645e-02, 7.7560e-02, 4.4870e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,939][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0172, 0.0027, 0.0033, 0.0031, 0.0235, 0.2369, 0.0819, 0.1017, 0.3508,
        0.0221, 0.1568], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,940][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0007, 0.0326, 0.0422, 0.0399, 0.2767, 0.0577, 0.0858, 0.1720, 0.0416,
        0.0140, 0.2367], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:24,942][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4200, 0.0322, 0.0231, 0.0577, 0.0121, 0.0288, 0.0267, 0.0647, 0.0852,
        0.0772, 0.1260, 0.0463], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,943][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0020, 0.0984, 0.0659, 0.1312, 0.0805, 0.0626, 0.0897, 0.2071, 0.0656,
        0.0333, 0.1089, 0.0547], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,945][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.5128, 0.0122, 0.0053, 0.0290, 0.0065, 0.0150, 0.0236, 0.0502, 0.0766,
        0.1345, 0.0836, 0.0508], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,946][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([7.9657e-01, 4.7165e-04, 7.0090e-04, 1.7079e-02, 2.7066e-03, 1.3412e-02,
        6.7612e-03, 2.8263e-02, 4.6757e-02, 2.3992e-02, 2.6200e-02, 3.7083e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,947][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0348, 0.0197, 0.0307, 0.0299, 0.0220, 0.0502, 0.0779, 0.0528, 0.2057,
        0.1042, 0.2907, 0.0814], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,948][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.6288, 0.0111, 0.0063, 0.0106, 0.0419, 0.0169, 0.0250, 0.0878, 0.0243,
        0.0542, 0.0489, 0.0443], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,949][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([2.3245e-05, 9.4070e-02, 8.9405e-02, 5.6910e-02, 1.1073e-01, 2.5029e-01,
        9.6580e-02, 2.1932e-02, 1.1862e-01, 2.0064e-02, 7.5077e-02, 6.6301e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,951][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1877, 0.0045, 0.0110, 0.0252, 0.0299, 0.0557, 0.0676, 0.0946, 0.1946,
        0.0241, 0.1618, 0.1435], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,952][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0158, 0.2314, 0.0666, 0.0891, 0.0320, 0.0230, 0.0148, 0.1141, 0.0944,
        0.1773, 0.1141, 0.0275], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,953][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([7.9822e-07, 9.1041e-02, 1.2408e-01, 7.8780e-02, 5.8410e-02, 2.1657e-01,
        8.8858e-02, 4.8182e-02, 9.3772e-02, 6.0295e-02, 3.5419e-02, 1.0459e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,955][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0443, 0.0017, 0.0037, 0.0107, 0.0152, 0.1497, 0.0433, 0.0504, 0.2240,
        0.0435, 0.0742, 0.3392], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,956][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0011, 0.0346, 0.0420, 0.0430, 0.1827, 0.0634, 0.0894, 0.1983, 0.0627,
        0.0174, 0.2020, 0.0633], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:24,958][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.1549, 0.0189, 0.0156, 0.0243, 0.0156, 0.0525, 0.0397, 0.1708, 0.1287,
        0.0541, 0.1639, 0.0393, 0.1218], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,959][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0006, 0.2109, 0.0336, 0.1097, 0.0975, 0.0328, 0.0490, 0.1027, 0.0474,
        0.0267, 0.1283, 0.0249, 0.1359], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,960][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.2709, 0.0145, 0.0055, 0.0226, 0.0134, 0.0288, 0.0335, 0.1169, 0.1386,
        0.1274, 0.1311, 0.0482, 0.0487], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,962][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.3387, 0.0014, 0.0011, 0.0113, 0.0021, 0.0216, 0.0131, 0.0837, 0.1357,
        0.0247, 0.0846, 0.1964, 0.0855], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,964][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.0189, 0.0302, 0.0259, 0.0574, 0.0518, 0.0628, 0.0568, 0.0826, 0.1450,
        0.0942, 0.1949, 0.0547, 0.1250], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,965][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.3383, 0.0096, 0.0071, 0.0081, 0.0494, 0.0226, 0.0393, 0.1321, 0.0382,
        0.0457, 0.0633, 0.0622, 0.1840], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,966][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([1.2025e-05, 8.8553e-02, 6.5774e-02, 4.4261e-02, 1.4953e-01, 1.3200e-01,
        4.2119e-02, 2.0188e-02, 9.3728e-02, 1.4055e-02, 1.3419e-01, 5.9209e-02,
        1.5637e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,967][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0215, 0.0052, 0.0112, 0.0101, 0.0260, 0.0703, 0.0787, 0.0899, 0.2104,
        0.0175, 0.1667, 0.2047, 0.0877], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,969][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.0247, 0.1878, 0.0246, 0.0526, 0.0311, 0.0141, 0.0155, 0.1480, 0.0619,
        0.1635, 0.1614, 0.0247, 0.0899], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,970][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([1.3149e-06, 8.3108e-02, 9.0626e-02, 6.0542e-02, 6.6134e-02, 1.8472e-01,
        8.1906e-02, 5.3020e-02, 1.0192e-01, 5.0822e-02, 6.0445e-02, 9.8777e-02,
        6.7981e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,971][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0047, 0.0023, 0.0010, 0.0032, 0.0056, 0.0459, 0.0277, 0.0509, 0.1362,
        0.0166, 0.0930, 0.3672, 0.2457], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,973][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0005, 0.0224, 0.0341, 0.0394, 0.2130, 0.0421, 0.0765, 0.1682, 0.0337,
        0.0089, 0.1655, 0.0542, 0.1416], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:24,974][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.3575, 0.0430, 0.0213, 0.0479, 0.0110, 0.0322, 0.0251, 0.0505, 0.0735,
        0.0892, 0.0836, 0.0368, 0.0495, 0.0791], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,974][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0011, 0.1860, 0.0436, 0.1352, 0.0595, 0.0397, 0.0598, 0.0995, 0.0308,
        0.0329, 0.0404, 0.0236, 0.2272, 0.0206], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,975][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.5486, 0.0084, 0.0035, 0.0291, 0.0060, 0.0113, 0.0193, 0.0378, 0.0532,
        0.1152, 0.0586, 0.0390, 0.0198, 0.0500], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,975][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([7.3791e-01, 5.9649e-04, 5.4505e-04, 1.5624e-02, 2.1468e-03, 8.2012e-03,
        6.2889e-03, 2.6445e-02, 3.6324e-02, 1.4995e-02, 1.8910e-02, 3.6441e-02,
        4.7208e-02, 4.8368e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,976][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0117, 0.0168, 0.0246, 0.0312, 0.0240, 0.0648, 0.0572, 0.0379, 0.1733,
        0.0799, 0.2198, 0.0520, 0.0920, 0.1149], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,976][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.5770, 0.0077, 0.0030, 0.0077, 0.0381, 0.0136, 0.0190, 0.0694, 0.0177,
        0.0484, 0.0430, 0.0335, 0.0779, 0.0439], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,977][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.4719e-05, 1.2697e-01, 7.1185e-02, 5.7913e-02, 9.4711e-02, 2.0185e-01,
        7.0804e-02, 1.2369e-02, 7.9903e-02, 1.8412e-02, 4.6161e-02, 3.8298e-02,
        1.1708e-01, 6.4334e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,977][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1263, 0.0035, 0.0060, 0.0143, 0.0201, 0.0390, 0.0463, 0.0645, 0.1601,
        0.0196, 0.1253, 0.1231, 0.1077, 0.1443], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,978][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0143, 0.2303, 0.0474, 0.0785, 0.0413, 0.0213, 0.0153, 0.1066, 0.0879,
        0.1557, 0.1127, 0.0304, 0.0259, 0.0323], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,979][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([4.4757e-07, 7.1878e-02, 8.3242e-02, 8.1286e-02, 5.2564e-02, 2.4224e-01,
        7.4667e-02, 2.5729e-02, 5.9982e-02, 5.5982e-02, 2.2845e-02, 6.2334e-02,
        4.5790e-02, 1.2146e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,980][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0343, 0.0019, 0.0015, 0.0081, 0.0070, 0.0525, 0.0228, 0.0364, 0.1019,
        0.0199, 0.0347, 0.1791, 0.2307, 0.2693], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,982][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0010, 0.0278, 0.0364, 0.0314, 0.1315, 0.0544, 0.0593, 0.1777, 0.0490,
        0.0187, 0.1945, 0.0384, 0.1275, 0.0523], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:24,983][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:23:24,985][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[1463],
        [  89],
        [  17],
        [   7],
        [   4],
        [   9],
        [   5],
        [   1],
        [   5],
        [   5],
        [   2],
        [   7],
        [   7],
        [   3]], device='cuda:0')
[2024-07-24 10:23:24,986][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[1315],
        [  55],
        [  14],
        [  21],
        [   3],
        [   9],
        [   5],
        [   3],
        [   6],
        [  12],
        [   3],
        [  10],
        [  21],
        [   4]], device='cuda:0')
[2024-07-24 10:23:24,988][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[10585],
        [15458],
        [14872],
        [18359],
        [21462],
        [17921],
        [18718],
        [23660],
        [22533],
        [21558],
        [17760],
        [18484],
        [23172],
        [21029]], device='cuda:0')
[2024-07-24 10:23:24,989][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 5196],
        [22786],
        [24073],
        [24539],
        [25390],
        [27625],
        [25348],
        [23277],
        [26190],
        [25300],
        [25989],
        [25543],
        [26438],
        [28010]], device='cuda:0')
[2024-07-24 10:23:24,991][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 4050],
        [32078],
        [11340],
        [46487],
        [45966],
        [40186],
        [33086],
        [37917],
        [46264],
        [42442],
        [41621],
        [36886],
        [38510],
        [36714]], device='cuda:0')
[2024-07-24 10:23:24,992][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[34144],
        [34747],
        [34801],
        [37788],
        [35790],
        [35165],
        [37482],
        [36843],
        [37012],
        [36020],
        [39573],
        [37917],
        [39671],
        [38583]], device='cuda:0')
[2024-07-24 10:23:24,993][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 9085],
        [ 1960],
        [ 7243],
        [ 1081],
        [ 3614],
        [13456],
        [ 9584],
        [16733],
        [22524],
        [14173],
        [22363],
        [31237],
        [25371],
        [33485]], device='cuda:0')
[2024-07-24 10:23:24,995][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[38709],
        [ 3170],
        [31433],
        [ 2802],
        [ 6822],
        [18127],
        [10862],
        [10062],
        [ 7451],
        [ 3968],
        [ 4096],
        [ 5019],
        [ 2722],
        [ 3828]], device='cuda:0')
[2024-07-24 10:23:24,996][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[25496],
        [43630],
        [43216],
        [48335],
        [47848],
        [43258],
        [40160],
        [35851],
        [39677],
        [34872],
        [42569],
        [36318],
        [39859],
        [38741]], device='cuda:0')
[2024-07-24 10:23:24,997][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 1892],
        [ 7490],
        [ 3633],
        [10849],
        [20786],
        [ 8784],
        [ 8552],
        [16489],
        [13187],
        [15606],
        [16187],
        [17077],
        [16421],
        [16550]], device='cuda:0')
[2024-07-24 10:23:24,999][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[27575],
        [32587],
        [24277],
        [41574],
        [42069],
        [37205],
        [36539],
        [36193],
        [36471],
        [36825],
        [39637],
        [38356],
        [40548],
        [39395]], device='cuda:0')
[2024-07-24 10:23:25,000][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[1101],
        [1305],
        [ 969],
        [   2],
        [   5],
        [   9],
        [   6],
        [  15],
        [   8],
        [  16],
        [  46],
        [  29],
        [  32],
        [  76]], device='cuda:0')
[2024-07-24 10:23:25,002][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[17749],
        [10678],
        [13928],
        [11139],
        [ 5389],
        [15264],
        [14378],
        [13755],
        [16065],
        [13802],
        [15130],
        [15858],
        [16484],
        [17824]], device='cuda:0')
[2024-07-24 10:23:25,003][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[23251],
        [46248],
        [25339],
        [42928],
        [24003],
        [25313],
        [27089],
        [24241],
        [24635],
        [24927],
        [23592],
        [24620],
        [25168],
        [25103]], device='cuda:0')
[2024-07-24 10:23:25,005][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[18180],
        [ 8493],
        [ 4118],
        [ 3426],
        [ 4912],
        [ 5372],
        [ 5913],
        [ 2776],
        [ 5515],
        [ 7036],
        [ 3566],
        [ 6256],
        [ 6997],
        [ 5301]], device='cuda:0')
[2024-07-24 10:23:25,006][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[12356],
        [33969],
        [25458],
        [36128],
        [20964],
        [23504],
        [22796],
        [21157],
        [22458],
        [29184],
        [24197],
        [18425],
        [14000],
        [18117]], device='cuda:0')
[2024-07-24 10:23:25,007][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 5344],
        [25712],
        [27268],
        [23547],
        [22587],
        [22014],
        [23505],
        [21810],
        [22797],
        [25994],
        [26054],
        [25528],
        [21287],
        [20913]], device='cuda:0')
[2024-07-24 10:23:25,009][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[15476],
        [18744],
        [27629],
        [ 7762],
        [ 9621],
        [ 9272],
        [ 8175],
        [11869],
        [ 7701],
        [ 9348],
        [14180],
        [10129],
        [12581],
        [ 9102]], device='cuda:0')
[2024-07-24 10:23:25,010][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[3347],
        [3463],
        [3142],
        [4170],
        [3820],
        [3199],
        [3669],
        [7144],
        [3521],
        [8336],
        [4265],
        [2755],
        [3781],
        [3054]], device='cuda:0')
[2024-07-24 10:23:25,012][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 707],
        [2779],
        [3313],
        [1463],
        [2097],
        [4178],
        [2928],
        [4047],
        [5319],
        [4606],
        [5102],
        [5344],
        [4635],
        [5068]], device='cuda:0')
[2024-07-24 10:23:25,013][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 3179],
        [ 6505],
        [ 2648],
        [ 2451],
        [ 3926],
        [ 2692],
        [ 4602],
        [ 6462],
        [ 5994],
        [ 9925],
        [ 8559],
        [ 9579],
        [14434],
        [13206]], device='cuda:0')
[2024-07-24 10:23:25,014][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[7541],
        [1871],
        [2611],
        [3946],
        [3341],
        [3419],
        [3297],
        [3723],
        [2731],
        [2843],
        [2548],
        [3645],
        [2017],
        [2066]], device='cuda:0')
[2024-07-24 10:23:25,016][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 3190],
        [30464],
        [ 7940],
        [ 5566],
        [ 6978],
        [11671],
        [13200],
        [10030],
        [ 7279],
        [ 7578],
        [ 6607],
        [ 4083],
        [ 3749],
        [ 3229]], device='cuda:0')
[2024-07-24 10:23:25,017][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[10251],
        [ 5941],
        [ 5612],
        [ 4302],
        [ 3708],
        [ 4732],
        [ 4546],
        [ 3471],
        [ 3690],
        [ 3063],
        [ 3150],
        [ 2711],
        [ 3751],
        [ 3393]], device='cuda:0')
[2024-07-24 10:23:25,018][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[20994],
        [13712],
        [20362],
        [21995],
        [28827],
        [30477],
        [30774],
        [33577],
        [32245],
        [34802],
        [32954],
        [35077],
        [36872],
        [33924]], device='cuda:0')
[2024-07-24 10:23:25,020][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 1234],
        [22757],
        [11154],
        [20641],
        [10819],
        [11653],
        [10913],
        [ 9501],
        [ 8177],
        [ 5982],
        [ 7166],
        [ 7379],
        [ 3823],
        [ 4737]], device='cuda:0')
[2024-07-24 10:23:25,021][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[7153],
        [2632],
        [5838],
        [4067],
        [7237],
        [6616],
        [6248],
        [8466],
        [8239],
        [7597],
        [6939],
        [6909],
        [7309],
        [7108]], device='cuda:0')
[2024-07-24 10:23:25,023][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[47219],
        [37285],
        [40419],
        [45622],
        [45742],
        [41926],
        [42178],
        [39650],
        [41705],
        [38794],
        [38999],
        [41021],
        [41854],
        [42529]], device='cuda:0')
[2024-07-24 10:23:25,024][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[23347],
        [46910],
        [45807],
        [45155],
        [44231],
        [47446],
        [46139],
        [47061],
        [45795],
        [45423],
        [48295],
        [45103],
        [46970],
        [46720]], device='cuda:0')
[2024-07-24 10:23:25,025][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[2501],
        [2501],
        [2501],
        [2501],
        [2501],
        [2501],
        [2501],
        [2501],
        [2501],
        [2501],
        [2501],
        [2501],
        [2501],
        [2501]], device='cuda:0')
[2024-07-24 10:23:25,086][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:25,088][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,089][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,090][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,091][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,093][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,094][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,095][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,096][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,097][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,098][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,099][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,101][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,102][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.0142, 0.9858], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,103][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.0023, 0.9977], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,105][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.0220, 0.9780], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,106][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.0350, 0.9650], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,108][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.4670, 0.5330], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,109][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.5916, 0.4084], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,111][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.2686, 0.7314], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,112][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.2385, 0.7615], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,114][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.0225, 0.9775], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,115][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.4879, 0.5121], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,116][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.1302, 0.8698], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,118][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.7037, 0.2963], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,118][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0010, 0.3543, 0.6447], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,119][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([4.2301e-05, 4.1102e-01, 5.8894e-01], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,119][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0045, 0.1143, 0.8812], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,119][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0129, 0.2241, 0.7630], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,120][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2765, 0.0888, 0.6347], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,120][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.4606, 0.0545, 0.4849], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,120][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0230, 0.5116, 0.4654], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,121][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2310, 0.3181, 0.4509], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,121][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0190, 0.5141, 0.4669], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,121][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2378, 0.1643, 0.5979], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,122][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1006, 0.7964, 0.1030], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,123][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1437, 0.1767, 0.6796], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,125][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Mary] are: tensor([0.0066, 0.2137, 0.4530, 0.3268], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,126][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Mary] are: tensor([9.4304e-05, 1.6840e-01, 4.2158e-01, 4.0992e-01], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,126][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Mary] are: tensor([6.8626e-04, 6.2657e-02, 7.8889e-01, 1.4777e-01], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,128][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Mary] are: tensor([0.0054, 0.1834, 0.4860, 0.3252], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,129][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Mary] are: tensor([0.2432, 0.0701, 0.5404, 0.1463], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,130][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Mary] are: tensor([0.1632, 0.1304, 0.4854, 0.2210], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,132][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Mary] are: tensor([0.0229, 0.4000, 0.2722, 0.3049], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,133][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Mary] are: tensor([0.1249, 0.1247, 0.1141, 0.6363], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,135][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Mary] are: tensor([0.0059, 0.2059, 0.2689, 0.5193], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,136][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Mary] are: tensor([0.3343, 0.2290, 0.2543, 0.1824], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,138][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Mary] are: tensor([0.0548, 0.7083, 0.0928, 0.1441], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,139][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Mary] are: tensor([0.0295, 0.1289, 0.4552, 0.3864], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,140][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0080, 0.0271, 0.1331, 0.1298, 0.7020], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,141][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ went] are: tensor([1.5925e-05, 1.0712e-02, 6.9136e-02, 9.8155e-02, 8.2198e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,142][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ went] are: tensor([2.1537e-04, 2.4190e-02, 5.1495e-01, 1.5952e-01, 3.0113e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,144][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0038, 0.0243, 0.2120, 0.1522, 0.6076], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,145][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.2424, 0.0292, 0.1827, 0.0830, 0.4627], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,146][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0514, 0.0060, 0.1010, 0.0971, 0.7445], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,148][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0052, 0.0523, 0.1076, 0.0758, 0.7591], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,149][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.1198, 0.0404, 0.0692, 0.5194, 0.2512], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,151][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0022, 0.0823, 0.2105, 0.3979, 0.3071], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,152][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.1033, 0.0110, 0.0888, 0.1505, 0.6464], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,154][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0512, 0.5723, 0.0998, 0.1588, 0.1177], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,155][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.1525, 0.0111, 0.0854, 0.1383, 0.6128], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,156][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0017, 0.0425, 0.1142, 0.0744, 0.2055, 0.5615], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,157][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([6.3334e-06, 9.3373e-03, 2.6041e-02, 9.0812e-02, 5.7072e-01, 3.0308e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,159][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0009, 0.0388, 0.3755, 0.1969, 0.1172, 0.2706], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,160][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0024, 0.0300, 0.1215, 0.1780, 0.3397, 0.3284], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,161][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.3113, 0.0178, 0.1453, 0.0697, 0.1548, 0.3011], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,163][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.2775, 0.0020, 0.0189, 0.0808, 0.1225, 0.4984], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,164][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0065, 0.0489, 0.0550, 0.1022, 0.5562, 0.2311], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,165][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0727, 0.0641, 0.0892, 0.6381, 0.0761, 0.0597], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,166][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0090, 0.0890, 0.1576, 0.3571, 0.1760, 0.2113], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,166][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.2081, 0.0031, 0.0155, 0.1511, 0.1051, 0.5171], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,166][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0540, 0.5762, 0.0788, 0.1282, 0.0812, 0.0816], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,167][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.8212, 0.0085, 0.0131, 0.0940, 0.0458, 0.0174], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,167][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0011, 0.0209, 0.1006, 0.1053, 0.1776, 0.3995, 0.1951],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,167][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ the] are: tensor([1.4056e-06, 6.8622e-03, 3.1350e-02, 8.7800e-02, 4.2165e-01, 2.7720e-01,
        1.7513e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,168][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ the] are: tensor([1.9056e-04, 2.7732e-02, 2.6682e-01, 2.1014e-01, 1.0989e-01, 1.9546e-01,
        1.8978e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,168][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0021, 0.0153, 0.0616, 0.1190, 0.2624, 0.1544, 0.3851],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,169][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2463, 0.0062, 0.0694, 0.0380, 0.0642, 0.1786, 0.3974],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,170][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1506, 0.0052, 0.0198, 0.0376, 0.1505, 0.3983, 0.2379],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,171][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0023, 0.0366, 0.0506, 0.1041, 0.4945, 0.2203, 0.0916],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,173][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1335, 0.0387, 0.0603, 0.5042, 0.0843, 0.0584, 0.1205],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,174][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0010, 0.0593, 0.1348, 0.3852, 0.1182, 0.1325, 0.1692],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,175][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0833, 0.0088, 0.0172, 0.0568, 0.0997, 0.4500, 0.2842],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,177][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0582, 0.5225, 0.0734, 0.1194, 0.0782, 0.0765, 0.0718],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,178][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.4064, 0.0100, 0.0330, 0.2590, 0.1732, 0.0450, 0.0735],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,179][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([1.4413e-04, 1.2377e-02, 6.5192e-02, 5.7170e-02, 1.3979e-01, 2.4225e-01,
        1.3070e-01, 3.5238e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,180][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([4.5928e-07, 5.2876e-03, 1.7952e-02, 6.8100e-02, 3.5872e-01, 1.4326e-01,
        1.2546e-01, 2.8122e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,181][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([9.9756e-06, 1.2119e-02, 2.4298e-01, 1.2356e-01, 1.2935e-01, 2.4364e-01,
        1.7108e-01, 7.7264e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,182][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([2.4915e-04, 7.3415e-03, 3.8486e-02, 3.6616e-02, 1.2144e-01, 1.8276e-01,
        2.8691e-01, 3.2620e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,183][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.0222, 0.0069, 0.0662, 0.0222, 0.0543, 0.1713, 0.4153, 0.2417],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,184][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.0016, 0.0062, 0.0241, 0.0100, 0.1161, 0.3363, 0.2058, 0.2999],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,185][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([2.6584e-04, 3.0592e-02, 4.8533e-02, 8.1414e-02, 4.4518e-01, 1.7397e-01,
        9.4263e-02, 1.2578e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,187][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.0116, 0.0156, 0.0319, 0.7331, 0.0704, 0.0212, 0.0312, 0.0850],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,188][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.0008, 0.0434, 0.0897, 0.1698, 0.1051, 0.1258, 0.1610, 0.3043],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,190][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.0005, 0.0034, 0.0151, 0.0060, 0.0394, 0.3921, 0.2228, 0.3206],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,191][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.0407, 0.4859, 0.0788, 0.1225, 0.0793, 0.0780, 0.0751, 0.0396],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,193][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.0018, 0.0035, 0.0406, 0.0278, 0.0961, 0.1614, 0.1003, 0.5684],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,194][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0004, 0.0218, 0.0485, 0.0651, 0.1652, 0.2413, 0.1186, 0.2002, 0.1388],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,195][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([3.8200e-07, 4.3741e-03, 1.3241e-02, 7.8581e-02, 3.6657e-01, 1.9288e-01,
        8.4520e-02, 1.4768e-01, 1.1215e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,196][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([8.0556e-05, 2.0366e-02, 1.8258e-01, 1.8852e-01, 8.9980e-02, 2.2038e-01,
        1.3630e-01, 5.5854e-02, 1.0594e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,197][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0008, 0.0154, 0.0363, 0.0901, 0.1267, 0.1310, 0.2430, 0.1936, 0.1632],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,199][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0752, 0.0045, 0.0249, 0.0224, 0.0351, 0.1031, 0.1800, 0.1394, 0.4154],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,200][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0596, 0.0059, 0.0124, 0.0446, 0.0762, 0.1846, 0.1405, 0.2090, 0.2672],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,202][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0014, 0.0318, 0.0320, 0.1139, 0.3692, 0.1665, 0.0612, 0.0972, 0.1268],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,203][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0391, 0.0210, 0.0283, 0.5344, 0.0443, 0.0310, 0.0447, 0.0372, 0.2201],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,204][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0008, 0.0420, 0.0644, 0.2557, 0.0708, 0.1186, 0.1052, 0.1988, 0.1437],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,206][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0123, 0.0029, 0.0066, 0.0345, 0.0407, 0.1402, 0.1617, 0.2627, 0.3383],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,207][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0413, 0.4643, 0.0726, 0.1193, 0.0678, 0.0723, 0.0647, 0.0329, 0.0647],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,209][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.3525, 0.0094, 0.0165, 0.2091, 0.1023, 0.0351, 0.0391, 0.2161, 0.0198],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,210][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.0004, 0.0232, 0.0467, 0.0753, 0.1792, 0.1753, 0.0939, 0.1721, 0.1279,
        0.1060], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,211][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([4.0031e-07, 4.1924e-03, 1.2540e-02, 7.6100e-02, 4.1204e-01, 1.8644e-01,
        8.6427e-02, 1.0054e-01, 1.0711e-01, 1.4614e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,212][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([6.3681e-06, 2.6124e-02, 2.5812e-01, 1.1217e-01, 8.8709e-02, 2.0701e-01,
        1.1566e-01, 7.0594e-02, 8.5388e-02, 3.6226e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,213][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.0004, 0.0177, 0.0437, 0.0370, 0.1115, 0.1328, 0.2342, 0.2071, 0.1446,
        0.0710], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,213][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.0155, 0.0043, 0.0270, 0.0110, 0.0656, 0.1050, 0.2229, 0.1424, 0.3740,
        0.0322], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,213][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.0027, 0.0431, 0.0192, 0.0270, 0.0462, 0.0256, 0.1226, 0.4456, 0.1953,
        0.0728], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,214][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([3.0924e-04, 3.2426e-02, 4.1947e-02, 8.5054e-02, 3.3805e-01, 1.6921e-01,
        7.1901e-02, 7.8471e-02, 1.1056e-01, 7.2085e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,214][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0213, 0.0188, 0.0301, 0.2787, 0.0488, 0.0278, 0.0332, 0.0582, 0.1851,
        0.2981], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,215][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.0006, 0.0556, 0.0624, 0.1620, 0.1137, 0.1061, 0.1088, 0.1628, 0.1252,
        0.1027], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,215][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([5.9769e-04, 1.7289e-02, 8.4735e-03, 1.2806e-02, 1.2937e-02, 1.8767e-02,
        1.4577e-01, 6.6766e-01, 9.9768e-02, 1.5931e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,215][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0393, 0.4155, 0.0687, 0.1069, 0.0719, 0.0691, 0.0618, 0.0383, 0.0682,
        0.0603], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,216][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.0008, 0.0106, 0.0472, 0.0764, 0.1633, 0.2330, 0.1461, 0.2529, 0.0590,
        0.0106], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,218][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0006, 0.0067, 0.0195, 0.0187, 0.0637, 0.1908, 0.0780, 0.1357, 0.1763,
        0.1383, 0.1715], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,218][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([6.1936e-07, 6.5757e-03, 1.5947e-02, 6.8565e-02, 2.5382e-01, 1.7110e-01,
        7.7224e-02, 1.7869e-01, 1.3871e-01, 4.9270e-02, 4.0100e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,219][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([8.7840e-06, 1.3049e-02, 1.3833e-01, 9.0188e-02, 8.7036e-02, 2.1140e-01,
        1.2868e-01, 7.3829e-02, 1.0323e-01, 5.5389e-02, 9.8870e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,220][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([9.6796e-05, 9.3190e-03, 2.1317e-02, 2.4318e-02, 6.3797e-02, 1.4420e-01,
        1.9032e-01, 1.2705e-01, 1.7317e-01, 8.4238e-02, 1.6219e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,222][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0459, 0.0019, 0.0196, 0.0053, 0.0165, 0.1187, 0.1467, 0.0961, 0.4498,
        0.0403, 0.0592], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,223][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0050, 0.0027, 0.0071, 0.0061, 0.0335, 0.1160, 0.1069, 0.1754, 0.2526,
        0.0496, 0.2450], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,224][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([2.5564e-04, 4.2471e-02, 2.4928e-02, 9.8439e-02, 2.8129e-01, 1.2491e-01,
        4.4340e-02, 5.5893e-02, 1.1948e-01, 1.3729e-01, 7.0710e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,226][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0109, 0.0136, 0.0192, 0.3039, 0.0366, 0.0326, 0.0329, 0.0322, 0.1549,
        0.2617, 0.1015], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,227][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0003, 0.0401, 0.0512, 0.1591, 0.0876, 0.0723, 0.0723, 0.2143, 0.0902,
        0.0987, 0.1140], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,229][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0007, 0.0025, 0.0037, 0.0074, 0.0171, 0.1193, 0.0939, 0.3135, 0.2467,
        0.0268, 0.1685], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,230][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0324, 0.4042, 0.0613, 0.1102, 0.0590, 0.0627, 0.0556, 0.0317, 0.0589,
        0.0561, 0.0678], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,231][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0434, 0.0104, 0.0316, 0.0932, 0.1522, 0.1119, 0.0929, 0.3249, 0.0693,
        0.0205, 0.0497], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,233][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0004, 0.0103, 0.0380, 0.0439, 0.0675, 0.2178, 0.0723, 0.1163, 0.1151,
        0.1220, 0.0965, 0.1000], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,234][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([2.6341e-07, 3.5124e-03, 2.0335e-02, 6.8693e-02, 2.4617e-01, 2.2267e-01,
        1.0296e-01, 1.2781e-01, 1.3367e-01, 2.3121e-02, 3.2866e-02, 1.8179e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,235][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([4.1006e-05, 1.2872e-02, 1.3211e-01, 1.0814e-01, 7.9366e-02, 1.6194e-01,
        1.2397e-01, 5.5653e-02, 8.4088e-02, 7.1632e-02, 9.0656e-02, 7.9532e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,236][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0006, 0.0081, 0.0339, 0.0333, 0.0910, 0.1178, 0.1812, 0.1332, 0.1182,
        0.0785, 0.1234, 0.0808], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,238][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0672, 0.0012, 0.0181, 0.0124, 0.0218, 0.0843, 0.1299, 0.1022, 0.3131,
        0.0360, 0.0532, 0.1607], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,239][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0354, 0.0032, 0.0048, 0.0240, 0.0187, 0.0868, 0.0670, 0.0972, 0.1534,
        0.0898, 0.1311, 0.2887], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,241][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0012, 0.0223, 0.0441, 0.1117, 0.2321, 0.1651, 0.0671, 0.0736, 0.1051,
        0.0832, 0.0696, 0.0247], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,242][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0222, 0.0099, 0.0193, 0.3570, 0.0271, 0.0221, 0.0332, 0.0263, 0.1368,
        0.2100, 0.0584, 0.0778], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,244][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0011, 0.0252, 0.0430, 0.2398, 0.0791, 0.0787, 0.0931, 0.1172, 0.0889,
        0.0847, 0.0773, 0.0719], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,245][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0080, 0.0019, 0.0027, 0.0209, 0.0117, 0.0638, 0.0570, 0.1409, 0.2487,
        0.0843, 0.1537, 0.2064], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,247][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0393, 0.3770, 0.0618, 0.0975, 0.0596, 0.0599, 0.0532, 0.0286, 0.0548,
        0.0497, 0.0646, 0.0538], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,248][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.5127, 0.0022, 0.0066, 0.0980, 0.0684, 0.0209, 0.0267, 0.2119, 0.0167,
        0.0142, 0.0167, 0.0050], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,249][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0009, 0.0030, 0.0222, 0.0241, 0.0505, 0.1602, 0.1063, 0.0939, 0.1492,
        0.0494, 0.1120, 0.1485, 0.0798], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,250][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([1.2477e-06, 1.7371e-03, 1.4558e-02, 4.0589e-02, 1.9985e-01, 1.4259e-01,
        1.1412e-01, 1.9907e-01, 1.5058e-01, 1.5892e-02, 4.7427e-02, 2.4001e-02,
        4.9582e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,251][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([1.7146e-05, 9.2914e-03, 1.4655e-01, 1.0023e-01, 7.5481e-02, 1.5778e-01,
        1.3003e-01, 5.3728e-02, 7.7343e-02, 2.4071e-02, 7.6297e-02, 9.4337e-02,
        5.4849e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,253][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0004, 0.0045, 0.0265, 0.0287, 0.0861, 0.1273, 0.1677, 0.1352, 0.1039,
        0.0382, 0.1379, 0.1011, 0.0423], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,255][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0121, 0.0006, 0.0194, 0.0082, 0.0308, 0.1193, 0.1430, 0.0995, 0.2809,
        0.0157, 0.0631, 0.1416, 0.0657], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,256][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0040, 0.0030, 0.0027, 0.0088, 0.0131, 0.0422, 0.0464, 0.0958, 0.1023,
        0.0280, 0.1540, 0.3497, 0.1501], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,257][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0007, 0.0134, 0.0269, 0.0755, 0.2055, 0.1214, 0.0852, 0.0611, 0.0978,
        0.0590, 0.0587, 0.0425, 0.1524], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,259][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0417, 0.0072, 0.0169, 0.1701, 0.0396, 0.0207, 0.0395, 0.0246, 0.1295,
        0.0775, 0.0818, 0.0951, 0.2558], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,260][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.0005, 0.0224, 0.0697, 0.1818, 0.0622, 0.0657, 0.1409, 0.1106, 0.0889,
        0.0231, 0.0812, 0.0697, 0.0834], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,260][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0005, 0.0009, 0.0014, 0.0073, 0.0045, 0.0378, 0.0688, 0.1293, 0.1582,
        0.0109, 0.0861, 0.2333, 0.2608], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,260][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0290, 0.3379, 0.0616, 0.0844, 0.0532, 0.0589, 0.0539, 0.0300, 0.0621,
        0.0444, 0.0732, 0.0620, 0.0495], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,261][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0280, 0.0046, 0.0287, 0.0620, 0.0729, 0.0712, 0.0815, 0.3209, 0.0439,
        0.0193, 0.0474, 0.0280, 0.1918], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,261][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0003, 0.0068, 0.0263, 0.0253, 0.0455, 0.1817, 0.0554, 0.0833, 0.0775,
        0.0802, 0.0709, 0.0859, 0.0646, 0.1962], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,262][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.3911e-07, 6.1676e-03, 2.1260e-02, 1.0380e-01, 2.6322e-01, 2.0606e-01,
        8.6246e-02, 9.4807e-02, 9.7942e-02, 1.8707e-02, 2.2722e-02, 1.1072e-02,
        4.8740e-02, 1.9256e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,262][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.6286e-05, 9.6741e-03, 1.1732e-01, 9.1711e-02, 5.1326e-02, 1.4120e-01,
        9.6709e-02, 5.2434e-02, 6.5682e-02, 5.1462e-02, 7.3251e-02, 5.9315e-02,
        7.1603e-02, 1.1829e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,263][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0004, 0.0084, 0.0245, 0.0273, 0.0751, 0.1094, 0.1474, 0.0927, 0.0987,
        0.0972, 0.1039, 0.0637, 0.0355, 0.1156], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,264][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0344, 0.0011, 0.0146, 0.0100, 0.0173, 0.0690, 0.1272, 0.0918, 0.2496,
        0.0255, 0.0411, 0.1356, 0.0364, 0.1464], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,265][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0192, 0.0026, 0.0028, 0.0138, 0.0122, 0.0394, 0.0424, 0.0627, 0.0948,
        0.0433, 0.0816, 0.2103, 0.1009, 0.2742], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,267][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0005, 0.0166, 0.0352, 0.0844, 0.1742, 0.1571, 0.0601, 0.0493, 0.0991,
        0.0695, 0.0568, 0.0223, 0.1253, 0.0497], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,268][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0113, 0.0090, 0.0177, 0.2979, 0.0147, 0.0202, 0.0201, 0.0233, 0.1067,
        0.1776, 0.0550, 0.0496, 0.0635, 0.1333], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,270][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0009, 0.0217, 0.0440, 0.1741, 0.0646, 0.0793, 0.0978, 0.1159, 0.0923,
        0.0697, 0.0722, 0.0705, 0.0431, 0.0538], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,271][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0014, 0.0011, 0.0018, 0.0087, 0.0056, 0.0409, 0.0496, 0.1082, 0.1376,
        0.0245, 0.0635, 0.1107, 0.2110, 0.2353], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,273][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0342, 0.3436, 0.0556, 0.0880, 0.0537, 0.0566, 0.0513, 0.0260, 0.0506,
        0.0475, 0.0593, 0.0510, 0.0444, 0.0382], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,274][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.3780, 0.0029, 0.0070, 0.1184, 0.0662, 0.0320, 0.0369, 0.1911, 0.0183,
        0.0192, 0.0157, 0.0047, 0.0958, 0.0138], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,335][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:25,337][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,338][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,339][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,340][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,341][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,342][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,344][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,345][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,346][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,347][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,348][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,349][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,350][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.0047, 0.9953], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,352][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.0023, 0.9977], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,353][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.1214, 0.8786], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,355][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.0350, 0.9650], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,356][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.4670, 0.5330], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,358][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.5916, 0.4084], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,359][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.2686, 0.7314], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,359][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.2385, 0.7615], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,360][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.0225, 0.9775], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,360][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.4879, 0.5121], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,360][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.0343, 0.9657], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,361][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.7037, 0.2963], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,361][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0008, 0.6407, 0.3585], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,361][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([4.2301e-05, 4.1102e-01, 5.8894e-01], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,362][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0114, 0.1438, 0.8448], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,362][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0129, 0.2241, 0.7630], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,363][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2765, 0.0888, 0.6347], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,364][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4606, 0.0545, 0.4849], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,365][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0230, 0.5116, 0.4654], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,367][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2310, 0.3181, 0.4509], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,368][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0190, 0.5141, 0.4669], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,369][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.2378, 0.1643, 0.5979], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,370][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0022, 0.9888, 0.0091], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,372][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1437, 0.1767, 0.6796], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,373][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Mary] are: tensor([0.0023, 0.3624, 0.2478, 0.3876], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,374][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Mary] are: tensor([9.4304e-05, 1.6840e-01, 4.2158e-01, 4.0992e-01], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,375][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Mary] are: tensor([0.0040, 0.0928, 0.7210, 0.1822], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,377][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Mary] are: tensor([0.0054, 0.1834, 0.4860, 0.3252], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,378][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Mary] are: tensor([0.2432, 0.0701, 0.5404, 0.1463], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,380][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Mary] are: tensor([0.1632, 0.1304, 0.4854, 0.2210], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,381][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Mary] are: tensor([0.0229, 0.4000, 0.2722, 0.3049], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,382][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Mary] are: tensor([0.1249, 0.1247, 0.1141, 0.6363], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,384][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Mary] are: tensor([0.0059, 0.2059, 0.2689, 0.5193], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,385][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Mary] are: tensor([0.3343, 0.2290, 0.2543, 0.1824], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,386][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Mary] are: tensor([0.0088, 0.5621, 0.0128, 0.4163], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,388][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Mary] are: tensor([0.0295, 0.1289, 0.4552, 0.3864], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,389][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.0035, 0.0378, 0.0814, 0.1581, 0.7192], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,390][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([1.5925e-05, 1.0712e-02, 6.9136e-02, 9.8155e-02, 8.2198e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,392][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0007, 0.0352, 0.4599, 0.1774, 0.3269], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,393][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.0038, 0.0243, 0.2120, 0.1522, 0.6076], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,394][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.2424, 0.0292, 0.1827, 0.0830, 0.4627], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,396][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.0514, 0.0060, 0.1010, 0.0971, 0.7445], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,397][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.0052, 0.0523, 0.1076, 0.0758, 0.7591], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,399][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.1198, 0.0404, 0.0692, 0.5194, 0.2512], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,400][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.0022, 0.0823, 0.2105, 0.3979, 0.3071], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,401][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.1033, 0.0110, 0.0888, 0.1505, 0.6464], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,403][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0015, 0.2253, 0.0185, 0.6350, 0.1197], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,404][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.1525, 0.0111, 0.0854, 0.1383, 0.6128], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,406][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0011, 0.1581, 0.1132, 0.2048, 0.2878, 0.2350], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,406][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([6.3334e-06, 9.3373e-03, 2.6041e-02, 9.0812e-02, 5.7072e-01, 3.0308e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,407][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0038, 0.0515, 0.3489, 0.2134, 0.1401, 0.2422], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,407][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0024, 0.0300, 0.1215, 0.1780, 0.3397, 0.3284], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,407][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.3113, 0.0178, 0.1453, 0.0697, 0.1548, 0.3011], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,408][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.2775, 0.0020, 0.0189, 0.0808, 0.1225, 0.4984], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,408][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0065, 0.0489, 0.0550, 0.1022, 0.5562, 0.2311], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,408][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0727, 0.0641, 0.0892, 0.6381, 0.0761, 0.0597], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,409][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0090, 0.0890, 0.1576, 0.3571, 0.1760, 0.2113], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,409][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.2081, 0.0031, 0.0155, 0.1511, 0.1051, 0.5171], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,410][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0013, 0.3674, 0.0046, 0.5691, 0.0506, 0.0070], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,412][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.8212, 0.0085, 0.0131, 0.0940, 0.0458, 0.0174], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,413][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0009, 0.0637, 0.0906, 0.2206, 0.2738, 0.1867, 0.1638],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,414][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([1.4056e-06, 6.8622e-03, 3.1350e-02, 8.7800e-02, 4.2165e-01, 2.7720e-01,
        1.7513e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,415][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0010, 0.0384, 0.2388, 0.2407, 0.1344, 0.1765, 0.1703],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,417][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0021, 0.0153, 0.0616, 0.1190, 0.2624, 0.1544, 0.3851],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,418][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.2463, 0.0062, 0.0694, 0.0380, 0.0642, 0.1786, 0.3974],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,419][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1506, 0.0052, 0.0198, 0.0376, 0.1505, 0.3983, 0.2379],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,421][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0023, 0.0366, 0.0506, 0.1041, 0.4945, 0.2203, 0.0916],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,422][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1335, 0.0387, 0.0603, 0.5042, 0.0843, 0.0584, 0.1205],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,424][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0010, 0.0593, 0.1348, 0.3852, 0.1182, 0.1325, 0.1692],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,425][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0833, 0.0088, 0.0172, 0.0568, 0.0997, 0.4500, 0.2842],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,426][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([4.0825e-04, 3.5097e-01, 3.1374e-03, 5.9732e-01, 4.2899e-02, 3.4190e-03,
        1.8542e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,428][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.4064, 0.0100, 0.0330, 0.2590, 0.1732, 0.0450, 0.0735],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,428][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([1.2885e-04, 4.3552e-02, 6.5919e-02, 1.6827e-01, 2.6680e-01, 1.5794e-01,
        1.5001e-01, 1.4738e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,429][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([4.5928e-07, 5.2876e-03, 1.7952e-02, 6.8100e-02, 3.5872e-01, 1.4326e-01,
        1.2546e-01, 2.8122e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,430][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([4.7929e-05, 1.8738e-02, 2.2989e-01, 1.4491e-01, 1.4220e-01, 2.1667e-01,
        1.4819e-01, 9.9357e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,431][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([2.4915e-04, 7.3415e-03, 3.8486e-02, 3.6616e-02, 1.2144e-01, 1.8276e-01,
        2.8691e-01, 3.2620e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,433][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.0222, 0.0069, 0.0662, 0.0222, 0.0543, 0.1713, 0.4153, 0.2417],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,434][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.0016, 0.0062, 0.0241, 0.0100, 0.1161, 0.3363, 0.2058, 0.2999],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,435][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([2.6584e-04, 3.0592e-02, 4.8533e-02, 8.1414e-02, 4.4518e-01, 1.7397e-01,
        9.4263e-02, 1.2578e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,437][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.0116, 0.0156, 0.0319, 0.7331, 0.0704, 0.0212, 0.0312, 0.0850],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,438][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.0008, 0.0434, 0.0897, 0.1698, 0.1051, 0.1258, 0.1610, 0.3043],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,439][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.0005, 0.0034, 0.0151, 0.0060, 0.0394, 0.3921, 0.2228, 0.3206],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,440][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([6.8313e-05, 2.5436e-01, 3.9986e-03, 6.7420e-01, 4.5510e-02, 4.8403e-03,
        3.0890e-03, 1.3934e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,442][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.0018, 0.0035, 0.0406, 0.0278, 0.0961, 0.1614, 0.1003, 0.5684],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,443][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0004, 0.0780, 0.0498, 0.1856, 0.2478, 0.1445, 0.1194, 0.1140, 0.0604],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,444][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([3.8200e-07, 4.3741e-03, 1.3241e-02, 7.8581e-02, 3.6657e-01, 1.9288e-01,
        8.4520e-02, 1.4768e-01, 1.1215e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,445][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0004, 0.0275, 0.1577, 0.2251, 0.1048, 0.1921, 0.1239, 0.0693, 0.0991],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,447][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0008, 0.0154, 0.0363, 0.0901, 0.1267, 0.1310, 0.2430, 0.1936, 0.1632],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,448][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0752, 0.0045, 0.0249, 0.0224, 0.0351, 0.1031, 0.1800, 0.1394, 0.4154],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,450][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0596, 0.0059, 0.0124, 0.0446, 0.0762, 0.1846, 0.1405, 0.2090, 0.2672],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,451][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0014, 0.0318, 0.0320, 0.1139, 0.3692, 0.1665, 0.0612, 0.0972, 0.1268],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,453][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0391, 0.0210, 0.0283, 0.5344, 0.0443, 0.0310, 0.0447, 0.0372, 0.2201],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,454][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0008, 0.0420, 0.0644, 0.2557, 0.0708, 0.1186, 0.1052, 0.1988, 0.1437],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,454][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0123, 0.0029, 0.0066, 0.0345, 0.0407, 0.1402, 0.1617, 0.2627, 0.3383],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,454][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([2.3683e-04, 3.1019e-01, 2.8470e-03, 6.3870e-01, 3.2920e-02, 4.8610e-03,
        1.6796e-03, 5.6111e-03, 2.9529e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,455][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.3525, 0.0094, 0.0165, 0.2091, 0.1023, 0.0351, 0.0391, 0.2161, 0.0198],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,455][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.0004, 0.0448, 0.0436, 0.1628, 0.2933, 0.0985, 0.1045, 0.1152, 0.0570,
        0.0799], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,456][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([4.0031e-07, 4.1924e-03, 1.2540e-02, 7.6100e-02, 4.1204e-01, 1.8644e-01,
        8.6427e-02, 1.0054e-01, 1.0711e-01, 1.4614e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,456][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([4.1302e-05, 3.4901e-02, 2.0650e-01, 1.4356e-01, 1.1252e-01, 1.8101e-01,
        1.0838e-01, 8.3391e-02, 8.1674e-02, 4.8039e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,456][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.0004, 0.0177, 0.0437, 0.0370, 0.1115, 0.1328, 0.2342, 0.2071, 0.1446,
        0.0710], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,457][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.0155, 0.0043, 0.0270, 0.0110, 0.0656, 0.1050, 0.2229, 0.1424, 0.3740,
        0.0322], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,458][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.0027, 0.0431, 0.0192, 0.0270, 0.0462, 0.0256, 0.1226, 0.4456, 0.1953,
        0.0728], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,459][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([3.0924e-04, 3.2426e-02, 4.1947e-02, 8.5054e-02, 3.3805e-01, 1.6921e-01,
        7.1901e-02, 7.8471e-02, 1.1056e-01, 7.2085e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,460][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0213, 0.0188, 0.0301, 0.2787, 0.0488, 0.0278, 0.0332, 0.0582, 0.1851,
        0.2981], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,462][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.0006, 0.0556, 0.0624, 0.1620, 0.1137, 0.1061, 0.1088, 0.1628, 0.1252,
        0.1027], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,463][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([5.9769e-04, 1.7289e-02, 8.4735e-03, 1.2806e-02, 1.2937e-02, 1.8767e-02,
        1.4577e-01, 6.6766e-01, 9.9768e-02, 1.5931e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,463][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([3.7726e-04, 3.8922e-01, 3.6252e-03, 5.0058e-01, 5.7148e-02, 6.0727e-03,
        2.1251e-03, 7.8731e-03, 3.8397e-03, 2.9138e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,465][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.0008, 0.0106, 0.0472, 0.0764, 0.1633, 0.2330, 0.1461, 0.2529, 0.0590,
        0.0106], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,466][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0003, 0.0296, 0.0270, 0.0677, 0.1370, 0.1471, 0.1039, 0.0962, 0.0944,
        0.1429, 0.1540], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,467][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([6.1936e-07, 6.5757e-03, 1.5947e-02, 6.8565e-02, 2.5382e-01, 1.7110e-01,
        7.7224e-02, 1.7869e-01, 1.3871e-01, 4.9270e-02, 4.0100e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,468][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([5.5224e-05, 1.6663e-02, 1.0853e-01, 1.0216e-01, 9.6746e-02, 1.7207e-01,
        1.1222e-01, 8.5068e-02, 9.6194e-02, 7.0098e-02, 1.4020e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,469][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([9.6796e-05, 9.3190e-03, 2.1317e-02, 2.4318e-02, 6.3797e-02, 1.4420e-01,
        1.9032e-01, 1.2705e-01, 1.7317e-01, 8.4238e-02, 1.6219e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,470][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0459, 0.0019, 0.0196, 0.0053, 0.0165, 0.1187, 0.1467, 0.0961, 0.4498,
        0.0403, 0.0592], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,472][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0050, 0.0027, 0.0071, 0.0061, 0.0335, 0.1160, 0.1069, 0.1754, 0.2526,
        0.0496, 0.2450], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,473][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([2.5564e-04, 4.2471e-02, 2.4928e-02, 9.8439e-02, 2.8129e-01, 1.2491e-01,
        4.4340e-02, 5.5893e-02, 1.1948e-01, 1.3729e-01, 7.0710e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,474][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0109, 0.0136, 0.0192, 0.3039, 0.0366, 0.0326, 0.0329, 0.0322, 0.1549,
        0.2617, 0.1015], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,476][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0003, 0.0401, 0.0512, 0.1591, 0.0876, 0.0723, 0.0723, 0.2143, 0.0902,
        0.0987, 0.1140], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,477][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0007, 0.0025, 0.0037, 0.0074, 0.0171, 0.1193, 0.0939, 0.3135, 0.2467,
        0.0268, 0.1685], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,478][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([8.5123e-05, 2.9017e-01, 2.3595e-03, 5.9929e-01, 2.5150e-02, 4.3724e-03,
        1.4903e-03, 4.6380e-03, 2.7176e-03, 3.9992e-02, 2.9738e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,479][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0434, 0.0104, 0.0316, 0.0932, 0.1522, 0.1119, 0.0929, 0.3249, 0.0693,
        0.0205, 0.0497], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,481][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0003, 0.0337, 0.0507, 0.1431, 0.1461, 0.1579, 0.0978, 0.0883, 0.0537,
        0.0878, 0.0957, 0.0450], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,482][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([2.6341e-07, 3.5124e-03, 2.0335e-02, 6.8693e-02, 2.4617e-01, 2.2267e-01,
        1.0296e-01, 1.2781e-01, 1.3367e-01, 2.3121e-02, 3.2866e-02, 1.8179e-02],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,483][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0002, 0.0178, 0.1087, 0.1236, 0.0797, 0.1316, 0.1075, 0.0668, 0.0782,
        0.0922, 0.1214, 0.0723], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,485][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0006, 0.0081, 0.0339, 0.0333, 0.0910, 0.1178, 0.1812, 0.1332, 0.1182,
        0.0785, 0.1234, 0.0808], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,486][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0672, 0.0012, 0.0181, 0.0124, 0.0218, 0.0843, 0.1299, 0.1022, 0.3131,
        0.0360, 0.0532, 0.1607], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,487][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0354, 0.0032, 0.0048, 0.0240, 0.0187, 0.0868, 0.0670, 0.0972, 0.1534,
        0.0898, 0.1311, 0.2887], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,489][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0012, 0.0223, 0.0441, 0.1117, 0.2321, 0.1651, 0.0671, 0.0736, 0.1051,
        0.0832, 0.0696, 0.0247], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,490][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0222, 0.0099, 0.0193, 0.3570, 0.0271, 0.0221, 0.0332, 0.0263, 0.1368,
        0.2100, 0.0584, 0.0778], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,492][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0011, 0.0252, 0.0430, 0.2398, 0.0791, 0.0787, 0.0931, 0.1172, 0.0889,
        0.0847, 0.0773, 0.0719], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,493][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0080, 0.0019, 0.0027, 0.0209, 0.0117, 0.0638, 0.0570, 0.1409, 0.2487,
        0.0843, 0.1537, 0.2064], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,494][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([1.6187e-04, 2.4309e-01, 3.3737e-03, 5.9273e-01, 3.9029e-02, 5.1567e-03,
        2.2431e-03, 8.3856e-03, 3.4500e-03, 5.0298e-02, 5.0716e-02, 1.3694e-03],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,496][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.5127, 0.0022, 0.0066, 0.0980, 0.0684, 0.0209, 0.0267, 0.2119, 0.0167,
        0.0142, 0.0167, 0.0050], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,497][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.0010, 0.0131, 0.0372, 0.0840, 0.1288, 0.1317, 0.1359, 0.0765, 0.0659,
        0.0403, 0.1054, 0.0683, 0.1118], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,498][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([1.2477e-06, 1.7371e-03, 1.4558e-02, 4.0589e-02, 1.9985e-01, 1.4259e-01,
        1.1412e-01, 1.9907e-01, 1.5058e-01, 1.5892e-02, 4.7427e-02, 2.4001e-02,
        4.9582e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,499][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([9.2806e-05, 1.2371e-02, 1.1964e-01, 1.1120e-01, 7.4142e-02, 1.2954e-01,
        1.1489e-01, 6.0500e-02, 7.1986e-02, 3.3173e-02, 1.0669e-01, 8.8976e-02,
        7.6792e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,501][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0004, 0.0045, 0.0265, 0.0287, 0.0861, 0.1273, 0.1677, 0.1352, 0.1039,
        0.0382, 0.1379, 0.1011, 0.0423], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,501][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.0121, 0.0006, 0.0194, 0.0082, 0.0308, 0.1193, 0.1430, 0.0995, 0.2809,
        0.0157, 0.0631, 0.1416, 0.0657], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,502][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.0040, 0.0030, 0.0027, 0.0088, 0.0131, 0.0422, 0.0464, 0.0958, 0.1023,
        0.0280, 0.1540, 0.3497, 0.1501], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,502][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0007, 0.0134, 0.0269, 0.0755, 0.2055, 0.1214, 0.0852, 0.0611, 0.0978,
        0.0590, 0.0587, 0.0425, 0.1524], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,503][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0417, 0.0072, 0.0169, 0.1701, 0.0396, 0.0207, 0.0395, 0.0246, 0.1295,
        0.0775, 0.0818, 0.0951, 0.2558], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,503][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.0005, 0.0224, 0.0697, 0.1818, 0.0622, 0.0657, 0.1409, 0.1106, 0.0889,
        0.0231, 0.0812, 0.0697, 0.0834], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,503][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0005, 0.0009, 0.0014, 0.0073, 0.0045, 0.0378, 0.0688, 0.1293, 0.1582,
        0.0109, 0.0861, 0.2333, 0.2608], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,504][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([2.5504e-04, 1.5849e-01, 6.8873e-03, 5.0064e-01, 5.1048e-02, 1.1789e-02,
        6.0439e-03, 1.4526e-02, 1.1556e-02, 3.0121e-02, 1.2151e-01, 5.9740e-03,
        8.1156e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,505][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0280, 0.0046, 0.0287, 0.0620, 0.0729, 0.0712, 0.0815, 0.3209, 0.0439,
        0.0193, 0.0474, 0.0280, 0.1918], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,507][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0002, 0.0357, 0.0450, 0.1212, 0.1166, 0.1363, 0.0768, 0.0731, 0.0418,
        0.0818, 0.0856, 0.0396, 0.0827, 0.0635], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,508][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.3911e-07, 6.1676e-03, 2.1260e-02, 1.0380e-01, 2.6322e-01, 2.0606e-01,
        8.6246e-02, 9.4807e-02, 9.7942e-02, 1.8707e-02, 2.2722e-02, 1.1072e-02,
        4.8740e-02, 1.9256e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,509][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0001, 0.0121, 0.0928, 0.1012, 0.0507, 0.1130, 0.0842, 0.0594, 0.0601,
        0.0644, 0.0972, 0.0545, 0.0969, 0.1135], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,510][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0004, 0.0084, 0.0245, 0.0273, 0.0751, 0.1094, 0.1474, 0.0927, 0.0987,
        0.0972, 0.1039, 0.0637, 0.0355, 0.1156], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,512][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0344, 0.0011, 0.0146, 0.0100, 0.0173, 0.0690, 0.1272, 0.0918, 0.2496,
        0.0255, 0.0411, 0.1356, 0.0364, 0.1464], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,513][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0192, 0.0026, 0.0028, 0.0138, 0.0122, 0.0394, 0.0424, 0.0627, 0.0948,
        0.0433, 0.0816, 0.2103, 0.1009, 0.2742], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,514][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0005, 0.0166, 0.0352, 0.0844, 0.1742, 0.1571, 0.0601, 0.0493, 0.0991,
        0.0695, 0.0568, 0.0223, 0.1253, 0.0497], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,516][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0113, 0.0090, 0.0177, 0.2979, 0.0147, 0.0202, 0.0201, 0.0233, 0.1067,
        0.1776, 0.0550, 0.0496, 0.0635, 0.1333], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,517][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0009, 0.0217, 0.0440, 0.1741, 0.0646, 0.0793, 0.0978, 0.1159, 0.0923,
        0.0697, 0.0722, 0.0705, 0.0431, 0.0538], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,519][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0014, 0.0011, 0.0018, 0.0087, 0.0056, 0.0409, 0.0496, 0.1082, 0.1376,
        0.0245, 0.0635, 0.1107, 0.2110, 0.2353], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,520][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.3841e-04, 2.6069e-01, 3.3837e-03, 5.1323e-01, 3.8260e-02, 6.4879e-03,
        2.6768e-03, 8.2038e-03, 4.0162e-03, 5.5187e-02, 5.3175e-02, 1.6696e-03,
        5.1447e-02, 1.4362e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,521][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.3780, 0.0029, 0.0070, 0.1184, 0.0662, 0.0320, 0.0369, 0.1911, 0.0183,
        0.0192, 0.0157, 0.0047, 0.0958, 0.0138], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,523][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:23:25,524][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[1399],
        [ 828],
        [  64],
        [   2],
        [ 113],
        [  40],
        [ 112],
        [  28],
        [  29],
        [ 109],
        [   7],
        [  38],
        [  20],
        [   3]], device='cuda:0')
[2024-07-24 10:23:25,526][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[1324],
        [ 565],
        [  45],
        [   1],
        [  66],
        [  27],
        [  79],
        [  30],
        [  22],
        [  86],
        [   6],
        [  23],
        [  18],
        [   3]], device='cuda:0')
[2024-07-24 10:23:25,527][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[  838],
        [27345],
        [18075],
        [43839],
        [38755],
        [15921],
        [18552],
        [11334],
        [13108],
        [15197],
        [10710],
        [11621],
        [10462],
        [ 8759]], device='cuda:0')
[2024-07-24 10:23:25,529][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[12263],
        [28719],
        [27106],
        [41165],
        [21367],
        [22433],
        [23362],
        [18894],
        [20675],
        [20850],
        [20336],
        [21373],
        [19296],
        [23899]], device='cuda:0')
[2024-07-24 10:23:25,530][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 7203],
        [32987],
        [ 8757],
        [17233],
        [26331],
        [20843],
        [20088],
        [10493],
        [14634],
        [ 9042],
        [ 5557],
        [ 5951],
        [ 5291],
        [ 4566]], device='cuda:0')
[2024-07-24 10:23:25,532][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[19529],
        [13839],
        [ 5851],
        [18286],
        [ 9553],
        [ 9929],
        [ 9661],
        [ 5722],
        [ 7252],
        [ 5742],
        [ 4582],
        [ 4899],
        [ 4849],
        [ 4441]], device='cuda:0')
[2024-07-24 10:23:25,533][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[22527],
        [24319],
        [25545],
        [27519],
        [24008],
        [26164],
        [28100],
        [28248],
        [28517],
        [27758],
        [28222],
        [29850],
        [30626],
        [30392]], device='cuda:0')
[2024-07-24 10:23:25,534][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 4128],
        [13284],
        [ 7813],
        [11373],
        [14011],
        [ 9159],
        [ 9791],
        [ 8968],
        [ 9281],
        [ 9042],
        [ 9057],
        [ 8219],
        [ 8219],
        [ 7032]], device='cuda:0')
[2024-07-24 10:23:25,536][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[23147],
        [41189],
        [41945],
        [46641],
        [45617],
        [46760],
        [46981],
        [46206],
        [46753],
        [46607],
        [46611],
        [46738],
        [47327],
        [47430]], device='cuda:0')
[2024-07-24 10:23:25,537][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[16560],
        [ 1152],
        [ 2145],
        [    1],
        [    2],
        [    1],
        [    2],
        [    1],
        [    2],
        [  149],
        [  135],
        [   55],
        [ 2521],
        [  184]], device='cuda:0')
[2024-07-24 10:23:25,539][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 6162],
        [16667],
        [14606],
        [ 8820],
        [ 9184],
        [10047],
        [ 9737],
        [15187],
        [14370],
        [15437],
        [16572],
        [14783],
        [16070],
        [16651]], device='cuda:0')
[2024-07-24 10:23:25,540][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[29544],
        [46490],
        [49282],
        [49647],
        [49957],
        [49898],
        [49851],
        [49720],
        [49842],
        [49612],
        [49888],
        [50028],
        [50061],
        [50057]], device='cuda:0')
[2024-07-24 10:23:25,541][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 2997],
        [23907],
        [22464],
        [34573],
        [32736],
        [30072],
        [28000],
        [27578],
        [26800],
        [24909],
        [24491],
        [22747],
        [20714],
        [21252]], device='cuda:0')
[2024-07-24 10:23:25,543][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[27703],
        [41912],
        [45146],
        [47034],
        [47032],
        [47697],
        [48588],
        [46376],
        [48662],
        [46412],
        [46677],
        [48890],
        [45653],
        [48067]], device='cuda:0')
[2024-07-24 10:23:25,544][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[17219],
        [20228],
        [12687],
        [23463],
        [11329],
        [24521],
        [15487],
        [ 3514],
        [ 7689],
        [12415],
        [ 5578],
        [22672],
        [ 7018],
        [17691]], device='cuda:0')
[2024-07-24 10:23:25,546][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[22261],
        [24799],
        [26105],
        [28556],
        [14631],
        [23916],
        [22982],
        [21946],
        [23095],
        [21527],
        [24465],
        [24819],
        [22404],
        [23482]], device='cuda:0')
[2024-07-24 10:23:25,547][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[17878],
        [ 1844],
        [ 4530],
        [ 8660],
        [26142],
        [25560],
        [23959],
        [24881],
        [25015],
        [25099],
        [24842],
        [24437],
        [25799],
        [25388]], device='cuda:0')
[2024-07-24 10:23:25,548][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[19145],
        [ 6403],
        [12503],
        [10855],
        [ 6271],
        [11041],
        [11917],
        [11849],
        [12688],
        [11888],
        [13571],
        [12885],
        [13698],
        [13680]], device='cuda:0')
[2024-07-24 10:23:25,550][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[7148],
        [3788],
        [4031],
        [3956],
        [3283],
        [4245],
        [4981],
        [4902],
        [5663],
        [5690],
        [7462],
        [7164],
        [7579],
        [7759]], device='cuda:0')
[2024-07-24 10:23:25,551][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[2531],
        [7344],
        [5437],
        [4558],
        [4587],
        [3655],
        [4559],
        [5070],
        [5593],
        [5823],
        [5871],
        [5750],
        [5573],
        [5896]], device='cuda:0')
[2024-07-24 10:23:25,552][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 6436],
        [ 3010],
        [ 5710],
        [ 3664],
        [ 5703],
        [ 3617],
        [ 4038],
        [ 6013],
        [ 6969],
        [ 8969],
        [ 8737],
        [ 9676],
        [11789],
        [11681]], device='cuda:0')
[2024-07-24 10:23:25,553][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[11425],
        [ 8848],
        [ 8042],
        [ 9184],
        [ 8360],
        [ 8382],
        [ 8497],
        [ 7889],
        [ 7411],
        [ 7657],
        [ 7025],
        [ 6736],
        [ 6976],
        [ 6786]], device='cuda:0')
[2024-07-24 10:23:25,554][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 3908],
        [10579],
        [13909],
        [ 9694],
        [13778],
        [11063],
        [11670],
        [11646],
        [12943],
        [15504],
        [15636],
        [14965],
        [21460],
        [17022]], device='cuda:0')
[2024-07-24 10:23:25,555][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[3493],
        [8324],
        [6925],
        [6312],
        [7154],
        [6785],
        [6297],
        [8113],
        [8490],
        [9456],
        [9243],
        [9224],
        [8592],
        [9467]], device='cuda:0')
[2024-07-24 10:23:25,557][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[27936],
        [ 2614],
        [  896],
        [ 1411],
        [ 2790],
        [ 2613],
        [ 2149],
        [ 2929],
        [ 2196],
        [ 3713],
        [ 2259],
        [ 1829],
        [ 2198],
        [ 2332]], device='cuda:0')
[2024-07-24 10:23:25,558][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 5192],
        [ 9194],
        [ 9203],
        [ 8600],
        [13133],
        [11005],
        [11335],
        [13058],
        [12128],
        [10620],
        [12075],
        [12600],
        [13100],
        [12060]], device='cuda:0')
[2024-07-24 10:23:25,559][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 4478],
        [ 1602],
        [10198],
        [11807],
        [ 8421],
        [  887],
        [ 7607],
        [ 8035],
        [ 7273],
        [ 8070],
        [ 7809],
        [ 4333],
        [ 7523],
        [ 6000]], device='cuda:0')
[2024-07-24 10:23:25,561][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[20482],
        [40639],
        [30974],
        [30100],
        [32489],
        [37118],
        [30995],
        [28560],
        [27883],
        [24657],
        [25251],
        [28550],
        [23909],
        [25062]], device='cuda:0')
[2024-07-24 10:23:25,562][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 8650],
        [17389],
        [17918],
        [15972],
        [23373],
        [12747],
        [23681],
        [32990],
        [21748],
        [25819],
        [25185],
        [23145],
        [23781],
        [16871]], device='cuda:0')
[2024-07-24 10:23:25,563][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[5216],
        [5216],
        [5216],
        [5216],
        [5216],
        [5216],
        [5216],
        [5216],
        [5216],
        [5216],
        [5216],
        [5216],
        [5216],
        [5216]], device='cuda:0')
[2024-07-24 10:23:25,627][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:25,628][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,629][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,631][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,632][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,633][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,634][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,635][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,636][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,637][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,639][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,640][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,641][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,642][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.1802, 0.8198], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,644][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.9862, 0.0138], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,645][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.0201, 0.9799], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,645][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.0023, 0.9977], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,646][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.0027, 0.9973], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,646][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.1175, 0.8825], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,646][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.0232, 0.9768], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,647][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0481, 0.9519], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,647][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([1.0000e+00, 2.5392e-16], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,647][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.0635, 0.9365], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,648][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.2638, 0.7362], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,649][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.0735, 0.9265], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,650][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0302, 0.3389, 0.6309], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,651][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.9506, 0.0459, 0.0035], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,653][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0065, 0.4809, 0.5127], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,653][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([5.6079e-05, 1.4211e-01, 8.5784e-01], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,654][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0016, 0.5144, 0.4840], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,655][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0015, 0.8838, 0.1147], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,656][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0057, 0.4564, 0.5378], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,656][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0483, 0.4728, 0.4788], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,656][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([1.0000e+00, 5.6426e-20, 9.2780e-23], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,657][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0175, 0.4118, 0.5707], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,657][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1876, 0.3640, 0.4484], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,657][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0330, 0.4990, 0.4680], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,658][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Mary] are: tensor([0.0083, 0.2144, 0.3204, 0.4568], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,658][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Mary] are: tensor([9.8169e-01, 4.0487e-03, 3.2517e-04, 1.3940e-02], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,659][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Mary] are: tensor([0.0133, 0.4239, 0.4109, 0.1520], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,660][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Mary] are: tensor([4.1870e-06, 9.0749e-02, 7.6852e-01, 1.4073e-01], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,662][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Mary] are: tensor([0.0017, 0.3708, 0.3258, 0.3017], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,663][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Mary] are: tensor([0.0162, 0.4911, 0.3235, 0.1692], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,664][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Mary] are: tensor([0.0107, 0.3961, 0.3792, 0.2140], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,666][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Mary] are: tensor([0.0447, 0.3959, 0.3101, 0.2492], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,667][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Mary] are: tensor([1.0000e+00, 2.6653e-17, 4.6559e-20, 8.3143e-18], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,668][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Mary] are: tensor([0.0332, 0.3293, 0.3826, 0.2549], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,670][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Mary] are: tensor([0.2827, 0.2715, 0.2496, 0.1962], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,671][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Mary] are: tensor([0.0188, 0.3865, 0.3520, 0.2427], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,672][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0155, 0.1200, 0.1461, 0.2884, 0.4300], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,674][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.4935, 0.0220, 0.0138, 0.2022, 0.2684], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,675][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0045, 0.2894, 0.3549, 0.1272, 0.2239], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,676][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ went] are: tensor([8.5878e-05, 5.8818e-02, 5.8399e-01, 2.3321e-01, 1.2390e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,677][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.0006, 0.2950, 0.2660, 0.2520, 0.1865], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,679][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0102, 0.2613, 0.0732, 0.0865, 0.5689], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,680][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0031, 0.2883, 0.3076, 0.1724, 0.2287], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,682][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0149, 0.2588, 0.2352, 0.1585, 0.3326], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,683][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ went] are: tensor([1.0000e+00, 1.2050e-14, 2.9612e-16, 8.9487e-15, 2.7456e-15],
       device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,684][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.0091, 0.1596, 0.2509, 0.1432, 0.4371], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,685][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0793, 0.1856, 0.2050, 0.1520, 0.3781], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,687][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0178, 0.2982, 0.2878, 0.1768, 0.2195], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,688][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0201, 0.0844, 0.1353, 0.1731, 0.2988, 0.2883], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,690][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.8663, 0.0233, 0.0027, 0.0809, 0.0202, 0.0066], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,691][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0029, 0.2190, 0.2433, 0.0790, 0.1486, 0.3072], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,692][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([3.2659e-06, 9.2084e-03, 5.1484e-02, 1.7599e-01, 5.3847e-02, 7.0946e-01],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,693][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0004, 0.2113, 0.1961, 0.1771, 0.1438, 0.2711], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,695][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0007, 0.3201, 0.0816, 0.0592, 0.4907, 0.0478], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,695][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0037, 0.2504, 0.2571, 0.1458, 0.1826, 0.1605], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,696][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0202, 0.2250, 0.2226, 0.1392, 0.2396, 0.1534], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,696][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([1.0000e+00, 4.5922e-21, 5.8657e-24, 8.1462e-22, 1.1983e-22, 1.2019e-23],
       device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,696][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0069, 0.1706, 0.1753, 0.1312, 0.3743, 0.1417], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,697][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1639, 0.1356, 0.1382, 0.0932, 0.2054, 0.2637], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,697][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0251, 0.2059, 0.1965, 0.1539, 0.1758, 0.2428], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,698][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0059, 0.0526, 0.0936, 0.1491, 0.2063, 0.1651, 0.3274],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,698][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.7865, 0.0154, 0.0026, 0.1494, 0.0292, 0.0067, 0.0103],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,699][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0017, 0.1919, 0.1842, 0.0690, 0.1094, 0.2236, 0.2203],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,700][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ the] are: tensor([4.7220e-06, 1.5056e-02, 1.4524e-01, 9.4594e-02, 2.2546e-02, 5.9316e-01,
        1.2940e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,701][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0003, 0.1995, 0.1579, 0.1465, 0.1106, 0.2110, 0.1742],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,702][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0141, 0.1535, 0.1578, 0.0900, 0.2768, 0.0797, 0.2282],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,704][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0021, 0.2358, 0.2042, 0.1357, 0.1356, 0.1231, 0.1635],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,705][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0203, 0.1857, 0.1771, 0.1236, 0.1903, 0.1224, 0.1805],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,706][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ the] are: tensor([1.0000e+00, 2.5863e-20, 2.7785e-23, 4.0265e-21, 5.0647e-22, 6.2488e-23,
        2.2383e-22], device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,707][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0080, 0.1811, 0.1493, 0.1151, 0.3110, 0.1139, 0.1216],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,709][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1397, 0.1114, 0.1118, 0.0619, 0.1608, 0.2238, 0.1906],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,710][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0085, 0.1725, 0.1521, 0.1009, 0.1242, 0.2465, 0.1953],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,712][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.0074, 0.0314, 0.0664, 0.0583, 0.1790, 0.1564, 0.3573, 0.1439],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,713][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([0.0972, 0.0143, 0.0069, 0.1776, 0.1340, 0.0292, 0.0501, 0.4905],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,715][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.0014, 0.1402, 0.1560, 0.0522, 0.1036, 0.2258, 0.2208, 0.1000],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,715][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([1.3489e-07, 5.1999e-04, 2.9549e-03, 5.6502e-04, 8.7681e-04, 8.4546e-03,
        4.0729e-03, 9.8256e-01], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,717][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.0004, 0.1838, 0.1488, 0.1418, 0.1139, 0.2014, 0.1597, 0.0502],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,718][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.0080, 0.1803, 0.1024, 0.0768, 0.1956, 0.0588, 0.3583, 0.0198],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,720][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.0012, 0.1629, 0.1619, 0.0993, 0.1438, 0.1355, 0.1845, 0.1109],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,721][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.0089, 0.1027, 0.1392, 0.0710, 0.1658, 0.1337, 0.1808, 0.1979],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,722][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([1.0000e+00, 1.6856e-21, 1.1182e-24, 2.5063e-22, 2.2374e-22, 1.2566e-23,
        4.7294e-23, 1.6848e-20], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,724][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.0034, 0.1158, 0.1430, 0.0784, 0.2211, 0.1633, 0.1693, 0.1056],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,725][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.0086, 0.0917, 0.1091, 0.0810, 0.1648, 0.2297, 0.1878, 0.1273],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,727][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.0047, 0.1663, 0.1291, 0.0792, 0.0993, 0.2875, 0.1539, 0.0800],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,728][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0116, 0.0395, 0.0906, 0.1043, 0.1539, 0.1286, 0.2535, 0.1060, 0.1119],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,729][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.6806, 0.0198, 0.0021, 0.1429, 0.0268, 0.0082, 0.0103, 0.0831, 0.0262],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,731][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0019, 0.1493, 0.1277, 0.0574, 0.0906, 0.1918, 0.1551, 0.0679, 0.1584],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,732][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([2.1015e-09, 3.1391e-05, 1.3388e-04, 1.7335e-04, 9.2464e-05, 4.4296e-04,
        2.7761e-04, 9.9859e-01, 2.5776e-04], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,733][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0002, 0.1548, 0.1182, 0.1133, 0.0971, 0.1836, 0.1386, 0.0412, 0.1528],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,735][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0029, 0.2107, 0.0550, 0.0574, 0.3199, 0.0304, 0.2558, 0.0155, 0.0524],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,736][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0026, 0.1712, 0.1466, 0.1037, 0.1238, 0.1202, 0.1433, 0.0947, 0.0939],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,738][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0139, 0.1041, 0.1187, 0.0811, 0.1340, 0.0903, 0.1203, 0.1615, 0.1761],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,739][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([1.0000e+00, 1.4592e-24, 2.9774e-28, 5.0044e-26, 1.7952e-26, 1.6411e-28,
        9.8773e-28, 1.6015e-25, 2.1694e-28], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,740][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0071, 0.1158, 0.0992, 0.1011, 0.2561, 0.1055, 0.1103, 0.1186, 0.0862],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,742][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0881, 0.0868, 0.0785, 0.0579, 0.1313, 0.1809, 0.1337, 0.0937, 0.1491],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,742][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0065, 0.1291, 0.1112, 0.0780, 0.0974, 0.2058, 0.1391, 0.0879, 0.1449],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,743][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.0060, 0.0360, 0.0770, 0.0736, 0.1728, 0.1139, 0.2827, 0.1113, 0.0968,
        0.0299], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,743][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.6378, 0.0054, 0.0014, 0.1211, 0.0445, 0.0069, 0.0116, 0.1073, 0.0215,
        0.0426], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,744][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.0030, 0.1012, 0.1210, 0.0481, 0.0907, 0.1797, 0.1574, 0.0767, 0.1688,
        0.0534], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,744][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([1.5579e-09, 8.6280e-05, 2.8641e-04, 1.8566e-04, 8.4294e-05, 1.3864e-04,
        4.6650e-04, 9.9839e-01, 1.3630e-04, 2.2110e-04], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,744][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.0004, 0.1523, 0.1170, 0.1097, 0.0940, 0.1806, 0.1299, 0.0390, 0.1394,
        0.0376], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,745][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.0096, 0.1094, 0.0867, 0.0770, 0.1585, 0.0423, 0.3409, 0.0279, 0.1027,
        0.0449], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,746][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.0023, 0.1412, 0.1467, 0.0872, 0.1229, 0.1430, 0.1538, 0.0760, 0.0988,
        0.0282], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,747][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0075, 0.0818, 0.1079, 0.0646, 0.1223, 0.1100, 0.1266, 0.1154, 0.1869,
        0.0770], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,748][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([1.0000e+00, 1.4473e-20, 2.2741e-24, 6.4126e-22, 4.4584e-22, 8.8260e-24,
        6.2049e-23, 2.4474e-20, 3.8865e-24, 2.0315e-20], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,750][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.0065, 0.0899, 0.0973, 0.0803, 0.1815, 0.1440, 0.1504, 0.0849, 0.1161,
        0.0492], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,751][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0185, 0.0838, 0.0960, 0.0693, 0.1262, 0.1772, 0.1319, 0.0842, 0.1560,
        0.0569], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,752][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.0055, 0.1279, 0.1026, 0.0700, 0.0855, 0.2206, 0.1184, 0.0673, 0.1281,
        0.0742], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,754][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0053, 0.0332, 0.0688, 0.0874, 0.1418, 0.1201, 0.2575, 0.1081, 0.0870,
        0.0240, 0.0668], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,755][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.1207, 0.0159, 0.0031, 0.2251, 0.0838, 0.0200, 0.0308, 0.2223, 0.0394,
        0.0682, 0.1706], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,757][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0015, 0.1204, 0.1114, 0.0467, 0.0724, 0.1673, 0.1418, 0.0690, 0.1551,
        0.0532, 0.0611], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,758][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([3.5023e-07, 3.0859e-04, 1.6845e-03, 7.7028e-04, 3.8935e-04, 3.6768e-03,
        1.6720e-03, 9.8441e-01, 1.0289e-03, 8.7998e-04, 5.1820e-03],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,759][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0003, 0.1436, 0.1084, 0.1023, 0.0831, 0.1746, 0.1265, 0.0358, 0.1360,
        0.0345, 0.0550], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,760][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0103, 0.1738, 0.0371, 0.0751, 0.1566, 0.0224, 0.1920, 0.0219, 0.0345,
        0.0546, 0.2218], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,762][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0017, 0.1382, 0.1299, 0.0883, 0.1034, 0.1231, 0.1363, 0.0795, 0.0952,
        0.0298, 0.0747], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,763][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0070, 0.0810, 0.0944, 0.0593, 0.1071, 0.0919, 0.1114, 0.1105, 0.1539,
        0.0665, 0.1168], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,764][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([1.0000e+00, 9.1221e-20, 1.7615e-22, 9.7774e-21, 3.1487e-21, 4.4576e-22,
        8.5667e-22, 3.9134e-19, 1.5186e-22, 1.0787e-19, 3.7147e-21],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,766][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0046, 0.0921, 0.0959, 0.0754, 0.1645, 0.1356, 0.1377, 0.0797, 0.1071,
        0.0433, 0.0643], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,767][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0148, 0.0765, 0.0811, 0.0644, 0.1144, 0.1724, 0.1382, 0.0719, 0.1530,
        0.0476, 0.0658], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,769][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0058, 0.1112, 0.0937, 0.0636, 0.0760, 0.1961, 0.1092, 0.0634, 0.1207,
        0.0720, 0.0882], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:25,770][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0049, 0.0344, 0.0662, 0.0917, 0.1281, 0.0950, 0.2360, 0.1219, 0.0742,
        0.0253, 0.0424, 0.0799], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,772][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.6056, 0.0083, 0.0022, 0.0961, 0.0296, 0.0101, 0.0132, 0.0784, 0.0222,
        0.0464, 0.0719, 0.0161], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,773][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0012, 0.1035, 0.1102, 0.0456, 0.0681, 0.1715, 0.1467, 0.0577, 0.1380,
        0.0392, 0.0487, 0.0696], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,774][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([4.6921e-09, 1.2771e-05, 2.9996e-04, 1.2472e-04, 1.8750e-05, 3.6698e-04,
        1.3553e-04, 9.9563e-01, 2.4679e-04, 7.1146e-04, 1.8837e-03, 5.7034e-04],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,775][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0002, 0.1373, 0.1105, 0.1061, 0.0790, 0.1642, 0.1201, 0.0324, 0.1220,
        0.0280, 0.0474, 0.0528], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,777][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0132, 0.1057, 0.0463, 0.0630, 0.1882, 0.0320, 0.1564, 0.0401, 0.0515,
        0.0428, 0.1912, 0.0697], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,778][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0017, 0.1369, 0.1350, 0.1007, 0.0987, 0.1141, 0.1327, 0.0702, 0.0820,
        0.0235, 0.0625, 0.0420], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,780][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0090, 0.0714, 0.0953, 0.0626, 0.0950, 0.0821, 0.1127, 0.0925, 0.1366,
        0.0540, 0.0994, 0.0895], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,781][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([1.0000e+00, 1.5350e-22, 3.0223e-26, 7.6515e-24, 1.6388e-24, 5.5174e-26,
        2.6505e-25, 9.5244e-23, 3.2100e-26, 7.4273e-23, 1.5853e-24, 4.0870e-25],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,782][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0071, 0.0920, 0.0893, 0.0834, 0.1795, 0.1047, 0.1149, 0.0911, 0.0830,
        0.0464, 0.0610, 0.0477], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,784][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0212, 0.0779, 0.0812, 0.0566, 0.1051, 0.1658, 0.1278, 0.0655, 0.1311,
        0.0379, 0.0499, 0.0800], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,785][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0053, 0.0964, 0.0853, 0.0588, 0.0696, 0.1705, 0.1036, 0.0577, 0.1126,
        0.0691, 0.0787, 0.0925], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:25,787][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0084, 0.0206, 0.0412, 0.0682, 0.1281, 0.0922, 0.2353, 0.1055, 0.0706,
        0.0251, 0.0387, 0.0744, 0.0917], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,788][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.2806, 0.0045, 0.0042, 0.0967, 0.0420, 0.0179, 0.0257, 0.1962, 0.0358,
        0.0270, 0.1724, 0.0440, 0.0531], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,789][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0015, 0.0797, 0.1038, 0.0385, 0.0671, 0.1624, 0.1408, 0.0552, 0.1416,
        0.0367, 0.0574, 0.0822, 0.0331], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,789][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([6.3808e-08, 9.6851e-05, 2.5307e-03, 3.4131e-04, 1.3425e-04, 4.4757e-03,
        9.3837e-04, 9.7800e-01, 9.0281e-04, 1.9693e-03, 5.5855e-03, 4.3701e-03,
        6.5604e-04], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,789][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0002, 0.1274, 0.1070, 0.1039, 0.0804, 0.1606, 0.1140, 0.0311, 0.1144,
        0.0261, 0.0482, 0.0521, 0.0345], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,790][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0203, 0.0839, 0.0749, 0.0529, 0.0544, 0.0344, 0.1635, 0.0302, 0.0777,
        0.0247, 0.1648, 0.0639, 0.1542], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,790][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0017, 0.1082, 0.1216, 0.0817, 0.0957, 0.1164, 0.1340, 0.0706, 0.0885,
        0.0237, 0.0682, 0.0462, 0.0436], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,790][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0092, 0.0551, 0.0784, 0.0491, 0.0853, 0.0826, 0.1079, 0.0882, 0.1400,
        0.0500, 0.1079, 0.0951, 0.0513], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,791][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([1.0000e+00, 2.1566e-16, 4.1086e-19, 5.4590e-17, 1.2255e-17, 2.0966e-18,
        9.9571e-18, 2.8834e-15, 1.0710e-18, 7.0944e-16, 4.8504e-17, 1.1972e-17,
        1.2403e-15], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,791][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0107, 0.0906, 0.0910, 0.0614, 0.1656, 0.1058, 0.1039, 0.0882, 0.0858,
        0.0435, 0.0607, 0.0486, 0.0441], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,792][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0141, 0.0720, 0.0793, 0.0503, 0.1003, 0.1574, 0.1127, 0.0590, 0.1350,
        0.0397, 0.0601, 0.0919, 0.0282], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,793][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0035, 0.0942, 0.0784, 0.0510, 0.0638, 0.1933, 0.0939, 0.0472, 0.1021,
        0.0566, 0.0725, 0.0938, 0.0497], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:25,794][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0056, 0.0328, 0.0661, 0.0767, 0.1097, 0.0909, 0.1543, 0.0989, 0.0644,
        0.0190, 0.0382, 0.0557, 0.1249, 0.0627], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,796][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.4685, 0.0082, 0.0031, 0.1048, 0.0269, 0.0150, 0.0204, 0.0853, 0.0269,
        0.0550, 0.0801, 0.0165, 0.0415, 0.0477], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,797][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0007, 0.0936, 0.1000, 0.0396, 0.0589, 0.1566, 0.1294, 0.0458, 0.1202,
        0.0317, 0.0389, 0.0552, 0.0264, 0.1028], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,798][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([5.2335e-10, 5.8146e-06, 8.2686e-05, 9.4335e-05, 2.6986e-05, 2.0470e-04,
        1.1990e-04, 9.9446e-01, 1.6273e-04, 4.1247e-04, 2.3940e-03, 7.3325e-04,
        1.7708e-04, 1.1247e-03], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,799][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.2190e-04, 1.2359e-01, 9.8935e-02, 9.5004e-02, 7.7889e-02, 1.5100e-01,
        1.0989e-01, 2.9356e-02, 1.1279e-01, 2.4977e-02, 4.4776e-02, 4.7897e-02,
        2.9180e-02, 5.4590e-02], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,800][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0014, 0.1400, 0.0369, 0.0461, 0.2315, 0.0239, 0.2248, 0.0087, 0.0305,
        0.0193, 0.1074, 0.0541, 0.0537, 0.0217], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,802][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0012, 0.1215, 0.1244, 0.0918, 0.0913, 0.1113, 0.1264, 0.0642, 0.0743,
        0.0196, 0.0546, 0.0334, 0.0367, 0.0494], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,803][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0063, 0.0598, 0.0903, 0.0542, 0.0855, 0.0757, 0.1034, 0.0827, 0.1207,
        0.0429, 0.0879, 0.0695, 0.0425, 0.0787], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,804][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([1.0000e+00, 1.4362e-25, 9.9627e-30, 4.6531e-27, 9.9333e-28, 1.2806e-29,
        6.9763e-29, 2.3738e-26, 8.8735e-30, 4.6895e-26, 7.5475e-28, 1.0614e-28,
        1.4254e-25, 2.1529e-32], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,806][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0044, 0.0925, 0.0913, 0.0857, 0.1676, 0.0972, 0.1033, 0.0811, 0.0687,
        0.0418, 0.0513, 0.0364, 0.0387, 0.0400], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,807][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0168, 0.0705, 0.0758, 0.0537, 0.0863, 0.1678, 0.1188, 0.0514, 0.1161,
        0.0288, 0.0360, 0.0638, 0.0188, 0.0954], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,809][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0039, 0.0826, 0.0721, 0.0487, 0.0596, 0.1618, 0.0907, 0.0465, 0.0957,
        0.0547, 0.0640, 0.0763, 0.0468, 0.0966], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:25,869][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:25,870][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,871][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,873][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,874][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,875][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,876][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,877][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,878][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,879][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,881][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,882][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,883][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:23:25,883][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.2630, 0.7370], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,883][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.0884, 0.9116], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,884][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.0201, 0.9799], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,884][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.2351, 0.7649], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,884][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.0150, 0.9850], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,885][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.0176, 0.9824], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,885][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.0232, 0.9768], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,885][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0481, 0.9519], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,885][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.5931, 0.4069], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,886][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.0635, 0.9365], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,887][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.2638, 0.7362], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,888][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.2866, 0.7134], device='cuda:0') for source tokens [After Anthony]
[2024-07-24 10:23:25,890][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1645, 0.4946, 0.3409], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,891][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0593, 0.4282, 0.5125], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,892][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0065, 0.4809, 0.5127], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,894][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1846, 0.3911, 0.4243], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,895][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0119, 0.4984, 0.4898], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,896][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0049, 0.2934, 0.7016], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,898][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0057, 0.4564, 0.5378], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,899][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0483, 0.4728, 0.4788], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,900][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0456, 0.2590, 0.6954], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,902][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0175, 0.4118, 0.5707], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,903][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1876, 0.3640, 0.4484], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,905][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.3508, 0.4461, 0.2031], device='cuda:0') for source tokens [After Anthony and]
[2024-07-24 10:23:25,906][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Mary] are: tensor([0.1090, 0.2953, 0.2242, 0.3715], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,907][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Mary] are: tensor([0.0469, 0.3258, 0.3668, 0.2605], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,909][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Mary] are: tensor([0.0133, 0.4239, 0.4109, 0.1520], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,910][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Mary] are: tensor([0.2071, 0.3094, 0.3058, 0.1778], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,911][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Mary] are: tensor([0.0116, 0.3915, 0.3532, 0.2438], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,913][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Mary] are: tensor([0.0108, 0.2975, 0.4991, 0.1926], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,914][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Mary] are: tensor([0.0107, 0.3961, 0.3792, 0.2140], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,915][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Mary] are: tensor([0.0447, 0.3959, 0.3101, 0.2492], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,917][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Mary] are: tensor([0.2241, 0.1918, 0.3677, 0.2164], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,918][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Mary] are: tensor([0.0332, 0.3293, 0.3826, 0.2549], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,920][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Mary] are: tensor([0.2827, 0.2715, 0.2496, 0.1962], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,921][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Mary] are: tensor([0.2293, 0.4086, 0.1702, 0.1919], device='cuda:0') for source tokens [After Anthony and Mary]
[2024-07-24 10:23:25,922][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.1487, 0.2109, 0.1772, 0.2571, 0.2061], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,924][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0322, 0.1907, 0.2788, 0.1705, 0.3277], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,925][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0045, 0.2894, 0.3549, 0.1272, 0.2239], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,926][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.1771, 0.1976, 0.2378, 0.1389, 0.2487], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,928][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.0032, 0.2902, 0.2708, 0.1810, 0.2548], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,929][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.0027, 0.2155, 0.3927, 0.1639, 0.2251], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,930][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.0031, 0.2883, 0.3076, 0.1724, 0.2287], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,931][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0149, 0.2588, 0.2352, 0.1585, 0.3326], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,931][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.0656, 0.1333, 0.3203, 0.1871, 0.2937], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,931][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.0091, 0.1596, 0.2509, 0.1432, 0.4371], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,931][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0793, 0.1856, 0.2050, 0.1520, 0.3781], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,932][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.2437, 0.2660, 0.1474, 0.1395, 0.2034], device='cuda:0') for source tokens [After Anthony and Mary went]
[2024-07-24 10:23:25,932][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1187, 0.1861, 0.1548, 0.1859, 0.1644, 0.1901], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,932][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0322, 0.1856, 0.2181, 0.1459, 0.2122, 0.2060], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,933][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0029, 0.2190, 0.2433, 0.0790, 0.1486, 0.3072], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,933][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1109, 0.1683, 0.1656, 0.0965, 0.1526, 0.3060], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,933][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0033, 0.2082, 0.2017, 0.1176, 0.1971, 0.2720], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,934][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0018, 0.1602, 0.2877, 0.1144, 0.1435, 0.2924], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,935][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0037, 0.2504, 0.2571, 0.1458, 0.1826, 0.1605], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,937][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0202, 0.2250, 0.2226, 0.1392, 0.2396, 0.1534], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,938][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.6171, 0.0364, 0.1141, 0.0590, 0.0575, 0.1158], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,939][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0069, 0.1706, 0.1753, 0.1312, 0.3743, 0.1417], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,940][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1639, 0.1356, 0.1382, 0.0932, 0.2054, 0.2637], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,942][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1498, 0.2809, 0.1274, 0.1562, 0.1845, 0.1011], device='cuda:0') for source tokens [After Anthony and Mary went to]
[2024-07-24 10:23:25,943][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1097, 0.1456, 0.1300, 0.1495, 0.1169, 0.1556, 0.1928],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,944][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0241, 0.1587, 0.1821, 0.1296, 0.1725, 0.1735, 0.1595],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,946][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0017, 0.1919, 0.1842, 0.0690, 0.1094, 0.2236, 0.2203],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,947][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0672, 0.1332, 0.1343, 0.0651, 0.1017, 0.2511, 0.2473],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,948][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0027, 0.1889, 0.1613, 0.1028, 0.1488, 0.2038, 0.1917],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,950][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0013, 0.1492, 0.2170, 0.0945, 0.1148, 0.2193, 0.2038],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,951][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0021, 0.2358, 0.2042, 0.1357, 0.1356, 0.1231, 0.1635],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,953][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0203, 0.1857, 0.1771, 0.1236, 0.1903, 0.1224, 0.1805],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,954][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.3928, 0.0521, 0.1418, 0.0764, 0.0779, 0.1642, 0.0947],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,955][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0080, 0.1811, 0.1493, 0.1151, 0.3110, 0.1139, 0.1216],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,957][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1397, 0.1114, 0.1118, 0.0619, 0.1608, 0.2238, 0.1906],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,958][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1391, 0.2676, 0.1116, 0.1158, 0.1573, 0.0935, 0.1151],
       device='cuda:0') for source tokens [After Anthony and Mary went to the]
[2024-07-24 10:23:25,960][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.0480, 0.1069, 0.1018, 0.1073, 0.1071, 0.1591, 0.1898, 0.1801],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,961][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([0.0136, 0.0999, 0.1438, 0.0782, 0.1718, 0.1857, 0.1767, 0.1303],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,962][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([0.0014, 0.1402, 0.1560, 0.0522, 0.1036, 0.2258, 0.2208, 0.1000],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,964][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.0155, 0.1221, 0.1319, 0.0505, 0.0938, 0.2431, 0.2350, 0.1081],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,965][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.0029, 0.1589, 0.1512, 0.0964, 0.1646, 0.1931, 0.1703, 0.0627],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,967][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.0006, 0.0773, 0.1581, 0.0688, 0.0972, 0.2397, 0.2200, 0.1382],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,968][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.0012, 0.1629, 0.1619, 0.0993, 0.1438, 0.1355, 0.1845, 0.1109],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,969][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.0089, 0.1027, 0.1392, 0.0710, 0.1658, 0.1337, 0.1808, 0.1979],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,971][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.0027, 0.0521, 0.1072, 0.0674, 0.1274, 0.3245, 0.1333, 0.1853],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,972][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.0034, 0.1158, 0.1430, 0.0784, 0.2211, 0.1633, 0.1693, 0.1056],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,973][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.0086, 0.0917, 0.1091, 0.0810, 0.1648, 0.2297, 0.1878, 0.1273],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,975][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.0371, 0.2590, 0.1169, 0.0937, 0.1518, 0.1228, 0.1080, 0.1107],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant]
[2024-07-24 10:23:25,976][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0860, 0.0993, 0.0878, 0.0975, 0.0888, 0.1076, 0.1328, 0.1434, 0.1568],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,978][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0312, 0.1102, 0.1182, 0.0915, 0.1436, 0.1375, 0.1201, 0.0951, 0.1526],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,978][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0019, 0.1493, 0.1277, 0.0574, 0.0906, 0.1918, 0.1551, 0.0679, 0.1584],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,978][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0484, 0.0993, 0.0851, 0.0515, 0.0804, 0.1735, 0.1543, 0.1123, 0.1952],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,979][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0030, 0.1418, 0.1131, 0.0770, 0.1364, 0.1767, 0.1500, 0.0545, 0.1474],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,979][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0012, 0.0899, 0.1416, 0.0728, 0.0947, 0.1783, 0.1487, 0.1157, 0.1572],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,979][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0026, 0.1712, 0.1466, 0.1037, 0.1238, 0.1202, 0.1433, 0.0947, 0.0939],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,980][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0139, 0.1041, 0.1187, 0.0811, 0.1340, 0.0903, 0.1203, 0.1615, 0.1761],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,980][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1609, 0.0431, 0.1093, 0.0644, 0.0793, 0.1731, 0.0815, 0.1011, 0.1875],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,980][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0071, 0.1158, 0.0992, 0.1011, 0.2561, 0.1055, 0.1103, 0.1186, 0.0862],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,981][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0881, 0.0868, 0.0785, 0.0579, 0.1313, 0.1809, 0.1337, 0.0937, 0.1491],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,982][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0966, 0.1937, 0.0857, 0.0969, 0.1375, 0.0934, 0.0896, 0.1320, 0.0745],
       device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant,]
[2024-07-24 10:23:25,983][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.0421, 0.0777, 0.0805, 0.0875, 0.0836, 0.1061, 0.1348, 0.1215, 0.1672,
        0.0990], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,985][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.0172, 0.0706, 0.1099, 0.0716, 0.1448, 0.1339, 0.1253, 0.0861, 0.1658,
        0.0748], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,986][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.0030, 0.1012, 0.1210, 0.0481, 0.0907, 0.1797, 0.1574, 0.0767, 0.1688,
        0.0534], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,987][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.0162, 0.1089, 0.0980, 0.0558, 0.0870, 0.1833, 0.1621, 0.0818, 0.1560,
        0.0509], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,989][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.0050, 0.1381, 0.1152, 0.0766, 0.1388, 0.1703, 0.1395, 0.0535, 0.1249,
        0.0381], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,990][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.0011, 0.0626, 0.1124, 0.0589, 0.0856, 0.1887, 0.1624, 0.1030, 0.1722,
        0.0533], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,991][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.0023, 0.1412, 0.1467, 0.0872, 0.1229, 0.1430, 0.1538, 0.0760, 0.0988,
        0.0282], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,993][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0075, 0.0818, 0.1079, 0.0646, 0.1223, 0.1100, 0.1266, 0.1154, 0.1869,
        0.0770], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,994][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.0011, 0.0310, 0.0579, 0.0497, 0.0986, 0.1899, 0.0818, 0.0976, 0.2363,
        0.1560], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,995][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.0065, 0.0899, 0.0973, 0.0803, 0.1815, 0.1440, 0.1504, 0.0849, 0.1161,
        0.0492], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,997][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.0185, 0.0838, 0.0960, 0.0693, 0.1262, 0.1772, 0.1319, 0.0842, 0.1560,
        0.0569], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:25,998][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.0627, 0.2008, 0.0925, 0.0915, 0.1341, 0.1008, 0.0822, 0.0963, 0.0771,
        0.0621], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony]
[2024-07-24 10:23:26,000][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0402, 0.0635, 0.0591, 0.0756, 0.0688, 0.0801, 0.1052, 0.1111, 0.1418,
        0.0922, 0.1625], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:26,001][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0164, 0.0749, 0.0969, 0.0646, 0.1197, 0.1248, 0.1059, 0.0763, 0.1368,
        0.0608, 0.1228], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:26,003][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0015, 0.1204, 0.1114, 0.0467, 0.0724, 0.1673, 0.1418, 0.0690, 0.1551,
        0.0532, 0.0611], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:26,004][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0267, 0.0719, 0.0748, 0.0373, 0.0650, 0.1783, 0.1483, 0.0787, 0.1734,
        0.0610, 0.0846], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:26,005][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0038, 0.1274, 0.1050, 0.0684, 0.1096, 0.1729, 0.1411, 0.0462, 0.1329,
        0.0350, 0.0576], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:26,007][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0009, 0.0680, 0.1123, 0.0560, 0.0759, 0.1854, 0.1474, 0.0803, 0.1520,
        0.0421, 0.0798], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:26,008][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0017, 0.1382, 0.1299, 0.0883, 0.1034, 0.1231, 0.1363, 0.0795, 0.0952,
        0.0298, 0.0747], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:26,010][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0070, 0.0810, 0.0944, 0.0593, 0.1071, 0.0919, 0.1114, 0.1105, 0.1539,
        0.0665, 0.1168], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:26,011][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0030, 0.0234, 0.0541, 0.0384, 0.0742, 0.1608, 0.0708, 0.0823, 0.2054,
        0.1379, 0.1496], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:26,013][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0046, 0.0921, 0.0959, 0.0754, 0.1645, 0.1356, 0.1377, 0.0797, 0.1071,
        0.0433, 0.0643], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:26,014][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0148, 0.0765, 0.0811, 0.0644, 0.1144, 0.1724, 0.1382, 0.0719, 0.1530,
        0.0476, 0.0658], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:26,015][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0815, 0.1591, 0.0790, 0.0793, 0.1033, 0.0910, 0.0734, 0.0884, 0.0726,
        0.0618, 0.1107], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave]
[2024-07-24 10:23:26,017][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0578, 0.0620, 0.0627, 0.0692, 0.0625, 0.0714, 0.0922, 0.0969, 0.1110,
        0.0732, 0.1237, 0.1174], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:26,018][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0189, 0.0740, 0.1036, 0.0666, 0.1038, 0.1212, 0.1016, 0.0640, 0.1219,
        0.0506, 0.0961, 0.0776], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:26,020][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0012, 0.1035, 0.1102, 0.0456, 0.0681, 0.1715, 0.1467, 0.0577, 0.1380,
        0.0392, 0.0487, 0.0696], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:26,021][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0239, 0.0782, 0.0757, 0.0418, 0.0648, 0.1527, 0.1320, 0.0752, 0.1428,
        0.0507, 0.0635, 0.0986], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:26,023][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0022, 0.1265, 0.1090, 0.0760, 0.1082, 0.1545, 0.1291, 0.0424, 0.1107,
        0.0284, 0.0506, 0.0624], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:26,024][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0007, 0.0770, 0.1195, 0.0671, 0.0733, 0.1544, 0.1295, 0.0834, 0.1171,
        0.0441, 0.0682, 0.0657], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:26,025][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0017, 0.1369, 0.1350, 0.1007, 0.0987, 0.1141, 0.1327, 0.0702, 0.0820,
        0.0235, 0.0625, 0.0420], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:26,025][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0090, 0.0714, 0.0953, 0.0626, 0.0950, 0.0821, 0.1127, 0.0925, 0.1366,
        0.0540, 0.0994, 0.0895], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:26,025][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0726, 0.0299, 0.0754, 0.0497, 0.0593, 0.1424, 0.0640, 0.0642, 0.1349,
        0.1029, 0.0977, 0.1071], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:26,026][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0071, 0.0920, 0.0893, 0.0834, 0.1795, 0.1047, 0.1149, 0.0911, 0.0830,
        0.0464, 0.0610, 0.0477], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:26,026][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0212, 0.0779, 0.0812, 0.0566, 0.1051, 0.1658, 0.1278, 0.0655, 0.1311,
        0.0379, 0.0499, 0.0800], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:26,026][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0654, 0.1316, 0.0739, 0.0751, 0.1023, 0.0823, 0.0790, 0.0804, 0.0707,
        0.0618, 0.0931, 0.0844], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a]
[2024-07-24 10:23:26,027][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.0351, 0.0582, 0.0548, 0.0642, 0.0597, 0.0798, 0.0961, 0.0902, 0.1172,
        0.0613, 0.1117, 0.1093, 0.0625], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:26,027][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0131, 0.0647, 0.0974, 0.0573, 0.0939, 0.1214, 0.1014, 0.0612, 0.1190,
        0.0407, 0.1032, 0.0819, 0.0447], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:26,027][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0015, 0.0797, 0.1038, 0.0385, 0.0671, 0.1624, 0.1408, 0.0552, 0.1416,
        0.0367, 0.0574, 0.0822, 0.0331], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:26,028][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0119, 0.0749, 0.0790, 0.0348, 0.0609, 0.1553, 0.1329, 0.0585, 0.1347,
        0.0366, 0.0639, 0.1062, 0.0504], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:26,029][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.0018, 0.1124, 0.1048, 0.0754, 0.1157, 0.1515, 0.1212, 0.0397, 0.1006,
        0.0241, 0.0522, 0.0592, 0.0415], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:26,030][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.0011, 0.0614, 0.1035, 0.0485, 0.0632, 0.1426, 0.1182, 0.0873, 0.1279,
        0.0411, 0.0745, 0.0740, 0.0569], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:26,032][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0017, 0.1082, 0.1216, 0.0817, 0.0957, 0.1164, 0.1340, 0.0706, 0.0885,
        0.0237, 0.0682, 0.0462, 0.0436], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:26,033][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0092, 0.0551, 0.0784, 0.0491, 0.0853, 0.0826, 0.1079, 0.0882, 0.1400,
        0.0500, 0.1079, 0.0951, 0.0513], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:26,035][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.0073, 0.0258, 0.0583, 0.0406, 0.0560, 0.1532, 0.0587, 0.0581, 0.1591,
        0.1000, 0.1033, 0.1219, 0.0576], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:26,036][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0107, 0.0906, 0.0910, 0.0614, 0.1656, 0.1058, 0.1039, 0.0882, 0.0858,
        0.0435, 0.0607, 0.0486, 0.0441], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:26,037][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0141, 0.0720, 0.0793, 0.0503, 0.1003, 0.1574, 0.1127, 0.0590, 0.1350,
        0.0397, 0.0601, 0.0919, 0.0282], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:26,039][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0413, 0.1391, 0.0724, 0.0684, 0.1025, 0.0886, 0.0680, 0.0627, 0.0602,
        0.0451, 0.0940, 0.0885, 0.0694], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer]
[2024-07-24 10:23:26,040][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0436, 0.0499, 0.0512, 0.0530, 0.0531, 0.0681, 0.0847, 0.0747, 0.1065,
        0.0617, 0.1074, 0.1034, 0.0614, 0.0813], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:26,042][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0154, 0.0620, 0.0901, 0.0572, 0.0891, 0.1089, 0.0918, 0.0548, 0.1047,
        0.0432, 0.0838, 0.0624, 0.0379, 0.0987], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:26,043][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0007, 0.0936, 0.1000, 0.0396, 0.0589, 0.1566, 0.1294, 0.0458, 0.1202,
        0.0317, 0.0389, 0.0552, 0.0264, 0.1028], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:26,045][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0191, 0.0712, 0.0656, 0.0345, 0.0519, 0.1407, 0.1229, 0.0545, 0.1257,
        0.0372, 0.0493, 0.0821, 0.0409, 0.1045], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:26,046][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0017, 0.1083, 0.0950, 0.0652, 0.1038, 0.1417, 0.1181, 0.0368, 0.1052,
        0.0244, 0.0471, 0.0547, 0.0323, 0.0657], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:26,047][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0005, 0.0643, 0.1079, 0.0575, 0.0629, 0.1397, 0.1188, 0.0723, 0.1083,
        0.0367, 0.0573, 0.0545, 0.0416, 0.0778], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:26,049][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0012, 0.1215, 0.1244, 0.0918, 0.0913, 0.1113, 0.1264, 0.0642, 0.0743,
        0.0196, 0.0546, 0.0334, 0.0367, 0.0494], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:26,050][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0063, 0.0598, 0.0903, 0.0542, 0.0855, 0.0757, 0.1034, 0.0827, 0.1207,
        0.0429, 0.0879, 0.0695, 0.0425, 0.0787], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:26,052][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0448, 0.0199, 0.0606, 0.0385, 0.0437, 0.1272, 0.0503, 0.0442, 0.1188,
        0.0781, 0.0787, 0.0893, 0.0392, 0.1669], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:26,053][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0044, 0.0925, 0.0913, 0.0857, 0.1676, 0.0972, 0.1033, 0.0811, 0.0687,
        0.0418, 0.0513, 0.0364, 0.0387, 0.0400], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:26,055][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0168, 0.0705, 0.0758, 0.0537, 0.0863, 0.1678, 0.1188, 0.0514, 0.1161,
        0.0288, 0.0360, 0.0638, 0.0188, 0.0954], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:26,056][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0428, 0.1145, 0.0656, 0.0643, 0.0936, 0.0806, 0.0738, 0.0667, 0.0612,
        0.0469, 0.0767, 0.0676, 0.0691, 0.0767], device='cuda:0') for source tokens [After Anthony and Mary went to the restaurant, Anthony gave a computer to]
[2024-07-24 10:23:26,057][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:23:26,058][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[1340],
        [ 202],
        [  39],
        [   2],
        [  62],
        [   9],
        [  66],
        [  18],
        [  22],
        [  30],
        [   2],
        [   9],
        [   4],
        [   1]], device='cuda:0')
[2024-07-24 10:23:26,060][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[1381],
        [ 212],
        [  73],
        [   3],
        [  59],
        [  14],
        [  92],
        [  24],
        [  25],
        [  39],
        [   2],
        [  22],
        [   6],
        [   3]], device='cuda:0')
[2024-07-24 10:23:26,061][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[2469],
        [2504],
        [ 965],
        [1824],
        [1189],
        [ 806],
        [1217],
        [1356],
        [1058],
        [1116],
        [1272],
        [1433],
        [1658],
        [1676]], device='cuda:0')
[2024-07-24 10:23:26,063][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[  182],
        [  264],
        [  681],
        [  448],
        [48652],
        [21706],
        [47508],
        [38887],
        [46014],
        [44114],
        [48929],
        [38459],
        [34176],
        [44457]], device='cuda:0')
[2024-07-24 10:23:26,064][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[17648],
        [41402],
        [34077],
        [41780],
        [40759],
        [34798],
        [32573],
        [27996],
        [24914],
        [20875],
        [20000],
        [19002],
        [17122],
        [16833]], device='cuda:0')
[2024-07-24 10:23:26,065][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[30499],
        [14850],
        [13693],
        [11317],
        [12099],
        [10200],
        [11815],
        [27369],
        [27500],
        [27500],
        [27409],
        [27506],
        [27460],
        [27506]], device='cuda:0')
[2024-07-24 10:23:26,067][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[3217],
        [1081],
        [1290],
        [1156],
        [1155],
        [1076],
        [1040],
        [ 985],
        [ 911],
        [ 886],
        [ 864],
        [ 861],
        [ 855],
        [ 841]], device='cuda:0')
[2024-07-24 10:23:26,068][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[29472],
        [10847],
        [11457],
        [14235],
        [25405],
        [23799],
        [24556],
        [23379],
        [24579],
        [23659],
        [26461],
        [28246],
        [24928],
        [26720]], device='cuda:0')
[2024-07-24 10:23:26,069][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[17421],
        [ 9177],
        [ 5919],
        [ 9167],
        [ 8616],
        [ 7343],
        [ 6811],
        [ 5374],
        [ 5066],
        [ 4682],
        [ 4425],
        [ 4567],
        [ 3873],
        [ 4127]], device='cuda:0')
[2024-07-24 10:23:26,071][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[33760],
        [20801],
        [24754],
        [15948],
        [23253],
        [25696],
        [27571],
        [32913],
        [32387],
        [33018],
        [32614],
        [32379],
        [32761],
        [32901]], device='cuda:0')
[2024-07-24 10:23:26,072][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[2852],
        [2852],
        [2852],
        [2852],
        [2852],
        [2852],
        [2852],
        [2852],
        [2852],
        [2852],
        [2852],
        [2852],
        [2852],
        [2852]], device='cuda:0')
[2024-07-24 10:23:26,073][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[19837],
        [15616],
        [24169],
        [26733],
        [30682],
        [31779],
        [32052],
        [33723],
        [33746],
        [34777],
        [34994],
        [34729],
        [34976],
        [34977]], device='cuda:0')
[2024-07-24 10:23:26,074][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[35725],
        [31505],
        [38111],
        [26656],
        [31106],
        [34033],
        [35324],
        [36026],
        [37040],
        [36311],
        [37269],
        [38072],
        [38511],
        [38156]], device='cuda:0')
[2024-07-24 10:23:26,075][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[18852],
        [11943],
        [12418],
        [14350],
        [12435],
        [12197],
        [11631],
        [11555],
        [12041],
        [11531],
        [11440],
        [11475],
        [11418],
        [11566]], device='cuda:0')
[2024-07-24 10:23:26,076][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[4037],
        [2536],
        [1891],
        [1784],
        [2631],
        [2826],
        [1632],
        [1051],
        [2524],
        [1360],
        [2056],
        [1958],
        [1514],
        [1733]], device='cuda:0')
[2024-07-24 10:23:26,077][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[8141],
        [6947],
        [6039],
        [6537],
        [7006],
        [5389],
        [3994],
        [3636],
        [3524],
        [3190],
        [3528],
        [3447],
        [3242],
        [3055]], device='cuda:0')
[2024-07-24 10:23:26,079][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[7387],
        [5624],
        [4965],
        [5265],
        [5405],
        [5756],
        [5591],
        [5513],
        [5793],
        [6098],
        [6419],
        [6397],
        [6556],
        [6830]], device='cuda:0')
[2024-07-24 10:23:26,080][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[13625],
        [ 7904],
        [10374],
        [ 9647],
        [ 9889],
        [ 9721],
        [ 9871],
        [ 9861],
        [10399],
        [10650],
        [10528],
        [10774],
        [10891],
        [11074]], device='cuda:0')
[2024-07-24 10:23:26,081][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[3536],
        [4033],
        [3544],
        [3624],
        [3490],
        [3223],
        [2993],
        [2946],
        [2807],
        [2816],
        [2727],
        [2735],
        [2733],
        [2735]], device='cuda:0')
[2024-07-24 10:23:26,083][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[7502],
        [3578],
        [2472],
        [2642],
        [2739],
        [2810],
        [2908],
        [2838],
        [2906],
        [2960],
        [3014],
        [3079],
        [3097],
        [3142]], device='cuda:0')
[2024-07-24 10:23:26,084][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[1894],
        [1393],
        [1636],
        [1777],
        [1528],
        [1520],
        [1509],
        [1317],
        [1295],
        [1215],
        [1217],
        [1238],
        [1205],
        [1218]], device='cuda:0')
[2024-07-24 10:23:26,085][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[1606],
        [3746],
        [4281],
        [4103],
        [4156],
        [4671],
        [4865],
        [4551],
        [4522],
        [4695],
        [4209],
        [4169],
        [4066],
        [4073]], device='cuda:0')
[2024-07-24 10:23:26,086][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[8546],
        [3851],
        [5571],
        [5189],
        [5006],
        [5001],
        [4676],
        [4148],
        [4108],
        [3895],
        [3775],
        [3619],
        [3254],
        [3172]], device='cuda:0')
[2024-07-24 10:23:26,088][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[11049],
        [10769],
        [ 3062],
        [ 9515],
        [ 2965],
        [10830],
        [10431],
        [ 3927],
        [ 7487],
        [ 3961],
        [ 3921],
        [ 3351],
        [ 3927],
        [ 3741]], device='cuda:0')
[2024-07-24 10:23:26,089][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[2072],
        [1838],
        [1938],
        [1813],
        [2464],
        [2289],
        [2258],
        [2326],
        [2352],
        [2200],
        [2219],
        [2311],
        [2336],
        [2295]], device='cuda:0')
[2024-07-24 10:23:26,090][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[2226],
        [6337],
        [8130],
        [7446],
        [6245],
        [6065],
        [5848],
        [5557],
        [5366],
        [5357],
        [5348],
        [5374],
        [5364],
        [5418]], device='cuda:0')
[2024-07-24 10:23:26,092][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[978],
        [793],
        [788],
        [720],
        [725],
        [678],
        [655],
        [677],
        [685],
        [672],
        [680],
        [685],
        [677],
        [692]], device='cuda:0')
[2024-07-24 10:23:26,093][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[39195],
        [42950],
        [41376],
        [42091],
        [42111],
        [43060],
        [43535],
        [44609],
        [43338],
        [44779],
        [45009],
        [44641],
        [45132],
        [45069]], device='cuda:0')
[2024-07-24 10:23:26,095][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[37666],
        [39674],
        [45774],
        [41883],
        [45727],
        [39023],
        [41639],
        [44024],
        [47162],
        [46067],
        [41030],
        [43259],
        [41115],
        [42071]], device='cuda:0')
[2024-07-24 10:23:26,096][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[2137],
        [2137],
        [2137],
        [2137],
        [2137],
        [2137],
        [2137],
        [2137],
        [2137],
        [2137],
        [2137],
        [2137],
        [2137],
        [2137]], device='cuda:0')
