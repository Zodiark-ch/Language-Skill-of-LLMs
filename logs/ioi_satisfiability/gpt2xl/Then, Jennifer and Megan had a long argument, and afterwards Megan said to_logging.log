[2024-07-24 10:29:20,740][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isThen, Jennifer and Megan had a long argument, and afterwards Megan said to
[2024-07-24 10:29:20,740][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Jennifer
[2024-07-24 10:29:20,740][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:29:20,741][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:29:20,741][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:29:20,741][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,741][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:29:20,742][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,742][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:29:20,742][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,743][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:29:20,743][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,743][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:29:20,743][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,744][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:29:20,744][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,744][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:29:20,745][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit4', 'circuit7', 'circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:29:20,745][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:29:20,745][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:29:20,745][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:29:20,745][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,746][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:29:20,746][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,746][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:29:20,746][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22']
[2024-07-24 10:29:20,746][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:29:20,746][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:20,746][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:29:20,747][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,747][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:29:20,747][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,747][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:29:20,747][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit27']
[2024-07-24 10:29:20,747][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:29:20,748][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,748][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:29:20,748][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,748][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:29:20,748][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,748][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:29:20,748][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,749][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:29:20,749][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,749][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:29:20,749][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit28']
[2024-07-24 10:29:20,749][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:29:20,749][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,749][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:29:20,750][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:29:20,750][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:29:20,750][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:29:20,750][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:29:20,750][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,750][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:29:20,751][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,751][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:29:20,751][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,751][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:29:20,751][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,751][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:29:20,751][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,752][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:29:20,752][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,752][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,752][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:29:20,752][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,752][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit3', 'circuit4', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,753][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:29:20,753][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,753][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit8', 'circuit27']
[2024-07-24 10:29:20,753][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:29:20,753][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit22']
[2024-07-24 10:29:20,753][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,753][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:29:20,754][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11']
[2024-07-24 10:29:20,754][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,754][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:29:20,754][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit20', 'circuit24']
[2024-07-24 10:29:20,754][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,754][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:29:20,755][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18', 'circuit19', 'circuit22', 'circuit27']
[2024-07-24 10:29:20,755][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit12', 'circuit13', 'circuit16', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,755][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:29:20,755][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:29:20,755][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18']
[2024-07-24 10:29:20,755][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:29:20,755][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:29:20,756][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,756][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:29:20,756][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:29:20,756][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,756][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:29:20,756][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,757][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:29:20,757][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:29:20,757][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,757][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,757][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:29:20,757][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit23']
[2024-07-24 10:29:20,757][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit26']
[2024-07-24 10:29:20,758][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:29:20,758][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,758][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,758][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:29:20,758][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:20,758][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,759][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:29:20,759][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,759][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit10', 'circuit13', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:29:20,759][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:29:20,759][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,759][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,759][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:29:20,760][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,760][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,760][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:29:20,760][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,760][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,760][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:29:20,761][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,761][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit6', 'circuit13', 'circuit15']
[2024-07-24 10:29:20,761][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:29:20,761][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:29:20,761][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,761][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:29:20,761][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit22', 'circuit23']
[2024-07-24 10:29:20,762][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,762][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:29:20,762][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:29:20,762][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22']
[2024-07-24 10:29:20,762][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:29:20,762][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:29:20,763][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,763][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:29:20,763][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,763][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,763][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:29:20,763][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,763][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,764][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:29:20,764][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,764][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,764][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:29:20,764][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,764][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,765][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:29:20,765][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,765][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,765][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:29:20,765][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,765][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,765][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit7', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,766][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:29:20,766][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit23']
[2024-07-24 10:29:20,766][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,766][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:29:20,766][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:29:20,766][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit21']
[2024-07-24 10:29:20,767][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,767][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,767][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:29:20,767][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:29:20,767][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,767][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit18']
[2024-07-24 10:29:20,767][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:29:20,768][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22']
[2024-07-24 10:29:20,768][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,768][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,768][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:29:20,768][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:20,768][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,769][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:29:20,769][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:29:20,769][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:29:20,769][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,769][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,769][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:29:20,770][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,770][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,770][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,770][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:29:20,770][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,770][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,770][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,771][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:29:20,771][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:29:20,771][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:29:20,771][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,771][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:29:20,771][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,772][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,772][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,772][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:29:20,772][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:20,772][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:29:20,772][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,772][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:29:20,773][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,773][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:29:20,773][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,773][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:29:20,773][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,773][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,774][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,774][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:29:20,774][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22']
[2024-07-24 10:29:20,774][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,774][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,774][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:29:20,774][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,775][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,775][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,775][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:29:20,775][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:20,775][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,775][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit4', 'circuit5', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit22', 'circuit23']
[2024-07-24 10:29:20,776][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:29:20,776][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit11', 'circuit12', 'circuit24']
[2024-07-24 10:29:20,776][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,776][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,776][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:29:20,776][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:29:20,776][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,777][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:20,777][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:29:20,777][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit22']
[2024-07-24 10:29:20,777][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,777][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,777][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:29:20,778][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,778][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,778][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,778][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:29:20,778][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,778][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,778][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,779][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:29:20,779][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,779][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,779][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,779][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:29:20,779][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,780][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,780][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,780][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:29:20,780][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,780][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,780][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,780][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:29:20,781][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,781][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,781][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,781][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:29:20,781][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,781][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,782][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,782][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:29:20,782][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,782][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,782][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,782][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:29:20,782][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,783][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,783][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,783][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:29:20,783][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,783][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,783][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,784][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,784][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:29:20,784][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit27']
[2024-07-24 10:29:20,784][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,784][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit22']
[2024-07-24 10:29:20,784][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,785][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:29:20,785][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit21', 'circuit23', 'circuit27']
[2024-07-24 10:29:20,785][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,785][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,785][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,785][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:29:20,785][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:20,786][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit18', 'circuit19']
[2024-07-24 10:29:20,786][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19']
[2024-07-24 10:29:20,786][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:29:20,786][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:29:20,786][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:29:20,786][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,787][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:29:20,787][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:29:20,787][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:29:20,787][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,787][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit20']
[2024-07-24 10:29:20,787][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit21', 'circuit22']
[2024-07-24 10:29:20,788][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,788][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:29:20,788][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18', 'circuit19']
[2024-07-24 10:29:20,788][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:29:20,788][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15']
[2024-07-24 10:29:20,788][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:29:20,788][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:29:20,789][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22']
[2024-07-24 10:29:20,789][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit17']
[2024-07-24 10:29:20,789][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit12', 'circuit14', 'circuit26']
[2024-07-24 10:29:20,789][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,789][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:29:20,789][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,790][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:29:20,790][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:20,790][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,790][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:29:20,790][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,790][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit9', 'circuit15']
[2024-07-24 10:29:20,790][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit27']
[2024-07-24 10:29:20,791][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit25']
[2024-07-24 10:29:20,791][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:29:20,791][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,791][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,791][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:20,791][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,792][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:29:20,792][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:20,792][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,792][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit23']
[2024-07-24 10:29:20,792][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,792][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:29:20,792][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,793][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,793][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,793][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,793][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:29:20,793][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,793][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,794][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,794][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,794][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:29:20,794][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,794][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit4']
[2024-07-24 10:29:20,794][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:29:20,794][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,795][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:29:20,795][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22']
[2024-07-24 10:29:20,795][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,795][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,795][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,795][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:29:20,796][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit20', 'circuit24']
[2024-07-24 10:29:20,796][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,796][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,796][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,796][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:29:20,796][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,796][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6']
[2024-07-24 10:29:20,797][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit26']
[2024-07-24 10:29:20,797][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,797][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:29:20,797][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,797][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,797][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,798][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,798][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:29:20,798][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,798][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:29:20,798][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,798][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,798][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:29:20,799][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:29:20,799][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,799][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit27']
[2024-07-24 10:29:20,799][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,799][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:29:20,799][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,800][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,800][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,800][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,800][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:29:20,800][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,800][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,800][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,801][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,801][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:29:20,801][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,801][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,801][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,801][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,802][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:29:20,802][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,802][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,802][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,802][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,802][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:29:20,802][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,803][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,803][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,803][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,803][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:29:20,803][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,803][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,804][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,804][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,804][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:29:20,804][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,804][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,804][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,805][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,805][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:29:20,805][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,805][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,805][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,805][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,805][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:29:20,806][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,806][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,806][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,806][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,806][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,806][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:29:20,807][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,807][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,807][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit1', 'circuit3', 'circuit4', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:20,807][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,807][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,807][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:29:20,808][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,808][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:20,808][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,808][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit20', 'circuit22', 'circuit26']
[2024-07-24 10:29:20,808][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit17', 'circuit19', 'circuit26']
[2024-07-24 10:29:20,808][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:29:20,808][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:29:20,809][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,809][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,809][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,809][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,809][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:29:20,809][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,810][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit3', 'circuit4', 'circuit7', 'circuit16', 'circuit18', 'circuit19', 'circuit21']
[2024-07-24 10:29:20,810][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:29:20,810][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit23', 'circuit27']
[2024-07-24 10:29:20,810][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,810][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:29:20,810][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,810][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit21']
[2024-07-24 10:29:20,811][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17']
[2024-07-24 10:29:20,811][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19']
[2024-07-24 10:29:20,811][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,811][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:29:20,811][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,811][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:20,812][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit22', 'circuit23']
[2024-07-24 10:29:20,812][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:29:20,812][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,812][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:29:20,812][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:29:20,812][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16']
[2024-07-24 10:29:20,813][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:29:20,813][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,813][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,813][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:29:20,813][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:29:20,813][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,813][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit15']
[2024-07-24 10:29:20,814][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20']
[2024-07-24 10:29:20,814][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,814][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:29:20,814][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,814][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:29:20,814][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:29:20,815][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:20,815][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:20,815][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:29:20,815][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,815][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,815][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,815][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,816][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:20,816][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:29:20,816][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,816][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit27']
[2024-07-24 10:29:20,816][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,816][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,817][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,817][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:29:20,817][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,817][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,817][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,817][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,817][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,818][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:29:20,818][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,818][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,818][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,818][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,818][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,819][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:29:20,819][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,819][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit7']
[2024-07-24 10:29:20,819][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,819][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,819][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,820][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:29:20,820][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:29:20,820][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,820][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,820][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,820][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,820][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:29:20,821][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,821][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,821][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,821][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,821][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,821][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:29:20,822][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit24', 'circuit25']
[2024-07-24 10:29:20,822][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,822][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,822][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,822][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,822][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:29:20,822][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,823][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,823][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,823][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,823][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,823][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:29:20,823][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,824][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,824][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,824][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,824][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,824][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:29:20,824][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,824][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,825][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,825][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,825][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,825][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:29:20,825][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,825][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,826][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,826][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,826][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,826][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:29:20,826][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,826][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,826][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,827][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,827][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,827][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:29:20,827][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,827][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,827][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,828][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,828][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,828][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:29:20,828][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,828][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,828][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,828][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,829][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,829][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:29:20,829][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,829][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:29:20,829][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,829][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,830][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,830][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:29:20,830][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,830][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,830][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,830][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,831][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,831][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:29:20,831][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,831][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,831][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,831][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,832][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,832][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:29:20,832][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,832][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,832][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,832][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,832][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,833][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:29:20,833][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,833][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,833][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,833][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,833][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit5', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,834][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,834][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:29:20,834][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit15', 'circuit18', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:29:20,834][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit19', 'circuit23']
[2024-07-24 10:29:20,834][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,834][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,835][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit20']
[2024-07-24 10:29:20,835][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit26']
[2024-07-24 10:29:20,835][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:29:20,835][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,835][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit21', 'circuit27']
[2024-07-24 10:29:20,835][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16']
[2024-07-24 10:29:20,835][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:29:20,836][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:29:20,836][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:20,836][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:29:20,836][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,836][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit7', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,836][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,837][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,837][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit5', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,837][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit6', 'circuit10', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,837][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:29:20,837][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:20,837][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:29:20,838][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,838][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,838][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit24', 'circuit27']
[2024-07-24 10:29:20,838][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit2']
[2024-07-24 10:29:20,838][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:29:20,838][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit4', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,838][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,839][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:29:20,839][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,839][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:29:20,839][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,839][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:29:20,839][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,840][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,840][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit22']
[2024-07-24 10:29:20,840][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:29:20,840][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,840][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:20,840][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:29:20,841][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,841][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,841][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:29:20,841][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,841][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,841][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23']
[2024-07-24 10:29:20,841][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:29:20,842][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,842][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit21']
[2024-07-24 10:29:20,842][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,842][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:29:20,842][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,842][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,843][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:29:20,843][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:29:20,843][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,843][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,843][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,843][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,843][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,844][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:29:20,844][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20']
[2024-07-24 10:29:20,844][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16']
[2024-07-24 10:29:20,844][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,844][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,844][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,845][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit27']
[2024-07-24 10:29:20,845][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:29:20,845][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit27']
[2024-07-24 10:29:20,845][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:29:20,845][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:29:20,845][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,846][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:20,846][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:20,846][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:29:20,846][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:29:20,846][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit27']
[2024-07-24 10:29:20,846][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,846][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,847][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,847][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,847][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:29:20,847][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,847][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,847][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,848][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit6', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,848][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,848][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,848][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:29:20,848][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,848][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,849][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,849][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:20,849][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,849][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,849][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:29:20,849][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit27']
[2024-07-24 10:29:20,849][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:29:20,850][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit22']
[2024-07-24 10:29:20,850][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit21', 'circuit22']
[2024-07-24 10:29:20,850][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:20,850][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24']
[2024-07-24 10:29:20,850][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:29:20,850][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,851][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit21', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,851][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,851][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:20,851][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:29:20,851][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit17', 'circuit19']
[2024-07-24 10:29:20,851][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:29:20,851][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:29:20,852][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,852][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,852][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,852][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit24']
[2024-07-24 10:29:20,852][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit18']
[2024-07-24 10:29:20,852][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:29:20,853][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit22', 'circuit24']
[2024-07-24 10:29:20,853][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit19']
[2024-07-24 10:29:20,853][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19']
[2024-07-24 10:29:20,853][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,853][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,853][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:29:20,854][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:29:20,854][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,854][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,854][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit21', 'circuit24', 'circuit26']
[2024-07-24 10:29:20,854][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21']
[2024-07-24 10:29:20,854][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,854][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit9', 'circuit13']
[2024-07-24 10:29:20,855][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:29:20,855][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,855][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit7', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit26']
[2024-07-24 10:29:20,855][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,855][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit19']
[2024-07-24 10:29:20,855][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:29:20,856][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,856][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:29:20,856][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23']
[2024-07-24 10:29:20,856][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit3', 'circuit4', 'circuit13', 'circuit14', 'circuit18']
[2024-07-24 10:29:20,856][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16']
[2024-07-24 10:29:20,856][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,857][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,857][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit19', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:29:20,857][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:29:20,857][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:20,857][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,857][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,857][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,858][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,858][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,858][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:29:20,858][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,858][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,858][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,859][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit6', 'circuit8', 'circuit9', 'circuit11']
[2024-07-24 10:29:20,859][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit24', 'circuit27']
[2024-07-24 10:29:20,859][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,859][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:29:20,859][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:29:20,859][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit10', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:29:20,859][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23']
[2024-07-24 10:29:20,860][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,860][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,860][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,860][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:29:20,860][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,860][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,861][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,861][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,861][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,861][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,861][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:29:20,861][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,861][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,862][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,862][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,862][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,862][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,862][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:29:20,862][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,863][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,863][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,863][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,863][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,863][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,863][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:29:20,864][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,864][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,864][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,864][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,864][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,864][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,865][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:29:20,865][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,865][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,865][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,865][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,865][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit7', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,866][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,866][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,866][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:29:20,866][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,866][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,866][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,866][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,867][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,867][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,867][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,867][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:29:20,867][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,867][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:29:20,868][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,868][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,868][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,868][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,868][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit27']
[2024-07-24 10:29:20,868][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:29:20,868][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit17', 'circuit19']
[2024-07-24 10:29:20,869][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,869][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,869][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,869][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,869][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,869][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,870][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:29:20,870][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,870][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,870][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:29:20,870][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,870][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,870][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,871][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,871][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:29:20,871][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit24']
[2024-07-24 10:29:20,871][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,871][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,871][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,872][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,872][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,872][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,872][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:29:20,872][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,872][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,873][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,873][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,873][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,873][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,873][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,873][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:29:20,873][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit22', 'circuit24']
[2024-07-24 10:29:20,874][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit18']
[2024-07-24 10:29:20,874][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,874][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,874][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,874][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:29:20,874][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,875][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:29:20,875][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,875][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,875][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,875][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,875][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,875][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,876][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,876][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:29:20,876][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,876][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,876][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,876][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,877][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,877][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,877][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,877][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:29:20,877][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:29:20,877][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,877][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,878][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,878][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,878][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,878][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit7']
[2024-07-24 10:29:20,878][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:29:20,878][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,879][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,879][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit27']
[2024-07-24 10:29:20,879][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,879][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,879][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,879][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,879][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:29:20,880][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:29:20,880][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,880][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,880][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21']
[2024-07-24 10:29:20,880][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,880][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,881][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,881][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:29:20,881][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,881][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,881][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,881][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,882][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit28']
[2024-07-24 10:29:20,882][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit8', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,882][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit18', 'circuit19', 'circuit21', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,882][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:29:20,882][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,882][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,882][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,883][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,883][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,883][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,883][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,883][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:29:20,883][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,884][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,884][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,884][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,884][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,884][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,884][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,884][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:29:20,885][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,885][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,885][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,885][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,885][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,885][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,886][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,886][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:29:20,886][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,886][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,886][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,886][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,887][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,887][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,887][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,887][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:29:20,887][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,887][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,887][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,888][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,888][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,888][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,888][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,888][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:29:20,888][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,889][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,889][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,889][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,889][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,889][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,889][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,889][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:29:20,890][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,890][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,890][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,890][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,890][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,890][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,891][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,891][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:29:20,891][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,891][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,891][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,891][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,891][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,892][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,892][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,892][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:29:20,892][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,892][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,892][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,893][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,893][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,893][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,893][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,893][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:29:20,893][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,893][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,894][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,894][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,894][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,894][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,894][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,894][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:29:20,895][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,895][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,895][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,895][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,895][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,895][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,896][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,896][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:29:20,896][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,896][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,896][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,896][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,896][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,897][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,897][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,897][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:29:20,897][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,897][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,897][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,898][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,898][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,898][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,898][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,898][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:29:20,898][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,899][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,899][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,899][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,899][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,899][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,899][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,899][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:29:20,900][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,900][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,900][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,900][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,900][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,900][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,901][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,901][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:29:20,901][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,901][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,901][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,901][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,902][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,902][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,902][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,902][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit18', 'circuit21', 'circuit23', 'circuit26']
[2024-07-24 10:29:20,902][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:29:20,902][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,903][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,903][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,903][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,903][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,903][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,903][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,903][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,904][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:29:20,904][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,904][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,904][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,904][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,904][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,905][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,905][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,905][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,905][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:29:20,905][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,905][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,905][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,906][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,906][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,906][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,906][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,906][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,906][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:29:20,907][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,907][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,907][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,907][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,907][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,907][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,907][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,908][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,908][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:29:20,908][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,908][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,908][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,908][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,909][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,909][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,909][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,909][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,909][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:29:20,909][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,910][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,910][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,910][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,910][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,910][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,910][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,910][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,911][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:29:20,911][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,911][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,911][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,911][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,911][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,912][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,912][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,912][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,912][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:29:20,912][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,912][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,912][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,913][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,913][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,913][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,913][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,913][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,913][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:29:20,914][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,914][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,914][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,914][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,914][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,914][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,914][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,915][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,915][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:29:20,915][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,915][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,915][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,915][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,916][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,916][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,916][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,916][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,916][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:29:20,916][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,916][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,917][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,917][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,917][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,917][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,917][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,917][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,918][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:29:20,918][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,918][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,918][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,918][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,918][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,919][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,919][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,919][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,919][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:29:20,919][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:20,919][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,919][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit26']
[2024-07-24 10:29:20,920][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,920][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,920][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,920][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit16', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:29:20,920][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit18', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,920][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:29:20,921][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,921][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,921][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,921][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,921][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,921][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,921][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,922][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,922][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:29:20,922][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,922][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,922][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,922][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,923][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,923][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,923][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,923][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,923][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:29:20,923][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,923][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,924][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22']
[2024-07-24 10:29:20,924][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:29:20,924][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:29:20,924][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,924][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,924][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,925][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:29:20,925][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,925][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,925][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,925][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,925][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,925][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,926][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,926][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,926][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:29:20,926][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,926][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,926][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,927][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,927][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,927][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,927][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,927][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,927][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:29:20,928][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,928][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,928][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,928][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,928][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,928][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,928][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,929][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,929][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:29:20,929][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,929][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,929][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,929][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,930][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,930][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,930][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,930][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,930][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:29:20,930][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,930][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,931][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,931][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,931][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,931][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,931][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,931][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,932][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:29:20,932][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,932][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,932][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,932][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,932][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,932][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,933][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,933][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,933][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:29:20,933][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,933][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,933][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,934][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,934][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,934][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,934][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,934][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,934][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:29:20,934][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,935][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,935][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,935][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,935][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,935][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,935][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,936][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,936][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:29:20,936][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,936][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,936][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,936][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,936][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,937][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,937][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,937][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,937][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:29:20,937][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,937][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,938][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,938][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,938][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,938][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,938][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,938][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,939][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:29:20,939][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,939][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,939][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,939][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,939][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,940][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,940][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,940][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,940][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:29:20,940][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,940][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,941][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,941][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,941][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,941][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,941][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,941][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,941][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:29:20,942][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,942][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,942][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,942][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit10', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,942][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,942][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,943][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,943][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit7', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,943][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,943][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:29:20,943][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,943][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,944][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,944][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,944][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,944][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,944][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,944][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,944][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,945][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:29:20,945][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,945][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,945][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,945][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,945][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,946][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,946][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,946][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,946][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,946][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:29:20,946][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,946][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,947][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,947][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,947][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,947][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,947][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,947][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,948][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,948][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:29:20,948][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,948][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,948][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,948][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,949][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,949][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,949][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,949][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,949][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,949][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:29:20,949][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,950][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,950][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,950][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,950][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,950][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,950][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,951][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,951][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,951][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:29:20,951][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,951][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,951][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,951][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,952][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,952][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,952][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,952][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,952][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,952][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:29:20,953][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,953][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,953][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,953][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,953][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,953][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13']
[2024-07-24 10:29:20,953][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit6', 'circuit11']
[2024-07-24 10:29:20,954][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:29:20,954][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:29:20,954][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:29:20,954][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:29:20,954][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,954][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,955][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:20,955][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit2', 'circuit3']
[2024-07-24 10:29:20,955][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit25']
[2024-07-24 10:29:20,955][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit14', 'circuit22', 'circuit25']
[2024-07-24 10:29:20,955][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,955][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,955][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:29:20,956][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:29:20,956][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:29:20,956][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:20,956][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:29:20,956][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:29:20,956][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,957][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit21', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:29:20,957][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,957][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit20', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:29:20,957][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:29:20,957][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,957][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,958][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,958][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit5']
[2024-07-24 10:29:20,958][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit27']
[2024-07-24 10:29:20,958][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13']
[2024-07-24 10:29:20,958][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13']
[2024-07-24 10:29:20,958][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,958][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,959][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:29:20,959][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,959][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,959][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,959][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,959][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,960][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,960][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,960][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,960][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,960][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:29:20,960][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,960][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,961][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,961][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:29:20,961][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,961][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit23']
[2024-07-24 10:29:20,961][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,961][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,962][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:20,962][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:29:20,962][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,962][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,962][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:29:20,962][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,963][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:20,963][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:29:20,963][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit23']
[2024-07-24 10:29:20,963][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,963][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit20', 'circuit23']
[2024-07-24 10:29:20,963][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:29:20,963][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,964][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,964][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,964][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,964][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,964][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,964][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,965][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,965][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,965][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:29:20,965][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,965][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,965][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,965][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,966][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,966][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,966][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,966][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,966][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,966][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:29:20,967][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,967][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,967][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,967][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,967][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,967][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,968][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,968][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,968][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,968][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:29:20,968][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,968][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,968][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,969][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,969][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,969][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,969][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,969][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,969][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,970][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:29:20,970][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,970][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,970][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,970][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,970][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,970][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,971][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,971][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,971][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,971][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:29:20,971][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,971][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,972][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,972][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,972][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,972][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,972][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,972][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,973][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,973][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:29:20,973][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,973][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,973][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,973][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,973][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,974][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,974][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,974][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,974][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,974][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:29:20,974][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,975][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,975][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,975][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,975][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,975][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,975][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,975][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,976][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,976][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:29:20,976][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,976][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,976][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,976][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,977][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,977][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,977][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,977][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,977][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,977][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:29:20,977][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,978][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,978][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,978][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,978][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,978][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,978][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,979][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,979][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,979][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:29:20,979][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,979][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,979][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,979][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,980][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,980][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,980][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,980][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,980][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,980][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:29:20,981][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,981][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,981][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,981][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,981][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,981][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,982][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,982][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,982][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,982][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:29:20,982][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,982][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,982][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,983][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,983][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,983][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,983][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,983][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,983][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,984][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:29:20,984][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,984][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,984][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,984][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,984][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,985][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,985][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,985][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,985][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,985][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:29:20,985][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,986][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,986][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,986][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,986][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,986][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,986][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,987][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,987][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:20,987][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:29:20,987][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,987][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,987][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit28']
[2024-07-24 10:29:20,987][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit8', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,988][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:20,988][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,988][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:20,988][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit7', 'circuit13', 'circuit14', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:20,988][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit16', 'circuit20', 'circuit24']
[2024-07-24 10:29:20,988][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:29:20,989][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:29:20,989][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,989][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,989][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,989][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,989][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,990][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,990][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,990][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,990][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,990][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:20,990][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:29:20,990][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,991][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,991][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,991][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,991][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,991][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,991][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,992][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,992][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,992][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:20,992][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:29:20,992][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,992][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,992][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,993][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,993][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,993][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,993][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,993][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,993][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,994][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:20,994][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:29:20,994][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,994][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,994][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,994][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,995][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,995][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,995][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,995][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,995][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,995][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:20,995][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:29:20,996][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,996][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:20,996][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:20,996][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:20,996][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit18']
[2024-07-24 10:29:20,996][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:20,997][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:29:20,997][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,997][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,997][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:20,997][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:29:20,997][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,997][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:29:20,998][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:20,998][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit6', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:20,998][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:20,998][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:29:20,998][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:20,998][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:20,999][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:20,999][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:29:20,999][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:29:20,999][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:20,999][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:29:20,999][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:29:21,000][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,000][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:29:21,000][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,000][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,000][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:29:21,000][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:29:21,000][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit19', 'circuit23']
[2024-07-24 10:29:21,001][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:29:21,001][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,001][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,001][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,001][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,001][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,002][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,002][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,002][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,002][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,002][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,002][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:29:21,002][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,003][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,003][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,003][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,003][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,003][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,003][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,004][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,004][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,004][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,004][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:29:21,004][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,004][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,005][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,005][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,005][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,005][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,005][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,005][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,005][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,006][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,006][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:29:21,006][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24']
[2024-07-24 10:29:21,006][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,006][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:29:21,006][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:29:21,007][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:29:21,007][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:29:21,007][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:29:21,007][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:29:21,007][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit9', 'circuit10', 'circuit12']
[2024-07-24 10:29:21,007][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:29:21,007][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:29:21,008][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,008][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,008][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,008][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,008][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,008][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,009][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,009][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,009][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,009][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,009][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:29:21,009][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14']
[2024-07-24 10:29:21,009][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:21,010][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit24', 'circuit26']
[2024-07-24 10:29:21,010][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,010][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:21,010][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,010][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,010][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,011][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:29:21,011][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:29:21,011][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:29:21,011][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,011][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,011][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,012][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,012][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,012][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,012][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,012][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,012][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,012][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,013][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:29:21,013][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,013][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,013][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,013][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,013][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,014][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,014][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,014][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,014][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,014][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,014][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:29:21,014][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,015][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,015][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,015][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,015][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,015][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,015][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,016][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,016][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,016][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,016][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:29:21,016][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,016][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,017][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,017][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,017][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,017][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,017][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,017][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,017][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,018][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,018][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:29:21,018][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,018][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,018][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,018][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,019][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,019][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,019][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,019][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,019][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,019][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,019][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:29:21,020][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,020][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,020][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,020][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,020][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,020][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,021][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,021][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,021][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,021][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,021][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:29:21,021][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,021][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,022][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,022][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,022][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,022][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,022][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,022][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,023][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,023][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,023][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:29:21,023][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,023][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,023][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,024][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,024][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,024][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,024][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,024][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,024][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,024][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,025][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:29:21,025][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,025][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,025][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,025][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,025][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,026][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,026][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,026][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,026][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,026][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,026][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:29:21,026][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,027][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,027][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,027][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,027][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,027][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,027][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,028][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,028][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,028][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,028][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:29:21,028][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,028][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,029][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,029][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,029][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,029][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,029][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,029][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,029][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,030][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,030][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:29:21,030][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,030][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,030][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,030][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,031][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,031][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,031][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,031][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,031][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,031][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,031][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:29:21,032][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,032][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,032][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,032][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,032][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,032][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,033][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,033][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,033][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,033][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,033][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:29:21,033][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,034][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,034][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,034][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,034][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,034][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,034][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,035][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,035][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,035][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,035][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:29:21,035][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,035][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,036][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,036][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,036][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,036][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,036][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,036][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,037][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,037][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,037][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:29:21,037][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit27']
[2024-07-24 10:29:21,037][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:29:21,037][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:21,037][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:21,038][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit9', 'circuit11', 'circuit16', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:21,038][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit3', 'circuit6', 'circuit8', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:21,038][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:29:21,038][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit13']
[2024-07-24 10:29:21,038][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit21', 'circuit24', 'circuit26']
[2024-07-24 10:29:21,038][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:21,039][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:21,039][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:29:21,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,039][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,039][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,039][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,040][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,040][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,040][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,040][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,040][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,040][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,040][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:21,041][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:29:21,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,041][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,041][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:29:21,041][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,041][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,042][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,042][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,042][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit14']
[2024-07-24 10:29:21,042][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:29:21,042][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit22', 'circuit25']
[2024-07-24 10:29:21,042][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:29:21,043][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:29:21,043][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:29:21,043][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,043][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,043][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,043][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,043][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,044][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,044][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,044][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,044][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,044][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:21,044][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:29:21,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,045][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,045][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,045][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,045][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,045][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,046][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,046][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,046][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,046][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,046][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:21,046][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:29:21,046][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,047][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,047][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,047][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,047][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,047][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,047][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,048][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,048][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,048][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,048][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:21,048][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:29:21,048][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,048][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,049][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,049][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,049][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,049][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,049][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,049][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,050][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,050][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,050][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:21,050][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:29:21,050][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,050][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,050][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,051][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,051][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,051][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,051][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,051][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,051][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,052][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,052][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:29:21,052][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:29:21,052][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,052][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,052][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,053][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,053][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,053][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,053][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,053][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,053][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,053][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,054][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:21,054][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:29:21,054][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,054][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:21,054][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,054][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,055][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,055][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,055][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,055][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,055][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,055][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,055][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:29:21,056][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:29:21,056][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,056][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,056][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,056][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,056][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,057][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,057][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,057][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,057][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,057][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,057][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:29:21,057][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:29:21,058][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit25']
[2024-07-24 10:29:21,058][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,058][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,058][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,058][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,058][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,059][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,059][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,059][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,059][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,059][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:21,059][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:29:21,060][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,060][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,060][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,060][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,060][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,060][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,060][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,061][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,061][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,061][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit25']
[2024-07-24 10:29:21,061][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:21,061][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:29:21,061][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,062][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:21,062][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit6', 'circuit7', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:29:21,062][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit4', 'circuit5', 'circuit9', 'circuit10', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:21,062][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit5', 'circuit8', 'circuit9', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:29:21,062][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit20']
[2024-07-24 10:29:21,062][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit6', 'circuit14', 'circuit23']
[2024-07-24 10:29:21,063][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,063][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:29:21,063][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit19', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:29:21,063][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit8', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:29:21,063][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:29:21,063][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,063][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,064][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,064][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,064][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,064][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,064][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,064][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,065][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,065][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,065][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:21,065][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:29:21,065][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,065][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,065][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,066][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,066][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,066][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,066][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,066][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,066][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,067][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,067][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:21,067][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:29:21,067][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,067][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,067][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,068][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,068][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,068][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,068][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,068][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,068][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,068][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,069][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:21,069][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:29:21,069][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,069][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,069][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,069][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,070][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,070][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,070][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,070][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,070][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,070][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,070][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:21,071][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:29:21,071][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,071][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,071][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,071][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,071][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,072][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,072][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,072][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,072][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,072][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,072][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:21,072][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:29:21,073][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,073][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,073][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,073][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,073][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,073][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,074][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,074][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,074][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,074][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,074][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:21,074][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:29:21,075][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,075][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,075][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,075][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,075][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,075][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,075][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,076][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,076][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,076][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,076][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:21,076][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:29:21,076][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,077][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,077][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,077][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,077][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,077][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,077][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,077][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,078][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,078][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,078][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:21,078][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:29:21,078][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,078][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,079][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,079][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,079][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,079][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,079][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,079][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,080][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,080][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,080][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:21,080][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:29:21,080][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,080][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,080][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,081][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,081][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,081][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,081][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,081][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,081][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,082][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,082][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:21,082][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:29:21,082][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,082][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,082][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,082][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,083][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,083][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,083][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,083][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,083][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,083][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,084][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:21,084][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:29:21,084][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:29:21,084][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:29:21,084][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:29:21,084][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:29:21,084][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:29:21,085][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:29:21,085][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:29:21,085][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:29:21,085][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:29:21,085][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:29:21,085][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:29:21,086][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:29:21,086][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,086][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,086][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,086][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,086][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,087][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,087][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,087][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,087][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,087][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,087][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,088][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:29:21,088][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,088][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,088][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,088][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,088][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,089][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,089][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,089][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,089][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,089][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,089][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,089][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:29:21,090][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,090][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,090][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,090][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,090][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,090][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,091][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,091][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,091][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,091][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:21,091][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:22,504][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:22,506][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:22,510][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:22,513][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:22,515][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:22,515][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:22,515][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:22,516][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:22,516][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:22,516][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:22,516][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:22,517][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:22,517][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:22,517][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:22,518][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:22,518][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:22,519][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:22,522][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:22,526][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:22,531][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:22,531][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:22,531][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:22,531][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:22,532][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:22,532][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:22,532][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Jennifer] are: tensor([0.4096, 0.3195, 0.2710], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:22,533][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Jennifer] are: tensor([1.1400e-04, 1.5100e-04, 9.9973e-01], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:22,533][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Jennifer] are: tensor([0.4937, 0.2494, 0.2569], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:22,533][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Jennifer] are: tensor([2.9770e-02, 3.5599e-04, 9.6987e-01], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:22,533][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Jennifer] are: tensor([0.0989, 0.0100, 0.8911], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:22,534][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Jennifer] are: tensor([9.6425e-03, 5.1053e-06, 9.9035e-01], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:22,535][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Jennifer] are: tensor([0.4367, 0.3075, 0.2558], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:22,539][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Jennifer] are: tensor([0.5048, 0.3961, 0.0991], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:22,542][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Jennifer] are: tensor([0.6050, 0.2910, 0.1040], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:22,546][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Jennifer] are: tensor([0.6361, 0.3095, 0.0543], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:22,549][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Jennifer] are: tensor([0.4456, 0.2661, 0.2883], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:22,549][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Jennifer] are: tensor([0.4622, 0.3692, 0.1685], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:22,549][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.6679, 0.0757, 0.1974, 0.0590], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:22,550][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.3027e-03, 3.9251e-02, 3.9782e-04, 9.5805e-01], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:22,550][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2404, 0.1800, 0.0258, 0.5538], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:22,550][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1116, 0.3814, 0.0405, 0.4666], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:22,550][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2983, 0.1352, 0.3217, 0.2448], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:22,551][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1230, 0.1969, 0.0076, 0.6725], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:22,551][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.5628, 0.0269, 0.3899, 0.0204], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:22,551][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2084, 0.1585, 0.3945, 0.2386], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:22,552][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0669, 0.4683, 0.0257, 0.4391], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:22,553][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4316, 0.2410, 0.1036, 0.2239], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:22,556][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4142, 0.3085, 0.0737, 0.2035], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:22,560][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4462, 0.1949, 0.1043, 0.2546], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:22,564][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Megan] are: tensor([0.2262, 0.2328, 0.1119, 0.2130, 0.2161], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:22,565][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Megan] are: tensor([6.4521e-05, 1.6054e-05, 1.8523e-03, 3.0505e-05, 9.9804e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:22,565][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Megan] are: tensor([0.3621, 0.2882, 0.1146, 0.1334, 0.1016], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:22,565][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Megan] are: tensor([2.1761e-02, 6.9288e-05, 1.3311e-02, 1.8703e-04, 9.6467e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:22,566][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Megan] are: tensor([0.0368, 0.0042, 0.1031, 0.0027, 0.8532], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:22,566][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Megan] are: tensor([7.3223e-04, 6.0556e-08, 1.0456e-04, 4.9237e-08, 9.9916e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:22,566][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Megan] are: tensor([0.2032, 0.2986, 0.1885, 0.1309, 0.1788], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:22,567][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Megan] are: tensor([0.2295, 0.2232, 0.0561, 0.3756, 0.1156], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:22,567][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Megan] are: tensor([0.3039, 0.2375, 0.1409, 0.2186, 0.0992], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:22,567][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Megan] are: tensor([0.3777, 0.2342, 0.1640, 0.2003, 0.0239], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:22,567][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Megan] are: tensor([0.2760, 0.2030, 0.1529, 0.1409, 0.2272], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:22,569][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Megan] are: tensor([0.2566, 0.2061, 0.0764, 0.3298, 0.1311], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:22,572][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.4195, 0.0369, 0.0952, 0.0367, 0.0884, 0.3232], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:22,574][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ had] are: tensor([3.2219e-04, 1.6755e-03, 2.8132e-04, 2.8619e-03, 9.5066e-05, 9.9476e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:22,578][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.4714, 0.1202, 0.0779, 0.1422, 0.0474, 0.1409], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:22,580][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0049, 0.0054, 0.0027, 0.0115, 0.0019, 0.9736], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:22,581][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2325, 0.0661, 0.0514, 0.1197, 0.0365, 0.4937], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:22,581][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ had] are: tensor([3.9825e-02, 1.8584e-03, 2.5954e-04, 1.2920e-03, 2.8840e-05, 9.5674e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:22,581][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2636, 0.0197, 0.3821, 0.0185, 0.2897, 0.0264], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:22,582][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1395, 0.1086, 0.0706, 0.2521, 0.1155, 0.3136], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:22,582][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0942, 0.2646, 0.0462, 0.3475, 0.0325, 0.2150], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:22,582][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.3148, 0.1898, 0.0904, 0.1956, 0.0771, 0.1322], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:22,583][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.2513, 0.1938, 0.0722, 0.1419, 0.0325, 0.3082], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:22,583][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.4307, 0.1438, 0.0678, 0.1794, 0.0876, 0.0907], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:22,583][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.4620, 0.0532, 0.1830, 0.0402, 0.1596, 0.0663, 0.0357],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:22,584][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([8.5587e-04, 4.3013e-03, 6.6129e-04, 4.2992e-03, 9.7541e-04, 4.6844e-04,
        9.8844e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:22,587][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.3094, 0.1919, 0.0571, 0.2263, 0.0393, 0.1281, 0.0478],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:22,590][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0288, 0.0177, 0.0130, 0.0325, 0.0270, 0.1759, 0.7050],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:22,594][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1414, 0.0311, 0.0606, 0.0438, 0.0674, 0.4420, 0.2138],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:22,596][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0561, 0.1299, 0.0020, 0.0972, 0.0019, 0.0449, 0.6679],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:22,596][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2933, 0.0097, 0.3262, 0.0083, 0.3097, 0.0431, 0.0095],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:22,597][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0903, 0.0543, 0.0707, 0.1213, 0.1796, 0.2036, 0.2802],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:22,597][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0238, 0.1297, 0.0109, 0.1926, 0.0155, 0.1408, 0.4867],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:22,597][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2604, 0.1667, 0.0895, 0.1692, 0.0757, 0.1049, 0.1335],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:22,598][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2220, 0.1893, 0.0719, 0.1605, 0.0522, 0.0822, 0.2219],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:22,598][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.3383, 0.1356, 0.0843, 0.1456, 0.0966, 0.0874, 0.1122],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:22,598][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.3094, 0.0740, 0.1179, 0.0686, 0.1154, 0.1274, 0.0972, 0.0901],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:22,599][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ long] are: tensor([2.8471e-04, 9.8960e-04, 5.7810e-04, 1.4117e-03, 1.7100e-04, 3.2535e-03,
        9.3884e-04, 9.9237e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:22,599][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.3122, 0.1609, 0.0745, 0.1627, 0.0542, 0.1136, 0.0813, 0.0404],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:22,600][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ long] are: tensor([6.5196e-03, 4.6007e-04, 2.1169e-04, 8.0361e-04, 2.3856e-04, 9.1072e-03,
        7.2552e-03, 9.7540e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:22,603][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.1035, 0.0236, 0.0284, 0.0309, 0.0179, 0.1545, 0.0818, 0.5594],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:22,605][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ long] are: tensor([5.4046e-03, 1.8792e-04, 4.9168e-05, 1.0306e-04, 3.6218e-05, 1.9185e-04,
        8.2377e-05, 9.9394e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:22,608][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.2594, 0.0279, 0.2996, 0.0194, 0.2556, 0.0430, 0.0201, 0.0751],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:22,612][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.1009, 0.0439, 0.0506, 0.0921, 0.0761, 0.1850, 0.3416, 0.1097],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:22,612][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.1167, 0.1168, 0.0583, 0.1484, 0.0810, 0.1437, 0.2920, 0.0432],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:22,613][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.2402, 0.1571, 0.0812, 0.1520, 0.0782, 0.0927, 0.1332, 0.0654],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:22,613][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.2195, 0.1554, 0.0642, 0.1089, 0.0386, 0.0755, 0.0854, 0.2526],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:22,613][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.3678, 0.0990, 0.0819, 0.1232, 0.0978, 0.0610, 0.0624, 0.1069],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:22,614][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.3650, 0.0873, 0.1634, 0.0688, 0.0480, 0.0745, 0.0586, 0.0744, 0.0601],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:22,614][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([1.8548e-03, 3.0734e-04, 2.6852e-03, 2.0890e-04, 5.0250e-04, 3.4842e-04,
        1.9498e-04, 3.4300e-05, 9.9386e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:22,614][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.3063, 0.1041, 0.0599, 0.0763, 0.0817, 0.1003, 0.1175, 0.0971, 0.0568],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:22,615][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([3.3839e-03, 4.0869e-05, 7.8008e-04, 9.1236e-05, 9.5153e-04, 2.4684e-04,
        6.2935e-04, 4.3039e-03, 9.8957e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:22,615][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.1319, 0.0060, 0.0140, 0.0051, 0.0126, 0.0160, 0.0135, 0.1768, 0.6242],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:22,616][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([1.2028e-02, 1.5133e-05, 6.6477e-05, 4.1248e-06, 3.3238e-05, 2.0253e-06,
        1.5989e-06, 6.3675e-07, 9.8785e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:22,619][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.1623, 0.0422, 0.2546, 0.0368, 0.2175, 0.0278, 0.0299, 0.0670, 0.1620],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:22,622][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0921, 0.0528, 0.0075, 0.0983, 0.0315, 0.1355, 0.2162, 0.2602, 0.1059],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:22,626][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.2506, 0.0968, 0.0611, 0.1133, 0.0480, 0.2363, 0.1210, 0.0653, 0.0076],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:22,628][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.2231, 0.1299, 0.0968, 0.1217, 0.0956, 0.1057, 0.1088, 0.0785, 0.0398],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:22,628][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.2096, 0.1306, 0.0814, 0.1103, 0.0343, 0.0753, 0.0728, 0.0382, 0.2476],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:22,628][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.3011, 0.1335, 0.1128, 0.0967, 0.0930, 0.0382, 0.0369, 0.0815, 0.1062],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:22,629][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4530, 0.0156, 0.1045, 0.0181, 0.0930, 0.0802, 0.0347, 0.0644, 0.1234,
        0.0132], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:22,629][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([1.8445e-03, 4.4358e-01, 1.0590e-04, 1.1171e-02, 6.5480e-05, 3.9672e-04,
        1.7962e-04, 5.1707e-05, 7.8252e-06, 5.4260e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:22,629][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2004, 0.3154, 0.0165, 0.0771, 0.0157, 0.0367, 0.0076, 0.0102, 0.0101,
        0.3102], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:22,630][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0331, 0.0077, 0.0023, 0.0077, 0.0041, 0.0606, 0.0497, 0.0551, 0.0864,
        0.6933], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:22,630][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2654, 0.0257, 0.0492, 0.0222, 0.0563, 0.1282, 0.0313, 0.1096, 0.0460,
        0.2662], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:22,630][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0974, 0.3440, 0.0124, 0.1241, 0.0065, 0.0690, 0.1021, 0.0301, 0.0101,
        0.2043], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:22,632][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2408, 0.0071, 0.2631, 0.0069, 0.2757, 0.0225, 0.0088, 0.0581, 0.1123,
        0.0047], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:22,635][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0372, 0.0140, 0.0260, 0.0381, 0.0614, 0.0696, 0.1110, 0.1456, 0.1391,
        0.3580], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:22,639][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0192, 0.1649, 0.0064, 0.1851, 0.0057, 0.0642, 0.1660, 0.0292, 0.0076,
        0.3517], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:22,642][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2120, 0.1212, 0.0748, 0.1260, 0.0602, 0.0850, 0.0926, 0.0692, 0.0559,
        0.1031], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:22,644][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1667, 0.1534, 0.0881, 0.1409, 0.0682, 0.0912, 0.0883, 0.0566, 0.0404,
        0.1063], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:22,644][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2473, 0.0956, 0.0638, 0.1085, 0.0814, 0.0690, 0.0657, 0.0803, 0.0747,
        0.1137], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:22,644][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3453, 0.0282, 0.1278, 0.0242, 0.0931, 0.0679, 0.0410, 0.0902, 0.1254,
        0.0276, 0.0294], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:22,645][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([1.0615e-03, 1.2476e-02, 8.2885e-05, 5.1187e-01, 7.6052e-05, 6.9045e-04,
        2.3420e-04, 1.8327e-04, 8.4971e-06, 7.4679e-03, 4.6585e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:22,645][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0841, 0.0629, 0.0120, 0.3149, 0.0168, 0.0438, 0.0176, 0.0150, 0.0235,
        0.0559, 0.3536], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:22,645][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([1.0822e-02, 6.0654e-03, 2.6019e-04, 3.9888e-03, 3.3736e-04, 7.8478e-03,
        1.3926e-02, 1.5640e-02, 7.4102e-03, 4.9309e-01, 4.4061e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:22,646][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0354, 0.0130, 0.0168, 0.0246, 0.0100, 0.1617, 0.0656, 0.1196, 0.1774,
        0.1214, 0.2545], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:22,646][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0326, 0.0871, 0.0042, 0.3873, 0.0037, 0.0542, 0.1209, 0.0254, 0.0037,
        0.0306, 0.2502], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:22,646][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2082, 0.0084, 0.2437, 0.0080, 0.2660, 0.0264, 0.0097, 0.0736, 0.1409,
        0.0064, 0.0089], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:22,648][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0329, 0.0119, 0.0246, 0.0199, 0.0324, 0.0421, 0.0633, 0.0791, 0.0975,
        0.2437, 0.3525], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:22,651][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0115, 0.1002, 0.0057, 0.1175, 0.0042, 0.0609, 0.2000, 0.0256, 0.0109,
        0.2626, 0.2009], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:22,655][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1744, 0.1088, 0.0601, 0.1098, 0.0595, 0.0760, 0.0873, 0.0587, 0.0574,
        0.0962, 0.1119], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:22,659][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1425, 0.1290, 0.0603, 0.1372, 0.0476, 0.0964, 0.0974, 0.0517, 0.0348,
        0.0936, 0.1096], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:22,660][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2179, 0.0888, 0.0562, 0.1023, 0.0679, 0.0531, 0.0472, 0.0611, 0.0779,
        0.1123, 0.1153], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:22,660][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.2368, 0.0431, 0.0621, 0.0478, 0.1372, 0.1257, 0.0490, 0.0344, 0.1511,
        0.0374, 0.0570, 0.0182], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:22,660][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([1.7337e-03, 4.1580e-04, 1.1243e-03, 1.5533e-04, 5.2641e-03, 1.7303e-04,
        8.9815e-05, 1.4283e-04, 6.0347e-04, 9.1969e-05, 7.0472e-05, 9.9014e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:22,661][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.2494, 0.0815, 0.0583, 0.0774, 0.0888, 0.1574, 0.0646, 0.0570, 0.0329,
        0.0517, 0.0623, 0.0187], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:22,661][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([1.2696e-02, 5.1819e-05, 5.4890e-05, 7.2038e-05, 5.6860e-05, 1.1423e-03,
        2.1231e-04, 3.4376e-03, 1.4255e-03, 2.2504e-03, 4.8180e-03, 9.7378e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:22,661][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0421, 0.0034, 0.0042, 0.0070, 0.0041, 0.0114, 0.0109, 0.0294, 0.0154,
        0.0128, 0.0438, 0.8156], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:22,662][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([9.2453e-02, 4.3741e-06, 9.2391e-05, 1.6933e-06, 1.4385e-04, 4.4306e-06,
        4.7550e-07, 4.6483e-06, 5.0048e-06, 9.8434e-08, 2.7242e-07, 9.0729e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:22,662][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.1303, 0.0545, 0.1390, 0.0406, 0.1954, 0.0340, 0.0578, 0.0508, 0.1171,
        0.0482, 0.0446, 0.0877], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:22,664][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0537, 0.0193, 0.0021, 0.0297, 0.0064, 0.0342, 0.0726, 0.0498, 0.0281,
        0.1957, 0.3985, 0.1099], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:22,666][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0976, 0.1102, 0.0204, 0.1395, 0.0243, 0.0394, 0.1219, 0.0365, 0.0999,
        0.1299, 0.1674, 0.0129], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:22,670][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.1739, 0.0983, 0.0723, 0.0903, 0.0687, 0.0748, 0.0659, 0.0564, 0.0853,
        0.0834, 0.0907, 0.0399], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:22,673][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.1900, 0.0923, 0.0514, 0.0884, 0.0469, 0.0827, 0.0549, 0.0513, 0.0385,
        0.0658, 0.0684, 0.1694], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:22,675][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.1815, 0.1439, 0.0563, 0.0954, 0.0509, 0.0328, 0.0420, 0.0423, 0.0386,
        0.1645, 0.1024, 0.0494], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:22,676][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Megan] are: tensor([0.1095, 0.0869, 0.0552, 0.0849, 0.1216, 0.0249, 0.0488, 0.0174, 0.0538,
        0.0841, 0.0979, 0.0680, 0.1470], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:22,676][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Megan] are: tensor([2.8914e-05, 3.5067e-06, 5.5019e-04, 8.1162e-06, 5.0665e-01, 4.1697e-07,
        8.1918e-06, 1.2547e-06, 2.0589e-06, 6.4161e-07, 3.4824e-06, 1.3934e-05,
        4.9273e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:22,676][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Megan] are: tensor([0.1710, 0.1212, 0.0607, 0.0707, 0.0727, 0.0973, 0.0719, 0.0214, 0.0293,
        0.0827, 0.0660, 0.0621, 0.0730], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:22,677][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Megan] are: tensor([1.9930e-03, 6.9106e-07, 8.9685e-05, 8.0916e-07, 7.6532e-03, 1.5562e-05,
        6.6780e-06, 4.3371e-05, 2.1275e-04, 2.6698e-05, 5.3416e-05, 1.6343e-03,
        9.8827e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:22,677][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Megan] are: tensor([6.5687e-03, 4.6202e-04, 7.9978e-03, 2.3410e-04, 7.1045e-02, 5.7579e-04,
        4.8392e-04, 1.1699e-03, 1.9301e-03, 2.4942e-03, 1.8317e-03, 6.3756e-03,
        8.9883e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:22,677][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Megan] are: tensor([1.9937e-04, 1.2760e-08, 4.9676e-05, 1.1701e-08, 5.7705e-01, 9.8532e-10,
        2.0812e-09, 2.6393e-09, 1.7504e-08, 4.8554e-10, 2.4218e-09, 3.8602e-08,
        4.2270e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:22,678][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Megan] are: tensor([0.1004, 0.1361, 0.1194, 0.0668, 0.1331, 0.0199, 0.0502, 0.0357, 0.0289,
        0.1009, 0.0579, 0.0219, 0.1288], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:22,678][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Megan] are: tensor([0.0692, 0.0255, 0.0052, 0.0343, 0.0099, 0.0312, 0.0556, 0.0327, 0.0692,
        0.1632, 0.2840, 0.1226, 0.0974], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:22,680][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Megan] are: tensor([0.1242, 0.0886, 0.0656, 0.0949, 0.0534, 0.0548, 0.0605, 0.0386, 0.1481,
        0.0899, 0.1032, 0.0175, 0.0606], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:22,682][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Megan] are: tensor([0.1777, 0.1126, 0.0990, 0.1013, 0.0139, 0.0541, 0.0737, 0.0643, 0.0472,
        0.0892, 0.0988, 0.0540, 0.0142], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:22,686][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Megan] are: tensor([0.0962, 0.0733, 0.0971, 0.0725, 0.2163, 0.0391, 0.0529, 0.0254, 0.0179,
        0.0558, 0.0534, 0.0224, 0.1777], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:22,691][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Megan] are: tensor([0.0826, 0.0651, 0.0266, 0.0919, 0.0451, 0.0755, 0.0771, 0.0704, 0.0703,
        0.0774, 0.1246, 0.1300, 0.0634], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:22,691][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.3203, 0.0277, 0.0854, 0.0160, 0.0749, 0.0584, 0.0171, 0.0424, 0.0408,
        0.0273, 0.0170, 0.0928, 0.1086, 0.0713], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:22,692][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ said] are: tensor([1.4427e-03, 3.5465e-03, 9.0441e-04, 1.1993e-03, 1.4333e-03, 8.4789e-03,
        1.4028e-03, 4.5720e-05, 1.5898e-03, 1.5486e-03, 7.2123e-04, 1.1223e-04,
        1.0631e-03, 9.7651e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:22,692][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.2285, 0.0511, 0.0344, 0.0441, 0.0164, 0.1051, 0.0347, 0.0254, 0.0500,
        0.0422, 0.0411, 0.0413, 0.0165, 0.2692], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:22,692][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ said] are: tensor([1.9982e-03, 7.3908e-05, 3.2254e-05, 5.5018e-05, 5.0299e-05, 3.0972e-04,
        4.3030e-04, 4.8914e-04, 1.2609e-03, 2.5534e-03, 3.5693e-03, 1.3245e-03,
        4.5448e-03, 9.8331e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:22,693][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0828, 0.0126, 0.0092, 0.0180, 0.0083, 0.0257, 0.0209, 0.0243, 0.0412,
        0.0543, 0.1154, 0.0233, 0.0617, 0.5022], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:22,693][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ said] are: tensor([1.2074e-02, 2.4341e-03, 4.1700e-04, 8.9048e-04, 8.4720e-05, 8.6967e-03,
        2.0759e-04, 2.9474e-05, 6.7242e-04, 2.4881e-04, 2.8118e-04, 6.2009e-06,
        3.0112e-05, 9.7393e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:22,693][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.1447, 0.0071, 0.2263, 0.0071, 0.1636, 0.0095, 0.0058, 0.0259, 0.0683,
        0.0054, 0.0070, 0.0991, 0.2162, 0.0140], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:22,694][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0269, 0.0051, 0.0089, 0.0086, 0.0167, 0.0116, 0.0245, 0.0106, 0.0168,
        0.0890, 0.1390, 0.1432, 0.3585, 0.1406], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:22,696][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0504, 0.1042, 0.0156, 0.1023, 0.0284, 0.0996, 0.1347, 0.0307, 0.0272,
        0.1725, 0.1350, 0.0244, 0.0385, 0.0365], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:22,698][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.1481, 0.0796, 0.0611, 0.0818, 0.0437, 0.0655, 0.0623, 0.0462, 0.0543,
        0.0740, 0.0847, 0.0550, 0.0490, 0.0947], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:22,702][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0994, 0.0717, 0.0547, 0.0756, 0.0407, 0.0779, 0.0584, 0.0245, 0.0468,
        0.0606, 0.0652, 0.0279, 0.0350, 0.2616], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:22,707][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.2451, 0.0583, 0.0571, 0.0779, 0.0521, 0.0373, 0.0313, 0.0563, 0.0668,
        0.0619, 0.0791, 0.0821, 0.0555, 0.0393], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:22,707][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2676, 0.0259, 0.0617, 0.0217, 0.0618, 0.0698, 0.0233, 0.0377, 0.0745,
        0.0259, 0.0265, 0.0862, 0.0892, 0.1111, 0.0171], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:22,707][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([4.1213e-03, 1.1779e-02, 9.8850e-05, 3.4316e-02, 1.3775e-04, 3.0534e-04,
        1.4492e-03, 1.7847e-04, 5.7932e-05, 8.2845e-03, 3.0206e-02, 2.4505e-04,
        9.7587e-05, 1.4515e-04, 9.0858e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:22,708][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1613, 0.0709, 0.0258, 0.0974, 0.0225, 0.0592, 0.0254, 0.0380, 0.0310,
        0.0605, 0.0959, 0.0394, 0.0231, 0.0753, 0.1743], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:22,708][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([2.9462e-03, 2.6597e-04, 4.6579e-05, 1.8226e-04, 3.5623e-05, 7.2950e-04,
        1.2066e-03, 2.4263e-04, 1.1486e-03, 7.2038e-03, 1.1945e-02, 1.6583e-02,
        3.2123e-03, 2.9353e-01, 6.6072e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:22,708][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0355, 0.0023, 0.0027, 0.0038, 0.0023, 0.0336, 0.0103, 0.0260, 0.0567,
        0.0122, 0.0313, 0.0725, 0.0240, 0.4119, 0.2750], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:22,709][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0434, 0.0613, 0.0012, 0.0784, 0.0017, 0.0312, 0.2267, 0.0344, 0.0048,
        0.0212, 0.0413, 0.0007, 0.0008, 0.0327, 0.4202], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:22,709][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1212, 0.0058, 0.0576, 0.0050, 0.0858, 0.0170, 0.0048, 0.0314, 0.0541,
        0.0043, 0.0063, 0.1103, 0.1422, 0.0325, 0.3216], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:22,710][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0212, 0.0040, 0.0046, 0.0066, 0.0088, 0.0086, 0.0114, 0.0176, 0.0257,
        0.0471, 0.0763, 0.0895, 0.1692, 0.2474, 0.2619], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:22,711][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0080, 0.0593, 0.0050, 0.1033, 0.0048, 0.0465, 0.1308, 0.0197, 0.0089,
        0.1504, 0.1810, 0.0048, 0.0074, 0.0337, 0.2363], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:22,714][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1195, 0.0741, 0.0434, 0.0815, 0.0397, 0.0544, 0.0693, 0.0476, 0.0428,
        0.0699, 0.0855, 0.0459, 0.0448, 0.0830, 0.0986], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:22,718][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1005, 0.0826, 0.0419, 0.0989, 0.0357, 0.0733, 0.0842, 0.0495, 0.0328,
        0.0750, 0.0913, 0.0271, 0.0323, 0.0632, 0.1117], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:22,722][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1771, 0.0700, 0.0462, 0.0719, 0.0542, 0.0499, 0.0453, 0.0532, 0.0533,
        0.0720, 0.0683, 0.0736, 0.0564, 0.0366, 0.0722], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:22,736][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:22,739][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:22,741][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:22,742][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:22,742][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:22,742][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:22,743][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:22,743][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:22,743][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:22,743][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:22,744][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:22,744][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:22,744][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:22,745][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:22,745][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:22,745][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:22,746][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:22,746][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:22,746][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:22,747][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:22,747][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:22,752][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:22,752][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:22,752][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:22,753][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:22,753][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Jennifer] are: tensor([0.4096, 0.3195, 0.2710], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:22,753][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Jennifer] are: tensor([1.1400e-04, 1.5100e-04, 9.9973e-01], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:22,754][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Jennifer] are: tensor([0.4937, 0.2494, 0.2569], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:22,754][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Jennifer] are: tensor([2.9770e-02, 3.5599e-04, 9.6987e-01], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:22,754][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Jennifer] are: tensor([0.0989, 0.0100, 0.8911], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:22,755][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Jennifer] are: tensor([9.6425e-03, 5.1053e-06, 9.9035e-01], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:22,756][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Jennifer] are: tensor([0.4367, 0.3075, 0.2558], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:22,759][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Jennifer] are: tensor([0.5048, 0.3961, 0.0991], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:22,763][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Jennifer] are: tensor([0.6050, 0.2910, 0.1040], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:22,767][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Jennifer] are: tensor([0.6361, 0.3095, 0.0543], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:22,768][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Jennifer] are: tensor([0.4456, 0.2661, 0.2883], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:22,768][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Jennifer] are: tensor([0.4622, 0.3692, 0.1685], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:22,768][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6679, 0.0757, 0.1974, 0.0590], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:22,769][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.3027e-03, 3.9251e-02, 3.9782e-04, 9.5805e-01], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:22,769][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2404, 0.1800, 0.0258, 0.5538], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:22,769][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1116, 0.3814, 0.0405, 0.4666], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:22,770][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2983, 0.1352, 0.3217, 0.2448], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:22,770][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1230, 0.1969, 0.0076, 0.6725], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:22,770][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.5628, 0.0269, 0.3899, 0.0204], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:22,772][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2084, 0.1585, 0.3945, 0.2386], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:22,775][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0669, 0.4683, 0.0257, 0.4391], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:22,779][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4316, 0.2410, 0.1036, 0.2239], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:22,783][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4142, 0.3085, 0.0737, 0.2035], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:22,783][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4462, 0.1949, 0.1043, 0.2546], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:22,784][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Megan] are: tensor([0.2262, 0.2328, 0.1119, 0.2130, 0.2161], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:22,784][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Megan] are: tensor([6.4521e-05, 1.6054e-05, 1.8523e-03, 3.0505e-05, 9.9804e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:22,784][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Megan] are: tensor([0.3621, 0.2882, 0.1146, 0.1334, 0.1016], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:22,785][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Megan] are: tensor([2.1761e-02, 6.9288e-05, 1.3311e-02, 1.8703e-04, 9.6467e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:22,785][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Megan] are: tensor([0.0368, 0.0042, 0.1031, 0.0027, 0.8532], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:22,785][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Megan] are: tensor([7.3223e-04, 6.0556e-08, 1.0456e-04, 4.9237e-08, 9.9916e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:22,785][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Megan] are: tensor([0.2032, 0.2986, 0.1885, 0.1309, 0.1788], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:22,786][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Megan] are: tensor([0.2295, 0.2232, 0.0561, 0.3756, 0.1156], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:22,786][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Megan] are: tensor([0.3039, 0.2375, 0.1409, 0.2186, 0.0992], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:22,788][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Megan] are: tensor([0.3777, 0.2342, 0.1640, 0.2003, 0.0239], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:22,790][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Megan] are: tensor([0.2760, 0.2030, 0.1529, 0.1409, 0.2272], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:22,794][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Megan] are: tensor([0.2566, 0.2061, 0.0764, 0.3298, 0.1311], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:22,797][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.4195, 0.0369, 0.0952, 0.0367, 0.0884, 0.3232], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:22,799][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([3.2219e-04, 1.6755e-03, 2.8132e-04, 2.8619e-03, 9.5066e-05, 9.9476e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:22,799][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.4714, 0.1202, 0.0779, 0.1422, 0.0474, 0.1409], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:22,800][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0049, 0.0054, 0.0027, 0.0115, 0.0019, 0.9736], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:22,800][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.2325, 0.0661, 0.0514, 0.1197, 0.0365, 0.4937], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:22,800][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([3.9825e-02, 1.8584e-03, 2.5954e-04, 1.2920e-03, 2.8840e-05, 9.5674e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:22,801][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.2636, 0.0197, 0.3821, 0.0185, 0.2897, 0.0264], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:22,801][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1395, 0.1086, 0.0706, 0.2521, 0.1155, 0.3136], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:22,801][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0942, 0.2646, 0.0462, 0.3475, 0.0325, 0.2150], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:22,801][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.3148, 0.1898, 0.0904, 0.1956, 0.0771, 0.1322], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:22,802][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.2513, 0.1938, 0.0722, 0.1419, 0.0325, 0.3082], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:22,803][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.4307, 0.1438, 0.0678, 0.1794, 0.0876, 0.0907], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:22,806][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4620, 0.0532, 0.1830, 0.0402, 0.1596, 0.0663, 0.0357],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:22,808][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([8.5587e-04, 4.3013e-03, 6.6129e-04, 4.2992e-03, 9.7541e-04, 4.6844e-04,
        9.8844e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:22,812][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.3094, 0.1919, 0.0571, 0.2263, 0.0393, 0.1281, 0.0478],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:22,815][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0288, 0.0177, 0.0130, 0.0325, 0.0270, 0.1759, 0.7050],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:22,815][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1414, 0.0311, 0.0606, 0.0438, 0.0674, 0.4420, 0.2138],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:22,815][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0561, 0.1299, 0.0020, 0.0972, 0.0019, 0.0449, 0.6679],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:22,816][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2933, 0.0097, 0.3262, 0.0083, 0.3097, 0.0431, 0.0095],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:22,816][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0903, 0.0543, 0.0707, 0.1213, 0.1796, 0.2036, 0.2802],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:22,816][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0238, 0.1297, 0.0109, 0.1926, 0.0155, 0.1408, 0.4867],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:22,817][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2604, 0.1667, 0.0895, 0.1692, 0.0757, 0.1049, 0.1335],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:22,817][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2220, 0.1893, 0.0719, 0.1605, 0.0522, 0.0822, 0.2219],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:22,817][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3383, 0.1356, 0.0843, 0.1456, 0.0966, 0.0874, 0.1122],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:22,818][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.3094, 0.0740, 0.1179, 0.0686, 0.1154, 0.1274, 0.0972, 0.0901],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:22,819][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([2.8471e-04, 9.8960e-04, 5.7810e-04, 1.4117e-03, 1.7100e-04, 3.2535e-03,
        9.3884e-04, 9.9237e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:22,821][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.3122, 0.1609, 0.0745, 0.1627, 0.0542, 0.1136, 0.0813, 0.0404],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:22,823][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([6.5196e-03, 4.6007e-04, 2.1169e-04, 8.0361e-04, 2.3856e-04, 9.1072e-03,
        7.2552e-03, 9.7540e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:22,827][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.1035, 0.0236, 0.0284, 0.0309, 0.0179, 0.1545, 0.0818, 0.5594],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:22,829][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([5.4046e-03, 1.8792e-04, 4.9168e-05, 1.0306e-04, 3.6218e-05, 1.9185e-04,
        8.2377e-05, 9.9394e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:22,831][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.2594, 0.0279, 0.2996, 0.0194, 0.2556, 0.0430, 0.0201, 0.0751],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:22,831][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.1009, 0.0439, 0.0506, 0.0921, 0.0761, 0.1850, 0.3416, 0.1097],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:22,831][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.1167, 0.1168, 0.0583, 0.1484, 0.0810, 0.1437, 0.2920, 0.0432],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:22,832][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.2402, 0.1571, 0.0812, 0.1520, 0.0782, 0.0927, 0.1332, 0.0654],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:22,832][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.2195, 0.1554, 0.0642, 0.1089, 0.0386, 0.0755, 0.0854, 0.2526],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:22,832][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.3678, 0.0990, 0.0819, 0.1232, 0.0978, 0.0610, 0.0624, 0.1069],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:22,833][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.3650, 0.0873, 0.1634, 0.0688, 0.0480, 0.0745, 0.0586, 0.0744, 0.0601],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:22,833][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([1.8548e-03, 3.0734e-04, 2.6852e-03, 2.0890e-04, 5.0250e-04, 3.4842e-04,
        1.9498e-04, 3.4300e-05, 9.9386e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:22,833][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.3063, 0.1041, 0.0599, 0.0763, 0.0817, 0.1003, 0.1175, 0.0971, 0.0568],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:22,834][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([3.3839e-03, 4.0869e-05, 7.8008e-04, 9.1236e-05, 9.5153e-04, 2.4684e-04,
        6.2935e-04, 4.3039e-03, 9.8957e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:22,834][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.1319, 0.0060, 0.0140, 0.0051, 0.0126, 0.0160, 0.0135, 0.1768, 0.6242],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:22,835][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([1.2028e-02, 1.5133e-05, 6.6477e-05, 4.1248e-06, 3.3238e-05, 2.0253e-06,
        1.5989e-06, 6.3675e-07, 9.8785e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:22,838][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.1623, 0.0422, 0.2546, 0.0368, 0.2175, 0.0278, 0.0299, 0.0670, 0.1620],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:22,840][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0921, 0.0528, 0.0075, 0.0983, 0.0315, 0.1355, 0.2162, 0.2602, 0.1059],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:22,845][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.2506, 0.0968, 0.0611, 0.1133, 0.0480, 0.2363, 0.1210, 0.0653, 0.0076],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:22,847][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.2231, 0.1299, 0.0968, 0.1217, 0.0956, 0.1057, 0.1088, 0.0785, 0.0398],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:22,847][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.2096, 0.1306, 0.0814, 0.1103, 0.0343, 0.0753, 0.0728, 0.0382, 0.2476],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:22,847][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.3011, 0.1335, 0.1128, 0.0967, 0.0930, 0.0382, 0.0369, 0.0815, 0.1062],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:22,848][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4530, 0.0156, 0.1045, 0.0181, 0.0930, 0.0802, 0.0347, 0.0644, 0.1234,
        0.0132], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:22,848][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([1.8445e-03, 4.4358e-01, 1.0590e-04, 1.1171e-02, 6.5480e-05, 3.9672e-04,
        1.7962e-04, 5.1707e-05, 7.8252e-06, 5.4260e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:22,848][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2004, 0.3154, 0.0165, 0.0771, 0.0157, 0.0367, 0.0076, 0.0102, 0.0101,
        0.3102], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:22,849][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0331, 0.0077, 0.0023, 0.0077, 0.0041, 0.0606, 0.0497, 0.0551, 0.0864,
        0.6933], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:22,849][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2654, 0.0257, 0.0492, 0.0222, 0.0563, 0.1282, 0.0313, 0.1096, 0.0460,
        0.2662], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:22,851][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0974, 0.3440, 0.0124, 0.1241, 0.0065, 0.0690, 0.1021, 0.0301, 0.0101,
        0.2043], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:22,854][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2408, 0.0071, 0.2631, 0.0069, 0.2757, 0.0225, 0.0088, 0.0581, 0.1123,
        0.0047], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:22,858][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0372, 0.0140, 0.0260, 0.0381, 0.0614, 0.0696, 0.1110, 0.1456, 0.1391,
        0.3580], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:22,862][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0192, 0.1649, 0.0064, 0.1851, 0.0057, 0.0642, 0.1660, 0.0292, 0.0076,
        0.3517], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:22,862][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2120, 0.1212, 0.0748, 0.1260, 0.0602, 0.0850, 0.0926, 0.0692, 0.0559,
        0.1031], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:22,863][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1667, 0.1534, 0.0881, 0.1409, 0.0682, 0.0912, 0.0883, 0.0566, 0.0404,
        0.1063], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:22,863][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2473, 0.0956, 0.0638, 0.1085, 0.0814, 0.0690, 0.0657, 0.0803, 0.0747,
        0.1137], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:22,863][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3453, 0.0282, 0.1278, 0.0242, 0.0931, 0.0679, 0.0410, 0.0902, 0.1254,
        0.0276, 0.0294], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:22,864][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([1.0615e-03, 1.2476e-02, 8.2885e-05, 5.1187e-01, 7.6052e-05, 6.9045e-04,
        2.3420e-04, 1.8327e-04, 8.4971e-06, 7.4679e-03, 4.6585e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:22,864][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0841, 0.0629, 0.0120, 0.3149, 0.0168, 0.0438, 0.0176, 0.0150, 0.0235,
        0.0559, 0.3536], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:22,864][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([1.0822e-02, 6.0654e-03, 2.6019e-04, 3.9888e-03, 3.3736e-04, 7.8478e-03,
        1.3926e-02, 1.5640e-02, 7.4102e-03, 4.9309e-01, 4.4061e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:22,865][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0354, 0.0130, 0.0168, 0.0246, 0.0100, 0.1617, 0.0656, 0.1196, 0.1774,
        0.1214, 0.2545], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:22,866][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0326, 0.0871, 0.0042, 0.3873, 0.0037, 0.0542, 0.1209, 0.0254, 0.0037,
        0.0306, 0.2502], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:22,869][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2082, 0.0084, 0.2437, 0.0080, 0.2660, 0.0264, 0.0097, 0.0736, 0.1409,
        0.0064, 0.0089], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:22,873][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0329, 0.0119, 0.0246, 0.0199, 0.0324, 0.0421, 0.0633, 0.0791, 0.0975,
        0.2437, 0.3525], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:22,876][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0115, 0.1002, 0.0057, 0.1175, 0.0042, 0.0609, 0.2000, 0.0256, 0.0109,
        0.2626, 0.2009], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:22,878][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1744, 0.1088, 0.0601, 0.1098, 0.0595, 0.0760, 0.0873, 0.0587, 0.0574,
        0.0962, 0.1119], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:22,878][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1425, 0.1290, 0.0603, 0.1372, 0.0476, 0.0964, 0.0974, 0.0517, 0.0348,
        0.0936, 0.1096], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:22,879][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2179, 0.0888, 0.0562, 0.1023, 0.0679, 0.0531, 0.0472, 0.0611, 0.0779,
        0.1123, 0.1153], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:22,879][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.2368, 0.0431, 0.0621, 0.0478, 0.1372, 0.1257, 0.0490, 0.0344, 0.1511,
        0.0374, 0.0570, 0.0182], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:22,879][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([1.7337e-03, 4.1580e-04, 1.1243e-03, 1.5533e-04, 5.2641e-03, 1.7303e-04,
        8.9815e-05, 1.4283e-04, 6.0347e-04, 9.1969e-05, 7.0472e-05, 9.9014e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:22,880][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.2494, 0.0815, 0.0583, 0.0774, 0.0888, 0.1574, 0.0646, 0.0570, 0.0329,
        0.0517, 0.0623, 0.0187], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:22,880][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([1.2696e-02, 5.1819e-05, 5.4890e-05, 7.2038e-05, 5.6860e-05, 1.1423e-03,
        2.1231e-04, 3.4376e-03, 1.4255e-03, 2.2504e-03, 4.8180e-03, 9.7378e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:22,880][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0421, 0.0034, 0.0042, 0.0070, 0.0041, 0.0114, 0.0109, 0.0294, 0.0154,
        0.0128, 0.0438, 0.8156], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:22,881][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([9.2453e-02, 4.3741e-06, 9.2391e-05, 1.6933e-06, 1.4385e-04, 4.4306e-06,
        4.7550e-07, 4.6483e-06, 5.0048e-06, 9.8434e-08, 2.7242e-07, 9.0729e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:22,883][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.1303, 0.0545, 0.1390, 0.0406, 0.1954, 0.0340, 0.0578, 0.0508, 0.1171,
        0.0482, 0.0446, 0.0877], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:22,885][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0537, 0.0193, 0.0021, 0.0297, 0.0064, 0.0342, 0.0726, 0.0498, 0.0281,
        0.1957, 0.3985, 0.1099], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:22,889][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0976, 0.1102, 0.0204, 0.1395, 0.0243, 0.0394, 0.1219, 0.0365, 0.0999,
        0.1299, 0.1674, 0.0129], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:22,894][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.1739, 0.0983, 0.0723, 0.0903, 0.0687, 0.0748, 0.0659, 0.0564, 0.0853,
        0.0834, 0.0907, 0.0399], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:22,894][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.1900, 0.0923, 0.0514, 0.0884, 0.0469, 0.0827, 0.0549, 0.0513, 0.0385,
        0.0658, 0.0684, 0.1694], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:22,894][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.1815, 0.1439, 0.0563, 0.0954, 0.0509, 0.0328, 0.0420, 0.0423, 0.0386,
        0.1645, 0.1024, 0.0494], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:22,895][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Megan] are: tensor([0.1095, 0.0869, 0.0552, 0.0849, 0.1216, 0.0249, 0.0488, 0.0174, 0.0538,
        0.0841, 0.0979, 0.0680, 0.1470], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:22,895][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Megan] are: tensor([2.8914e-05, 3.5067e-06, 5.5019e-04, 8.1162e-06, 5.0665e-01, 4.1697e-07,
        8.1918e-06, 1.2547e-06, 2.0589e-06, 6.4161e-07, 3.4824e-06, 1.3934e-05,
        4.9273e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:22,895][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Megan] are: tensor([0.1710, 0.1212, 0.0607, 0.0707, 0.0727, 0.0973, 0.0719, 0.0214, 0.0293,
        0.0827, 0.0660, 0.0621, 0.0730], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:22,896][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Megan] are: tensor([1.9930e-03, 6.9106e-07, 8.9685e-05, 8.0916e-07, 7.6532e-03, 1.5562e-05,
        6.6780e-06, 4.3371e-05, 2.1275e-04, 2.6698e-05, 5.3416e-05, 1.6343e-03,
        9.8827e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:22,896][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Megan] are: tensor([6.5687e-03, 4.6202e-04, 7.9978e-03, 2.3410e-04, 7.1045e-02, 5.7579e-04,
        4.8392e-04, 1.1699e-03, 1.9301e-03, 2.4942e-03, 1.8317e-03, 6.3756e-03,
        8.9883e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:22,897][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Megan] are: tensor([1.9937e-04, 1.2760e-08, 4.9676e-05, 1.1701e-08, 5.7705e-01, 9.8532e-10,
        2.0812e-09, 2.6393e-09, 1.7504e-08, 4.8554e-10, 2.4218e-09, 3.8602e-08,
        4.2270e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:22,897][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Megan] are: tensor([0.1004, 0.1361, 0.1194, 0.0668, 0.1331, 0.0199, 0.0502, 0.0357, 0.0289,
        0.1009, 0.0579, 0.0219, 0.1288], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:22,898][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Megan] are: tensor([0.0692, 0.0255, 0.0052, 0.0343, 0.0099, 0.0312, 0.0556, 0.0327, 0.0692,
        0.1632, 0.2840, 0.1226, 0.0974], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:22,901][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Megan] are: tensor([0.1242, 0.0886, 0.0656, 0.0949, 0.0534, 0.0548, 0.0605, 0.0386, 0.1481,
        0.0899, 0.1032, 0.0175, 0.0606], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:22,905][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Megan] are: tensor([0.1777, 0.1126, 0.0990, 0.1013, 0.0139, 0.0541, 0.0737, 0.0643, 0.0472,
        0.0892, 0.0988, 0.0540, 0.0142], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:22,908][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Megan] are: tensor([0.0962, 0.0733, 0.0971, 0.0725, 0.2163, 0.0391, 0.0529, 0.0254, 0.0179,
        0.0558, 0.0534, 0.0224, 0.1777], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:22,910][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Megan] are: tensor([0.0826, 0.0651, 0.0266, 0.0919, 0.0451, 0.0755, 0.0771, 0.0704, 0.0703,
        0.0774, 0.1246, 0.1300, 0.0634], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:22,910][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.3203, 0.0277, 0.0854, 0.0160, 0.0749, 0.0584, 0.0171, 0.0424, 0.0408,
        0.0273, 0.0170, 0.0928, 0.1086, 0.0713], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:22,911][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([1.4427e-03, 3.5465e-03, 9.0441e-04, 1.1993e-03, 1.4333e-03, 8.4789e-03,
        1.4028e-03, 4.5720e-05, 1.5898e-03, 1.5486e-03, 7.2123e-04, 1.1223e-04,
        1.0631e-03, 9.7651e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:22,911][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.2285, 0.0511, 0.0344, 0.0441, 0.0164, 0.1051, 0.0347, 0.0254, 0.0500,
        0.0422, 0.0411, 0.0413, 0.0165, 0.2692], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:22,912][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([1.9982e-03, 7.3908e-05, 3.2254e-05, 5.5018e-05, 5.0299e-05, 3.0972e-04,
        4.3030e-04, 4.8914e-04, 1.2609e-03, 2.5534e-03, 3.5693e-03, 1.3245e-03,
        4.5448e-03, 9.8331e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:22,912][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0828, 0.0126, 0.0092, 0.0180, 0.0083, 0.0257, 0.0209, 0.0243, 0.0412,
        0.0543, 0.1154, 0.0233, 0.0617, 0.5022], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:22,912][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([1.2074e-02, 2.4341e-03, 4.1700e-04, 8.9048e-04, 8.4720e-05, 8.6967e-03,
        2.0759e-04, 2.9474e-05, 6.7242e-04, 2.4881e-04, 2.8118e-04, 6.2009e-06,
        3.0112e-05, 9.7393e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:22,913][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.1447, 0.0071, 0.2263, 0.0071, 0.1636, 0.0095, 0.0058, 0.0259, 0.0683,
        0.0054, 0.0070, 0.0991, 0.2162, 0.0140], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:22,915][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0269, 0.0051, 0.0089, 0.0086, 0.0167, 0.0116, 0.0245, 0.0106, 0.0168,
        0.0890, 0.1390, 0.1432, 0.3585, 0.1406], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:22,918][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0504, 0.1042, 0.0156, 0.1023, 0.0284, 0.0996, 0.1347, 0.0307, 0.0272,
        0.1725, 0.1350, 0.0244, 0.0385, 0.0365], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:22,921][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.1481, 0.0796, 0.0611, 0.0818, 0.0437, 0.0655, 0.0623, 0.0462, 0.0543,
        0.0740, 0.0847, 0.0550, 0.0490, 0.0947], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:22,926][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0994, 0.0717, 0.0547, 0.0756, 0.0407, 0.0779, 0.0584, 0.0245, 0.0468,
        0.0606, 0.0652, 0.0279, 0.0350, 0.2616], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:22,926][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.2451, 0.0583, 0.0571, 0.0779, 0.0521, 0.0373, 0.0313, 0.0563, 0.0668,
        0.0619, 0.0791, 0.0821, 0.0555, 0.0393], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:22,926][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2676, 0.0259, 0.0617, 0.0217, 0.0618, 0.0698, 0.0233, 0.0377, 0.0745,
        0.0259, 0.0265, 0.0862, 0.0892, 0.1111, 0.0171], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:22,927][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.1213e-03, 1.1779e-02, 9.8850e-05, 3.4316e-02, 1.3775e-04, 3.0534e-04,
        1.4492e-03, 1.7847e-04, 5.7932e-05, 8.2845e-03, 3.0206e-02, 2.4505e-04,
        9.7587e-05, 1.4515e-04, 9.0858e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:22,927][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1613, 0.0709, 0.0258, 0.0974, 0.0225, 0.0592, 0.0254, 0.0380, 0.0310,
        0.0605, 0.0959, 0.0394, 0.0231, 0.0753, 0.1743], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:22,927][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.9462e-03, 2.6597e-04, 4.6579e-05, 1.8226e-04, 3.5623e-05, 7.2950e-04,
        1.2066e-03, 2.4263e-04, 1.1486e-03, 7.2038e-03, 1.1945e-02, 1.6583e-02,
        3.2123e-03, 2.9353e-01, 6.6072e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:22,928][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0355, 0.0023, 0.0027, 0.0038, 0.0023, 0.0336, 0.0103, 0.0260, 0.0567,
        0.0122, 0.0313, 0.0725, 0.0240, 0.4119, 0.2750], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:22,928][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0434, 0.0613, 0.0012, 0.0784, 0.0017, 0.0312, 0.2267, 0.0344, 0.0048,
        0.0212, 0.0413, 0.0007, 0.0008, 0.0327, 0.4202], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:22,929][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1212, 0.0058, 0.0576, 0.0050, 0.0858, 0.0170, 0.0048, 0.0314, 0.0541,
        0.0043, 0.0063, 0.1103, 0.1422, 0.0325, 0.3216], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:22,930][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0212, 0.0040, 0.0046, 0.0066, 0.0088, 0.0086, 0.0114, 0.0176, 0.0257,
        0.0471, 0.0763, 0.0895, 0.1692, 0.2474, 0.2619], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:22,933][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0080, 0.0593, 0.0050, 0.1033, 0.0048, 0.0465, 0.1308, 0.0197, 0.0089,
        0.1504, 0.1810, 0.0048, 0.0074, 0.0337, 0.2363], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:22,937][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1195, 0.0741, 0.0434, 0.0815, 0.0397, 0.0544, 0.0693, 0.0476, 0.0428,
        0.0699, 0.0855, 0.0459, 0.0448, 0.0830, 0.0986], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:22,941][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1005, 0.0826, 0.0419, 0.0989, 0.0357, 0.0733, 0.0842, 0.0495, 0.0328,
        0.0750, 0.0913, 0.0271, 0.0323, 0.0632, 0.1117], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:22,942][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1771, 0.0700, 0.0462, 0.0719, 0.0542, 0.0499, 0.0453, 0.0532, 0.0533,
        0.0720, 0.0683, 0.0736, 0.0564, 0.0366, 0.0722], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:22,943][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:22,944][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 9720],
        [17608],
        [    1],
        [21000],
        [ 3079],
        [13558],
        [20936],
        [14253],
        [15791],
        [15349],
        [23794],
        [35547],
        [ 6730],
        [ 1726],
        [12399]], device='cuda:0')
[2024-07-24 10:29:22,945][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[40541],
        [33525],
        [    1],
        [40992],
        [  124],
        [46481],
        [37530],
        [44105],
        [35897],
        [42033],
        [39765],
        [46788],
        [  123],
        [32927],
        [41283]], device='cuda:0')
[2024-07-24 10:29:22,946][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[17461],
        [15896],
        [ 1106],
        [ 5035],
        [ 2005],
        [ 5647],
        [ 3083],
        [ 2275],
        [ 2280],
        [ 5399],
        [ 3147],
        [ 2874],
        [ 1922],
        [ 2208],
        [ 2076]], device='cuda:0')
[2024-07-24 10:29:22,947][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[35453],
        [ 8942],
        [ 4655],
        [26712],
        [26708],
        [32187],
        [45875],
        [27821],
        [40174],
        [10351],
        [27808],
        [46790],
        [27349],
        [27659],
        [25043]], device='cuda:0')
[2024-07-24 10:29:22,950][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 8720],
        [14403],
        [ 6403],
        [36541],
        [15237],
        [19834],
        [26477],
        [21286],
        [15707],
        [27693],
        [41132],
        [23099],
        [21906],
        [22444],
        [32888]], device='cuda:0')
[2024-07-24 10:29:22,951][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[40947],
        [40273],
        [ 6532],
        [31606],
        [ 5560],
        [ 3151],
        [ 8609],
        [11192],
        [ 6822],
        [17592],
        [23521],
        [31809],
        [ 3872],
        [  880],
        [ 6532]], device='cuda:0')
[2024-07-24 10:29:22,953][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 6976],
        [ 6896],
        [  772],
        [ 1643],
        [ 4928],
        [ 9155],
        [ 7762],
        [ 4336],
        [14778],
        [ 4429],
        [ 7434],
        [16593],
        [ 5512],
        [ 8711],
        [ 7979]], device='cuda:0')
[2024-07-24 10:29:22,956][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[36130],
        [37027],
        [ 3841],
        [35968],
        [37710],
        [26401],
        [19362],
        [20149],
        [10094],
        [32187],
        [32209],
        [47378],
        [38000],
        [12192],
        [25084]], device='cuda:0')
[2024-07-24 10:29:22,958][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[34799],
        [35362],
        [18460],
        [ 1315],
        [11640],
        [   31],
        [   42],
        [  100],
        [   55],
        [   27],
        [   28],
        [ 4861],
        [10496],
        [   66],
        [ 6479]], device='cuda:0')
[2024-07-24 10:29:22,961][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[21754],
        [21235],
        [15038],
        [13355],
        [30192],
        [35926],
        [33922],
        [36942],
        [39717],
        [26935],
        [36796],
        [37868],
        [34343],
        [17948],
        [24655]], device='cuda:0')
[2024-07-24 10:29:22,962][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[13173],
        [ 7813],
        [ 6370],
        [ 7109],
        [ 2218],
        [ 8496],
        [11948],
        [ 9002],
        [11434],
        [10060],
        [ 9292],
        [ 5428],
        [ 3677],
        [ 8299],
        [ 7240]], device='cuda:0')
[2024-07-24 10:29:22,963][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[23250],
        [34786],
        [34231],
        [37972],
        [35097],
        [39894],
        [39307],
        [38926],
        [36537],
        [39991],
        [41434],
        [39586],
        [40245],
        [40608],
        [42395]], device='cuda:0')
[2024-07-24 10:29:22,963][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[10552],
        [ 3409],
        [15225],
        [ 1694],
        [19390],
        [  704],
        [ 5976],
        [ 8004],
        [ 3223],
        [ 2890],
        [ 2059],
        [ 5688],
        [35952],
        [  905],
        [ 1897]], device='cuda:0')
[2024-07-24 10:29:22,964][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[39664],
        [36787],
        [29321],
        [32235],
        [25936],
        [30738],
        [31043],
        [35178],
        [28601],
        [31117],
        [30656],
        [30188],
        [27312],
        [28951],
        [27023]], device='cuda:0')
[2024-07-24 10:29:22,966][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[43260],
        [14231],
        [   15],
        [32229],
        [24456],
        [35806],
        [41362],
        [38097],
        [25191],
        [14418],
        [31402],
        [44210],
        [24192],
        [ 6412],
        [25990]], device='cuda:0')
[2024-07-24 10:29:22,967][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[28307],
        [28271],
        [23345],
        [26627],
        [21140],
        [23754],
        [21734],
        [22568],
        [24070],
        [22391],
        [22901],
        [22741],
        [19370],
        [15138],
        [15934]], device='cuda:0')
[2024-07-24 10:29:22,969][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 5880],
        [22596],
        [37195],
        [11725],
        [27945],
        [27137],
        [11405],
        [39688],
        [32156],
        [16538],
        [ 8972],
        [22161],
        [27366],
        [35701],
        [11502]], device='cuda:0')
[2024-07-24 10:29:22,970][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[44895],
        [36414],
        [32985],
        [45478],
        [37957],
        [43774],
        [42274],
        [42133],
        [42303],
        [28288],
        [46338],
        [43157],
        [39845],
        [46918],
        [39502]], device='cuda:0')
[2024-07-24 10:29:22,973][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[22766],
        [22774],
        [28780],
        [20527],
        [28420],
        [29409],
        [24778],
        [33634],
        [38899],
        [28030],
        [27817],
        [37321],
        [37767],
        [43557],
        [36249]], device='cuda:0')
[2024-07-24 10:29:22,975][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[13420],
        [13918],
        [25678],
        [25200],
        [13802],
        [18868],
        [17074],
        [27720],
        [25591],
        [25103],
        [22470],
        [43110],
        [15573],
        [21785],
        [21581]], device='cuda:0')
[2024-07-24 10:29:22,978][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[27208],
        [38692],
        [28870],
        [40012],
        [ 8559],
        [30371],
        [44431],
        [33584],
        [37974],
        [39659],
        [41115],
        [12627],
        [ 7963],
        [37756],
        [42253]], device='cuda:0')
[2024-07-24 10:29:22,980][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[34154],
        [34206],
        [23778],
        [17692],
        [24204],
        [ 8932],
        [11351],
        [11589],
        [ 9226],
        [ 9764],
        [ 9818],
        [21882],
        [30476],
        [17070],
        [40237]], device='cuda:0')
[2024-07-24 10:29:22,981][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[21191],
        [21886],
        [22248],
        [ 8919],
        [13996],
        [ 9127],
        [ 6229],
        [ 7124],
        [10928],
        [18077],
        [13564],
        [13766],
        [16411],
        [17010],
        [ 8983]], device='cuda:0')
[2024-07-24 10:29:22,982][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[34826],
        [17221],
        [26978],
        [21957],
        [29296],
        [24386],
        [21600],
        [24791],
        [26500],
        [18235],
        [19262],
        [22599],
        [27463],
        [22315],
        [19505]], device='cuda:0')
[2024-07-24 10:29:22,983][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[47604],
        [43831],
        [42675],
        [42001],
        [41089],
        [43115],
        [44037],
        [44889],
        [44846],
        [43957],
        [43791],
        [43290],
        [43318],
        [43619],
        [43749]], device='cuda:0')
[2024-07-24 10:29:22,984][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[44162],
        [49381],
        [47395],
        [49662],
        [47563],
        [49919],
        [49474],
        [48765],
        [48085],
        [49550],
        [49591],
        [49362],
        [46471],
        [49921],
        [49794]], device='cuda:0')
[2024-07-24 10:29:22,985][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[10032],
        [18021],
        [37909],
        [35435],
        [41435],
        [35787],
        [39489],
        [32217],
        [40411],
        [44207],
        [43872],
        [44895],
        [43236],
        [41187],
        [42904]], device='cuda:0')
[2024-07-24 10:29:22,986][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[4554],
        [2965],
        [4480],
        [4100],
        [5011],
        [3987],
        [5608],
        [4115],
        [4347],
        [4159],
        [4397],
        [2999],
        [5181],
        [2098],
        [3079]], device='cuda:0')
[2024-07-24 10:29:22,989][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 3873],
        [29407],
        [50200],
        [12831],
        [19101],
        [10585],
        [ 5512],
        [ 8284],
        [19996],
        [29598],
        [13385],
        [ 4644],
        [19631],
        [39943],
        [17861]], device='cuda:0')
[2024-07-24 10:29:22,990][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[16513],
        [16513],
        [16513],
        [16513],
        [16513],
        [16513],
        [16513],
        [16513],
        [16513],
        [16513],
        [16513],
        [16513],
        [16513],
        [16513],
        [16513]], device='cuda:0')
[2024-07-24 10:29:23,006][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:23,009][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,009][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,009][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,010][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,010][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,010][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,011][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,011][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,011][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,012][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,012][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,013][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,013][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.8948, 0.1052], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,014][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.9867, 0.0133], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,014][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9574, 0.0426], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,014][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5449, 0.4551], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,015][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([1.9714e-04, 9.9980e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,015][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.3537, 0.6463], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,015][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.7411, 0.2589], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,016][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9939, 0.0061], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,016][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4254, 0.5746], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,016][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0807, 0.9193], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,017][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2261, 0.7739], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,017][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.7350, 0.2650], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,017][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Jennifer] are: tensor([0.0276, 0.2010, 0.7714], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,018][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Jennifer] are: tensor([0.6690, 0.2658, 0.0652], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,018][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Jennifer] are: tensor([0.9485, 0.0394, 0.0121], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,018][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Jennifer] are: tensor([0.3935, 0.3055, 0.3010], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,020][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Jennifer] are: tensor([0.0897, 0.6535, 0.2568], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,022][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Jennifer] are: tensor([6.4039e-04, 4.5378e-02, 9.5398e-01], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,026][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Jennifer] are: tensor([0.4696, 0.4714, 0.0590], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,029][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Jennifer] are: tensor([0.4744, 0.1981, 0.3275], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,031][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Jennifer] are: tensor([0.3945, 0.4666, 0.1389], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,031][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Jennifer] are: tensor([0.0591, 0.8166, 0.1243], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,031][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Jennifer] are: tensor([0.1264, 0.3945, 0.4791], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,032][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Jennifer] are: tensor([0.0015, 0.0023, 0.9961], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,032][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0099, 0.0640, 0.8924, 0.0338], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,032][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.6710, 0.1288, 0.1053, 0.0950], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,033][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.6358, 0.0981, 0.0425, 0.2236], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,033][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3101, 0.1870, 0.2035, 0.2994], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,033][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0209, 0.5078, 0.1632, 0.3081], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,033][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([3.3626e-03, 8.5787e-04, 6.8191e-04, 9.9510e-01], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,034][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.4809, 0.1682, 0.0595, 0.2915], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,035][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3072, 0.0312, 0.3486, 0.3130], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,039][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1658, 0.2530, 0.0549, 0.5262], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,042][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0466, 0.5915, 0.2061, 0.1558], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,046][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0926, 0.2848, 0.3724, 0.2502], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,049][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1758, 0.1413, 0.0528, 0.6301], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,049][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Megan] are: tensor([0.0030, 0.0315, 0.7882, 0.0672, 0.1101], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,049][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Megan] are: tensor([0.2972, 0.2044, 0.0691, 0.4042, 0.0250], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,050][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Megan] are: tensor([0.7286, 0.0650, 0.0152, 0.1741, 0.0171], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,050][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Megan] are: tensor([0.2505, 0.1503, 0.1522, 0.2405, 0.2065], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,050][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Megan] are: tensor([0.4281, 0.2154, 0.0905, 0.1608, 0.1052], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,051][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Megan] are: tensor([0.0011, 0.0176, 0.5333, 0.4193, 0.0288], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,051][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Megan] are: tensor([0.1765, 0.1473, 0.0443, 0.4987, 0.1332], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,051][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Megan] are: tensor([0.2593, 0.0902, 0.3250, 0.2939, 0.0317], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,053][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Megan] are: tensor([0.1686, 0.2207, 0.0574, 0.4674, 0.0860], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,056][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Megan] are: tensor([0.0413, 0.7333, 0.0854, 0.1126, 0.0274], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,060][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Megan] are: tensor([0.0754, 0.2314, 0.2752, 0.1965, 0.2214], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,062][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Megan] are: tensor([8.9424e-04, 3.7424e-04, 2.8722e-03, 2.9087e-04, 9.9557e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,064][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.1093, 0.0728, 0.2341, 0.1784, 0.1343, 0.2711], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,064][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.5535, 0.0862, 0.0784, 0.1487, 0.0745, 0.0587], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,065][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.6299, 0.0670, 0.0221, 0.1582, 0.0227, 0.1000], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,065][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.2196, 0.1113, 0.1185, 0.1796, 0.1578, 0.2132], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,065][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0536, 0.2531, 0.1282, 0.1963, 0.0790, 0.2899], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,066][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0077, 0.0388, 0.0265, 0.0296, 0.0581, 0.8392], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,066][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.3351, 0.1061, 0.0184, 0.3631, 0.0992, 0.0781], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,066][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1866, 0.0427, 0.2627, 0.1860, 0.1733, 0.1488], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,067][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1258, 0.2102, 0.0473, 0.3366, 0.0716, 0.2085], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,067][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0235, 0.4759, 0.1612, 0.0615, 0.0541, 0.2239], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,069][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0566, 0.1839, 0.2344, 0.1563, 0.1878, 0.1809], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,071][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0023, 0.0046, 0.0095, 0.0035, 0.0062, 0.9739], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,074][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([5.8767e-04, 4.1582e-03, 3.1972e-01, 9.2153e-03, 1.8243e-02, 6.1948e-01,
        2.8600e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,078][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.3535, 0.0659, 0.0906, 0.1572, 0.1020, 0.1451, 0.0857],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,080][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.4618, 0.0613, 0.0219, 0.1368, 0.0227, 0.1013, 0.1943],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,080][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1929, 0.0873, 0.0940, 0.1467, 0.1282, 0.1762, 0.1747],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,080][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0833, 0.2719, 0.0889, 0.1505, 0.0531, 0.1951, 0.1571],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,081][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([9.4258e-03, 4.0342e-03, 6.4844e-01, 1.7296e-01, 1.6130e-01, 3.5092e-03,
        3.3407e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,081][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1141, 0.0455, 0.0112, 0.1033, 0.0484, 0.0225, 0.6550],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,081][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1216, 0.0446, 0.2463, 0.1569, 0.1139, 0.1088, 0.2080],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,082][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1068, 0.1425, 0.0362, 0.2689, 0.0560, 0.1383, 0.2513],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,082][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0273, 0.3686, 0.0975, 0.0718, 0.0375, 0.1447, 0.2525],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,082][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0516, 0.1550, 0.2002, 0.1354, 0.1666, 0.1546, 0.1365],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,083][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([4.0183e-04, 5.1108e-04, 3.7928e-04, 5.6523e-04, 2.4312e-04, 5.7485e-04,
        9.9732e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,084][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ long] are: tensor([1.4245e-04, 4.8584e-04, 1.7845e-03, 2.0019e-03, 6.9815e-03, 3.2969e-01,
        6.5124e-01, 7.6674e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,086][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.2357, 0.0615, 0.0930, 0.1225, 0.0863, 0.1277, 0.2012, 0.0720],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,089][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.5984, 0.0502, 0.0140, 0.1167, 0.0157, 0.0550, 0.1189, 0.0311],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,093][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.1744, 0.0712, 0.0761, 0.1239, 0.1075, 0.1522, 0.1496, 0.1451],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,095][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0350, 0.1543, 0.0759, 0.1097, 0.0675, 0.1529, 0.1446, 0.2601],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,096][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ long] are: tensor([2.0291e-04, 3.0228e-03, 9.2481e-06, 1.1507e-03, 3.6645e-06, 8.3963e-04,
        4.4404e-05, 9.9473e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,096][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.1127, 0.0333, 0.0014, 0.0967, 0.0042, 0.0186, 0.7167, 0.0163],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,096][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.1502, 0.0728, 0.1040, 0.1584, 0.0584, 0.2223, 0.2077, 0.0261],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,097][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0757, 0.1279, 0.0374, 0.2348, 0.0522, 0.1165, 0.2432, 0.1123],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,097][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0157, 0.3249, 0.1119, 0.0658, 0.0466, 0.1241, 0.2973, 0.0136],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,097][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0444, 0.1371, 0.1729, 0.1172, 0.1437, 0.1338, 0.1186, 0.1323],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,098][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ long] are: tensor([2.3905e-03, 2.3090e-03, 6.0954e-04, 1.4406e-03, 1.9160e-04, 2.9667e-03,
        2.5707e-03, 9.8752e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,099][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([5.7778e-05, 1.2774e-03, 8.0745e-02, 7.4395e-03, 1.6129e-02, 3.5677e-01,
        2.9273e-01, 2.3843e-01, 6.4211e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,101][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.2763, 0.0408, 0.0473, 0.1135, 0.0652, 0.1217, 0.1117, 0.0905, 0.1330],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,104][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.5309, 0.0515, 0.0108, 0.1543, 0.0132, 0.0521, 0.1317, 0.0261, 0.0295],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,108][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.1583, 0.0597, 0.0636, 0.1043, 0.0919, 0.1316, 0.1302, 0.1273, 0.1331],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,111][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.1271, 0.1105, 0.0562, 0.0696, 0.0606, 0.1020, 0.1107, 0.2178, 0.1455],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,111][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([8.5565e-05, 1.0012e-02, 9.7033e-02, 1.6594e-03, 4.6198e-04, 4.5078e-02,
        1.8843e-03, 1.6969e-03, 8.4209e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,111][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.1218, 0.0476, 0.0038, 0.1443, 0.0200, 0.0139, 0.6354, 0.0084, 0.0047],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,112][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0811, 0.0123, 0.1763, 0.1442, 0.0963, 0.2436, 0.1373, 0.0892, 0.0197],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,112][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0897, 0.1075, 0.0330, 0.1940, 0.0545, 0.1295, 0.2105, 0.1276, 0.0537],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,112][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0128, 0.2945, 0.1043, 0.0448, 0.0363, 0.1523, 0.3269, 0.0115, 0.0164],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,113][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0390, 0.1170, 0.1497, 0.0991, 0.1223, 0.1125, 0.1002, 0.1117, 0.1485],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,113][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([3.9325e-03, 2.9636e-03, 7.2958e-03, 2.1535e-03, 1.5797e-03, 9.6411e-04,
        7.1172e-03, 1.4556e-03, 9.7254e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,113][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0088, 0.0028, 0.0557, 0.0151, 0.0614, 0.0358, 0.1851, 0.0568, 0.5693,
        0.0093], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,114][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.2621, 0.0134, 0.0734, 0.0992, 0.0787, 0.0895, 0.0891, 0.0728, 0.1018,
        0.1199], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,115][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2332, 0.0534, 0.0188, 0.0968, 0.0191, 0.0854, 0.1443, 0.0333, 0.0424,
        0.2732], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,118][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1501, 0.0490, 0.0522, 0.0862, 0.0759, 0.1093, 0.1070, 0.1039, 0.1080,
        0.1582], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,122][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1791, 0.0957, 0.0403, 0.0545, 0.0402, 0.0755, 0.0768, 0.1781, 0.1126,
        0.1472], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,124][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([2.7157e-04, 1.3886e-03, 4.3017e-04, 3.1671e-02, 2.2623e-02, 4.6027e-05,
        1.0839e-05, 1.1587e-03, 9.3876e-01, 3.6428e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,126][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1214, 0.0554, 0.0177, 0.0855, 0.0782, 0.0286, 0.4042, 0.0260, 0.0068,
        0.1762], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,127][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1450, 0.0204, 0.2350, 0.1170, 0.1345, 0.0548, 0.1070, 0.0290, 0.0966,
        0.0605], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,127][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0668, 0.0940, 0.0221, 0.1525, 0.0348, 0.0992, 0.1598, 0.0691, 0.0387,
        0.2630], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,127][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0236, 0.2493, 0.0793, 0.0612, 0.0328, 0.0846, 0.1752, 0.0154, 0.0183,
        0.2603], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,128][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0345, 0.1041, 0.1355, 0.0903, 0.1121, 0.1040, 0.0893, 0.1040, 0.1368,
        0.0894], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,128][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0132, 0.0120, 0.0845, 0.0153, 0.3033, 0.0894, 0.1273, 0.0902, 0.1644,
        0.1005], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,129][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0007, 0.0062, 0.0839, 0.0032, 0.1763, 0.0266, 0.2428, 0.1441, 0.2924,
        0.0202, 0.0034], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,129][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1327, 0.0266, 0.0419, 0.0230, 0.0542, 0.0797, 0.0853, 0.0551, 0.0974,
        0.3134, 0.0907], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,131][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1498, 0.0475, 0.0172, 0.0832, 0.0175, 0.0803, 0.1316, 0.0281, 0.0361,
        0.2250, 0.1837], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,133][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1353, 0.0412, 0.0443, 0.0733, 0.0639, 0.0927, 0.0904, 0.0876, 0.0906,
        0.1336, 0.1471], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,137][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2709, 0.0593, 0.0308, 0.0386, 0.0391, 0.0541, 0.0609, 0.1311, 0.0962,
        0.1303, 0.0888], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,140][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([8.1460e-04, 1.7889e-04, 1.1999e-04, 2.4410e-01, 8.6170e-04, 2.3368e-06,
        1.2770e-06, 2.7649e-04, 2.8310e-01, 2.0537e-04, 4.7034e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,142][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1140, 0.0431, 0.0156, 0.0684, 0.0794, 0.0277, 0.4196, 0.0195, 0.0055,
        0.1355, 0.0716], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,142][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0878, 0.0243, 0.1426, 0.1095, 0.0668, 0.1325, 0.1257, 0.0389, 0.0829,
        0.0893, 0.0998], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,142][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0455, 0.0716, 0.0158, 0.1486, 0.0219, 0.0723, 0.1208, 0.0517, 0.0284,
        0.2305, 0.1929], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,143][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0179, 0.2167, 0.0714, 0.0585, 0.0275, 0.0691, 0.2255, 0.0156, 0.0163,
        0.2368, 0.0448], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,143][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0323, 0.0940, 0.1242, 0.0833, 0.1031, 0.0956, 0.0817, 0.0960, 0.1265,
        0.0818, 0.0814], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,143][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0079, 0.0115, 0.0099, 0.0459, 0.0411, 0.1182, 0.0281, 0.0235, 0.0589,
        0.2257, 0.4292], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,144][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([2.6851e-04, 4.1793e-03, 1.2847e-02, 1.3185e-02, 1.5911e-02, 2.4550e-01,
        3.1658e-02, 5.5142e-01, 4.7031e-02, 3.0553e-02, 1.5423e-02, 3.2022e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,144][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0751, 0.0154, 0.0272, 0.0491, 0.0273, 0.0267, 0.0401, 0.0430, 0.0621,
        0.2791, 0.3234, 0.0315], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,145][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.2641, 0.0346, 0.0099, 0.0803, 0.0113, 0.0376, 0.0820, 0.0222, 0.0252,
        0.1961, 0.2043, 0.0325], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,146][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.1174, 0.0351, 0.0367, 0.0627, 0.0543, 0.0809, 0.0803, 0.0779, 0.0810,
        0.1213, 0.1338, 0.1187], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,149][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.2900, 0.0558, 0.0245, 0.0348, 0.0338, 0.0451, 0.0552, 0.1094, 0.0839,
        0.1258, 0.0850, 0.0569], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,151][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([6.0520e-03, 2.8736e-02, 4.7447e-03, 1.3131e-02, 4.0010e-04, 1.4637e-02,
        3.6472e-04, 2.1977e-01, 3.0826e-01, 2.3156e-02, 1.3568e-02, 3.6718e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,155][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0550, 0.0364, 0.0025, 0.1226, 0.0067, 0.0129, 0.3462, 0.0129, 0.0011,
        0.2773, 0.1223, 0.0043], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,158][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0519, 0.0388, 0.0818, 0.0695, 0.0583, 0.1721, 0.2010, 0.0312, 0.0689,
        0.1044, 0.0890, 0.0331], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,158][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0487, 0.0711, 0.0252, 0.1148, 0.0330, 0.0727, 0.1262, 0.0914, 0.0417,
        0.1807, 0.1500, 0.0445], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,158][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0136, 0.1753, 0.0421, 0.0319, 0.0244, 0.2041, 0.2493, 0.0079, 0.0109,
        0.2084, 0.0200, 0.0120], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,159][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0300, 0.0886, 0.1104, 0.0757, 0.0906, 0.0851, 0.0762, 0.0838, 0.1106,
        0.0746, 0.0733, 0.1011], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,159][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([5.7935e-04, 2.5841e-04, 3.4796e-04, 2.6670e-04, 2.6420e-04, 2.2437e-04,
        1.0009e-04, 2.1443e-03, 1.8737e-03, 1.0132e-03, 6.1854e-04, 9.9231e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,159][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Megan] are: tensor([3.7768e-04, 4.0336e-03, 7.9810e-02, 9.1297e-03, 1.1364e-02, 4.7403e-01,
        2.0716e-01, 4.8589e-02, 4.0949e-02, 2.5078e-02, 1.2332e-02, 7.7562e-02,
        9.5818e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,160][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Megan] are: tensor([0.0362, 0.0226, 0.0098, 0.0405, 0.0038, 0.0425, 0.0649, 0.0389, 0.0651,
        0.3213, 0.2405, 0.0898, 0.0242], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,160][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Megan] are: tensor([0.2188, 0.0454, 0.0080, 0.0913, 0.0087, 0.0368, 0.0838, 0.0142, 0.0157,
        0.2017, 0.2272, 0.0246, 0.0240], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,162][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Megan] are: tensor([0.1004, 0.0299, 0.0302, 0.0546, 0.0467, 0.0725, 0.0724, 0.0686, 0.0739,
        0.1120, 0.1245, 0.1108, 0.1036], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,164][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Megan] are: tensor([0.3103, 0.0184, 0.0139, 0.0167, 0.0361, 0.0257, 0.0414, 0.0564, 0.0742,
        0.1282, 0.0989, 0.0743, 0.1056], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,169][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Megan] are: tensor([0.0004, 0.0062, 0.1888, 0.1281, 0.0087, 0.0005, 0.0029, 0.0101, 0.3516,
        0.0170, 0.1566, 0.1216, 0.0075], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,173][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Megan] are: tensor([0.0369, 0.0303, 0.0087, 0.1054, 0.0280, 0.0097, 0.4392, 0.0067, 0.0010,
        0.1996, 0.1124, 0.0024, 0.0197], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,173][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Megan] are: tensor([0.0312, 0.0414, 0.1185, 0.0710, 0.0132, 0.1688, 0.2003, 0.0218, 0.0744,
        0.1266, 0.0819, 0.0450, 0.0058], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,174][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Megan] are: tensor([0.0442, 0.0600, 0.0152, 0.1285, 0.0227, 0.0729, 0.1105, 0.0855, 0.0320,
        0.1830, 0.1809, 0.0427, 0.0221], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,174][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Megan] are: tensor([0.0103, 0.1883, 0.0210, 0.0286, 0.0068, 0.1611, 0.3000, 0.0083, 0.0119,
        0.2356, 0.0166, 0.0063, 0.0053], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,174][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Megan] are: tensor([0.0275, 0.0841, 0.1009, 0.0718, 0.0813, 0.0797, 0.0709, 0.0762, 0.1011,
        0.0700, 0.0695, 0.0945, 0.0727], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,175][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Megan] are: tensor([1.0336e-06, 2.9380e-06, 1.2725e-04, 1.4342e-06, 9.3593e-02, 3.7874e-06,
        3.4319e-06, 7.0778e-07, 4.4923e-06, 5.8562e-04, 3.4903e-05, 1.2029e-05,
        9.0563e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,175][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0029, 0.0092, 0.1463, 0.0334, 0.0226, 0.3190, 0.0985, 0.1182, 0.0098,
        0.0505, 0.0476, 0.0804, 0.0190, 0.0426], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,175][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.1266, 0.0236, 0.0140, 0.0270, 0.0162, 0.0391, 0.0292, 0.0287, 0.0291,
        0.2237, 0.1420, 0.2076, 0.0593, 0.0340], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,176][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.2734, 0.0333, 0.0091, 0.0701, 0.0098, 0.0331, 0.0694, 0.0156, 0.0199,
        0.1693, 0.1827, 0.0237, 0.0279, 0.0626], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,177][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.1044, 0.0266, 0.0277, 0.0480, 0.0416, 0.0629, 0.0617, 0.0597, 0.0622,
        0.0937, 0.1041, 0.0931, 0.0854, 0.1290], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,180][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.1487, 0.1134, 0.0352, 0.0443, 0.0305, 0.0554, 0.0540, 0.1161, 0.0759,
        0.0997, 0.0611, 0.0404, 0.0537, 0.0715], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,182][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ said] are: tensor([6.5567e-06, 3.0074e-05, 7.5167e-04, 8.8316e-05, 6.8063e-05, 2.2065e-04,
        3.6625e-06, 1.7911e-04, 2.5992e-01, 2.4539e-05, 1.2901e-04, 3.7375e-04,
        6.7446e-05, 7.3814e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,186][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.1044, 0.0479, 0.0086, 0.1075, 0.0315, 0.0155, 0.2520, 0.0087, 0.0071,
        0.1845, 0.1266, 0.0114, 0.0209, 0.0735], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,189][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0477, 0.0151, 0.2558, 0.1117, 0.0902, 0.0392, 0.0664, 0.0602, 0.0513,
        0.0500, 0.1231, 0.0473, 0.0247, 0.0174], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,189][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0575, 0.0684, 0.0177, 0.1122, 0.0269, 0.0765, 0.1330, 0.0559, 0.0316,
        0.1785, 0.1409, 0.0372, 0.0262, 0.0375], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,190][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0196, 0.1598, 0.0729, 0.0274, 0.0301, 0.1227, 0.1810, 0.0131, 0.0283,
        0.1491, 0.0190, 0.0160, 0.0247, 0.1362], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,190][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0241, 0.0718, 0.0942, 0.0626, 0.0786, 0.0722, 0.0624, 0.0724, 0.0958,
        0.0624, 0.0613, 0.0904, 0.0701, 0.0818], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,190][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ said] are: tensor([3.5463e-04, 5.7978e-04, 2.9447e-04, 5.0627e-04, 3.5756e-04, 3.7005e-04,
        3.1154e-03, 2.5933e-04, 7.9996e-03, 8.4414e-03, 1.8314e-03, 1.1079e-03,
        1.5354e-03, 9.7325e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,191][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([5.2772e-04, 1.1835e-03, 3.3229e-03, 1.0444e-03, 4.6222e-03, 2.7951e-01,
        3.2961e-02, 3.1438e-02, 5.9500e-02, 5.3954e-03, 1.5269e-03, 2.5844e-02,
        4.0183e-03, 5.4903e-01, 8.0111e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,191][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0716, 0.0111, 0.0179, 0.0266, 0.0227, 0.0283, 0.0383, 0.0194, 0.0412,
        0.1230, 0.1242, 0.0811, 0.0920, 0.1650, 0.1376], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,193][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1334, 0.0320, 0.0102, 0.0572, 0.0106, 0.0461, 0.0807, 0.0166, 0.0214,
        0.1593, 0.1388, 0.0230, 0.0259, 0.0738, 0.1711], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,195][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0962, 0.0229, 0.0238, 0.0419, 0.0362, 0.0554, 0.0541, 0.0518, 0.0538,
        0.0824, 0.0918, 0.0818, 0.0749, 0.1144, 0.1188], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,199][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.2257, 0.0525, 0.0225, 0.0259, 0.0275, 0.0368, 0.0423, 0.0883, 0.0701,
        0.0936, 0.0615, 0.0447, 0.0627, 0.0696, 0.0763], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,202][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.2628e-05, 1.8565e-06, 4.6058e-05, 2.3668e-04, 1.3180e-04, 1.4057e-06,
        4.4538e-08, 1.0197e-03, 9.2986e-01, 8.4565e-07, 4.3878e-04, 2.5843e-02,
        2.0048e-04, 1.1741e-03, 4.1034e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,204][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1385, 0.0293, 0.0041, 0.0725, 0.0248, 0.0206, 0.3662, 0.0152, 0.0033,
        0.0954, 0.0752, 0.0077, 0.0176, 0.0604, 0.0692], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,205][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0494, 0.0421, 0.0878, 0.1144, 0.0463, 0.0434, 0.1085, 0.0237, 0.0718,
        0.0959, 0.0721, 0.0582, 0.0124, 0.0715, 0.1025], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,205][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0389, 0.0598, 0.0150, 0.1015, 0.0222, 0.0636, 0.1048, 0.0496, 0.0272,
        0.1653, 0.1271, 0.0321, 0.0213, 0.0322, 0.1393], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,205][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0172, 0.1589, 0.0479, 0.0397, 0.0227, 0.0878, 0.2081, 0.0130, 0.0141,
        0.1922, 0.0286, 0.0138, 0.0193, 0.0695, 0.0670], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,206][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0227, 0.0682, 0.0894, 0.0586, 0.0737, 0.0677, 0.0590, 0.0678, 0.0907,
        0.0589, 0.0573, 0.0838, 0.0659, 0.0775, 0.0588], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,206][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0017, 0.0032, 0.0047, 0.0070, 0.0018, 0.0051, 0.0326, 0.0033, 0.0119,
        0.0909, 0.0393, 0.0174, 0.0256, 0.0397, 0.7157], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,241][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:23,244][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,244][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,244][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,245][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,245][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,245][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,246][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,246][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,246][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,247][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,248][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,250][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,253][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9711, 0.0289], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,257][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2621, 0.7379], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,259][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.5000, 0.5000], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,260][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5000, 0.5000], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,260][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5210, 0.4790], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,260][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.7504, 0.2496], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,261][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.6877, 0.3123], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,261][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0013, 0.9987], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,261][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4881, 0.5119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,262][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0759, 0.9241], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,263][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0358, 0.9642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,266][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9058, 0.0942], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,270][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Jennifer] are: tensor([0.2831, 0.2981, 0.4188], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,275][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Jennifer] are: tensor([0.0749, 0.3880, 0.5370], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,275][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Jennifer] are: tensor([0.3334, 0.3333, 0.3333], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,275][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Jennifer] are: tensor([0.3333, 0.3333, 0.3334], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,275][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Jennifer] are: tensor([0.1430, 0.4529, 0.4041], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,276][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Jennifer] are: tensor([0.2756, 0.4357, 0.2887], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,276][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Jennifer] are: tensor([0.5501, 0.3821, 0.0679], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,276][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Jennifer] are: tensor([0.0035, 0.9177, 0.0789], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,277][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Jennifer] are: tensor([0.4637, 0.4225, 0.1138], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,277][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Jennifer] are: tensor([0.0547, 0.7816, 0.1637], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,277][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Jennifer] are: tensor([0.0203, 0.6500, 0.3298], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,277][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Jennifer] are: tensor([3.1489e-04, 1.9325e-03, 9.9775e-01], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,279][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1232, 0.1146, 0.6728, 0.0895], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,282][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0581, 0.2213, 0.4748, 0.2458], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,286][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2500, 0.2499, 0.2500, 0.2501], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,290][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2500, 0.2500, 0.2500, 0.2500], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,291][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1177, 0.1592, 0.4266, 0.2965], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,291][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0527, 0.0118, 0.0143, 0.9212], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,291][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.4173, 0.2029, 0.0620, 0.3179], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,291][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0249, 0.6216, 0.0914, 0.2621], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,292][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2599, 0.2735, 0.0476, 0.4191], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,292][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0394, 0.4965, 0.3133, 0.1508], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,292][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0202, 0.4655, 0.2438, 0.2705], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,293][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1064, 0.0314, 0.0010, 0.8612], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,293][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Megan] are: tensor([0.0597, 0.0623, 0.5565, 0.1976, 0.1239], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,295][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Megan] are: tensor([0.0392, 0.2088, 0.3183, 0.3563, 0.0774], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,297][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Megan] are: tensor([0.2000, 0.2000, 0.2000, 0.2002, 0.1998], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,301][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Megan] are: tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2001], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,306][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Megan] are: tensor([0.0827, 0.2535, 0.2082, 0.2413, 0.2142], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,306][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Megan] are: tensor([0.0153, 0.0132, 0.0268, 0.9219, 0.0228], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,306][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Megan] are: tensor([0.2484, 0.1653, 0.0571, 0.3885, 0.1408], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,307][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Megan] are: tensor([0.0465, 0.6069, 0.1404, 0.1820, 0.0241], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,307][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Megan] are: tensor([0.2457, 0.2598, 0.0554, 0.3598, 0.0793], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,307][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Megan] are: tensor([0.0412, 0.6438, 0.1248, 0.1402, 0.0501], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,308][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Megan] are: tensor([0.0133, 0.3695, 0.2058, 0.2345, 0.1769], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,308][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Megan] are: tensor([9.7699e-05, 1.1585e-04, 5.7212e-04, 2.7432e-04, 9.9894e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,308][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.5358, 0.0431, 0.0676, 0.1609, 0.0640, 0.1284], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,309][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0337, 0.1300, 0.2706, 0.1911, 0.1195, 0.2552], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,309][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.1667, 0.1667, 0.1667, 0.1668, 0.1665, 0.1667], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,310][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1666, 0.1666, 0.1667, 0.1666, 0.1667, 0.1667], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,313][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0701, 0.1644, 0.2244, 0.1530, 0.2110, 0.1771], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,317][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0180, 0.0155, 0.0204, 0.8971, 0.0243, 0.0246], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,321][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.3091, 0.1154, 0.0247, 0.2968, 0.1005, 0.1534], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,322][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0012, 0.4094, 0.0714, 0.2759, 0.0212, 0.2209], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,322][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.1894, 0.2416, 0.0481, 0.2739, 0.0887, 0.1583], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,323][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0212, 0.3316, 0.2249, 0.0716, 0.0940, 0.2568], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,323][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0118, 0.3148, 0.1619, 0.1837, 0.1338, 0.1940], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,323][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([2.4699e-04, 8.4351e-04, 2.1059e-04, 8.2678e-04, 1.2518e-04, 9.9775e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,323][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0091, 0.0076, 0.2014, 0.0237, 0.0198, 0.6983, 0.0401],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,324][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0312, 0.1033, 0.2077, 0.1520, 0.0822, 0.2698, 0.1539],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,324][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1429, 0.1429, 0.1429, 0.1430, 0.1427, 0.1429, 0.1429],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,324][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1428, 0.1428, 0.1429, 0.1428, 0.1429, 0.1429, 0.1428],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,325][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0679, 0.1062, 0.1492, 0.1462, 0.2032, 0.1515, 0.1758],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,326][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0247, 0.0088, 0.0189, 0.8986, 0.0214, 0.0170, 0.0105],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,329][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1210, 0.0548, 0.0142, 0.1057, 0.0474, 0.0504, 0.6066],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,333][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0099, 0.4318, 0.0826, 0.1751, 0.0266, 0.1634, 0.1106],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,337][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.2046, 0.1549, 0.0348, 0.2442, 0.0684, 0.1087, 0.1844],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,338][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0230, 0.2891, 0.1687, 0.0762, 0.0750, 0.1980, 0.1701],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,338][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0105, 0.2622, 0.1355, 0.1517, 0.1101, 0.1619, 0.1681],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,338][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([7.0085e-04, 3.5066e-04, 2.7415e-05, 5.8298e-04, 2.0294e-05, 2.0743e-04,
        9.9811e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,339][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0049, 0.0009, 0.0015, 0.0051, 0.0080, 0.3130, 0.6224, 0.0442],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,339][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0183, 0.0763, 0.1822, 0.1306, 0.0601, 0.2254, 0.2181, 0.0891],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,339][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.1250, 0.1250, 0.1250, 0.1251, 0.1249, 0.1250, 0.1250, 0.1250],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,340][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.1250, 0.1250, 0.1250, 0.1250, 0.1251, 0.1250, 0.1250, 0.1249],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,340][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0484, 0.1299, 0.1504, 0.1134, 0.1842, 0.1265, 0.1177, 0.1295],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,340][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0252, 0.0149, 0.0163, 0.8292, 0.0270, 0.0254, 0.0213, 0.0408],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,341][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.1421, 0.0554, 0.0056, 0.1087, 0.0132, 0.0539, 0.5813, 0.0397],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,342][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0007, 0.2512, 0.0797, 0.2188, 0.0244, 0.2051, 0.1485, 0.0717],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,345][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.1154, 0.1491, 0.0479, 0.2134, 0.0779, 0.0913, 0.2093, 0.0958],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,349][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0163, 0.2809, 0.1719, 0.0710, 0.0773, 0.1741, 0.1925, 0.0161],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,353][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0081, 0.2167, 0.1127, 0.1278, 0.0944, 0.1348, 0.1399, 0.1655],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,354][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([1.1772e-04, 3.0704e-04, 2.1093e-06, 5.8889e-04, 1.5555e-06, 5.7152e-04,
        9.5918e-05, 9.9832e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,354][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0006, 0.0013, 0.0337, 0.0118, 0.0108, 0.1888, 0.1906, 0.5571, 0.0053],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,354][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0177, 0.0697, 0.1483, 0.1119, 0.0612, 0.2262, 0.1688, 0.1159, 0.0804],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,355][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.1111, 0.1111, 0.1111, 0.1112, 0.1110, 0.1111, 0.1111, 0.1111, 0.1111],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,355][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.1111, 0.1111, 0.1112, 0.1111, 0.1112, 0.1111, 0.1111, 0.1110, 0.1110],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,355][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0457, 0.0973, 0.1456, 0.0876, 0.1718, 0.1302, 0.0894, 0.0913, 0.1412],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,356][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0106, 0.0188, 0.0226, 0.7466, 0.0380, 0.0310, 0.0326, 0.0510, 0.0487],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,356][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.1446, 0.0674, 0.0111, 0.1337, 0.0356, 0.0568, 0.4921, 0.0286, 0.0302],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,356][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0006, 0.3674, 0.0467, 0.2255, 0.0099, 0.1693, 0.1082, 0.0525, 0.0199],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,358][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.1643, 0.1236, 0.0499, 0.1493, 0.0932, 0.1041, 0.1602, 0.0941, 0.0614],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,361][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0142, 0.2637, 0.1225, 0.0566, 0.0496, 0.1782, 0.2764, 0.0161, 0.0227],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,365][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0074, 0.1835, 0.0990, 0.1126, 0.0828, 0.1206, 0.1257, 0.1487, 0.1197],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,367][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([8.5601e-04, 7.8631e-04, 3.8970e-04, 1.2275e-03, 8.1607e-05, 6.9614e-05,
        7.4370e-04, 2.5823e-05, 9.9582e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,369][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0518, 0.0030, 0.0227, 0.0227, 0.0429, 0.0270, 0.1376, 0.1628, 0.5045,
        0.0252], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,370][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0183, 0.0519, 0.1270, 0.0950, 0.0658, 0.2006, 0.1299, 0.1108, 0.0853,
        0.1154], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,370][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1000, 0.1000, 0.1000, 0.1001, 0.0999, 0.1000, 0.1000, 0.1000, 0.1000,
        0.1000], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,370][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1001, 0.1000, 0.1000, 0.0999, 0.0999,
        0.1000], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,371][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0397, 0.0723, 0.1335, 0.0978, 0.1412, 0.1138, 0.0853, 0.0935, 0.1388,
        0.0840], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,371][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0360, 0.0234, 0.0194, 0.7190, 0.0212, 0.0205, 0.0129, 0.0236, 0.0191,
        0.1050], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,371][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0929, 0.0555, 0.0171, 0.0809, 0.0558, 0.0563, 0.3701, 0.0500, 0.0223,
        0.1991], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,372][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0306, 0.2861, 0.0597, 0.1323, 0.0273, 0.1391, 0.0850, 0.1113, 0.0840,
        0.0445], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,372][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1432, 0.1180, 0.0303, 0.1422, 0.0561, 0.0910, 0.1278, 0.0654, 0.0411,
        0.1849], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,374][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0186, 0.2117, 0.1318, 0.0607, 0.0608, 0.1200, 0.1275, 0.0168, 0.0279,
        0.2241], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,376][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0072, 0.1666, 0.0884, 0.1012, 0.0731, 0.1083, 0.1126, 0.1326, 0.1063,
        0.1038], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,380][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0737, 0.0140, 0.0393, 0.0676, 0.1429, 0.3164, 0.1252, 0.0997, 0.1168,
        0.0045], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,384][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0046, 0.0057, 0.0326, 0.0043, 0.1133, 0.0199, 0.1533, 0.3693, 0.2461,
        0.0428, 0.0082], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,385][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0171, 0.0602, 0.1277, 0.0620, 0.0636, 0.1803, 0.1380, 0.0973, 0.0731,
        0.1247, 0.0559], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,386][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0909, 0.0909, 0.0909, 0.0910, 0.0908, 0.0909, 0.0909, 0.0909, 0.0909,
        0.0909, 0.0910], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,386][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0909, 0.0909, 0.0909, 0.0909, 0.0910, 0.0909, 0.0909, 0.0909, 0.0908,
        0.0909, 0.0909], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,386][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0355, 0.0536, 0.1162, 0.0983, 0.1527, 0.0874, 0.0784, 0.0796, 0.1297,
        0.0771, 0.0915], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,387][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0235, 0.0050, 0.0066, 0.3750, 0.0084, 0.0084, 0.0053, 0.0098, 0.0061,
        0.0116, 0.5403], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,387][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0847, 0.0452, 0.0151, 0.0679, 0.0564, 0.0480, 0.3808, 0.0377, 0.0178,
        0.1588, 0.0875], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,387][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0569, 0.2593, 0.0595, 0.1198, 0.0337, 0.1337, 0.0851, 0.0995, 0.0734,
        0.0481, 0.0309], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,388][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1019, 0.0964, 0.0193, 0.1505, 0.0318, 0.0695, 0.0983, 0.0493, 0.0259,
        0.1751, 0.1820], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,388][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0175, 0.1910, 0.1412, 0.0607, 0.0633, 0.1052, 0.1255, 0.0168, 0.0287,
        0.1952, 0.0549], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,390][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0069, 0.1526, 0.0810, 0.0933, 0.0665, 0.0992, 0.1026, 0.1204, 0.0963,
        0.0937, 0.0874], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,393][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0292, 0.0177, 0.0004, 0.3722, 0.0010, 0.2512, 0.0058, 0.0034, 0.0058,
        0.0033, 0.3101], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,397][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0016, 0.0029, 0.0040, 0.0128, 0.0078, 0.0955, 0.0148, 0.7681, 0.0228,
        0.0401, 0.0249, 0.0048], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,401][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0115, 0.0504, 0.1061, 0.1008, 0.0401, 0.1526, 0.1035, 0.0833, 0.0688,
        0.1353, 0.0993, 0.0482], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,401][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0833, 0.0833, 0.0833, 0.0834, 0.0832, 0.0833, 0.0833, 0.0833, 0.0833,
        0.0833, 0.0834, 0.0834], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,402][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0833, 0.0833, 0.0834, 0.0833, 0.0834, 0.0834, 0.0833, 0.0833, 0.0833,
        0.0833, 0.0833, 0.0834], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,402][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0322, 0.0881, 0.0879, 0.0993, 0.0958, 0.0775, 0.0871, 0.0830, 0.0998,
        0.0939, 0.0687, 0.0867], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,403][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([9.1867e-03, 1.2800e-02, 4.0499e-03, 3.5421e-01, 4.7311e-03, 1.3440e-02,
        9.7130e-03, 1.5141e-02, 4.9195e-03, 6.3075e-02, 5.0845e-01, 2.7896e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,403][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0674, 0.0439, 0.0055, 0.1007, 0.0134, 0.0399, 0.2882, 0.0279, 0.0071,
        0.2553, 0.1350, 0.0155], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,403][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.1907, 0.3508, 0.0796, 0.0574, 0.0204, 0.0659, 0.0576, 0.0705, 0.0584,
        0.0260, 0.0143, 0.0083], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,404][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.1094, 0.0957, 0.0494, 0.0885, 0.0606, 0.0538, 0.0889, 0.1094, 0.0756,
        0.1028, 0.1030, 0.0629], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,404][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0127, 0.1815, 0.0726, 0.0429, 0.0413, 0.1938, 0.1613, 0.0113, 0.0170,
        0.2127, 0.0315, 0.0214], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,405][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0070, 0.1379, 0.0729, 0.0856, 0.0607, 0.0903, 0.0935, 0.1091, 0.0887,
        0.0869, 0.0818, 0.0854], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,407][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([3.2235e-04, 1.6957e-04, 2.1183e-05, 4.5342e-04, 3.1359e-05, 8.2625e-05,
        1.6272e-05, 6.0611e-04, 2.3273e-04, 7.3099e-05, 2.2445e-04, 9.9777e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,410][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Megan] are: tensor([0.0051, 0.0055, 0.0398, 0.0187, 0.0087, 0.3683, 0.1898, 0.1699, 0.0444,
        0.0688, 0.0437, 0.0271, 0.0103], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,414][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Megan] are: tensor([0.0107, 0.0573, 0.0845, 0.0979, 0.0205, 0.1233, 0.1641, 0.0721, 0.0635,
        0.1374, 0.0883, 0.0670, 0.0136], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,417][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Megan] are: tensor([0.0769, 0.0769, 0.0769, 0.0770, 0.0768, 0.0769, 0.0769, 0.0769, 0.0769,
        0.0769, 0.0770, 0.0770, 0.0769], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,417][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Megan] are: tensor([0.0769, 0.0769, 0.0769, 0.0769, 0.0770, 0.0769, 0.0769, 0.0769, 0.0769,
        0.0769, 0.0769, 0.0770, 0.0770], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,418][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Megan] are: tensor([0.0292, 0.0948, 0.0740, 0.0873, 0.0769, 0.0880, 0.0654, 0.0737, 0.1355,
        0.0569, 0.0573, 0.1003, 0.0609], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,418][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Megan] are: tensor([2.3781e-03, 7.9321e-03, 1.0572e-02, 3.3685e-01, 1.2140e-02, 1.1258e-02,
        1.3979e-02, 2.0120e-02, 1.3896e-02, 3.5846e-02, 5.2906e-01, 3.1609e-04,
        5.6547e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,418][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Megan] are: tensor([0.0596, 0.0398, 0.0139, 0.0973, 0.0352, 0.0283, 0.3347, 0.0192, 0.0064,
        0.1971, 0.1316, 0.0106, 0.0262], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,419][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Megan] are: tensor([0.0154, 0.3203, 0.0764, 0.1345, 0.0143, 0.1433, 0.1227, 0.0628, 0.0488,
        0.0350, 0.0198, 0.0031, 0.0037], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,419][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Megan] are: tensor([0.0938, 0.0968, 0.0210, 0.1340, 0.0289, 0.0541, 0.0827, 0.0682, 0.0386,
        0.1368, 0.1661, 0.0508, 0.0283], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,420][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Megan] are: tensor([0.0121, 0.1943, 0.0351, 0.0415, 0.0138, 0.1522, 0.2451, 0.0123, 0.0156,
        0.2280, 0.0263, 0.0127, 0.0110], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,422][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Megan] are: tensor([0.0054, 0.1207, 0.0662, 0.0794, 0.0571, 0.0851, 0.0886, 0.1013, 0.0844,
        0.0834, 0.0792, 0.0838, 0.0654], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,423][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Megan] are: tensor([1.3441e-06, 2.0021e-05, 2.9079e-04, 2.2811e-06, 7.8193e-01, 3.0462e-06,
        1.6938e-06, 1.7861e-07, 1.5888e-06, 1.3373e-04, 5.3957e-06, 6.5241e-06,
        2.1761e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,427][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0255, 0.0092, 0.0647, 0.0498, 0.0166, 0.1924, 0.0822, 0.2580, 0.0093,
        0.1065, 0.1253, 0.0194, 0.0199, 0.0211], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,431][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0156, 0.0563, 0.0951, 0.0770, 0.0411, 0.1157, 0.0873, 0.0826, 0.0503,
        0.1350, 0.0792, 0.0827, 0.0281, 0.0540], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,432][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0714, 0.0714, 0.0714, 0.0715, 0.0713, 0.0714, 0.0714, 0.0714, 0.0714,
        0.0714, 0.0715, 0.0715, 0.0714, 0.0714], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,433][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0714, 0.0714, 0.0715, 0.0714, 0.0715, 0.0714, 0.0714, 0.0714, 0.0714,
        0.0714, 0.0714, 0.0715, 0.0715, 0.0714], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,433][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0210, 0.0660, 0.0951, 0.0576, 0.1007, 0.0720, 0.0608, 0.0457, 0.0851,
        0.0788, 0.0469, 0.0817, 0.0836, 0.1049], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,434][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0079, 0.0162, 0.0055, 0.3517, 0.0102, 0.0174, 0.0148, 0.0211, 0.0109,
        0.0517, 0.4843, 0.0007, 0.0042, 0.0034], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,434][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0778, 0.0407, 0.0096, 0.0767, 0.0296, 0.0363, 0.2460, 0.0210, 0.0214,
        0.1722, 0.1203, 0.0236, 0.0216, 0.1032], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,434][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0050, 0.3018, 0.0391, 0.1737, 0.0130, 0.1412, 0.1025, 0.0897, 0.0435,
        0.0438, 0.0242, 0.0016, 0.0035, 0.0175], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,435][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.1256, 0.0810, 0.0265, 0.0940, 0.0456, 0.0713, 0.1099, 0.0536, 0.0397,
        0.1136, 0.1049, 0.0473, 0.0457, 0.0412], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,436][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0138, 0.1373, 0.1179, 0.0330, 0.0516, 0.1286, 0.1067, 0.0131, 0.0321,
        0.1427, 0.0274, 0.0228, 0.0458, 0.1273], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,439][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0062, 0.1288, 0.0628, 0.0744, 0.0500, 0.0775, 0.0789, 0.0927, 0.0733,
        0.0719, 0.0677, 0.0702, 0.0554, 0.0902], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,441][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([6.9979e-05, 1.2552e-04, 4.5903e-06, 1.8236e-04, 8.7230e-06, 3.3157e-05,
        1.3427e-04, 3.2379e-06, 3.7719e-04, 6.9511e-05, 9.3497e-05, 2.0964e-05,
        1.1242e-06, 9.9888e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,443][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([8.0670e-03, 2.0149e-03, 2.5571e-03, 2.5100e-03, 5.8975e-03, 3.0474e-01,
        3.9072e-02, 1.4885e-01, 8.4989e-02, 1.9035e-02, 6.1298e-03, 1.2083e-02,
        6.9611e-03, 3.5682e-01, 2.7084e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,448][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0136, 0.0414, 0.0886, 0.0724, 0.0442, 0.1235, 0.1021, 0.0718, 0.0486,
        0.0904, 0.0712, 0.0676, 0.0323, 0.0828, 0.0496], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,448][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0667, 0.0667, 0.0667, 0.0667, 0.0666, 0.0667, 0.0667, 0.0666, 0.0667,
        0.0666, 0.0667, 0.0667, 0.0667, 0.0667, 0.0667], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,448][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0667, 0.0667, 0.0667, 0.0667, 0.0667, 0.0667, 0.0667, 0.0666, 0.0666,
        0.0667, 0.0666, 0.0667, 0.0667, 0.0666, 0.0667], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,449][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0316, 0.0413, 0.0897, 0.0571, 0.1002, 0.0639, 0.0791, 0.0665, 0.0669,
        0.0670, 0.0523, 0.0819, 0.0870, 0.0567, 0.0589], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,449][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0063, 0.0080, 0.0063, 0.3558, 0.0130, 0.0153, 0.0144, 0.0193, 0.0121,
        0.0273, 0.4944, 0.0007, 0.0057, 0.0026, 0.0189], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,450][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0903, 0.0303, 0.0056, 0.0609, 0.0242, 0.0371, 0.3182, 0.0279, 0.0114,
        0.1135, 0.0802, 0.0165, 0.0177, 0.0803, 0.0859], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,450][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0231, 0.2851, 0.0499, 0.1125, 0.0183, 0.1473, 0.0906, 0.0978, 0.0676,
        0.0405, 0.0236, 0.0034, 0.0066, 0.0240, 0.0096], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,450][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0956, 0.0756, 0.0203, 0.0945, 0.0332, 0.0551, 0.0764, 0.0527, 0.0279,
        0.1119, 0.1098, 0.0442, 0.0323, 0.0316, 0.1387], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,451][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0140, 0.1512, 0.0913, 0.0433, 0.0465, 0.1014, 0.1049, 0.0129, 0.0214,
        0.1667, 0.0372, 0.0241, 0.0414, 0.0874, 0.0563], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,452][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0044, 0.1081, 0.0530, 0.0648, 0.0440, 0.0675, 0.0696, 0.0819, 0.0663,
        0.0659, 0.0626, 0.0652, 0.0525, 0.0841, 0.1102], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,454][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([5.2830e-03, 4.4542e-03, 1.1188e-04, 1.4306e-02, 2.9934e-05, 2.4719e-03,
        4.5770e-03, 1.7534e-04, 4.6631e-04, 6.5708e-04, 3.1810e-03, 3.4716e-04,
        1.7717e-06, 1.1144e-02, 9.5279e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,455][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:23,457][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 7541],
        [32781],
        [ 9003],
        [36092],
        [28054],
        [27367],
        [34743],
        [36719],
        [30051],
        [29473],
        [38038],
        [25368],
        [36343],
        [25502],
        [25000]], device='cuda:0')
[2024-07-24 10:29:23,459][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 6960],
        [14276],
        [    3],
        [21015],
        [ 4866],
        [14696],
        [19061],
        [14310],
        [18206],
        [19979],
        [16070],
        [23375],
        [12058],
        [ 2648],
        [ 9027]], device='cuda:0')
[2024-07-24 10:29:23,462][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[16262],
        [14423],
        [12618],
        [14522],
        [15500],
        [ 6852],
        [ 5619],
        [ 1459],
        [ 3507],
        [15435],
        [10645],
        [12552],
        [ 3535],
        [ 4604],
        [ 7211]], device='cuda:0')
[2024-07-24 10:29:23,464][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[31144],
        [31085],
        [26612],
        [28149],
        [33635],
        [28795],
        [29272],
        [28640],
        [30142],
        [28241],
        [30712],
        [35280],
        [35562],
        [32876],
        [28124]], device='cuda:0')
[2024-07-24 10:29:23,467][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[11763],
        [12240],
        [12093],
        [11080],
        [11164],
        [11899],
        [11802],
        [11154],
        [11285],
        [13520],
        [13448],
        [12928],
        [13119],
        [11797],
        [10975]], device='cuda:0')
[2024-07-24 10:29:23,468][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[13759],
        [11065],
        [13378],
        [14060],
        [14266],
        [13569],
        [13097],
        [12891],
        [13024],
        [12934],
        [13080],
        [13090],
        [13156],
        [13203],
        [13124]], device='cuda:0')
[2024-07-24 10:29:23,469][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 6897],
        [15636],
        [17918],
        [20135],
        [18665],
        [23360],
        [23768],
        [27423],
        [29106],
        [29681],
        [29180],
        [29230],
        [31618],
        [30461],
        [31211]], device='cuda:0')
[2024-07-24 10:29:23,470][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 5609],
        [30628],
        [41791],
        [19453],
        [36965],
        [44876],
        [39856],
        [24533],
        [10771],
        [ 8029],
        [12260],
        [18615],
        [19126],
        [29496],
        [ 8027]], device='cuda:0')
[2024-07-24 10:29:23,471][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[6936],
        [6862],
        [5849],
        [6084],
        [5720],
        [6032],
        [8268],
        [9431],
        [8809],
        [7735],
        [7796],
        [9329],
        [8720],
        [7525],
        [8407]], device='cuda:0')
[2024-07-24 10:29:23,472][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 8039],
        [ 8238],
        [    4],
        [  181],
        [  165],
        [   23],
        [   81],
        [12508],
        [  546],
        [   36],
        [ 5020],
        [20551],
        [20795],
        [   90],
        [16779]], device='cuda:0')
[2024-07-24 10:29:23,474][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 9900],
        [14410],
        [18139],
        [18675],
        [19128],
        [15691],
        [14742],
        [15671],
        [15172],
        [15189],
        [16006],
        [15646],
        [15684],
        [15000],
        [15193]], device='cuda:0')
[2024-07-24 10:29:23,476][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[43417],
        [44163],
        [45355],
        [46106],
        [45280],
        [46733],
        [45988],
        [46014],
        [45892],
        [45377],
        [45092],
        [45290],
        [44756],
        [45179],
        [45089]], device='cuda:0')
[2024-07-24 10:29:23,478][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[3982],
        [6256],
        [7774],
        [8356],
        [8717],
        [9028],
        [8821],
        [8677],
        [8124],
        [8125],
        [8340],
        [7853],
        [8063],
        [8026],
        [8091]], device='cuda:0')
[2024-07-24 10:29:23,480][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[19700],
        [11273],
        [40474],
        [ 7724],
        [45913],
        [16282],
        [19714],
        [16896],
        [ 7922],
        [23878],
        [ 7971],
        [21334],
        [43851],
        [22079],
        [25781]], device='cuda:0')
[2024-07-24 10:29:23,483][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[10197],
        [19662],
        [20561],
        [22769],
        [34720],
        [28519],
        [17827],
        [33414],
        [42221],
        [16260],
        [23144],
        [36509],
        [37000],
        [21760],
        [16043]], device='cuda:0')
[2024-07-24 10:29:23,485][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[24203],
        [23681],
        [34929],
        [38798],
        [37017],
        [24923],
        [19060],
        [10558],
        [25600],
        [27793],
        [26626],
        [32322],
        [12845],
        [16198],
        [16054]], device='cuda:0')
[2024-07-24 10:29:23,486][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[6992],
        [4418],
        [8356],
        [7159],
        [6080],
        [6245],
        [6859],
        [6774],
        [6511],
        [6345],
        [6271],
        [5839],
        [6037],
        [5540],
        [5777]], device='cuda:0')
[2024-07-24 10:29:23,487][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[3186],
        [3186],
        [3187],
        [3187],
        [3187],
        [3186],
        [3187],
        [3187],
        [3187],
        [3187],
        [3187],
        [3187],
        [3187],
        [3187],
        [3187]], device='cuda:0')
[2024-07-24 10:29:23,488][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[7223],
        [7225],
        [7240],
        [7229],
        [7228],
        [7229],
        [7226],
        [7225],
        [7226],
        [7229],
        [7228],
        [7230],
        [7231],
        [7231],
        [7231]], device='cuda:0')
[2024-07-24 10:29:23,489][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[27027],
        [24538],
        [30309],
        [35368],
        [34135],
        [39577],
        [41588],
        [39731],
        [37547],
        [37203],
        [37444],
        [37381],
        [36775],
        [37383],
        [38232]], device='cuda:0')
[2024-07-24 10:29:23,490][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[35892],
        [34955],
        [29971],
        [21881],
        [21313],
        [21630],
        [21731],
        [22315],
        [23042],
        [23134],
        [21925],
        [22180],
        [22006],
        [22403],
        [22161]], device='cuda:0')
[2024-07-24 10:29:23,491][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[43577],
        [43622],
        [42871],
        [45979],
        [46102],
        [44937],
        [44539],
        [44613],
        [44750],
        [45007],
        [45926],
        [46974],
        [46724],
        [46699],
        [46603]], device='cuda:0')
[2024-07-24 10:29:23,494][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[32636],
        [36352],
        [40685],
        [41260],
        [43966],
        [43537],
        [44858],
        [46529],
        [44842],
        [47168],
        [47293],
        [46394],
        [46873],
        [46339],
        [46963]], device='cuda:0')
[2024-07-24 10:29:23,495][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[9315],
        [8140],
        [7349],
        [7423],
        [7373],
        [7867],
        [8139],
        [7697],
        [7230],
        [7904],
        [8025],
        [7131],
        [7627],
        [7650],
        [7609]], device='cuda:0')
[2024-07-24 10:29:23,497][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[7429],
        [9070],
        [8780],
        [8151],
        [8487],
        [7542],
        [6912],
        [6774],
        [6631],
        [7531],
        [7493],
        [7536],
        [7395],
        [7099],
        [7412]], device='cuda:0')
[2024-07-24 10:29:23,500][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[7876],
        [7754],
        [7793],
        [7806],
        [7909],
        [8120],
        [8362],
        [8548],
        [8654],
        [8689],
        [8674],
        [8689],
        [8732],
        [8719],
        [8673]], device='cuda:0')
[2024-07-24 10:29:23,502][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[16306],
        [16490],
        [27673],
        [23582],
        [19172],
        [29570],
        [31843],
        [36782],
        [34829],
        [28026],
        [20839],
        [48422],
        [ 7714],
        [41940],
        [12358]], device='cuda:0')
[2024-07-24 10:29:23,505][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[26823],
        [30136],
        [23953],
        [20353],
        [21823],
        [23466],
        [23870],
        [25625],
        [24515],
        [22032],
        [21664],
        [19979],
        [26623],
        [23475],
        [24111]], device='cuda:0')
[2024-07-24 10:29:23,506][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[31961],
        [38859],
        [44466],
        [35833],
        [28318],
        [20568],
        [37019],
        [28070],
        [21407],
        [40666],
        [34561],
        [ 8549],
        [27768],
        [34024],
        [36979]], device='cuda:0')
[2024-07-24 10:29:23,506][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[22134],
        [22134],
        [22134],
        [22134],
        [22134],
        [22134],
        [22134],
        [22134],
        [22134],
        [22134],
        [22134],
        [22134],
        [22134],
        [22134],
        [22134]], device='cuda:0')
[2024-07-24 10:29:23,533][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:23,536][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,536][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,537][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,537][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,537][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,538][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,538][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,538][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,539][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,539][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,539][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,541][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,543][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.7429, 0.2571], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,547][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.3441, 0.6559], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,556][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0919, 0.9081], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,559][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6680, 0.3320], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,563][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5657, 0.4343], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,567][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.8181, 0.1819], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,567][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2429, 0.7571], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,568][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.5358, 0.4642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,568][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9041, 0.0959], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,568][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.6661, 0.3339], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,569][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.5071, 0.4929], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,569][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6142, 0.3858], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,569][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Jennifer] are: tensor([0.4244, 0.2946, 0.2810], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,570][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Jennifer] are: tensor([0.3051, 0.5216, 0.1733], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,570][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Jennifer] are: tensor([0.0167, 0.3379, 0.6454], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,572][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Jennifer] are: tensor([0.4908, 0.2313, 0.2779], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,574][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Jennifer] are: tensor([0.2278, 0.7053, 0.0669], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,578][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Jennifer] are: tensor([0.8058, 0.1154, 0.0788], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,582][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Jennifer] are: tensor([0.0613, 0.2620, 0.6767], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,583][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Jennifer] are: tensor([0.3947, 0.3306, 0.2748], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,583][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Jennifer] are: tensor([0.4533, 0.5266, 0.0201], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,584][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Jennifer] are: tensor([0.5045, 0.3167, 0.1787], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,584][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Jennifer] are: tensor([0.2800, 0.3365, 0.3835], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,584][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Jennifer] are: tensor([0.2571, 0.1786, 0.5643], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,585][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2578, 0.1607, 0.1800, 0.4016], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,585][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1365, 0.2440, 0.1914, 0.4281], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,586][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0147, 0.2124, 0.6623, 0.1106], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,586][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3651, 0.1927, 0.2266, 0.2156], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,587][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1088, 0.5568, 0.1394, 0.1950], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,590][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.6021, 0.1419, 0.1828, 0.0732], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,590][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0617, 0.2090, 0.4366, 0.2926], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,591][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3126, 0.2633, 0.2244, 0.1998], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,591][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.3294, 0.2682, 0.3594, 0.0429], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,595][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.3604, 0.2015, 0.3100, 0.1282], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,598][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2396, 0.2475, 0.2690, 0.2439], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,600][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2169, 0.1525, 0.4983, 0.1324], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,600][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Megan] are: tensor([0.1837, 0.1147, 0.1345, 0.3380, 0.2292], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,601][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Megan] are: tensor([0.0854, 0.1408, 0.0442, 0.6500, 0.0795], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,601][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Megan] are: tensor([0.0010, 0.0220, 0.0734, 0.0157, 0.8878], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,601][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Megan] are: tensor([0.3246, 0.1486, 0.1753, 0.1720, 0.1795], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,602][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Megan] are: tensor([0.0870, 0.3909, 0.1154, 0.3455, 0.0612], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,602][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Megan] are: tensor([0.7463, 0.0658, 0.1019, 0.0653, 0.0207], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,603][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Megan] are: tensor([0.0287, 0.1187, 0.2849, 0.1634, 0.4043], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,603][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Megan] are: tensor([0.2539, 0.2208, 0.1775, 0.1754, 0.1723], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,605][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Megan] are: tensor([0.2843, 0.2121, 0.0439, 0.4550, 0.0047], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,607][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Megan] are: tensor([0.2866, 0.2014, 0.2368, 0.1762, 0.0991], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,611][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Megan] are: tensor([0.1690, 0.1998, 0.2193, 0.1884, 0.2235], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,615][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Megan] are: tensor([0.1532, 0.0978, 0.3060, 0.0903, 0.3526], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,616][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.1403, 0.0953, 0.1054, 0.2729, 0.1824, 0.2037], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,616][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0656, 0.1247, 0.0622, 0.3959, 0.1187, 0.2328], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,616][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ had] are: tensor([8.9395e-04, 1.4786e-02, 5.8143e-02, 7.7118e-03, 8.9999e-01, 1.8472e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,617][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.2604, 0.1262, 0.1502, 0.1447, 0.1531, 0.1654], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,617][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1584, 0.2141, 0.0149, 0.3649, 0.1298, 0.1178], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,618][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.5663, 0.0896, 0.1127, 0.0866, 0.0867, 0.0581], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,618][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0271, 0.1064, 0.2239, 0.1545, 0.3117, 0.1762], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,618][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.2152, 0.1821, 0.1563, 0.1419, 0.1529, 0.1516], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,620][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1716, 0.5565, 0.0782, 0.0902, 0.0719, 0.0315], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,622][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.2371, 0.1585, 0.1992, 0.1453, 0.1770, 0.0830], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,626][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.1497, 0.1665, 0.1818, 0.1542, 0.1874, 0.1605], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,629][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.1237, 0.0883, 0.2811, 0.0694, 0.3491, 0.0884], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,631][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1134, 0.0741, 0.0817, 0.1800, 0.1436, 0.1421, 0.2651],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,632][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0612, 0.1113, 0.1244, 0.1728, 0.2048, 0.1739, 0.1517],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,632][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([1.9316e-04, 7.2785e-03, 3.9006e-02, 4.7118e-03, 9.2336e-01, 1.5053e-02,
        1.0394e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,632][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2210, 0.1111, 0.1289, 0.1256, 0.1310, 0.1428, 0.1395],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,633][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1362, 0.2146, 0.0567, 0.2556, 0.1293, 0.1456, 0.0619],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,633][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.5472, 0.0790, 0.0920, 0.0793, 0.0529, 0.1170, 0.0327],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,634][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0230, 0.0900, 0.1891, 0.1313, 0.2657, 0.1575, 0.1433],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,634][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1788, 0.1594, 0.1383, 0.1273, 0.1346, 0.1322, 0.1294],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,636][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1050, 0.0951, 0.0465, 0.1494, 0.0267, 0.5715, 0.0058],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,638][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2158, 0.1454, 0.1632, 0.1314, 0.1434, 0.1249, 0.0759],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,642][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1369, 0.1409, 0.1509, 0.1424, 0.1543, 0.1421, 0.1325],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,646][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1185, 0.0823, 0.2461, 0.0779, 0.2993, 0.0958, 0.0800],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,647][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0837, 0.0539, 0.0641, 0.1537, 0.1137, 0.1166, 0.2413, 0.1730],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,647][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0468, 0.0706, 0.0346, 0.2083, 0.0732, 0.1117, 0.3261, 0.1287],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,648][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ long] are: tensor([7.0440e-04, 1.1959e-02, 4.7653e-02, 7.7419e-03, 8.2643e-01, 2.2718e-02,
        2.1508e-02, 6.1284e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,648][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.1931, 0.0971, 0.1120, 0.1101, 0.1134, 0.1242, 0.1227, 0.1274],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,649][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0936, 0.1451, 0.0079, 0.1902, 0.2360, 0.1191, 0.1538, 0.0544],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,649][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.4427, 0.0643, 0.1195, 0.0841, 0.0631, 0.0989, 0.0757, 0.0517],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,649][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0199, 0.0747, 0.1571, 0.1041, 0.2176, 0.1275, 0.1232, 0.1758],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,650][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.1615, 0.1384, 0.1198, 0.1158, 0.1192, 0.1192, 0.1117, 0.1142],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,651][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0683, 0.1840, 0.0675, 0.0737, 0.0192, 0.5263, 0.0542, 0.0067],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,654][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.1711, 0.1195, 0.1238, 0.1374, 0.1487, 0.1319, 0.0972, 0.0704],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,658][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.1199, 0.1288, 0.1324, 0.1258, 0.1341, 0.1263, 0.1146, 0.1182],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,662][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.1086, 0.0742, 0.2343, 0.0628, 0.2856, 0.0869, 0.0715, 0.0761],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,663][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0727, 0.0421, 0.0535, 0.1242, 0.0995, 0.0921, 0.1972, 0.1462, 0.1726],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,663][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0458, 0.0678, 0.0352, 0.1992, 0.0591, 0.1142, 0.2838, 0.1112, 0.0835],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,663][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0008, 0.0133, 0.0470, 0.0093, 0.7156, 0.0269, 0.0295, 0.0793, 0.0783],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,664][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.1727, 0.0857, 0.0983, 0.0973, 0.1007, 0.1091, 0.1083, 0.1133, 0.1147],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,664][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0294, 0.1199, 0.0551, 0.1819, 0.1040, 0.2182, 0.1551, 0.1047, 0.0317],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,665][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.3758, 0.0752, 0.0997, 0.0788, 0.0628, 0.0905, 0.0733, 0.0779, 0.0660],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,665][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0141, 0.0602, 0.1324, 0.0844, 0.1868, 0.1019, 0.1022, 0.1506, 0.1674],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,665][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.1431, 0.1187, 0.1084, 0.1008, 0.1064, 0.1082, 0.1015, 0.1019, 0.1109],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,667][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0486, 0.1425, 0.0544, 0.0882, 0.0413, 0.4894, 0.1138, 0.0194, 0.0025],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,670][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.1636, 0.1242, 0.1209, 0.1114, 0.1191, 0.1256, 0.0888, 0.0913, 0.0550],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,674][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.1094, 0.1184, 0.1169, 0.1107, 0.1169, 0.1142, 0.1043, 0.1059, 0.1033],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,678][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0952, 0.0601, 0.2188, 0.0530, 0.2602, 0.0780, 0.0670, 0.0791, 0.0886],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,678][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0749, 0.0348, 0.0448, 0.0845, 0.0832, 0.0704, 0.1364, 0.1203, 0.1595,
        0.1913], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,679][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0360, 0.0683, 0.0604, 0.1193, 0.0936, 0.1143, 0.1300, 0.1505, 0.1310,
        0.0966], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,679][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([2.0222e-04, 6.7878e-03, 3.8680e-02, 4.7286e-03, 8.1366e-01, 1.3902e-02,
        9.6910e-03, 4.1404e-02, 5.2798e-02, 1.8142e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,679][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1496, 0.0789, 0.0901, 0.0886, 0.0907, 0.0993, 0.0978, 0.1014, 0.1032,
        0.1004], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,680][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0860, 0.0766, 0.0498, 0.1259, 0.1414, 0.0639, 0.2190, 0.0851, 0.0548,
        0.0974], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,680][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.3355, 0.0506, 0.0740, 0.0761, 0.0592, 0.0930, 0.0525, 0.0747, 0.1047,
        0.0796], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,681][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0154, 0.0561, 0.1124, 0.0801, 0.1558, 0.0967, 0.0910, 0.1317, 0.1519,
        0.1088], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,681][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1305, 0.1121, 0.0990, 0.0914, 0.0972, 0.0967, 0.0930, 0.0917, 0.1017,
        0.0867], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,683][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1821, 0.0200, 0.0330, 0.0809, 0.0116, 0.4283, 0.0904, 0.0456, 0.0964,
        0.0117], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,685][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1606, 0.0821, 0.1160, 0.0923, 0.1097, 0.0983, 0.0965, 0.0868, 0.0953,
        0.0625], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,689][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0965, 0.1023, 0.1054, 0.1025, 0.1088, 0.1054, 0.0941, 0.0976, 0.0941,
        0.0935], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,693][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0881, 0.0572, 0.1936, 0.0589, 0.2461, 0.0712, 0.0613, 0.0668, 0.0785,
        0.0782], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,694][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0531, 0.0267, 0.0339, 0.0679, 0.0662, 0.0547, 0.1134, 0.0950, 0.1232,
        0.1668, 0.1991], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,694][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0357, 0.0647, 0.0713, 0.0920, 0.1063, 0.0985, 0.0882, 0.1412, 0.1389,
        0.0760, 0.0872], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,695][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([1.9980e-04, 7.1497e-03, 3.7495e-02, 3.8904e-03, 7.8903e-01, 1.3184e-02,
        9.1071e-03, 3.9608e-02, 4.9884e-02, 1.9764e-02, 3.0686e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,695][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1366, 0.0720, 0.0826, 0.0800, 0.0831, 0.0909, 0.0888, 0.0927, 0.0939,
        0.0913, 0.0881], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,695][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0324, 0.2647, 0.0678, 0.0727, 0.0284, 0.0392, 0.1520, 0.0253, 0.0126,
        0.2633, 0.0415], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,696][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2909, 0.0578, 0.0777, 0.0327, 0.0514, 0.0958, 0.0536, 0.0794, 0.1072,
        0.0942, 0.0594], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,696][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0150, 0.0525, 0.1058, 0.0750, 0.1448, 0.0900, 0.0818, 0.1204, 0.1427,
        0.1000, 0.0720], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,696][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1186, 0.1040, 0.0933, 0.0834, 0.0917, 0.0900, 0.0857, 0.0836, 0.0956,
        0.0790, 0.0752], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,697][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0982, 0.0908, 0.1210, 0.0135, 0.0074, 0.3734, 0.0973, 0.0716, 0.0526,
        0.0663, 0.0078], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,698][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1455, 0.0845, 0.1178, 0.0550, 0.1162, 0.1026, 0.0780, 0.0944, 0.0915,
        0.0649, 0.0496], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,701][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0897, 0.0938, 0.0994, 0.0919, 0.0981, 0.0982, 0.0870, 0.0873, 0.0878,
        0.0849, 0.0819], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,705][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0824, 0.0584, 0.1830, 0.0529, 0.2243, 0.0713, 0.0603, 0.0597, 0.0752,
        0.0778, 0.0547], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,709][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0444, 0.0209, 0.0321, 0.0637, 0.0600, 0.0536, 0.1110, 0.0859, 0.1110,
        0.1509, 0.1929, 0.0736], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,710][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0252, 0.0335, 0.0136, 0.1500, 0.0243, 0.0670, 0.2492, 0.0591, 0.0363,
        0.1042, 0.2046, 0.0330], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,710][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0007, 0.0086, 0.0275, 0.0066, 0.4237, 0.0204, 0.0201, 0.0563, 0.0576,
        0.0424, 0.0655, 0.2706], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,710][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.1342, 0.0632, 0.0720, 0.0720, 0.0743, 0.0808, 0.0804, 0.0844, 0.0853,
        0.0844, 0.0815, 0.0876], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,711][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0252, 0.1267, 0.0042, 0.0885, 0.0253, 0.0860, 0.0206, 0.4418, 0.0043,
        0.0999, 0.0590, 0.0184], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,711][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.2713, 0.0425, 0.0624, 0.0522, 0.0374, 0.0799, 0.0428, 0.0544, 0.0876,
        0.0758, 0.0970, 0.0968], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,711][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0134, 0.0463, 0.0981, 0.0649, 0.1354, 0.0792, 0.0774, 0.1102, 0.1231,
        0.0933, 0.0667, 0.0921], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,712][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.1127, 0.0930, 0.0832, 0.0758, 0.0828, 0.0842, 0.0759, 0.0789, 0.0860,
        0.0783, 0.0709, 0.0783], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,712][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0359, 0.0878, 0.0063, 0.0809, 0.0015, 0.5225, 0.0195, 0.0519, 0.0881,
        0.0502, 0.0535, 0.0020], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,712][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.1328, 0.0927, 0.0960, 0.0817, 0.0903, 0.0975, 0.0706, 0.0737, 0.0744,
        0.0696, 0.0738, 0.0469], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,714][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0773, 0.0930, 0.0908, 0.0848, 0.0930, 0.0886, 0.0776, 0.0776, 0.0801,
        0.0833, 0.0753, 0.0787], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,717][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0698, 0.0481, 0.1596, 0.0402, 0.1975, 0.0597, 0.0469, 0.0576, 0.0704,
        0.0607, 0.0405, 0.1489], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,721][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Megan] are: tensor([0.0366, 0.0199, 0.0252, 0.0626, 0.0488, 0.0482, 0.1084, 0.0734, 0.0960,
        0.1553, 0.1902, 0.0632, 0.0722], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,725][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Megan] are: tensor([0.0194, 0.0339, 0.0120, 0.1596, 0.0219, 0.0616, 0.2366, 0.0612, 0.0319,
        0.1051, 0.2111, 0.0268, 0.0190], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,725][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Megan] are: tensor([5.7184e-05, 7.1771e-04, 2.6647e-03, 5.6332e-04, 3.8905e-02, 1.5924e-03,
        1.3671e-03, 5.2734e-03, 5.3603e-03, 3.6966e-03, 5.9642e-03, 3.1578e-02,
        9.0226e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,726][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Megan] are: tensor([0.1288, 0.0563, 0.0654, 0.0654, 0.0679, 0.0741, 0.0740, 0.0782, 0.0790,
        0.0783, 0.0754, 0.0820, 0.0753], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,726][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Megan] are: tensor([0.0390, 0.1732, 0.0464, 0.1512, 0.0219, 0.0418, 0.1073, 0.0274, 0.0307,
        0.1687, 0.1020, 0.0715, 0.0189], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,726][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Megan] are: tensor([0.3641, 0.0281, 0.0441, 0.0318, 0.0106, 0.0366, 0.0290, 0.0541, 0.0858,
        0.0580, 0.0754, 0.1614, 0.0209], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,727][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Megan] are: tensor([0.0094, 0.0387, 0.0916, 0.0537, 0.1302, 0.0646, 0.0634, 0.0998, 0.1115,
        0.0809, 0.0536, 0.0863, 0.1163], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,727][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Megan] are: tensor([0.1011, 0.0873, 0.0742, 0.0734, 0.0736, 0.0776, 0.0733, 0.0729, 0.0794,
        0.0722, 0.0684, 0.0726, 0.0740], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,727][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Megan] are: tensor([4.2475e-02, 2.8728e-02, 6.7945e-03, 6.8345e-02, 7.0014e-04, 5.8667e-01,
        2.1104e-02, 1.2975e-02, 9.5911e-02, 2.0617e-02, 5.3780e-02, 6.1382e-02,
        5.1570e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,728][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Megan] are: tensor([0.1178, 0.0847, 0.0939, 0.0769, 0.0422, 0.0794, 0.0803, 0.0965, 0.0786,
        0.0660, 0.0711, 0.0730, 0.0395], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,728][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Megan] are: tensor([0.0684, 0.0813, 0.0860, 0.0762, 0.0866, 0.0819, 0.0733, 0.0740, 0.0733,
        0.0738, 0.0680, 0.0789, 0.0783], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,730][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Megan] are: tensor([0.0658, 0.0411, 0.1248, 0.0389, 0.1410, 0.0545, 0.0458, 0.0539, 0.0661,
        0.0537, 0.0400, 0.1381, 0.1363], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,732][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0319, 0.0182, 0.0238, 0.0528, 0.0468, 0.0426, 0.0906, 0.0706, 0.0894,
        0.1386, 0.1640, 0.0600, 0.0745, 0.0962], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,736][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0201, 0.0346, 0.0175, 0.1110, 0.0345, 0.0642, 0.1553, 0.0851, 0.0664,
        0.0810, 0.1351, 0.0761, 0.0308, 0.0884], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,739][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ said] are: tensor([2.8108e-05, 5.3951e-04, 2.2515e-03, 3.5589e-04, 4.3465e-02, 8.3048e-04,
        5.7869e-04, 2.4529e-03, 3.0805e-03, 1.4449e-03, 2.5419e-03, 2.2339e-02,
        9.0676e-01, 1.3327e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,741][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.1120, 0.0544, 0.0625, 0.0617, 0.0641, 0.0695, 0.0690, 0.0723, 0.0737,
        0.0720, 0.0696, 0.0755, 0.0699, 0.0737], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,741][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.1709, 0.1196, 0.0118, 0.0991, 0.0217, 0.0884, 0.0536, 0.1263, 0.0061,
        0.1088, 0.0775, 0.0928, 0.0166, 0.0068], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,742][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.2375, 0.0455, 0.0480, 0.0479, 0.0413, 0.0446, 0.0377, 0.0619, 0.0566,
        0.0712, 0.0895, 0.1243, 0.0587, 0.0353], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,742][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0094, 0.0368, 0.0801, 0.0532, 0.1151, 0.0644, 0.0615, 0.0923, 0.1057,
        0.0737, 0.0538, 0.0767, 0.1073, 0.0702], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,742][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0915, 0.0754, 0.0755, 0.0640, 0.0739, 0.0709, 0.0665, 0.0672, 0.0752,
        0.0651, 0.0601, 0.0720, 0.0743, 0.0685], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,743][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0489, 0.3633, 0.0312, 0.0682, 0.0326, 0.0610, 0.0168, 0.0490, 0.0278,
        0.1603, 0.0461, 0.0546, 0.0254, 0.0149], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,743][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.1195, 0.0785, 0.0863, 0.0820, 0.0658, 0.0711, 0.0580, 0.0653, 0.0639,
        0.0685, 0.0807, 0.0598, 0.0615, 0.0390], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,744][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0694, 0.0742, 0.0774, 0.0688, 0.0779, 0.0722, 0.0689, 0.0725, 0.0694,
        0.0691, 0.0636, 0.0714, 0.0736, 0.0717], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,746][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0554, 0.0358, 0.1338, 0.0302, 0.1542, 0.0458, 0.0401, 0.0489, 0.0551,
        0.0484, 0.0320, 0.1361, 0.1475, 0.0366], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,749][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0327, 0.0195, 0.0249, 0.0470, 0.0472, 0.0388, 0.0770, 0.0645, 0.0836,
        0.1161, 0.1357, 0.0566, 0.0710, 0.0841, 0.1010], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,753][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0225, 0.0416, 0.0441, 0.0641, 0.0736, 0.0633, 0.0621, 0.0981, 0.0931,
        0.0506, 0.0605, 0.1217, 0.0665, 0.0691, 0.0693], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,756][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([1.1341e-05, 3.2051e-04, 1.8941e-03, 3.2502e-04, 3.1886e-02, 1.2816e-03,
        1.0689e-03, 2.9934e-03, 2.5963e-03, 2.2932e-03, 3.9981e-03, 1.7522e-02,
        9.0723e-01, 2.5765e-02, 8.1589e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,756][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1011, 0.0523, 0.0594, 0.0581, 0.0601, 0.0656, 0.0643, 0.0672, 0.0686,
        0.0670, 0.0646, 0.0698, 0.0649, 0.0683, 0.0688], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,757][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0363, 0.0652, 0.0123, 0.0951, 0.0462, 0.1278, 0.0601, 0.0862, 0.1157,
        0.1021, 0.0745, 0.0410, 0.0366, 0.0688, 0.0322], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,757][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.2146, 0.0386, 0.0556, 0.0483, 0.0335, 0.0633, 0.0284, 0.0422, 0.0635,
        0.0584, 0.0876, 0.1102, 0.0467, 0.0534, 0.0557], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,757][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0109, 0.0375, 0.0751, 0.0533, 0.1017, 0.0641, 0.0587, 0.0839, 0.0987,
        0.0711, 0.0519, 0.0723, 0.0964, 0.0668, 0.0576], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,758][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0817, 0.0752, 0.0692, 0.0631, 0.0687, 0.0676, 0.0634, 0.0625, 0.0697,
        0.0607, 0.0574, 0.0682, 0.0680, 0.0666, 0.0581], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,758][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([6.8149e-03, 1.5222e-02, 5.0726e-03, 1.1361e-02, 1.1069e-03, 1.2111e-01,
        5.0719e-03, 1.4669e-03, 6.7312e-03, 8.0276e-03, 8.9823e-03, 5.5988e-03,
        8.0053e-04, 8.0257e-01, 5.5151e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,758][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1114, 0.0638, 0.0818, 0.0561, 0.0841, 0.0576, 0.0616, 0.0713, 0.0665,
        0.0501, 0.0541, 0.0553, 0.0791, 0.0732, 0.0340], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,759][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0670, 0.0713, 0.0690, 0.0704, 0.0671, 0.0706, 0.0641, 0.0645, 0.0635,
        0.0664, 0.0637, 0.0641, 0.0635, 0.0707, 0.0641], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,760][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0534, 0.0381, 0.1250, 0.0363, 0.1525, 0.0474, 0.0393, 0.0415, 0.0492,
        0.0518, 0.0376, 0.1166, 0.1422, 0.0407, 0.0283], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,787][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:23,788][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,788][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,788][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,789][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,789][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,790][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,790][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,791][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,791][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,791][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,792][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,792][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:23,792][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.7801, 0.2199], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,793][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.6793, 0.3207], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,793][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0030, 0.9970], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,793][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0677, 0.9323], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,794][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0670, 0.9330], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,794][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([9.9998e-01, 1.6901e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,794][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2975, 0.7025], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,795][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3972, 0.6028], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,795][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.2306, 0.7694], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,796][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.5301, 0.4699], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,800][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2425, 0.7575], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,803][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0369, 0.9631], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:23,807][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Jennifer] are: tensor([0.5630, 0.2824, 0.1546], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,807][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Jennifer] are: tensor([0.4851, 0.2369, 0.2780], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,808][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Jennifer] are: tensor([6.1185e-06, 3.9917e-01, 6.0082e-01], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,808][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Jennifer] are: tensor([0.0024, 0.3411, 0.6565], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,808][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Jennifer] are: tensor([0.0017, 0.5962, 0.4021], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,809][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Jennifer] are: tensor([9.9997e-01, 6.1818e-07, 2.5438e-05], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,809][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Jennifer] are: tensor([0.1151, 0.3091, 0.5758], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,809][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Jennifer] are: tensor([0.2761, 0.4861, 0.2379], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,810][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Jennifer] are: tensor([0.0861, 0.3474, 0.5665], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,811][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Jennifer] are: tensor([0.3531, 0.3555, 0.2914], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,814][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Jennifer] are: tensor([0.0904, 0.4970, 0.4126], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,818][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Jennifer] are: tensor([0.0288, 0.6711, 0.3000], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:23,821][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.4415, 0.1913, 0.2017, 0.1654], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,823][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.3003, 0.1815, 0.2080, 0.3102], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,823][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([1.7320e-06, 9.7084e-03, 4.4165e-01, 5.4864e-01], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,823][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0008, 0.0577, 0.4268, 0.5147], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,824][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0011, 0.0754, 0.5849, 0.3386], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,824][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([9.9883e-01, 3.8203e-05, 3.4999e-04, 7.7889e-04], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,824][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0833, 0.2167, 0.3807, 0.3194], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,824][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2646, 0.3706, 0.2137, 0.1511], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,825][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0624, 0.2256, 0.4159, 0.2962], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,825][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.2601, 0.2441, 0.2426, 0.2532], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,825][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0572, 0.2784, 0.2532, 0.4112], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,826][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0241, 0.4871, 0.1973, 0.2915], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:23,828][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Megan] are: tensor([0.3439, 0.1596, 0.1857, 0.2296, 0.0813], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,831][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Megan] are: tensor([0.2552, 0.1328, 0.1531, 0.2581, 0.2008], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,833][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Megan] are: tensor([5.5527e-08, 6.8505e-04, 1.5098e-02, 2.1465e-01, 7.6957e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,836][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Megan] are: tensor([1.0402e-04, 1.1891e-02, 6.0234e-02, 2.5266e-01, 6.7511e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,838][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Megan] are: tensor([7.5872e-05, 1.0087e-02, 1.0075e-01, 1.4841e-01, 7.4068e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,838][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Megan] are: tensor([9.9998e-01, 4.8237e-09, 7.2723e-07, 5.6284e-06, 8.7566e-06],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,839][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Megan] are: tensor([0.0461, 0.1325, 0.2443, 0.1833, 0.3937], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,839][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Megan] are: tensor([0.1880, 0.3355, 0.1568, 0.1553, 0.1644], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,839][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Megan] are: tensor([0.0310, 0.1370, 0.2413, 0.1934, 0.3973], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,840][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Megan] are: tensor([0.2038, 0.2041, 0.1714, 0.2112, 0.2096], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,840][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Megan] are: tensor([0.0261, 0.1554, 0.1399, 0.3179, 0.3607], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,840][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Megan] are: tensor([0.0192, 0.3121, 0.1321, 0.2752, 0.2613], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:23,841][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.2533, 0.1368, 0.2005, 0.1402, 0.1678, 0.1013], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,841][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.1983, 0.1121, 0.1306, 0.2070, 0.1640, 0.1880], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,841][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([2.6309e-09, 2.5241e-05, 1.2446e-03, 1.3013e-02, 9.0873e-01, 7.6986e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,842][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([6.0290e-05, 5.9247e-03, 2.3518e-02, 8.6567e-02, 6.8057e-01, 2.0336e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,843][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([3.6847e-05, 1.0356e-02, 1.8048e-03, 1.5551e-01, 1.7457e-01, 6.5773e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,845][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([9.9986e-01, 3.5715e-07, 1.0032e-05, 4.2882e-05, 7.2217e-05, 9.9616e-06],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,849][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0381, 0.1065, 0.1734, 0.1560, 0.2756, 0.2504], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,852][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1573, 0.2917, 0.1389, 0.1149, 0.1476, 0.1495], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,854][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0308, 0.1144, 0.2203, 0.1566, 0.3295, 0.1485], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,854][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.1715, 0.1576, 0.1543, 0.1641, 0.1880, 0.1644], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,855][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0188, 0.1065, 0.0968, 0.1988, 0.2668, 0.3122], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,855][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0125, 0.2516, 0.0923, 0.1389, 0.2228, 0.2819], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:23,855][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2286, 0.1179, 0.1084, 0.1858, 0.1096, 0.1649, 0.0848],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,856][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1556, 0.1003, 0.1138, 0.1573, 0.1332, 0.1471, 0.1927],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,856][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([6.6790e-09, 1.4928e-05, 4.9534e-04, 1.0379e-02, 1.6382e-01, 6.5703e-01,
        1.6826e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,856][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([4.6905e-05, 2.1235e-03, 1.3601e-02, 4.2968e-02, 4.7191e-01, 1.6687e-01,
        3.0248e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,856][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([2.2947e-05, 2.2827e-03, 9.2610e-03, 3.1111e-02, 4.3193e-01, 3.2276e-01,
        2.0263e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,857][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([9.9956e-01, 2.4031e-06, 2.8245e-05, 1.4170e-04, 1.2395e-04, 3.8350e-05,
        1.1006e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,858][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0302, 0.0861, 0.1427, 0.1307, 0.2305, 0.2081, 0.1717],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,861][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1551, 0.2336, 0.1307, 0.1000, 0.1334, 0.1200, 0.1272],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,865][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0288, 0.0945, 0.1908, 0.1228, 0.2720, 0.1224, 0.1686],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,869][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1509, 0.1335, 0.1338, 0.1386, 0.1631, 0.1423, 0.1378],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,870][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0170, 0.0833, 0.0743, 0.1504, 0.1807, 0.1986, 0.2956],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,870][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0128, 0.1840, 0.0669, 0.1228, 0.1471, 0.2168, 0.2496],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:23,870][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.2173, 0.0979, 0.0607, 0.1275, 0.1396, 0.1434, 0.1319, 0.0817],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,871][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.1384, 0.0809, 0.0925, 0.1403, 0.1144, 0.1295, 0.1830, 0.1210],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,871][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([6.5823e-10, 5.5710e-07, 3.0858e-05, 2.0880e-04, 2.5326e-02, 4.2103e-02,
        1.6554e-01, 7.6679e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,871][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([4.6230e-06, 2.6614e-04, 2.9300e-03, 8.0630e-03, 9.7929e-02, 4.0580e-02,
        4.2345e-01, 4.2678e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,872][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([4.7474e-06, 2.2937e-04, 3.9720e-04, 6.2219e-03, 3.8303e-01, 1.5462e-01,
        1.2837e-01, 3.2713e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,872][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([9.9982e-01, 1.2099e-07, 6.4801e-06, 3.6139e-05, 3.2754e-05, 9.7269e-06,
        3.6331e-05, 6.2777e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,872][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0292, 0.0728, 0.1167, 0.1041, 0.1843, 0.1667, 0.1434, 0.1827],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,873][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.1250, 0.2318, 0.0955, 0.0968, 0.1054, 0.1042, 0.1025, 0.1389],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,874][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0203, 0.0738, 0.1258, 0.1005, 0.1994, 0.1049, 0.1627, 0.2126],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,877][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.1320, 0.1197, 0.1052, 0.1250, 0.1253, 0.1286, 0.1253, 0.1387],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,881][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0085, 0.0496, 0.0380, 0.0934, 0.1043, 0.1239, 0.1796, 0.4027],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,885][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0104, 0.1207, 0.0413, 0.0738, 0.0977, 0.1217, 0.1406, 0.3939],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:23,885][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.2134, 0.0781, 0.0583, 0.0897, 0.1313, 0.1871, 0.0734, 0.1209, 0.0478],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,886][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.1222, 0.0733, 0.0832, 0.1262, 0.1017, 0.1169, 0.1642, 0.1092, 0.1032],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,886][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([7.5018e-11, 8.9593e-08, 1.3279e-06, 3.8223e-05, 3.5480e-03, 2.9235e-03,
        1.6513e-02, 5.3033e-01, 4.4665e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,886][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([3.1288e-06, 2.0498e-04, 1.8569e-03, 4.7853e-03, 6.3655e-02, 3.9234e-02,
        1.4124e-01, 4.7110e-01, 2.7792e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,887][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([8.3387e-07, 1.3401e-04, 3.6581e-04, 2.5254e-03, 4.5986e-02, 4.2906e-02,
        3.8216e-02, 6.9589e-01, 1.7397e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,887][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([9.9989e-01, 2.4450e-08, 2.2970e-06, 1.3731e-05, 2.0998e-05, 3.6927e-06,
        2.1662e-05, 4.1929e-05, 5.2360e-06], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,887][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0207, 0.0602, 0.0991, 0.0855, 0.1604, 0.1375, 0.1209, 0.1561, 0.1595],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,888][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.1023, 0.1942, 0.0878, 0.0851, 0.0899, 0.1034, 0.1016, 0.1267, 0.1090],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,888][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0133, 0.0558, 0.0937, 0.0822, 0.1588, 0.0879, 0.1461, 0.1918, 0.1703],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,889][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.1144, 0.1059, 0.0886, 0.1089, 0.1088, 0.1120, 0.1118, 0.1262, 0.1233],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,892][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0075, 0.0361, 0.0264, 0.0779, 0.0762, 0.0843, 0.1579, 0.2579, 0.2757],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,896][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0074, 0.0978, 0.0264, 0.0657, 0.0585, 0.0976, 0.1276, 0.2853, 0.2338],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:23,899][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1645, 0.0608, 0.0675, 0.1040, 0.1008, 0.1656, 0.0988, 0.1185, 0.0770,
        0.0425], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,901][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1081, 0.0660, 0.0752, 0.1127, 0.0900, 0.1031, 0.1451, 0.0967, 0.0925,
        0.1106], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,901][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([7.2412e-11, 3.3978e-09, 8.6771e-07, 1.4334e-05, 6.1810e-04, 6.3655e-04,
        3.1130e-03, 9.8280e-02, 1.9296e-01, 7.0438e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,902][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([3.0217e-06, 2.9364e-05, 6.1829e-04, 1.5011e-03, 1.6936e-02, 1.2036e-02,
        5.9716e-02, 1.6857e-01, 1.8057e-01, 5.6002e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,902][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([5.6304e-06, 4.9649e-05, 8.1392e-04, 2.0769e-03, 2.5376e-02, 1.4713e-02,
        3.9217e-02, 1.4571e-01, 3.9339e-01, 3.7864e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,902][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([9.9974e-01, 7.4485e-07, 7.4498e-06, 5.4324e-05, 2.4921e-05, 1.2910e-05,
        4.2401e-05, 5.9561e-05, 1.5877e-05, 3.9756e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,903][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0198, 0.0517, 0.0845, 0.0758, 0.1359, 0.1215, 0.1031, 0.1349, 0.1430,
        0.1298], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,903][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1190, 0.1603, 0.0925, 0.0723, 0.0965, 0.0933, 0.0909, 0.1096, 0.1143,
        0.0512], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,903][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0166, 0.0552, 0.0976, 0.0758, 0.1410, 0.0752, 0.1090, 0.1555, 0.1549,
        0.1192], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,904][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1016, 0.0860, 0.0860, 0.0912, 0.1047, 0.0938, 0.0933, 0.1139, 0.1213,
        0.1081], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,905][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0067, 0.0309, 0.0235, 0.0534, 0.0605, 0.0678, 0.0893, 0.1686, 0.1737,
        0.3257], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,908][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0067, 0.0660, 0.0264, 0.0466, 0.0602, 0.0726, 0.0890, 0.2385, 0.1920,
        0.2020], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:23,912][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1539, 0.0774, 0.0703, 0.0602, 0.1318, 0.1196, 0.0919, 0.1164, 0.0803,
        0.0522, 0.0460], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,915][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0959, 0.0621, 0.0705, 0.0981, 0.0818, 0.0916, 0.1219, 0.0867, 0.0834,
        0.0955, 0.1126], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,917][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([1.9347e-11, 8.1168e-10, 9.7768e-08, 5.8719e-08, 4.7870e-05, 1.6153e-05,
        1.3480e-04, 2.5236e-03, 7.8665e-03, 1.6150e-01, 8.2791e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,917][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([1.0765e-06, 1.1254e-05, 1.5229e-04, 1.1545e-04, 4.5878e-03, 2.3258e-03,
        1.3850e-02, 3.4238e-02, 4.8462e-02, 2.2385e-01, 6.7240e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,917][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([5.9244e-06, 4.0872e-05, 2.1212e-04, 1.9694e-04, 9.9575e-04, 1.4576e-03,
        9.3096e-03, 9.9216e-03, 1.9268e-02, 3.3104e-01, 6.2755e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,918][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([9.9735e-01, 3.8387e-06, 4.7173e-05, 1.6380e-04, 1.8952e-04, 6.5131e-05,
        1.7996e-04, 4.1690e-04, 1.2404e-04, 2.1365e-04, 1.2461e-03],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,918][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0191, 0.0469, 0.0750, 0.0705, 0.1183, 0.1070, 0.0915, 0.1190, 0.1238,
        0.1139, 0.1149], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,918][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1139, 0.1491, 0.0908, 0.0663, 0.0974, 0.0909, 0.0882, 0.0985, 0.1153,
        0.0472, 0.0423], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,919][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0152, 0.0509, 0.0964, 0.0643, 0.1379, 0.0656, 0.0936, 0.1435, 0.1466,
        0.1065, 0.0796], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,919][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0929, 0.0762, 0.0802, 0.0815, 0.0988, 0.0844, 0.0829, 0.1048, 0.1137,
        0.0974, 0.0872], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,919][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0044, 0.0242, 0.0203, 0.0352, 0.0463, 0.0481, 0.0637, 0.1048, 0.1245,
        0.2404, 0.2882], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,921][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0073, 0.0697, 0.0245, 0.0323, 0.0534, 0.0673, 0.0723, 0.1917, 0.1586,
        0.1915, 0.1314], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:23,924][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.1548, 0.0938, 0.0518, 0.1061, 0.0762, 0.1153, 0.0557, 0.0710, 0.0818,
        0.0641, 0.0790, 0.0504], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,928][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0897, 0.0494, 0.0569, 0.0902, 0.0728, 0.0849, 0.1242, 0.0806, 0.0741,
        0.0898, 0.1111, 0.0764], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,930][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([5.7373e-12, 1.6936e-10, 2.5091e-09, 7.4646e-08, 1.0388e-06, 2.0818e-06,
        2.2750e-05, 1.2260e-04, 9.9286e-04, 2.1159e-02, 7.9627e-01, 1.8143e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,932][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([3.0165e-07, 6.9754e-06, 6.2297e-05, 8.6562e-05, 1.7368e-03, 1.0038e-03,
        4.8483e-03, 8.7808e-03, 1.5948e-02, 1.1775e-01, 4.6110e-01, 3.8868e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,933][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([3.2956e-07, 6.0362e-06, 3.6518e-06, 1.1791e-04, 1.9043e-04, 1.1461e-03,
        1.2121e-03, 1.5422e-01, 3.1797e-03, 6.0859e-02, 4.0276e-01, 3.7630e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,933][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([9.9684e-01, 2.3737e-08, 1.0666e-06, 1.4661e-05, 5.8856e-06, 2.5116e-06,
        1.6983e-05, 1.8988e-05, 3.7843e-06, 1.9300e-05, 3.5463e-04, 2.7203e-03],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,933][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0163, 0.0401, 0.0674, 0.0577, 0.1062, 0.0924, 0.0816, 0.1067, 0.1116,
        0.1046, 0.1058, 0.1096], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,934][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0790, 0.1671, 0.0713, 0.0698, 0.0813, 0.0924, 0.0786, 0.1049, 0.0945,
        0.0629, 0.0465, 0.0516], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,934][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0129, 0.0436, 0.0750, 0.0592, 0.1143, 0.0628, 0.0966, 0.1282, 0.1263,
        0.1003, 0.0780, 0.1029], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,934][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0863, 0.0734, 0.0666, 0.0784, 0.0813, 0.0795, 0.0786, 0.0897, 0.0937,
        0.0922, 0.0863, 0.0940], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,935][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0026, 0.0160, 0.0126, 0.0245, 0.0309, 0.0357, 0.0477, 0.0820, 0.1033,
        0.2206, 0.2343, 0.1898], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,935][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0070, 0.0666, 0.0206, 0.0313, 0.0452, 0.0604, 0.0647, 0.1756, 0.1445,
        0.1732, 0.1181, 0.0927], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:23,937][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Megan] are: tensor([0.1387, 0.0677, 0.0695, 0.0891, 0.0348, 0.1437, 0.0557, 0.1095, 0.0655,
        0.0483, 0.0743, 0.0681, 0.0352], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,940][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Megan] are: tensor([0.0823, 0.0436, 0.0501, 0.0839, 0.0659, 0.0774, 0.1192, 0.0729, 0.0670,
        0.0839, 0.1064, 0.0698, 0.0776], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,942][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Megan] are: tensor([9.9400e-13, 5.4590e-11, 2.4660e-09, 1.4513e-08, 1.1899e-07, 1.5688e-06,
        2.0786e-06, 6.5412e-05, 2.5775e-04, 3.2889e-03, 1.1542e-01, 3.5675e-01,
        5.2422e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,944][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Megan] are: tensor([9.8623e-08, 1.5434e-06, 9.4074e-06, 2.9363e-05, 9.8801e-05, 1.7231e-04,
        1.6149e-03, 5.7339e-03, 7.0918e-03, 3.6338e-02, 1.7159e-01, 3.7384e-01,
        4.0348e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,946][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Megan] are: tensor([2.4692e-07, 3.2437e-06, 2.9184e-05, 4.5765e-05, 2.6082e-04, 1.0948e-04,
        1.0696e-03, 1.0726e-03, 3.4447e-03, 2.6067e-02, 1.3205e-01, 1.5546e-01,
        6.8038e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,948][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Megan] are: tensor([9.9936e-01, 9.4927e-11, 1.1367e-08, 2.8642e-07, 1.0708e-07, 3.1958e-08,
        4.2637e-07, 8.4287e-07, 5.7067e-08, 4.9013e-07, 1.9093e-05, 5.9402e-04,
        2.9645e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,949][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Megan] are: tensor([0.0117, 0.0344, 0.0615, 0.0486, 0.1014, 0.0772, 0.0658, 0.0936, 0.0967,
        0.0918, 0.0899, 0.1063, 0.1212], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,949][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Megan] are: tensor([0.0842, 0.1444, 0.0695, 0.0697, 0.0731, 0.0815, 0.0813, 0.0891, 0.0882,
        0.0531, 0.0474, 0.0514, 0.0671], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,949][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Megan] are: tensor([0.0076, 0.0333, 0.0600, 0.0474, 0.1003, 0.0520, 0.0824, 0.1179, 0.1193,
        0.0883, 0.0659, 0.0955, 0.1301], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,950][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Megan] are: tensor([0.0733, 0.0669, 0.0583, 0.0729, 0.0728, 0.0733, 0.0712, 0.0864, 0.0873,
        0.0861, 0.0791, 0.0905, 0.0819], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,950][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Megan] are: tensor([0.0016, 0.0112, 0.0098, 0.0233, 0.0236, 0.0296, 0.0431, 0.0621, 0.0760,
        0.1385, 0.2167, 0.1717, 0.1927], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,950][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Megan] are: tensor([0.0053, 0.0448, 0.0175, 0.0340, 0.0317, 0.0585, 0.0635, 0.1571, 0.1065,
        0.1217, 0.1189, 0.0798, 0.1607], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:23,951][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.1190, 0.0461, 0.0670, 0.0708, 0.0653, 0.1280, 0.0552, 0.0656, 0.1076,
        0.0342, 0.0561, 0.0795, 0.0591, 0.0464], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,951][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0745, 0.0466, 0.0527, 0.0779, 0.0638, 0.0728, 0.0994, 0.0687, 0.0657,
        0.0754, 0.0897, 0.0655, 0.0716, 0.0756], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,951][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([2.0905e-13, 4.3263e-12, 9.2688e-11, 1.3817e-09, 7.2866e-08, 1.3723e-07,
        2.1344e-07, 2.1609e-06, 2.4162e-05, 8.6583e-04, 2.7297e-02, 8.0118e-02,
        7.2604e-01, 1.6566e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,953][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([8.4990e-08, 9.1941e-07, 2.2496e-06, 1.7021e-05, 1.1856e-04, 2.9061e-05,
        3.0380e-04, 1.3920e-03, 2.0876e-03, 2.1172e-02, 1.3457e-01, 1.9038e-01,
        5.3019e-01, 1.1974e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,954][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([1.6630e-07, 2.5880e-06, 2.9874e-06, 3.1968e-05, 6.7184e-05, 1.8278e-04,
        4.5745e-04, 7.1409e-04, 1.9490e-03, 2.3454e-02, 1.5000e-01, 3.5164e-01,
        1.4533e-01, 3.2618e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,956][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([9.9230e-01, 1.3555e-07, 1.8706e-06, 2.0336e-05, 1.3707e-05, 3.5943e-06,
        2.1061e-05, 4.2893e-05, 8.6787e-06, 3.4510e-05, 3.3419e-04, 6.0106e-03,
        8.1594e-04, 3.8784e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,959][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0114, 0.0325, 0.0534, 0.0474, 0.0872, 0.0772, 0.0665, 0.0879, 0.0896,
        0.0805, 0.0827, 0.0890, 0.1053, 0.0892], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,963][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0749, 0.1203, 0.0784, 0.0534, 0.0769, 0.0758, 0.0719, 0.0891, 0.0864,
        0.0473, 0.0379, 0.0586, 0.0721, 0.0571], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,964][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0095, 0.0339, 0.0602, 0.0480, 0.0939, 0.0482, 0.0760, 0.1078, 0.1017,
        0.0801, 0.0635, 0.0900, 0.1221, 0.0652], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,965][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0711, 0.0603, 0.0570, 0.0649, 0.0706, 0.0657, 0.0650, 0.0780, 0.0819,
        0.0764, 0.0709, 0.0833, 0.0805, 0.0745], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,965][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0016, 0.0104, 0.0082, 0.0187, 0.0196, 0.0216, 0.0344, 0.0498, 0.0543,
        0.1243, 0.1585, 0.1175, 0.1601, 0.2210], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,966][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0066, 0.0563, 0.0136, 0.0251, 0.0286, 0.0454, 0.0483, 0.1231, 0.0878,
        0.1294, 0.0873, 0.0769, 0.1412, 0.1304], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:23,966][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1242, 0.0523, 0.0467, 0.0757, 0.0578, 0.1072, 0.0636, 0.0762, 0.0697,
        0.0372, 0.0609, 0.0784, 0.0579, 0.0605, 0.0316], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,966][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0681, 0.0454, 0.0513, 0.0700, 0.0596, 0.0659, 0.0864, 0.0628, 0.0605,
        0.0686, 0.0803, 0.0610, 0.0662, 0.0676, 0.0863], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,967][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([2.5371e-13, 6.6189e-13, 1.0011e-11, 1.4989e-10, 7.0841e-09, 1.4877e-08,
        4.0972e-08, 6.8167e-07, 5.5865e-06, 6.3593e-05, 2.1599e-03, 5.2155e-03,
        6.1423e-02, 2.1982e-01, 7.1132e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,967][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([5.8685e-08, 2.5500e-07, 1.7610e-06, 2.9263e-06, 5.0453e-05, 1.1392e-05,
        1.3938e-04, 3.0126e-04, 4.5882e-04, 4.3270e-03, 1.7284e-02, 4.0294e-02,
        2.3146e-01, 2.9138e-01, 4.1430e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,968][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([6.0673e-08, 4.5994e-07, 1.1008e-06, 2.8991e-06, 2.3229e-05, 1.0620e-04,
        3.9295e-05, 4.5940e-04, 2.2051e-03, 2.3530e-03, 1.1860e-02, 3.7446e-02,
        6.0796e-02, 6.6361e-01, 2.2110e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,969][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.8927e-01, 1.1582e-06, 1.0255e-05, 7.6364e-05, 3.6306e-05, 1.6605e-05,
        5.9834e-05, 1.1705e-04, 2.5472e-05, 8.5558e-05, 6.4579e-04, 7.2470e-03,
        8.0341e-04, 6.8165e-04, 9.2228e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,972][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0129, 0.0320, 0.0500, 0.0480, 0.0768, 0.0735, 0.0631, 0.0790, 0.0819,
        0.0775, 0.0769, 0.0799, 0.0922, 0.0831, 0.0733], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,975][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0896, 0.1150, 0.0647, 0.0545, 0.0710, 0.0714, 0.0679, 0.0793, 0.0790,
        0.0424, 0.0360, 0.0635, 0.0646, 0.0631, 0.0380], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,979][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0120, 0.0354, 0.0650, 0.0444, 0.0916, 0.0442, 0.0617, 0.0927, 0.0982,
        0.0705, 0.0537, 0.0851, 0.1197, 0.0657, 0.0600], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,982][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0680, 0.0530, 0.0552, 0.0587, 0.0686, 0.0596, 0.0589, 0.0719, 0.0796,
        0.0692, 0.0626, 0.0765, 0.0777, 0.0695, 0.0710], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,982][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0016, 0.0075, 0.0062, 0.0120, 0.0135, 0.0164, 0.0207, 0.0362, 0.0398,
        0.0780, 0.0987, 0.0924, 0.1010, 0.1670, 0.3091], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,983][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0066, 0.0383, 0.0121, 0.0207, 0.0247, 0.0341, 0.0369, 0.0944, 0.0680,
        0.0901, 0.0746, 0.0627, 0.1244, 0.1132, 0.1992], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:23,984][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:23,985][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 9691],
        [14657],
        [25648],
        [28145],
        [27928],
        [22480],
        [14334],
        [15525],
        [14806],
        [12836],
        [23074],
        [12835],
        [19107],
        [25266],
        [19513]], device='cuda:0')
[2024-07-24 10:29:23,986][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 7814],
        [37865],
        [31514],
        [40251],
        [40713],
        [34094],
        [39009],
        [39577],
        [36442],
        [33395],
        [40464],
        [25823],
        [45029],
        [35887],
        [31303]], device='cuda:0')
[2024-07-24 10:29:23,987][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[41160],
        [42567],
        [39108],
        [36780],
        [35273],
        [35569],
        [36838],
        [37492],
        [37279],
        [37105],
        [36715],
        [37014],
        [36512],
        [36225],
        [36239]], device='cuda:0')
[2024-07-24 10:29:23,989][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[31879],
        [27556],
        [29201],
        [28557],
        [26144],
        [27938],
        [29631],
        [34553],
        [35799],
        [35747],
        [35000],
        [33632],
        [33343],
        [34723],
        [35264]], device='cuda:0')
[2024-07-24 10:29:23,991][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[21133],
        [14448],
        [17303],
        [17573],
        [18041],
        [18080],
        [18083],
        [17837],
        [17951],
        [18155],
        [18224],
        [17138],
        [14276],
        [14265],
        [14254]], device='cuda:0')
[2024-07-24 10:29:23,993][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[15922],
        [15983],
        [16031],
        [15780],
        [15895],
        [15555],
        [15331],
        [15039],
        [14913],
        [14777],
        [14642],
        [14624],
        [14711],
        [14614],
        [14533]], device='cuda:0')
[2024-07-24 10:29:23,996][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[14018],
        [12060],
        [10277],
        [ 9275],
        [10210],
        [12070],
        [11705],
        [15154],
        [11855],
        [11777],
        [ 9581],
        [16059],
        [ 8549],
        [10764],
        [ 8890]], device='cuda:0')
[2024-07-24 10:29:23,998][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[39148],
        [39826],
        [40401],
        [41480],
        [40566],
        [40874],
        [40147],
        [40956],
        [41208],
        [41006],
        [41086],
        [40996],
        [41197],
        [41189],
        [40815]], device='cuda:0')
[2024-07-24 10:29:24,001][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[17139],
        [12853],
        [ 9677],
        [10467],
        [ 9113],
        [10021],
        [10227],
        [ 9956],
        [ 9224],
        [ 9217],
        [ 9207],
        [ 9055],
        [ 8483],
        [ 8610],
        [ 8667]], device='cuda:0')
[2024-07-24 10:29:24,001][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[34836],
        [37126],
        [39943],
        [39879],
        [40984],
        [40397],
        [40711],
        [40325],
        [40005],
        [39998],
        [40029],
        [39617],
        [40082],
        [39935],
        [39914]], device='cuda:0')
[2024-07-24 10:29:24,002][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[30861],
        [32153],
        [37332],
        [28433],
        [42682],
        [38742],
        [25362],
        [25735],
        [28191],
        [28658],
        [27038],
        [28481],
        [25623],
        [40631],
        [13803]], device='cuda:0')
[2024-07-24 10:29:24,003][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[24688],
        [22306],
        [17742],
        [14971],
        [14481],
        [13662],
        [14335],
        [14755],
        [15370],
        [15608],
        [15526],
        [16383],
        [16521],
        [16099],
        [15431]], device='cuda:0')
[2024-07-24 10:29:24,004][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 6772],
        [12047],
        [13318],
        [12215],
        [11924],
        [12326],
        [10315],
        [10768],
        [11304],
        [11827],
        [11678],
        [11780],
        [11685],
        [11322],
        [11398]], device='cuda:0')
[2024-07-24 10:29:24,005][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[17251],
        [21827],
        [40290],
        [38527],
        [31057],
        [29519],
        [28561],
        [27538],
        [26639],
        [26332],
        [26168],
        [25287],
        [23778],
        [23739],
        [23556]], device='cuda:0')
[2024-07-24 10:29:24,007][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[11200],
        [13203],
        [13980],
        [16848],
        [13134],
        [14276],
        [ 4782],
        [ 2682],
        [15448],
        [ 7468],
        [ 4896],
        [12259],
        [ 5616],
        [ 7945],
        [12242]], device='cuda:0')
[2024-07-24 10:29:24,009][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[18983],
        [21788],
        [20667],
        [18960],
        [18345],
        [17346],
        [19787],
        [21372],
        [21011],
        [21617],
        [21389],
        [21067],
        [20843],
        [20605],
        [21746]], device='cuda:0')
[2024-07-24 10:29:24,010][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[11451],
        [17950],
        [20044],
        [21305],
        [21937],
        [22144],
        [21160],
        [19769],
        [18873],
        [19353],
        [20316],
        [20401],
        [20978],
        [20323],
        [20275]], device='cuda:0')
[2024-07-24 10:29:24,012][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 3506],
        [ 8248],
        [14489],
        [ 8651],
        [18007],
        [18449],
        [ 5789],
        [ 2037],
        [ 3975],
        [ 3559],
        [ 3879],
        [ 5151],
        [26081],
        [26806],
        [22424]], device='cuda:0')
[2024-07-24 10:29:24,015][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[23651],
        [27286],
        [29561],
        [28876],
        [25661],
        [25281],
        [23138],
        [17615],
        [24863],
        [26510],
        [25029],
        [25578],
        [27288],
        [29027],
        [27648]], device='cuda:0')
[2024-07-24 10:29:24,017][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[28196],
        [21778],
        [36799],
        [39420],
        [31380],
        [22431],
        [27295],
        [22412],
        [10264],
        [20332],
        [21360],
        [25392],
        [33185],
        [24964],
        [18678]], device='cuda:0')
[2024-07-24 10:29:24,020][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[6681],
        [6681],
        [6681],
        [6672],
        [6681],
        [6680],
        [6678],
        [6680],
        [6680],
        [6679],
        [6667],
        [6669],
        [6676],
        [6650],
        [6630]], device='cuda:0')
[2024-07-24 10:29:24,021][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[5106],
        [5909],
        [6016],
        [5691],
        [6332],
        [6416],
        [6020],
        [6216],
        [6861],
        [6698],
        [6666],
        [6971],
        [7067],
        [7045],
        [6825]], device='cuda:0')
[2024-07-24 10:29:24,022][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 918],
        [2498],
        [2262],
        [2254],
        [1819],
        [2043],
        [1771],
        [1962],
        [2111],
        [2054],
        [2080],
        [2228],
        [1914],
        [1945],
        [1953]], device='cuda:0')
[2024-07-24 10:29:24,022][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[25783],
        [26320],
        [24819],
        [24792],
        [23125],
        [22932],
        [23036],
        [23024],
        [22790],
        [22866],
        [22879],
        [22992],
        [22541],
        [22710],
        [22763]], device='cuda:0')
[2024-07-24 10:29:24,023][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[19736],
        [21454],
        [21455],
        [21934],
        [21911],
        [21978],
        [21981],
        [22036],
        [22124],
        [22099],
        [22090],
        [21987],
        [21991],
        [21954],
        [21862]], device='cuda:0')
[2024-07-24 10:29:24,025][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[4030],
        [3447],
        [2394],
        [2560],
        [2020],
        [2422],
        [2374],
        [2642],
        [3065],
        [3268],
        [3012],
        [3129],
        [2644],
        [2742],
        [2995]], device='cuda:0')
[2024-07-24 10:29:24,026][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[15161],
        [ 7351],
        [ 8039],
        [ 8181],
        [10058],
        [10944],
        [ 9106],
        [10751],
        [ 9726],
        [10442],
        [10266],
        [ 9815],
        [10129],
        [ 9910],
        [ 9194]], device='cuda:0')
[2024-07-24 10:29:24,028][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[23970],
        [20422],
        [15151],
        [16458],
        [18420],
        [19468],
        [21735],
        [25676],
        [27870],
        [24897],
        [22773],
        [23591],
        [17814],
        [19735],
        [20031]], device='cuda:0')
[2024-07-24 10:29:24,029][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[23764],
        [22041],
        [18332],
        [11783],
        [20559],
        [19417],
        [24199],
        [31700],
        [26005],
        [29110],
        [18438],
        [22315],
        [18502],
        [15678],
        [17119]], device='cuda:0')
[2024-07-24 10:29:24,031][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[37660],
        [37660],
        [37660],
        [37660],
        [37660],
        [37660],
        [37660],
        [37660],
        [37660],
        [37660],
        [37660],
        [37660],
        [37660],
        [37660],
        [37660]], device='cuda:0')
[2024-07-24 10:29:24,064][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:24,065][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,065][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,065][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,065][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,066][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,066][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,066][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,067][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,067][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,067][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,068][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,068][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,068][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.8703, 0.1297], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,069][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.5572, 0.4428], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,069][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.3766, 0.6234], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,069][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1046, 0.8954], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,070][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3974, 0.6026], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,070][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.5342, 0.4658], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,070][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.8145, 0.1855], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,071][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0865, 0.9135], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,071][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0226, 0.9774], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,071][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.6094, 0.3906], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,072][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.8202, 0.1798], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,072][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0038, 0.9962], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,072][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Jennifer] are: tensor([0.8305, 0.0869, 0.0827], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,073][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Jennifer] are: tensor([0.2886, 0.4335, 0.2779], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,073][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Jennifer] are: tensor([0.2529, 0.3625, 0.3846], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,073][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Jennifer] are: tensor([0.0479, 0.8871, 0.0650], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,074][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Jennifer] are: tensor([0.2666, 0.4276, 0.3058], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,074][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Jennifer] are: tensor([0.1992, 0.1690, 0.6317], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,074][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Jennifer] are: tensor([0.7853, 0.0274, 0.1873], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,075][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Jennifer] are: tensor([0.2219, 0.1043, 0.6738], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,075][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Jennifer] are: tensor([0.0037, 0.0132, 0.9832], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,075][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Jennifer] are: tensor([0.6304, 0.0681, 0.3015], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,076][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Jennifer] are: tensor([0.7394, 0.1526, 0.1080], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,076][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Jennifer] are: tensor([0.0013, 0.0021, 0.9966], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,076][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.9418, 0.0474, 0.0020, 0.0087], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,077][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1772, 0.2931, 0.4920, 0.0377], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,077][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1586, 0.2732, 0.2964, 0.2718], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,077][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0185, 0.5077, 0.3672, 0.1065], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,078][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1856, 0.2852, 0.2314, 0.2978], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,078][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1128, 0.0749, 0.4226, 0.3897], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,078][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0631, 0.0224, 0.8970, 0.0175], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,079][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0019, 0.0118, 0.9767, 0.0096], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,079][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([1.7688e-04, 4.2201e-03, 9.7156e-01, 2.4038e-02], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,079][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1597, 0.1393, 0.6325, 0.0685], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,079][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.6178, 0.1378, 0.1017, 0.1428], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,080][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([2.1159e-05, 2.6159e-03, 9.8955e-01, 7.8150e-03], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,081][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Megan] are: tensor([3.1241e-01, 7.3454e-03, 7.5410e-05, 1.7926e-04, 6.7999e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,082][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Megan] are: tensor([0.1498, 0.2557, 0.1909, 0.1550, 0.2485], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,083][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Megan] are: tensor([0.1489, 0.2002, 0.2136, 0.1976, 0.2397], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,085][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Megan] are: tensor([0.0201, 0.4432, 0.1202, 0.3564, 0.0601], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,086][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Megan] are: tensor([0.1433, 0.2310, 0.1818, 0.2405, 0.2034], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,088][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Megan] are: tensor([0.0753, 0.0710, 0.2285, 0.3166, 0.3086], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,089][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Megan] are: tensor([0.3031, 0.0018, 0.0168, 0.0013, 0.6770], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,089][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Megan] are: tensor([1.9956e-02, 2.3852e-04, 7.8085e-03, 3.1156e-04, 9.7169e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,090][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Megan] are: tensor([0.0136, 0.0098, 0.3783, 0.0207, 0.5776], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,090][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Megan] are: tensor([0.2046, 0.0054, 0.0250, 0.0030, 0.7621], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,091][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Megan] are: tensor([0.5655, 0.1175, 0.0863, 0.1189, 0.1118], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,091][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Megan] are: tensor([1.1267e-04, 5.4069e-05, 3.0844e-02, 1.4096e-04, 9.6885e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,091][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ had] are: tensor([8.8679e-01, 7.2214e-02, 6.9207e-05, 5.6232e-03, 8.5699e-04, 3.4445e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,092][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.1596, 0.1201, 0.2841, 0.1909, 0.1863, 0.0590], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,093][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0953, 0.1694, 0.1859, 0.1748, 0.2241, 0.1505], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,094][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0097, 0.3224, 0.2459, 0.1563, 0.2519, 0.0138], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,095][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1194, 0.1763, 0.1415, 0.1857, 0.1774, 0.1997], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,097][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0482, 0.0415, 0.1795, 0.1983, 0.3155, 0.2171], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,098][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ had] are: tensor([7.1208e-04, 4.8533e-04, 1.1440e-02, 3.0118e-04, 9.8669e-01, 3.6727e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,098][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ had] are: tensor([3.7090e-06, 2.1319e-05, 1.3583e-03, 1.4714e-05, 9.9851e-01, 8.8017e-05],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,099][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ had] are: tensor([2.6452e-04, 1.2347e-02, 4.8352e-01, 3.8575e-02, 4.5339e-01, 1.1905e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,101][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0393, 0.0433, 0.0274, 0.0062, 0.8786, 0.0051], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,102][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.4575, 0.1182, 0.0876, 0.1206, 0.1104, 0.1056], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,103][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ had] are: tensor([4.5831e-07, 6.8208e-05, 2.2062e-02, 2.0727e-04, 9.7517e-01, 2.4922e-03],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,104][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([8.7231e-01, 2.2000e-02, 1.8364e-04, 2.0375e-03, 2.5964e-03, 2.5551e-04,
        1.0062e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,105][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1003, 0.1334, 0.1898, 0.0676, 0.3899, 0.0662, 0.0528],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,107][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0773, 0.1482, 0.1623, 0.1495, 0.2012, 0.1354, 0.1261],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,108][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0135, 0.4932, 0.0944, 0.1029, 0.2123, 0.0698, 0.0139],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,110][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0987, 0.1467, 0.1246, 0.1553, 0.1526, 0.1767, 0.1453],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,111][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0246, 0.0297, 0.1581, 0.1671, 0.3043, 0.1944, 0.1218],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,112][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([1.1451e-03, 5.8045e-04, 1.4190e-02, 4.8479e-04, 9.8015e-01, 2.1639e-03,
        1.2886e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,113][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([2.2131e-06, 2.7548e-05, 2.0139e-03, 2.1858e-05, 9.9768e-01, 1.8224e-04,
        6.8624e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,114][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([6.6929e-06, 3.3725e-03, 4.7282e-01, 2.7095e-02, 4.8443e-01, 5.9483e-03,
        6.3325e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,115][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0045, 0.0077, 0.0311, 0.0045, 0.9385, 0.0090, 0.0047],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,116][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.4285, 0.0943, 0.0778, 0.1050, 0.0963, 0.0925, 0.1055],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,117][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([9.1788e-08, 2.1871e-05, 1.2270e-02, 9.0364e-05, 9.8454e-01, 2.2908e-03,
        7.8173e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,118][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ long] are: tensor([5.4702e-01, 3.8148e-02, 1.8317e-05, 2.7383e-03, 3.7137e-04, 5.1514e-04,
        9.3086e-03, 4.0188e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,120][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0846, 0.1433, 0.1726, 0.1368, 0.2815, 0.0618, 0.0979, 0.0216],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,120][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0674, 0.1283, 0.1417, 0.1309, 0.1760, 0.1191, 0.1118, 0.1249],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,121][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0121, 0.5231, 0.0487, 0.2637, 0.0482, 0.0221, 0.0598, 0.0222],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,121][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0865, 0.1317, 0.1122, 0.1388, 0.1354, 0.1550, 0.1287, 0.1117],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,121][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0267, 0.0281, 0.1272, 0.1510, 0.2203, 0.1654, 0.1238, 0.1574],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,122][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ long] are: tensor([3.8397e-03, 6.5459e-04, 1.0628e-02, 4.3727e-04, 9.3204e-01, 8.8198e-04,
        2.4385e-03, 4.9082e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,122][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ long] are: tensor([1.5286e-05, 3.0532e-05, 1.1662e-03, 2.3113e-05, 9.9096e-01, 1.3302e-04,
        1.4585e-04, 7.5296e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,123][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0006, 0.0123, 0.3892, 0.0360, 0.4836, 0.0147, 0.0214, 0.0422],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,123][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0245, 0.0267, 0.0303, 0.0084, 0.7923, 0.0253, 0.0168, 0.0758],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,124][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.3962, 0.0880, 0.0674, 0.0909, 0.0860, 0.0812, 0.0960, 0.0943],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,125][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ long] are: tensor([7.2605e-07, 3.0273e-05, 8.5273e-03, 1.1467e-04, 7.2959e-01, 1.9174e-03,
        1.1139e-03, 2.5871e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,125][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([4.7978e-01, 3.3514e-02, 3.3084e-04, 2.7108e-03, 3.5196e-04, 2.3393e-04,
        5.4890e-03, 6.6047e-04, 4.7693e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,127][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0508, 0.1117, 0.1022, 0.0967, 0.4037, 0.0903, 0.0969, 0.0389, 0.0088],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,128][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0517, 0.1188, 0.1300, 0.1167, 0.1684, 0.1072, 0.0988, 0.1131, 0.0952],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,130][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0071, 0.3182, 0.0858, 0.1675, 0.2152, 0.0797, 0.0280, 0.0859, 0.0127],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,131][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0784, 0.1188, 0.0958, 0.1257, 0.1200, 0.1454, 0.1132, 0.1055, 0.0972],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,132][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0217, 0.0238, 0.0967, 0.1250, 0.1543, 0.1736, 0.1362, 0.1351, 0.1336],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,133][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([2.8003e-03, 7.2497e-04, 1.0064e-02, 5.6744e-04, 7.6039e-01, 2.0907e-03,
        3.7567e-03, 1.9974e-01, 1.9867e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,134][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([2.0306e-05, 3.1679e-05, 1.4846e-03, 3.5965e-05, 9.0299e-01, 2.2629e-04,
        2.2603e-04, 8.4950e-02, 1.0036e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,136][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0009, 0.0143, 0.4267, 0.0398, 0.3848, 0.0142, 0.0262, 0.0525, 0.0406],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,137][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0035, 0.0042, 0.0264, 0.0019, 0.9100, 0.0057, 0.0042, 0.0348, 0.0092],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,138][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.3514, 0.0796, 0.0607, 0.0865, 0.0786, 0.0771, 0.0915, 0.0858, 0.0888],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,139][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([2.5585e-07, 1.3985e-05, 5.9486e-03, 6.5030e-05, 3.0119e-01, 1.3555e-03,
        1.2776e-03, 6.1180e-01, 7.8343e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,141][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.7084, 0.0844, 0.0089, 0.0184, 0.0094, 0.0019, 0.0182, 0.0123, 0.0124,
        0.1257], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,142][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0492, 0.0605, 0.1432, 0.0762, 0.3361, 0.1031, 0.0768, 0.0447, 0.0420,
        0.0682], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,144][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0411, 0.1046, 0.1189, 0.1068, 0.1640, 0.0992, 0.0918, 0.1105, 0.0814,
        0.0817], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,145][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0091, 0.1902, 0.1702, 0.0692, 0.1963, 0.0743, 0.0583, 0.1842, 0.0303,
        0.0180], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,146][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0679, 0.1068, 0.0884, 0.1129, 0.1079, 0.1294, 0.1045, 0.0916, 0.0845,
        0.1061], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,148][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0188, 0.0167, 0.0976, 0.0951, 0.1789, 0.1152, 0.0762, 0.1125, 0.1617,
        0.1272], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,149][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0135, 0.0008, 0.0201, 0.0009, 0.8249, 0.0020, 0.0032, 0.0680, 0.0280,
        0.0387], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,150][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([7.8099e-05, 5.8222e-05, 4.2688e-03, 5.2277e-05, 9.2358e-01, 3.3814e-04,
        3.2768e-04, 1.8654e-02, 3.5080e-02, 1.7567e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,151][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([1.9758e-04, 3.6574e-03, 3.5888e-01, 1.4865e-02, 4.4200e-01, 8.0908e-03,
        5.5632e-03, 2.3332e-02, 2.7532e-02, 1.1588e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,152][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0055, 0.0020, 0.0507, 0.0031, 0.8741, 0.0029, 0.0031, 0.0135, 0.0114,
        0.0338], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,152][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.3235, 0.0696, 0.0551, 0.0779, 0.0655, 0.0672, 0.0759, 0.0699, 0.0716,
        0.1238], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,153][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([6.2572e-07, 4.5750e-05, 1.3262e-02, 1.7584e-04, 5.2510e-01, 1.8769e-03,
        2.3927e-03, 2.0002e-01, 1.9601e-01, 6.1105e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,153][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([8.5767e-01, 3.6045e-02, 2.5356e-03, 7.5669e-03, 3.0071e-03, 2.4351e-04,
        4.4985e-03, 1.3730e-03, 2.7577e-03, 7.5213e-02, 9.0889e-03],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,153][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0402, 0.0761, 0.1508, 0.0088, 0.3701, 0.0927, 0.0432, 0.0539, 0.0536,
        0.1036, 0.0070], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,154][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0496, 0.0965, 0.1090, 0.1010, 0.1403, 0.0909, 0.0861, 0.0992, 0.0725,
        0.0742, 0.0808], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,155][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0047, 0.2673, 0.2353, 0.0592, 0.1061, 0.0758, 0.0722, 0.0905, 0.0533,
        0.0274, 0.0084], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,157][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0622, 0.0959, 0.0802, 0.1012, 0.0978, 0.1143, 0.0922, 0.0820, 0.0764,
        0.0967, 0.1010], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,158][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0170, 0.0121, 0.0796, 0.0757, 0.1492, 0.0919, 0.0556, 0.1066, 0.1666,
        0.1056, 0.1401], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,159][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([1.1805e-02, 2.0829e-04, 1.1694e-02, 1.6903e-04, 8.3611e-01, 7.6004e-04,
        1.5133e-03, 5.8465e-02, 1.2966e-02, 3.5000e-02, 3.1311e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,160][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([1.5220e-04, 9.3716e-06, 1.4022e-03, 1.2435e-05, 9.3611e-01, 8.2920e-05,
        1.0244e-04, 9.3541e-03, 1.5709e-02, 1.2680e-02, 2.4384e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,161][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([2.2484e-04, 1.5522e-03, 3.1784e-01, 5.0468e-03, 4.7425e-01, 5.7955e-03,
        2.6439e-03, 1.7707e-02, 2.1097e-02, 8.1264e-02, 7.2586e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,162][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0930, 0.0092, 0.0264, 0.0036, 0.4948, 0.0057, 0.0056, 0.0238, 0.0247,
        0.1902, 0.1230], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,163][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2905, 0.0625, 0.0507, 0.0703, 0.0616, 0.0620, 0.0672, 0.0634, 0.0651,
        0.1123, 0.0945], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,164][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([4.5519e-07, 9.4174e-06, 5.8051e-03, 2.5968e-05, 3.9872e-01, 8.7376e-04,
        9.6010e-04, 2.2310e-01, 2.4660e-01, 6.8417e-02, 5.5488e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,166][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.4474, 0.0465, 0.0023, 0.0053, 0.0031, 0.0014, 0.0100, 0.0094, 0.0081,
        0.0543, 0.0055, 0.4066], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,167][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0418, 0.1371, 0.0895, 0.0737, 0.1702, 0.1066, 0.0423, 0.1310, 0.0228,
        0.1176, 0.0572, 0.0103], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,169][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0406, 0.0925, 0.1037, 0.0922, 0.1318, 0.0846, 0.0755, 0.0888, 0.0642,
        0.0690, 0.0764, 0.0808], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,170][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0037, 0.2849, 0.0316, 0.2581, 0.0420, 0.0282, 0.0509, 0.2072, 0.0063,
        0.0314, 0.0388, 0.0168], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,172][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0552, 0.0898, 0.0708, 0.0973, 0.0893, 0.1078, 0.0872, 0.0802, 0.0759,
        0.0904, 0.0965, 0.0596], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,173][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0151, 0.0139, 0.0683, 0.0720, 0.1070, 0.0970, 0.0693, 0.0975, 0.1187,
        0.1009, 0.1214, 0.1189], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,174][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0098, 0.0039, 0.0275, 0.0031, 0.4688, 0.0112, 0.0089, 0.1248, 0.0508,
        0.0551, 0.0711, 0.1651], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,175][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([6.1956e-05, 3.5435e-04, 9.3171e-03, 4.2144e-04, 7.5127e-01, 1.7805e-03,
        1.4699e-03, 8.9907e-02, 2.5834e-02, 2.5705e-02, 5.8186e-02, 3.5693e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,177][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0014, 0.0071, 0.2949, 0.0144, 0.2499, 0.0091, 0.0069, 0.0273, 0.0305,
        0.0875, 0.0815, 0.1893], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,178][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0030, 0.0111, 0.0717, 0.0058, 0.4904, 0.0173, 0.0094, 0.1022, 0.0577,
        0.0756, 0.0669, 0.0887], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,180][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.2946, 0.0562, 0.0410, 0.0609, 0.0508, 0.0546, 0.0582, 0.0554, 0.0574,
        0.0995, 0.0864, 0.0849], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,181][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([1.2267e-05, 2.3012e-04, 3.1811e-02, 7.7049e-04, 4.4530e-01, 6.8489e-03,
        5.0825e-03, 2.2371e-01, 1.4560e-01, 5.5410e-02, 7.0241e-02, 1.4986e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,182][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Megan] are: tensor([1.6166e-01, 3.6288e-03, 5.2452e-05, 1.0236e-04, 3.5361e-01, 1.1264e-05,
        1.2496e-03, 1.7114e-04, 2.7952e-04, 5.2016e-03, 1.0461e-04, 5.3628e-02,
        4.2031e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,182][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Megan] are: tensor([0.0662, 0.1006, 0.0935, 0.0691, 0.1026, 0.0341, 0.0492, 0.0250, 0.0850,
        0.0969, 0.0927, 0.0788, 0.1064], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,183][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Megan] are: tensor([0.0576, 0.0850, 0.0916, 0.0824, 0.1052, 0.0721, 0.0671, 0.0742, 0.0547,
        0.0632, 0.0733, 0.0768, 0.0969], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,183][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Megan] are: tensor([0.0096, 0.1991, 0.0642, 0.1695, 0.0239, 0.0369, 0.0798, 0.2308, 0.0116,
        0.0322, 0.0505, 0.0733, 0.0184], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,184][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Megan] are: tensor([0.0524, 0.0856, 0.0680, 0.0903, 0.0756, 0.1029, 0.0818, 0.0750, 0.0681,
        0.0854, 0.0926, 0.0579, 0.0644], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,184][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Megan] are: tensor([0.0136, 0.0166, 0.0588, 0.0798, 0.0815, 0.0917, 0.0721, 0.0817, 0.0744,
        0.0919, 0.1279, 0.1238, 0.0860], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,184][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Megan] are: tensor([5.1659e-02, 1.4839e-04, 1.6606e-03, 1.1916e-04, 6.2082e-02, 8.8917e-05,
        3.4682e-04, 5.0390e-03, 2.9786e-03, 2.1894e-02, 2.2645e-02, 1.1583e-01,
        7.1551e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,185][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Megan] are: tensor([3.5633e-03, 1.0120e-05, 2.9989e-04, 1.0875e-05, 3.1781e-02, 1.7453e-05,
        6.6867e-05, 2.0770e-03, 3.9619e-03, 1.2263e-02, 2.1662e-02, 2.3320e-01,
        6.9108e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,185][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Megan] are: tensor([0.0071, 0.0025, 0.0843, 0.0033, 0.1118, 0.0034, 0.0024, 0.0139, 0.0200,
        0.0540, 0.0374, 0.2726, 0.3874], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,186][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Megan] are: tensor([6.3746e-02, 1.2602e-03, 2.9487e-03, 4.6849e-04, 6.3703e-02, 2.4881e-04,
        6.1242e-04, 2.1055e-03, 2.5767e-03, 3.5615e-02, 1.8408e-02, 1.2534e-01,
        6.8296e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,188][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Megan] are: tensor([0.2763, 0.0537, 0.0402, 0.0557, 0.0513, 0.0503, 0.0548, 0.0510, 0.0544,
        0.0899, 0.0800, 0.0773, 0.0648], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,188][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Megan] are: tensor([6.3217e-06, 5.2739e-06, 3.6441e-03, 1.9013e-05, 1.1443e-01, 3.3977e-04,
        3.5721e-04, 3.5577e-02, 4.4344e-02, 2.2274e-02, 1.5968e-02, 1.0464e-02,
        7.5257e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,189][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ said] are: tensor([4.7514e-01, 1.7851e-02, 1.3781e-04, 1.8208e-03, 2.5472e-03, 2.0268e-04,
        1.2332e-02, 4.0782e-04, 5.7925e-03, 3.9674e-02, 2.7550e-03, 2.0411e-01,
        3.4819e-03, 2.3375e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,191][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0386, 0.0768, 0.0645, 0.0584, 0.1856, 0.0246, 0.0765, 0.0729, 0.0042,
        0.1123, 0.0721, 0.0490, 0.1513, 0.0131], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,192][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0313, 0.0751, 0.0847, 0.0746, 0.1106, 0.0673, 0.0605, 0.0756, 0.0599,
        0.0600, 0.0598, 0.0753, 0.1079, 0.0573], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,193][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0051, 0.2484, 0.0560, 0.1292, 0.0838, 0.0251, 0.0265, 0.1605, 0.0032,
        0.0471, 0.0323, 0.1235, 0.0565, 0.0029], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,195][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0499, 0.0764, 0.0622, 0.0813, 0.0788, 0.0898, 0.0738, 0.0673, 0.0649,
        0.0761, 0.0814, 0.0544, 0.0678, 0.0760], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,196][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0132, 0.0122, 0.0675, 0.0613, 0.1090, 0.0732, 0.0601, 0.0644, 0.0822,
        0.0726, 0.0931, 0.0986, 0.1232, 0.0693], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,197][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ said] are: tensor([5.5766e-03, 3.6302e-05, 7.4513e-04, 2.9901e-05, 5.6564e-02, 3.4519e-05,
        1.1906e-04, 3.7617e-03, 1.0552e-03, 6.9082e-03, 6.5556e-03, 3.1130e-02,
        8.8266e-01, 4.8254e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,198][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ said] are: tensor([2.9520e-05, 5.7053e-07, 5.7485e-05, 8.2763e-07, 4.6117e-02, 1.4079e-06,
        6.1203e-06, 2.2551e-04, 5.2014e-04, 8.5399e-04, 1.4632e-03, 9.7175e-03,
        9.3747e-01, 3.5349e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,200][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0008, 0.0017, 0.1414, 0.0045, 0.1518, 0.0038, 0.0027, 0.0150, 0.0146,
        0.0450, 0.0389, 0.1407, 0.4087, 0.0306], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,201][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ said] are: tensor([6.1228e-02, 1.5631e-03, 2.5180e-03, 4.9368e-04, 8.4333e-02, 2.1570e-04,
        4.2319e-04, 1.8521e-03, 1.2250e-03, 3.6145e-02, 1.9203e-02, 1.3490e-01,
        6.4717e-01, 8.7337e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,202][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.2274, 0.0502, 0.0425, 0.0545, 0.0508, 0.0492, 0.0559, 0.0514, 0.0526,
        0.0875, 0.0761, 0.0726, 0.0629, 0.0665], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,203][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ said] are: tensor([6.8551e-07, 5.2609e-06, 3.9959e-03, 3.0325e-05, 1.5126e-01, 6.3646e-04,
        5.0623e-04, 1.0366e-01, 9.1285e-02, 2.6560e-02, 2.3539e-02, 9.5653e-03,
        4.9590e-01, 9.3060e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,204][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([7.1449e-01, 2.0021e-02, 2.3455e-04, 1.5719e-03, 3.0311e-04, 1.7613e-04,
        3.6516e-03, 1.9458e-03, 3.4365e-03, 3.5499e-02, 1.7319e-03, 2.0368e-01,
        3.7133e-04, 2.4196e-03, 1.0469e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,206][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0337, 0.0364, 0.1505, 0.0306, 0.1308, 0.1014, 0.0372, 0.0472, 0.0609,
        0.0433, 0.0340, 0.0330, 0.1176, 0.1387, 0.0046], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,207][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0337, 0.0734, 0.0802, 0.0726, 0.1003, 0.0659, 0.0605, 0.0730, 0.0527,
        0.0543, 0.0611, 0.0612, 0.0932, 0.0486, 0.0693], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,209][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0048, 0.2318, 0.0311, 0.0675, 0.1404, 0.0597, 0.0349, 0.1008, 0.1147,
        0.0276, 0.0114, 0.0514, 0.0933, 0.0287, 0.0018], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,210][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0472, 0.0715, 0.0600, 0.0761, 0.0721, 0.0891, 0.0702, 0.0624, 0.0587,
        0.0714, 0.0755, 0.0511, 0.0623, 0.0699, 0.0625], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,212][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0096, 0.0103, 0.0624, 0.0483, 0.1015, 0.0587, 0.0388, 0.0649, 0.0817,
        0.0650, 0.0779, 0.0913, 0.1177, 0.0559, 0.1161], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,213][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([6.3179e-03, 1.6718e-05, 4.6181e-04, 2.0390e-05, 5.3682e-02, 5.2966e-05,
        9.1517e-05, 3.8079e-03, 1.0611e-03, 4.2210e-03, 5.3582e-03, 4.2958e-02,
        8.4990e-01, 1.0713e-02, 2.1338e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,214][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([2.9738e-05, 4.5145e-07, 3.8122e-05, 6.7810e-07, 2.2199e-02, 1.7396e-06,
        6.2951e-06, 6.6176e-04, 9.6063e-04, 1.1433e-03, 2.0647e-03, 1.3025e-02,
        8.7330e-01, 3.5397e-02, 5.1169e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,214][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0004, 0.0011, 0.0962, 0.0037, 0.1240, 0.0040, 0.0018, 0.0117, 0.0119,
        0.0391, 0.0351, 0.1420, 0.3935, 0.0645, 0.0710], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,215][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([2.3790e-02, 7.5039e-04, 2.8581e-03, 2.7482e-04, 6.4560e-02, 3.3804e-04,
        5.7831e-04, 2.2419e-03, 6.7659e-03, 3.3158e-02, 1.4539e-02, 7.8551e-02,
        7.0723e-01, 4.2095e-02, 2.2272e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,215][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.2044, 0.0473, 0.0396, 0.0514, 0.0486, 0.0462, 0.0527, 0.0494, 0.0507,
        0.0806, 0.0673, 0.0623, 0.0581, 0.0646, 0.0769], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,216][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.0422e-07, 2.3220e-06, 1.4894e-03, 1.0512e-05, 6.0943e-02, 2.5639e-04,
        2.4731e-04, 9.1049e-02, 9.2861e-02, 1.6550e-02, 1.4190e-02, 2.4628e-03,
        3.8556e-01, 1.7945e-01, 1.5493e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,238][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:24,239][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,240][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,241][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,242][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,243][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,244][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,246][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,247][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,248][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,249][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,250][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,251][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,253][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1809, 0.8191], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,254][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.7036, 0.2964], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,254][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.4376, 0.5624], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,255][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.4885, 0.5115], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,255][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.4675, 0.5325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,255][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.6069, 0.3931], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,256][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1035, 0.8965], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,256][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0865, 0.9135], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,256][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.6008, 0.3992], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,257][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.6094, 0.3906], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,257][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9366, 0.0634], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,258][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.5262, 0.4738], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,259][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Jennifer] are: tensor([0.0073, 0.1465, 0.8462], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,260][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Jennifer] are: tensor([0.7567, 0.1111, 0.1323], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,262][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Jennifer] are: tensor([0.3697, 0.3950, 0.2353], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,263][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Jennifer] are: tensor([0.6432, 0.2888, 0.0679], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,265][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Jennifer] are: tensor([0.3067, 0.3515, 0.3418], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,266][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Jennifer] are: tensor([0.1021, 0.3797, 0.5182], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,267][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Jennifer] are: tensor([0.0824, 0.5064, 0.4112], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,269][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Jennifer] are: tensor([0.2219, 0.1043, 0.6738], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,270][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Jennifer] are: tensor([0.6063, 0.0224, 0.3713], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,271][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Jennifer] are: tensor([0.6304, 0.0681, 0.3015], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,273][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Jennifer] are: tensor([0.9337, 0.0149, 0.0514], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,274][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Jennifer] are: tensor([0.7871, 0.0889, 0.1240], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,276][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0606, 0.2042, 0.0999, 0.6353], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,277][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.4155, 0.1862, 0.3623, 0.0360], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,279][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2412, 0.3063, 0.2746, 0.1778], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,280][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3718, 0.1324, 0.0487, 0.4470], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,281][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2282, 0.2629, 0.2562, 0.2527], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,283][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2241, 0.2287, 0.3789, 0.1683], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,284][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0282, 0.2731, 0.3320, 0.3667], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,286][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0019, 0.0118, 0.9767, 0.0096], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,286][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0467, 0.0395, 0.8814, 0.0324], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,287][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1597, 0.1393, 0.6325, 0.0685], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,287][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.7554, 0.0563, 0.1388, 0.0495], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,287][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2651, 0.3426, 0.2621, 0.1302], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,288][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Megan] are: tensor([0.0046, 0.0119, 0.0018, 0.0132, 0.9685], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,288][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Megan] are: tensor([0.4813, 0.0215, 0.0213, 0.0070, 0.4689], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,288][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Megan] are: tensor([0.2498, 0.2537, 0.1967, 0.1651, 0.1347], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,290][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Megan] are: tensor([0.2840, 0.1208, 0.0344, 0.4732, 0.0876], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,291][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Megan] are: tensor([0.1817, 0.2087, 0.2031, 0.2013, 0.2052], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,292][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Megan] are: tensor([0.0580, 0.2011, 0.3237, 0.1016, 0.3156], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,293][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Megan] are: tensor([0.0426, 0.2385, 0.1902, 0.2872, 0.2415], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,294][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Megan] are: tensor([1.9956e-02, 2.3852e-04, 7.8085e-03, 3.1156e-04, 9.7169e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,295][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Megan] are: tensor([1.2490e-01, 2.7039e-04, 3.9156e-03, 6.9622e-04, 8.7021e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,296][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Megan] are: tensor([0.2046, 0.0054, 0.0250, 0.0030, 0.7621], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,298][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Megan] are: tensor([0.7952, 0.0061, 0.0223, 0.0077, 0.1688], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,299][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Megan] are: tensor([0.4300, 0.0125, 0.0184, 0.0069, 0.5323], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,301][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0187, 0.1400, 0.0047, 0.2425, 0.0219, 0.5723], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,302][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0657, 0.0245, 0.0256, 0.0070, 0.8743, 0.0028], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,303][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.1752, 0.1788, 0.1994, 0.1524, 0.2232, 0.0711], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,305][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1837, 0.0545, 0.0375, 0.1781, 0.1512, 0.3950], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,306][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1492, 0.1717, 0.1672, 0.1658, 0.1691, 0.1769], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,308][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0600, 0.1070, 0.1572, 0.1147, 0.4224, 0.1387], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,309][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0107, 0.1204, 0.1563, 0.1764, 0.2009, 0.3353], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,310][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([3.7090e-06, 2.1319e-05, 1.3583e-03, 1.4714e-05, 9.9851e-01, 8.8017e-05],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,311][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([2.7951e-04, 1.9764e-04, 2.8449e-03, 2.2293e-04, 9.9632e-01, 1.3988e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,312][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0393, 0.0433, 0.0274, 0.0062, 0.8786, 0.0051], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,314][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.1817, 0.0213, 0.0797, 0.0195, 0.6606, 0.0372], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,315][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0274, 0.0331, 0.0171, 0.0106, 0.9031, 0.0087], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,317][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0252, 0.0458, 0.0092, 0.0992, 0.0400, 0.0153, 0.7653],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,317][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0367, 0.0265, 0.0293, 0.0057, 0.8893, 0.0049, 0.0076],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,317][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1259, 0.1731, 0.1347, 0.1531, 0.1746, 0.1103, 0.1283],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,318][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0678, 0.0256, 0.0129, 0.0997, 0.0584, 0.4590, 0.2766],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,318][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1271, 0.1458, 0.1422, 0.1411, 0.1434, 0.1495, 0.1508],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,318][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0605, 0.0902, 0.1946, 0.0612, 0.4454, 0.0890, 0.0591],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,319][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0045, 0.0800, 0.1378, 0.1446, 0.1770, 0.3163, 0.1400],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,319][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([2.2131e-06, 2.7548e-05, 2.0139e-03, 2.1858e-05, 9.9768e-01, 1.8224e-04,
        6.8624e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,319][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.2870e-04, 1.5567e-04, 3.7807e-03, 1.7043e-04, 9.9515e-01, 2.8735e-04,
        3.2885e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,320][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0045, 0.0077, 0.0311, 0.0045, 0.9385, 0.0090, 0.0047],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,320][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2757, 0.0304, 0.0910, 0.0289, 0.4676, 0.0392, 0.0672],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,321][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0135, 0.0178, 0.0166, 0.0072, 0.9195, 0.0144, 0.0110],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,323][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0093, 0.0497, 0.0008, 0.0898, 0.0042, 0.0141, 0.0512, 0.7809],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,324][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.1300, 0.0638, 0.0199, 0.0070, 0.7194, 0.0064, 0.0129, 0.0405],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,325][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0960, 0.1267, 0.0961, 0.1678, 0.1079, 0.1026, 0.2448, 0.0582],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,327][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0337, 0.0378, 0.0153, 0.1158, 0.0403, 0.3389, 0.3053, 0.1131],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,328][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.1103, 0.1281, 0.1250, 0.1235, 0.1264, 0.1311, 0.1328, 0.1228],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,329][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0899, 0.0644, 0.1223, 0.0948, 0.3791, 0.1191, 0.0979, 0.0326],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,331][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0152, 0.1019, 0.1025, 0.1380, 0.1268, 0.2538, 0.1472, 0.1146],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,332][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([1.5286e-05, 3.0532e-05, 1.1662e-03, 2.3113e-05, 9.9096e-01, 1.3302e-04,
        1.4585e-04, 7.5296e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,333][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([8.4131e-04, 1.6881e-04, 1.0383e-03, 1.6023e-04, 9.8632e-01, 1.9576e-04,
        4.7436e-04, 1.0800e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,334][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0245, 0.0267, 0.0303, 0.0084, 0.7923, 0.0253, 0.0168, 0.0758],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,335][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.2885, 0.0239, 0.0332, 0.0188, 0.3558, 0.0268, 0.0467, 0.2064],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,337][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0429, 0.0138, 0.0057, 0.0058, 0.6767, 0.0067, 0.0086, 0.2399],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,338][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0029, 0.0168, 0.0018, 0.0272, 0.0013, 0.0027, 0.0109, 0.0027, 0.9336],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,340][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0384, 0.0153, 0.0154, 0.0052, 0.8369, 0.0049, 0.0084, 0.0486, 0.0269],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,341][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.1140, 0.1389, 0.0968, 0.1337, 0.1047, 0.0816, 0.1896, 0.0692, 0.0715],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,343][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0103, 0.0226, 0.0074, 0.1012, 0.0177, 0.4077, 0.3300, 0.0876, 0.0156],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,344][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0979, 0.1148, 0.1121, 0.1106, 0.1137, 0.1178, 0.1197, 0.1112, 0.1022],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,345][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0440, 0.0682, 0.1384, 0.1143, 0.3625, 0.0998, 0.0867, 0.0277, 0.0584],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,347][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0129, 0.1045, 0.0797, 0.1329, 0.0932, 0.2523, 0.1651, 0.0999, 0.0596],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,348][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([2.0306e-05, 3.1679e-05, 1.4846e-03, 3.5965e-05, 9.0299e-01, 2.2629e-04,
        2.2603e-04, 8.4950e-02, 1.0036e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,348][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([9.6241e-04, 1.8922e-04, 4.6837e-03, 3.2237e-04, 9.1909e-01, 3.9314e-04,
        9.0379e-04, 6.5841e-02, 7.6105e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,349][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0035, 0.0042, 0.0264, 0.0019, 0.9100, 0.0057, 0.0042, 0.0348, 0.0092],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,349][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.2049, 0.0202, 0.0538, 0.0160, 0.3948, 0.0163, 0.0326, 0.1454, 0.1161],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,349][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0159, 0.0049, 0.0055, 0.0034, 0.2543, 0.0050, 0.0101, 0.6437, 0.0571],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,350][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0355, 0.1164, 0.0581, 0.2381, 0.0383, 0.0180, 0.0678, 0.0554, 0.0566,
        0.3158], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,350][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0462, 0.0076, 0.0178, 0.0028, 0.8322, 0.0019, 0.0066, 0.0153, 0.0139,
        0.0558], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,350][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0840, 0.0895, 0.0995, 0.0939, 0.1124, 0.0661, 0.1775, 0.0727, 0.0842,
        0.1202], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,351][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0295, 0.0132, 0.0058, 0.0440, 0.0175, 0.2002, 0.1432, 0.1117, 0.0502,
        0.3847], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,352][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0884, 0.1030, 0.1004, 0.0996, 0.1015, 0.1054, 0.1063, 0.0982, 0.0904,
        0.1070], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,353][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0486, 0.0344, 0.1215, 0.0496, 0.5045, 0.0652, 0.0567, 0.0357, 0.0692,
        0.0146], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,354][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0046, 0.0638, 0.0968, 0.1049, 0.1206, 0.2295, 0.1062, 0.1087, 0.0726,
        0.0924], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,355][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([7.8099e-05, 5.8222e-05, 4.2688e-03, 5.2277e-05, 9.2358e-01, 3.3814e-04,
        3.2768e-04, 1.8654e-02, 3.5080e-02, 1.7567e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,356][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([2.2637e-03, 3.8760e-04, 6.4121e-03, 4.2825e-04, 9.4100e-01, 5.4121e-04,
        1.3036e-03, 1.0139e-02, 9.9068e-03, 2.7615e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,357][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0055, 0.0020, 0.0507, 0.0031, 0.8741, 0.0029, 0.0031, 0.0135, 0.0114,
        0.0338], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,359][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2852, 0.0273, 0.0554, 0.0144, 0.2758, 0.0133, 0.0258, 0.0499, 0.0444,
        0.2085], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,360][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0389, 0.0141, 0.0134, 0.0081, 0.3886, 0.0068, 0.0170, 0.1238, 0.1301,
        0.2592], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,362][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0254, 0.0755, 0.0557, 0.2299, 0.0382, 0.0108, 0.0386, 0.0153, 0.0287,
        0.2844, 0.1976], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,363][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.2381, 0.0097, 0.0127, 0.0016, 0.5914, 0.0015, 0.0056, 0.0118, 0.0139,
        0.0710, 0.0427], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,364][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0764, 0.0889, 0.0786, 0.0489, 0.0910, 0.0634, 0.1559, 0.0590, 0.0786,
        0.1369, 0.1225], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,366][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0527, 0.0029, 0.0013, 0.0057, 0.0056, 0.0239, 0.0183, 0.0371, 0.0175,
        0.1118, 0.7231], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,367][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0802, 0.0925, 0.0906, 0.0897, 0.0917, 0.0953, 0.0955, 0.0888, 0.0822,
        0.0965, 0.0971], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,369][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0690, 0.0581, 0.1173, 0.0494, 0.3798, 0.0762, 0.0792, 0.0480, 0.0660,
        0.0235, 0.0335], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,370][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0025, 0.0512, 0.0934, 0.0947, 0.1159, 0.2184, 0.1001, 0.1025, 0.0688,
        0.0888, 0.0637], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,371][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([1.5220e-04, 9.3716e-06, 1.4022e-03, 1.2435e-05, 9.3611e-01, 8.2920e-05,
        1.0244e-04, 9.3541e-03, 1.5709e-02, 1.2680e-02, 2.4384e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,372][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([5.1313e-03, 1.0735e-04, 2.5739e-03, 9.8180e-05, 9.2160e-01, 2.1690e-04,
        5.6310e-04, 6.0839e-03, 4.9306e-03, 2.7617e-02, 3.1073e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,373][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0930, 0.0092, 0.0264, 0.0036, 0.4948, 0.0057, 0.0056, 0.0238, 0.0247,
        0.1902, 0.1230], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,375][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4494, 0.0141, 0.0252, 0.0089, 0.1124, 0.0083, 0.0156, 0.0252, 0.0260,
        0.1698, 0.1452], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,376][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0797, 0.0075, 0.0051, 0.0028, 0.2108, 0.0033, 0.0091, 0.0861, 0.1074,
        0.2670, 0.2211], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,378][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0422, 0.0740, 0.0094, 0.0782, 0.0081, 0.0075, 0.0288, 0.0588, 0.0362,
        0.1795, 0.0541, 0.4231], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,379][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0165, 0.0171, 0.0298, 0.0082, 0.4053, 0.0113, 0.0172, 0.0796, 0.0449,
        0.1181, 0.1144, 0.1376], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,379][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0770, 0.0853, 0.0654, 0.0797, 0.0681, 0.0620, 0.1175, 0.0570, 0.0618,
        0.1011, 0.1449, 0.0801], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,380][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0045, 0.0052, 0.0023, 0.0194, 0.0055, 0.0737, 0.0516, 0.0250, 0.0083,
        0.0828, 0.6942, 0.0276], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,380][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0724, 0.0852, 0.0833, 0.0824, 0.0850, 0.0876, 0.0890, 0.0830, 0.0767,
        0.0901, 0.0906, 0.0747], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,381][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0284, 0.0711, 0.0709, 0.1246, 0.2246, 0.1528, 0.1118, 0.0273, 0.0341,
        0.0349, 0.0846, 0.0350], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,381][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0124, 0.0703, 0.0674, 0.0900, 0.0798, 0.1756, 0.0976, 0.0835, 0.0574,
        0.0863, 0.0676, 0.1121], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,381][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([6.1956e-05, 3.5435e-04, 9.3171e-03, 4.2144e-04, 7.5127e-01, 1.7805e-03,
        1.4699e-03, 8.9907e-02, 2.5834e-02, 2.5705e-02, 5.8186e-02, 3.5693e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,382][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0024, 0.0013, 0.0188, 0.0018, 0.6709, 0.0021, 0.0028, 0.0400, 0.0207,
        0.0562, 0.0974, 0.0855], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,382][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0030, 0.0111, 0.0717, 0.0058, 0.4904, 0.0173, 0.0094, 0.1022, 0.0577,
        0.0756, 0.0669, 0.0887], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,382][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0705, 0.0259, 0.0399, 0.0205, 0.1008, 0.0314, 0.0307, 0.0638, 0.0516,
        0.1255, 0.1584, 0.2809], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,384][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0079, 0.0077, 0.0156, 0.0056, 0.2221, 0.0117, 0.0131, 0.1829, 0.0954,
        0.1138, 0.1332, 0.1911], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,385][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Megan] are: tensor([0.0023, 0.0056, 0.0010, 0.0066, 0.5413, 0.0008, 0.0103, 0.0017, 0.0024,
        0.0190, 0.0054, 0.0046, 0.3992], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,386][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Megan] are: tensor([0.1635, 0.0075, 0.0044, 0.0018, 0.0826, 0.0006, 0.0027, 0.0046, 0.0046,
        0.0540, 0.0491, 0.3037, 0.3207], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,388][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Megan] are: tensor([0.0963, 0.0848, 0.0656, 0.0573, 0.0446, 0.0472, 0.0987, 0.0474, 0.0649,
        0.0974, 0.1202, 0.1085, 0.0670], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,389][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Megan] are: tensor([0.0053, 0.0034, 0.0009, 0.0131, 0.0025, 0.0730, 0.0457, 0.0256, 0.0039,
        0.0729, 0.7214, 0.0286, 0.0036], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,390][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Megan] are: tensor([0.0687, 0.0794, 0.0774, 0.0769, 0.0781, 0.0816, 0.0821, 0.0758, 0.0698,
        0.0829, 0.0836, 0.0684, 0.0753], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,392][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Megan] are: tensor([0.0283, 0.0798, 0.1630, 0.0410, 0.1519, 0.1090, 0.0532, 0.0198, 0.0746,
        0.0308, 0.0376, 0.0643, 0.1467], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,393][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Megan] are: tensor([0.0098, 0.0676, 0.0597, 0.0878, 0.0744, 0.1531, 0.0916, 0.0781, 0.0506,
        0.0866, 0.0614, 0.1225, 0.0569], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,394][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Megan] are: tensor([3.5633e-03, 1.0120e-05, 2.9989e-04, 1.0875e-05, 3.1781e-02, 1.7453e-05,
        6.6867e-05, 2.0770e-03, 3.9619e-03, 1.2263e-02, 2.1662e-02, 2.3320e-01,
        6.9108e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,395][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Megan] are: tensor([2.4810e-02, 2.2703e-05, 2.9165e-04, 5.1349e-05, 4.9187e-02, 1.7580e-05,
        1.5209e-04, 1.3166e-03, 1.5740e-03, 1.3958e-02, 2.4079e-02, 1.5747e-01,
        7.2707e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,396][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Megan] are: tensor([6.3746e-02, 1.2602e-03, 2.9487e-03, 4.6849e-04, 6.3703e-02, 2.4881e-04,
        6.1242e-04, 2.1055e-03, 2.5767e-03, 3.5615e-02, 1.8408e-02, 1.2534e-01,
        6.8296e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,397][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Megan] are: tensor([0.3082, 0.0039, 0.0135, 0.0030, 0.0616, 0.0015, 0.0035, 0.0044, 0.0091,
        0.0460, 0.0458, 0.2083, 0.2911], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,399][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Megan] are: tensor([0.0843, 0.0009, 0.0012, 0.0006, 0.0351, 0.0005, 0.0019, 0.0096, 0.0140,
        0.0661, 0.0577, 0.3912, 0.3368], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,400][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0057, 0.0237, 0.0033, 0.0367, 0.0145, 0.0070, 0.0508, 0.0039, 0.0357,
        0.0682, 0.0303, 0.0122, 0.0100, 0.6980], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,401][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([1.3470e-01, 3.7799e-03, 2.2145e-03, 5.9203e-04, 6.8405e-02, 3.4284e-04,
        8.1712e-04, 4.2909e-03, 2.7906e-03, 3.4912e-02, 2.2464e-02, 1.8240e-01,
        5.2403e-01, 1.8259e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,403][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0569, 0.0719, 0.0627, 0.0585, 0.0730, 0.0338, 0.0972, 0.0378, 0.0560,
        0.0976, 0.1377, 0.0708, 0.1091, 0.0371], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,404][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0077, 0.0036, 0.0023, 0.0144, 0.0069, 0.0310, 0.0324, 0.0227, 0.0083,
        0.0909, 0.6958, 0.0404, 0.0116, 0.0320], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,406][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0631, 0.0741, 0.0721, 0.0718, 0.0730, 0.0762, 0.0766, 0.0707, 0.0646,
        0.0773, 0.0782, 0.0635, 0.0704, 0.0683], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,407][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0238, 0.0311, 0.1014, 0.0293, 0.2043, 0.0624, 0.0317, 0.0209, 0.0655,
        0.0136, 0.0291, 0.0557, 0.1708, 0.1604], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,409][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0030, 0.0515, 0.0681, 0.0819, 0.0831, 0.1533, 0.0833, 0.0743, 0.0499,
        0.0772, 0.0594, 0.1023, 0.0641, 0.0485], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,410][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([2.9520e-05, 5.7053e-07, 5.7485e-05, 8.2763e-07, 4.6117e-02, 1.4079e-06,
        6.1203e-06, 2.2551e-04, 5.2014e-04, 8.5399e-04, 1.4632e-03, 9.7175e-03,
        9.3747e-01, 3.5349e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,411][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([6.3647e-03, 1.9972e-05, 3.7826e-04, 2.4469e-05, 9.0873e-02, 1.0658e-05,
        5.8808e-05, 8.4452e-04, 4.5416e-04, 6.5877e-03, 7.7751e-03, 4.2024e-02,
        8.4329e-01, 1.2923e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,411][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([6.1228e-02, 1.5631e-03, 2.5180e-03, 4.9368e-04, 8.4333e-02, 2.1570e-04,
        4.2319e-04, 1.8521e-03, 1.2250e-03, 3.6145e-02, 1.9203e-02, 1.3490e-01,
        6.4717e-01, 8.7337e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,411][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.1791, 0.0036, 0.0118, 0.0029, 0.0592, 0.0028, 0.0053, 0.0072, 0.0104,
        0.0558, 0.0496, 0.2000, 0.3056, 0.1068], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,412][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([5.7623e-02, 1.2515e-03, 6.1568e-04, 6.7298e-04, 2.6619e-02, 5.2052e-04,
        1.8031e-03, 1.6912e-02, 1.7952e-02, 6.2695e-02, 6.0760e-02, 5.4620e-01,
        1.5595e-01, 5.0425e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,412][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0288, 0.0729, 0.0140, 0.0993, 0.0092, 0.0134, 0.0488, 0.0263, 0.0577,
        0.1967, 0.0749, 0.0335, 0.0058, 0.0590, 0.2595], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,413][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.3796e-01, 2.7188e-03, 2.3375e-03, 6.1937e-04, 8.5598e-02, 2.8400e-04,
        1.1942e-03, 2.6116e-03, 3.0874e-03, 3.1735e-02, 2.3412e-02, 1.1467e-01,
        4.9154e-01, 5.6441e-02, 4.5793e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,413][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0614, 0.0628, 0.0585, 0.0505, 0.0715, 0.0359, 0.0886, 0.0287, 0.0521,
        0.0919, 0.1230, 0.0748, 0.1026, 0.0486, 0.0492], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,413][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0356, 0.0021, 0.0009, 0.0039, 0.0034, 0.0145, 0.0117, 0.0207, 0.0115,
        0.0575, 0.3199, 0.0387, 0.0066, 0.0424, 0.4305], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,414][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0595, 0.0688, 0.0671, 0.0667, 0.0678, 0.0704, 0.0710, 0.0658, 0.0607,
        0.0715, 0.0722, 0.0599, 0.0653, 0.0637, 0.0695], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,415][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0499, 0.0419, 0.0717, 0.0340, 0.2246, 0.0488, 0.0453, 0.0254, 0.0563,
        0.0160, 0.0210, 0.0308, 0.1730, 0.1538, 0.0077], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,417][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0034, 0.0457, 0.0678, 0.0775, 0.0830, 0.1502, 0.0692, 0.0752, 0.0528,
        0.0667, 0.0467, 0.1003, 0.0602, 0.0465, 0.0548], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,418][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([2.9738e-05, 4.5145e-07, 3.8122e-05, 6.7810e-07, 2.2199e-02, 1.7396e-06,
        6.2951e-06, 6.6176e-04, 9.6063e-04, 1.1433e-03, 2.0647e-03, 1.3025e-02,
        8.7330e-01, 3.5397e-02, 5.1169e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,419][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([2.0021e-03, 7.5419e-06, 1.0396e-04, 1.4847e-05, 4.2144e-02, 1.1445e-05,
        3.7541e-05, 6.1727e-04, 4.5125e-04, 5.2325e-03, 7.7890e-03, 4.0786e-02,
        8.1777e-01, 2.3344e-02, 5.9688e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,420][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.3790e-02, 7.5039e-04, 2.8581e-03, 2.7482e-04, 6.4560e-02, 3.3804e-04,
        5.7831e-04, 2.2419e-03, 6.7659e-03, 3.3158e-02, 1.4539e-02, 7.8551e-02,
        7.0723e-01, 4.2095e-02, 2.2272e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,421][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1703, 0.0029, 0.0056, 0.0016, 0.0465, 0.0016, 0.0035, 0.0046, 0.0057,
        0.0437, 0.0316, 0.1499, 0.2974, 0.1012, 0.1340], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,422][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0250, 0.0010, 0.0004, 0.0004, 0.0173, 0.0003, 0.0012, 0.0230, 0.0259,
        0.0529, 0.0451, 0.2773, 0.1791, 0.1371, 0.2141], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,423][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:24,426][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 9361],
        [11762],
        [16052],
        [17861],
        [21215],
        [11927],
        [11440],
        [11977],
        [13116],
        [11182],
        [16507],
        [11669],
        [16889],
        [11803],
        [10141]], device='cuda:0')
[2024-07-24 10:29:24,427][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 9524],
        [14121],
        [33274],
        [25323],
        [25136],
        [17788],
        [13411],
        [13113],
        [14105],
        [12163],
        [21473],
        [12333],
        [18688],
        [21592],
        [19744]], device='cuda:0')
[2024-07-24 10:29:24,428][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[26536],
        [24511],
        [23508],
        [25401],
        [19875],
        [25931],
        [26329],
        [28206],
        [26903],
        [23116],
        [24056],
        [22854],
        [18853],
        [22897],
        [24207]], device='cuda:0')
[2024-07-24 10:29:24,430][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[22909],
        [32497],
        [26281],
        [20455],
        [17707],
        [16452],
        [11657],
        [15051],
        [12830],
        [14827],
        [14862],
        [26714],
        [24755],
        [19586],
        [16810]], device='cuda:0')
[2024-07-24 10:29:24,431][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[17068],
        [13494],
        [12389],
        [10542],
        [ 9556],
        [ 9136],
        [ 8959],
        [ 8688],
        [ 8557],
        [ 8333],
        [ 8547],
        [ 8452],
        [ 8320],
        [ 8051],
        [ 8185]], device='cuda:0')
[2024-07-24 10:29:24,432][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[20560],
        [ 4969],
        [ 4955],
        [ 8024],
        [ 9735],
        [11476],
        [ 8204],
        [ 7909],
        [ 9688],
        [10097],
        [ 7578],
        [10442],
        [10281],
        [10494],
        [ 7512]], device='cuda:0')
[2024-07-24 10:29:24,434][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 7038],
        [ 8216],
        [ 9099],
        [10169],
        [10786],
        [10888],
        [11184],
        [12079],
        [12303],
        [12194],
        [12133],
        [12329],
        [12374],
        [12424],
        [12388]], device='cuda:0')
[2024-07-24 10:29:24,435][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[5474],
        [4707],
        [6634],
        [5301],
        [5566],
        [5813],
        [5868],
        [5668],
        [5931],
        [5862],
        [5589],
        [5437],
        [5396],
        [5822],
        [5154]], device='cuda:0')
[2024-07-24 10:29:24,437][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 8953],
        [ 7687],
        [10433],
        [20319],
        [14497],
        [16801],
        [16822],
        [17054],
        [18188],
        [17103],
        [16916],
        [17356],
        [13780],
        [13891],
        [13869]], device='cuda:0')
[2024-07-24 10:29:24,438][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[21798],
        [13133],
        [21517],
        [22861],
        [30926],
        [31027],
        [31023],
        [31041],
        [31028],
        [30450],
        [30595],
        [30348],
        [31781],
        [30583],
        [29836]], device='cuda:0')
[2024-07-24 10:29:24,439][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[13725],
        [13506],
        [16370],
        [16372],
        [17216],
        [16998],
        [17056],
        [16852],
        [16645],
        [15956],
        [15663],
        [14776],
        [14982],
        [15135],
        [14667]], device='cuda:0')
[2024-07-24 10:29:24,441][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[25470],
        [22271],
        [31498],
        [33174],
        [33425],
        [33368],
        [33614],
        [33454],
        [33746],
        [33370],
        [28625],
        [31095],
        [30463],
        [30518],
        [30521]], device='cuda:0')
[2024-07-24 10:29:24,442][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[31739],
        [30912],
        [30254],
        [29893],
        [29592],
        [28835],
        [28476],
        [28011],
        [27713],
        [27706],
        [27620],
        [28139],
        [27925],
        [27362],
        [27094]], device='cuda:0')
[2024-07-24 10:29:24,443][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[23198],
        [10437],
        [26570],
        [26548],
        [35200],
        [35226],
        [35280],
        [35028],
        [33476],
        [34614],
        [34163],
        [33828],
        [34142],
        [33508],
        [33743]], device='cuda:0')
[2024-07-24 10:29:24,444][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[22433],
        [16635],
        [ 8716],
        [16139],
        [ 9455],
        [ 7340],
        [14038],
        [ 8667],
        [12385],
        [12964],
        [23700],
        [18151],
        [14906],
        [ 2277],
        [ 9391]], device='cuda:0')
[2024-07-24 10:29:24,445][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[29406],
        [45207],
        [44542],
        [45773],
        [38609],
        [46268],
        [46625],
        [41874],
        [45510],
        [46300],
        [46084],
        [44909],
        [38709],
        [45828],
        [45785]], device='cuda:0')
[2024-07-24 10:29:24,446][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[17904],
        [14296],
        [15746],
        [21926],
        [30316],
        [30426],
        [30413],
        [30248],
        [30269],
        [30628],
        [30270],
        [28019],
        [25261],
        [25589],
        [26322]], device='cuda:0')
[2024-07-24 10:29:24,447][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[11845],
        [ 4453],
        [ 4857],
        [ 4922],
        [ 3828],
        [ 3344],
        [ 4320],
        [ 5354],
        [ 4911],
        [ 4800],
        [ 4524],
        [ 4488],
        [ 3993],
        [ 3687],
        [ 3232]], device='cuda:0')
[2024-07-24 10:29:24,448][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[19494],
        [22297],
        [21652],
        [20903],
        [21284],
        [25848],
        [26309],
        [25776],
        [26635],
        [26931],
        [28243],
        [28065],
        [28144],
        [28124],
        [28195]], device='cuda:0')
[2024-07-24 10:29:24,450][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[26682],
        [26663],
        [26775],
        [27445],
        [27093],
        [27222],
        [27370],
        [27488],
        [27470],
        [27719],
        [27954],
        [28038],
        [27893],
        [27944],
        [28181]], device='cuda:0')
[2024-07-24 10:29:24,451][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[20860],
        [24877],
        [39140],
        [34608],
        [35062],
        [31622],
        [32194],
        [29532],
        [30027],
        [30607],
        [29958],
        [27636],
        [31614],
        [31972],
        [31624]], device='cuda:0')
[2024-07-24 10:29:24,453][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[10087],
        [ 4705],
        [ 4363],
        [ 4500],
        [ 4475],
        [ 4604],
        [ 4563],
        [ 4699],
        [ 4706],
        [ 4780],
        [ 4749],
        [ 4751],
        [ 4700],
        [ 4730],
        [ 4746]], device='cuda:0')
[2024-07-24 10:29:24,454][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[11715],
        [ 5284],
        [ 1862],
        [ 1329],
        [ 3531],
        [ 3531],
        [ 3526],
        [ 3466],
        [ 2816],
        [ 3073],
        [ 3263],
        [ 2555],
        [ 3550],
        [ 3322],
        [ 3065]], device='cuda:0')
[2024-07-24 10:29:24,455][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[30584],
        [24153],
        [14636],
        [14742],
        [18510],
        [19269],
        [19263],
        [19225],
        [18965],
        [18843],
        [18768],
        [17064],
        [14663],
        [15539],
        [14950]], device='cuda:0')
[2024-07-24 10:29:24,456][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 4985],
        [ 4191],
        [ 5505],
        [ 7120],
        [ 8998],
        [ 8620],
        [ 8932],
        [ 9476],
        [ 9121],
        [ 9103],
        [ 8081],
        [10892],
        [12493],
        [12597],
        [12412]], device='cuda:0')
[2024-07-24 10:29:24,458][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[36706],
        [36180],
        [37695],
        [39246],
        [36506],
        [37796],
        [38084],
        [36229],
        [37411],
        [35081],
        [33837],
        [27227],
        [28467],
        [30481],
        [29913]], device='cuda:0')
[2024-07-24 10:29:24,459][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[1744],
        [3203],
        [2666],
        [4406],
        [4740],
        [7122],
        [7182],
        [7648],
        [9236],
        [5536],
        [4884],
        [4942],
        [4360],
        [4192],
        [4371]], device='cuda:0')
[2024-07-24 10:29:24,461][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[27168],
        [30586],
        [31456],
        [28037],
        [24955],
        [22351],
        [21981],
        [22013],
        [22382],
        [23130],
        [24193],
        [25879],
        [27018],
        [25940],
        [25532]], device='cuda:0')
[2024-07-24 10:29:24,462][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[30975],
        [33988],
        [35525],
        [35838],
        [37609],
        [31982],
        [28915],
        [36964],
        [28908],
        [28769],
        [24429],
        [26323],
        [32983],
        [37071],
        [32905]], device='cuda:0')
[2024-07-24 10:29:24,463][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[12449],
        [12449],
        [12449],
        [12449],
        [12449],
        [12449],
        [12449],
        [12449],
        [12449],
        [12449],
        [12449],
        [12449],
        [12449],
        [12449],
        [12449]], device='cuda:0')
[2024-07-24 10:29:24,484][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:24,485][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,486][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,487][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,488][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,489][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,491][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,492][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,493][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,494][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,495][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,496][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,497][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,499][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.6543, 0.3457], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,500][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1448, 0.8552], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,501][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4354, 0.5646], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,502][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([9.9925e-01, 7.4557e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,504][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4538, 0.5462], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,505][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.3945, 0.6055], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,507][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.5071, 0.4929], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,508][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1737, 0.8263], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,508][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.6658, 0.3342], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,509][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3223, 0.6777], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,509][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.6436, 0.3564], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,509][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0839, 0.9161], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,510][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Jennifer] are: tensor([0.2144, 0.0391, 0.7464], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,510][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Jennifer] are: tensor([0.0672, 0.4134, 0.5194], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,510][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Jennifer] are: tensor([0.2437, 0.3274, 0.4290], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,510][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Jennifer] are: tensor([0.5452, 0.0049, 0.4499], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,511][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Jennifer] are: tensor([0.2210, 0.2927, 0.4863], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,511][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Jennifer] are: tensor([0.1449, 0.3701, 0.4850], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,511][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Jennifer] are: tensor([0.3404, 0.3198, 0.3398], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,512][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Jennifer] are: tensor([0.0743, 0.5413, 0.3844], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,514][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Jennifer] are: tensor([0.5658, 0.2304, 0.2038], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,515][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Jennifer] are: tensor([0.1930, 0.4010, 0.4060], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,516][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Jennifer] are: tensor([0.2416, 0.2159, 0.5425], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,517][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Jennifer] are: tensor([2.4329e-06, 4.0107e-04, 9.9960e-01], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,518][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1168, 0.0208, 0.6720, 0.1903], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,520][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0582, 0.2567, 0.3707, 0.3144], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,521][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1793, 0.2244, 0.3041, 0.2923], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,522][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([2.4944e-01, 4.5196e-04, 7.4644e-01, 3.6708e-03], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,523][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1172, 0.1917, 0.3579, 0.3332], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,525][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0898, 0.2437, 0.2365, 0.4300], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,526][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2538, 0.2408, 0.2580, 0.2474], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,527][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1442, 0.3777, 0.2352, 0.2429], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,529][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.5164, 0.1849, 0.2319, 0.0668], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,530][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1407, 0.2887, 0.2845, 0.2860], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,532][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4354, 0.1470, 0.2471, 0.1705], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,532][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([5.3480e-16, 3.0849e-12, 1.0000e+00, 1.1152e-08], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,534][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Megan] are: tensor([0.1078, 0.0099, 0.4887, 0.1585, 0.2352], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,535][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Megan] are: tensor([0.0402, 0.1880, 0.2634, 0.2606, 0.2478], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,537][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Megan] are: tensor([0.1547, 0.1696, 0.2379, 0.2288, 0.2089], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,538][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Megan] are: tensor([0.2226, 0.0125, 0.3713, 0.2611, 0.1325], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,540][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Megan] are: tensor([0.1007, 0.1338, 0.2734, 0.2533, 0.2387], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,540][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Megan] are: tensor([0.0705, 0.1845, 0.1887, 0.4219, 0.1344], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,540][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Megan] are: tensor([0.2064, 0.1898, 0.2000, 0.1919, 0.2119], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,541][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Megan] are: tensor([0.0375, 0.1907, 0.1480, 0.1650, 0.4588], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,541][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Megan] are: tensor([0.5041, 0.1386, 0.1490, 0.0572, 0.1510], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,541][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Megan] are: tensor([0.1090, 0.2207, 0.2249, 0.2185, 0.2270], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,542][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Megan] are: tensor([0.2741, 0.1450, 0.2728, 0.0570, 0.2510], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,542][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Megan] are: tensor([1.3522e-07, 3.3718e-06, 1.7423e-02, 1.8874e-05, 9.8255e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,542][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0477, 0.0181, 0.4704, 0.1668, 0.1668, 0.1302], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,542][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0433, 0.1523, 0.2070, 0.1938, 0.2018, 0.2018], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,543][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.1149, 0.1429, 0.1937, 0.1860, 0.1719, 0.1906], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,543][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ had] are: tensor([1.0749e-02, 9.6948e-04, 7.6370e-01, 1.2328e-02, 2.1203e-01, 2.1785e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,545][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0799, 0.1041, 0.2217, 0.2000, 0.1890, 0.2053], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,546][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0732, 0.1020, 0.1652, 0.2684, 0.3194, 0.0718], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,547][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.1662, 0.1587, 0.1707, 0.1639, 0.1822, 0.1583], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,549][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0650, 0.1529, 0.0904, 0.1056, 0.2501, 0.3359], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,550][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.3095, 0.1347, 0.1499, 0.0779, 0.1919, 0.1362], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,551][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0857, 0.1720, 0.1745, 0.1763, 0.1841, 0.2074], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,552][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.1907, 0.1907, 0.1734, 0.0824, 0.1379, 0.2249], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,553][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ had] are: tensor([2.9006e-14, 1.5321e-11, 4.8739e-01, 8.8659e-07, 5.1260e-01, 2.8200e-07],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,554][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([7.5063e-03, 2.2509e-03, 6.9861e-01, 1.2555e-01, 6.4179e-02, 1.0165e-01,
        2.6362e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,556][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0266, 0.1287, 0.1697, 0.1606, 0.1677, 0.1872, 0.1595],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,557][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1071, 0.1147, 0.1681, 0.1568, 0.1436, 0.1642, 0.1455],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,558][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([7.1808e-02, 2.0271e-03, 6.8870e-01, 8.6175e-02, 1.4687e-01, 3.8316e-03,
        5.8418e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,559][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0588, 0.0795, 0.1940, 0.1774, 0.1644, 0.1851, 0.1410],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,560][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0192, 0.1088, 0.1891, 0.1760, 0.4042, 0.0432, 0.0594],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,562][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1411, 0.1373, 0.1481, 0.1427, 0.1566, 0.1386, 0.1355],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,563][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0486, 0.1377, 0.0669, 0.0802, 0.1891, 0.2795, 0.1980],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,565][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.3448, 0.1212, 0.0955, 0.0508, 0.1347, 0.1203, 0.1328],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,566][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0716, 0.1487, 0.1508, 0.1502, 0.1571, 0.1803, 0.1413],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,567][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2713, 0.0838, 0.2903, 0.0392, 0.1573, 0.1010, 0.0571],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,568][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([3.0963e-11, 1.6533e-09, 9.7360e-01, 1.3673e-04, 2.6128e-02, 1.3073e-04,
        1.5738e-08], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,569][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ long] are: tensor([7.6178e-03, 2.8840e-03, 6.5155e-01, 1.4009e-01, 6.9933e-02, 1.2561e-01,
        5.5645e-04, 1.7567e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,571][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0269, 0.1081, 0.1376, 0.1340, 0.1336, 0.1432, 0.1544, 0.1623],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,572][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0917, 0.1009, 0.1444, 0.1383, 0.1260, 0.1418, 0.1272, 0.1298],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,572][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.2131, 0.0067, 0.1754, 0.1479, 0.1740, 0.0115, 0.0398, 0.2316],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,572][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0480, 0.0706, 0.1752, 0.1535, 0.1475, 0.1658, 0.1203, 0.1191],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,573][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0397, 0.0906, 0.1615, 0.2851, 0.1728, 0.0465, 0.1637, 0.0401],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,573][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.1240, 0.1208, 0.1304, 0.1259, 0.1381, 0.1218, 0.1197, 0.1193],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,573][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0253, 0.0966, 0.0618, 0.0678, 0.1919, 0.2605, 0.1622, 0.1339],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,574][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.1966, 0.0780, 0.0964, 0.0433, 0.1114, 0.1019, 0.1204, 0.2519],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,574][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0608, 0.1321, 0.1318, 0.1335, 0.1349, 0.1590, 0.1271, 0.1207],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,574][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.2416, 0.1081, 0.0987, 0.0438, 0.0737, 0.0511, 0.0627, 0.3204],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,575][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ long] are: tensor([2.0410e-09, 5.6390e-08, 9.0559e-01, 6.4832e-04, 9.3506e-02, 2.5384e-04,
        5.2738e-07, 2.3093e-06], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,576][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0246, 0.0129, 0.4687, 0.1384, 0.2341, 0.0947, 0.0043, 0.0108, 0.0116],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,577][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0222, 0.0825, 0.1141, 0.1091, 0.1066, 0.1402, 0.1396, 0.1676, 0.1181],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,578][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0791, 0.0860, 0.1347, 0.1274, 0.1125, 0.1320, 0.1137, 0.1179, 0.0966],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,579][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0603, 0.0028, 0.2939, 0.0233, 0.2682, 0.0070, 0.0210, 0.2811, 0.0423],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,581][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0149, 0.0205, 0.2382, 0.1854, 0.1621, 0.1982, 0.0952, 0.0829, 0.0026],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,582][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0075, 0.1454, 0.0862, 0.3011, 0.1970, 0.0264, 0.0527, 0.1818, 0.0018],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,583][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.1142, 0.1089, 0.1159, 0.1118, 0.1226, 0.1086, 0.1073, 0.1071, 0.1035],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,585][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0263, 0.0808, 0.0558, 0.0593, 0.1669, 0.2233, 0.1390, 0.1220, 0.1266],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,586][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.1450, 0.0762, 0.0946, 0.0444, 0.0910, 0.0952, 0.1103, 0.2212, 0.1221],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,588][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0509, 0.1186, 0.1205, 0.1216, 0.1250, 0.1454, 0.1152, 0.1130, 0.0900],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,589][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0803, 0.0276, 0.0634, 0.0445, 0.1193, 0.0320, 0.2498, 0.2698, 0.1135],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,590][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([1.5500e-09, 2.1612e-08, 9.7852e-01, 1.0593e-03, 1.9759e-02, 6.5721e-04,
        2.3223e-07, 1.5230e-06, 9.1925e-08], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,592][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0579, 0.0245, 0.4184, 0.1280, 0.2284, 0.0857, 0.0047, 0.0088, 0.0186,
        0.0250], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,593][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0170, 0.0695, 0.1038, 0.0919, 0.1043, 0.1289, 0.1223, 0.1597, 0.1347,
        0.0678], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,594][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0825, 0.0756, 0.1277, 0.1177, 0.1025, 0.1266, 0.1030, 0.1096, 0.0893,
        0.0656], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,595][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([4.9281e-02, 2.7347e-05, 1.3394e-01, 1.9374e-03, 1.3703e-01, 1.0117e-03,
        3.2947e-03, 1.1090e-01, 5.6244e-01, 1.3505e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,597][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0185, 0.0380, 0.2389, 0.1855, 0.1637, 0.1861, 0.0858, 0.0771, 0.0034,
        0.0031], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,598][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0155, 0.0311, 0.0823, 0.2886, 0.2977, 0.0197, 0.1319, 0.1129, 0.0030,
        0.0173], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,600][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1015, 0.0975, 0.1046, 0.1008, 0.1106, 0.0985, 0.0966, 0.0965, 0.0933,
        0.1001], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,601][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0648, 0.0920, 0.0427, 0.0526, 0.1046, 0.1570, 0.1205, 0.0886, 0.0924,
        0.1847], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,603][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1897, 0.0793, 0.0747, 0.0408, 0.0845, 0.0767, 0.0912, 0.1387, 0.1024,
        0.1218], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,603][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0511, 0.1090, 0.1087, 0.1083, 0.1119, 0.1329, 0.1021, 0.1030, 0.0861,
        0.0869], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,603][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2771, 0.0741, 0.0915, 0.0289, 0.0579, 0.0436, 0.0351, 0.1653, 0.1032,
        0.1233], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,604][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([1.4479e-09, 2.2469e-08, 9.8511e-01, 5.3709e-04, 1.4142e-02, 2.0520e-04,
        1.8033e-07, 7.6668e-07, 9.9984e-08, 7.8861e-08], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,604][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0713, 0.0161, 0.4413, 0.1180, 0.1184, 0.1248, 0.0030, 0.0076, 0.0145,
        0.0216, 0.0633], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,605][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0222, 0.0734, 0.1040, 0.0864, 0.0971, 0.1108, 0.1052, 0.1241, 0.1048,
        0.0748, 0.0972], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,605][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0688, 0.0784, 0.1056, 0.1008, 0.0935, 0.1034, 0.0947, 0.0960, 0.0861,
        0.0756, 0.0972], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,605][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([5.0314e-02, 8.2558e-05, 1.3845e-01, 6.3684e-04, 1.2948e-01, 1.5535e-03,
        1.5405e-03, 1.8014e-01, 4.9532e-01, 4.7872e-04, 1.9962e-03],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,606][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0448, 0.0617, 0.1361, 0.1254, 0.1166, 0.1282, 0.0981, 0.1009, 0.0389,
        0.0297, 0.1197], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,606][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0274, 0.0894, 0.0811, 0.1342, 0.1524, 0.0520, 0.1565, 0.0867, 0.0184,
        0.0820, 0.1198], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,607][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0917, 0.0883, 0.0952, 0.0916, 0.1009, 0.0891, 0.0873, 0.0872, 0.0841,
        0.0907, 0.0940], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,608][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0365, 0.0767, 0.0406, 0.0497, 0.1077, 0.1510, 0.1142, 0.0778, 0.0812,
        0.1585, 0.1061], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,609][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2287, 0.0658, 0.0491, 0.0196, 0.0674, 0.0477, 0.0615, 0.1728, 0.1038,
        0.1250, 0.0587], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,611][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0493, 0.0982, 0.0961, 0.0967, 0.0985, 0.1157, 0.0927, 0.0911, 0.0776,
        0.0835, 0.1005], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,612][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1478, 0.0689, 0.0791, 0.0532, 0.0640, 0.0738, 0.0621, 0.2690, 0.0637,
        0.0602, 0.0583], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,613][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([5.6015e-14, 2.6585e-10, 1.3035e-03, 5.4325e-11, 2.3047e-01, 2.4590e-10,
        1.3560e-09, 2.5170e-08, 2.7516e-08, 3.7702e-08, 7.6823e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,614][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0465, 0.0285, 0.2587, 0.1103, 0.2707, 0.0671, 0.0111, 0.0169, 0.0291,
        0.0335, 0.0662, 0.0613], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,616][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0111, 0.0574, 0.0800, 0.0808, 0.0670, 0.1173, 0.1044, 0.1433, 0.1052,
        0.0608, 0.0963, 0.0764], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,617][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0649, 0.0517, 0.1343, 0.1192, 0.0937, 0.1314, 0.0909, 0.1022, 0.0657,
        0.0371, 0.1031, 0.0059], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,619][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0399, 0.0101, 0.0401, 0.0244, 0.0397, 0.0132, 0.0395, 0.4393, 0.0902,
        0.0309, 0.0440, 0.1889], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,620][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0930, 0.1365, 0.0966, 0.0789, 0.1033, 0.0873, 0.0735, 0.0687, 0.0316,
        0.0800, 0.0668, 0.0837], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,621][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0084, 0.1091, 0.0914, 0.2103, 0.1424, 0.0492, 0.1112, 0.0641, 0.0064,
        0.0443, 0.1577, 0.0055], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,623][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0820, 0.0809, 0.0872, 0.0844, 0.0920, 0.0822, 0.0803, 0.0804, 0.0778,
        0.0831, 0.0863, 0.0834], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,624][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0530, 0.0844, 0.0500, 0.0496, 0.1021, 0.1330, 0.1035, 0.0843, 0.0870,
        0.1255, 0.0729, 0.0546], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,626][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.1227, 0.0748, 0.0724, 0.0521, 0.0761, 0.0872, 0.0925, 0.0948, 0.0645,
        0.0865, 0.0598, 0.1164], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,627][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0299, 0.0938, 0.0898, 0.0992, 0.0975, 0.1206, 0.0951, 0.0836, 0.0675,
        0.0754, 0.1027, 0.0449], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,629][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0551, 0.1296, 0.0768, 0.0780, 0.0851, 0.0606, 0.1124, 0.0971, 0.0695,
        0.0970, 0.0690, 0.0700], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,630][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([5.9005e-10, 3.9400e-09, 3.9590e-01, 6.7629e-04, 1.5258e-03, 2.5067e-04,
        3.7547e-08, 1.8362e-07, 1.2465e-08, 9.3457e-09, 6.0165e-01, 3.1427e-09],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,631][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Megan] are: tensor([0.0475, 0.0094, 0.4172, 0.1314, 0.1361, 0.0902, 0.0035, 0.0075, 0.0153,
        0.0177, 0.0603, 0.0526, 0.0113], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,633][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Megan] are: tensor([0.0133, 0.0574, 0.0771, 0.0785, 0.0714, 0.0937, 0.0907, 0.1170, 0.0965,
        0.0575, 0.0928, 0.0856, 0.0684], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,634][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Megan] are: tensor([0.0717, 0.0651, 0.0983, 0.0929, 0.0843, 0.0956, 0.0834, 0.0869, 0.0739,
        0.0604, 0.0884, 0.0279, 0.0712], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,635][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Megan] are: tensor([0.0247, 0.0013, 0.0455, 0.0274, 0.0152, 0.0019, 0.0149, 0.2027, 0.0472,
        0.0051, 0.0699, 0.5246, 0.0196], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,635][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Megan] are: tensor([0.0273, 0.0435, 0.1568, 0.1312, 0.1234, 0.1305, 0.0860, 0.0903, 0.0156,
        0.0108, 0.1093, 0.0217, 0.0537], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,636][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Megan] are: tensor([0.0250, 0.0726, 0.0865, 0.2176, 0.0524, 0.0566, 0.0706, 0.0784, 0.0069,
        0.0527, 0.2196, 0.0245, 0.0364], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,636][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Megan] are: tensor([0.0798, 0.0746, 0.0790, 0.0760, 0.0837, 0.0741, 0.0734, 0.0734, 0.0710,
        0.0768, 0.0784, 0.0783, 0.0815], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,636][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Megan] are: tensor([0.0104, 0.0513, 0.0403, 0.0400, 0.1316, 0.1636, 0.1025, 0.0806, 0.0862,
        0.1203, 0.0918, 0.0183, 0.0631], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,637][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Megan] are: tensor([0.1645, 0.0414, 0.0361, 0.0192, 0.0463, 0.0501, 0.0677, 0.1372, 0.0727,
        0.0983, 0.0480, 0.1475, 0.0710], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,637][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Megan] are: tensor([0.0406, 0.0851, 0.0876, 0.0846, 0.0883, 0.1031, 0.0806, 0.0795, 0.0670,
        0.0674, 0.0879, 0.0513, 0.0767], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,638][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Megan] are: tensor([0.0986, 0.0460, 0.0978, 0.0118, 0.1197, 0.0205, 0.0386, 0.0669, 0.0925,
        0.0297, 0.0137, 0.0760, 0.2880], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,638][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Megan] are: tensor([4.8909e-09, 7.7722e-08, 6.7243e-03, 1.7935e-05, 5.5222e-03, 1.6193e-05,
        3.8864e-07, 1.4379e-06, 4.4110e-07, 5.4640e-07, 9.8767e-01, 2.5178e-07,
        5.1094e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,639][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0412, 0.0163, 0.3258, 0.1145, 0.1498, 0.0988, 0.0064, 0.0124, 0.0180,
        0.0197, 0.0652, 0.0471, 0.0157, 0.0691], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,641][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0178, 0.0555, 0.0764, 0.0702, 0.0756, 0.0869, 0.0799, 0.1105, 0.0793,
        0.0553, 0.0793, 0.0690, 0.0724, 0.0718], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,642][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0577, 0.0651, 0.0842, 0.0813, 0.0755, 0.0823, 0.0770, 0.0767, 0.0697,
        0.0635, 0.0787, 0.0372, 0.0679, 0.0832], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,643][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ said] are: tensor([5.4615e-03, 1.0134e-04, 2.6518e-01, 2.7127e-03, 2.1304e-01, 2.1299e-04,
        9.7121e-04, 3.8354e-02, 8.1836e-02, 4.9128e-04, 9.5119e-03, 1.1071e-01,
        2.7124e-01, 1.7072e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,644][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0301, 0.0450, 0.1310, 0.1140, 0.1069, 0.1122, 0.0818, 0.0826, 0.0192,
        0.0141, 0.1008, 0.0255, 0.0528, 0.0837], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,646][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0181, 0.0742, 0.0728, 0.1558, 0.1169, 0.0347, 0.0913, 0.0542, 0.0167,
        0.0593, 0.1636, 0.0243, 0.0880, 0.0300], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,647][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0747, 0.0693, 0.0735, 0.0704, 0.0784, 0.0685, 0.0682, 0.0682, 0.0658,
        0.0715, 0.0727, 0.0731, 0.0763, 0.0693], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,649][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0200, 0.0557, 0.0375, 0.0402, 0.1088, 0.1434, 0.1018, 0.0759, 0.0750,
        0.1219, 0.0880, 0.0242, 0.0549, 0.0529], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,650][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.1358, 0.0412, 0.0352, 0.0171, 0.0491, 0.0370, 0.0469, 0.1360, 0.0848,
        0.0970, 0.0577, 0.1272, 0.0885, 0.0464], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,651][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0360, 0.0773, 0.0795, 0.0787, 0.0820, 0.0949, 0.0752, 0.0723, 0.0641,
        0.0634, 0.0811, 0.0476, 0.0705, 0.0774], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,653][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0442, 0.0483, 0.1647, 0.0239, 0.0591, 0.0620, 0.0278, 0.0849, 0.0598,
        0.0488, 0.0319, 0.0546, 0.0944, 0.1955], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,654][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ said] are: tensor([7.2756e-17, 4.6306e-14, 2.0208e-09, 4.7081e-16, 2.6051e-05, 9.2387e-16,
        4.1086e-13, 7.0616e-12, 8.1447e-12, 2.0538e-11, 2.8016e-05, 8.5046e-12,
        2.1657e-07, 9.9995e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,655][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0482, 0.0144, 0.3127, 0.0986, 0.0991, 0.1014, 0.0033, 0.0084, 0.0136,
        0.0197, 0.0615, 0.0583, 0.0099, 0.0720, 0.0787], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,657][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0141, 0.0524, 0.0774, 0.0638, 0.0686, 0.0754, 0.0753, 0.0897, 0.0786,
        0.0514, 0.0739, 0.0672, 0.0657, 0.0752, 0.0713], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,658][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0525, 0.0593, 0.0790, 0.0758, 0.0703, 0.0775, 0.0711, 0.0717, 0.0641,
        0.0569, 0.0731, 0.0320, 0.0622, 0.0780, 0.0766], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,659][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.2523e-02, 1.1115e-04, 2.8841e-02, 2.1428e-03, 1.8911e-02, 4.0739e-04,
        6.8444e-04, 6.4009e-02, 5.2345e-01, 9.9776e-04, 9.5683e-03, 3.0228e-01,
        3.2895e-02, 9.1046e-04, 2.2596e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,660][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0306, 0.0410, 0.1097, 0.1005, 0.0912, 0.1021, 0.0766, 0.0728, 0.0194,
        0.0159, 0.0942, 0.0265, 0.0476, 0.0780, 0.0939], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,662][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0234, 0.0480, 0.0817, 0.1289, 0.1461, 0.0306, 0.0875, 0.0583, 0.0221,
        0.0387, 0.1278, 0.0229, 0.1216, 0.0320, 0.0303], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,663][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0683, 0.0645, 0.0687, 0.0661, 0.0727, 0.0643, 0.0636, 0.0634, 0.0611,
        0.0664, 0.0681, 0.0676, 0.0708, 0.0653, 0.0689], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,665][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0293, 0.0590, 0.0305, 0.0361, 0.0828, 0.1305, 0.0974, 0.0636, 0.0636,
        0.1196, 0.0827, 0.0288, 0.0464, 0.0510, 0.0786], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,666][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1492, 0.0397, 0.0319, 0.0141, 0.0501, 0.0424, 0.0433, 0.1291, 0.0774,
        0.0825, 0.0372, 0.1433, 0.0729, 0.0232, 0.0638], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,667][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0343, 0.0699, 0.0721, 0.0717, 0.0740, 0.0837, 0.0702, 0.0682, 0.0594,
        0.0605, 0.0749, 0.0436, 0.0652, 0.0725, 0.0798], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,667][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1036, 0.0411, 0.0706, 0.0388, 0.0445, 0.0475, 0.0478, 0.1174, 0.0709,
        0.0451, 0.0442, 0.1139, 0.0561, 0.0993, 0.0592], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,667][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([7.4147e-24, 3.3152e-19, 4.9976e-16, 2.9840e-22, 5.5277e-11, 6.1319e-20,
        3.0423e-18, 7.5849e-17, 1.4532e-16, 1.8121e-16, 2.3922e-10, 4.9131e-17,
        2.1962e-12, 8.2836e-01, 1.7164e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,693][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:24,695][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,696][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,697][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,697][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,698][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,698][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,698][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,699][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,699][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,699][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,700][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,700][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,700][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3719, 0.6281], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,701][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.3563, 0.6437], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,702][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.3666, 0.6334], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,703][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.4645, 0.5355], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,705][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.7440, 0.2560], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,706][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4025, 0.5975], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,716][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.5230, 0.4770], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,717][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2072, 0.7928], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,719][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.6224, 0.3776], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,720][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.5016, 0.4984], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,721][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.5811, 0.4189], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,723][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0839, 0.9161], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,724][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Jennifer] are: tensor([0.5582, 0.0571, 0.3846], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,726][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Jennifer] are: tensor([0.0760, 0.0328, 0.8912], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,727][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Jennifer] are: tensor([0.2816, 0.2999, 0.4186], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,728][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Jennifer] are: tensor([0.2858, 0.3316, 0.3827], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,729][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Jennifer] are: tensor([9.1363e-01, 8.6292e-02, 8.1332e-05], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,729][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Jennifer] are: tensor([0.0159, 0.0086, 0.9755], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,729][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Jennifer] are: tensor([0.4584, 0.3238, 0.2178], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,730][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Jennifer] are: tensor([0.0027, 0.0050, 0.9923], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,730][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Jennifer] are: tensor([0.5427, 0.2865, 0.1708], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,730][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Jennifer] are: tensor([0.5141, 0.1508, 0.3351], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,731][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Jennifer] are: tensor([7.9463e-01, 2.0498e-01, 3.8910e-04], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,731][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Jennifer] are: tensor([2.4329e-06, 4.0107e-04, 9.9960e-01], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,731][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0021, 0.0017, 0.9924, 0.0039], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,731][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([9.2007e-04, 9.3778e-04, 9.7548e-01, 2.2666e-02], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,732][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0428, 0.0966, 0.5944, 0.2662], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,733][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2049, 0.2368, 0.2728, 0.2855], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,734][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([8.7675e-01, 1.2084e-01, 3.2369e-04, 2.0878e-03], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,735][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0011, 0.0011, 0.9902, 0.0077], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,736][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.3095, 0.2054, 0.1994, 0.2857], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,738][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0009, 0.0026, 0.8519, 0.1446], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,739][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.4555, 0.1989, 0.1623, 0.1833], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,740][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.2088, 0.0951, 0.6037, 0.0924], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,742][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.7605, 0.2318, 0.0010, 0.0067], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,743][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([5.3480e-16, 3.0849e-12, 1.0000e+00, 1.1152e-08], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,744][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Megan] are: tensor([0.0560, 0.0122, 0.0717, 0.0048, 0.8554], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,745][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Megan] are: tensor([0.0232, 0.0116, 0.3510, 0.0442, 0.5701], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,747][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Megan] are: tensor([0.1668, 0.1723, 0.2227, 0.1571, 0.2810], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,748][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Megan] are: tensor([0.1650, 0.1862, 0.2119, 0.2211, 0.2158], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,750][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Megan] are: tensor([0.7960, 0.1382, 0.0014, 0.0050, 0.0593], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,751][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Megan] are: tensor([0.0295, 0.0173, 0.2786, 0.0269, 0.6476], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,752][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Megan] are: tensor([0.2937, 0.1782, 0.1174, 0.2414, 0.1694], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,754][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Megan] are: tensor([0.0026, 0.0060, 0.6526, 0.1441, 0.1947], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,755][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Megan] are: tensor([0.4088, 0.1859, 0.1170, 0.2016, 0.0866], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,756][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Megan] are: tensor([0.2341, 0.0962, 0.1884, 0.0542, 0.4271], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,757][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Megan] are: tensor([0.6328, 0.2717, 0.0061, 0.0231, 0.0662], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,758][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Megan] are: tensor([1.3522e-07, 3.3718e-06, 1.7423e-02, 1.8874e-05, 9.8255e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,760][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0020, 0.0014, 0.3739, 0.0067, 0.6134, 0.0027], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,760][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([1.9128e-04, 2.9603e-04, 5.8344e-01, 4.8665e-02, 3.6550e-01, 1.9061e-03],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,761][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0211, 0.0512, 0.3199, 0.1401, 0.3081, 0.1595], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,761][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1343, 0.1548, 0.1773, 0.1846, 0.1807, 0.1683], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,761][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([8.2971e-01, 1.1950e-01, 4.2240e-04, 2.2773e-03, 4.5422e-02, 2.6643e-03],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,762][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([2.0911e-04, 2.8994e-04, 7.3225e-01, 1.3734e-02, 2.4074e-01, 1.2777e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,762][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.1266, 0.1197, 0.1312, 0.2024, 0.2246, 0.1955], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,762][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([5.6483e-04, 1.6701e-03, 6.0365e-01, 9.6779e-02, 1.1573e-01, 1.8161e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,763][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.4791, 0.1608, 0.0902, 0.1304, 0.0566, 0.0829], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,763][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0861, 0.0485, 0.1987, 0.0470, 0.5597, 0.0600], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,764][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.7060, 0.2150, 0.0013, 0.0055, 0.0244, 0.0478], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,764][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([2.9006e-14, 1.5321e-11, 4.8739e-01, 8.8659e-07, 5.1260e-01, 2.8200e-07],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:24,766][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0025, 0.0040, 0.5970, 0.0280, 0.3261, 0.0375, 0.0049],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,767][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0011, 0.0025, 0.5696, 0.1976, 0.1853, 0.0417, 0.0023],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,768][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0220, 0.0531, 0.2852, 0.1449, 0.2559, 0.1526, 0.0862],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,770][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1161, 0.1327, 0.1528, 0.1590, 0.1557, 0.1462, 0.1376],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,771][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.5704, 0.1665, 0.0074, 0.0184, 0.1062, 0.0156, 0.1155],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,772][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0054, 0.0076, 0.5674, 0.0857, 0.2162, 0.1061, 0.0115],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,774][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0963, 0.1009, 0.1109, 0.1705, 0.1683, 0.2004, 0.1527],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,775][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0009, 0.0035, 0.5720, 0.1619, 0.0895, 0.1640, 0.0082],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,777][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.2241, 0.1099, 0.0999, 0.1508, 0.0693, 0.1428, 0.2032],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,778][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0468, 0.0419, 0.3054, 0.0993, 0.2919, 0.1636, 0.0510],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,779][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.3373, 0.2039, 0.0291, 0.0450, 0.1046, 0.1082, 0.1719],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,780][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([3.0963e-11, 1.6533e-09, 9.7360e-01, 1.3673e-04, 2.6128e-02, 1.3073e-04,
        1.5738e-08], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:24,782][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0049, 0.0079, 0.4505, 0.0492, 0.3971, 0.0575, 0.0101, 0.0228],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,783][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0016, 0.0029, 0.5361, 0.1872, 0.2301, 0.0332, 0.0028, 0.0060],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,785][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0208, 0.0492, 0.2001, 0.1462, 0.1971, 0.1696, 0.1106, 0.1064],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,786][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.1026, 0.1164, 0.1338, 0.1400, 0.1364, 0.1278, 0.1206, 0.1223],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,787][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.5270, 0.1458, 0.0047, 0.0142, 0.0873, 0.0124, 0.0946, 0.1140],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,788][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0056, 0.0077, 0.5018, 0.0886, 0.2174, 0.1323, 0.0128, 0.0337],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,790][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0855, 0.0894, 0.0904, 0.1571, 0.1338, 0.1984, 0.1713, 0.0743],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,791][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0009, 0.0034, 0.5353, 0.1827, 0.0801, 0.1810, 0.0076, 0.0090],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,792][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.1980, 0.1038, 0.0930, 0.1579, 0.0537, 0.1117, 0.2052, 0.0767],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,792][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0508, 0.0437, 0.2492, 0.0868, 0.2833, 0.1421, 0.0565, 0.0876],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,792][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.2956, 0.1774, 0.0206, 0.0364, 0.0798, 0.0989, 0.1368, 0.1545],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,793][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([2.0410e-09, 5.6390e-08, 9.0559e-01, 6.4832e-04, 9.3506e-02, 2.5384e-04,
        5.2738e-07, 2.3093e-06], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:24,793][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0043, 0.0071, 0.5500, 0.0465, 0.2789, 0.0662, 0.0111, 0.0250, 0.0110],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,793][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0031, 0.0060, 0.4940, 0.2154, 0.1808, 0.0745, 0.0061, 0.0140, 0.0059],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,794][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0387, 0.0655, 0.1473, 0.1335, 0.1522, 0.1602, 0.1227, 0.1030, 0.0769],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,794][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0932, 0.1039, 0.1182, 0.1233, 0.1206, 0.1129, 0.1074, 0.1089, 0.1115],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,794][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.3700, 0.1305, 0.0101, 0.0222, 0.0878, 0.0174, 0.0926, 0.1098, 0.1598],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,796][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0065, 0.0099, 0.4408, 0.1476, 0.1669, 0.1614, 0.0171, 0.0356, 0.0142],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,797][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0662, 0.0751, 0.0850, 0.1582, 0.1240, 0.1891, 0.1579, 0.0905, 0.0539],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,798][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0010, 0.0039, 0.5366, 0.1915, 0.0777, 0.1660, 0.0086, 0.0098, 0.0049],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,800][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.1823, 0.0956, 0.0797, 0.1176, 0.0588, 0.0781, 0.1646, 0.0698, 0.1535],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,801][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0350, 0.0354, 0.2840, 0.1075, 0.2134, 0.1574, 0.0492, 0.0745, 0.0436],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,802][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.1791, 0.1319, 0.0416, 0.0567, 0.0979, 0.0894, 0.1233, 0.1358, 0.1443],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,803][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([1.5500e-09, 2.1612e-08, 9.7852e-01, 1.0593e-03, 1.9759e-02, 6.5721e-04,
        2.3223e-07, 1.5230e-06, 9.1925e-08], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:24,804][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0048, 0.0066, 0.6003, 0.0320, 0.2731, 0.0346, 0.0089, 0.0190, 0.0102,
        0.0104], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,806][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0040, 0.0074, 0.5120, 0.1773, 0.1958, 0.0662, 0.0074, 0.0158, 0.0075,
        0.0067], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,807][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0443, 0.0695, 0.1626, 0.1159, 0.1509, 0.1214, 0.0868, 0.0979, 0.0793,
        0.0713], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,808][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0826, 0.0931, 0.1066, 0.1114, 0.1087, 0.1019, 0.0964, 0.0983, 0.1009,
        0.1002], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,810][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3062, 0.1120, 0.0090, 0.0207, 0.0758, 0.0142, 0.0757, 0.0957, 0.1370,
        0.1538], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,811][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0108, 0.0149, 0.4053, 0.1458, 0.1723, 0.1475, 0.0223, 0.0428, 0.0202,
        0.0182], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,813][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0718, 0.0763, 0.0861, 0.1265, 0.1245, 0.1481, 0.1179, 0.0774, 0.0555,
        0.1158], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,814][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0010, 0.0039, 0.5782, 0.1724, 0.0777, 0.1405, 0.0081, 0.0087, 0.0047,
        0.0047], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,816][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1364, 0.0800, 0.0841, 0.0942, 0.0604, 0.0921, 0.1184, 0.0761, 0.1224,
        0.1359], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,817][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0349, 0.0348, 0.2783, 0.0993, 0.2089, 0.1452, 0.0461, 0.0675, 0.0433,
        0.0417], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,818][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1464, 0.1121, 0.0409, 0.0534, 0.0892, 0.0818, 0.1065, 0.1241, 0.1220,
        0.1238], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,819][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([1.4479e-09, 2.2469e-08, 9.8511e-01, 5.3709e-04, 1.4142e-02, 2.0520e-04,
        1.8033e-07, 7.6668e-07, 9.9984e-08, 7.8861e-08], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:24,820][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([2.7308e-02, 3.8146e-03, 2.7925e-02, 3.6512e-04, 4.3485e-01, 8.6376e-04,
        3.1591e-03, 1.4539e-02, 1.0576e-02, 1.9409e-02, 4.5719e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,822][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0032, 0.0018, 0.2508, 0.0036, 0.3296, 0.0005, 0.0010, 0.0018, 0.0020,
        0.0031, 0.4027], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,823][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0075, 0.0207, 0.2082, 0.0773, 0.2069, 0.0835, 0.0477, 0.0754, 0.0583,
        0.0257, 0.1888], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,823][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0735, 0.0841, 0.0965, 0.1009, 0.0984, 0.0918, 0.0865, 0.0879, 0.0903,
        0.0903, 0.0998], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,824][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([5.8232e-01, 7.6664e-02, 1.4471e-04, 1.2405e-03, 1.9048e-02, 5.8944e-04,
        3.3565e-02, 3.6835e-02, 9.9656e-02, 1.4587e-01, 4.0634e-03],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,824][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0025, 0.0013, 0.1560, 0.0015, 0.2600, 0.0028, 0.0025, 0.0082, 0.0041,
        0.0045, 0.5567], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,824][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0947, 0.0664, 0.0607, 0.0844, 0.1031, 0.0958, 0.0959, 0.0484, 0.0384,
        0.1134, 0.1988], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,825][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([5.2829e-04, 1.3008e-03, 1.4406e-01, 2.9237e-02, 5.1015e-02, 3.5142e-02,
        3.2467e-03, 3.3344e-03, 2.2036e-03, 2.4631e-03, 7.2747e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,825][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2105, 0.0682, 0.0470, 0.0522, 0.0298, 0.0379, 0.0878, 0.0407, 0.1398,
        0.1682, 0.1177], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,825][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1175, 0.0372, 0.0549, 0.0085, 0.3582, 0.0218, 0.0354, 0.0553, 0.0531,
        0.0664, 0.1916], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,826][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([4.4943e-01, 1.1784e-01, 3.0258e-04, 2.3592e-03, 1.1027e-02, 6.5796e-03,
        6.4489e-02, 5.9886e-02, 1.2142e-01, 1.6243e-01, 4.2373e-03],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,826][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([5.6015e-14, 2.6585e-10, 1.3035e-03, 5.4325e-11, 2.3047e-01, 2.4590e-10,
        1.3560e-09, 2.5170e-08, 2.7516e-08, 3.7702e-08, 7.6823e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:24,827][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0007, 0.0017, 0.3655, 0.0330, 0.0927, 0.0367, 0.0031, 0.0084, 0.0027,
        0.0027, 0.4482, 0.0045], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,829][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0018, 0.0038, 0.3443, 0.1518, 0.0927, 0.0622, 0.0042, 0.0093, 0.0039,
        0.0034, 0.3196, 0.0029], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,830][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0377, 0.0565, 0.1231, 0.0990, 0.1132, 0.1008, 0.0741, 0.0796, 0.0627,
        0.0603, 0.1345, 0.0587], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,832][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0689, 0.0775, 0.0885, 0.0920, 0.0902, 0.0846, 0.0806, 0.0820, 0.0841,
        0.0830, 0.0911, 0.0775], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,832][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.2152, 0.0911, 0.0135, 0.0235, 0.0715, 0.0194, 0.0669, 0.0858, 0.1110,
        0.1200, 0.0384, 0.1436], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,834][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0054, 0.0088, 0.2604, 0.1150, 0.0845, 0.1157, 0.0133, 0.0247, 0.0113,
        0.0100, 0.3427, 0.0081], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,835][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0483, 0.0598, 0.0689, 0.1037, 0.0903, 0.1209, 0.0911, 0.0664, 0.0462,
        0.0843, 0.1588, 0.0616], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,836][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0005, 0.0021, 0.3627, 0.1212, 0.0406, 0.0995, 0.0044, 0.0050, 0.0024,
        0.0024, 0.3579, 0.0014], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,838][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0738, 0.0562, 0.0774, 0.0913, 0.0535, 0.1020, 0.0991, 0.0642, 0.0833,
        0.0876, 0.1317, 0.0798], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,839][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0172, 0.0208, 0.2299, 0.0933, 0.1264, 0.1293, 0.0301, 0.0437, 0.0257,
        0.0242, 0.2382, 0.0212], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,840][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0968, 0.0857, 0.0593, 0.0609, 0.0885, 0.0927, 0.0834, 0.0989, 0.0908,
        0.0894, 0.0609, 0.0927], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,841][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([5.9005e-10, 3.9400e-09, 3.9590e-01, 6.7629e-04, 1.5258e-03, 2.5067e-04,
        3.7547e-08, 1.8362e-07, 1.2465e-08, 9.3457e-09, 6.0165e-01, 3.1427e-09],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:24,843][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Megan] are: tensor([0.0160, 0.0092, 0.1047, 0.0115, 0.2509, 0.0115, 0.0127, 0.0231, 0.0171,
        0.0205, 0.4164, 0.0398, 0.0664], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,844][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Megan] are: tensor([0.0089, 0.0089, 0.2529, 0.0611, 0.1750, 0.0152, 0.0072, 0.0117, 0.0091,
        0.0107, 0.3939, 0.0109, 0.0345], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,846][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Megan] are: tensor([0.0505, 0.0589, 0.0832, 0.0657, 0.0994, 0.0659, 0.0697, 0.0611, 0.0657,
        0.0727, 0.1445, 0.0774, 0.0854], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,847][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Megan] are: tensor([0.0640, 0.0718, 0.0817, 0.0851, 0.0832, 0.0776, 0.0736, 0.0747, 0.0766,
        0.0765, 0.0844, 0.0712, 0.0795], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,849][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Megan] are: tensor([0.2575, 0.0758, 0.0038, 0.0087, 0.0486, 0.0070, 0.0488, 0.0571, 0.0955,
        0.1131, 0.0164, 0.1420, 0.1256], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,850][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Megan] are: tensor([0.0138, 0.0130, 0.1474, 0.0453, 0.1544, 0.0503, 0.0192, 0.0348, 0.0204,
        0.0203, 0.4156, 0.0182, 0.0473], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,852][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Megan] are: tensor([0.0848, 0.0575, 0.0356, 0.0769, 0.0513, 0.0876, 0.0946, 0.0427, 0.0339,
        0.1053, 0.1858, 0.0853, 0.0588], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,853][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Megan] are: tensor([0.0011, 0.0034, 0.2753, 0.0904, 0.0618, 0.0832, 0.0071, 0.0078, 0.0044,
        0.0045, 0.4469, 0.0027, 0.0116], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,855][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Megan] are: tensor([0.1297, 0.0618, 0.0468, 0.0745, 0.0349, 0.0487, 0.1003, 0.0415, 0.1006,
        0.1118, 0.0955, 0.1012, 0.0526], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,856][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Megan] are: tensor([0.0442, 0.0326, 0.1207, 0.0437, 0.1471, 0.0704, 0.0431, 0.0583, 0.0418,
        0.0442, 0.2271, 0.0427, 0.0839], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,857][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Megan] are: tensor([0.1446, 0.0947, 0.0159, 0.0290, 0.0536, 0.0527, 0.0793, 0.0897, 0.1008,
        0.1051, 0.0322, 0.1162, 0.0862], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,858][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Megan] are: tensor([4.8909e-09, 7.7722e-08, 6.7243e-03, 1.7935e-05, 5.5222e-03, 1.6193e-05,
        3.8864e-07, 1.4379e-06, 4.4110e-07, 5.4640e-07, 9.8767e-01, 2.5178e-07,
        5.1094e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:24,859][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([2.6144e-02, 1.1347e-03, 4.6523e-03, 1.2615e-04, 1.8118e-01, 9.5906e-05,
        1.5270e-03, 7.8938e-03, 4.4114e-03, 1.0787e-02, 3.7399e-01, 4.1831e-02,
        5.0457e-02, 2.9576e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,860][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([1.6674e-02, 5.1869e-03, 1.3216e-01, 2.5927e-03, 3.3392e-01, 2.5914e-04,
        3.0509e-03, 5.1107e-03, 6.3186e-03, 1.2081e-02, 3.1085e-01, 1.8139e-02,
        6.1116e-02, 9.2536e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,860][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0213, 0.0312, 0.1118, 0.0476, 0.1144, 0.0566, 0.0557, 0.0433, 0.0465,
        0.0426, 0.1352, 0.0427, 0.0794, 0.1716], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,860][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0585, 0.0662, 0.0755, 0.0784, 0.0770, 0.0714, 0.0674, 0.0683, 0.0699,
        0.0704, 0.0780, 0.0652, 0.0732, 0.0807], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,861][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([5.2240e-01, 4.4373e-02, 3.6041e-05, 2.4205e-04, 1.2884e-02, 2.4170e-04,
        1.6649e-02, 1.7693e-02, 6.3291e-02, 9.4371e-02, 6.5575e-04, 1.3995e-01,
        8.7008e-02, 2.0371e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,861][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0023, 0.0010, 0.0665, 0.0014, 0.0920, 0.0023, 0.0020, 0.0055, 0.0038,
        0.0046, 0.6814, 0.0033, 0.0208, 0.1131], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,861][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0687, 0.0502, 0.0423, 0.0667, 0.0696, 0.0640, 0.0761, 0.0389, 0.0280,
        0.0887, 0.1607, 0.0789, 0.0856, 0.0816], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,862][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([2.6464e-04, 4.3087e-04, 2.5581e-02, 3.8194e-03, 1.4225e-02, 7.4025e-03,
        1.0412e-03, 1.0276e-03, 7.9205e-04, 8.5997e-04, 1.1198e-01, 5.5451e-04,
        2.9105e-03, 8.2911e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,863][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.1841, 0.0619, 0.0306, 0.0421, 0.0213, 0.0243, 0.0735, 0.0249, 0.0920,
        0.1338, 0.0804, 0.1176, 0.0497, 0.0638], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,864][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.1897, 0.0358, 0.0132, 0.0030, 0.1939, 0.0069, 0.0282, 0.0359, 0.0513,
        0.0719, 0.0888, 0.0895, 0.1705, 0.0213], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,865][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([4.5478e-01, 7.2002e-02, 7.1051e-05, 3.0396e-04, 4.4164e-03, 9.3975e-04,
        3.1186e-02, 2.8761e-02, 8.5430e-02, 1.0718e-01, 5.3781e-04, 1.7328e-01,
        4.0863e-02, 2.5026e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,866][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([7.2756e-17, 4.6306e-14, 2.0208e-09, 4.7081e-16, 2.6051e-05, 9.2387e-16,
        4.1086e-13, 7.0616e-12, 8.1447e-12, 2.0538e-11, 2.8016e-05, 8.5046e-12,
        2.1657e-07, 9.9995e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:24,867][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([8.2984e-03, 6.8052e-04, 1.0254e-03, 3.0490e-05, 8.0479e-02, 4.9543e-05,
        5.2677e-04, 3.8467e-03, 2.5601e-03, 5.5805e-03, 1.1294e-01, 2.0973e-02,
        2.8276e-02, 4.1891e-01, 3.1583e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,868][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.4804e-02, 5.6508e-03, 1.2888e-01, 2.1171e-03, 2.3452e-01, 2.1936e-04,
        2.6587e-03, 4.0948e-03, 5.7637e-03, 1.2610e-02, 1.8500e-01, 1.6759e-02,
        5.3438e-02, 8.1581e-02, 2.5191e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,869][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0112, 0.0214, 0.1326, 0.0404, 0.1111, 0.0432, 0.0292, 0.0345, 0.0413,
        0.0236, 0.0871, 0.0238, 0.0608, 0.1719, 0.1678], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,871][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0545, 0.0612, 0.0696, 0.0726, 0.0711, 0.0664, 0.0628, 0.0638, 0.0654,
        0.0655, 0.0719, 0.0607, 0.0679, 0.0753, 0.0713], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,872][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([4.9389e-01, 4.9974e-02, 3.5743e-05, 4.8264e-04, 1.2546e-02, 3.1137e-04,
        1.9612e-02, 1.9106e-02, 6.9030e-02, 1.0074e-01, 1.5227e-03, 1.4474e-01,
        8.7353e-02, 3.9685e-04, 2.6666e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,873][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([5.3528e-04, 2.8019e-04, 4.6139e-02, 4.4237e-04, 7.5139e-02, 1.6153e-03,
        6.7453e-04, 2.3792e-03, 1.1674e-03, 1.1576e-03, 2.1432e-01, 9.0150e-04,
        8.9041e-03, 2.1879e-01, 4.2755e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,874][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0637, 0.0410, 0.0335, 0.0504, 0.0546, 0.0580, 0.0590, 0.0290, 0.0235,
        0.0718, 0.1248, 0.0671, 0.0703, 0.0764, 0.1767], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,875][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.3404e-05, 2.4616e-05, 1.6259e-03, 2.4048e-04, 9.1336e-04, 6.4349e-04,
        6.5557e-05, 6.5779e-05, 5.0273e-05, 5.5777e-05, 1.0695e-02, 3.2509e-05,
        2.1638e-04, 1.2963e-01, 8.5573e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,876][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1234, 0.0479, 0.0328, 0.0412, 0.0220, 0.0278, 0.0617, 0.0300, 0.0949,
        0.1028, 0.0781, 0.0942, 0.0472, 0.0801, 0.1160], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,878][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0954, 0.0223, 0.0136, 0.0018, 0.1607, 0.0069, 0.0187, 0.0341, 0.0368,
        0.0436, 0.0645, 0.0547, 0.1255, 0.0844, 0.2372], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,879][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([3.7800e-01, 8.0890e-02, 1.5809e-04, 9.6208e-04, 4.9786e-03, 4.1096e-03,
        4.8659e-02, 3.9638e-02, 9.5949e-02, 1.2251e-01, 1.9873e-03, 1.7010e-01,
        4.4777e-02, 1.3989e-03, 5.8798e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,880][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([7.4147e-24, 3.3152e-19, 4.9976e-16, 2.9840e-22, 5.5277e-11, 6.1319e-20,
        3.0423e-18, 7.5849e-17, 1.4532e-16, 1.8121e-16, 2.3922e-10, 4.9131e-17,
        2.1962e-12, 8.2836e-01, 1.7164e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:24,881][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:24,882][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 9011],
        [ 9945],
        [22428],
        [21297],
        [21725],
        [15146],
        [11149],
        [ 8451],
        [10626],
        [ 9348],
        [11501],
        [10173],
        [16552],
        [11978],
        [ 7524]], device='cuda:0')
[2024-07-24 10:29:24,883][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 9558],
        [12393],
        [32211],
        [18710],
        [27622],
        [12830],
        [12317],
        [12358],
        [13595],
        [11562],
        [17876],
        [11736],
        [21625],
        [14049],
        [12206]], device='cuda:0')
[2024-07-24 10:29:24,885][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[18180],
        [22020],
        [17213],
        [17215],
        [18937],
        [18316],
        [17486],
        [17504],
        [18806],
        [19093],
        [18682],
        [20213],
        [19131],
        [19365],
        [19626]], device='cuda:0')
[2024-07-24 10:29:24,886][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[31488],
        [24372],
        [26134],
        [24792],
        [20776],
        [19368],
        [17206],
        [15162],
        [14262],
        [14080],
        [15195],
        [15965],
        [16409],
        [16292],
        [16584]], device='cuda:0')
[2024-07-24 10:29:24,887][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[365],
        [404],
        [527],
        [537],
        [585],
        [616],
        [671],
        [773],
        [839],
        [848],
        [877],
        [869],
        [863],
        [893],
        [914]], device='cuda:0')
[2024-07-24 10:29:24,889][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[  407],
        [  406],
        [36808],
        [44422],
        [29479],
        [44197],
        [42894],
        [ 7052],
        [14519],
        [ 3669],
        [ 2642],
        [  474],
        [  897],
        [27232],
        [ 1398]], device='cuda:0')
[2024-07-24 10:29:24,890][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[11320],
        [13031],
        [11421],
        [10894],
        [10760],
        [11999],
        [13195],
        [14553],
        [13900],
        [13784],
        [16687],
        [17436],
        [15785],
        [16438],
        [16501]], device='cuda:0')
[2024-07-24 10:29:24,892][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[17029],
        [35852],
        [26250],
        [37630],
        [35696],
        [28776],
        [25881],
        [34341],
        [35496],
        [32869],
        [37206],
        [38112],
        [39227],
        [35615],
        [32624]], device='cuda:0')
[2024-07-24 10:29:24,893][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[26253],
        [22612],
        [20688],
        [20595],
        [20100],
        [19235],
        [19192],
        [18902],
        [18813],
        [18936],
        [18890],
        [19111],
        [19137],
        [18940],
        [18723]], device='cuda:0')
[2024-07-24 10:29:24,894][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[41025],
        [37995],
        [33009],
        [31939],
        [27783],
        [29675],
        [29490],
        [28579],
        [27900],
        [29797],
        [29135],
        [29483],
        [28230],
        [28421],
        [28778]], device='cuda:0')
[2024-07-24 10:29:24,895][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[15789],
        [17359],
        [18692],
        [18280],
        [16563],
        [15491],
        [14701],
        [14627],
        [12846],
        [12670],
        [12181],
        [12751],
        [12174],
        [12451],
        [12639]], device='cuda:0')
[2024-07-24 10:29:24,896][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[18367],
        [17336],
        [15271],
        [15568],
        [14198],
        [12892],
        [12913],
        [13174],
        [13441],
        [13094],
        [13551],
        [13322],
        [13136],
        [13087],
        [13083]], device='cuda:0')
[2024-07-24 10:29:24,896][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 2891],
        [ 9291],
        [21078],
        [ 9973],
        [20443],
        [21936],
        [21376],
        [ 8287],
        [11653],
        [12110],
        [10103],
        [13616],
        [21850],
        [21750],
        [14186]], device='cuda:0')
[2024-07-24 10:29:24,898][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 6043],
        [ 4482],
        [29142],
        [29145],
        [19717],
        [24857],
        [28971],
        [28473],
        [28988],
        [29045],
        [ 6003],
        [11037],
        [ 4843],
        [ 7683],
        [ 7358]], device='cuda:0')
[2024-07-24 10:29:24,899][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[17634],
        [16248],
        [12728],
        [28749],
        [24325],
        [40743],
        [22091],
        [21458],
        [17193],
        [16701],
        [32650],
        [16799],
        [19868],
        [42883],
        [34264]], device='cuda:0')
[2024-07-24 10:29:24,901][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[  723],
        [ 2036],
        [19144],
        [20560],
        [15094],
        [19862],
        [20644],
        [19048],
        [19401],
        [20659],
        [22502],
        [23204],
        [22579],
        [14740],
        [10671]], device='cuda:0')
[2024-07-24 10:29:24,902][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[20191],
        [ 8242],
        [ 1208],
        [ 1173],
        [ 1409],
        [ 1268],
        [ 1239],
        [ 1252],
        [ 1319],
        [ 1326],
        [ 1320],
        [ 1216],
        [ 1253],
        [ 1233],
        [  678]], device='cuda:0')
[2024-07-24 10:29:24,903][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[15418],
        [13285],
        [15989],
        [14609],
        [13370],
        [13519],
        [13098],
        [13261],
        [13443],
        [13750],
        [12126],
        [12067],
        [11623],
        [12470],
        [12383]], device='cuda:0')
[2024-07-24 10:29:24,904][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[15034],
        [14426],
        [14582],
        [14297],
        [14599],
        [14780],
        [14733],
        [14824],
        [14896],
        [14794],
        [14684],
        [14738],
        [14829],
        [14901],
        [14821]], device='cuda:0')
[2024-07-24 10:29:24,906][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[36098],
        [29935],
        [33908],
        [32926],
        [34415],
        [34458],
        [25561],
        [24344],
        [20456],
        [19622],
        [24345],
        [20407],
        [23614],
        [29644],
        [28886]], device='cuda:0')
[2024-07-24 10:29:24,907][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[32503],
        [34337],
        [22436],
        [22409],
        [18265],
        [20710],
        [20503],
        [20066],
        [19670],
        [19593],
        [23936],
        [20439],
        [22351],
        [23552],
        [21052]], device='cuda:0')
[2024-07-24 10:29:24,909][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 5076],
        [ 5155],
        [ 5299],
        [ 6760],
        [ 7253],
        [ 7802],
        [ 7806],
        [ 8266],
        [ 8327],
        [ 8213],
        [ 9246],
        [ 9043],
        [ 9234],
        [ 9290],
        [10838]], device='cuda:0')
[2024-07-24 10:29:24,910][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 7385],
        [ 5883],
        [ 5994],
        [ 6195],
        [ 6122],
        [ 5878],
        [ 5990],
        [ 5994],
        [ 6018],
        [ 6045],
        [ 9594],
        [ 7485],
        [ 7980],
        [ 9511],
        [14129]], device='cuda:0')
[2024-07-24 10:29:24,911][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[3563],
        [2560],
        [3654],
        [2991],
        [2940],
        [2618],
        [2297],
        [2266],
        [2734],
        [2797],
        [2425],
        [2365],
        [2382],
        [2487],
        [2428]], device='cuda:0')
[2024-07-24 10:29:24,913][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 8510],
        [ 8333],
        [ 4957],
        [ 5145],
        [ 5401],
        [ 5206],
        [ 5648],
        [ 5691],
        [ 5698],
        [ 5678],
        [ 7513],
        [ 7447],
        [ 7935],
        [ 7122],
        [11038]], device='cuda:0')
[2024-07-24 10:29:24,914][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[20647],
        [17553],
        [19219],
        [18526],
        [16596],
        [18659],
        [13283],
        [11202],
        [10015],
        [ 9333],
        [14465],
        [ 7941],
        [10095],
        [16537],
        [14868]], device='cuda:0')
[2024-07-24 10:29:24,916][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[39196],
        [36536],
        [22881],
        [22876],
        [30202],
        [28394],
        [23136],
        [23858],
        [23075],
        [23011],
        [20121],
        [26710],
        [19021],
        [33141],
        [34018]], device='cuda:0')
[2024-07-24 10:29:24,917][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[32263],
        [36228],
        [35141],
        [35230],
        [36058],
        [34646],
        [38284],
        [38864],
        [39734],
        [40035],
        [38116],
        [40093],
        [39741],
        [35789],
        [36647]], device='cuda:0')
[2024-07-24 10:29:24,918][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[20920],
        [29158],
        [33151],
        [31920],
        [21454],
        [11807],
        [25478],
        [25683],
        [29704],
        [30426],
        [17674],
        [29442],
        [25420],
        [ 6437],
        [13737]], device='cuda:0')
[2024-07-24 10:29:24,920][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[8872],
        [8872],
        [8872],
        [8872],
        [8872],
        [8872],
        [8872],
        [8872],
        [8872],
        [8872],
        [8872],
        [8872],
        [8872],
        [8872],
        [8872]], device='cuda:0')
[2024-07-24 10:29:24,952][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:24,954][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,955][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,956][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,956][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,957][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,957][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,957][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,958][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,958][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,958][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,959][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,959][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:24,959][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.5062, 0.4938], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,960][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.5434, 0.4566], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,961][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1868, 0.8132], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,963][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6491, 0.3509], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,964][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.6314, 0.3686], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,965][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.3944, 0.6056], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,967][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.5693, 0.4307], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,968][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.4405, 0.5595], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,969][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1202, 0.8798], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,971][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.5727, 0.4273], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,972][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.5099, 0.4901], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,973][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.4697, 0.5303], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:24,975][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Jennifer] are: tensor([0.3040, 0.2453, 0.4507], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,976][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Jennifer] are: tensor([0.3586, 0.3047, 0.3367], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,978][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Jennifer] are: tensor([0.1145, 0.3811, 0.5044], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,979][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Jennifer] are: tensor([0.6511, 0.1461, 0.2028], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,980][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Jennifer] are: tensor([0.2188, 0.0653, 0.7159], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,982][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Jennifer] are: tensor([0.1729, 0.3506, 0.4765], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,983][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Jennifer] are: tensor([0.5161, 0.4757, 0.0082], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,984][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Jennifer] are: tensor([0.3727, 0.4041, 0.2232], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,986][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Jennifer] are: tensor([0.0841, 0.4262, 0.4898], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,987][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Jennifer] are: tensor([0.3808, 0.3589, 0.2603], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,989][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Jennifer] are: tensor([0.6190, 0.2751, 0.1059], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,989][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Jennifer] are: tensor([0.1469, 0.1779, 0.6752], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:24,989][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1862, 0.1804, 0.4420, 0.1915], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,989][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2724, 0.2332, 0.2505, 0.2439], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,990][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0694, 0.2511, 0.3665, 0.3130], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,990][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.4268, 0.1429, 0.3468, 0.0835], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,990][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1196, 0.0291, 0.4051, 0.4463], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,991][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1074, 0.2284, 0.3297, 0.3346], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,991][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([8.1058e-01, 1.7068e-01, 1.8048e-02, 6.8868e-04], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,991][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2651, 0.2625, 0.2284, 0.2439], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,991][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0510, 0.2815, 0.3300, 0.3376], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,992][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2790, 0.2021, 0.2582, 0.2607], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,993][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4297, 0.2649, 0.1750, 0.1304], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,994][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0793, 0.0786, 0.3237, 0.5184], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:24,996][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Megan] are: tensor([0.2186, 0.1388, 0.2696, 0.1209, 0.2521], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,997][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Megan] are: tensor([0.2092, 0.1881, 0.2027, 0.1933, 0.2067], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:24,998][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Megan] are: tensor([0.0583, 0.1955, 0.2682, 0.2510, 0.2270], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,000][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Megan] are: tensor([0.4180, 0.1187, 0.1755, 0.1033, 0.1846], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,001][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Megan] are: tensor([0.0902, 0.0229, 0.2896, 0.3684, 0.2288], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,003][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Megan] are: tensor([0.0860, 0.1733, 0.2500, 0.2538, 0.2370], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,004][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Megan] are: tensor([0.2257, 0.2831, 0.0045, 0.4857, 0.0011], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,005][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Megan] are: tensor([0.1841, 0.2576, 0.1480, 0.2648, 0.1455], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,007][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Megan] are: tensor([0.0372, 0.2116, 0.2467, 0.2548, 0.2497], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,008][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Megan] are: tensor([0.2224, 0.2092, 0.2912, 0.1823, 0.0949], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,010][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Megan] are: tensor([0.3385, 0.2236, 0.1109, 0.1086, 0.2184], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,011][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Megan] are: tensor([0.0992, 0.0937, 0.2749, 0.1559, 0.3762], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,012][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.1828, 0.1048, 0.2273, 0.0809, 0.2191, 0.1851], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,014][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.1839, 0.1538, 0.1663, 0.1606, 0.1602, 0.1752], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,015][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0461, 0.1535, 0.2176, 0.1965, 0.1884, 0.1978], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,016][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1164, 0.0679, 0.1930, 0.0814, 0.4345, 0.1067], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,018][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0565, 0.0183, 0.2317, 0.2623, 0.1881, 0.2431], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,019][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0692, 0.1427, 0.1973, 0.2009, 0.1911, 0.1989], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,020][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.5672, 0.3537, 0.0165, 0.0309, 0.0246, 0.0071], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,021][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1606, 0.1707, 0.1918, 0.2013, 0.0930, 0.1827], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,021][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0298, 0.1667, 0.1967, 0.2023, 0.1979, 0.2066], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,021][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.1610, 0.1592, 0.2463, 0.1674, 0.1587, 0.1075], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,021][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.2275, 0.1733, 0.1344, 0.1142, 0.2147, 0.1359], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,022][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0514, 0.0354, 0.1631, 0.1322, 0.1473, 0.4705], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,022][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1435, 0.0897, 0.2198, 0.0638, 0.1886, 0.1564, 0.1382],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,022][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1513, 0.1226, 0.1518, 0.1440, 0.1517, 0.1621, 0.1166],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,023][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0348, 0.1299, 0.1884, 0.1658, 0.1670, 0.1708, 0.1432],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,023][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1154, 0.0533, 0.1665, 0.0919, 0.3282, 0.1937, 0.0510],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,023][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0106, 0.0056, 0.2184, 0.2828, 0.1537, 0.2757, 0.0532],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,024][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0747, 0.1211, 0.1611, 0.1644, 0.1590, 0.1622, 0.1574],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,025][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3824, 0.2800, 0.0633, 0.0660, 0.1195, 0.0289, 0.0600],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,027][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0910, 0.1205, 0.1937, 0.1609, 0.1269, 0.1721, 0.1350],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,028][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0266, 0.1377, 0.1631, 0.1701, 0.1646, 0.1745, 0.1635],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,029][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1565, 0.1405, 0.1960, 0.1307, 0.1472, 0.0927, 0.1364],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,031][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1308, 0.1395, 0.1705, 0.1302, 0.1677, 0.1298, 0.1315],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,032][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0330, 0.0403, 0.2269, 0.1508, 0.1863, 0.2508, 0.1119],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,034][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.1106, 0.0732, 0.1732, 0.0574, 0.1526, 0.1145, 0.1205, 0.1980],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,035][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.1382, 0.1111, 0.1432, 0.1311, 0.1340, 0.1482, 0.0979, 0.0963],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,037][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0280, 0.1122, 0.1662, 0.1482, 0.1420, 0.1511, 0.1309, 0.1213],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,038][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0951, 0.0528, 0.1545, 0.1046, 0.3298, 0.1139, 0.0578, 0.0914],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,039][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0342, 0.0109, 0.1791, 0.2547, 0.1256, 0.2483, 0.0633, 0.0840],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,041][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0522, 0.1031, 0.1453, 0.1484, 0.1403, 0.1450, 0.1370, 0.1287],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,042][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.3236, 0.2253, 0.0516, 0.0423, 0.0217, 0.0947, 0.1817, 0.0590],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,044][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0689, 0.1034, 0.0889, 0.1010, 0.0646, 0.1068, 0.1613, 0.3051],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,045][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0221, 0.1188, 0.1409, 0.1465, 0.1418, 0.1504, 0.1414, 0.1381],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,047][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.1586, 0.1001, 0.1729, 0.1352, 0.1483, 0.1057, 0.1129, 0.0663],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,048][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.1372, 0.1249, 0.1191, 0.1154, 0.1417, 0.1211, 0.1279, 0.1127],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,049][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0243, 0.0264, 0.1449, 0.1629, 0.1290, 0.2420, 0.0508, 0.2199],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,051][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0940, 0.0538, 0.1343, 0.0462, 0.1342, 0.1094, 0.1195, 0.1986, 0.1099],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,052][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.1247, 0.0961, 0.1376, 0.1230, 0.1319, 0.1460, 0.0870, 0.0852, 0.0684],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,052][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0189, 0.0977, 0.1510, 0.1369, 0.1325, 0.1378, 0.1191, 0.1182, 0.0879],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,053][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0642, 0.0452, 0.1536, 0.1079, 0.2203, 0.1161, 0.0689, 0.1540, 0.0696],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,053][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0191, 0.0072, 0.1501, 0.2744, 0.1002, 0.2670, 0.0822, 0.0854, 0.0146],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,053][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0528, 0.0905, 0.1313, 0.1339, 0.1277, 0.1309, 0.1247, 0.1165, 0.0916],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,054][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.1297, 0.1615, 0.0866, 0.1293, 0.0623, 0.0565, 0.1671, 0.1207, 0.0862],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,054][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0582, 0.0789, 0.0949, 0.1119, 0.1086, 0.1217, 0.1178, 0.2137, 0.0943],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,054][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0194, 0.1037, 0.1233, 0.1298, 0.1245, 0.1341, 0.1265, 0.1231, 0.1155],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,055][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.1207, 0.1126, 0.1491, 0.0838, 0.1936, 0.0928, 0.0842, 0.1042, 0.0589],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,055][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.1224, 0.1156, 0.1016, 0.0992, 0.1206, 0.1017, 0.1152, 0.1085, 0.1153],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,056][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0442, 0.0514, 0.1408, 0.0999, 0.1436, 0.1828, 0.0656, 0.1376, 0.1342],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,057][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0731, 0.0546, 0.1517, 0.0563, 0.1336, 0.1131, 0.1185, 0.1665, 0.0892,
        0.0434], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,058][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1180, 0.0927, 0.1261, 0.1189, 0.1192, 0.1330, 0.0855, 0.0804, 0.0631,
        0.0631], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,060][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0196, 0.0876, 0.1426, 0.1147, 0.1257, 0.1271, 0.1066, 0.1087, 0.0934,
        0.0740], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,061][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0859, 0.0503, 0.1219, 0.0675, 0.1851, 0.1196, 0.0657, 0.1227, 0.1178,
        0.0635], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,063][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0282, 0.0085, 0.1714, 0.2351, 0.1323, 0.2284, 0.0596, 0.0919, 0.0172,
        0.0273], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,064][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0702, 0.0828, 0.1118, 0.1147, 0.1113, 0.1122, 0.1113, 0.1040, 0.0865,
        0.0953], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,065][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1170, 0.0915, 0.0908, 0.0303, 0.1662, 0.0502, 0.1254, 0.1346, 0.1089,
        0.0851], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,067][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0582, 0.0715, 0.1156, 0.1122, 0.1250, 0.1148, 0.0921, 0.1518, 0.0859,
        0.0730], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,068][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0174, 0.0936, 0.1114, 0.1174, 0.1125, 0.1211, 0.1132, 0.1112, 0.1042,
        0.0980], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,070][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1123, 0.0871, 0.1444, 0.1005, 0.1185, 0.0728, 0.1064, 0.0999, 0.0830,
        0.0752], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,071][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1011, 0.1024, 0.1019, 0.0898, 0.1113, 0.0883, 0.0981, 0.0992, 0.1023,
        0.1056], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,072][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0631, 0.0615, 0.1271, 0.1293, 0.1047, 0.1454, 0.0721, 0.1296, 0.1009,
        0.0664], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,074][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0816, 0.0700, 0.1661, 0.0644, 0.1168, 0.0919, 0.0884, 0.1551, 0.0817,
        0.0394, 0.0446], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,075][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1056, 0.0907, 0.1006, 0.0985, 0.0947, 0.1044, 0.0836, 0.0809, 0.0702,
        0.0711, 0.0997], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,077][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0238, 0.0832, 0.1204, 0.1032, 0.1094, 0.1100, 0.0974, 0.0975, 0.0831,
        0.0736, 0.0982], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,078][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1717, 0.0509, 0.0911, 0.0240, 0.1896, 0.0971, 0.0633, 0.0890, 0.1121,
        0.0811, 0.0303], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,079][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0351, 0.0108, 0.1639, 0.1727, 0.1330, 0.1721, 0.0499, 0.0860, 0.0261,
        0.0285, 0.1220], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,081][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0418, 0.0751, 0.1065, 0.1078, 0.1032, 0.1071, 0.1012, 0.0959, 0.0745,
        0.0750, 0.1121], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,082][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([3.7620e-01, 8.2308e-02, 1.2613e-02, 3.3568e-04, 7.2022e-02, 2.0616e-02,
        6.7117e-02, 5.4146e-02, 2.2481e-01, 8.9531e-02, 2.9747e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,083][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1080, 0.1028, 0.0869, 0.0798, 0.0436, 0.0793, 0.0817, 0.0821, 0.0951,
        0.1035, 0.1372], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,084][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0171, 0.0865, 0.1004, 0.1036, 0.1009, 0.1056, 0.0990, 0.0984, 0.0922,
        0.0874, 0.1088], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,084][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1075, 0.0807, 0.1110, 0.1025, 0.0852, 0.0738, 0.0891, 0.0934, 0.0799,
        0.0715, 0.1054], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,084][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1294, 0.0907, 0.0768, 0.0521, 0.1365, 0.0590, 0.0840, 0.0841, 0.0952,
        0.1058, 0.0863], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,085][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0202, 0.0224, 0.1300, 0.1747, 0.0984, 0.1575, 0.0348, 0.0591, 0.0447,
        0.0271, 0.2310], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,085][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0688, 0.0597, 0.1317, 0.0588, 0.1050, 0.0890, 0.0802, 0.1451, 0.0816,
        0.0439, 0.0480, 0.0882], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,085][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.1005, 0.0756, 0.1077, 0.0963, 0.1036, 0.1117, 0.0690, 0.0672, 0.0544,
        0.0505, 0.1029, 0.0606], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,086][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0066, 0.0724, 0.1296, 0.1113, 0.1101, 0.1161, 0.0978, 0.0957, 0.0795,
        0.0616, 0.1010, 0.0182], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,086][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0663, 0.0489, 0.1067, 0.0692, 0.1334, 0.0891, 0.0618, 0.0987, 0.0881,
        0.0650, 0.0923, 0.0804], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,087][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0646, 0.0171, 0.1146, 0.1503, 0.0952, 0.1496, 0.0485, 0.0685, 0.0229,
        0.0434, 0.1255, 0.0999], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,088][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0416, 0.0660, 0.1074, 0.1076, 0.1030, 0.1058, 0.0971, 0.0909, 0.0666,
        0.0654, 0.1128, 0.0357], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,089][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0595, 0.0856, 0.1084, 0.1154, 0.0888, 0.0899, 0.0867, 0.0862, 0.0605,
        0.0694, 0.0943, 0.0553], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,091][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0462, 0.0568, 0.0967, 0.0986, 0.1034, 0.1029, 0.0739, 0.1176, 0.0654,
        0.0578, 0.1233, 0.0574], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,092][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0087, 0.0753, 0.0926, 0.1007, 0.0934, 0.1058, 0.0982, 0.0952, 0.0881,
        0.0826, 0.1101, 0.0494], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,093][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0800, 0.0730, 0.1332, 0.0629, 0.1138, 0.0607, 0.0738, 0.0892, 0.0906,
        0.0646, 0.0763, 0.0818], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,095][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0804, 0.0850, 0.0862, 0.0789, 0.0890, 0.0788, 0.0821, 0.0834, 0.0837,
        0.0854, 0.0818, 0.0853], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,096][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0625, 0.0617, 0.0773, 0.0934, 0.0796, 0.1041, 0.0712, 0.1242, 0.0922,
        0.0608, 0.0931, 0.0799], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,097][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Megan] are: tensor([0.0986, 0.0661, 0.0952, 0.0491, 0.0894, 0.0787, 0.0769, 0.1064, 0.0612,
        0.0420, 0.0432, 0.0753, 0.1177], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,099][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Megan] are: tensor([0.0859, 0.0718, 0.0932, 0.0857, 0.0932, 0.0992, 0.0694, 0.0681, 0.0577,
        0.0539, 0.0900, 0.0598, 0.0722], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,100][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Megan] are: tensor([0.0203, 0.0763, 0.1075, 0.0998, 0.0875, 0.1037, 0.0855, 0.0905, 0.0708,
        0.0650, 0.0962, 0.0299, 0.0669], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,102][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Megan] are: tensor([0.1174, 0.0438, 0.0763, 0.0465, 0.0844, 0.0556, 0.0430, 0.0837, 0.1064,
        0.0685, 0.0693, 0.1102, 0.0949], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,103][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Megan] are: tensor([0.0229, 0.0045, 0.1273, 0.1921, 0.0858, 0.2058, 0.0571, 0.0740, 0.0156,
        0.0204, 0.1167, 0.0651, 0.0128], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,105][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Megan] are: tensor([0.0395, 0.0672, 0.0933, 0.0947, 0.0904, 0.0933, 0.0896, 0.0834, 0.0651,
        0.0670, 0.0982, 0.0384, 0.0798], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,106][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Megan] are: tensor([0.0920, 0.1110, 0.0082, 0.1503, 0.0025, 0.0144, 0.1272, 0.0647, 0.0633,
        0.1122, 0.1809, 0.0627, 0.0105], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,107][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Megan] are: tensor([0.0489, 0.0656, 0.0528, 0.0774, 0.0569, 0.0830, 0.0954, 0.1406, 0.0720,
        0.0621, 0.1080, 0.0616, 0.0755], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,109][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Megan] are: tensor([0.0123, 0.0732, 0.0865, 0.0907, 0.0875, 0.0939, 0.0873, 0.0862, 0.0801,
        0.0755, 0.0962, 0.0503, 0.0803], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,110][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Megan] are: tensor([0.0783, 0.0747, 0.1025, 0.0628, 0.0355, 0.0776, 0.0927, 0.0863, 0.1000,
        0.0670, 0.0764, 0.1053, 0.0407], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,112][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Megan] are: tensor([0.0903, 0.0804, 0.0616, 0.0575, 0.0830, 0.0644, 0.0806, 0.0753, 0.0780,
        0.0848, 0.0697, 0.0847, 0.0895], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,113][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Megan] are: tensor([0.0399, 0.0392, 0.1016, 0.0565, 0.1407, 0.1775, 0.0422, 0.0489, 0.0723,
        0.0341, 0.0696, 0.0534, 0.1241], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,115][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0931, 0.0596, 0.0898, 0.0374, 0.0849, 0.0720, 0.0668, 0.0861, 0.0547,
        0.0334, 0.0342, 0.0625, 0.1154, 0.1102], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,115][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0833, 0.0701, 0.0822, 0.0788, 0.0797, 0.0886, 0.0654, 0.0626, 0.0546,
        0.0537, 0.0808, 0.0569, 0.0645, 0.0787], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,116][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0194, 0.0664, 0.1002, 0.0877, 0.0890, 0.0898, 0.0782, 0.0784, 0.0641,
        0.0588, 0.0849, 0.0307, 0.0702, 0.0822], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,116][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.1062, 0.0294, 0.0675, 0.0258, 0.1392, 0.0744, 0.0441, 0.0958, 0.0625,
        0.0497, 0.0433, 0.0955, 0.1330, 0.0334], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,116][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0430, 0.0107, 0.1218, 0.1350, 0.0957, 0.1310, 0.0423, 0.0650, 0.0233,
        0.0283, 0.0999, 0.0683, 0.0253, 0.1104], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,117][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0329, 0.0617, 0.0856, 0.0872, 0.0829, 0.0864, 0.0811, 0.0767, 0.0588,
        0.0585, 0.0902, 0.0338, 0.0733, 0.0910], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,117][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0967, 0.1269, 0.0097, 0.1120, 0.0193, 0.0087, 0.0873, 0.0702, 0.0585,
        0.1517, 0.1422, 0.0634, 0.0504, 0.0030], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,118][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0769, 0.0783, 0.0535, 0.0616, 0.0361, 0.0637, 0.0775, 0.0784, 0.0714,
        0.0785, 0.0932, 0.0803, 0.0621, 0.0886], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,118][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0132, 0.0672, 0.0795, 0.0819, 0.0797, 0.0838, 0.0793, 0.0784, 0.0737,
        0.0705, 0.0856, 0.0488, 0.0738, 0.0847], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,119][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0873, 0.0686, 0.0835, 0.0541, 0.0766, 0.0550, 0.0672, 0.0644, 0.0817,
        0.0568, 0.0595, 0.0788, 0.0896, 0.0769], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,120][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.1088, 0.0669, 0.0439, 0.0318, 0.0982, 0.0477, 0.0735, 0.0647, 0.0772,
        0.0832, 0.0627, 0.0826, 0.1034, 0.0553], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,121][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0109, 0.0140, 0.0881, 0.0691, 0.0739, 0.1265, 0.0241, 0.0321, 0.0376,
        0.0148, 0.0892, 0.0185, 0.0519, 0.3495], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,123][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0736, 0.0443, 0.0974, 0.0321, 0.0871, 0.0624, 0.0625, 0.0919, 0.0558,
        0.0251, 0.0241, 0.0550, 0.1107, 0.1026, 0.0755], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,124][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0748, 0.0626, 0.0765, 0.0742, 0.0741, 0.0829, 0.0602, 0.0573, 0.0490,
        0.0499, 0.0771, 0.0523, 0.0600, 0.0732, 0.0757], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,125][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0166, 0.0614, 0.0920, 0.0796, 0.0829, 0.0817, 0.0736, 0.0721, 0.0591,
        0.0550, 0.0759, 0.0283, 0.0662, 0.0766, 0.0790], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,126][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0901, 0.0350, 0.0549, 0.0324, 0.1215, 0.0599, 0.0414, 0.0715, 0.0767,
        0.0564, 0.0442, 0.0866, 0.1059, 0.0497, 0.0735], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,128][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0348, 0.0078, 0.1151, 0.1224, 0.0907, 0.1228, 0.0330, 0.0568, 0.0181,
        0.0211, 0.0884, 0.0550, 0.0206, 0.1044, 0.1089], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,129][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0315, 0.0563, 0.0778, 0.0788, 0.0752, 0.0780, 0.0739, 0.0700, 0.0546,
        0.0552, 0.0819, 0.0323, 0.0671, 0.0824, 0.0850], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,131][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1004, 0.0742, 0.0100, 0.0047, 0.0653, 0.0117, 0.1609, 0.1690, 0.0839,
        0.0862, 0.0060, 0.0735, 0.1471, 0.0047, 0.0025], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,132][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0824, 0.0746, 0.0600, 0.0500, 0.0296, 0.0516, 0.0498, 0.0492, 0.0690,
        0.0755, 0.0815, 0.0831, 0.0583, 0.0981, 0.0874], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,133][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0111, 0.0620, 0.0734, 0.0760, 0.0737, 0.0778, 0.0730, 0.0723, 0.0677,
        0.0643, 0.0796, 0.0441, 0.0679, 0.0788, 0.0782], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,135][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0900, 0.0704, 0.0817, 0.0664, 0.0647, 0.0474, 0.0729, 0.0597, 0.0600,
        0.0568, 0.0704, 0.0696, 0.0703, 0.0607, 0.0591], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,136][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0968, 0.0607, 0.0500, 0.0326, 0.0923, 0.0430, 0.0601, 0.0561, 0.0692,
        0.0761, 0.0613, 0.0755, 0.0944, 0.0617, 0.0702], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,138][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0144, 0.0187, 0.0863, 0.0968, 0.0608, 0.1337, 0.0310, 0.0448, 0.0279,
        0.0201, 0.1151, 0.0237, 0.0421, 0.1587, 0.1260], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,164][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:25,166][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,166][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,167][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,167][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,167][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,168][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,168][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,168][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,168][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,169][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,170][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,171][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,173][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.5069, 0.4931], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,174][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.3088, 0.6912], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,175][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.4811, 0.5189], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,177][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5949, 0.4051], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,178][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.4657, 0.5343], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,183][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4526, 0.5474], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,184][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.4028, 0.5972], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,185][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4774, 0.5226], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,185][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4788, 0.5212], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,185][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.5466, 0.4534], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,186][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.5123, 0.4877], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,186][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.5259, 0.4741], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,186][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Jennifer] are: tensor([0.7299, 0.2621, 0.0080], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,187][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Jennifer] are: tensor([0.3740, 0.4567, 0.1693], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,187][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Jennifer] are: tensor([0.4578, 0.1681, 0.3741], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,187][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Jennifer] are: tensor([0.5803, 0.3493, 0.0704], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,188][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Jennifer] are: tensor([0.2366, 0.1147, 0.6488], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,189][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Jennifer] are: tensor([0.6188, 0.3048, 0.0765], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,190][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Jennifer] are: tensor([0.3317, 0.1809, 0.4874], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,192][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Jennifer] are: tensor([0.6614, 0.2302, 0.1084], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,193][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Jennifer] are: tensor([0.6361, 0.2527, 0.1113], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,195][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Jennifer] are: tensor([0.7110, 0.2878, 0.0012], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,196][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Jennifer] are: tensor([0.7978, 0.1982, 0.0040], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,197][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Jennifer] are: tensor([0.6593, 0.3173, 0.0234], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,199][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6872, 0.2769, 0.0135, 0.0224], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,200][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0041, 0.0113, 0.1247, 0.8598], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,201][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0717, 0.0454, 0.8215, 0.0615], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,202][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.7785, 0.2035, 0.0073, 0.0107], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,204][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0401, 0.0281, 0.8443, 0.0874], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,205][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4248, 0.2745, 0.1386, 0.1621], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,206][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0328, 0.0295, 0.8659, 0.0717], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,208][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2258, 0.1423, 0.4574, 0.1745], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,209][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3030, 0.1651, 0.4229, 0.1090], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,210][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.7155, 0.2693, 0.0080, 0.0072], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,212][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.7108, 0.2571, 0.0143, 0.0178], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,213][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.6211, 0.3347, 0.0157, 0.0285], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,214][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Megan] are: tensor([0.3290, 0.2387, 0.0896, 0.1364, 0.2062], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,216][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Megan] are: tensor([0.0136, 0.0230, 0.0914, 0.7523, 0.1196], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,216][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Megan] are: tensor([0.1837, 0.1103, 0.2470, 0.0745, 0.3844], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,217][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Megan] are: tensor([0.5256, 0.2725, 0.0452, 0.1029, 0.0537], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,217][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Megan] are: tensor([0.1369, 0.0883, 0.2228, 0.0889, 0.4632], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,217][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Megan] are: tensor([0.1708, 0.1494, 0.2790, 0.2271, 0.1737], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,217][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Megan] are: tensor([0.0908, 0.0756, 0.3877, 0.1118, 0.3341], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,218][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Megan] are: tensor([0.2191, 0.1436, 0.1680, 0.0896, 0.3796], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,218][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Megan] are: tensor([0.2229, 0.1497, 0.1939, 0.1144, 0.3191], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,218][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Megan] are: tensor([0.4990, 0.2992, 0.0322, 0.0478, 0.1218], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,219][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Megan] are: tensor([0.4160, 0.2553, 0.0500, 0.0588, 0.2199], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,219][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Megan] are: tensor([0.3525, 0.2565, 0.0724, 0.0883, 0.2303], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,220][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.4221, 0.2109, 0.0146, 0.0235, 0.0985, 0.2304], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,221][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([1.6683e-04, 5.0930e-04, 3.4085e-03, 2.1595e-02, 2.9917e-03, 9.7133e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,222][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0628, 0.0462, 0.3803, 0.0674, 0.4041, 0.0391], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,223][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.4892, 0.1873, 0.0343, 0.0483, 0.0714, 0.1695], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,225][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0362, 0.0265, 0.3529, 0.0668, 0.4678, 0.0499], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,226][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.3833, 0.2690, 0.0263, 0.0582, 0.1496, 0.1136], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,227][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0555, 0.0501, 0.3330, 0.0599, 0.4025, 0.0990], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,228][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0982, 0.0660, 0.2067, 0.1130, 0.4248, 0.0914], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,230][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.2221, 0.1360, 0.1028, 0.0671, 0.4030, 0.0690], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,231][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.5541, 0.2642, 0.0112, 0.0195, 0.1334, 0.0176], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,233][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.4530, 0.2351, 0.0265, 0.0351, 0.2176, 0.0328], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,234][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.4548, 0.2520, 0.0283, 0.0472, 0.1774, 0.0403], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,236][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1549, 0.1368, 0.1088, 0.1135, 0.1363, 0.1958, 0.1540],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,237][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0022, 0.0054, 0.2227, 0.1720, 0.0602, 0.5259, 0.0117],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,238][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0426, 0.0454, 0.4114, 0.1409, 0.1789, 0.1260, 0.0547],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,239][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.3817, 0.1886, 0.0201, 0.0457, 0.0524, 0.1665, 0.1450],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,241][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0420, 0.0445, 0.3520, 0.1385, 0.2223, 0.1494, 0.0513],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,242][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0964, 0.1004, 0.2145, 0.1728, 0.1470, 0.1543, 0.1145],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,243][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0205, 0.0271, 0.4491, 0.1441, 0.1265, 0.1989, 0.0338],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,245][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0713, 0.0750, 0.2846, 0.1418, 0.1915, 0.1636, 0.0723],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,246][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0798, 0.0785, 0.2440, 0.1682, 0.1958, 0.1426, 0.0910],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,248][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2676, 0.2010, 0.0737, 0.0644, 0.1573, 0.0644, 0.1715],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,248][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1812, 0.1655, 0.1114, 0.1109, 0.1702, 0.1033, 0.1574],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,248][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.2455, 0.1941, 0.0562, 0.0754, 0.1701, 0.0616, 0.1971],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,249][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.1064, 0.0990, 0.1059, 0.1103, 0.1063, 0.2225, 0.1195, 0.1300],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,249][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0012, 0.0031, 0.0833, 0.1543, 0.0345, 0.6896, 0.0089, 0.0251],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,249][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0496, 0.0510, 0.3547, 0.1210, 0.1873, 0.1086, 0.0621, 0.0658],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,250][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.3502, 0.1797, 0.0223, 0.0556, 0.0402, 0.1068, 0.1493, 0.0960],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,250][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0409, 0.0443, 0.2986, 0.1376, 0.2075, 0.1540, 0.0531, 0.0640],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,250][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0819, 0.0872, 0.1900, 0.1671, 0.1275, 0.1365, 0.1055, 0.1042],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,251][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0282, 0.0369, 0.3205, 0.1506, 0.1292, 0.2333, 0.0468, 0.0545],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,251][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0776, 0.0749, 0.2144, 0.1238, 0.1766, 0.1598, 0.0724, 0.1005],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,253][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0671, 0.0667, 0.2430, 0.1426, 0.1772, 0.1346, 0.0811, 0.0878],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,254][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.2151, 0.1698, 0.0732, 0.0712, 0.1312, 0.0606, 0.1431, 0.1358],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,255][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.1645, 0.1437, 0.0901, 0.1051, 0.1471, 0.0888, 0.1371, 0.1236],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,257][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.1812, 0.1592, 0.0689, 0.0795, 0.1469, 0.0649, 0.1504, 0.1489],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,258][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0969, 0.0929, 0.1195, 0.1050, 0.1048, 0.1606, 0.1077, 0.1107, 0.1018],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,259][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0030, 0.0066, 0.2604, 0.1931, 0.0668, 0.4240, 0.0137, 0.0234, 0.0091],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,260][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0398, 0.0444, 0.3277, 0.1440, 0.1483, 0.1264, 0.0562, 0.0624, 0.0507],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,262][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.1599, 0.1301, 0.0341, 0.0834, 0.0526, 0.1178, 0.1499, 0.1349, 0.1374],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,263][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0349, 0.0404, 0.3031, 0.1492, 0.1621, 0.1551, 0.0508, 0.0604, 0.0440],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,264][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0609, 0.0714, 0.2123, 0.1606, 0.1092, 0.1393, 0.0837, 0.0832, 0.0794],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,266][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0236, 0.0319, 0.3561, 0.1628, 0.1038, 0.1941, 0.0418, 0.0508, 0.0350],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,267][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0597, 0.0640, 0.2353, 0.1349, 0.1449, 0.1412, 0.0656, 0.0860, 0.0685],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,269][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0560, 0.0612, 0.2244, 0.1595, 0.1432, 0.1379, 0.0732, 0.0790, 0.0656],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,270][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.1670, 0.1373, 0.0687, 0.0643, 0.1161, 0.0571, 0.1242, 0.1225, 0.1428],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,271][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.1306, 0.1225, 0.0871, 0.1016, 0.1206, 0.0858, 0.1190, 0.1123, 0.1205],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,273][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.1464, 0.1309, 0.0652, 0.0796, 0.1232, 0.0659, 0.1304, 0.1202, 0.1383],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,274][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0964, 0.0908, 0.1060, 0.0881, 0.0971, 0.1310, 0.0995, 0.1021, 0.0969,
        0.0921], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,276][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0047, 0.0099, 0.3465, 0.1941, 0.0889, 0.2953, 0.0158, 0.0255, 0.0116,
        0.0077], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,277][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0435, 0.0465, 0.3045, 0.1249, 0.1381, 0.1179, 0.0575, 0.0635, 0.0542,
        0.0494], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,279][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1524, 0.1078, 0.0326, 0.0472, 0.0544, 0.1216, 0.1283, 0.1045, 0.1405,
        0.1108], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,279][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0377, 0.0419, 0.2962, 0.1323, 0.1606, 0.1345, 0.0501, 0.0581, 0.0448,
        0.0437], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,280][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0551, 0.0632, 0.2210, 0.1497, 0.1054, 0.1253, 0.0735, 0.0731, 0.0698,
        0.0639], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,280][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0227, 0.0311, 0.3531, 0.1605, 0.1010, 0.1790, 0.0401, 0.0466, 0.0338,
        0.0321], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,280][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0564, 0.0606, 0.2326, 0.1202, 0.1390, 0.1294, 0.0601, 0.0771, 0.0643,
        0.0603], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,281][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0580, 0.0609, 0.2036, 0.1435, 0.1388, 0.1191, 0.0708, 0.0769, 0.0651,
        0.0633], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,281][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1482, 0.1201, 0.0616, 0.0529, 0.1003, 0.0496, 0.1079, 0.1083, 0.1257,
        0.1254], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,281][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1134, 0.1090, 0.0800, 0.0851, 0.1091, 0.0734, 0.1046, 0.1032, 0.1080,
        0.1142], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,282][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1391, 0.1208, 0.0455, 0.0597, 0.1037, 0.0518, 0.1177, 0.1092, 0.1252,
        0.1271], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,282][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3149, 0.1031, 0.0036, 0.0061, 0.0411, 0.0321, 0.0964, 0.1205, 0.1463,
        0.1267, 0.0092], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,284][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0005, 0.0017, 0.0324, 0.1520, 0.0247, 0.4602, 0.0082, 0.0276, 0.0037,
        0.0009, 0.2883], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,285][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0951, 0.0427, 0.1579, 0.0126, 0.2744, 0.0190, 0.0488, 0.0613, 0.0680,
        0.0638, 0.1566], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,287][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3016, 0.0956, 0.0054, 0.0069, 0.0202, 0.0745, 0.1252, 0.0659, 0.1885,
        0.1118, 0.0045], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,288][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0624, 0.0267, 0.0740, 0.0110, 0.2758, 0.0179, 0.0279, 0.0322, 0.0347,
        0.0408, 0.3966], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,289][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1617, 0.1023, 0.0236, 0.0300, 0.0915, 0.0367, 0.1219, 0.1249, 0.1374,
        0.1221, 0.0478], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,291][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0723, 0.0470, 0.0933, 0.0175, 0.2329, 0.0404, 0.0440, 0.0672, 0.0675,
        0.0686, 0.2493], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,292][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1551, 0.0703, 0.0335, 0.0173, 0.2360, 0.0220, 0.0513, 0.0689, 0.0882,
        0.0949, 0.1625], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,294][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2035, 0.0826, 0.0363, 0.0102, 0.1937, 0.0123, 0.0850, 0.0917, 0.1068,
        0.1119, 0.0660], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,295][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.3632, 0.1257, 0.0032, 0.0027, 0.0495, 0.0030, 0.0735, 0.0718, 0.1465,
        0.1571, 0.0038], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,296][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.3212, 0.1141, 0.0058, 0.0077, 0.1044, 0.0067, 0.0791, 0.0767, 0.1181,
        0.1480, 0.0181], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,298][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.3068, 0.1344, 0.0019, 0.0038, 0.0522, 0.0022, 0.0929, 0.0945, 0.1366,
        0.1658, 0.0089], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,299][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0663, 0.0706, 0.1113, 0.0945, 0.0823, 0.1163, 0.0792, 0.0765, 0.0712,
        0.0695, 0.0934, 0.0690], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,301][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0038, 0.0081, 0.3111, 0.1681, 0.0787, 0.2331, 0.0123, 0.0186, 0.0089,
        0.0063, 0.1454, 0.0056], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,302][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0276, 0.0332, 0.2446, 0.1221, 0.0986, 0.1108, 0.0410, 0.0465, 0.0372,
        0.0344, 0.1711, 0.0330], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,304][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0863, 0.0929, 0.0545, 0.0731, 0.0633, 0.1084, 0.1122, 0.0932, 0.0908,
        0.0915, 0.0536, 0.0803], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,305][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0230, 0.0280, 0.2257, 0.1106, 0.1020, 0.1146, 0.0347, 0.0413, 0.0300,
        0.0290, 0.2338, 0.0272], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,306][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0351, 0.0456, 0.2149, 0.1425, 0.0816, 0.1217, 0.0530, 0.0524, 0.0481,
        0.0437, 0.1198, 0.0415], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,308][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0136, 0.0203, 0.2673, 0.1422, 0.0635, 0.1597, 0.0274, 0.0313, 0.0216,
        0.0204, 0.2144, 0.0184], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,309][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0424, 0.0482, 0.1892, 0.1015, 0.0988, 0.1153, 0.0490, 0.0640, 0.0508,
        0.0469, 0.1461, 0.0478], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,310][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0361, 0.0428, 0.1718, 0.1272, 0.0960, 0.1147, 0.0500, 0.0549, 0.0444,
        0.0432, 0.1778, 0.0411], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,311][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.1055, 0.0947, 0.0659, 0.0588, 0.0853, 0.0569, 0.0894, 0.0900, 0.0976,
        0.0968, 0.0572, 0.1018], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,311][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0777, 0.0833, 0.0839, 0.0863, 0.0862, 0.0768, 0.0824, 0.0827, 0.0814,
        0.0844, 0.0924, 0.0823], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,311][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.1037, 0.0954, 0.0489, 0.0622, 0.0884, 0.0538, 0.0955, 0.0885, 0.1002,
        0.0995, 0.0627, 0.1013], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,312][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Megan] are: tensor([0.0766, 0.0700, 0.0633, 0.0708, 0.0744, 0.1111, 0.0817, 0.0801, 0.0763,
        0.0731, 0.0731, 0.0731, 0.0764], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,312][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Megan] are: tensor([0.0043, 0.0088, 0.1574, 0.1859, 0.0695, 0.3570, 0.0184, 0.0259, 0.0113,
        0.0068, 0.1348, 0.0059, 0.0139], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,312][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Megan] are: tensor([0.0510, 0.0446, 0.1594, 0.0663, 0.1209, 0.0683, 0.0522, 0.0562, 0.0531,
        0.0510, 0.1491, 0.0530, 0.0749], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,313][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Megan] are: tensor([0.1254, 0.0843, 0.0214, 0.0430, 0.0205, 0.0876, 0.1057, 0.0984, 0.1488,
        0.0906, 0.0313, 0.1107, 0.0322], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,313][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Megan] are: tensor([0.0447, 0.0395, 0.1198, 0.0626, 0.1295, 0.0724, 0.0460, 0.0521, 0.0448,
        0.0450, 0.2200, 0.0459, 0.0777], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,314][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Megan] are: tensor([0.0506, 0.0560, 0.1582, 0.1070, 0.0790, 0.1095, 0.0651, 0.0614, 0.0593,
        0.0549, 0.0897, 0.0541, 0.0552], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,315][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Megan] are: tensor([0.0316, 0.0356, 0.1607, 0.0872, 0.0929, 0.1155, 0.0433, 0.0514, 0.0405,
        0.0393, 0.2068, 0.0378, 0.0573], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,317][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Megan] are: tensor([0.0678, 0.0597, 0.0935, 0.0610, 0.1110, 0.0670, 0.0571, 0.0712, 0.0647,
        0.0626, 0.1300, 0.0664, 0.0879], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,318][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Megan] are: tensor([0.0589, 0.0547, 0.1099, 0.0747, 0.1057, 0.0695, 0.0626, 0.0634, 0.0594,
        0.0597, 0.1403, 0.0605, 0.0807], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,320][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Megan] are: tensor([0.1238, 0.0966, 0.0402, 0.0383, 0.0655, 0.0348, 0.0853, 0.0796, 0.0995,
        0.1008, 0.0377, 0.1092, 0.0888], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,321][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Megan] are: tensor([0.0974, 0.0868, 0.0494, 0.0542, 0.0860, 0.0465, 0.0807, 0.0779, 0.0841,
        0.0909, 0.0626, 0.0910, 0.0924], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,322][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Megan] are: tensor([0.1080, 0.0914, 0.0351, 0.0438, 0.0783, 0.0379, 0.0879, 0.0788, 0.0947,
        0.0983, 0.0508, 0.0990, 0.0961], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,324][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.2987, 0.0700, 0.0010, 0.0014, 0.0243, 0.0147, 0.0736, 0.1065, 0.1233,
        0.0991, 0.0023, 0.1098, 0.0742, 0.0011], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,325][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([1.2239e-04, 4.3533e-04, 1.3734e-02, 5.2616e-02, 6.9263e-03, 5.4313e-01,
        2.4237e-03, 9.4692e-03, 1.0506e-03, 2.5341e-04, 1.4574e-01, 1.8115e-04,
        8.5437e-04, 2.2306e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,326][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0784, 0.0268, 0.0365, 0.0049, 0.2291, 0.0079, 0.0329, 0.0334, 0.0422,
        0.0438, 0.0910, 0.0515, 0.1170, 0.2047], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,327][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.1637, 0.0571, 0.0081, 0.0160, 0.0197, 0.1038, 0.1399, 0.0690, 0.1337,
        0.0860, 0.0135, 0.1219, 0.0358, 0.0317], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,329][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0422, 0.0120, 0.0082, 0.0025, 0.1156, 0.0035, 0.0131, 0.0141, 0.0178,
        0.0225, 0.1560, 0.0254, 0.0675, 0.4996], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,330][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.1944, 0.0926, 0.0031, 0.0069, 0.0369, 0.0068, 0.0900, 0.0716, 0.1297,
        0.1094, 0.0119, 0.1506, 0.0898, 0.0062], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,332][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0441, 0.0194, 0.0140, 0.0020, 0.0997, 0.0059, 0.0160, 0.0199, 0.0290,
        0.0313, 0.0526, 0.0366, 0.0745, 0.5549], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,333][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.1951, 0.0544, 0.0033, 0.0036, 0.1517, 0.0048, 0.0390, 0.0458, 0.0758,
        0.0902, 0.0500, 0.1022, 0.1415, 0.0427], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,335][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.1776, 0.0582, 0.0099, 0.0030, 0.1019, 0.0036, 0.0528, 0.0520, 0.0791,
        0.0919, 0.0389, 0.1186, 0.1598, 0.0527], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,336][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([3.1853e-01, 8.5545e-02, 5.2890e-04, 7.6197e-04, 2.9848e-02, 1.3065e-03,
        4.9630e-02, 3.9693e-02, 1.0331e-01, 1.1325e-01, 1.0550e-03, 1.6300e-01,
        9.3353e-02, 1.9315e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,337][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.3258, 0.0741, 0.0009, 0.0013, 0.0590, 0.0019, 0.0522, 0.0455, 0.0892,
        0.1050, 0.0035, 0.1283, 0.1124, 0.0010], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,339][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.2371, 0.0871, 0.0010, 0.0018, 0.0385, 0.0014, 0.0695, 0.0663, 0.1040,
        0.1243, 0.0060, 0.1476, 0.1127, 0.0028], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,340][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2746, 0.0723, 0.0011, 0.0013, 0.0264, 0.0186, 0.0717, 0.1005, 0.1328,
        0.0963, 0.0023, 0.1159, 0.0830, 0.0014, 0.0021], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,341][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.0775e-04, 7.1850e-04, 4.0632e-02, 7.9955e-02, 1.5733e-02, 3.7798e-01,
        5.8119e-03, 1.8725e-02, 2.2557e-03, 5.1003e-04, 1.2920e-01, 3.0963e-04,
        1.6643e-03, 2.9559e-01, 3.0714e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,342][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0540, 0.0179, 0.0284, 0.0025, 0.1187, 0.0051, 0.0207, 0.0259, 0.0320,
        0.0303, 0.0456, 0.0379, 0.0761, 0.3732, 0.1318], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,342][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1688, 0.0678, 0.0053, 0.0136, 0.0182, 0.0953, 0.0938, 0.0696, 0.1459,
        0.0854, 0.0094, 0.1174, 0.0307, 0.0371, 0.0417], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,343][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0235, 0.0076, 0.0065, 0.0016, 0.0695, 0.0033, 0.0077, 0.0087, 0.0101,
        0.0124, 0.0760, 0.0146, 0.0368, 0.4376, 0.2841], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,343][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1586, 0.0803, 0.0075, 0.0093, 0.0488, 0.0114, 0.0925, 0.0912, 0.1248,
        0.1043, 0.0194, 0.1318, 0.0925, 0.0163, 0.0114], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,343][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0087, 0.0043, 0.0020, 0.0006, 0.0169, 0.0027, 0.0040, 0.0064, 0.0073,
        0.0077, 0.0155, 0.0078, 0.0162, 0.5727, 0.3271], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,344][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1185, 0.0430, 0.0075, 0.0042, 0.1278, 0.0064, 0.0270, 0.0357, 0.0553,
        0.0632, 0.0585, 0.0697, 0.1112, 0.1419, 0.1302], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,344][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1917, 0.0541, 0.0069, 0.0022, 0.1167, 0.0023, 0.0524, 0.0581, 0.0830,
        0.0808, 0.0177, 0.1189, 0.1552, 0.0321, 0.0278], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,345][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.3068, 0.0866, 0.0010, 0.0010, 0.0280, 0.0014, 0.0503, 0.0420, 0.1066,
        0.1172, 0.0015, 0.1658, 0.0909, 0.0003, 0.0006], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,345][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.3238, 0.0733, 0.0011, 0.0015, 0.0526, 0.0018, 0.0490, 0.0451, 0.0893,
        0.1095, 0.0048, 0.1304, 0.1139, 0.0012, 0.0028], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,345][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.2727, 0.0910, 0.0003, 0.0007, 0.0221, 0.0006, 0.0605, 0.0631, 0.1036,
        0.1264, 0.0027, 0.1539, 0.0989, 0.0006, 0.0030], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,346][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:25,348][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 9336],
        [10596],
        [37982],
        [20258],
        [25057],
        [14312],
        [11251],
        [ 9824],
        [10872],
        [ 9756],
        [10298],
        [10117],
        [18382],
        [13262],
        [ 7608]], device='cuda:0')
[2024-07-24 10:29:25,349][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 8988],
        [11527],
        [39520],
        [20678],
        [27186],
        [13876],
        [ 9535],
        [ 7964],
        [10534],
        [ 9292],
        [10490],
        [ 9882],
        [21040],
        [13159],
        [ 7474]], device='cuda:0')
[2024-07-24 10:29:25,351][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[3357],
        [2029],
        [1840],
        [1996],
        [1999],
        [2390],
        [2600],
        [3682],
        [4073],
        [3899],
        [3414],
        [3384],
        [3081],
        [3020],
        [3330]], device='cuda:0')
[2024-07-24 10:29:25,352][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[25719],
        [25193],
        [27072],
        [27450],
        [28296],
        [27920],
        [28094],
        [28086],
        [28431],
        [28597],
        [28298],
        [28532],
        [28656],
        [28377],
        [27970]], device='cuda:0')
[2024-07-24 10:29:25,353][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[7426],
        [9799],
        [8203],
        [7271],
        [7862],
        [7342],
        [6991],
        [6299],
        [6049],
        [6051],
        [6185],
        [6141],
        [6478],
        [6576],
        [6817]], device='cuda:0')
[2024-07-24 10:29:25,355][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[13514],
        [14053],
        [24011],
        [28027],
        [24103],
        [27782],
        [28116],
        [26814],
        [26476],
        [25550],
        [23937],
        [22981],
        [21793],
        [23304],
        [20328]], device='cuda:0')
[2024-07-24 10:29:25,356][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[21384],
        [17236],
        [19902],
        [24531],
        [23939],
        [23277],
        [23088],
        [22086],
        [22062],
        [21639],
        [21783],
        [21315],
        [21867],
        [21994],
        [22695]], device='cuda:0')
[2024-07-24 10:29:25,357][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[17173],
        [ 9130],
        [ 8169],
        [ 7935],
        [ 8024],
        [ 7737],
        [ 7502],
        [ 7417],
        [ 7390],
        [ 7309],
        [ 7261],
        [ 7339],
        [ 7373],
        [ 7270],
        [ 7164]], device='cuda:0')
[2024-07-24 10:29:25,359][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[24543],
        [22393],
        [21783],
        [23023],
        [28577],
        [22267],
        [21738],
        [25384],
        [25914],
        [23803],
        [24561],
        [26501],
        [32682],
        [31353],
        [27161]], device='cuda:0')
[2024-07-24 10:29:25,360][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 2230],
        [ 3067],
        [ 6370],
        [15672],
        [19500],
        [23175],
        [26385],
        [27127],
        [26994],
        [26577],
        [26000],
        [27534],
        [26967],
        [26684],
        [27735]], device='cuda:0')
[2024-07-24 10:29:25,361][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[35203],
        [32120],
        [31219],
        [30449],
        [29930],
        [29665],
        [29625],
        [29880],
        [29855],
        [29651],
        [29244],
        [29163],
        [29145],
        [29090],
        [28629]], device='cuda:0')
[2024-07-24 10:29:25,363][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[46003],
        [45584],
        [45968],
        [45316],
        [45936],
        [45918],
        [46831],
        [46640],
        [46615],
        [46519],
        [46154],
        [46051],
        [45903],
        [46608],
        [46779]], device='cuda:0')
[2024-07-24 10:29:25,364][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 2377],
        [ 1760],
        [ 6029],
        [10492],
        [14550],
        [19503],
        [19655],
        [17696],
        [15936],
        [15251],
        [13166],
        [12834],
        [12008],
        [12152],
        [11441]], device='cuda:0')
[2024-07-24 10:29:25,366][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[34792],
        [30656],
        [43883],
        [29730],
        [34045],
        [20134],
        [25448],
        [17460],
        [21678],
        [21742],
        [21493],
        [20885],
        [24241],
        [19886],
        [18942]], device='cuda:0')
[2024-07-24 10:29:25,367][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[18047],
        [ 4000],
        [ 6668],
        [10645],
        [17351],
        [13567],
        [18155],
        [21460],
        [ 7843],
        [ 9496],
        [10188],
        [ 8548],
        [ 9401],
        [ 6420],
        [11358]], device='cuda:0')
[2024-07-24 10:29:25,368][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 9104],
        [10644],
        [10219],
        [10954],
        [17977],
        [18709],
        [19575],
        [19616],
        [19304],
        [18989],
        [15908],
        [18742],
        [18803],
        [15634],
        [15975]], device='cuda:0')
[2024-07-24 10:29:25,370][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[13116],
        [ 8445],
        [ 8930],
        [19782],
        [18691],
        [17959],
        [18707],
        [17852],
        [18706],
        [19230],
        [15740],
        [17878],
        [16496],
        [14399],
        [13397]], device='cuda:0')
[2024-07-24 10:29:25,371][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 4755],
        [ 7105],
        [11231],
        [10135],
        [11768],
        [11167],
        [11627],
        [11626],
        [11671],
        [11678],
        [13580],
        [13874],
        [14101],
        [17317],
        [19894]], device='cuda:0')
[2024-07-24 10:29:25,372][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[11250],
        [10799],
        [10090],
        [11351],
        [ 8265],
        [ 6190],
        [ 7443],
        [ 7296],
        [ 7127],
        [ 7140],
        [ 8335],
        [ 7133],
        [ 7522],
        [ 7633],
        [ 7466]], device='cuda:0')
[2024-07-24 10:29:25,374][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[20053],
        [26301],
        [20175],
        [22382],
        [24142],
        [23834],
        [24368],
        [24549],
        [24251],
        [24109],
        [20586],
        [19327],
        [20898],
        [20562],
        [17327]], device='cuda:0')
[2024-07-24 10:29:25,375][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[19823],
        [18957],
        [17732],
        [19709],
        [21874],
        [16023],
        [21305],
        [21214],
        [21020],
        [20932],
        [16155],
        [21947],
        [20538],
        [15243],
        [14701]], device='cuda:0')
[2024-07-24 10:29:25,377][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[30762],
        [37151],
        [21920],
        [18517],
        [22101],
        [22621],
        [23727],
        [26064],
        [25694],
        [25783],
        [33665],
        [29231],
        [32233],
        [37257],
        [33631]], device='cuda:0')
[2024-07-24 10:29:25,377][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[34959],
        [37983],
        [39765],
        [33096],
        [32102],
        [30405],
        [30804],
        [30317],
        [30775],
        [31010],
        [29575],
        [30656],
        [29956],
        [33116],
        [31742]], device='cuda:0')
[2024-07-24 10:29:25,378][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[26310],
        [29994],
        [31626],
        [19187],
        [26991],
        [27349],
        [21408],
        [21820],
        [22783],
        [24625],
        [31577],
        [22434],
        [28029],
        [31939],
        [31665]], device='cuda:0')
[2024-07-24 10:29:25,379][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[37915],
        [37337],
        [37549],
        [37401],
        [36480],
        [37098],
        [34344],
        [34713],
        [34948],
        [35563],
        [37495],
        [34203],
        [35822],
        [37438],
        [37447]], device='cuda:0')
[2024-07-24 10:29:25,381][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[34128],
        [34565],
        [34392],
        [34274],
        [34543],
        [35132],
        [33152],
        [35151],
        [35838],
        [36231],
        [35501],
        [34882],
        [36555],
        [34292],
        [34393]], device='cuda:0')
[2024-07-24 10:29:25,382][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[12134],
        [16142],
        [18840],
        [21621],
        [39609],
        [36741],
        [38008],
        [37843],
        [37427],
        [36763],
        [27685],
        [36699],
        [36739],
        [27287],
        [24974]], device='cuda:0')
[2024-07-24 10:29:25,383][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[21772],
        [20748],
        [22147],
        [23298],
        [19150],
        [21278],
        [20739],
        [19836],
        [19678],
        [19522],
        [19017],
        [19930],
        [18177],
        [18362],
        [19708]], device='cuda:0')
[2024-07-24 10:29:25,385][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 9142],
        [11282],
        [ 9065],
        [ 9321],
        [ 6970],
        [ 8124],
        [ 7238],
        [ 7073],
        [11461],
        [ 9941],
        [ 7512],
        [10401],
        [ 7984],
        [ 7807],
        [ 7287]], device='cuda:0')
[2024-07-24 10:29:25,386][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[25340],
        [25340],
        [25340],
        [25340],
        [25340],
        [25340],
        [25340],
        [25340],
        [25340],
        [25340],
        [25340],
        [25340],
        [25340],
        [25340],
        [25340]], device='cuda:0')
[2024-07-24 10:29:25,419][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:25,420][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,421][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,423][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,424][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,425][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,426][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,427][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,429][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,430][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,431][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,432][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,433][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,435][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.6540, 0.3460], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,436][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0104, 0.9896], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,437][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4505, 0.5495], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,439][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1591, 0.8409], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,439][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4786, 0.5214], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,440][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1733, 0.8267], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,440][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4759, 0.5241], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,440][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9800, 0.0200], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,441][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.5105, 0.4895], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,441][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1456, 0.8544], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,441][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4592, 0.5408], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,442][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.4545, 0.5455], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,442][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Jennifer] are: tensor([9.2547e-01, 7.4397e-02, 1.2779e-04], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,442][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Jennifer] are: tensor([0.0035, 0.0867, 0.9098], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,443][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Jennifer] are: tensor([0.4196, 0.5140, 0.0664], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,444][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Jennifer] are: tensor([0.0902, 0.4152, 0.4946], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,446][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Jennifer] are: tensor([0.1440, 0.3146, 0.5414], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,447][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Jennifer] are: tensor([0.0947, 0.2941, 0.6113], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,448][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Jennifer] are: tensor([0.5766, 0.2840, 0.1394], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,449][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Jennifer] are: tensor([0.4447, 0.0311, 0.5242], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,451][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Jennifer] are: tensor([0.8474, 0.1476, 0.0050], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,452][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Jennifer] are: tensor([0.8910, 0.0833, 0.0256], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,453][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Jennifer] are: tensor([0.7694, 0.2123, 0.0183], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,455][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Jennifer] are: tensor([0.0227, 0.0207, 0.9566], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,456][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([9.1038e-01, 8.9210e-02, 2.0650e-04, 2.0240e-04], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,457][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([4.7736e-04, 3.2336e-02, 5.3699e-01, 4.3020e-01], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,458][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4715, 0.4244, 0.0521, 0.0519], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,460][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0583, 0.2684, 0.3360, 0.3374], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,461][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2040, 0.2319, 0.2747, 0.2893], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,462][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0579, 0.1732, 0.4057, 0.3632], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,464][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1176, 0.1485, 0.1727, 0.5612], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,465][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2796, 0.0169, 0.3748, 0.3286], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,467][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.6248, 0.2004, 0.1651, 0.0098], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,468][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.7429, 0.1292, 0.0203, 0.1077], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,470][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.7617, 0.2063, 0.0209, 0.0111], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,471][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0082, 0.0082, 0.9135, 0.0700], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,471][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Megan] are: tensor([8.7793e-01, 1.1668e-01, 5.0718e-04, 5.8191e-04, 4.2995e-03],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,472][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Megan] are: tensor([0.0004, 0.0273, 0.4267, 0.4228, 0.1228], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,472][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Megan] are: tensor([0.1327, 0.2124, 0.1715, 0.3296, 0.1538], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,472][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Megan] are: tensor([0.0510, 0.2096, 0.2571, 0.2572, 0.2252], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,473][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Megan] are: tensor([0.1057, 0.1450, 0.2128, 0.2097, 0.3269], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,473][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Megan] are: tensor([0.0401, 0.1372, 0.2950, 0.2663, 0.2614], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,473][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Megan] are: tensor([0.3221, 0.1516, 0.0961, 0.0353, 0.3949], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,474][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Megan] are: tensor([0.3622, 0.0067, 0.3119, 0.2653, 0.0539], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,475][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Megan] are: tensor([0.3479, 0.1608, 0.0931, 0.0275, 0.3708], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,476][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Megan] are: tensor([0.7147, 0.0467, 0.0080, 0.0671, 0.1636], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,478][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Megan] are: tensor([0.3072, 0.2747, 0.1089, 0.1350, 0.1742], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,479][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Megan] are: tensor([0.0370, 0.0381, 0.5649, 0.1392, 0.2208], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,480][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ had] are: tensor([8.6545e-01, 1.2701e-01, 5.8713e-04, 7.6420e-04, 5.6682e-03, 5.2848e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,481][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0005, 0.0242, 0.3224, 0.3012, 0.1028, 0.2489], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,483][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.2188, 0.3066, 0.0833, 0.1555, 0.1504, 0.0853], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,484][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0401, 0.1670, 0.2114, 0.2090, 0.1861, 0.1864], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,486][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0922, 0.1237, 0.1846, 0.2151, 0.2103, 0.1741], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,487][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0365, 0.1069, 0.2294, 0.2093, 0.2051, 0.2128], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,488][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0438, 0.0621, 0.1000, 0.0963, 0.2137, 0.4840], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,490][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.2118, 0.0118, 0.2625, 0.2376, 0.0667, 0.2096], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,491][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1424, 0.0769, 0.1693, 0.0549, 0.5531, 0.0034], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,493][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.7608, 0.0445, 0.0052, 0.0430, 0.0875, 0.0589], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,494][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.4203, 0.2374, 0.0565, 0.0869, 0.1198, 0.0792], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,496][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0047, 0.0060, 0.7505, 0.0813, 0.1030, 0.0545], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,497][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.6282, 0.2298, 0.0131, 0.0127, 0.0392, 0.0094, 0.0676],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,498][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([1.2911e-04, 1.5754e-02, 3.2846e-01, 2.8980e-01, 8.5156e-02, 2.2076e-01,
        5.9949e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,499][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1011, 0.1366, 0.1395, 0.1754, 0.1484, 0.1491, 0.1498],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,501][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0269, 0.1372, 0.1852, 0.1798, 0.1627, 0.1684, 0.1396],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,502][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1333, 0.1207, 0.1374, 0.1495, 0.1645, 0.1260, 0.1687],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,502][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0221, 0.0868, 0.2084, 0.1833, 0.1812, 0.1919, 0.1264],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,503][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1098, 0.1065, 0.1108, 0.0901, 0.2429, 0.1474, 0.1924],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,503][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.2670, 0.0015, 0.2736, 0.2325, 0.0244, 0.2008, 0.0003],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,503][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0399, 0.0425, 0.4499, 0.1934, 0.1662, 0.0711, 0.0371],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,504][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.4127, 0.1573, 0.0221, 0.0589, 0.1049, 0.0859, 0.1582],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,504][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1849, 0.1472, 0.1224, 0.1143, 0.1179, 0.1790, 0.1343],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,504][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0191, 0.0254, 0.5473, 0.1387, 0.1255, 0.1166, 0.0273],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,505][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.6407, 0.2172, 0.0087, 0.0092, 0.0252, 0.0067, 0.0590, 0.0333],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,505][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ long] are: tensor([2.4103e-04, 1.5915e-02, 2.8199e-01, 2.5255e-01, 8.7740e-02, 2.0349e-01,
        6.4434e-02, 9.3638e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,505][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0923, 0.1283, 0.1239, 0.1370, 0.1257, 0.1118, 0.1379, 0.1430],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,506][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0265, 0.1190, 0.1555, 0.1522, 0.1364, 0.1426, 0.1234, 0.1444],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,508][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0799, 0.0734, 0.1382, 0.1597, 0.1512, 0.0993, 0.1633, 0.1351],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,509][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0196, 0.0745, 0.1808, 0.1654, 0.1545, 0.1702, 0.1127, 0.1223],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,510][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0995, 0.0954, 0.0857, 0.0913, 0.1626, 0.1624, 0.1373, 0.1659],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,512][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.3152, 0.0022, 0.2518, 0.2213, 0.0244, 0.1828, 0.0004, 0.0018],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,513][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0596, 0.0591, 0.3159, 0.1951, 0.1774, 0.0829, 0.0561, 0.0540],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,514][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.3568, 0.0587, 0.0103, 0.0622, 0.1137, 0.0636, 0.1746, 0.1601],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,516][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.1812, 0.1488, 0.0736, 0.0969, 0.1031, 0.1155, 0.1586, 0.1224],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,517][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0162, 0.0228, 0.4894, 0.1723, 0.1119, 0.1291, 0.0266, 0.0318],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,519][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.4212, 0.1960, 0.0220, 0.0227, 0.0524, 0.0172, 0.0778, 0.0555, 0.1351],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,520][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([5.6605e-05, 8.7089e-03, 2.9212e-01, 2.8923e-01, 6.7665e-02, 1.9942e-01,
        5.0602e-02, 8.7151e-02, 5.0396e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,521][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0722, 0.0955, 0.1271, 0.1146, 0.1335, 0.1239, 0.1124, 0.1236, 0.0973],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,523][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0207, 0.1078, 0.1401, 0.1387, 0.1183, 0.1225, 0.1097, 0.1316, 0.1107],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,524][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0576, 0.0647, 0.1258, 0.1378, 0.1498, 0.0995, 0.1594, 0.1422, 0.0631],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,525][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0078, 0.0632, 0.1862, 0.1637, 0.1502, 0.1649, 0.1018, 0.1178, 0.0443],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,527][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.1176, 0.1038, 0.0987, 0.0742, 0.1676, 0.1035, 0.1113, 0.0917, 0.1316],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,528][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.2872, 0.0033, 0.2644, 0.2153, 0.0328, 0.1916, 0.0009, 0.0032, 0.0013],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,530][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0700, 0.0692, 0.2621, 0.1536, 0.1602, 0.0883, 0.0645, 0.0635, 0.0686],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,531][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.1366, 0.1893, 0.0620, 0.0859, 0.1006, 0.1059, 0.1088, 0.0935, 0.1174],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,533][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0804, 0.0964, 0.1166, 0.1412, 0.0883, 0.1593, 0.1166, 0.1076, 0.0937],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,534][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0250, 0.0321, 0.4196, 0.1575, 0.1202, 0.1272, 0.0376, 0.0446, 0.0363],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,534][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3137, 0.1541, 0.0258, 0.0246, 0.0557, 0.0188, 0.0696, 0.0528, 0.1166,
        0.1684], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,535][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([1.2902e-05, 5.8540e-03, 3.2438e-01, 2.7548e-01, 5.8683e-02, 2.0688e-01,
        4.1515e-02, 8.2910e-02, 3.3995e-03, 8.7538e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,535][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0645, 0.0842, 0.1075, 0.1103, 0.1253, 0.1267, 0.1026, 0.1120, 0.0873,
        0.0795], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,536][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0218, 0.0950, 0.1270, 0.1247, 0.1098, 0.1161, 0.0972, 0.1181, 0.0981,
        0.0921], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,536][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1129, 0.0820, 0.0914, 0.0957, 0.1205, 0.0780, 0.1345, 0.1158, 0.0701,
        0.0991], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,536][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0069, 0.0440, 0.2020, 0.1635, 0.1531, 0.1807, 0.0920, 0.1103, 0.0325,
        0.0150], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,537][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0930, 0.0912, 0.0958, 0.0843, 0.1772, 0.0811, 0.0947, 0.0732, 0.0950,
        0.1146], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,538][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2297, 0.0094, 0.2527, 0.2153, 0.0567, 0.1963, 0.0039, 0.0105, 0.0053,
        0.0201], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,539][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0628, 0.0620, 0.2752, 0.1316, 0.1538, 0.0736, 0.0561, 0.0555, 0.0632,
        0.0662], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,541][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0698, 0.2060, 0.0986, 0.0804, 0.1010, 0.1253, 0.0796, 0.0768, 0.0766,
        0.0859], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,542][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0671, 0.0757, 0.1177, 0.1532, 0.0851, 0.1637, 0.0953, 0.0843, 0.0788,
        0.0790], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,543][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0295, 0.0357, 0.4061, 0.1270, 0.1286, 0.1124, 0.0387, 0.0460, 0.0405,
        0.0355], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,544][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([6.5770e-01, 9.4686e-02, 6.8245e-04, 7.1970e-04, 6.3527e-03, 5.9066e-04,
        1.9366e-02, 8.8937e-03, 6.4236e-02, 1.4524e-01, 1.5316e-03],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,546][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0003, 0.0154, 0.2299, 0.1934, 0.0722, 0.1720, 0.0578, 0.0858, 0.0111,
        0.0047, 0.1573], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,547][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1185, 0.1374, 0.0506, 0.0307, 0.0924, 0.0483, 0.1236, 0.1358, 0.1373,
        0.1100, 0.0155], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,549][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0193, 0.0862, 0.1056, 0.1072, 0.0971, 0.1019, 0.0905, 0.1066, 0.0882,
        0.0879, 0.1096], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,550][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0681, 0.0779, 0.0995, 0.1037, 0.1101, 0.0904, 0.1030, 0.1033, 0.0626,
        0.0761, 0.1052], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,551][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0196, 0.0628, 0.1404, 0.1246, 0.1267, 0.1299, 0.0912, 0.1001, 0.0502,
        0.0358, 0.1187], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,553][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0458, 0.0500, 0.0574, 0.1235, 0.1414, 0.0795, 0.0747, 0.0587, 0.0537,
        0.0771, 0.2383], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,554][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1942, 0.0086, 0.2006, 0.1771, 0.0514, 0.1598, 0.0037, 0.0091, 0.0051,
        0.0190, 0.1715], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,556][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1342, 0.0622, 0.1384, 0.0056, 0.3693, 0.0009, 0.0346, 0.0370, 0.0751,
        0.0927, 0.0500], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,557][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.3115, 0.0279, 0.0051, 0.0292, 0.0642, 0.0366, 0.1069, 0.1072, 0.1733,
        0.1279, 0.0101], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,559][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4630, 0.1118, 0.0150, 0.0113, 0.0427, 0.0305, 0.0607, 0.0423, 0.0916,
        0.1178, 0.0131], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,560][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0131, 0.0122, 0.5364, 0.0345, 0.1560, 0.0396, 0.0120, 0.0178, 0.0163,
        0.0134, 0.1486], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,562][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.1882, 0.1180, 0.0365, 0.0357, 0.0594, 0.0275, 0.0635, 0.0521, 0.0911,
        0.1235, 0.0448, 0.1598], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,563][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([5.1502e-06, 3.7654e-03, 2.5196e-01, 2.6055e-01, 3.5202e-02, 1.6611e-01,
        3.2942e-02, 6.0536e-02, 1.9608e-03, 5.7268e-04, 1.8637e-01, 1.5740e-05],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,564][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0530, 0.0685, 0.1007, 0.1023, 0.1043, 0.1091, 0.0829, 0.0904, 0.0712,
        0.0654, 0.0868, 0.0653], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,565][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0084, 0.0754, 0.1154, 0.1105, 0.0893, 0.0971, 0.0821, 0.1109, 0.0870,
        0.0758, 0.1135, 0.0346], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,565][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0744, 0.0693, 0.0858, 0.0897, 0.0937, 0.0777, 0.0992, 0.0984, 0.0643,
        0.0799, 0.0984, 0.0690], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,566][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0034, 0.0469, 0.1647, 0.1437, 0.1275, 0.1496, 0.0826, 0.1025, 0.0326,
        0.0177, 0.1248, 0.0041], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,566][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0861, 0.0809, 0.0745, 0.0621, 0.1288, 0.0631, 0.0715, 0.0670, 0.0842,
        0.0948, 0.1052, 0.0819], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,567][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.1030, 0.0217, 0.1798, 0.1589, 0.0736, 0.1431, 0.0157, 0.0272, 0.0157,
        0.0301, 0.1493, 0.0819], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,567][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0559, 0.0552, 0.1901, 0.1050, 0.1127, 0.0657, 0.0500, 0.0496, 0.0554,
        0.0585, 0.1363, 0.0656], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,567][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0163, 0.1665, 0.1503, 0.0657, 0.0634, 0.1015, 0.0355, 0.0372, 0.0271,
        0.0327, 0.2762, 0.0279], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,568][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0311, 0.0489, 0.1134, 0.1525, 0.0615, 0.1526, 0.0673, 0.0601, 0.0482,
        0.0485, 0.1726, 0.0433], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,568][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0230, 0.0295, 0.2960, 0.1212, 0.0930, 0.0989, 0.0335, 0.0391, 0.0332,
        0.0295, 0.1745, 0.0287], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,569][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Megan] are: tensor([0.3442, 0.1041, 0.0041, 0.0044, 0.0161, 0.0039, 0.0330, 0.0205, 0.0714,
        0.1233, 0.0073, 0.2057, 0.0621], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,570][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Megan] are: tensor([1.0520e-04, 1.0631e-02, 2.2082e-01, 2.2325e-01, 5.3714e-02, 1.6824e-01,
        4.7762e-02, 7.3392e-02, 7.3999e-03, 2.7692e-03, 1.7999e-01, 2.4284e-04,
        1.1679e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,572][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Megan] are: tensor([0.0461, 0.0658, 0.1060, 0.1227, 0.0857, 0.0996, 0.0780, 0.0804, 0.0630,
        0.0581, 0.0822, 0.0566, 0.0558], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,573][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Megan] are: tensor([0.0177, 0.0760, 0.0969, 0.0962, 0.0833, 0.0884, 0.0742, 0.0971, 0.0810,
        0.0733, 0.0987, 0.0464, 0.0709], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,575][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Megan] are: tensor([0.0470, 0.0505, 0.0763, 0.0751, 0.1251, 0.0590, 0.0847, 0.1001, 0.0480,
        0.0609, 0.0889, 0.0447, 0.1398], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,576][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Megan] are: tensor([0.0113, 0.0525, 0.1350, 0.1183, 0.1153, 0.1202, 0.0819, 0.0933, 0.0433,
        0.0279, 0.1121, 0.0123, 0.0766], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,577][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Megan] are: tensor([0.1062, 0.0635, 0.0523, 0.0206, 0.1489, 0.0373, 0.0580, 0.0550, 0.0679,
        0.0909, 0.0410, 0.0936, 0.1648], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,578][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Megan] are: tensor([3.1072e-01, 1.0957e-03, 1.6908e-01, 1.3763e-01, 1.4022e-02, 1.2358e-01,
        1.6879e-04, 8.6763e-04, 3.4119e-04, 3.9451e-03, 1.2090e-01, 1.1752e-01,
        1.1862e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,580][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Megan] are: tensor([0.0981, 0.0706, 0.0867, 0.0381, 0.1221, 0.0262, 0.0576, 0.0530, 0.0722,
        0.0807, 0.0802, 0.0997, 0.1149], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,581][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Megan] are: tensor([0.1098, 0.0606, 0.0301, 0.0616, 0.1017, 0.0780, 0.0897, 0.0841, 0.0953,
        0.0837, 0.0528, 0.0846, 0.0681], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,583][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Megan] are: tensor([0.0549, 0.0689, 0.0767, 0.1072, 0.0678, 0.1101, 0.0726, 0.0637, 0.0690,
        0.0702, 0.1147, 0.0611, 0.0633], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,584][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Megan] are: tensor([0.0261, 0.0295, 0.2634, 0.0909, 0.1037, 0.0910, 0.0334, 0.0392, 0.0341,
        0.0305, 0.1729, 0.0305, 0.0549], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,586][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.4932, 0.0710, 0.0005, 0.0006, 0.0043, 0.0005, 0.0153, 0.0073, 0.0480,
        0.1035, 0.0011, 0.2184, 0.0357, 0.0007], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,587][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0005, 0.0150, 0.1741, 0.1687, 0.0603, 0.1390, 0.0514, 0.0762, 0.0110,
        0.0055, 0.1439, 0.0008, 0.0178, 0.1357], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,589][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.1031, 0.1041, 0.0420, 0.0175, 0.0645, 0.0264, 0.0841, 0.1004, 0.1031,
        0.0922, 0.0140, 0.1062, 0.0879, 0.0544], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,590][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0163, 0.0701, 0.0855, 0.0842, 0.0765, 0.0794, 0.0719, 0.0857, 0.0763,
        0.0722, 0.0864, 0.0433, 0.0677, 0.0844], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,592][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0326, 0.0504, 0.0843, 0.0859, 0.0943, 0.0822, 0.0825, 0.0795, 0.0473,
        0.0509, 0.0911, 0.0364, 0.0807, 0.1019], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,593][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0155, 0.0530, 0.1168, 0.1037, 0.1031, 0.1060, 0.0743, 0.0813, 0.0417,
        0.0303, 0.0983, 0.0147, 0.0720, 0.0893], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,595][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0635, 0.0351, 0.0260, 0.0089, 0.1228, 0.0282, 0.0471, 0.0371, 0.0644,
        0.0644, 0.0234, 0.0618, 0.1374, 0.2796], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,596][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.1427, 0.0082, 0.1549, 0.1370, 0.0424, 0.1265, 0.0035, 0.0087, 0.0047,
        0.0162, 0.1307, 0.0921, 0.0032, 0.1292], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,597][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.1633, 0.0548, 0.0172, 0.0033, 0.1791, 0.0006, 0.0358, 0.0340, 0.0604,
        0.0826, 0.0248, 0.1360, 0.2029, 0.0052], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,597][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.2551, 0.0125, 0.0035, 0.0260, 0.0537, 0.0246, 0.0918, 0.1208, 0.1478,
        0.0973, 0.0051, 0.1167, 0.0408, 0.0044], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,597][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ said] are: tensor([5.1471e-01, 6.8621e-02, 2.3955e-03, 2.9403e-03, 2.1825e-02, 4.0375e-03,
        2.9490e-02, 2.5724e-02, 6.2945e-02, 7.6617e-02, 2.7243e-03, 1.3765e-01,
        5.0149e-02, 1.7172e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,598][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0060, 0.0058, 0.3041, 0.0314, 0.0848, 0.0288, 0.0071, 0.0103, 0.0080,
        0.0067, 0.1388, 0.0067, 0.0238, 0.3376], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,598][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.4486, 0.0732, 0.0008, 0.0008, 0.0065, 0.0007, 0.0183, 0.0091, 0.0536,
        0.1129, 0.0016, 0.2276, 0.0438, 0.0011, 0.0015], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,599][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0004, 0.0144, 0.1504, 0.1371, 0.0520, 0.1205, 0.0441, 0.0684, 0.0102,
        0.0048, 0.1199, 0.0007, 0.0157, 0.1198, 0.1414], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,599][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0676, 0.0823, 0.0622, 0.0403, 0.0632, 0.0455, 0.0810, 0.0865, 0.0775,
        0.0704, 0.0270, 0.0745, 0.0657, 0.0775, 0.0786], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,599][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0151, 0.0637, 0.0763, 0.0772, 0.0712, 0.0743, 0.0669, 0.0788, 0.0669,
        0.0674, 0.0798, 0.0392, 0.0634, 0.0790, 0.0807], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,600][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0367, 0.0513, 0.0786, 0.0829, 0.0793, 0.0714, 0.0787, 0.0732, 0.0423,
        0.0499, 0.0853, 0.0363, 0.0696, 0.0858, 0.0787], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,601][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0143, 0.0463, 0.1062, 0.0953, 0.0962, 0.0980, 0.0688, 0.0760, 0.0366,
        0.0268, 0.0912, 0.0130, 0.0663, 0.0832, 0.0816], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,603][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0351, 0.0308, 0.0525, 0.0375, 0.1655, 0.0507, 0.0530, 0.0266, 0.0376,
        0.0499, 0.0768, 0.0377, 0.1064, 0.0769, 0.1630], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,604][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1254, 0.0067, 0.1397, 0.1213, 0.0368, 0.1108, 0.0029, 0.0073, 0.0040,
        0.0136, 0.1153, 0.0815, 0.0027, 0.1160, 0.1159], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,606][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1278, 0.0476, 0.0202, 0.0027, 0.1785, 0.0005, 0.0255, 0.0332, 0.0612,
        0.0755, 0.0200, 0.1346, 0.2196, 0.0166, 0.0365], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,607][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.2674, 0.0151, 0.0032, 0.0217, 0.0427, 0.0234, 0.0881, 0.1030, 0.1472,
        0.0988, 0.0058, 0.1264, 0.0394, 0.0053, 0.0125], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,608][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.4949, 0.0743, 0.0037, 0.0034, 0.0164, 0.0069, 0.0350, 0.0252, 0.0658,
        0.0789, 0.0039, 0.1452, 0.0442, 0.0006, 0.0017], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,609][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0068, 0.0062, 0.2552, 0.0152, 0.0776, 0.0206, 0.0059, 0.0099, 0.0085,
        0.0069, 0.0712, 0.0075, 0.0236, 0.3328, 0.1521], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,644][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:25,646][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,647][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,648][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,649][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,650][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,652][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,653][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,654][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,655][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,656][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,657][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,659][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,659][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.5284, 0.4716], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,659][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9933, 0.0067], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,666][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.7984, 0.2016], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,667][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5407, 0.4593], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,668][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.4716, 0.5284], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,670][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4875, 0.5125], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,671][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.5686, 0.4314], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,672][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.5010, 0.4990], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,674][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.6293, 0.3707], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,675][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1399, 0.8601], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,676][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.4498, 0.5502], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,678][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.4746, 0.5254], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,679][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Jennifer] are: tensor([0.4539, 0.1696, 0.3765], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,681][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Jennifer] are: tensor([0.0761, 0.0027, 0.9213], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,682][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Jennifer] are: tensor([0.1562, 0.1020, 0.7418], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,683][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Jennifer] are: tensor([0.7400, 0.1633, 0.0967], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,685][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Jennifer] are: tensor([0.1845, 0.2378, 0.5777], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,686][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Jennifer] are: tensor([0.3109, 0.3120, 0.3771], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,687][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Jennifer] are: tensor([0.6340, 0.2917, 0.0743], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,689][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Jennifer] are: tensor([0.6809, 0.2678, 0.0513], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,690][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Jennifer] are: tensor([8.3873e-01, 1.6092e-01, 3.4660e-04], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,691][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Jennifer] are: tensor([0.1474, 0.1568, 0.6959], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,691][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Jennifer] are: tensor([0.2881, 0.2925, 0.4195], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,691][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Jennifer] are: tensor([0.2991, 0.1309, 0.5700], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,692][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2362, 0.0840, 0.6535, 0.0263], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,692][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([8.2203e-03, 2.6496e-04, 6.1577e-01, 3.7574e-01], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,692][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1028, 0.0565, 0.4859, 0.3548], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,693][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.6904, 0.1591, 0.1447, 0.0058], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,693][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1635, 0.1659, 0.3015, 0.3691], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,693][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2161, 0.2224, 0.2761, 0.2854], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,693][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.4993, 0.2581, 0.0825, 0.1601], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,694][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.6145, 0.2711, 0.0715, 0.0429], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,694][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([9.3499e-01, 6.4874e-02, 6.1054e-05, 7.3011e-05], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,695][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0576, 0.0938, 0.4991, 0.3494], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,697][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.3343, 0.2538, 0.1955, 0.2164], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,698][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0420, 0.0259, 0.8707, 0.0614], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,699][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Megan] are: tensor([0.3239, 0.1222, 0.1679, 0.0519, 0.3340], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,700][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Megan] are: tensor([1.2307e-02, 2.9689e-04, 4.8436e-01, 4.3328e-01, 6.9760e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,702][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Megan] are: tensor([0.0677, 0.0258, 0.4275, 0.3017, 0.1772], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,703][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Megan] are: tensor([0.5308, 0.1641, 0.2305, 0.0239, 0.0508], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,704][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Megan] are: tensor([0.1049, 0.0956, 0.2297, 0.2705, 0.2993], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,706][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Megan] are: tensor([0.1680, 0.1755, 0.2151, 0.2214, 0.2200], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,707][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Megan] are: tensor([0.2955, 0.1918, 0.1051, 0.1702, 0.2373], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,708][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Megan] are: tensor([0.3963, 0.2501, 0.0882, 0.1045, 0.1609], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,709][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Megan] are: tensor([8.2449e-01, 1.7181e-01, 6.0039e-04, 2.3960e-03, 7.0358e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,711][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Megan] are: tensor([0.0042, 0.0076, 0.3470, 0.6073, 0.0339], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,712][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Megan] are: tensor([0.2126, 0.1742, 0.2067, 0.2334, 0.1730], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,713][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Megan] are: tensor([0.0846, 0.0655, 0.4592, 0.1104, 0.2802], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,715][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0850, 0.0353, 0.3126, 0.0277, 0.5333, 0.0060], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,716][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0119, 0.0004, 0.3635, 0.2972, 0.0683, 0.2587], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,718][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0586, 0.0279, 0.3138, 0.2317, 0.1582, 0.2097], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,719][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.3863, 0.1200, 0.4433, 0.0091, 0.0308, 0.0106], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,721][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0852, 0.0777, 0.1812, 0.2279, 0.1978, 0.2302], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,722][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.1389, 0.1432, 0.1761, 0.1826, 0.1822, 0.1769], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,723][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.3231, 0.1795, 0.0639, 0.1188, 0.1966, 0.1181], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,723][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.4623, 0.2426, 0.0519, 0.0613, 0.1461, 0.0358], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,723][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([8.9780e-01, 1.0073e-01, 2.4761e-04, 4.7544e-04, 4.3695e-04, 3.0667e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,723][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0435, 0.0719, 0.0906, 0.1311, 0.0988, 0.5641], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,724][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.1694, 0.1474, 0.1623, 0.1937, 0.1379, 0.1893], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,724][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0285, 0.0195, 0.5945, 0.0624, 0.2452, 0.0499], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,724][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0558, 0.0460, 0.3134, 0.1798, 0.2407, 0.1188, 0.0455],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,725][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([3.5880e-03, 2.3413e-05, 4.0792e-01, 3.0964e-01, 4.1581e-02, 2.2041e-01,
        1.6835e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,725][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0388, 0.0128, 0.3431, 0.2319, 0.1211, 0.1918, 0.0605],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,725][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.2307, 0.1288, 0.3584, 0.0627, 0.1056, 0.0897, 0.0241],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,726][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0602, 0.0763, 0.1452, 0.2055, 0.1734, 0.1921, 0.1473],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,726][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1187, 0.1240, 0.1527, 0.1563, 0.1549, 0.1520, 0.1415],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,728][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2170, 0.1457, 0.0737, 0.1196, 0.1634, 0.1164, 0.1641],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,729][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1833, 0.1537, 0.1366, 0.1341, 0.1441, 0.1113, 0.1369],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,730][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.6479, 0.2485, 0.0092, 0.0202, 0.0158, 0.0220, 0.0365],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,731][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([3.6913e-04, 1.2375e-03, 3.1349e-01, 4.9490e-01, 6.8795e-03, 1.8115e-01,
        1.9734e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,732][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1674, 0.1294, 0.1195, 0.1505, 0.0990, 0.1442, 0.1900],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,734][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0247, 0.0271, 0.5753, 0.1110, 0.1132, 0.1188, 0.0298],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,735][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0591, 0.0485, 0.2778, 0.2083, 0.1827, 0.1203, 0.0486, 0.0546],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,736][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([7.3236e-03, 1.5952e-04, 3.2929e-01, 2.9031e-01, 6.3304e-02, 2.3144e-01,
        4.0516e-02, 3.7655e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,738][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0336, 0.0119, 0.3228, 0.2182, 0.1147, 0.1811, 0.0589, 0.0586],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,739][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.1644, 0.0809, 0.5514, 0.0534, 0.0488, 0.0750, 0.0249, 0.0013],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,740][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0561, 0.0322, 0.1497, 0.2102, 0.1562, 0.1781, 0.1295, 0.0879],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,742][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.1024, 0.1091, 0.1352, 0.1379, 0.1357, 0.1340, 0.1239, 0.1221],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,743][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.1691, 0.1197, 0.0714, 0.1098, 0.1442, 0.1078, 0.1395, 0.1384],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,745][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.1743, 0.1429, 0.1029, 0.1156, 0.1280, 0.0869, 0.1216, 0.1278],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,746][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.7285, 0.1910, 0.0029, 0.0055, 0.0038, 0.0051, 0.0286, 0.0346],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,748][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0007, 0.0020, 0.2786, 0.4723, 0.0105, 0.2292, 0.0031, 0.0036],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,749][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0872, 0.0791, 0.1404, 0.1723, 0.1017, 0.1656, 0.1376, 0.1161],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,750][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0240, 0.0271, 0.4960, 0.1353, 0.1118, 0.1377, 0.0307, 0.0374],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,751][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0438, 0.0396, 0.2417, 0.1981, 0.1773, 0.1548, 0.0452, 0.0558, 0.0438],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,752][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([1.6666e-03, 1.4693e-06, 3.7570e-01, 3.9121e-01, 1.9532e-02, 1.8399e-01,
        1.1975e-02, 1.5924e-02, 1.1719e-06], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,754][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0277, 0.0070, 0.3672, 0.2338, 0.0971, 0.1810, 0.0378, 0.0397, 0.0087],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,754][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.1231, 0.0987, 0.2132, 0.1088, 0.1140, 0.1587, 0.0649, 0.0220, 0.0966],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,755][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0273, 0.0153, 0.1424, 0.2182, 0.1915, 0.1813, 0.1338, 0.0741, 0.0162],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,755][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0935, 0.0979, 0.1194, 0.1219, 0.1208, 0.1188, 0.1107, 0.1097, 0.1073],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,755][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.1408, 0.1053, 0.0690, 0.0993, 0.1234, 0.0973, 0.1201, 0.1178, 0.1271],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,756][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.1131, 0.1043, 0.1210, 0.1240, 0.1137, 0.1026, 0.1024, 0.1080, 0.1109],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,756][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.3561, 0.2099, 0.0236, 0.0436, 0.0297, 0.0385, 0.0792, 0.0840, 0.1355],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,756][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([7.7331e-05, 3.5977e-04, 2.9701e-01, 5.2749e-01, 3.2174e-03, 1.7007e-01,
        6.9100e-04, 7.0016e-04, 3.7609e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,757][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0555, 0.0622, 0.1354, 0.1647, 0.1131, 0.1577, 0.1320, 0.1087, 0.0709],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,757][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0256, 0.0292, 0.4791, 0.1276, 0.1016, 0.1289, 0.0343, 0.0410, 0.0328],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:25,757][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0538, 0.0465, 0.2344, 0.1557, 0.1789, 0.1202, 0.0502, 0.0603, 0.0520,
        0.0480], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,758][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([1.6498e-04, 5.8429e-07, 4.1786e-01, 2.9288e-01, 1.7634e-02, 2.3062e-01,
        1.2643e-02, 2.8186e-02, 9.4017e-07, 8.4618e-07], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,759][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0335, 0.0115, 0.3513, 0.2235, 0.1016, 0.1751, 0.0413, 0.0437, 0.0113,
        0.0073], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,761][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1053, 0.0862, 0.1755, 0.0978, 0.1122, 0.1539, 0.0539, 0.0261, 0.0888,
        0.1003], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,762][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0591, 0.0488, 0.1097, 0.1781, 0.1681, 0.1243, 0.1505, 0.0770, 0.0211,
        0.0633], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,764][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0858, 0.0887, 0.1071, 0.1089, 0.1092, 0.1069, 0.1005, 0.0992, 0.0975,
        0.0962], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,764][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1331, 0.0968, 0.0563, 0.0839, 0.1073, 0.0816, 0.1068, 0.1047, 0.1155,
        0.1139], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,765][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0875, 0.0847, 0.1214, 0.1173, 0.1052, 0.1093, 0.0908, 0.0960, 0.0936,
        0.0942], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,765][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.2677, 0.1580, 0.0271, 0.0350, 0.0432, 0.0489, 0.0775, 0.0756, 0.1245,
        0.1425], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,765][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([4.1158e-05, 2.2272e-04, 3.2238e-01, 5.3157e-01, 2.5003e-03, 1.4197e-01,
        4.4475e-04, 4.4627e-04, 2.3047e-04, 1.9178e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,766][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0638, 0.0678, 0.1223, 0.1430, 0.1025, 0.1391, 0.1164, 0.0979, 0.0724,
        0.0748], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,766][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0296, 0.0325, 0.4618, 0.1090, 0.1076, 0.1102, 0.0362, 0.0423, 0.0364,
        0.0343], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:25,767][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2049, 0.0504, 0.0755, 0.0016, 0.3475, 0.0020, 0.0332, 0.0397, 0.0735,
        0.0763, 0.0953], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,768][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([6.3869e-03, 1.7387e-04, 2.7177e-01, 1.7134e-01, 5.3566e-02, 1.8739e-01,
        3.3019e-02, 4.5564e-02, 2.5279e-04, 2.6571e-04, 2.3027e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,770][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0417, 0.0202, 0.2116, 0.1556, 0.1051, 0.1386, 0.0712, 0.0682, 0.0319,
        0.0249, 0.1310], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,771][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([4.9093e-01, 1.0610e-01, 8.4570e-02, 3.2099e-03, 1.6832e-02, 8.4485e-03,
        1.2839e-02, 4.6700e-04, 7.8292e-02, 1.9574e-01, 2.5803e-03],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,772][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0504, 0.0569, 0.1035, 0.1221, 0.1150, 0.1255, 0.1009, 0.0816, 0.0542,
        0.0575, 0.1323], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,773][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0781, 0.0776, 0.0930, 0.0967, 0.0989, 0.0948, 0.0898, 0.0884, 0.0867,
        0.0861, 0.1098], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,775][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1516, 0.0849, 0.0314, 0.0580, 0.0975, 0.0571, 0.0954, 0.0942, 0.1142,
        0.1091, 0.1068], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,776][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2172, 0.1065, 0.0480, 0.0327, 0.0916, 0.0295, 0.0835, 0.0821, 0.1244,
        0.1371, 0.0474], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,777][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([7.6008e-01, 7.5753e-02, 1.7367e-04, 1.8750e-04, 8.2100e-04, 4.8057e-04,
        6.1752e-03, 1.6287e-02, 7.3764e-02, 6.6170e-02, 1.0875e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,779][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0194, 0.0360, 0.2298, 0.1288, 0.0758, 0.1327, 0.0440, 0.0494, 0.0416,
        0.0332, 0.2095], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,780][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1685, 0.1082, 0.0670, 0.0799, 0.0541, 0.0764, 0.1045, 0.0735, 0.0905,
        0.1056, 0.0718], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,782][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0742, 0.0366, 0.1835, 0.0123, 0.2478, 0.0148, 0.0310, 0.0409, 0.0442,
        0.0487, 0.2661], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:25,783][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0274, 0.0267, 0.1559, 0.1457, 0.0991, 0.1195, 0.0309, 0.0371, 0.0296,
        0.0276, 0.2725, 0.0283], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,784][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0057, 0.0004, 0.2002, 0.2050, 0.0342, 0.1502, 0.0446, 0.0519, 0.0005,
        0.0008, 0.3000, 0.0065], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,786][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0459, 0.0215, 0.2321, 0.1718, 0.0923, 0.1454, 0.0468, 0.0496, 0.0180,
        0.0131, 0.1336, 0.0299], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,787][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0635, 0.0614, 0.1316, 0.1031, 0.0928, 0.1354, 0.0536, 0.0331, 0.0632,
        0.0705, 0.1092, 0.0827], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,789][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0634, 0.0388, 0.1011, 0.1261, 0.1103, 0.1081, 0.0970, 0.0781, 0.0291,
        0.0528, 0.1457, 0.0495], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,790][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0678, 0.0731, 0.0907, 0.0913, 0.0898, 0.0892, 0.0827, 0.0822, 0.0801,
        0.0789, 0.0999, 0.0743], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,792][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0953, 0.0761, 0.0550, 0.0763, 0.0891, 0.0739, 0.0866, 0.0845, 0.0895,
        0.0882, 0.0985, 0.0871], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,793][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0627, 0.0643, 0.1100, 0.1065, 0.0881, 0.1016, 0.0737, 0.0786, 0.0721,
        0.0716, 0.0981, 0.0728], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,793][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.1043, 0.1069, 0.0560, 0.0882, 0.0647, 0.0997, 0.0740, 0.0669, 0.0804,
        0.0982, 0.0686, 0.0922], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,793][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([4.3031e-06, 3.7632e-05, 2.5886e-01, 5.0081e-01, 7.1664e-04, 1.1004e-01,
        8.8803e-05, 8.7422e-05, 3.7592e-05, 2.9916e-05, 1.2927e-01, 1.5688e-05],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,794][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0251, 0.0365, 0.1236, 0.1387, 0.1039, 0.1386, 0.0812, 0.0819, 0.0450,
        0.0417, 0.1487, 0.0350], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,794][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0179, 0.0215, 0.3640, 0.0991, 0.0696, 0.0973, 0.0253, 0.0299, 0.0244,
        0.0226, 0.2064, 0.0221], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:25,794][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Megan] are: tensor([0.0642, 0.0463, 0.1239, 0.0624, 0.1366, 0.0556, 0.0447, 0.0532, 0.0530,
        0.0509, 0.1739, 0.0584, 0.0769], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,795][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Megan] are: tensor([1.7711e-03, 1.1660e-05, 2.1248e-01, 2.1562e-01, 1.4948e-02, 1.4416e-01,
        1.6832e-02, 1.6636e-02, 1.4894e-05, 2.9438e-05, 3.7553e-01, 1.6492e-03,
        3.2057e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,795][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Megan] are: tensor([0.0275, 0.0081, 0.2882, 0.1852, 0.0834, 0.1450, 0.0374, 0.0380, 0.0102,
        0.0071, 0.1325, 0.0162, 0.0213], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,796][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Megan] are: tensor([0.1462, 0.0755, 0.1082, 0.0280, 0.0385, 0.0680, 0.0171, 0.0076, 0.0836,
        0.1135, 0.0330, 0.2169, 0.0639], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,797][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Megan] are: tensor([0.0311, 0.0223, 0.0887, 0.1131, 0.1330, 0.1051, 0.0725, 0.0639, 0.0298,
        0.0362, 0.1394, 0.0289, 0.1360], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,799][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Megan] are: tensor([0.0648, 0.0674, 0.0818, 0.0830, 0.0831, 0.0810, 0.0761, 0.0751, 0.0737,
        0.0734, 0.0924, 0.0694, 0.0790], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,800][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Megan] are: tensor([0.0904, 0.0666, 0.0446, 0.0655, 0.0829, 0.0643, 0.0790, 0.0772, 0.0833,
        0.0806, 0.0940, 0.0792, 0.0925], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,801][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Megan] are: tensor([0.0880, 0.0737, 0.0689, 0.0739, 0.0762, 0.0629, 0.0697, 0.0734, 0.0797,
        0.0841, 0.0785, 0.0910, 0.0800], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,803][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Megan] are: tensor([0.3795, 0.1406, 0.0034, 0.0078, 0.0031, 0.0040, 0.0205, 0.0355, 0.0919,
        0.1133, 0.0054, 0.1801, 0.0150], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,804][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Megan] are: tensor([2.2447e-04, 8.1225e-04, 2.5543e-01, 4.1603e-01, 5.5494e-03, 1.6384e-01,
        1.3911e-03, 1.3794e-03, 8.2918e-04, 7.2566e-04, 1.5228e-01, 4.8404e-04,
        1.0235e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,805][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Megan] are: tensor([0.0762, 0.0596, 0.0822, 0.1009, 0.0663, 0.0980, 0.0933, 0.0675, 0.0609,
        0.0662, 0.0949, 0.0681, 0.0658], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,807][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Megan] are: tensor([0.0333, 0.0320, 0.2423, 0.0676, 0.0966, 0.0784, 0.0349, 0.0407, 0.0361,
        0.0351, 0.2106, 0.0358, 0.0566], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:25,808][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.1189, 0.0501, 0.0835, 0.0025, 0.1840, 0.0047, 0.0333, 0.0392, 0.0615,
        0.0620, 0.0425, 0.0899, 0.1185, 0.1094], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,809][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([9.8909e-03, 1.7458e-04, 2.0588e-01, 1.6971e-01, 4.0191e-02, 1.4517e-01,
        2.6090e-02, 3.7606e-02, 2.2331e-04, 3.2546e-04, 2.2889e-01, 7.6299e-03,
        2.8178e-03, 1.2540e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,811][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0323, 0.0174, 0.1723, 0.1245, 0.0871, 0.1105, 0.0575, 0.0545, 0.0262,
        0.0202, 0.1071, 0.0267, 0.0418, 0.1220], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,812][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.1597, 0.0545, 0.2171, 0.0066, 0.0225, 0.0188, 0.0124, 0.0005, 0.0632,
        0.0989, 0.0053, 0.2506, 0.0390, 0.0508], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,813][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0257, 0.0426, 0.0755, 0.0903, 0.0872, 0.1013, 0.0799, 0.0610, 0.0460,
        0.0449, 0.1027, 0.0289, 0.0744, 0.1397], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,815][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0632, 0.0605, 0.0696, 0.0732, 0.0760, 0.0714, 0.0691, 0.0680, 0.0672,
        0.0676, 0.0841, 0.0648, 0.0731, 0.0923], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,816][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.1171, 0.0630, 0.0221, 0.0431, 0.0732, 0.0422, 0.0727, 0.0730, 0.0877,
        0.0826, 0.0805, 0.0858, 0.0979, 0.0592], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,818][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.2336, 0.0813, 0.0137, 0.0124, 0.0598, 0.0091, 0.0504, 0.0518, 0.0978,
        0.1159, 0.0190, 0.1536, 0.0910, 0.0105], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,819][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([5.2463e-01, 9.4451e-02, 6.2525e-04, 1.0685e-03, 1.2106e-03, 8.9032e-04,
        8.6344e-03, 2.6480e-02, 6.1776e-02, 7.6482e-02, 7.7547e-04, 1.9257e-01,
        1.0113e-02, 2.9505e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,820][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0164, 0.0237, 0.1281, 0.0853, 0.0563, 0.0773, 0.0320, 0.0235, 0.0261,
        0.0224, 0.1245, 0.0192, 0.0235, 0.3417], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,822][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0805, 0.0671, 0.0688, 0.0816, 0.0576, 0.0785, 0.0837, 0.0710, 0.0628,
        0.0650, 0.0724, 0.0668, 0.0602, 0.0841], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,823][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0596, 0.0206, 0.0306, 0.0042, 0.1504, 0.0044, 0.0190, 0.0240, 0.0250,
        0.0304, 0.1729, 0.0364, 0.0851, 0.3373], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:25,824][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1276, 0.0460, 0.0513, 0.0013, 0.1923, 0.0022, 0.0314, 0.0375, 0.0631,
        0.0637, 0.0291, 0.0989, 0.1259, 0.0927, 0.0371], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,824][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([6.4701e-03, 1.6219e-04, 1.7748e-01, 1.3181e-01, 3.6933e-02, 1.3191e-01,
        2.2379e-02, 3.5500e-02, 2.2466e-04, 2.5874e-04, 1.8077e-01, 5.3757e-03,
        2.7341e-03, 1.1090e-01, 1.5709e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,824][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0299, 0.0171, 0.1529, 0.1104, 0.0762, 0.0979, 0.0518, 0.0487, 0.0240,
        0.0188, 0.0947, 0.0247, 0.0367, 0.1069, 0.1094], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,825][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.4734e-01, 5.4317e-02, 7.3077e-02, 3.0704e-03, 1.1936e-02, 7.2554e-03,
        7.5209e-03, 3.3347e-04, 4.4554e-02, 1.0809e-01, 2.5405e-03, 3.6718e-01,
        3.2060e-02, 3.3615e-02, 7.0992e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,825][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0256, 0.0388, 0.0728, 0.0891, 0.0770, 0.0907, 0.0740, 0.0555, 0.0359,
        0.0385, 0.0980, 0.0256, 0.0613, 0.1215, 0.0956], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,826][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0568, 0.0548, 0.0644, 0.0672, 0.0697, 0.0662, 0.0634, 0.0623, 0.0613,
        0.0612, 0.0768, 0.0587, 0.0669, 0.0860, 0.0842], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,826][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1121, 0.0593, 0.0201, 0.0384, 0.0677, 0.0378, 0.0672, 0.0669, 0.0820,
        0.0776, 0.0719, 0.0814, 0.0918, 0.0513, 0.0745], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,826][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.2767, 0.0832, 0.0086, 0.0078, 0.0438, 0.0055, 0.0456, 0.0433, 0.0963,
        0.1161, 0.0137, 0.1594, 0.0864, 0.0081, 0.0056], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,827][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([5.3706e-01, 8.4666e-02, 6.2546e-04, 6.8544e-04, 1.6479e-03, 8.2456e-04,
        8.7576e-03, 2.1920e-02, 6.5171e-02, 6.7453e-02, 4.2262e-04, 1.9776e-01,
        1.2323e-02, 4.6215e-04, 2.1300e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,828][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0304, 0.0391, 0.0812, 0.0369, 0.0606, 0.0386, 0.0515, 0.0504, 0.0515,
        0.0408, 0.0610, 0.0385, 0.0444, 0.2173, 0.1579], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,829][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0986, 0.0731, 0.0555, 0.0664, 0.0469, 0.0642, 0.0835, 0.0614, 0.0648,
        0.0712, 0.0596, 0.0754, 0.0556, 0.0661, 0.0576], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,830][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0460, 0.0177, 0.0242, 0.0017, 0.0909, 0.0032, 0.0132, 0.0199, 0.0218,
        0.0255, 0.0628, 0.0307, 0.0602, 0.3704, 0.2119], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:25,831][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:25,833][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 9893],
        [11270],
        [16794],
        [ 7219],
        [22480],
        [ 5757],
        [ 8782],
        [10086],
        [11984],
        [10311],
        [ 7207],
        [10139],
        [21171],
        [ 5238],
        [ 6663]], device='cuda:0')
[2024-07-24 10:29:25,835][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[10724],
        [15071],
        [47479],
        [27640],
        [34839],
        [14061],
        [13687],
        [16087],
        [16305],
        [13569],
        [23092],
        [12105],
        [29431],
        [22754],
        [22513]], device='cuda:0')
[2024-07-24 10:29:25,836][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[29573],
        [30915],
        [29939],
        [30012],
        [30066],
        [30063],
        [27345],
        [27860],
        [22980],
        [21683],
        [27009],
        [20751],
        [23464],
        [25494],
        [24956]], device='cuda:0')
[2024-07-24 10:29:25,837][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 9094],
        [ 6174],
        [10373],
        [ 6554],
        [ 6101],
        [ 5765],
        [ 5744],
        [ 5639],
        [ 5588],
        [ 5773],
        [ 5627],
        [ 5546],
        [ 5563],
        [ 6048],
        [ 6364]], device='cuda:0')
[2024-07-24 10:29:25,839][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[25334],
        [34128],
        [39447],
        [40725],
        [42155],
        [41129],
        [40777],
        [41622],
        [41616],
        [41590],
        [42477],
        [40895],
        [41066],
        [41245],
        [38502]], device='cuda:0')
[2024-07-24 10:29:25,840][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[9613],
        [9471],
        [9129],
        [9081],
        [8812],
        [8578],
        [8424],
        [9081],
        [9039],
        [9213],
        [9320],
        [9353],
        [9245],
        [9130],
        [9025]], device='cuda:0')
[2024-07-24 10:29:25,842][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[3825],
        [ 919],
        [  55],
        [ 163],
        [ 182],
        [ 292],
        [ 355],
        [ 603],
        [ 752],
        [ 849],
        [ 812],
        [ 898],
        [ 645],
        [ 682],
        [ 744]], device='cuda:0')
[2024-07-24 10:29:25,843][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[17497],
        [18686],
        [21397],
        [23413],
        [23731],
        [23823],
        [24028],
        [23891],
        [24139],
        [24315],
        [23990],
        [24306],
        [24173],
        [24264],
        [24327]], device='cuda:0')
[2024-07-24 10:29:25,844][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[13217],
        [27054],
        [12729],
        [24421],
        [18453],
        [32512],
        [25986],
        [27534],
        [25152],
        [24323],
        [27304],
        [25469],
        [23049],
        [21680],
        [26813]], device='cuda:0')
[2024-07-24 10:29:25,846][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[3932],
        [3725],
        [4039],
        [3531],
        [3581],
        [3525],
        [3485],
        [3454],
        [3483],
        [3447],
        [3294],
        [3193],
        [3177],
        [3237],
        [3157]], device='cuda:0')
[2024-07-24 10:29:25,847][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[8011],
        [5077],
        [6854],
        [4257],
        [3582],
        [3914],
        [4243],
        [3684],
        [3473],
        [3560],
        [3482],
        [3127],
        [2804],
        [2985],
        [2630]], device='cuda:0')
[2024-07-24 10:29:25,849][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[39964],
        [42806],
        [41919],
        [39160],
        [35529],
        [34414],
        [26873],
        [18583],
        [22925],
        [25214],
        [16047],
        [27579],
        [19719],
        [16097],
        [16860]], device='cuda:0')
[2024-07-24 10:29:25,850][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[2148],
        [1749],
        [1734],
        [1639],
        [4009],
        [4546],
        [7522],
        [6154],
        [7039],
        [6987],
        [2736],
        [6238],
        [5975],
        [1814],
        [1717]], device='cuda:0')
[2024-07-24 10:29:25,851][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[15873],
        [15487],
        [23429],
        [22822],
        [21652],
        [22698],
        [21703],
        [21269],
        [21305],
        [21583],
        [22226],
        [20623],
        [21082],
        [22440],
        [22588]], device='cuda:0')
[2024-07-24 10:29:25,853][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 3656],
        [15525],
        [ 2872],
        [ 9147],
        [ 8854],
        [10203],
        [15194],
        [12089],
        [13028],
        [15463],
        [12022],
        [13183],
        [12650],
        [ 7652],
        [12255]], device='cuda:0')
[2024-07-24 10:29:25,854][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[15145],
        [12382],
        [ 6370],
        [ 3641],
        [ 3071],
        [ 1716],
        [ 2150],
        [ 2306],
        [ 2401],
        [ 2488],
        [ 2455],
        [ 2240],
        [ 2246],
        [ 2988],
        [ 3294]], device='cuda:0')
[2024-07-24 10:29:25,855][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[39120],
        [39098],
        [16183],
        [23405],
        [25079],
        [22322],
        [22182],
        [22330],
        [23920],
        [21867],
        [24080],
        [26117],
        [26829],
        [25305],
        [25178]], device='cuda:0')
[2024-07-24 10:29:25,857][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[3786],
        [3893],
        [4684],
        [5205],
        [5009],
        [5428],
        [5552],
        [5657],
        [5647],
        [5663],
        [5703],
        [5586],
        [5534],
        [5702],
        [5704]], device='cuda:0')
[2024-07-24 10:29:25,858][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 9571],
        [11545],
        [12043],
        [12264],
        [11940],
        [11833],
        [10046],
        [10381],
        [ 9077],
        [ 9074],
        [10855],
        [ 8626],
        [ 9269],
        [10840],
        [10737]], device='cuda:0')
[2024-07-24 10:29:25,859][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[35671],
        [41959],
        [42000],
        [38216],
        [39298],
        [39003],
        [38644],
        [38877],
        [38711],
        [40059],
        [39710],
        [39668],
        [39361],
        [39948],
        [39455]], device='cuda:0')
[2024-07-24 10:29:25,859][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[14551],
        [17271],
        [22326],
        [21566],
        [21539],
        [21719],
        [21700],
        [21546],
        [21911],
        [21789],
        [22015],
        [22187],
        [22487],
        [22221],
        [22301]], device='cuda:0')
[2024-07-24 10:29:25,861][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[47777],
        [45153],
        [43795],
        [36291],
        [28821],
        [30251],
        [28862],
        [28965],
        [30175],
        [31745],
        [33154],
        [31479],
        [32839],
        [34312],
        [33346]], device='cuda:0')
[2024-07-24 10:29:25,862][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[38757],
        [30674],
        [27723],
        [20378],
        [12185],
        [14154],
        [ 8867],
        [ 8644],
        [ 8130],
        [ 8056],
        [ 9956],
        [ 7467],
        [ 8255],
        [13317],
        [15068]], device='cuda:0')
[2024-07-24 10:29:25,863][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[21507],
        [16519],
        [21268],
        [21869],
        [20993],
        [21726],
        [12077],
        [15574],
        [ 5372],
        [ 5195],
        [16936],
        [ 6094],
        [ 7445],
        [11001],
        [11117]], device='cuda:0')
[2024-07-24 10:29:25,865][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[30198],
        [15594],
        [13104],
        [12607],
        [12632],
        [13312],
        [13069],
        [13164],
        [13091],
        [13033],
        [12399],
        [13187],
        [13260],
        [14160],
        [14973]], device='cuda:0')
[2024-07-24 10:29:25,866][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 6020],
        [10029],
        [10172],
        [ 8736],
        [ 8426],
        [ 7816],
        [ 6984],
        [ 6929],
        [ 6881],
        [ 6929],
        [ 6945],
        [ 6616],
        [ 6872],
        [ 6866],
        [ 6771]], device='cuda:0')
[2024-07-24 10:29:25,867][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[22940],
        [19471],
        [ 9756],
        [ 8012],
        [ 8615],
        [ 8489],
        [ 7213],
        [ 6767],
        [ 6851],
        [ 7107],
        [ 5483],
        [ 4370],
        [ 4699],
        [ 6836],
        [ 7513]], device='cuda:0')
[2024-07-24 10:29:25,869][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[19546],
        [21960],
        [26867],
        [32831],
        [35662],
        [36195],
        [39799],
        [39202],
        [40574],
        [40826],
        [37376],
        [40980],
        [39719],
        [35953],
        [34855]], device='cuda:0')
[2024-07-24 10:29:25,870][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[42605],
        [33258],
        [41541],
        [44075],
        [42688],
        [43426],
        [38535],
        [40645],
        [40785],
        [38452],
        [43499],
        [41955],
        [41592],
        [46215],
        [42973]], device='cuda:0')
[2024-07-24 10:29:25,871][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[12255],
        [12255],
        [12255],
        [12255],
        [12255],
        [12255],
        [12255],
        [12255],
        [12255],
        [12255],
        [12255],
        [12255],
        [12255],
        [12255],
        [12255]], device='cuda:0')
[2024-07-24 10:29:25,899][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:25,901][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,902][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,903][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,904][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,905][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,906][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,908][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,909][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,910][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,911][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,912][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,913][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:25,915][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4672, 0.5328], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,916][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.3318, 0.6682], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,918][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1940, 0.8060], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,919][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4788, 0.5212], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,920][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4282, 0.5718], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,920][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4909, 0.5091], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,920][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1515, 0.8485], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,921][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2604, 0.7396], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,921][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4158, 0.5842], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,921][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.4429, 0.5571], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,922][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1629, 0.8371], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,922][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.3330, 0.6670], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:25,922][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Jennifer] are: tensor([0.0735, 0.0336, 0.8929], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,923][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Jennifer] are: tensor([0.1345, 0.0652, 0.8002], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,924][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Jennifer] are: tensor([8.1217e-01, 1.8733e-01, 5.0178e-04], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,925][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Jennifer] are: tensor([0.6233, 0.2202, 0.1565], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,927][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Jennifer] are: tensor([0.6027, 0.2582, 0.1391], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,928][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Jennifer] are: tensor([0.7983, 0.1955, 0.0062], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,929][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Jennifer] are: tensor([0.1392, 0.4306, 0.4302], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,930][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Jennifer] are: tensor([0.2821, 0.1843, 0.5336], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,932][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Jennifer] are: tensor([0.2767, 0.1034, 0.6199], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,933][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Jennifer] are: tensor([0.1073, 0.0615, 0.8312], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,935][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Jennifer] are: tensor([0.0052, 0.0082, 0.9866], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,936][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Jennifer] are: tensor([0.4445, 0.2715, 0.2841], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:25,937][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0220, 0.0113, 0.8838, 0.0829], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,939][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0119, 0.0099, 0.7316, 0.2465], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,940][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.7800, 0.2156, 0.0032, 0.0012], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,941][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.4825, 0.1964, 0.2730, 0.0480], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,943][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1788, 0.1061, 0.3217, 0.3934], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,944][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.7061, 0.2226, 0.0487, 0.0226], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,945][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0924, 0.2946, 0.3065, 0.3065], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,946][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1193, 0.1109, 0.2729, 0.4969], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,948][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0243, 0.0179, 0.8891, 0.0687], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,949][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0165, 0.0114, 0.8623, 0.1098], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,951][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0131, 0.0311, 0.6864, 0.2694], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,951][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2713, 0.1889, 0.2327, 0.3071], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:25,951][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Megan] are: tensor([0.0539, 0.0461, 0.5794, 0.1493, 0.1713], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,952][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Megan] are: tensor([0.0095, 0.0157, 0.6490, 0.3000, 0.0258], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,952][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Megan] are: tensor([0.2646, 0.2097, 0.2439, 0.0991, 0.1827], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,952][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Megan] are: tensor([0.1327, 0.0854, 0.2181, 0.0840, 0.4798], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,953][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Megan] are: tensor([0.0460, 0.0449, 0.3228, 0.5155, 0.0709], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,953][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Megan] are: tensor([0.3065, 0.2315, 0.1209, 0.1173, 0.2239], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,953][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Megan] are: tensor([0.0668, 0.2609, 0.2221, 0.2256, 0.2246], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,954][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Megan] are: tensor([0.0044, 0.0107, 0.5285, 0.4319, 0.0245], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,954][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Megan] are: tensor([0.0392, 0.0411, 0.6607, 0.1303, 0.1288], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,955][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Megan] are: tensor([0.0260, 0.0277, 0.6752, 0.2141, 0.0571], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,956][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Megan] are: tensor([0.0117, 0.0530, 0.6623, 0.2491, 0.0239], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,957][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Megan] are: tensor([0.0300, 0.0300, 0.3713, 0.4610, 0.1077], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:25,958][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0344, 0.0204, 0.5660, 0.1078, 0.1944, 0.0769], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,960][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0161, 0.0150, 0.4907, 0.2727, 0.0330, 0.1725], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,961][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ had] are: tensor([8.1711e-01, 1.6663e-01, 9.8183e-04, 1.1503e-03, 1.3332e-02, 7.8842e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,962][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1088, 0.0540, 0.1556, 0.0513, 0.5525, 0.0777], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,963][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0873, 0.0608, 0.1326, 0.4353, 0.0650, 0.2189], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,965][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.3443, 0.1649, 0.0892, 0.0499, 0.2422, 0.1095], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,966][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0502, 0.1964, 0.1806, 0.1890, 0.1843, 0.1994], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,967][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0455, 0.0477, 0.1931, 0.2871, 0.0956, 0.3310], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,969][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0129, 0.0135, 0.7335, 0.1012, 0.0851, 0.0539], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,970][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0021, 0.0024, 0.7068, 0.2567, 0.0129, 0.0191], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,972][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0325, 0.0736, 0.2581, 0.2083, 0.0340, 0.3934], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,973][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0428, 0.0369, 0.1444, 0.2824, 0.1543, 0.3392], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:25,974][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0227, 0.0241, 0.5728, 0.1629, 0.0804, 0.1104, 0.0267],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,976][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0062, 0.0122, 0.6586, 0.1847, 0.0197, 0.1051, 0.0135],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,977][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0040, 0.0075, 0.4485, 0.1146, 0.1203, 0.2899, 0.0152],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,978][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0250, 0.0252, 0.3013, 0.2394, 0.1201, 0.2573, 0.0318],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,980][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0109, 0.0148, 0.3086, 0.3945, 0.0342, 0.2206, 0.0165],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,981][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1133, 0.1115, 0.2100, 0.1430, 0.1258, 0.1860, 0.1104],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,983][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0379, 0.1821, 0.1499, 0.1515, 0.1564, 0.1656, 0.1566],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,983][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0045, 0.0113, 0.4527, 0.3181, 0.0226, 0.1769, 0.0139],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,983][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0106, 0.0151, 0.6527, 0.1504, 0.0424, 0.1126, 0.0162],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,984][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0090, 0.0119, 0.6463, 0.2165, 0.0269, 0.0776, 0.0117],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,984][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0365, 0.1839, 0.4624, 0.1345, 0.0305, 0.1051, 0.0470],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,984][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0034, 0.0062, 0.2167, 0.3069, 0.0253, 0.4286, 0.0129],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:25,985][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0199, 0.0225, 0.5145, 0.1955, 0.0730, 0.1205, 0.0258, 0.0283],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,985][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0047, 0.0101, 0.6536, 0.1979, 0.0166, 0.0964, 0.0113, 0.0094],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,985][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0199, 0.0245, 0.4036, 0.1379, 0.1390, 0.1925, 0.0369, 0.0456],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,986][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0224, 0.0229, 0.2564, 0.2637, 0.1114, 0.2614, 0.0292, 0.0325],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,988][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0147, 0.0184, 0.2211, 0.4349, 0.0323, 0.2369, 0.0204, 0.0214],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,989][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0990, 0.1017, 0.1609, 0.1490, 0.1122, 0.1702, 0.1010, 0.1060],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,991][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0297, 0.1558, 0.1317, 0.1320, 0.1390, 0.1444, 0.1391, 0.1283],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,992][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0035, 0.0092, 0.4274, 0.3498, 0.0184, 0.1693, 0.0114, 0.0110],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,993][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0117, 0.0171, 0.5507, 0.1974, 0.0459, 0.1369, 0.0190, 0.0213],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,994][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0093, 0.0124, 0.5702, 0.2674, 0.0267, 0.0890, 0.0126, 0.0125],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,996][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0276, 0.1367, 0.4615, 0.1583, 0.0315, 0.1214, 0.0418, 0.0213],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,997][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0035, 0.0058, 0.1802, 0.3221, 0.0252, 0.4331, 0.0132, 0.0168],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:25,999][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0212, 0.0242, 0.5260, 0.1645, 0.0705, 0.1059, 0.0282, 0.0315, 0.0279],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,000][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0074, 0.0156, 0.6248, 0.1857, 0.0223, 0.1001, 0.0162, 0.0139, 0.0141],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,001][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([1.3119e-04, 4.7230e-04, 6.4965e-01, 7.8491e-02, 2.9994e-02, 2.3471e-01,
        1.5644e-03, 4.0844e-03, 8.9554e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,002][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0210, 0.0225, 0.2697, 0.2415, 0.0958, 0.2619, 0.0287, 0.0336, 0.0254],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,004][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0141, 0.0186, 0.2999, 0.3520, 0.0401, 0.2104, 0.0210, 0.0238, 0.0202],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,005][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0857, 0.0901, 0.1729, 0.1330, 0.0985, 0.1411, 0.0909, 0.0950, 0.0927],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,007][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0169, 0.1821, 0.0934, 0.0913, 0.1117, 0.1072, 0.1309, 0.1118, 0.1548],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,008][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0034, 0.0095, 0.4491, 0.3209, 0.0186, 0.1670, 0.0118, 0.0111, 0.0088],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,009][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0136, 0.0185, 0.5651, 0.1639, 0.0479, 0.1257, 0.0211, 0.0241, 0.0200],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,011][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0138, 0.0175, 0.5821, 0.2073, 0.0360, 0.0880, 0.0180, 0.0183, 0.0190],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,012][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0445, 0.2165, 0.3610, 0.0992, 0.0326, 0.0852, 0.0578, 0.0297, 0.0735],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,013][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0034, 0.0059, 0.2365, 0.2862, 0.0260, 0.4044, 0.0126, 0.0160, 0.0090],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,014][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0255, 0.0280, 0.5043, 0.1436, 0.0769, 0.0937, 0.0315, 0.0343, 0.0320,
        0.0301], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,014][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0069, 0.0145, 0.6267, 0.1768, 0.0222, 0.0967, 0.0154, 0.0131, 0.0133,
        0.0143], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,014][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([6.1034e-05, 2.5722e-04, 6.7327e-01, 8.8415e-02, 2.3343e-02, 2.1041e-01,
        9.3792e-04, 2.4716e-03, 6.0418e-04, 2.3445e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,015][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0257, 0.0272, 0.2686, 0.2257, 0.1032, 0.2204, 0.0329, 0.0373, 0.0302,
        0.0288], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,015][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0173, 0.0227, 0.3352, 0.2981, 0.0498, 0.1762, 0.0243, 0.0271, 0.0249,
        0.0246], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,015][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0820, 0.0851, 0.1552, 0.1130, 0.0929, 0.1256, 0.0840, 0.0890, 0.0879,
        0.0853], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,016][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0188, 0.1473, 0.0683, 0.0611, 0.0836, 0.0743, 0.0997, 0.0894, 0.1413,
        0.2161], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,016][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0039, 0.0110, 0.4596, 0.3084, 0.0207, 0.1502, 0.0131, 0.0125, 0.0100,
        0.0106], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,017][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0153, 0.0206, 0.5642, 0.1479, 0.0497, 0.1109, 0.0227, 0.0254, 0.0222,
        0.0211], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,018][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0158, 0.0196, 0.5788, 0.1852, 0.0392, 0.0806, 0.0198, 0.0199, 0.0211,
        0.0200], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,019][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0374, 0.1928, 0.3562, 0.0927, 0.0311, 0.0709, 0.0492, 0.0251, 0.0634,
        0.0812], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,020][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0030, 0.0058, 0.2534, 0.2808, 0.0243, 0.3908, 0.0113, 0.0150, 0.0088,
        0.0069], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,022][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0550, 0.0247, 0.1851, 0.0161, 0.2117, 0.0226, 0.0265, 0.0295, 0.0389,
        0.0405, 0.3494], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,023][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0113, 0.0098, 0.3139, 0.1106, 0.0355, 0.1430, 0.0143, 0.0181, 0.0134,
        0.0124, 0.3178], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,024][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4187, 0.1351, 0.0027, 0.0011, 0.0359, 0.0032, 0.0823, 0.0542, 0.1417,
        0.1239, 0.0011], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,026][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1339, 0.0430, 0.0245, 0.0015, 0.4124, 0.0039, 0.0374, 0.0351, 0.0666,
        0.0735, 0.1682], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,027][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0744, 0.0514, 0.1370, 0.1055, 0.0741, 0.1037, 0.0417, 0.0522, 0.0552,
        0.0714, 0.2334], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,029][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2484, 0.0873, 0.0299, 0.0074, 0.1629, 0.0189, 0.0706, 0.0944, 0.1165,
        0.1171, 0.0466], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,030][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0291, 0.0970, 0.1013, 0.1016, 0.1008, 0.1102, 0.0975, 0.0970, 0.0835,
        0.0817, 0.1002], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,031][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0195, 0.0221, 0.1094, 0.1495, 0.0494, 0.1042, 0.0285, 0.0298, 0.0255,
        0.0250, 0.4371], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,033][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0431, 0.0287, 0.3207, 0.0206, 0.1322, 0.0232, 0.0239, 0.0292, 0.0367,
        0.0415, 0.3002], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,034][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0148, 0.0124, 0.7077, 0.0687, 0.0466, 0.0140, 0.0096, 0.0102, 0.0173,
        0.0160, 0.0827], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,036][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0089, 0.0285, 0.3987, 0.1221, 0.0215, 0.1445, 0.0135, 0.0069, 0.0127,
        0.0141, 0.2287], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,037][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0877, 0.0630, 0.0572, 0.0947, 0.1124, 0.1098, 0.1223, 0.0905, 0.0743,
        0.0720, 0.1162], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,039][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0171, 0.0203, 0.4123, 0.1324, 0.0535, 0.0845, 0.0234, 0.0257, 0.0231,
        0.0216, 0.1646, 0.0214], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,040][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0039, 0.0096, 0.6046, 0.1551, 0.0145, 0.0775, 0.0100, 0.0085, 0.0084,
        0.0091, 0.0914, 0.0076], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,041][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([2.8096e-06, 2.2808e-05, 6.5466e-01, 8.3374e-02, 6.4976e-03, 1.7293e-01,
        1.2107e-04, 3.9801e-04, 5.9119e-05, 2.1182e-05, 8.1906e-02, 1.2480e-05],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,043][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0107, 0.0124, 0.1852, 0.1675, 0.0524, 0.1663, 0.0160, 0.0190, 0.0138,
        0.0130, 0.3311, 0.0126], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,044][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0121, 0.0166, 0.2778, 0.2397, 0.0380, 0.1448, 0.0183, 0.0209, 0.0186,
        0.0180, 0.1776, 0.0176], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,045][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0576, 0.0651, 0.1429, 0.1146, 0.0690, 0.1208, 0.0673, 0.0686, 0.0665,
        0.0642, 0.1001, 0.0635], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,045][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0118, 0.0929, 0.0977, 0.0952, 0.0935, 0.1048, 0.1077, 0.0940, 0.0894,
        0.0967, 0.0893, 0.0270], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,046][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0019, 0.0064, 0.4089, 0.2605, 0.0126, 0.1194, 0.0078, 0.0074, 0.0057,
        0.0061, 0.1588, 0.0045], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,046][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0102, 0.0149, 0.4681, 0.1394, 0.0357, 0.1048, 0.0173, 0.0195, 0.0159,
        0.0149, 0.1448, 0.0146], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,046][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0141, 0.0181, 0.5016, 0.1673, 0.0346, 0.0778, 0.0185, 0.0187, 0.0194,
        0.0185, 0.0918, 0.0195], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,047][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0258, 0.1544, 0.2864, 0.0712, 0.0222, 0.0577, 0.0374, 0.0194, 0.0486,
        0.0617, 0.1487, 0.0664], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,047][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0014, 0.0030, 0.2044, 0.2319, 0.0137, 0.3222, 0.0060, 0.0079, 0.0044,
        0.0035, 0.1987, 0.0029], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,047][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Megan] are: tensor([0.0307, 0.0302, 0.2980, 0.0906, 0.0799, 0.0698, 0.0332, 0.0365, 0.0352,
        0.0344, 0.1763, 0.0349, 0.0503], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,048][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Megan] are: tensor([0.0058, 0.0123, 0.5264, 0.1611, 0.0180, 0.0871, 0.0131, 0.0110, 0.0111,
        0.0119, 0.1200, 0.0102, 0.0119], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,049][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Megan] are: tensor([0.0023, 0.0047, 0.4159, 0.0961, 0.0483, 0.2897, 0.0105, 0.0190, 0.0075,
        0.0045, 0.0844, 0.0037, 0.0133], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,051][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Megan] are: tensor([0.0217, 0.0209, 0.1505, 0.1030, 0.0866, 0.1439, 0.0258, 0.0296, 0.0240,
        0.0229, 0.3104, 0.0233, 0.0374], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,052][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Megan] are: tensor([0.0171, 0.0208, 0.2132, 0.2317, 0.0385, 0.1565, 0.0218, 0.0236, 0.0218,
        0.0226, 0.1845, 0.0224, 0.0255], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,054][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Megan] are: tensor([0.0737, 0.0728, 0.0862, 0.0736, 0.0727, 0.0937, 0.0703, 0.0749, 0.0755,
        0.0732, 0.0830, 0.0750, 0.0756], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,055][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Megan] are: tensor([0.0204, 0.1014, 0.0738, 0.0739, 0.0772, 0.0853, 0.0854, 0.0775, 0.0935,
        0.1123, 0.0735, 0.0390, 0.0869], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,056][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Megan] are: tensor([0.0026, 0.0074, 0.3570, 0.2576, 0.0149, 0.1363, 0.0093, 0.0088, 0.0068,
        0.0071, 0.1784, 0.0053, 0.0085], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,058][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Megan] are: tensor([0.0194, 0.0240, 0.3700, 0.1056, 0.0563, 0.0978, 0.0254, 0.0291, 0.0260,
        0.0252, 0.1596, 0.0254, 0.0362], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,059][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Megan] are: tensor([0.0191, 0.0224, 0.4432, 0.1572, 0.0407, 0.0747, 0.0215, 0.0215, 0.0243,
        0.0231, 0.0986, 0.0249, 0.0289], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,061][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Megan] are: tensor([0.0205, 0.1011, 0.3038, 0.0871, 0.0220, 0.0873, 0.0324, 0.0160, 0.0360,
        0.0441, 0.1680, 0.0450, 0.0367], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,062][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Megan] are: tensor([0.0030, 0.0049, 0.1798, 0.2143, 0.0227, 0.3382, 0.0112, 0.0130, 0.0074,
        0.0058, 0.1857, 0.0050, 0.0089], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,064][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0448, 0.0095, 0.0080, 0.0007, 0.0957, 0.0025, 0.0092, 0.0120, 0.0170,
        0.0196, 0.0748, 0.0245, 0.0554, 0.6263], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,065][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0246, 0.0134, 0.1009, 0.0528, 0.0307, 0.1053, 0.0189, 0.0261, 0.0193,
        0.0159, 0.2193, 0.0173, 0.0225, 0.3329], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,066][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ said] are: tensor([3.9597e-01, 1.1011e-01, 9.0737e-04, 6.8491e-04, 1.3830e-02, 1.8878e-03,
        4.8947e-02, 4.4907e-02, 6.9245e-02, 9.4319e-02, 6.2070e-04, 1.7345e-01,
        4.4901e-02, 2.2745e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,067][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0988, 0.0391, 0.0183, 0.0035, 0.2091, 0.0093, 0.0381, 0.0406, 0.0559,
        0.0602, 0.1099, 0.0725, 0.1216, 0.1232], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,069][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0540, 0.0371, 0.0383, 0.0968, 0.0354, 0.1212, 0.0338, 0.0407, 0.0365,
        0.0494, 0.2366, 0.0576, 0.0502, 0.1123], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,070][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.3019, 0.0592, 0.0028, 0.0008, 0.0899, 0.0038, 0.0423, 0.0577, 0.0852,
        0.0864, 0.0115, 0.1233, 0.1266, 0.0088], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,072][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0192, 0.0856, 0.0762, 0.0785, 0.0778, 0.0839, 0.0778, 0.0765, 0.0761,
        0.0794, 0.0787, 0.0319, 0.0779, 0.0804], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,073][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0545, 0.0259, 0.0261, 0.0492, 0.0613, 0.1017, 0.0356, 0.0404, 0.0347,
        0.0306, 0.2898, 0.0289, 0.0439, 0.1775], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,075][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0188, 0.0066, 0.0103, 0.0011, 0.0337, 0.0019, 0.0055, 0.0069, 0.0089,
        0.0112, 0.0508, 0.0135, 0.0238, 0.8071], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,076][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0064, 0.0064, 0.5109, 0.1682, 0.0289, 0.0294, 0.0058, 0.0053, 0.0080,
        0.0078, 0.1127, 0.0094, 0.0134, 0.0875], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,076][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0278, 0.0280, 0.1626, 0.0967, 0.0418, 0.1399, 0.0206, 0.0123, 0.0194,
        0.0157, 0.2045, 0.0160, 0.0240, 0.1905], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,077][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0574, 0.0375, 0.0560, 0.0905, 0.0742, 0.1158, 0.0740, 0.0696, 0.0480,
        0.0473, 0.1149, 0.0438, 0.0562, 0.1148], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,077][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0275, 0.0075, 0.0111, 0.0009, 0.0746, 0.0026, 0.0074, 0.0102, 0.0137,
        0.0145, 0.0540, 0.0181, 0.0393, 0.5764, 0.1420], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,078][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0220, 0.0124, 0.0937, 0.0369, 0.0272, 0.0657, 0.0180, 0.0253, 0.0183,
        0.0159, 0.1805, 0.0174, 0.0201, 0.3162, 0.1303], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,078][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2628, 0.1080, 0.0018, 0.0013, 0.0298, 0.0054, 0.0853, 0.0525, 0.1089,
        0.1134, 0.0017, 0.1473, 0.0792, 0.0013, 0.0013], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,078][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1090, 0.0385, 0.0105, 0.0011, 0.1862, 0.0028, 0.0345, 0.0346, 0.0595,
        0.0635, 0.0525, 0.0797, 0.1335, 0.0896, 0.1046], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,079][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0911, 0.0487, 0.0310, 0.0407, 0.0476, 0.0320, 0.0372, 0.0395, 0.0513,
        0.0707, 0.1125, 0.0883, 0.0713, 0.1015, 0.1365], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,079][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.2351, 0.0553, 0.0098, 0.0014, 0.1188, 0.0072, 0.0416, 0.0628, 0.0810,
        0.0795, 0.0154, 0.1108, 0.1273, 0.0248, 0.0292], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,080][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0185, 0.0787, 0.0726, 0.0749, 0.0722, 0.0798, 0.0721, 0.0713, 0.0674,
        0.0708, 0.0745, 0.0306, 0.0702, 0.0745, 0.0721], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,081][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0293, 0.0231, 0.0387, 0.0455, 0.0534, 0.0655, 0.0307, 0.0354, 0.0306,
        0.0272, 0.1962, 0.0239, 0.0377, 0.1338, 0.2289], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,083][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0116, 0.0052, 0.0138, 0.0009, 0.0238, 0.0017, 0.0041, 0.0055, 0.0076,
        0.0087, 0.0269, 0.0102, 0.0176, 0.7599, 0.1023], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,084][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0344, 0.0259, 0.3726, 0.0810, 0.0779, 0.0106, 0.0174, 0.0187, 0.0350,
        0.0313, 0.0587, 0.0446, 0.0529, 0.0797, 0.0593], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,085][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0035, 0.0090, 0.3089, 0.0578, 0.0107, 0.0682, 0.0057, 0.0026, 0.0055,
        0.0049, 0.0744, 0.0045, 0.0067, 0.3349, 0.1028], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,087][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0637, 0.0434, 0.0458, 0.0689, 0.0835, 0.0733, 0.0819, 0.0706, 0.0538,
        0.0510, 0.0709, 0.0491, 0.0638, 0.1167, 0.0637], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,126][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:26,127][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,128][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,129][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,131][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,132][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,133][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,134][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,135][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,136][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,137][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,138][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,139][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,139][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4672, 0.5328], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,139][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.3386, 0.6614], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,139][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1033, 0.8967], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,140][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.4797, 0.5203], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,140][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.4178, 0.5822], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,140][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4909, 0.5091], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,141][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.4356, 0.5644], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,141][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2604, 0.7396], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,141][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4158, 0.5842], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,141][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.4236, 0.5764], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,142][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1396, 0.8604], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,143][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.3158, 0.6842], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,145][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Jennifer] are: tensor([0.0735, 0.0336, 0.8929], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,146][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Jennifer] are: tensor([0.6016, 0.2327, 0.1657], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,147][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Jennifer] are: tensor([1.6974e-04, 5.3746e-04, 9.9929e-01], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,148][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Jennifer] are: tensor([0.5123, 0.1733, 0.3145], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,149][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Jennifer] are: tensor([0.2120, 0.1141, 0.6739], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,151][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Jennifer] are: tensor([0.7983, 0.1955, 0.0062], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,152][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Jennifer] are: tensor([0.6558, 0.2710, 0.0732], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,154][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Jennifer] are: tensor([0.2821, 0.1843, 0.5336], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,155][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Jennifer] are: tensor([0.2767, 0.1034, 0.6199], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,156][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Jennifer] are: tensor([0.0785, 0.0458, 0.8757], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,158][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Jennifer] are: tensor([0.0020, 0.0029, 0.9951], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,159][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Jennifer] are: tensor([0.4066, 0.3064, 0.2870], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,160][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0220, 0.0113, 0.8838, 0.0829], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,162][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.2502, 0.1478, 0.4018, 0.2002], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,163][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([2.4924e-04, 9.4237e-04, 6.7209e-01, 3.2672e-01], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,164][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1343, 0.0716, 0.6144, 0.1797], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,165][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0290, 0.0235, 0.7850, 0.1626], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,167][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.7061, 0.2226, 0.0487, 0.0226], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,168][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.5410, 0.2611, 0.1082, 0.0897], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,170][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1193, 0.1109, 0.2729, 0.4969], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,170][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0243, 0.0179, 0.8891, 0.0687], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,170][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0150, 0.0113, 0.8378, 0.1359], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,171][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0009, 0.0019, 0.8370, 0.1603], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,171][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1425, 0.1739, 0.4203, 0.2632], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,171][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Megan] are: tensor([0.0539, 0.0461, 0.5794, 0.1493, 0.1713], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,172][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Megan] are: tensor([0.0236, 0.0364, 0.5684, 0.3159, 0.0556], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,172][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Megan] are: tensor([8.0957e-06, 6.1419e-05, 7.4804e-01, 2.5153e-01, 3.6666e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,172][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Megan] are: tensor([0.0963, 0.0772, 0.4089, 0.1987, 0.2189], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,172][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Megan] are: tensor([0.0307, 0.0348, 0.6028, 0.2390, 0.0927], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,173][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Megan] are: tensor([0.3065, 0.2315, 0.1209, 0.1173, 0.2239], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,174][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Megan] are: tensor([0.1385, 0.1448, 0.3055, 0.2437, 0.1675], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,176][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Megan] are: tensor([0.0044, 0.0107, 0.5285, 0.4319, 0.0245], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,177][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Megan] are: tensor([0.0392, 0.0411, 0.6607, 0.1303, 0.1288], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,179][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Megan] are: tensor([0.0261, 0.0274, 0.6415, 0.2228, 0.0823], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,179][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Megan] are: tensor([1.0093e-04, 5.0893e-04, 7.9634e-01, 2.0105e-01, 1.9985e-03],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,181][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Megan] are: tensor([0.0152, 0.0283, 0.6458, 0.2644, 0.0464], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,182][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0344, 0.0204, 0.5660, 0.1078, 0.1944, 0.0769], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,183][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.1483, 0.1081, 0.2886, 0.1784, 0.1594, 0.1172], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,185][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0005, 0.0015, 0.4458, 0.2738, 0.0049, 0.2735], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,186][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0625, 0.0395, 0.3717, 0.1686, 0.1955, 0.1621], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,187][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0275, 0.0246, 0.5452, 0.2056, 0.1033, 0.0938], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,189][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.3443, 0.1649, 0.0892, 0.0499, 0.2422, 0.1095], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,190][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.1933, 0.1335, 0.1610, 0.1290, 0.1667, 0.2165], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,192][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0455, 0.0477, 0.1931, 0.2871, 0.0956, 0.3310], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,193][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0129, 0.0135, 0.7335, 0.1012, 0.0851, 0.0539], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,194][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0072, 0.0069, 0.6448, 0.1787, 0.0550, 0.1073], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,195][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0034, 0.0071, 0.5284, 0.2238, 0.0162, 0.2210], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,197][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0203, 0.0303, 0.3436, 0.1847, 0.0593, 0.3618], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,198][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0227, 0.0241, 0.5728, 0.1629, 0.0804, 0.1104, 0.0267],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,200][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0121, 0.0224, 0.5549, 0.2252, 0.0367, 0.1237, 0.0250],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,200][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([1.5045e-05, 1.1467e-04, 6.8350e-01, 2.5694e-01, 4.9492e-04, 5.8711e-02,
        2.2157e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,201][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0348, 0.0357, 0.3934, 0.2165, 0.0939, 0.1828, 0.0429],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,201][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0100, 0.0141, 0.5584, 0.2326, 0.0409, 0.1278, 0.0161],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,202][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1133, 0.1115, 0.2100, 0.1430, 0.1258, 0.1860, 0.1104],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,202][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0561, 0.0710, 0.2735, 0.1953, 0.0869, 0.2357, 0.0815],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,202][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0045, 0.0113, 0.4527, 0.3181, 0.0226, 0.1769, 0.0139],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,203][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0106, 0.0151, 0.6527, 0.1504, 0.0424, 0.1126, 0.0162],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,203][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0084, 0.0115, 0.5852, 0.2021, 0.0351, 0.1436, 0.0140],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,203][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([1.5077e-04, 8.4802e-04, 7.2195e-01, 2.0035e-01, 2.4110e-03, 7.3028e-02,
        1.2571e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,204][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0090, 0.0192, 0.4663, 0.2068, 0.0298, 0.2446, 0.0243],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,204][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0199, 0.0225, 0.5145, 0.1955, 0.0730, 0.1205, 0.0258, 0.0283],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,205][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0093, 0.0180, 0.5467, 0.2423, 0.0309, 0.1143, 0.0205, 0.0180],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,206][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([2.1021e-05, 1.4855e-04, 6.4964e-01, 2.7865e-01, 6.5568e-04, 7.0289e-02,
        2.8734e-04, 3.0752e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,207][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0336, 0.0346, 0.3491, 0.2269, 0.0895, 0.1798, 0.0414, 0.0451],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,208][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0096, 0.0137, 0.5305, 0.2521, 0.0390, 0.1240, 0.0152, 0.0160],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,210][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0990, 0.1017, 0.1609, 0.1490, 0.1122, 0.1702, 0.1010, 0.1060],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,211][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0501, 0.0632, 0.2478, 0.1836, 0.0793, 0.2281, 0.0721, 0.0760],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,212][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0035, 0.0092, 0.4274, 0.3498, 0.0184, 0.1693, 0.0114, 0.0110],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,214][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0117, 0.0171, 0.5507, 0.1974, 0.0459, 0.1369, 0.0190, 0.0213],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,215][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0088, 0.0118, 0.5266, 0.2308, 0.0363, 0.1554, 0.0147, 0.0155],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,216][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([1.5479e-04, 8.5839e-04, 7.1716e-01, 2.0136e-01, 2.7046e-03, 7.5379e-02,
        1.3251e-03, 1.0521e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,217][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0077, 0.0163, 0.4579, 0.2057, 0.0261, 0.2423, 0.0212, 0.0228],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,219][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0212, 0.0242, 0.5260, 0.1645, 0.0705, 0.1059, 0.0282, 0.0315, 0.0279],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,220][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0109, 0.0220, 0.5253, 0.2245, 0.0337, 0.1183, 0.0239, 0.0212, 0.0202],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,221][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([1.4543e-05, 1.0866e-04, 6.8566e-01, 2.5906e-01, 4.8380e-04, 5.4146e-02,
        2.0631e-04, 2.0189e-04, 1.1241e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,223][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0335, 0.0356, 0.3413, 0.2004, 0.0849, 0.1745, 0.0425, 0.0476, 0.0396],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,224][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0106, 0.0152, 0.5321, 0.2241, 0.0404, 0.1256, 0.0174, 0.0186, 0.0159],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,225][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0857, 0.0901, 0.1729, 0.1330, 0.0985, 0.1411, 0.0909, 0.0950, 0.0927],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,227][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0474, 0.0625, 0.2362, 0.1687, 0.0755, 0.2007, 0.0708, 0.0729, 0.0655],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,228][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0034, 0.0095, 0.4491, 0.3209, 0.0186, 0.1670, 0.0118, 0.0111, 0.0088],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,230][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0136, 0.0185, 0.5651, 0.1639, 0.0479, 0.1257, 0.0211, 0.0241, 0.0200],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,231][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0093, 0.0128, 0.5466, 0.2046, 0.0359, 0.1437, 0.0159, 0.0173, 0.0139],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,232][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([1.9663e-04, 1.1105e-03, 7.1515e-01, 1.9797e-01, 2.9973e-03, 7.8443e-02,
        1.6725e-03, 1.3263e-03, 1.1362e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,233][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0083, 0.0174, 0.4637, 0.1955, 0.0277, 0.2226, 0.0226, 0.0239, 0.0183],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,233][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0255, 0.0280, 0.5043, 0.1436, 0.0769, 0.0937, 0.0315, 0.0343, 0.0320,
        0.0301], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,233][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0102, 0.0206, 0.5333, 0.2100, 0.0330, 0.1112, 0.0225, 0.0197, 0.0191,
        0.0203], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,234][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([1.2960e-05, 1.0497e-04, 6.7882e-01, 2.7108e-01, 4.6970e-04, 4.8930e-02,
        1.9169e-04, 1.8121e-04, 1.0385e-04, 1.0863e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,234][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0358, 0.0379, 0.3237, 0.1858, 0.0865, 0.1563, 0.0440, 0.0483, 0.0417,
        0.0400], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,234][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0130, 0.0181, 0.5135, 0.2076, 0.0458, 0.1225, 0.0204, 0.0213, 0.0190,
        0.0186], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,235][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0820, 0.0851, 0.1552, 0.1130, 0.0929, 0.1256, 0.0840, 0.0890, 0.0879,
        0.0853], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,235][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0475, 0.0621, 0.2136, 0.1560, 0.0729, 0.1800, 0.0694, 0.0711, 0.0647,
        0.0627], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,236][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0039, 0.0110, 0.4596, 0.3084, 0.0207, 0.1502, 0.0131, 0.0125, 0.0100,
        0.0106], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,237][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0153, 0.0206, 0.5642, 0.1479, 0.0497, 0.1109, 0.0227, 0.0254, 0.0222,
        0.0211], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,238][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0112, 0.0150, 0.5441, 0.1876, 0.0398, 0.1332, 0.0182, 0.0194, 0.0163,
        0.0154], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,239][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([1.5299e-04, 9.1923e-04, 7.2941e-01, 1.9313e-01, 2.7022e-03, 6.9492e-02,
        1.3559e-03, 1.0667e-03, 9.2074e-04, 8.4401e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,241][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0093, 0.0197, 0.4522, 0.1896, 0.0300, 0.2092, 0.0246, 0.0262, 0.0205,
        0.0187], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,242][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0550, 0.0247, 0.1851, 0.0161, 0.2117, 0.0226, 0.0265, 0.0295, 0.0389,
        0.0405, 0.3494], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,243][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0588, 0.0487, 0.2495, 0.1025, 0.1101, 0.0694, 0.0546, 0.0613, 0.0567,
        0.0578, 0.1308], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,244][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([5.5436e-05, 3.0371e-04, 4.6017e-01, 2.4502e-01, 1.4450e-03, 7.9625e-02,
        6.9852e-04, 6.8479e-04, 3.4345e-04, 3.0900e-04, 2.1135e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,246][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0717, 0.0364, 0.1359, 0.0341, 0.1714, 0.0473, 0.0390, 0.0412, 0.0496,
        0.0509, 0.3225], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,247][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0416, 0.0325, 0.2478, 0.0528, 0.1183, 0.0427, 0.0301, 0.0325, 0.0355,
        0.0400, 0.3263], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,248][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2484, 0.0873, 0.0299, 0.0074, 0.1629, 0.0189, 0.0706, 0.0944, 0.1165,
        0.1171, 0.0466], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,250][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1665, 0.0883, 0.0435, 0.0282, 0.0994, 0.0624, 0.0960, 0.1011, 0.1124,
        0.1096, 0.0925], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,251][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0195, 0.0221, 0.1094, 0.1495, 0.0494, 0.1042, 0.0285, 0.0298, 0.0255,
        0.0250, 0.4371], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,253][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0431, 0.0287, 0.3207, 0.0206, 0.1322, 0.0232, 0.0239, 0.0292, 0.0367,
        0.0415, 0.3002], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,254][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0226, 0.0162, 0.3282, 0.0458, 0.0914, 0.0469, 0.0180, 0.0199, 0.0214,
        0.0229, 0.3667], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,255][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([2.0156e-04, 7.4816e-04, 7.8758e-01, 9.6834e-02, 3.8055e-03, 4.9238e-02,
        1.1306e-03, 9.0813e-04, 7.9620e-04, 7.0518e-04, 5.8056e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,256][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0461, 0.0611, 0.1898, 0.0966, 0.0822, 0.1719, 0.0712, 0.0696, 0.0593,
        0.0575, 0.0947], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,258][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0171, 0.0203, 0.4123, 0.1324, 0.0535, 0.0845, 0.0234, 0.0257, 0.0231,
        0.0216, 0.1646, 0.0214], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,259][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0054, 0.0130, 0.5146, 0.1948, 0.0213, 0.0973, 0.0143, 0.0126, 0.0117,
        0.0125, 0.0922, 0.0103], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,260][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([6.1173e-06, 5.7805e-05, 6.1705e-01, 2.1782e-01, 2.7112e-04, 3.7170e-02,
        1.0617e-04, 1.0281e-04, 5.6688e-05, 5.9261e-05, 1.2727e-01, 3.2654e-05],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,262][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0217, 0.0248, 0.2763, 0.1543, 0.0580, 0.1290, 0.0298, 0.0337, 0.0273,
        0.0259, 0.1939, 0.0254], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,263][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0076, 0.0113, 0.4514, 0.1735, 0.0302, 0.1022, 0.0132, 0.0141, 0.0120,
        0.0116, 0.1623, 0.0106], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,264][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0576, 0.0651, 0.1429, 0.1146, 0.0690, 0.1208, 0.0673, 0.0686, 0.0665,
        0.0642, 0.1001, 0.0635], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,264][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0298, 0.0435, 0.2049, 0.1500, 0.0525, 0.1660, 0.0497, 0.0509, 0.0447,
        0.0432, 0.1239, 0.0409], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,264][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0019, 0.0064, 0.4089, 0.2605, 0.0126, 0.1194, 0.0078, 0.0074, 0.0057,
        0.0061, 0.1588, 0.0045], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,265][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0102, 0.0149, 0.4681, 0.1394, 0.0357, 0.1048, 0.0173, 0.0195, 0.0159,
        0.0149, 0.1448, 0.0146], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,265][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0073, 0.0105, 0.4724, 0.1633, 0.0277, 0.1140, 0.0131, 0.0140, 0.0114,
        0.0107, 0.1457, 0.0100], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,265][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([7.7986e-05, 5.5816e-04, 6.9364e-01, 1.8172e-01, 1.7130e-03, 6.4525e-02,
        8.5175e-04, 6.7629e-04, 5.5823e-04, 5.0288e-04, 5.4831e-02, 3.4599e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,266][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0054, 0.0126, 0.4367, 0.1762, 0.0198, 0.1804, 0.0162, 0.0170, 0.0129,
        0.0119, 0.1008, 0.0102], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,266][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Megan] are: tensor([0.0307, 0.0302, 0.2980, 0.0906, 0.0799, 0.0698, 0.0332, 0.0365, 0.0352,
        0.0344, 0.1763, 0.0349, 0.0503], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,266][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Megan] are: tensor([0.0089, 0.0179, 0.4522, 0.1928, 0.0279, 0.0951, 0.0196, 0.0169, 0.0163,
        0.0174, 0.1023, 0.0149, 0.0178], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,267][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Megan] are: tensor([1.1213e-05, 8.7037e-05, 6.0182e-01, 2.1642e-01, 4.0995e-04, 4.9580e-02,
        1.6614e-04, 1.5795e-04, 8.8707e-05, 8.9967e-05, 1.3098e-01, 5.1641e-05,
        1.3661e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,269][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Megan] are: tensor([0.0324, 0.0316, 0.2070, 0.1131, 0.0745, 0.1167, 0.0368, 0.0407, 0.0355,
        0.0342, 0.1922, 0.0347, 0.0506], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,270][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Megan] are: tensor([0.0141, 0.0186, 0.3653, 0.1511, 0.0443, 0.0981, 0.0200, 0.0211, 0.0194,
        0.0196, 0.1838, 0.0183, 0.0264], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,271][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Megan] are: tensor([0.0737, 0.0728, 0.0862, 0.0736, 0.0727, 0.0937, 0.0703, 0.0749, 0.0755,
        0.0732, 0.0830, 0.0750, 0.0756], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,273][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Megan] are: tensor([0.0397, 0.0500, 0.1551, 0.1167, 0.0582, 0.1483, 0.0557, 0.0580, 0.0524,
        0.0507, 0.1114, 0.0491, 0.0547], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,274][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Megan] are: tensor([0.0026, 0.0074, 0.3570, 0.2576, 0.0149, 0.1363, 0.0093, 0.0088, 0.0068,
        0.0071, 0.1784, 0.0053, 0.0085], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,275][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Megan] are: tensor([0.0194, 0.0240, 0.3700, 0.1056, 0.0563, 0.0978, 0.0254, 0.0291, 0.0260,
        0.0252, 0.1596, 0.0254, 0.0362], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,277][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Megan] are: tensor([0.0134, 0.0163, 0.3786, 0.1428, 0.0409, 0.1157, 0.0192, 0.0204, 0.0180,
        0.0172, 0.1770, 0.0167, 0.0239], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,278][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Megan] are: tensor([1.2852e-04, 7.6471e-04, 6.8704e-01, 1.7003e-01, 2.3839e-03, 7.6608e-02,
        1.2008e-03, 9.3125e-04, 7.7253e-04, 6.9533e-04, 5.7974e-02, 4.9124e-04,
        9.8067e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,279][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Megan] are: tensor([0.0070, 0.0144, 0.3993, 0.1627, 0.0236, 0.1989, 0.0190, 0.0193, 0.0150,
        0.0136, 0.0983, 0.0119, 0.0172], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,281][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0448, 0.0095, 0.0080, 0.0007, 0.0957, 0.0025, 0.0092, 0.0120, 0.0170,
        0.0196, 0.0748, 0.0245, 0.0554, 0.6263], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,282][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.1710, 0.0621, 0.0365, 0.0234, 0.0997, 0.0282, 0.0680, 0.0874, 0.0830,
        0.0759, 0.0474, 0.0913, 0.0905, 0.0358], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,284][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0007, 0.0014, 0.1127, 0.0527, 0.0051, 0.0660, 0.0034, 0.0041, 0.0022,
        0.0016, 0.0840, 0.0012, 0.0025, 0.6627], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,285][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0675, 0.0214, 0.0198, 0.0071, 0.1093, 0.0160, 0.0226, 0.0255, 0.0324,
        0.0343, 0.1283, 0.0432, 0.0757, 0.3969], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,287][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0257, 0.0165, 0.0273, 0.0114, 0.0524, 0.0170, 0.0144, 0.0171, 0.0174,
        0.0210, 0.1458, 0.0230, 0.0414, 0.5695], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,288][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.3019, 0.0592, 0.0028, 0.0008, 0.0899, 0.0038, 0.0423, 0.0577, 0.0852,
        0.0864, 0.0115, 0.1233, 0.1266, 0.0088], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,289][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.1930, 0.0713, 0.0094, 0.0104, 0.0674, 0.0244, 0.0737, 0.0784, 0.0926,
        0.0921, 0.0522, 0.1010, 0.1008, 0.0335], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,291][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0545, 0.0259, 0.0261, 0.0492, 0.0613, 0.1017, 0.0356, 0.0404, 0.0347,
        0.0306, 0.2898, 0.0289, 0.0439, 0.1775], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,292][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0188, 0.0066, 0.0103, 0.0011, 0.0337, 0.0019, 0.0055, 0.0069, 0.0089,
        0.0112, 0.0508, 0.0135, 0.0238, 0.8071], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,294][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0116, 0.0073, 0.0533, 0.0140, 0.0503, 0.0201, 0.0085, 0.0088, 0.0092,
        0.0109, 0.1749, 0.0111, 0.0226, 0.5973], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,295][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0061, 0.0058, 0.4358, 0.0982, 0.0254, 0.0752, 0.0087, 0.0072, 0.0071,
        0.0052, 0.0877, 0.0053, 0.0089, 0.2233], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,295][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0725, 0.0532, 0.0542, 0.0486, 0.0750, 0.1477, 0.0696, 0.0745, 0.0598,
        0.0614, 0.0766, 0.0519, 0.0676, 0.0873], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,296][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0275, 0.0075, 0.0111, 0.0009, 0.0746, 0.0026, 0.0074, 0.0102, 0.0137,
        0.0145, 0.0540, 0.0181, 0.0393, 0.5764, 0.1420], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,296][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1173, 0.0560, 0.0601, 0.0287, 0.0902, 0.0287, 0.0647, 0.0808, 0.0747,
        0.0713, 0.0639, 0.0827, 0.0773, 0.0714, 0.0323], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,297][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.4688e-05, 5.5617e-05, 3.6226e-02, 9.7114e-03, 2.8646e-04, 7.3771e-03,
        1.5706e-04, 1.4871e-04, 8.3114e-05, 6.1620e-05, 1.3413e-02, 4.0812e-05,
        1.0521e-04, 3.6552e-01, 5.6680e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,297][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0471, 0.0177, 0.0206, 0.0055, 0.0811, 0.0110, 0.0185, 0.0202, 0.0269,
        0.0275, 0.0897, 0.0337, 0.0590, 0.3198, 0.2217], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,297][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0324, 0.0191, 0.0242, 0.0098, 0.0522, 0.0091, 0.0158, 0.0174, 0.0211,
        0.0248, 0.0924, 0.0278, 0.0424, 0.4690, 0.1425], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,298][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.2351, 0.0553, 0.0098, 0.0014, 0.1188, 0.0072, 0.0416, 0.0628, 0.0810,
        0.0795, 0.0154, 0.1108, 0.1273, 0.0248, 0.0292], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,299][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1531, 0.0650, 0.0123, 0.0104, 0.0638, 0.0243, 0.0691, 0.0691, 0.0833,
        0.0830, 0.0432, 0.0919, 0.0922, 0.0509, 0.0886], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,301][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0293, 0.0231, 0.0387, 0.0455, 0.0534, 0.0655, 0.0307, 0.0354, 0.0306,
        0.0272, 0.1962, 0.0239, 0.0377, 0.1338, 0.2289], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,302][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0116, 0.0052, 0.0138, 0.0009, 0.0238, 0.0017, 0.0041, 0.0055, 0.0076,
        0.0087, 0.0269, 0.0102, 0.0176, 0.7599, 0.1023], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,303][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0166, 0.0093, 0.0381, 0.0087, 0.0456, 0.0106, 0.0095, 0.0109, 0.0126,
        0.0136, 0.0965, 0.0149, 0.0261, 0.4770, 0.2101], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,304][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([2.5590e-04, 5.6043e-04, 4.9607e-01, 2.9823e-02, 2.9563e-03, 2.0717e-02,
        9.4278e-04, 6.7959e-04, 7.2791e-04, 5.4884e-04, 1.8496e-02, 4.5491e-04,
        9.2526e-04, 2.6403e-01, 1.6282e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,306][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0827, 0.0737, 0.0483, 0.0347, 0.1003, 0.0803, 0.0817, 0.0877, 0.0727,
        0.0688, 0.0369, 0.0660, 0.0869, 0.0401, 0.0392], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,307][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:26,308][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 8305],
        [ 4446],
        [11751],
        [ 4460],
        [13468],
        [ 1913],
        [ 5094],
        [ 6446],
        [ 8168],
        [ 6646],
        [ 3178],
        [ 7605],
        [14535],
        [ 1371],
        [ 2254]], device='cuda:0')
[2024-07-24 10:29:26,309][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 9052],
        [11186],
        [21542],
        [10186],
        [27273],
        [ 8867],
        [12651],
        [14514],
        [15526],
        [12899],
        [13504],
        [10940],
        [27262],
        [10020],
        [12610]], device='cuda:0')
[2024-07-24 10:29:26,311][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[27222],
        [27432],
        [39725],
        [39255],
        [38631],
        [38431],
        [37358],
        [36809],
        [37208],
        [37317],
        [36588],
        [36561],
        [36538],
        [34152],
        [33898]], device='cuda:0')
[2024-07-24 10:29:26,312][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[22119],
        [17367],
        [23409],
        [15408],
        [13781],
        [10048],
        [14234],
        [14084],
        [13992],
        [14247],
        [10848],
        [14455],
        [13373],
        [ 5403],
        [ 6891]], device='cuda:0')
[2024-07-24 10:29:26,314][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[16866],
        [ 5526],
        [13276],
        [11704],
        [    9],
        [11561],
        [    9],
        [    8],
        [    1],
        [    1],
        [11157],
        [    1],
        [   11],
        [13138],
        [ 9307]], device='cuda:0')
[2024-07-24 10:29:26,315][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 7764],
        [10133],
        [ 4867],
        [ 5802],
        [ 3504],
        [ 4887],
        [20146],
        [21313],
        [21303],
        [19460],
        [ 5837],
        [21675],
        [20081],
        [ 9098],
        [ 7394]], device='cuda:0')
[2024-07-24 10:29:26,316][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[24904],
        [34657],
        [36244],
        [39156],
        [38781],
        [40018],
        [40072],
        [40123],
        [39965],
        [39733],
        [38949],
        [39583],
        [39592],
        [37713],
        [35768]], device='cuda:0')
[2024-07-24 10:29:26,318][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[28853],
        [32159],
        [30975],
        [37099],
        [45540],
        [42717],
        [41541],
        [39805],
        [41090],
        [41214],
        [40074],
        [39947],
        [39420],
        [38003],
        [40153]], device='cuda:0')
[2024-07-24 10:29:26,319][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 122],
        [ 515],
        [ 835],
        [1022],
        [1187],
        [1234],
        [1434],
        [1465],
        [1600],
        [1627],
        [1620],
        [1634],
        [1627],
        [1772],
        [1750]], device='cuda:0')
[2024-07-24 10:29:26,321][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[41112],
        [34349],
        [49876],
        [48983],
        [49528],
        [49320],
        [49570],
        [49521],
        [49565],
        [49586],
        [47869],
        [49378],
        [49274],
        [48197],
        [48133]], device='cuda:0')
[2024-07-24 10:29:26,322][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 2499],
        [ 1384],
        [10744],
        [15003],
        [12258],
        [13029],
        [12285],
        [11345],
        [11184],
        [11001],
        [ 6913],
        [10151],
        [ 8126],
        [16671],
        [16412]], device='cuda:0')
[2024-07-24 10:29:26,323][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[26432],
        [28690],
        [12020],
        [13191],
        [15235],
        [15457],
        [14802],
        [15882],
        [14977],
        [14798],
        [13536],
        [15602],
        [15947],
        [15238],
        [15045]], device='cuda:0')
[2024-07-24 10:29:26,325][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 6211],
        [ 6916],
        [49815],
        [47840],
        [47763],
        [32321],
        [45864],
        [45262],
        [44548],
        [44845],
        [42532],
        [41907],
        [41420],
        [30266],
        [39141]], device='cuda:0')
[2024-07-24 10:29:26,326][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[15582],
        [ 2823],
        [ 4256],
        [ 1484],
        [ 1579],
        [  862],
        [  707],
        [  657],
        [  735],
        [  762],
        [  778],
        [  668],
        [  655],
        [  625],
        [  602]], device='cuda:0')
[2024-07-24 10:29:26,327][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[15167],
        [ 1919],
        [ 1203],
        [ 1772],
        [ 3494],
        [ 2368],
        [10512],
        [11405],
        [ 9717],
        [ 9479],
        [ 2266],
        [ 7966],
        [ 9669],
        [ 2188],
        [ 2475]], device='cuda:0')
[2024-07-24 10:29:26,329][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[17575],
        [16228],
        [19521],
        [19233],
        [18995],
        [19596],
        [20365],
        [20672],
        [20390],
        [20320],
        [17662],
        [20241],
        [19797],
        [10916],
        [11276]], device='cuda:0')
[2024-07-24 10:29:26,330][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[31497],
        [38720],
        [40366],
        [40186],
        [40230],
        [41306],
        [40392],
        [40445],
        [40516],
        [40515],
        [42491],
        [40911],
        [41201],
        [43642],
        [44584]], device='cuda:0')
[2024-07-24 10:29:26,331][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[23382],
        [18469],
        [23165],
        [24863],
        [24358],
        [27332],
        [24881],
        [25152],
        [24858],
        [24896],
        [29506],
        [26894],
        [27097],
        [31288],
        [31795]], device='cuda:0')
[2024-07-24 10:29:26,331][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 6414],
        [12813],
        [24948],
        [37818],
        [34109],
        [32274],
        [30821],
        [29600],
        [29907],
        [29911],
        [15557],
        [22194],
        [20731],
        [17050],
        [13804]], device='cuda:0')
[2024-07-24 10:29:26,332][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[34328],
        [25271],
        [ 6671],
        [ 4932],
        [ 4597],
        [ 4169],
        [ 3779],
        [ 3645],
        [ 3740],
        [ 3794],
        [ 2032],
        [ 2636],
        [ 2468],
        [ 1593],
        [ 1335]], device='cuda:0')
[2024-07-24 10:29:26,334][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[28206],
        [23912],
        [25964],
        [19567],
        [19518],
        [24334],
        [27898],
        [28455],
        [27446],
        [26971],
        [17778],
        [25787],
        [24784],
        [20074],
        [19814]], device='cuda:0')
[2024-07-24 10:29:26,335][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[41276],
        [45607],
        [46225],
        [46945],
        [46315],
        [45985],
        [45323],
        [45212],
        [45481],
        [45681],
        [46248],
        [44399],
        [44861],
        [46928],
        [45439]], device='cuda:0')
[2024-07-24 10:29:26,336][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[24604],
        [37997],
        [18528],
        [15229],
        [15782],
        [11859],
        [14272],
        [14084],
        [14310],
        [14609],
        [ 7321],
        [12893],
        [12205],
        [ 5946],
        [ 5478]], device='cuda:0')
[2024-07-24 10:29:26,338][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[34677],
        [33681],
        [39805],
        [40315],
        [41326],
        [41387],
        [41548],
        [41560],
        [41696],
        [41749],
        [36938],
        [40825],
        [39941],
        [41258],
        [41537]], device='cuda:0')
[2024-07-24 10:29:26,339][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[42392],
        [40419],
        [21299],
        [19728],
        [18476],
        [17873],
        [17240],
        [16661],
        [17188],
        [17518],
        [17719],
        [17166],
        [17043],
        [13103],
        [12975]], device='cuda:0')
[2024-07-24 10:29:26,340][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[20475],
        [19523],
        [19101],
        [18516],
        [18317],
        [13713],
        [17017],
        [16971],
        [16942],
        [17137],
        [18114],
        [17201],
        [17062],
        [13460],
        [15588]], device='cuda:0')
[2024-07-24 10:29:26,341][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[19609],
        [13721],
        [ 6013],
        [ 5421],
        [ 4993],
        [ 7221],
        [ 6190],
        [ 6287],
        [ 6193],
        [ 6213],
        [ 8793],
        [ 6533],
        [ 6774],
        [11498],
        [12182]], device='cuda:0')
[2024-07-24 10:29:26,343][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[10138],
        [ 7881],
        [14042],
        [13336],
        [13373],
        [14997],
        [13628],
        [13775],
        [13621],
        [13465],
        [24483],
        [17001],
        [17973],
        [29134],
        [28569]], device='cuda:0')
[2024-07-24 10:29:26,344][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[11916],
        [22476],
        [46420],
        [45282],
        [37345],
        [41219],
        [28104],
        [27432],
        [33431],
        [34872],
        [41558],
        [35923],
        [28557],
        [41789],
        [40443]], device='cuda:0')
[2024-07-24 10:29:26,346][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[9667],
        [9667],
        [9667],
        [9667],
        [9667],
        [9667],
        [9667],
        [9667],
        [9667],
        [9667],
        [9667],
        [9667],
        [9667],
        [9667],
        [9667]], device='cuda:0')
[2024-07-24 10:29:26,388][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:26,389][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,390][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,391][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,392][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,392][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,392][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,393][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,393][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,393][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,394][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,394][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,394][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,395][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4894, 0.5106], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,396][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1110, 0.8890], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,397][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4351, 0.5649], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,398][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3511, 0.6489], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,399][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3970, 0.6030], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,401][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.5098, 0.4902], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,402][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3197, 0.6803], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,403][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.4397, 0.5603], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,405][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.5094, 0.4906], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,406][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.4461, 0.5539], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,408][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4358, 0.5642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,409][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.3460, 0.6540], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,410][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Jennifer] are: tensor([0.7030, 0.2592, 0.0378], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,412][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Jennifer] are: tensor([0.0114, 0.0074, 0.9812], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,413][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Jennifer] are: tensor([0.6937, 0.2491, 0.0571], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,414][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Jennifer] are: tensor([0.5102, 0.2763, 0.2135], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,416][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Jennifer] are: tensor([0.1263, 0.0642, 0.8094], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,417][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Jennifer] are: tensor([0.5381, 0.1703, 0.2916], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,419][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Jennifer] are: tensor([0.5628, 0.1808, 0.2564], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,420][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Jennifer] are: tensor([0.0964, 0.0455, 0.8581], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,422][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Jennifer] are: tensor([0.8273, 0.1524, 0.0203], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,423][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Jennifer] are: tensor([0.7542, 0.2219, 0.0239], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,423][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Jennifer] are: tensor([0.4581, 0.1952, 0.3466], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,424][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Jennifer] are: tensor([0.1112, 0.0718, 0.8170], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,424][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.4876, 0.2487, 0.1463, 0.1174], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,424][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0032, 0.0024, 0.8126, 0.1818], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,424][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.5801, 0.2666, 0.0940, 0.0593], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,425][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1361, 0.0921, 0.4853, 0.2866], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,425][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0135, 0.0098, 0.8425, 0.1342], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,425][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3067, 0.1016, 0.4841, 0.1076], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,426][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2510, 0.1350, 0.4467, 0.1673], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,426][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0228, 0.0131, 0.8305, 0.1335], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,428][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.6637, 0.1610, 0.1445, 0.0309], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,429][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.6107, 0.2344, 0.0896, 0.0652], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,430][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1497, 0.0828, 0.5726, 0.1949], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,432][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0200, 0.0154, 0.5305, 0.4341], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,433][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Megan] are: tensor([0.1156, 0.1020, 0.2227, 0.3272, 0.2325], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,434][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Megan] are: tensor([5.0333e-05, 3.2735e-04, 7.8610e-01, 2.1272e-01, 7.9326e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,435][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Megan] are: tensor([0.1164, 0.1265, 0.3087, 0.3180, 0.1304], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,437][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Megan] are: tensor([0.0268, 0.0445, 0.4566, 0.4173, 0.0547], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,438][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Megan] are: tensor([0.0250, 0.0324, 0.6081, 0.2624, 0.0721], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,439][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Megan] are: tensor([0.1702, 0.1228, 0.3594, 0.1549, 0.1927], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,441][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Megan] are: tensor([0.0233, 0.0404, 0.5363, 0.3420, 0.0581], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,442][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Megan] are: tensor([0.0476, 0.0521, 0.5383, 0.2109, 0.1511], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,444][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Megan] are: tensor([0.2501, 0.1749, 0.2131, 0.1281, 0.2337], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,445][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Megan] are: tensor([0.1626, 0.1621, 0.2358, 0.2593, 0.1801], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,446][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Megan] are: tensor([0.0568, 0.0627, 0.4905, 0.2715, 0.1184], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,448][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Megan] are: tensor([0.0112, 0.0176, 0.4042, 0.5384, 0.0286], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,449][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.1745, 0.1156, 0.1831, 0.1723, 0.3142, 0.0403], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,450][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0060, 0.0050, 0.6511, 0.2362, 0.0110, 0.0908], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,451][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.2599, 0.1589, 0.1506, 0.1258, 0.1610, 0.1437], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,453][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0436, 0.0461, 0.3764, 0.3009, 0.0754, 0.1575], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,454][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0084, 0.0083, 0.6596, 0.2348, 0.0422, 0.0467], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,455][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.1298, 0.0598, 0.3608, 0.1837, 0.1818, 0.0840], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,455][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0702, 0.0496, 0.3350, 0.2266, 0.0861, 0.2326], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,455][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0287, 0.0200, 0.4618, 0.2800, 0.1414, 0.0681], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,456][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.2678, 0.1096, 0.1750, 0.0650, 0.2541, 0.1284], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,456][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.2353, 0.1406, 0.1435, 0.1459, 0.1984, 0.1363], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,456][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0616, 0.0451, 0.4321, 0.2035, 0.1204, 0.1372], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,457][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0051, 0.0068, 0.4641, 0.4156, 0.0238, 0.0846], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,457][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0726, 0.0727, 0.1778, 0.3162, 0.1437, 0.0767, 0.1402],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,457][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([1.0743e-04, 6.7630e-04, 7.2616e-01, 2.3127e-01, 1.3712e-03, 3.9511e-02,
        9.0626e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,458][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0605, 0.0736, 0.2664, 0.2538, 0.0809, 0.1854, 0.0794],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,459][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0101, 0.0194, 0.4475, 0.3400, 0.0272, 0.1340, 0.0219],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,460][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0065, 0.0100, 0.6091, 0.2608, 0.0224, 0.0808, 0.0105],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,461][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0586, 0.0547, 0.4126, 0.2032, 0.0854, 0.1345, 0.0510],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,463][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0170, 0.0320, 0.4583, 0.2596, 0.0466, 0.1510, 0.0355],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,464][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0175, 0.0219, 0.5210, 0.2620, 0.0610, 0.0939, 0.0226],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,465][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1056, 0.0915, 0.2461, 0.1628, 0.1256, 0.1763, 0.0921],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,467][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0649, 0.0781, 0.2240, 0.2746, 0.0911, 0.1862, 0.0811],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,468][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0259, 0.0329, 0.4629, 0.2469, 0.0596, 0.1352, 0.0366],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,470][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0043, 0.0082, 0.3763, 0.4848, 0.0145, 0.1021, 0.0098],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,471][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0638, 0.0653, 0.1770, 0.2771, 0.1276, 0.0705, 0.1239, 0.0949],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,472][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ long] are: tensor([1.5542e-04, 9.5304e-04, 6.8947e-01, 2.5611e-01, 1.8028e-03, 4.8976e-02,
        1.2871e-03, 1.2522e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,473][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0463, 0.0601, 0.2473, 0.2629, 0.0646, 0.1888, 0.0650, 0.0650],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,475][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0113, 0.0210, 0.4212, 0.3378, 0.0299, 0.1324, 0.0234, 0.0230],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,476][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0081, 0.0121, 0.5189, 0.3105, 0.0254, 0.0981, 0.0130, 0.0139],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,478][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0542, 0.0505, 0.3483, 0.2333, 0.0787, 0.1366, 0.0483, 0.0501],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,479][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0147, 0.0283, 0.4292, 0.2639, 0.0421, 0.1518, 0.0321, 0.0378],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,480][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0167, 0.0209, 0.4051, 0.3439, 0.0570, 0.1102, 0.0225, 0.0237],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,482][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0920, 0.0822, 0.2159, 0.1643, 0.1087, 0.1661, 0.0834, 0.0874],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,483][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0543, 0.0673, 0.2076, 0.2763, 0.0804, 0.1741, 0.0709, 0.0691],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,485][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0248, 0.0315, 0.4235, 0.2563, 0.0574, 0.1372, 0.0348, 0.0344],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,486][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0041, 0.0080, 0.3734, 0.4870, 0.0141, 0.0951, 0.0095, 0.0087],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,486][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0628, 0.0647, 0.1475, 0.2625, 0.1159, 0.0709, 0.1214, 0.0914, 0.0628],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,486][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([9.9840e-05, 7.5011e-04, 7.1554e-01, 2.3748e-01, 1.4435e-03, 4.1923e-02,
        1.0227e-03, 9.6647e-04, 7.7151e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,487][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0448, 0.0595, 0.2477, 0.2308, 0.0640, 0.1651, 0.0639, 0.0651, 0.0593],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,487][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0109, 0.0217, 0.4196, 0.3181, 0.0295, 0.1318, 0.0240, 0.0233, 0.0210],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,487][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0090, 0.0135, 0.5431, 0.2657, 0.0274, 0.0965, 0.0147, 0.0161, 0.0141],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,488][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0516, 0.0495, 0.3495, 0.1887, 0.0753, 0.1315, 0.0492, 0.0521, 0.0526],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,488][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0135, 0.0282, 0.4605, 0.2342, 0.0413, 0.1256, 0.0314, 0.0363, 0.0289],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,488][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0195, 0.0243, 0.4552, 0.2529, 0.0619, 0.1039, 0.0266, 0.0293, 0.0264],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,490][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0807, 0.0769, 0.2097, 0.1418, 0.1012, 0.1465, 0.0788, 0.0838, 0.0806],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,491][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0551, 0.0692, 0.1926, 0.2295, 0.0794, 0.1590, 0.0720, 0.0712, 0.0721],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,492][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0258, 0.0336, 0.4123, 0.2312, 0.0583, 0.1295, 0.0371, 0.0368, 0.0353],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,494][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0050, 0.0097, 0.3787, 0.4549, 0.0163, 0.1038, 0.0117, 0.0109, 0.0090],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,495][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0585, 0.0612, 0.1376, 0.2468, 0.1092, 0.0689, 0.1149, 0.0863, 0.0595,
        0.0570], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,496][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([9.2914e-05, 7.3405e-04, 7.3008e-01, 2.2564e-01, 1.4385e-03, 3.8642e-02,
        9.8172e-04, 9.1734e-04, 7.4294e-04, 7.2648e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,497][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0457, 0.0594, 0.2288, 0.2064, 0.0643, 0.1498, 0.0637, 0.0651, 0.0596,
        0.0573], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,499][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0119, 0.0228, 0.4090, 0.3011, 0.0305, 0.1315, 0.0251, 0.0244, 0.0221,
        0.0216], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,500][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0104, 0.0155, 0.5509, 0.2377, 0.0300, 0.0906, 0.0163, 0.0172, 0.0159,
        0.0155], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,502][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0582, 0.0554, 0.3138, 0.1572, 0.0784, 0.1139, 0.0535, 0.0547, 0.0583,
        0.0566], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,503][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0141, 0.0304, 0.4483, 0.2156, 0.0434, 0.1158, 0.0330, 0.0382, 0.0309,
        0.0305], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,505][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0236, 0.0292, 0.4487, 0.2125, 0.0685, 0.0919, 0.0306, 0.0327, 0.0313,
        0.0310], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,506][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0787, 0.0749, 0.1838, 0.1234, 0.0962, 0.1288, 0.0764, 0.0819, 0.0788,
        0.0770], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,507][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0541, 0.0675, 0.1756, 0.2024, 0.0771, 0.1437, 0.0697, 0.0689, 0.0702,
        0.0708], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,509][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0271, 0.0350, 0.3913, 0.2154, 0.0593, 0.1231, 0.0381, 0.0377, 0.0365,
        0.0364], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,510][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0056, 0.0106, 0.3663, 0.4450, 0.0173, 0.1109, 0.0127, 0.0120, 0.0098,
        0.0098], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,512][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1138, 0.0658, 0.0483, 0.0438, 0.1751, 0.0169, 0.1416, 0.0946, 0.0683,
        0.0656, 0.1663], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,512][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([5.5276e-04, 9.0138e-04, 7.2280e-01, 1.3550e-01, 2.9591e-03, 3.8388e-02,
        1.3557e-03, 1.2928e-03, 1.0766e-03, 9.5928e-04, 9.4218e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,514][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2079, 0.1073, 0.0334, 0.0197, 0.1127, 0.0300, 0.0987, 0.0996, 0.1257,
        0.1224, 0.0426], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,515][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0380, 0.0371, 0.2498, 0.1460, 0.0636, 0.0835, 0.0382, 0.0363, 0.0410,
        0.0413, 0.2252], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,517][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0309, 0.0214, 0.3268, 0.0325, 0.0859, 0.0213, 0.0202, 0.0193, 0.0258,
        0.0298, 0.3861], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,517][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1974, 0.0732, 0.0777, 0.0125, 0.1797, 0.0175, 0.0531, 0.0553, 0.0897,
        0.1006, 0.1432], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,517][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0538, 0.0414, 0.2792, 0.0637, 0.0883, 0.0895, 0.0437, 0.0594, 0.0503,
        0.0456, 0.1852], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,518][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0473, 0.0274, 0.1457, 0.0184, 0.1743, 0.0141, 0.0247, 0.0271, 0.0361,
        0.0438, 0.4409], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,518][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2266, 0.0745, 0.0571, 0.0102, 0.1816, 0.0249, 0.0674, 0.0765, 0.0965,
        0.1023, 0.0824], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,518][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1730, 0.0835, 0.0375, 0.0245, 0.1290, 0.0321, 0.0826, 0.0876, 0.1046,
        0.1121, 0.1335], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,519][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0574, 0.0382, 0.2247, 0.0609, 0.1076, 0.0542, 0.0403, 0.0408, 0.0481,
        0.0500, 0.2776], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,519][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0128, 0.0118, 0.3054, 0.1771, 0.0383, 0.0578, 0.0133, 0.0125, 0.0127,
        0.0136, 0.3448], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,520][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0365, 0.0401, 0.1077, 0.2166, 0.0727, 0.0513, 0.0783, 0.0580, 0.0386,
        0.0368, 0.2265, 0.0371], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,520][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([3.8023e-05, 3.8802e-04, 7.2232e-01, 2.0883e-01, 7.6813e-04, 3.1427e-02,
        5.3423e-04, 4.9556e-04, 3.9205e-04, 3.8040e-04, 3.4198e-02, 2.2816e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,520][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0268, 0.0398, 0.2267, 0.2074, 0.0433, 0.1354, 0.0438, 0.0448, 0.0396,
        0.0377, 0.1202, 0.0346], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,522][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0073, 0.0156, 0.3944, 0.2721, 0.0215, 0.1104, 0.0176, 0.0171, 0.0151,
        0.0147, 0.1014, 0.0127], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,523][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0068, 0.0109, 0.4747, 0.2144, 0.0210, 0.0804, 0.0117, 0.0127, 0.0113,
        0.0109, 0.1346, 0.0106], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,524][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0406, 0.0415, 0.2844, 0.1394, 0.0579, 0.1036, 0.0411, 0.0428, 0.0440,
        0.0421, 0.1196, 0.0430], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,526][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0074, 0.0189, 0.4253, 0.2077, 0.0274, 0.0991, 0.0210, 0.0241, 0.0190,
        0.0187, 0.1159, 0.0155], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,527][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0137, 0.0187, 0.3787, 0.1846, 0.0440, 0.0788, 0.0203, 0.0224, 0.0203,
        0.0196, 0.1796, 0.0194], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,528][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0517, 0.0546, 0.1647, 0.1244, 0.0701, 0.1211, 0.0577, 0.0618, 0.0573,
        0.0554, 0.1251, 0.0559], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,530][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0338, 0.0464, 0.1628, 0.1824, 0.0538, 0.1217, 0.0486, 0.0481, 0.0480,
        0.0481, 0.1609, 0.0455], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,531][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0164, 0.0230, 0.3494, 0.1896, 0.0399, 0.1012, 0.0256, 0.0253, 0.0240,
        0.0238, 0.1599, 0.0219], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,532][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0032, 0.0067, 0.3224, 0.3956, 0.0110, 0.0886, 0.0082, 0.0078, 0.0062,
        0.0061, 0.1387, 0.0055], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,534][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Megan] are: tensor([0.0447, 0.0441, 0.0946, 0.1657, 0.0838, 0.0430, 0.0846, 0.0638, 0.0431,
        0.0409, 0.1865, 0.0420, 0.0632], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,535][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Megan] are: tensor([8.4647e-05, 6.3144e-04, 6.9609e-01, 2.1854e-01, 1.2620e-03, 3.8234e-02,
        8.5734e-04, 7.8787e-04, 6.4589e-04, 6.1513e-04, 4.1089e-02, 3.9072e-04,
        7.6312e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,536][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Megan] are: tensor([0.0376, 0.0480, 0.1696, 0.1692, 0.0501, 0.1256, 0.0523, 0.0527, 0.0484,
        0.0460, 0.1092, 0.0435, 0.0479], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,538][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Megan] are: tensor([0.0120, 0.0227, 0.3174, 0.2524, 0.0295, 0.1166, 0.0247, 0.0236, 0.0219,
        0.0215, 0.1165, 0.0192, 0.0221], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,539][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Megan] are: tensor([0.0140, 0.0195, 0.3683, 0.1808, 0.0361, 0.0829, 0.0203, 0.0219, 0.0203,
        0.0202, 0.1691, 0.0201, 0.0266], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,540][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Megan] are: tensor([0.0600, 0.0524, 0.1864, 0.0931, 0.0730, 0.0860, 0.0499, 0.0526, 0.0560,
        0.0552, 0.1137, 0.0579, 0.0637], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,542][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Megan] are: tensor([0.0114, 0.0239, 0.3579, 0.1882, 0.0341, 0.1103, 0.0266, 0.0307, 0.0244,
        0.0233, 0.1221, 0.0202, 0.0269], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,543][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Megan] are: tensor([0.0286, 0.0318, 0.2550, 0.1266, 0.0731, 0.0703, 0.0322, 0.0353, 0.0344,
        0.0351, 0.1921, 0.0356, 0.0500], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,545][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Megan] are: tensor([0.0708, 0.0626, 0.1121, 0.0768, 0.0802, 0.0928, 0.0628, 0.0678, 0.0658,
        0.0653, 0.1024, 0.0680, 0.0725], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,546][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Megan] are: tensor([0.0469, 0.0555, 0.1081, 0.1279, 0.0620, 0.1010, 0.0568, 0.0565, 0.0577,
        0.0590, 0.1489, 0.0574, 0.0624], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,548][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Megan] are: tensor([0.0251, 0.0311, 0.2662, 0.1572, 0.0537, 0.0970, 0.0337, 0.0331, 0.0328,
        0.0329, 0.1676, 0.0309, 0.0387], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,549][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Megan] are: tensor([0.0062, 0.0113, 0.2841, 0.3594, 0.0180, 0.0932, 0.0131, 0.0124, 0.0104,
        0.0105, 0.1589, 0.0097, 0.0128], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,549][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.1582, 0.0556, 0.0111, 0.0105, 0.1372, 0.0042, 0.1203, 0.0808, 0.0599,
        0.0588, 0.0652, 0.0694, 0.1142, 0.0544], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,549][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0269, 0.0064, 0.2252, 0.1179, 0.0190, 0.0861, 0.0086, 0.0090, 0.0076,
        0.0069, 0.2265, 0.0071, 0.0086, 0.2440], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,550][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.2656, 0.0809, 0.0083, 0.0052, 0.0824, 0.0106, 0.0654, 0.0677, 0.0935,
        0.0921, 0.0144, 0.1189, 0.0895, 0.0055], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,550][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0772, 0.0450, 0.0583, 0.0423, 0.0653, 0.0396, 0.0472, 0.0426, 0.0549,
        0.0551, 0.1491, 0.0634, 0.0648, 0.1952], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,550][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0227, 0.0076, 0.0171, 0.0048, 0.0447, 0.0045, 0.0080, 0.0073, 0.0101,
        0.0124, 0.1220, 0.0147, 0.0258, 0.6982], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,551][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.1597, 0.0446, 0.0159, 0.0042, 0.1442, 0.0094, 0.0324, 0.0389, 0.0561,
        0.0657, 0.1023, 0.0883, 0.1212, 0.1172], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,551][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.1134, 0.0322, 0.0565, 0.0303, 0.0769, 0.0654, 0.0359, 0.0532, 0.0414,
        0.0365, 0.1260, 0.0421, 0.0519, 0.2383], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,553][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0919, 0.0198, 0.0058, 0.0016, 0.1867, 0.0040, 0.0185, 0.0196, 0.0268,
        0.0381, 0.1410, 0.0482, 0.0935, 0.3046], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,554][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.2833, 0.0500, 0.0071, 0.0013, 0.1294, 0.0078, 0.0441, 0.0520, 0.0701,
        0.0775, 0.0311, 0.1017, 0.1126, 0.0320], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,555][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.2434, 0.0649, 0.0046, 0.0034, 0.0845, 0.0078, 0.0585, 0.0590, 0.0841,
        0.0948, 0.0423, 0.1214, 0.1145, 0.0168], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,557][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0925, 0.0372, 0.0468, 0.0120, 0.1027, 0.0210, 0.0394, 0.0402, 0.0508,
        0.0540, 0.1067, 0.0628, 0.0817, 0.2523], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,558][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0185, 0.0123, 0.0828, 0.0545, 0.0450, 0.0212, 0.0126, 0.0117, 0.0136,
        0.0154, 0.2038, 0.0174, 0.0268, 0.4643], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,559][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1273, 0.0522, 0.0186, 0.0130, 0.1462, 0.0062, 0.1146, 0.0738, 0.0559,
        0.0529, 0.0678, 0.0634, 0.1117, 0.0493, 0.0470], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,561][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0029, 0.0018, 0.3274, 0.0607, 0.0061, 0.0364, 0.0026, 0.0025, 0.0023,
        0.0019, 0.0713, 0.0018, 0.0025, 0.2710, 0.2087], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,562][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2308, 0.0810, 0.0096, 0.0042, 0.0804, 0.0108, 0.0674, 0.0695, 0.0995,
        0.0963, 0.0152, 0.1183, 0.0964, 0.0077, 0.0129], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,564][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0673, 0.0465, 0.0909, 0.0492, 0.0662, 0.0519, 0.0437, 0.0419, 0.0522,
        0.0503, 0.0931, 0.0588, 0.0552, 0.1613, 0.0714], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,565][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0112, 0.0051, 0.0164, 0.0029, 0.0211, 0.0033, 0.0050, 0.0052, 0.0065,
        0.0079, 0.0607, 0.0089, 0.0135, 0.5683, 0.2640], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,567][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1552, 0.0439, 0.0189, 0.0032, 0.1299, 0.0072, 0.0312, 0.0366, 0.0562,
        0.0645, 0.0629, 0.0865, 0.1140, 0.1337, 0.0560], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,568][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0859, 0.0362, 0.0466, 0.0139, 0.0760, 0.0437, 0.0399, 0.0523, 0.0472,
        0.0401, 0.0700, 0.0463, 0.0570, 0.2200, 0.1250], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,570][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0682, 0.0200, 0.0086, 0.0018, 0.1194, 0.0031, 0.0173, 0.0193, 0.0279,
        0.0369, 0.0997, 0.0449, 0.0754, 0.2737, 0.1838], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,571][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2133, 0.0531, 0.0191, 0.0020, 0.1313, 0.0088, 0.0447, 0.0527, 0.0729,
        0.0777, 0.0276, 0.1017, 0.1068, 0.0457, 0.0427], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,573][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1596, 0.0582, 0.0119, 0.0077, 0.0864, 0.0133, 0.0585, 0.0616, 0.0768,
        0.0829, 0.0643, 0.1010, 0.1054, 0.0399, 0.0724], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,574][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0583, 0.0295, 0.0515, 0.0138, 0.0743, 0.0210, 0.0306, 0.0308, 0.0391,
        0.0405, 0.0970, 0.0453, 0.0592, 0.2401, 0.1691], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,576][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0128, 0.0103, 0.0879, 0.0485, 0.0313, 0.0208, 0.0100, 0.0094, 0.0108,
        0.0119, 0.1076, 0.0132, 0.0193, 0.3412, 0.2650], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,617][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:26,619][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,619][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,621][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,622][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,623][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,624][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,625][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,626][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,627][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,628][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,630][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,631][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,632][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4894, 0.5106], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,633][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1110, 0.8890], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,635][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.4446, 0.5554], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,636][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3511, 0.6489], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,637][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3970, 0.6030], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,638][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.5098, 0.4902], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,640][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3197, 0.6803], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,641][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4397, 0.5603], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,642][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.5094, 0.4906], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,642][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.4461, 0.5539], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,642][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.4358, 0.5642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,643][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.3460, 0.6540], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,643][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Jennifer] are: tensor([0.7030, 0.2592, 0.0378], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,643][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Jennifer] are: tensor([0.0114, 0.0074, 0.9812], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,643][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Jennifer] are: tensor([0.5008, 0.3859, 0.1134], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,644][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Jennifer] are: tensor([0.5102, 0.2763, 0.2135], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,644][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Jennifer] are: tensor([0.1263, 0.0642, 0.8094], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,644][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Jennifer] are: tensor([0.5381, 0.1703, 0.2916], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,645][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Jennifer] are: tensor([0.5628, 0.1808, 0.2564], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,645][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Jennifer] are: tensor([0.0964, 0.0455, 0.8581], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,647][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Jennifer] are: tensor([0.8273, 0.1524, 0.0203], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,648][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Jennifer] are: tensor([0.7542, 0.2219, 0.0239], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,649][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Jennifer] are: tensor([0.4581, 0.1952, 0.3466], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,651][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Jennifer] are: tensor([0.1112, 0.0718, 0.8170], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,652][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.4876, 0.2487, 0.1463, 0.1174], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,653][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0032, 0.0024, 0.8126, 0.1818], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,655][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4410, 0.3201, 0.0994, 0.1395], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,656][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1361, 0.0921, 0.4853, 0.2866], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,658][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0135, 0.0098, 0.8425, 0.1342], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,659][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3067, 0.1016, 0.4841, 0.1076], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,660][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2510, 0.1350, 0.4467, 0.1673], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,662][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0228, 0.0131, 0.8305, 0.1335], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,663][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.6637, 0.1610, 0.1445, 0.0309], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,665][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.6107, 0.2344, 0.0896, 0.0652], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,666][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1497, 0.0828, 0.5726, 0.1949], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,668][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0200, 0.0154, 0.5305, 0.4341], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,669][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Megan] are: tensor([0.1156, 0.1020, 0.2227, 0.3272, 0.2325], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,670][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Megan] are: tensor([5.0333e-05, 3.2735e-04, 7.8610e-01, 2.1272e-01, 7.9326e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,671][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Megan] are: tensor([0.3195, 0.2887, 0.0776, 0.1929, 0.1212], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,672][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Megan] are: tensor([0.0268, 0.0445, 0.4566, 0.4173, 0.0547], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,673][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Megan] are: tensor([0.0250, 0.0324, 0.6081, 0.2624, 0.0721], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,673][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Megan] are: tensor([0.1702, 0.1228, 0.3594, 0.1549, 0.1927], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,674][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Megan] are: tensor([0.0233, 0.0404, 0.5363, 0.3420, 0.0581], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,674][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Megan] are: tensor([0.0476, 0.0521, 0.5383, 0.2109, 0.1511], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,674][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Megan] are: tensor([0.2501, 0.1749, 0.2131, 0.1281, 0.2337], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,675][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Megan] are: tensor([0.1626, 0.1621, 0.2358, 0.2593, 0.1801], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,675][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Megan] are: tensor([0.0568, 0.0627, 0.4905, 0.2715, 0.1184], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,675][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Megan] are: tensor([0.0112, 0.0176, 0.4042, 0.5384, 0.0286], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,675][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.1745, 0.1156, 0.1831, 0.1723, 0.3142, 0.0403], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,677][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0060, 0.0050, 0.6511, 0.2362, 0.0110, 0.0908], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,678][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.1937, 0.1566, 0.0718, 0.1492, 0.0855, 0.3431], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,679][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0436, 0.0461, 0.3764, 0.3009, 0.0754, 0.1575], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,681][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0084, 0.0083, 0.6596, 0.2348, 0.0422, 0.0467], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,682][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.1298, 0.0598, 0.3608, 0.1837, 0.1818, 0.0840], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,683][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0702, 0.0496, 0.3350, 0.2266, 0.0861, 0.2326], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,685][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0287, 0.0200, 0.4618, 0.2800, 0.1414, 0.0681], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,686][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.2678, 0.1096, 0.1750, 0.0650, 0.2541, 0.1284], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,688][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.2353, 0.1406, 0.1435, 0.1459, 0.1984, 0.1363], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,689][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0616, 0.0451, 0.4321, 0.2035, 0.1204, 0.1372], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,690][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0051, 0.0068, 0.4641, 0.4156, 0.0238, 0.0846], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,692][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0726, 0.0727, 0.1778, 0.3162, 0.1437, 0.0767, 0.1402],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,692][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([1.0743e-04, 6.7630e-04, 7.2616e-01, 2.3127e-01, 1.3712e-03, 3.9511e-02,
        9.0626e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,694][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0734, 0.0880, 0.1463, 0.2229, 0.0767, 0.2932, 0.0995],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,695][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0101, 0.0194, 0.4475, 0.3400, 0.0272, 0.1340, 0.0219],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,697][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0065, 0.0100, 0.6091, 0.2608, 0.0224, 0.0808, 0.0105],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,698][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0586, 0.0547, 0.4126, 0.2032, 0.0854, 0.1345, 0.0510],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,699][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0170, 0.0320, 0.4583, 0.2596, 0.0466, 0.1510, 0.0355],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,701][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0175, 0.0219, 0.5210, 0.2620, 0.0610, 0.0939, 0.0226],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,702][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1056, 0.0915, 0.2461, 0.1628, 0.1256, 0.1763, 0.0921],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,703][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0649, 0.0781, 0.2240, 0.2746, 0.0911, 0.1862, 0.0811],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,705][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0259, 0.0329, 0.4629, 0.2469, 0.0596, 0.1352, 0.0366],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,706][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0043, 0.0082, 0.3763, 0.4848, 0.0145, 0.1021, 0.0098],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,707][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0638, 0.0653, 0.1770, 0.2771, 0.1276, 0.0705, 0.1239, 0.0949],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,708][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([1.5542e-04, 9.5304e-04, 6.8947e-01, 2.5611e-01, 1.8028e-03, 4.8976e-02,
        1.2871e-03, 1.2522e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,709][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0537, 0.0686, 0.1245, 0.2268, 0.0486, 0.3273, 0.0778, 0.0727],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,709][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0113, 0.0210, 0.4212, 0.3378, 0.0299, 0.1324, 0.0234, 0.0230],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,710][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0081, 0.0121, 0.5189, 0.3105, 0.0254, 0.0981, 0.0130, 0.0139],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,710][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0542, 0.0505, 0.3483, 0.2333, 0.0787, 0.1366, 0.0483, 0.0501],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,710][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0147, 0.0283, 0.4292, 0.2639, 0.0421, 0.1518, 0.0321, 0.0378],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,711][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0167, 0.0209, 0.4051, 0.3439, 0.0570, 0.1102, 0.0225, 0.0237],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,711][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0920, 0.0822, 0.2159, 0.1643, 0.1087, 0.1661, 0.0834, 0.0874],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,711][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0543, 0.0673, 0.2076, 0.2763, 0.0804, 0.1741, 0.0709, 0.0691],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,712][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0248, 0.0315, 0.4235, 0.2563, 0.0574, 0.1372, 0.0348, 0.0344],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,712][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0041, 0.0080, 0.3734, 0.4870, 0.0141, 0.0951, 0.0095, 0.0087],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,713][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0628, 0.0647, 0.1475, 0.2625, 0.1159, 0.0709, 0.1214, 0.0914, 0.0628],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,714][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([9.9840e-05, 7.5011e-04, 7.1554e-01, 2.3748e-01, 1.4435e-03, 4.1923e-02,
        1.0227e-03, 9.6647e-04, 7.7151e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,715][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0515, 0.0683, 0.1558, 0.2089, 0.0619, 0.2382, 0.0743, 0.0743, 0.0668],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,716][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0109, 0.0217, 0.4196, 0.3181, 0.0295, 0.1318, 0.0240, 0.0233, 0.0210],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,718][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0090, 0.0135, 0.5431, 0.2657, 0.0274, 0.0965, 0.0147, 0.0161, 0.0141],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,719][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0516, 0.0495, 0.3495, 0.1887, 0.0753, 0.1315, 0.0492, 0.0521, 0.0526],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,720][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0135, 0.0282, 0.4605, 0.2342, 0.0413, 0.1256, 0.0314, 0.0363, 0.0289],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,721][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0195, 0.0243, 0.4552, 0.2529, 0.0619, 0.1039, 0.0266, 0.0293, 0.0264],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,723][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0807, 0.0769, 0.2097, 0.1418, 0.1012, 0.1465, 0.0788, 0.0838, 0.0806],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,724][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0551, 0.0692, 0.1926, 0.2295, 0.0794, 0.1590, 0.0720, 0.0712, 0.0721],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,726][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0258, 0.0336, 0.4123, 0.2312, 0.0583, 0.1295, 0.0371, 0.0368, 0.0353],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,727][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0050, 0.0097, 0.3787, 0.4549, 0.0163, 0.1038, 0.0117, 0.0109, 0.0090],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,729][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0585, 0.0612, 0.1376, 0.2468, 0.1092, 0.0689, 0.1149, 0.0863, 0.0595,
        0.0570], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,729][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([9.2914e-05, 7.3405e-04, 7.3008e-01, 2.2564e-01, 1.4385e-03, 3.8642e-02,
        9.8172e-04, 9.1734e-04, 7.4294e-04, 7.2648e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,731][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0504, 0.0656, 0.1519, 0.1898, 0.0652, 0.2070, 0.0712, 0.0724, 0.0648,
        0.0617], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,732][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0119, 0.0228, 0.4090, 0.3011, 0.0305, 0.1315, 0.0251, 0.0244, 0.0221,
        0.0216], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,734][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0104, 0.0155, 0.5509, 0.2377, 0.0300, 0.0906, 0.0163, 0.0172, 0.0159,
        0.0155], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,735][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0582, 0.0554, 0.3138, 0.1572, 0.0784, 0.1139, 0.0535, 0.0547, 0.0583,
        0.0566], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,736][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0141, 0.0304, 0.4483, 0.2156, 0.0434, 0.1158, 0.0330, 0.0382, 0.0309,
        0.0305], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,738][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0236, 0.0292, 0.4487, 0.2125, 0.0685, 0.0919, 0.0306, 0.0327, 0.0313,
        0.0310], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,739][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0787, 0.0749, 0.1838, 0.1234, 0.0962, 0.1288, 0.0764, 0.0819, 0.0788,
        0.0770], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,740][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0541, 0.0675, 0.1756, 0.2024, 0.0771, 0.1437, 0.0697, 0.0689, 0.0702,
        0.0708], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,741][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0271, 0.0350, 0.3913, 0.2154, 0.0593, 0.1231, 0.0381, 0.0377, 0.0365,
        0.0364], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,741][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0056, 0.0106, 0.3663, 0.4450, 0.0173, 0.1109, 0.0127, 0.0120, 0.0098,
        0.0098], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,741][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1138, 0.0658, 0.0483, 0.0438, 0.1751, 0.0169, 0.1416, 0.0946, 0.0683,
        0.0656, 0.1663], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,742][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([5.5276e-04, 9.0138e-04, 7.2280e-01, 1.3550e-01, 2.9591e-03, 3.8388e-02,
        1.3557e-03, 1.2928e-03, 1.0766e-03, 9.5928e-04, 9.4218e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,742][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1662, 0.1132, 0.0249, 0.0319, 0.0608, 0.0681, 0.1053, 0.0941, 0.1104,
        0.0994, 0.1257], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,742][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0380, 0.0371, 0.2498, 0.1460, 0.0636, 0.0835, 0.0382, 0.0363, 0.0410,
        0.0413, 0.2252], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,743][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0309, 0.0214, 0.3268, 0.0325, 0.0859, 0.0213, 0.0202, 0.0193, 0.0258,
        0.0298, 0.3861], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,743][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1974, 0.0732, 0.0777, 0.0125, 0.1797, 0.0175, 0.0531, 0.0553, 0.0897,
        0.1006, 0.1432], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,744][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0538, 0.0414, 0.2792, 0.0637, 0.0883, 0.0895, 0.0437, 0.0594, 0.0503,
        0.0456, 0.1852], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,745][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0473, 0.0274, 0.1457, 0.0184, 0.1743, 0.0141, 0.0247, 0.0271, 0.0361,
        0.0438, 0.4409], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,746][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2266, 0.0745, 0.0571, 0.0102, 0.1816, 0.0249, 0.0674, 0.0765, 0.0965,
        0.1023, 0.0824], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,748][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1730, 0.0835, 0.0375, 0.0245, 0.1290, 0.0321, 0.0826, 0.0876, 0.1046,
        0.1121, 0.1335], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,749][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0574, 0.0382, 0.2247, 0.0609, 0.1076, 0.0542, 0.0403, 0.0408, 0.0481,
        0.0500, 0.2776], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,750][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0128, 0.0118, 0.3054, 0.1771, 0.0383, 0.0578, 0.0133, 0.0125, 0.0127,
        0.0136, 0.3448], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,752][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0365, 0.0401, 0.1077, 0.2166, 0.0727, 0.0513, 0.0783, 0.0580, 0.0386,
        0.0368, 0.2265, 0.0371], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,752][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([3.8023e-05, 3.8802e-04, 7.2232e-01, 2.0883e-01, 7.6813e-04, 3.1427e-02,
        5.3423e-04, 4.9556e-04, 3.9205e-04, 3.8040e-04, 3.4198e-02, 2.2816e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,754][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0286, 0.0426, 0.1435, 0.1859, 0.0437, 0.1878, 0.0476, 0.0489, 0.0420,
        0.0397, 0.1532, 0.0367], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,755][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0073, 0.0156, 0.3944, 0.2721, 0.0215, 0.1104, 0.0176, 0.0171, 0.0151,
        0.0147, 0.1014, 0.0127], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,757][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0068, 0.0109, 0.4747, 0.2144, 0.0210, 0.0804, 0.0117, 0.0127, 0.0113,
        0.0109, 0.1346, 0.0106], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,758][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0406, 0.0415, 0.2844, 0.1394, 0.0579, 0.1036, 0.0411, 0.0428, 0.0440,
        0.0421, 0.1196, 0.0430], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,760][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0074, 0.0189, 0.4253, 0.2077, 0.0274, 0.0991, 0.0210, 0.0241, 0.0190,
        0.0187, 0.1159, 0.0155], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,761][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0137, 0.0187, 0.3787, 0.1846, 0.0440, 0.0788, 0.0203, 0.0224, 0.0203,
        0.0196, 0.1796, 0.0194], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,762][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0517, 0.0546, 0.1647, 0.1244, 0.0701, 0.1211, 0.0577, 0.0618, 0.0573,
        0.0554, 0.1251, 0.0559], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,764][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0338, 0.0464, 0.1628, 0.1824, 0.0538, 0.1217, 0.0486, 0.0481, 0.0480,
        0.0481, 0.1609, 0.0455], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,765][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0164, 0.0230, 0.3494, 0.1896, 0.0399, 0.1012, 0.0256, 0.0253, 0.0240,
        0.0238, 0.1599, 0.0219], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,767][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0032, 0.0067, 0.3224, 0.3956, 0.0110, 0.0886, 0.0082, 0.0078, 0.0062,
        0.0061, 0.1387, 0.0055], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,768][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Megan] are: tensor([0.0447, 0.0441, 0.0946, 0.1657, 0.0838, 0.0430, 0.0846, 0.0638, 0.0431,
        0.0409, 0.1865, 0.0420, 0.0632], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,769][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Megan] are: tensor([8.4647e-05, 6.3144e-04, 6.9609e-01, 2.1854e-01, 1.2620e-03, 3.8234e-02,
        8.5734e-04, 7.8787e-04, 6.4589e-04, 6.1513e-04, 4.1089e-02, 3.9072e-04,
        7.6312e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,771][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Megan] are: tensor([0.0462, 0.0576, 0.0835, 0.1295, 0.0425, 0.1701, 0.0655, 0.0628, 0.0572,
        0.0529, 0.1319, 0.0500, 0.0503], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,772][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Megan] are: tensor([0.0120, 0.0227, 0.3174, 0.2524, 0.0295, 0.1166, 0.0247, 0.0236, 0.0219,
        0.0215, 0.1165, 0.0192, 0.0221], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,772][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Megan] are: tensor([0.0140, 0.0195, 0.3683, 0.1808, 0.0361, 0.0829, 0.0203, 0.0219, 0.0203,
        0.0202, 0.1691, 0.0201, 0.0266], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,773][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Megan] are: tensor([0.0600, 0.0524, 0.1864, 0.0931, 0.0730, 0.0860, 0.0499, 0.0526, 0.0560,
        0.0552, 0.1137, 0.0579, 0.0637], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,773][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Megan] are: tensor([0.0114, 0.0239, 0.3579, 0.1882, 0.0341, 0.1103, 0.0266, 0.0307, 0.0244,
        0.0233, 0.1221, 0.0202, 0.0269], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,773][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Megan] are: tensor([0.0286, 0.0318, 0.2550, 0.1266, 0.0731, 0.0703, 0.0322, 0.0353, 0.0344,
        0.0351, 0.1921, 0.0356, 0.0500], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,774][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Megan] are: tensor([0.0708, 0.0626, 0.1121, 0.0768, 0.0802, 0.0928, 0.0628, 0.0678, 0.0658,
        0.0653, 0.1024, 0.0680, 0.0725], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,774][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Megan] are: tensor([0.0469, 0.0555, 0.1081, 0.1279, 0.0620, 0.1010, 0.0568, 0.0565, 0.0577,
        0.0590, 0.1489, 0.0574, 0.0624], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,775][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Megan] are: tensor([0.0251, 0.0311, 0.2662, 0.1572, 0.0537, 0.0970, 0.0337, 0.0331, 0.0328,
        0.0329, 0.1676, 0.0309, 0.0387], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,775][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Megan] are: tensor([0.0062, 0.0113, 0.2841, 0.3594, 0.0180, 0.0932, 0.0131, 0.0124, 0.0104,
        0.0105, 0.1589, 0.0097, 0.0128], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,776][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.1582, 0.0556, 0.0111, 0.0105, 0.1372, 0.0042, 0.1203, 0.0808, 0.0599,
        0.0588, 0.0652, 0.0694, 0.1142, 0.0544], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,777][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0269, 0.0064, 0.2252, 0.1179, 0.0190, 0.0861, 0.0086, 0.0090, 0.0076,
        0.0069, 0.2265, 0.0071, 0.0086, 0.2440], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,778][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0935, 0.0786, 0.0361, 0.0528, 0.0572, 0.0913, 0.0780, 0.0727, 0.0734,
        0.0673, 0.1258, 0.0673, 0.0651, 0.0409], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,780][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0772, 0.0450, 0.0583, 0.0423, 0.0653, 0.0396, 0.0472, 0.0426, 0.0549,
        0.0551, 0.1491, 0.0634, 0.0648, 0.1952], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,781][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0227, 0.0076, 0.0171, 0.0048, 0.0447, 0.0045, 0.0080, 0.0073, 0.0101,
        0.0124, 0.1220, 0.0147, 0.0258, 0.6982], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,783][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.1597, 0.0446, 0.0159, 0.0042, 0.1442, 0.0094, 0.0324, 0.0389, 0.0561,
        0.0657, 0.1023, 0.0883, 0.1212, 0.1172], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,784][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.1134, 0.0322, 0.0565, 0.0303, 0.0769, 0.0654, 0.0359, 0.0532, 0.0414,
        0.0365, 0.1260, 0.0421, 0.0519, 0.2383], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,786][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0919, 0.0198, 0.0058, 0.0016, 0.1867, 0.0040, 0.0185, 0.0196, 0.0268,
        0.0381, 0.1410, 0.0482, 0.0935, 0.3046], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,787][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.2833, 0.0500, 0.0071, 0.0013, 0.1294, 0.0078, 0.0441, 0.0520, 0.0701,
        0.0775, 0.0311, 0.1017, 0.1126, 0.0320], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,788][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.2434, 0.0649, 0.0046, 0.0034, 0.0845, 0.0078, 0.0585, 0.0590, 0.0841,
        0.0948, 0.0423, 0.1214, 0.1145, 0.0168], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,790][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0925, 0.0372, 0.0468, 0.0120, 0.1027, 0.0210, 0.0394, 0.0402, 0.0508,
        0.0540, 0.1067, 0.0628, 0.0817, 0.2523], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,791][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0185, 0.0123, 0.0828, 0.0545, 0.0450, 0.0212, 0.0126, 0.0117, 0.0136,
        0.0154, 0.2038, 0.0174, 0.0268, 0.4643], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:26,793][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1273, 0.0522, 0.0186, 0.0130, 0.1462, 0.0062, 0.1146, 0.0738, 0.0559,
        0.0529, 0.0678, 0.0634, 0.1117, 0.0493, 0.0470], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,794][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0029, 0.0018, 0.3274, 0.0607, 0.0061, 0.0364, 0.0026, 0.0025, 0.0023,
        0.0019, 0.0713, 0.0018, 0.0025, 0.2710, 0.2087], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,795][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1088, 0.0825, 0.0248, 0.0289, 0.0483, 0.0588, 0.0775, 0.0707, 0.0795,
        0.0727, 0.0912, 0.0734, 0.0705, 0.0306, 0.0816], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,797][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0673, 0.0465, 0.0909, 0.0492, 0.0662, 0.0519, 0.0437, 0.0419, 0.0522,
        0.0503, 0.0931, 0.0588, 0.0552, 0.1613, 0.0714], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,798][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0112, 0.0051, 0.0164, 0.0029, 0.0211, 0.0033, 0.0050, 0.0052, 0.0065,
        0.0079, 0.0607, 0.0089, 0.0135, 0.5683, 0.2640], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,800][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1552, 0.0439, 0.0189, 0.0032, 0.1299, 0.0072, 0.0312, 0.0366, 0.0562,
        0.0645, 0.0629, 0.0865, 0.1140, 0.1337, 0.0560], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,801][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0859, 0.0362, 0.0466, 0.0139, 0.0760, 0.0437, 0.0399, 0.0523, 0.0472,
        0.0401, 0.0700, 0.0463, 0.0570, 0.2200, 0.1250], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,803][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0682, 0.0200, 0.0086, 0.0018, 0.1194, 0.0031, 0.0173, 0.0193, 0.0279,
        0.0369, 0.0997, 0.0449, 0.0754, 0.2737, 0.1838], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,804][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2133, 0.0531, 0.0191, 0.0020, 0.1313, 0.0088, 0.0447, 0.0527, 0.0729,
        0.0777, 0.0276, 0.1017, 0.1068, 0.0457, 0.0427], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,804][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1596, 0.0582, 0.0119, 0.0077, 0.0864, 0.0133, 0.0585, 0.0616, 0.0768,
        0.0829, 0.0643, 0.1010, 0.1054, 0.0399, 0.0724], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,805][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0583, 0.0295, 0.0515, 0.0138, 0.0743, 0.0210, 0.0306, 0.0308, 0.0391,
        0.0405, 0.0970, 0.0453, 0.0592, 0.2401, 0.1691], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,805][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0128, 0.0103, 0.0879, 0.0485, 0.0313, 0.0208, 0.0100, 0.0094, 0.0108,
        0.0119, 0.1076, 0.0132, 0.0193, 0.3412, 0.2650], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:26,806][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:26,807][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 3438],
        [ 2181],
        [ 2664],
        [  350],
        [ 2118],
        [  419],
        [ 2495],
        [ 1994],
        [ 4821],
        [ 4815],
        [ 1401],
        [ 3797],
        [10397],
        [  654],
        [  521]], device='cuda:0')
[2024-07-24 10:29:26,808][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[5769],
        [3261],
        [1887],
        [ 361],
        [2298],
        [ 432],
        [1820],
        [2245],
        [3874],
        [3433],
        [1604],
        [3398],
        [8937],
        [ 896],
        [ 967]], device='cuda:0')
[2024-07-24 10:29:26,810][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 6950],
        [ 8790],
        [10477],
        [23829],
        [32805],
        [30526],
        [31298],
        [31623],
        [30308],
        [29520],
        [20597],
        [26906],
        [25695],
        [19022],
        [19505]], device='cuda:0')
[2024-07-24 10:29:26,811][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 3439],
        [ 4497],
        [49315],
        [48844],
        [48734],
        [48110],
        [48486],
        [48291],
        [48438],
        [48510],
        [48614],
        [48512],
        [48390],
        [35796],
        [37254]], device='cuda:0')
[2024-07-24 10:29:26,812][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[  498],
        [  339],
        [ 2501],
        [ 6568],
        [29924],
        [20360],
        [28382],
        [27495],
        [28263],
        [27280],
        [ 6107],
        [28570],
        [24893],
        [ 2222],
        [ 2771]], device='cuda:0')
[2024-07-24 10:29:26,814][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[39360],
        [38099],
        [44744],
        [43398],
        [43423],
        [41639],
        [41832],
        [41811],
        [41770],
        [41772],
        [41876],
        [41859],
        [41748],
        [39635],
        [39763]], device='cuda:0')
[2024-07-24 10:29:26,815][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[27273],
        [21753],
        [21189],
        [19138],
        [16370],
        [17414],
        [17188],
        [16278],
        [16964],
        [17324],
        [13709],
        [15740],
        [15150],
        [23344],
        [23112]], device='cuda:0')
[2024-07-24 10:29:26,816][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 8453],
        [ 7955],
        [12006],
        [15645],
        [16464],
        [16886],
        [17043],
        [17154],
        [16591],
        [15948],
        [14294],
        [16758],
        [15854],
        [17207],
        [18403]], device='cuda:0')
[2024-07-24 10:29:26,818][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[17108],
        [21368],
        [46773],
        [48092],
        [48047],
        [48200],
        [48269],
        [48199],
        [48303],
        [48321],
        [48236],
        [48205],
        [48142],
        [48169],
        [47986]], device='cuda:0')
[2024-07-24 10:29:26,819][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[18861],
        [21726],
        [22867],
        [23870],
        [24952],
        [26288],
        [26303],
        [27309],
        [26808],
        [26620],
        [32104],
        [28752],
        [29674],
        [33806],
        [35807]], device='cuda:0')
[2024-07-24 10:29:26,820][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[23777],
        [29982],
        [29657],
        [45132],
        [48370],
        [47771],
        [47290],
        [47072],
        [47192],
        [47191],
        [46543],
        [46818],
        [46817],
        [42476],
        [44562]], device='cuda:0')
[2024-07-24 10:29:26,822][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[14952],
        [19571],
        [15725],
        [14627],
        [14064],
        [13670],
        [15018],
        [15343],
        [15069],
        [14818],
        [12099],
        [13429],
        [12945],
        [12427],
        [ 9111]], device='cuda:0')
[2024-07-24 10:29:26,823][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[41109],
        [38215],
        [ 2920],
        [ 2634],
        [ 2994],
        [ 3376],
        [ 3867],
        [ 4229],
        [ 4043],
        [ 4026],
        [ 4713],
        [ 4820],
        [ 5306],
        [ 5046],
        [ 4525]], device='cuda:0')
[2024-07-24 10:29:26,825][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[  738],
        [  278],
        [50229],
        [49226],
        [45848],
        [48347],
        [44789],
        [44689],
        [45488],
        [45119],
        [45156],
        [42854],
        [41162],
        [15852],
        [19841]], device='cuda:0')
[2024-07-24 10:29:26,826][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[3144],
        [3242],
        [6542],
        [7468],
        [5747],
        [5621],
        [3961],
        [2057],
        [2494],
        [3562],
        [8470],
        [2638],
        [4289],
        [9681],
        [6875]], device='cuda:0')
[2024-07-24 10:29:26,827][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[29258],
        [28268],
        [21180],
        [ 7303],
        [ 6436],
        [ 5885],
        [ 9225],
        [ 8499],
        [ 9147],
        [ 9395],
        [16741],
        [14905],
        [14240],
        [21063],
        [20548]], device='cuda:0')
[2024-07-24 10:29:26,829][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 8031],
        [ 9074],
        [10643],
        [12703],
        [13112],
        [14822],
        [13947],
        [14524],
        [14095],
        [13847],
        [14130],
        [14116],
        [14526],
        [26727],
        [24841]], device='cuda:0')
[2024-07-24 10:29:26,830][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[22484],
        [12985],
        [ 9647],
        [ 5942],
        [ 4372],
        [ 2724],
        [ 2643],
        [ 2572],
        [ 2750],
        [ 2854],
        [ 2967],
        [ 2286],
        [ 2398],
        [ 2709],
        [ 2593]], device='cuda:0')
[2024-07-24 10:29:26,831][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[37349],
        [41031],
        [19238],
        [20562],
        [22339],
        [22113],
        [22036],
        [22173],
        [21931],
        [21801],
        [23351],
        [22374],
        [22943],
        [25408],
        [25282]], device='cuda:0')
[2024-07-24 10:29:26,833][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[29910],
        [29109],
        [12344],
        [13856],
        [14950],
        [14671],
        [14825],
        [15390],
        [14901],
        [14544],
        [18510],
        [15867],
        [16349],
        [ 8333],
        [11443]], device='cuda:0')
[2024-07-24 10:29:26,834][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[26102],
        [27193],
        [26382],
        [28196],
        [28667],
        [29990],
        [30930],
        [31061],
        [30705],
        [30145],
        [27894],
        [30874],
        [29713],
        [30115],
        [30798]], device='cuda:0')
[2024-07-24 10:29:26,836][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[26807],
        [16143],
        [ 3987],
        [ 6062],
        [ 7930],
        [ 7910],
        [ 7987],
        [ 8029],
        [ 7704],
        [ 7439],
        [ 6027],
        [ 7725],
        [ 7489],
        [ 7884],
        [ 7282]], device='cuda:0')
[2024-07-24 10:29:26,837][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 5709],
        [ 8155],
        [43698],
        [43395],
        [41062],
        [40698],
        [41820],
        [40753],
        [41230],
        [41015],
        [30935],
        [40143],
        [36490],
        [31204],
        [32515]], device='cuda:0')
[2024-07-24 10:29:26,838][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 6329],
        [ 6111],
        [ 5558],
        [ 9647],
        [ 9261],
        [ 6778],
        [10486],
        [10903],
        [10991],
        [10960],
        [ 4507],
        [ 9339],
        [ 8128],
        [ 5681],
        [10221]], device='cuda:0')
[2024-07-24 10:29:26,839][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[32602],
        [26620],
        [29996],
        [26499],
        [25478],
        [23569],
        [22366],
        [22080],
        [21890],
        [21614],
        [18493],
        [19244],
        [18787],
        [24646],
        [18582]], device='cuda:0')
[2024-07-24 10:29:26,840][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[18474],
        [ 5529],
        [ 5224],
        [ 6473],
        [ 5431],
        [ 4427],
        [ 4479],
        [ 4153],
        [ 4175],
        [ 4091],
        [ 2863],
        [ 3629],
        [ 3112],
        [ 1186],
        [ 1242]], device='cuda:0')
[2024-07-24 10:29:26,841][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 6482],
        [ 3696],
        [23773],
        [10267],
        [ 7700],
        [ 9565],
        [ 8110],
        [ 8036],
        [ 8301],
        [ 8205],
        [ 5342],
        [ 6498],
        [ 6007],
        [10630],
        [ 8064]], device='cuda:0')
[2024-07-24 10:29:26,842][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[27022],
        [38496],
        [35243],
        [35599],
        [36057],
        [37631],
        [36112],
        [36366],
        [36547],
        [37135],
        [43075],
        [38111],
        [40281],
        [40684],
        [40367]], device='cuda:0')
[2024-07-24 10:29:26,843][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[45291],
        [45363],
        [47423],
        [45852],
        [46317],
        [47885],
        [47695],
        [48862],
        [48605],
        [47712],
        [46265],
        [48146],
        [47516],
        [46511],
        [47589]], device='cuda:0')
[2024-07-24 10:29:26,844][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[6444],
        [6444],
        [6444],
        [6444],
        [6444],
        [6444],
        [6444],
        [6444],
        [6444],
        [6444],
        [6444],
        [6444],
        [6444],
        [6444],
        [6444]], device='cuda:0')
[2024-07-24 10:29:26,877][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:26,877][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,878][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,878][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,878][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,879][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,879][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,879][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,880][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,880][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,880][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,881][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,881][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:26,881][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3833, 0.6167], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,882][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1940, 0.8060], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,882][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.3924, 0.6076], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,882][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5575, 0.4425], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,883][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2409, 0.7591], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,883][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4639, 0.5361], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,883][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0460, 0.9540], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,884][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2961, 0.7039], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,884][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0594, 0.9406], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,884][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0390, 0.9610], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,885][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4232, 0.5768], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,886][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2861, 0.7139], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:26,886][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Jennifer] are: tensor([0.4141, 0.2267, 0.3592], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,887][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Jennifer] are: tensor([0.0426, 0.0420, 0.9154], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,887][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Jennifer] are: tensor([0.3592, 0.1942, 0.4466], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,887][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Jennifer] are: tensor([0.7525, 0.1849, 0.0626], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,888][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Jennifer] are: tensor([0.0421, 0.0871, 0.8708], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,888][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Jennifer] are: tensor([0.5325, 0.2913, 0.1762], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,888][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Jennifer] are: tensor([0.0033, 0.0195, 0.9772], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,889][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Jennifer] are: tensor([0.0096, 0.0188, 0.9716], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,889][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Jennifer] are: tensor([0.0084, 0.2509, 0.7407], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,889][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Jennifer] are: tensor([1.1052e-05, 8.5918e-05, 9.9990e-01], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,890][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Jennifer] are: tensor([0.0415, 0.0182, 0.9403], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,890][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Jennifer] are: tensor([0.2421, 0.5473, 0.2106], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:26,890][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1763, 0.1294, 0.5022, 0.1921], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,891][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0200, 0.0220, 0.6475, 0.3105], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,891][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1248, 0.0802, 0.5737, 0.2213], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,891][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.7110, 0.1427, 0.1053, 0.0410], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,892][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0130, 0.0277, 0.5596, 0.3998], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,892][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3361, 0.2000, 0.2898, 0.1741], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,892][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0012, 0.0101, 0.7371, 0.2516], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,893][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0031, 0.0081, 0.7105, 0.2783], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,893][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0072, 0.1519, 0.4818, 0.3590], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,893][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([1.2053e-06, 1.3319e-05, 5.1175e-01, 4.8824e-01], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,894][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0140, 0.0065, 0.8421, 0.1374], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,894][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1072, 0.3013, 0.2234, 0.3681], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:26,894][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Megan] are: tensor([0.0621, 0.0900, 0.4413, 0.3004, 0.1061], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,895][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Megan] are: tensor([5.8463e-04, 2.2923e-03, 6.5550e-01, 3.3768e-01, 3.9343e-03],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,895][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Megan] are: tensor([0.0401, 0.0622, 0.3465, 0.4843, 0.0670], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,896][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Megan] are: tensor([0.3501, 0.2190, 0.0978, 0.0843, 0.2488], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,897][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Megan] are: tensor([0.0018, 0.0069, 0.5739, 0.4077, 0.0098], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,898][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Megan] are: tensor([0.1207, 0.1304, 0.3258, 0.2615, 0.1616], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,899][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Megan] are: tensor([6.5648e-04, 8.0848e-03, 6.8449e-01, 2.6019e-01, 4.6581e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,900][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Megan] are: tensor([0.0069, 0.0169, 0.5982, 0.2228, 0.1553], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,902][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Megan] are: tensor([0.0044, 0.1043, 0.3193, 0.1982, 0.3738], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,902][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Megan] are: tensor([8.5097e-07, 2.6121e-05, 4.3368e-01, 5.6624e-01, 5.9353e-05],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,904][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Megan] are: tensor([0.0306, 0.0354, 0.5738, 0.2845, 0.0758], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,905][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Megan] are: tensor([0.0762, 0.2046, 0.1990, 0.4444, 0.0758], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:26,907][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0432, 0.0469, 0.4344, 0.2485, 0.0994, 0.1275], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,908][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0032, 0.0061, 0.6808, 0.2444, 0.0131, 0.0524], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,909][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0407, 0.0382, 0.3749, 0.3120, 0.0791, 0.1550], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,911][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.3129, 0.1017, 0.1012, 0.1331, 0.2955, 0.0556], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,912][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0024, 0.0076, 0.5289, 0.3098, 0.0109, 0.1404], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,913][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.1231, 0.0948, 0.1494, 0.1211, 0.1479, 0.3638], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,915][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0008, 0.0078, 0.5210, 0.1891, 0.0425, 0.2388], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,916][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0012, 0.0039, 0.4742, 0.1708, 0.1743, 0.1757], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,918][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0041, 0.0905, 0.2591, 0.1760, 0.2700, 0.2002], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,918][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ had] are: tensor([1.7792e-06, 2.3946e-05, 3.0488e-01, 6.6695e-01, 8.0531e-05, 2.8063e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,920][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0058, 0.0048, 0.6184, 0.3209, 0.0280, 0.0221], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,921][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0780, 0.2194, 0.1781, 0.3241, 0.0691, 0.1314], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:26,922][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0312, 0.0509, 0.3890, 0.2627, 0.0623, 0.1515, 0.0524],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,922][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([5.0307e-04, 2.1296e-03, 6.7365e-01, 2.8449e-01, 3.5613e-03, 3.2931e-02,
        2.7365e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,923][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0243, 0.0393, 0.2697, 0.3875, 0.0480, 0.1867, 0.0445],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,923][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1191, 0.0916, 0.2246, 0.2279, 0.1189, 0.1362, 0.0817],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,923][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0017, 0.0060, 0.5398, 0.3454, 0.0092, 0.0909, 0.0069],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,923][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0595, 0.0681, 0.2347, 0.2151, 0.0813, 0.2633, 0.0780],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,924][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([2.7804e-04, 4.3628e-03, 4.5636e-01, 2.1214e-01, 3.3830e-02, 2.8311e-01,
        9.9230e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,924][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0019, 0.0072, 0.4229, 0.2197, 0.0924, 0.2468, 0.0090],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,924][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0020, 0.0493, 0.2563, 0.1789, 0.2216, 0.1986, 0.0933],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,925][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.7111e-06, 4.5678e-05, 4.5572e-01, 5.2715e-01, 1.0343e-04, 1.6911e-02,
        6.9772e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,925][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0068, 0.0098, 0.5496, 0.3429, 0.0216, 0.0594, 0.0099],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,926][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0426, 0.1133, 0.1833, 0.3811, 0.0579, 0.1377, 0.0841],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:26,928][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0228, 0.0392, 0.3946, 0.2697, 0.0483, 0.1425, 0.0410, 0.0420],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,928][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ long] are: tensor([5.2366e-04, 2.1542e-03, 6.3754e-01, 3.1525e-01, 3.6049e-03, 3.5443e-02,
        2.7909e-03, 2.6886e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,930][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0188, 0.0315, 0.2835, 0.3883, 0.0387, 0.1700, 0.0362, 0.0329],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,931][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0961, 0.0772, 0.1787, 0.2577, 0.0985, 0.1387, 0.0717, 0.0814],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,933][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0014, 0.0051, 0.5105, 0.3762, 0.0075, 0.0874, 0.0059, 0.0060],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,934][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0509, 0.0604, 0.2138, 0.2148, 0.0709, 0.2494, 0.0698, 0.0700],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,935][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ long] are: tensor([3.0916e-04, 4.5860e-03, 4.3585e-01, 2.0882e-01, 3.4313e-02, 2.9171e-01,
        1.0273e-02, 1.4130e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,936][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0015, 0.0055, 0.4336, 0.2451, 0.0584, 0.2393, 0.0057, 0.0109],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,938][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0038, 0.0551, 0.2027, 0.1552, 0.1877, 0.1735, 0.0995, 0.1224],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,938][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ long] are: tensor([1.5779e-06, 4.4231e-05, 4.4553e-01, 5.3556e-01, 1.0025e-04, 1.8627e-02,
        6.9397e-05, 6.5300e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,940][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0069, 0.0098, 0.4469, 0.4285, 0.0219, 0.0655, 0.0102, 0.0102],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,941][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0359, 0.0974, 0.1682, 0.3831, 0.0496, 0.1338, 0.0736, 0.0583],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:26,943][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0322, 0.0532, 0.3405, 0.2138, 0.0611, 0.1368, 0.0532, 0.0557, 0.0535],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,943][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([5.5865e-04, 2.4069e-03, 6.6226e-01, 2.8758e-01, 3.8247e-03, 3.5052e-02,
        3.0309e-03, 2.9644e-03, 2.3191e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,945][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0263, 0.0414, 0.2416, 0.3417, 0.0487, 0.1694, 0.0470, 0.0433, 0.0407],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,946][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0986, 0.0798, 0.1790, 0.1664, 0.0997, 0.1234, 0.0765, 0.0900, 0.0867],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,948][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0019, 0.0063, 0.5261, 0.3477, 0.0095, 0.0879, 0.0072, 0.0074, 0.0060],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,949][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0556, 0.0635, 0.2019, 0.1754, 0.0727, 0.2190, 0.0714, 0.0712, 0.0692],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,950][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([1.9772e-04, 3.7116e-03, 4.1364e-01, 2.2245e-01, 3.1987e-02, 3.0202e-01,
        9.3416e-03, 1.2370e-02, 4.2826e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,951][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0066, 0.0185, 0.3548, 0.2268, 0.0849, 0.2381, 0.0200, 0.0340, 0.0162],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,953][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0060, 0.0624, 0.1827, 0.1430, 0.1704, 0.1560, 0.0938, 0.1158, 0.0698],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,953][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([2.5843e-06, 6.8786e-05, 4.5760e-01, 5.2208e-01, 1.3529e-04, 1.9841e-02,
        1.0337e-04, 9.7853e-05, 7.2030e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,954][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0091, 0.0130, 0.5111, 0.3233, 0.0273, 0.0740, 0.0138, 0.0144, 0.0139],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,954][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0416, 0.0950, 0.1541, 0.3104, 0.0525, 0.1145, 0.0735, 0.0602, 0.0983],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:26,954][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0315, 0.0516, 0.3153, 0.2056, 0.0593, 0.1274, 0.0514, 0.0535, 0.0516,
        0.0527], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,955][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([5.4087e-04, 2.3644e-03, 6.7675e-01, 2.7329e-01, 3.7704e-03, 3.2850e-02,
        2.9945e-03, 2.9046e-03, 2.2723e-03, 2.2619e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,955][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0265, 0.0412, 0.2291, 0.3166, 0.0491, 0.1656, 0.0468, 0.0435, 0.0408,
        0.0408], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,955][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1055, 0.0848, 0.1482, 0.1255, 0.0970, 0.0957, 0.0781, 0.0872, 0.0904,
        0.0876], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,956][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0021, 0.0070, 0.5342, 0.3265, 0.0106, 0.0906, 0.0079, 0.0082, 0.0066,
        0.0062], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,956][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0531, 0.0603, 0.1885, 0.1602, 0.0691, 0.2049, 0.0675, 0.0676, 0.0653,
        0.0636], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,957][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([1.5338e-04, 3.1263e-03, 4.1487e-01, 2.2304e-01, 3.1139e-02, 3.0143e-01,
        8.4220e-03, 1.1218e-02, 3.7210e-03, 2.8762e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,957][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0085, 0.0219, 0.3431, 0.2023, 0.1027, 0.2125, 0.0250, 0.0456, 0.0207,
        0.0177], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,959][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0046, 0.0518, 0.1918, 0.1496, 0.1575, 0.1619, 0.0828, 0.1054, 0.0619,
        0.0327], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,959][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([2.9174e-06, 7.1976e-05, 4.5458e-01, 5.2452e-01, 1.4898e-04, 2.0320e-02,
        1.0746e-04, 1.0257e-04, 7.6457e-05, 7.2110e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,961][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0120, 0.0167, 0.5161, 0.2833, 0.0325, 0.0699, 0.0170, 0.0171, 0.0176,
        0.0178], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,962][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0350, 0.0813, 0.1453, 0.2826, 0.0494, 0.1099, 0.0655, 0.0546, 0.0841,
        0.0924], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:26,963][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0446, 0.0437, 0.2852, 0.0549, 0.0982, 0.0484, 0.0494, 0.0568, 0.0629,
        0.0622, 0.1935], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,965][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0042, 0.0084, 0.5996, 0.1476, 0.0192, 0.0444, 0.0106, 0.0101, 0.0092,
        0.0087, 0.1380], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,966][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0384, 0.0326, 0.3492, 0.0849, 0.0865, 0.0650, 0.0359, 0.0369, 0.0405,
        0.0391, 0.1909], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,967][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3137, 0.0769, 0.0090, 0.0016, 0.1838, 0.0046, 0.0557, 0.0643, 0.1051,
        0.1206, 0.0646], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,969][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0025, 0.0073, 0.4913, 0.2363, 0.0134, 0.1233, 0.0089, 0.0093, 0.0076,
        0.0065, 0.0936], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,970][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0866, 0.0593, 0.0873, 0.0437, 0.1106, 0.1320, 0.0733, 0.0791, 0.0854,
        0.0792, 0.1635], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,971][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([3.6073e-04, 3.8165e-03, 4.8283e-01, 1.4759e-01, 3.5705e-02, 1.8949e-01,
        8.4138e-03, 1.0954e-02, 4.4930e-03, 3.3907e-03, 1.1296e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,973][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0028, 0.0061, 0.3101, 0.1246, 0.1562, 0.1221, 0.0074, 0.0100, 0.0048,
        0.0054, 0.2506], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,974][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0022, 0.0508, 0.1512, 0.1154, 0.1618, 0.1353, 0.0856, 0.1025, 0.0520,
        0.0259, 0.1173], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,975][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([4.5931e-07, 9.6389e-06, 5.0878e-01, 4.2382e-01, 5.2826e-05, 1.2330e-02,
        1.7186e-05, 1.8221e-05, 1.2371e-05, 1.0030e-05, 5.4949e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,976][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0322, 0.0188, 0.3700, 0.0321, 0.1063, 0.0131, 0.0164, 0.0165, 0.0240,
        0.0289, 0.3417], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,978][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0423, 0.1064, 0.0833, 0.1721, 0.0349, 0.0646, 0.0632, 0.0470, 0.1150,
        0.1380, 0.1331], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:26,979][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0211, 0.0376, 0.2897, 0.1951, 0.0429, 0.1138, 0.0377, 0.0392, 0.0369,
        0.0378, 0.1140, 0.0340], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,980][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([2.6405e-04, 1.3754e-03, 6.5556e-01, 2.6090e-01, 2.2111e-03, 2.5504e-02,
        1.7635e-03, 1.7200e-03, 1.3102e-03, 1.2974e-03, 4.7162e-02, 9.2655e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,982][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0171, 0.0287, 0.1897, 0.2902, 0.0333, 0.1385, 0.0332, 0.0304, 0.0281,
        0.0282, 0.1570, 0.0256], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,983][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0801, 0.0672, 0.1293, 0.1038, 0.0773, 0.0848, 0.0632, 0.0727, 0.0727,
        0.0695, 0.1054, 0.0740], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,984][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0012, 0.0044, 0.5086, 0.3180, 0.0067, 0.0731, 0.0050, 0.0052, 0.0041,
        0.0038, 0.0669, 0.0030], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,985][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0376, 0.0452, 0.1845, 0.1458, 0.0517, 0.1785, 0.0512, 0.0511, 0.0487,
        0.0472, 0.1137, 0.0448], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,985][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([5.7445e-05, 1.7100e-03, 3.5507e-01, 1.9792e-01, 2.1159e-02, 2.8307e-01,
        5.2374e-03, 7.0939e-03, 2.0669e-03, 1.5719e-03, 1.2433e-01, 7.0957e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,986][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0074, 0.0195, 0.2741, 0.1753, 0.0742, 0.1851, 0.0232, 0.0417, 0.0194,
        0.0157, 0.1511, 0.0132], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,986][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0040, 0.0453, 0.1562, 0.1312, 0.1170, 0.1452, 0.0745, 0.0935, 0.0544,
        0.0299, 0.1358, 0.0131], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,986][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([1.6752e-06, 4.9381e-05, 4.3966e-01, 5.0808e-01, 9.7742e-05, 1.7280e-02,
        7.3739e-05, 7.0014e-05, 5.2249e-05, 4.9732e-05, 3.4555e-02, 2.7918e-05],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,987][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0080, 0.0119, 0.4448, 0.2306, 0.0234, 0.0597, 0.0125, 0.0129, 0.0128,
        0.0127, 0.1582, 0.0124], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,987][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0255, 0.0605, 0.1150, 0.2370, 0.0369, 0.0895, 0.0496, 0.0419, 0.0626,
        0.0686, 0.1510, 0.0618], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:26,988][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Megan] are: tensor([0.0271, 0.0444, 0.2522, 0.1572, 0.0494, 0.1018, 0.0437, 0.0453, 0.0442,
        0.0453, 0.1025, 0.0414, 0.0455], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,988][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Megan] are: tensor([0.0007, 0.0028, 0.6065, 0.2669, 0.0044, 0.0381, 0.0035, 0.0034, 0.0027,
        0.0026, 0.0633, 0.0020, 0.0032], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,989][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Megan] are: tensor([0.0212, 0.0337, 0.1869, 0.2459, 0.0380, 0.1311, 0.0370, 0.0342, 0.0325,
        0.0329, 0.1422, 0.0304, 0.0339], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,990][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Megan] are: tensor([0.1023, 0.0751, 0.0641, 0.0521, 0.0828, 0.0601, 0.0688, 0.0808, 0.0824,
        0.0807, 0.0762, 0.0875, 0.0871], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,991][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Megan] are: tensor([0.0018, 0.0062, 0.4792, 0.3095, 0.0089, 0.0823, 0.0070, 0.0072, 0.0059,
        0.0055, 0.0764, 0.0044, 0.0058], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,993][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Megan] are: tensor([0.0462, 0.0515, 0.1311, 0.1089, 0.0587, 0.1619, 0.0582, 0.0589, 0.0569,
        0.0549, 0.1047, 0.0527, 0.0554], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,994][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Megan] are: tensor([2.2938e-04, 3.7743e-03, 3.8233e-01, 1.7820e-01, 2.9514e-02, 2.4500e-01,
        8.5508e-03, 1.1160e-02, 4.1958e-03, 3.2841e-03, 1.2389e-01, 1.7434e-03,
        8.1194e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,995][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Megan] are: tensor([0.0088, 0.0199, 0.2760, 0.1408, 0.0806, 0.1618, 0.0167, 0.0291, 0.0166,
        0.0156, 0.1966, 0.0135, 0.0242], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,996][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Megan] are: tensor([0.0036, 0.0506, 0.1333, 0.0958, 0.1468, 0.1073, 0.0708, 0.0963, 0.0536,
        0.0245, 0.0897, 0.0112, 0.1166], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,997][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Megan] are: tensor([2.2331e-06, 6.1745e-05, 4.3742e-01, 5.0546e-01, 1.2652e-04, 1.9665e-02,
        9.2507e-05, 8.7620e-05, 6.4972e-05, 6.1513e-05, 3.6838e-02, 3.4495e-05,
        8.3981e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:26,999][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Megan] are: tensor([0.0159, 0.0205, 0.3577, 0.1876, 0.0394, 0.0640, 0.0209, 0.0215, 0.0220,
        0.0225, 0.1756, 0.0225, 0.0298], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,000][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Megan] are: tensor([0.0289, 0.0682, 0.0895, 0.1920, 0.0337, 0.0763, 0.0525, 0.0411, 0.0733,
        0.0812, 0.1292, 0.0745, 0.0597], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,002][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0495, 0.0272, 0.0683, 0.0062, 0.0701, 0.0155, 0.0361, 0.0427, 0.0485,
        0.0452, 0.0449, 0.0493, 0.0633, 0.4331], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,003][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0296, 0.0239, 0.1269, 0.0626, 0.0484, 0.0417, 0.0263, 0.0262, 0.0282,
        0.0259, 0.1489, 0.0258, 0.0344, 0.3510], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,004][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0993, 0.0411, 0.1755, 0.0145, 0.1194, 0.0309, 0.0424, 0.0422, 0.0545,
        0.0503, 0.0510, 0.0605, 0.0781, 0.1402], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,005][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ said] are: tensor([2.7870e-01, 4.0001e-02, 5.1348e-04, 2.4723e-04, 1.8005e-01, 2.4712e-03,
        3.3696e-02, 4.2406e-02, 6.0031e-02, 7.4164e-02, 3.1530e-02, 1.0117e-01,
        1.4749e-01, 7.5230e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,007][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0087, 0.0156, 0.2101, 0.0982, 0.0226, 0.1079, 0.0192, 0.0200, 0.0174,
        0.0137, 0.0603, 0.0134, 0.0159, 0.3770], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,008][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.1389, 0.0576, 0.0085, 0.0031, 0.0793, 0.0236, 0.0669, 0.0761, 0.0899,
        0.0846, 0.0254, 0.0938, 0.0977, 0.1547], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,010][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0006, 0.0038, 0.2861, 0.0883, 0.0265, 0.1084, 0.0072, 0.0089, 0.0045,
        0.0033, 0.0665, 0.0023, 0.0080, 0.3857], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,011][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0032, 0.0071, 0.2665, 0.1306, 0.1088, 0.1291, 0.0083, 0.0103, 0.0054,
        0.0060, 0.2121, 0.0048, 0.0133, 0.0945], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,012][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0023, 0.0449, 0.1123, 0.0936, 0.1206, 0.1068, 0.0723, 0.0882, 0.0468,
        0.0247, 0.0917, 0.0089, 0.0953, 0.0916], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,013][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ said] are: tensor([6.0876e-07, 4.1257e-06, 5.1620e-02, 6.6216e-02, 2.0787e-05, 3.6050e-03,
        8.0526e-06, 8.2711e-06, 5.8113e-06, 4.2538e-06, 1.1976e-02, 3.0615e-06,
        8.7320e-06, 8.6652e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,015][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0338, 0.0110, 0.0515, 0.0039, 0.0938, 0.0048, 0.0110, 0.0117, 0.0150,
        0.0193, 0.0967, 0.0249, 0.0440, 0.5785], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,016][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0392, 0.0605, 0.0178, 0.0380, 0.0158, 0.0178, 0.0330, 0.0227, 0.0669,
        0.0824, 0.0520, 0.0831, 0.0486, 0.4221], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,017][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0234, 0.0161, 0.0763, 0.0053, 0.0351, 0.0093, 0.0184, 0.0223, 0.0254,
        0.0243, 0.0256, 0.0273, 0.0331, 0.5993, 0.0587], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,017][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0062, 0.0082, 0.1441, 0.0402, 0.0180, 0.0256, 0.0101, 0.0100, 0.0092,
        0.0086, 0.0715, 0.0078, 0.0125, 0.3804, 0.2477], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,018][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0453, 0.0287, 0.1780, 0.0192, 0.0737, 0.0305, 0.0301, 0.0318, 0.0371,
        0.0347, 0.0564, 0.0402, 0.0518, 0.2300, 0.1125], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,018][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([2.9027e-01, 4.4071e-02, 8.9079e-04, 2.6714e-04, 1.3959e-01, 2.4205e-03,
        3.5209e-02, 4.6937e-02, 6.7783e-02, 7.8712e-02, 2.3543e-02, 1.1148e-01,
        1.3662e-01, 7.6663e-03, 1.4539e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,018][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0022, 0.0055, 0.1399, 0.0808, 0.0083, 0.0701, 0.0069, 0.0071, 0.0058,
        0.0047, 0.0421, 0.0042, 0.0054, 0.5300, 0.0871], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,019][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0665, 0.0363, 0.0153, 0.0063, 0.0644, 0.0417, 0.0456, 0.0521, 0.0564,
        0.0524, 0.0431, 0.0548, 0.0665, 0.2689, 0.1299], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,019][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0004, 0.0029, 0.2904, 0.0726, 0.0226, 0.0850, 0.0055, 0.0070, 0.0033,
        0.0025, 0.0520, 0.0017, 0.0061, 0.3125, 0.1356], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,020][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0021, 0.0049, 0.2363, 0.0992, 0.0907, 0.1003, 0.0056, 0.0075, 0.0037,
        0.0042, 0.1761, 0.0034, 0.0104, 0.0747, 0.1808], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,020][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0030, 0.0461, 0.1058, 0.0827, 0.1200, 0.0915, 0.0685, 0.0759, 0.0421,
        0.0245, 0.0751, 0.0098, 0.0862, 0.0770, 0.0916], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,021][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([8.3288e-08, 1.2796e-06, 7.3871e-02, 4.8223e-02, 8.0447e-06, 1.4830e-03,
        2.3248e-06, 2.5008e-06, 1.6818e-06, 1.2894e-06, 5.8727e-03, 7.9584e-07,
        2.8287e-06, 7.6260e-01, 1.0793e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,022][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0253, 0.0099, 0.0357, 0.0035, 0.0603, 0.0036, 0.0084, 0.0094, 0.0135,
        0.0167, 0.0612, 0.0211, 0.0353, 0.5797, 0.1164], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,023][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0078, 0.0182, 0.0196, 0.0463, 0.0077, 0.0168, 0.0127, 0.0096, 0.0222,
        0.0247, 0.0455, 0.0229, 0.0176, 0.5187, 0.2098], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,067][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:27,068][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,068][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,068][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,069][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,069][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,069][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,070][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,070][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,070][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,071][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,072][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,073][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,074][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3833, 0.6167], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,075][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1940, 0.8060], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,077][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.3924, 0.6076], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,078][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5575, 0.4425], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,080][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2409, 0.7591], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,081][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4639, 0.5361], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,082][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0984, 0.9016], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,084][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3809, 0.6191], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,085][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3583, 0.6417], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,086][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0407, 0.9593], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,088][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.4232, 0.5768], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,089][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2040, 0.7960], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,091][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Jennifer] are: tensor([0.4141, 0.2267, 0.3592], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,092][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Jennifer] are: tensor([0.0426, 0.0420, 0.9154], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,092][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Jennifer] are: tensor([0.3592, 0.1942, 0.4466], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,093][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Jennifer] are: tensor([0.7525, 0.1849, 0.0626], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,093][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Jennifer] are: tensor([0.0421, 0.0871, 0.8708], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,093][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Jennifer] are: tensor([0.5325, 0.2913, 0.1762], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,094][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Jennifer] are: tensor([1.0989e-04, 4.3096e-04, 9.9946e-01], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,094][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Jennifer] are: tensor([0.1286, 0.1241, 0.7473], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,094][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Jennifer] are: tensor([0.1174, 0.1020, 0.7806], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,094][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Jennifer] are: tensor([1.4411e-05, 9.4224e-05, 9.9989e-01], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,095][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Jennifer] are: tensor([0.0415, 0.0182, 0.9403], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,095][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Jennifer] are: tensor([0.0223, 0.0561, 0.9216], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,095][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1763, 0.1294, 0.5022, 0.1921], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,096][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0200, 0.0220, 0.6475, 0.3105], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,096][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1248, 0.0802, 0.5737, 0.2213], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,098][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.7110, 0.1427, 0.1053, 0.0410], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,099][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0130, 0.0277, 0.5596, 0.3998], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,100][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3361, 0.2000, 0.2898, 0.1741], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,101][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([2.9098e-05, 1.3339e-04, 5.4132e-01, 4.5852e-01], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,102][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0428, 0.0369, 0.4912, 0.4291], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,104][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1333, 0.1133, 0.5523, 0.2011], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,104][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([2.3360e-06, 1.8006e-05, 5.0836e-01, 4.9162e-01], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,106][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0140, 0.0065, 0.8421, 0.1374], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,107][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0034, 0.0110, 0.6016, 0.3840], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,109][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Megan] are: tensor([0.0621, 0.0900, 0.4413, 0.3004, 0.1061], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,110][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Megan] are: tensor([5.8463e-04, 2.2923e-03, 6.5550e-01, 3.3768e-01, 3.9343e-03],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,111][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Megan] are: tensor([0.0401, 0.0622, 0.3465, 0.4843, 0.0670], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,112][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Megan] are: tensor([0.3501, 0.2190, 0.0978, 0.0843, 0.2488], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,114][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Megan] are: tensor([0.0018, 0.0069, 0.5739, 0.4077, 0.0098], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,115][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Megan] are: tensor([0.1207, 0.1304, 0.3258, 0.2615, 0.1616], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,116][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Megan] are: tensor([9.6140e-06, 1.0166e-04, 5.7464e-01, 4.2500e-01, 2.4610e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,117][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Megan] are: tensor([0.0419, 0.0607, 0.3942, 0.4268, 0.0765], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,119][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Megan] are: tensor([0.0195, 0.0328, 0.4664, 0.4376, 0.0438], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,120][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Megan] are: tensor([7.6375e-07, 2.1254e-05, 3.8855e-01, 6.1139e-01, 4.3569e-05],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,121][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Megan] are: tensor([0.0306, 0.0354, 0.5738, 0.2845, 0.0758], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,122][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Megan] are: tensor([2.3369e-04, 1.0381e-03, 4.0098e-01, 5.9585e-01, 1.8989e-03],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,123][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0432, 0.0469, 0.4344, 0.2485, 0.0994, 0.1275], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,124][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0032, 0.0061, 0.6808, 0.2444, 0.0131, 0.0524], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,125][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0407, 0.0382, 0.3749, 0.3120, 0.0791, 0.1550], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,125][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.3129, 0.1017, 0.1012, 0.1331, 0.2955, 0.0556], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,125][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0024, 0.0076, 0.5289, 0.3098, 0.0109, 0.1404], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,126][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.1231, 0.0948, 0.1494, 0.1211, 0.1479, 0.3638], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,126][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([1.1644e-05, 9.0158e-05, 5.2834e-01, 4.4040e-01, 3.0078e-04, 3.0865e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,126][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0085, 0.0110, 0.4700, 0.3758, 0.0302, 0.1045], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,127][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0268, 0.0328, 0.5130, 0.2240, 0.0721, 0.1314], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,127][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([2.0110e-06, 2.2493e-05, 2.8096e-01, 6.9675e-01, 7.3988e-05, 2.2188e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,127][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0058, 0.0048, 0.6184, 0.3209, 0.0280, 0.0221], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,127][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0010, 0.0038, 0.4742, 0.4203, 0.0074, 0.0933], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,128][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0312, 0.0509, 0.3890, 0.2627, 0.0623, 0.1515, 0.0524],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,129][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([5.0307e-04, 2.1296e-03, 6.7365e-01, 2.8449e-01, 3.5613e-03, 3.2931e-02,
        2.7365e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,130][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0243, 0.0393, 0.2697, 0.3875, 0.0480, 0.1867, 0.0445],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,132][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1191, 0.0916, 0.2246, 0.2279, 0.1189, 0.1362, 0.0817],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,133][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0017, 0.0060, 0.5398, 0.3454, 0.0092, 0.0909, 0.0069],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,134][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0595, 0.0681, 0.2347, 0.2151, 0.0813, 0.2633, 0.0780],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,135][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([1.6639e-05, 1.6388e-04, 5.4265e-01, 4.2855e-01, 4.0470e-04, 2.8001e-02,
        2.1211e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,136][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0181, 0.0293, 0.3474, 0.3651, 0.0391, 0.1674, 0.0337],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,138][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0156, 0.0273, 0.3333, 0.4128, 0.0358, 0.1473, 0.0280],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,139][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.5195e-06, 3.6394e-05, 4.0750e-01, 5.7856e-01, 7.4858e-05, 1.3767e-02,
        5.5956e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,140][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0068, 0.0098, 0.5496, 0.3429, 0.0216, 0.0594, 0.0099],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,141][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([4.2733e-04, 1.7095e-03, 4.0546e-01, 5.1052e-01, 2.9148e-03, 7.6699e-02,
        2.2617e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,142][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0228, 0.0392, 0.3946, 0.2697, 0.0483, 0.1425, 0.0410, 0.0420],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,143][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([5.2366e-04, 2.1542e-03, 6.3754e-01, 3.1525e-01, 3.6049e-03, 3.5443e-02,
        2.7909e-03, 2.6886e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,145][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0188, 0.0315, 0.2835, 0.3883, 0.0387, 0.1700, 0.0362, 0.0329],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,146][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0961, 0.0772, 0.1787, 0.2577, 0.0985, 0.1387, 0.0717, 0.0814],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,147][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0014, 0.0051, 0.5105, 0.3762, 0.0075, 0.0874, 0.0059, 0.0060],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,149][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0509, 0.0604, 0.2138, 0.2148, 0.0709, 0.2494, 0.0698, 0.0700],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,150][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([1.4979e-05, 1.4800e-04, 5.3413e-01, 4.3671e-01, 3.6181e-04, 2.8239e-02,
        1.9257e-04, 2.0684e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,151][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0150, 0.0253, 0.3269, 0.3872, 0.0334, 0.1499, 0.0288, 0.0335],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,152][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0122, 0.0225, 0.3298, 0.4149, 0.0294, 0.1441, 0.0233, 0.0236],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,153][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([1.3973e-06, 3.4936e-05, 3.9488e-01, 5.8994e-01, 7.1071e-05, 1.4962e-02,
        5.4943e-05, 5.2752e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,155][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0069, 0.0098, 0.4469, 0.4285, 0.0219, 0.0655, 0.0102, 0.0102],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,155][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([3.6430e-04, 1.4618e-03, 3.7232e-01, 5.4353e-01, 2.5104e-03, 7.5889e-02,
        1.9759e-03, 1.9488e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,157][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0322, 0.0532, 0.3405, 0.2138, 0.0611, 0.1368, 0.0532, 0.0557, 0.0535],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,157][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([5.5865e-04, 2.4069e-03, 6.6226e-01, 2.8758e-01, 3.8247e-03, 3.5052e-02,
        3.0309e-03, 2.9644e-03, 2.3191e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,157][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0263, 0.0414, 0.2416, 0.3417, 0.0487, 0.1694, 0.0470, 0.0433, 0.0407],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,158][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0986, 0.0798, 0.1790, 0.1664, 0.0997, 0.1234, 0.0765, 0.0900, 0.0867],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,158][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0019, 0.0063, 0.5261, 0.3477, 0.0095, 0.0879, 0.0072, 0.0074, 0.0060],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,158][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0556, 0.0635, 0.2019, 0.1754, 0.0727, 0.2190, 0.0714, 0.0712, 0.0692],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,159][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([2.0725e-05, 1.9857e-04, 5.4690e-01, 4.2086e-01, 4.7395e-04, 3.0819e-02,
        2.5626e-04, 2.7653e-04, 1.9660e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,159][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0220, 0.0351, 0.3121, 0.3010, 0.0443, 0.1602, 0.0403, 0.0472, 0.0377],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,159][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0138, 0.0255, 0.2925, 0.4114, 0.0321, 0.1479, 0.0264, 0.0268, 0.0236],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,160][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([1.9317e-06, 4.8781e-05, 4.2069e-01, 5.6335e-01, 8.9106e-05, 1.5629e-02,
        7.3888e-05, 7.1751e-05, 5.2222e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,161][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0091, 0.0130, 0.5111, 0.3233, 0.0273, 0.0740, 0.0138, 0.0144, 0.0139],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,161][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([4.5973e-04, 1.7511e-03, 3.8389e-01, 5.2569e-01, 2.9196e-03, 7.8886e-02,
        2.3439e-03, 2.3108e-03, 1.7481e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,163][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0315, 0.0516, 0.3153, 0.2056, 0.0593, 0.1274, 0.0514, 0.0535, 0.0516,
        0.0527], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,163][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([5.4087e-04, 2.3644e-03, 6.7675e-01, 2.7329e-01, 3.7704e-03, 3.2850e-02,
        2.9945e-03, 2.9046e-03, 2.2723e-03, 2.2619e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,165][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0265, 0.0412, 0.2291, 0.3166, 0.0491, 0.1656, 0.0468, 0.0435, 0.0408,
        0.0408], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,166][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1055, 0.0848, 0.1482, 0.1255, 0.0970, 0.0957, 0.0781, 0.0872, 0.0904,
        0.0876], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,168][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0021, 0.0070, 0.5342, 0.3265, 0.0106, 0.0906, 0.0079, 0.0082, 0.0066,
        0.0062], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,169][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0531, 0.0603, 0.1885, 0.1602, 0.0691, 0.2049, 0.0675, 0.0676, 0.0653,
        0.0636], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,170][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([2.1848e-05, 2.0498e-04, 5.4849e-01, 4.1950e-01, 5.0785e-04, 3.0326e-02,
        2.6696e-04, 2.8567e-04, 2.0382e-04, 1.8989e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,171][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0242, 0.0378, 0.3051, 0.2611, 0.0474, 0.1503, 0.0433, 0.0507, 0.0410,
        0.0390], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,173][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0154, 0.0277, 0.2831, 0.3868, 0.0344, 0.1433, 0.0287, 0.0288, 0.0256,
        0.0262], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,174][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([2.1374e-06, 5.0646e-05, 4.1824e-01, 5.6531e-01, 9.8064e-05, 1.6039e-02,
        7.6454e-05, 7.4903e-05, 5.5097e-05, 5.0494e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,175][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0120, 0.0167, 0.5161, 0.2833, 0.0325, 0.0699, 0.0170, 0.0171, 0.0176,
        0.0178], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,176][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([4.9736e-04, 1.8924e-03, 3.8286e-01, 5.2219e-01, 3.1636e-03, 8.0777e-02,
        2.5015e-03, 2.4761e-03, 1.8725e-03, 1.7726e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,177][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0446, 0.0437, 0.2852, 0.0549, 0.0982, 0.0484, 0.0494, 0.0568, 0.0629,
        0.0622, 0.1935], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,179][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0042, 0.0084, 0.5996, 0.1476, 0.0192, 0.0444, 0.0106, 0.0101, 0.0092,
        0.0087, 0.1380], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,180][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0384, 0.0326, 0.3492, 0.0849, 0.0865, 0.0650, 0.0359, 0.0369, 0.0405,
        0.0391, 0.1909], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,182][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3137, 0.0769, 0.0090, 0.0016, 0.1838, 0.0046, 0.0557, 0.0643, 0.1051,
        0.1206, 0.0646], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,183][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0025, 0.0073, 0.4913, 0.2363, 0.0134, 0.1233, 0.0089, 0.0093, 0.0076,
        0.0065, 0.0936], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,185][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0866, 0.0593, 0.0873, 0.0437, 0.1106, 0.1320, 0.0733, 0.0791, 0.0854,
        0.0792, 0.1635], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,186][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([8.9831e-06, 6.0021e-05, 6.8915e-01, 2.5441e-01, 2.5997e-04, 1.5749e-02,
        8.5837e-05, 8.8135e-05, 6.6751e-05, 5.7998e-05, 4.0063e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,187][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0392, 0.0348, 0.2021, 0.0955, 0.0984, 0.0712, 0.0370, 0.0452, 0.0442,
        0.0444, 0.2880], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,188][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0409, 0.0459, 0.3125, 0.0894, 0.0938, 0.0882, 0.0439, 0.0440, 0.0513,
        0.0510, 0.1391], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,188][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([7.0660e-07, 1.0754e-05, 5.0737e-01, 4.3689e-01, 5.4440e-05, 9.7914e-03,
        1.9089e-05, 2.0182e-05, 1.3867e-05, 1.0918e-05, 4.5814e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,189][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0322, 0.0188, 0.3700, 0.0321, 0.1063, 0.0131, 0.0164, 0.0165, 0.0240,
        0.0289, 0.3417], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,189][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0016, 0.0056, 0.4141, 0.3315, 0.0119, 0.0867, 0.0072, 0.0071, 0.0056,
        0.0052, 0.1234], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,189][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0211, 0.0376, 0.2897, 0.1951, 0.0429, 0.1138, 0.0377, 0.0392, 0.0369,
        0.0378, 0.1140, 0.0340], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,190][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([2.6405e-04, 1.3754e-03, 6.5556e-01, 2.6090e-01, 2.2111e-03, 2.5504e-02,
        1.7635e-03, 1.7200e-03, 1.3102e-03, 1.2974e-03, 4.7162e-02, 9.2655e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,190][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0171, 0.0287, 0.1897, 0.2902, 0.0333, 0.1385, 0.0332, 0.0304, 0.0281,
        0.0282, 0.1570, 0.0256], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,191][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0801, 0.0672, 0.1293, 0.1038, 0.0773, 0.0848, 0.0632, 0.0727, 0.0727,
        0.0695, 0.1054, 0.0740], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,191][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0012, 0.0044, 0.5086, 0.3180, 0.0067, 0.0731, 0.0050, 0.0052, 0.0041,
        0.0038, 0.0669, 0.0030], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,191][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0376, 0.0452, 0.1845, 0.1458, 0.0517, 0.1785, 0.0512, 0.0511, 0.0487,
        0.0472, 0.1137, 0.0448], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,192][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([1.0293e-05, 1.1499e-04, 5.3116e-01, 4.0652e-01, 2.9347e-04, 2.4971e-02,
        1.5201e-04, 1.6435e-04, 1.1353e-04, 1.0549e-04, 3.6331e-02, 6.7671e-05],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,193][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0168, 0.0278, 0.2864, 0.2319, 0.0347, 0.1310, 0.0324, 0.0384, 0.0302,
        0.0285, 0.1149, 0.0269], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,195][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0092, 0.0184, 0.2535, 0.3507, 0.0225, 0.1164, 0.0191, 0.0194, 0.0169,
        0.0172, 0.1418, 0.0149], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,196][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([1.0231e-06, 3.0311e-05, 4.0573e-01, 5.5213e-01, 5.7504e-05, 1.3139e-02,
        4.6362e-05, 4.5425e-05, 3.2991e-05, 3.0393e-05, 2.8744e-02, 1.6386e-05],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,197][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0080, 0.0119, 0.4448, 0.2306, 0.0234, 0.0597, 0.0125, 0.0129, 0.0128,
        0.0127, 0.1582, 0.0124], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,198][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([2.5551e-04, 1.0827e-03, 3.3013e-01, 4.9395e-01, 1.7858e-03, 6.3829e-02,
        1.4535e-03, 1.4380e-03, 1.0645e-03, 1.0051e-03, 1.0328e-01, 7.3036e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,199][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Megan] are: tensor([0.0271, 0.0444, 0.2522, 0.1572, 0.0494, 0.1018, 0.0437, 0.0453, 0.0442,
        0.0453, 0.1025, 0.0414, 0.0455], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,201][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Megan] are: tensor([0.0007, 0.0028, 0.6065, 0.2669, 0.0044, 0.0381, 0.0035, 0.0034, 0.0027,
        0.0026, 0.0633, 0.0020, 0.0032], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,202][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Megan] are: tensor([0.0212, 0.0337, 0.1869, 0.2459, 0.0380, 0.1311, 0.0370, 0.0342, 0.0325,
        0.0329, 0.1422, 0.0304, 0.0339], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,204][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Megan] are: tensor([0.1023, 0.0751, 0.0641, 0.0521, 0.0828, 0.0601, 0.0688, 0.0808, 0.0824,
        0.0807, 0.0762, 0.0875, 0.0871], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,205][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Megan] are: tensor([0.0018, 0.0062, 0.4792, 0.3095, 0.0089, 0.0823, 0.0070, 0.0072, 0.0059,
        0.0055, 0.0764, 0.0044, 0.0058], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,206][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Megan] are: tensor([0.0462, 0.0515, 0.1311, 0.1089, 0.0587, 0.1619, 0.0582, 0.0589, 0.0569,
        0.0549, 0.1047, 0.0527, 0.0554], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,207][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Megan] are: tensor([1.8645e-05, 1.8390e-04, 5.4642e-01, 3.8313e-01, 4.3261e-04, 2.9350e-02,
        2.3524e-04, 2.5363e-04, 1.8051e-04, 1.6704e-04, 3.9279e-02, 1.0960e-04,
        2.3356e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,209][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Megan] are: tensor([0.0237, 0.0354, 0.2306, 0.1937, 0.0434, 0.1212, 0.0393, 0.0472, 0.0381,
        0.0363, 0.1163, 0.0351, 0.0395], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,210][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Megan] are: tensor([0.0124, 0.0224, 0.2633, 0.2972, 0.0279, 0.1173, 0.0229, 0.0235, 0.0209,
        0.0211, 0.1302, 0.0184, 0.0225], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,211][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Megan] are: tensor([1.8707e-06, 4.7532e-05, 4.0177e-01, 5.4980e-01, 8.8721e-05, 1.6217e-02,
        7.1064e-05, 6.9119e-05, 5.1202e-05, 4.6942e-05, 3.1742e-02, 2.5809e-05,
        6.3579e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,213][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Megan] are: tensor([0.0159, 0.0205, 0.3577, 0.1876, 0.0394, 0.0640, 0.0209, 0.0215, 0.0220,
        0.0225, 0.1756, 0.0225, 0.0298], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,214][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Megan] are: tensor([3.6250e-04, 1.4192e-03, 3.3958e-01, 4.6997e-01, 2.3938e-03, 7.1454e-02,
        1.9388e-03, 1.8962e-03, 1.4183e-03, 1.3153e-03, 1.0550e-01, 9.6817e-04,
        1.7775e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,215][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0495, 0.0272, 0.0683, 0.0062, 0.0701, 0.0155, 0.0361, 0.0427, 0.0485,
        0.0452, 0.0449, 0.0493, 0.0633, 0.4331], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,216][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0296, 0.0239, 0.1269, 0.0626, 0.0484, 0.0417, 0.0263, 0.0262, 0.0282,
        0.0259, 0.1489, 0.0258, 0.0344, 0.3510], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,218][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0993, 0.0411, 0.1755, 0.0145, 0.1194, 0.0309, 0.0424, 0.0422, 0.0545,
        0.0503, 0.0510, 0.0605, 0.0781, 0.1402], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,219][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([2.7870e-01, 4.0001e-02, 5.1348e-04, 2.4723e-04, 1.8005e-01, 2.4712e-03,
        3.3696e-02, 4.2406e-02, 6.0031e-02, 7.4164e-02, 3.1530e-02, 1.0117e-01,
        1.4749e-01, 7.5230e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,220][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0087, 0.0156, 0.2101, 0.0982, 0.0226, 0.1079, 0.0192, 0.0200, 0.0174,
        0.0137, 0.0603, 0.0134, 0.0159, 0.3770], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,220][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.1389, 0.0576, 0.0085, 0.0031, 0.0793, 0.0236, 0.0669, 0.0761, 0.0899,
        0.0846, 0.0254, 0.0938, 0.0977, 0.1547], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,221][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([4.4316e-05, 1.2547e-04, 1.5427e-01, 6.6044e-02, 3.9338e-04, 9.5546e-03,
        1.6202e-04, 1.6123e-04, 1.4237e-04, 1.1766e-04, 1.9625e-02, 1.0439e-04,
        1.8571e-04, 7.4907e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,221][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0407, 0.0258, 0.0942, 0.0329, 0.0763, 0.0305, 0.0251, 0.0341, 0.0330,
        0.0353, 0.1266, 0.0423, 0.0570, 0.3461], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,221][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0697, 0.0507, 0.1038, 0.0220, 0.1247, 0.0407, 0.0451, 0.0540, 0.0633,
        0.0591, 0.0596, 0.0624, 0.0878, 0.1571], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,222][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([1.7068e-06, 8.9505e-06, 8.2884e-02, 9.7524e-02, 4.4725e-05, 4.6250e-03,
        1.7361e-05, 1.8527e-05, 1.2572e-05, 8.9404e-06, 1.6267e-02, 6.6525e-06,
        1.8885e-05, 7.9856e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,222][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0338, 0.0110, 0.0515, 0.0039, 0.0938, 0.0048, 0.0110, 0.0117, 0.0150,
        0.0193, 0.0967, 0.0249, 0.0440, 0.5785], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,223][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0053, 0.0119, 0.1895, 0.2059, 0.0238, 0.0645, 0.0151, 0.0145, 0.0120,
        0.0112, 0.1296, 0.0086, 0.0159, 0.2921], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,223][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0234, 0.0161, 0.0763, 0.0053, 0.0351, 0.0093, 0.0184, 0.0223, 0.0254,
        0.0243, 0.0256, 0.0273, 0.0331, 0.5993, 0.0587], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,224][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0062, 0.0082, 0.1441, 0.0402, 0.0180, 0.0256, 0.0101, 0.0100, 0.0092,
        0.0086, 0.0715, 0.0078, 0.0125, 0.3804, 0.2477], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,225][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0453, 0.0287, 0.1780, 0.0192, 0.0737, 0.0305, 0.0301, 0.0318, 0.0371,
        0.0347, 0.0564, 0.0402, 0.0518, 0.2300, 0.1125], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,226][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.9027e-01, 4.4071e-02, 8.9079e-04, 2.6714e-04, 1.3959e-01, 2.4205e-03,
        3.5209e-02, 4.6937e-02, 6.7783e-02, 7.8712e-02, 2.3543e-02, 1.1148e-01,
        1.3662e-01, 7.6663e-03, 1.4539e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,227][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0022, 0.0055, 0.1399, 0.0808, 0.0083, 0.0701, 0.0069, 0.0071, 0.0058,
        0.0047, 0.0421, 0.0042, 0.0054, 0.5300, 0.0871], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,229][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0665, 0.0363, 0.0153, 0.0063, 0.0644, 0.0417, 0.0456, 0.0521, 0.0564,
        0.0524, 0.0431, 0.0548, 0.0665, 0.2689, 0.1299], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,230][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([8.4986e-06, 3.5937e-05, 1.2930e-01, 4.0755e-02, 1.2724e-04, 4.0057e-03,
        4.7680e-05, 4.7823e-05, 3.9555e-05, 3.3920e-05, 8.5724e-03, 2.7222e-05,
        5.3013e-05, 7.0088e-01, 1.1607e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,231][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0329, 0.0245, 0.0695, 0.0209, 0.0684, 0.0247, 0.0238, 0.0311, 0.0324,
        0.0323, 0.0919, 0.0391, 0.0537, 0.3456, 0.1092], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,233][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0416, 0.0376, 0.1248, 0.0289, 0.0780, 0.0516, 0.0351, 0.0393, 0.0445,
        0.0419, 0.0582, 0.0424, 0.0605, 0.2091, 0.1065], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,233][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.6442e-07, 2.7547e-06, 1.0440e-01, 7.0731e-02, 1.6204e-05, 1.9514e-03,
        4.9363e-06, 5.4024e-06, 3.6292e-06, 2.6747e-06, 7.4489e-03, 1.7663e-06,
        5.9354e-06, 6.7623e-01, 1.3919e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,235][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0253, 0.0099, 0.0357, 0.0035, 0.0603, 0.0036, 0.0084, 0.0094, 0.0135,
        0.0167, 0.0612, 0.0211, 0.0353, 0.5797, 0.1164], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,236][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0052, 0.0121, 0.1705, 0.0903, 0.0235, 0.0602, 0.0142, 0.0145, 0.0122,
        0.0111, 0.0657, 0.0091, 0.0162, 0.1517, 0.3433], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,237][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:27,239][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[3530],
        [ 405],
        [ 889],
        [ 103],
        [ 149],
        [  52],
        [  51],
        [  35],
        [  96],
        [ 136],
        [ 206],
        [ 118],
        [ 219],
        [  79],
        [  89]], device='cuda:0')
[2024-07-24 10:29:27,240][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[2799],
        [ 582],
        [ 351],
        [  34],
        [  90],
        [  38],
        [  37],
        [  29],
        [  73],
        [ 105],
        [ 149],
        [  95],
        [ 163],
        [ 121],
        [ 111]], device='cuda:0')
[2024-07-24 10:29:27,242][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 3083],
        [ 2554],
        [41259],
        [36198],
        [29153],
        [28506],
        [25462],
        [25712],
        [25030],
        [24030],
        [22794],
        [19772],
        [18894],
        [10689],
        [10956]], device='cuda:0')
[2024-07-24 10:29:27,243][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[32461],
        [37325],
        [28083],
        [30709],
        [30801],
        [30835],
        [30838],
        [31143],
        [30917],
        [30787],
        [31276],
        [30893],
        [31332],
        [40885],
        [39661]], device='cuda:0')
[2024-07-24 10:29:27,244][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[23546],
        [25701],
        [49944],
        [49871],
        [49107],
        [49306],
        [48319],
        [48432],
        [48185],
        [48153],
        [49667],
        [47691],
        [47910],
        [48889],
        [47646]], device='cuda:0')
[2024-07-24 10:29:27,246][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[29913],
        [31103],
        [31209],
        [32755],
        [34298],
        [36214],
        [39039],
        [39557],
        [38697],
        [37890],
        [34359],
        [39025],
        [37529],
        [33831],
        [34154]], device='cuda:0')
[2024-07-24 10:29:27,247][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 3648],
        [10804],
        [25443],
        [28949],
        [29064],
        [30209],
        [29850],
        [30054],
        [29905],
        [29803],
        [31249],
        [30619],
        [30941],
        [33094],
        [35043]], device='cuda:0')
[2024-07-24 10:29:27,249][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[44726],
        [43080],
        [44744],
        [43464],
        [41699],
        [42772],
        [42886],
        [42974],
        [43073],
        [43085],
        [41027],
        [42332],
        [42114],
        [30206],
        [26220]], device='cuda:0')
[2024-07-24 10:29:27,250][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[48466],
        [42483],
        [50083],
        [49648],
        [49504],
        [48757],
        [48144],
        [47960],
        [47643],
        [47655],
        [48415],
        [46361],
        [47079],
        [43941],
        [43748]], device='cuda:0')
[2024-07-24 10:29:27,251][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 479],
        [1345],
        [1366],
        [1431],
        [2080],
        [1994],
        [1640],
        [1522],
        [1672],
        [1798],
        [2013],
        [1689],
        [1775],
        [1899],
        [2171]], device='cuda:0')
[2024-07-24 10:29:27,253][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[1352],
        [1191],
        [ 316],
        [  73],
        [  44],
        [  35],
        [  26],
        [  18],
        [  16],
        [  16],
        [  16],
        [  15],
        [  17],
        [  19],
        [  25]], device='cuda:0')
[2024-07-24 10:29:27,254][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 2842],
        [ 9962],
        [50253],
        [50162],
        [49991],
        [48793],
        [50054],
        [50026],
        [50061],
        [50049],
        [50176],
        [50027],
        [50025],
        [17186],
        [20940]], device='cuda:0')
[2024-07-24 10:29:27,255][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[10834],
        [10262],
        [14288],
        [13548],
        [12195],
        [12278],
        [11859],
        [11352],
        [11644],
        [11652],
        [10089],
        [10911],
        [10354],
        [13637],
        [14353]], device='cuda:0')
[2024-07-24 10:29:27,256][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[19475],
        [16810],
        [30569],
        [21808],
        [21325],
        [21538],
        [20396],
        [19703],
        [20167],
        [20190],
        [17839],
        [18287],
        [18548],
        [15962],
        [14911]], device='cuda:0')
[2024-07-24 10:29:27,257][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[26741],
        [30618],
        [26307],
        [28033],
        [31936],
        [26056],
        [31976],
        [30016],
        [29065],
        [29665],
        [26875],
        [27660],
        [31190],
        [21003],
        [23252]], device='cuda:0')
[2024-07-24 10:29:27,258][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 6646],
        [10803],
        [36346],
        [36751],
        [34216],
        [33737],
        [32671],
        [32635],
        [31892],
        [31392],
        [28184],
        [28632],
        [27558],
        [25110],
        [26787]], device='cuda:0')
[2024-07-24 10:29:27,259][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[18302],
        [ 7684],
        [ 2363],
        [  879],
        [  822],
        [  984],
        [  917],
        [  800],
        [  891],
        [  938],
        [  745],
        [  827],
        [  699],
        [  420],
        [  319]], device='cuda:0')
[2024-07-24 10:29:27,260][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[12641],
        [16072],
        [16801],
        [18513],
        [18167],
        [20791],
        [21676],
        [21593],
        [21606],
        [21465],
        [18202],
        [21165],
        [20613],
        [22152],
        [28500]], device='cuda:0')
[2024-07-24 10:29:27,262][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[1431],
        [ 961],
        [ 844],
        [ 524],
        [ 410],
        [ 291],
        [ 163],
        [ 163],
        [ 192],
        [ 232],
        [ 607],
        [ 188],
        [ 289],
        [ 834],
        [ 751]], device='cuda:0')
[2024-07-24 10:29:27,263][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 8637],
        [ 9506],
        [26986],
        [30151],
        [30176],
        [28191],
        [28834],
        [28842],
        [28770],
        [28681],
        [26772],
        [27952],
        [27511],
        [16481],
        [13550]], device='cuda:0')
[2024-07-24 10:29:27,265][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 7068],
        [ 8587],
        [11275],
        [ 8584],
        [ 8356],
        [ 4978],
        [ 5692],
        [ 5687],
        [ 6033],
        [ 6095],
        [ 6378],
        [ 5937],
        [ 5958],
        [16058],
        [ 9614]], device='cuda:0')
[2024-07-24 10:29:27,266][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[12306],
        [ 5360],
        [ 4979],
        [ 3207],
        [ 3354],
        [ 3109],
        [ 3176],
        [ 3131],
        [ 3193],
        [ 3199],
        [ 3920],
        [ 3267],
        [ 3325],
        [ 3662],
        [ 4056]], device='cuda:0')
[2024-07-24 10:29:27,267][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 8458],
        [13805],
        [11063],
        [23643],
        [25922],
        [23747],
        [27300],
        [28429],
        [26387],
        [25200],
        [23914],
        [26084],
        [26129],
        [22734],
        [19800]], device='cuda:0')
[2024-07-24 10:29:27,269][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[18118],
        [15107],
        [31230],
        [32517],
        [29907],
        [31076],
        [26907],
        [26795],
        [26167],
        [26235],
        [30231],
        [25426],
        [26139],
        [27845],
        [24677]], device='cuda:0')
[2024-07-24 10:29:27,270][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[32278],
        [27821],
        [21698],
        [27224],
        [27709],
        [27851],
        [28017],
        [28068],
        [28056],
        [28074],
        [27316],
        [27972],
        [28046],
        [27884],
        [27628]], device='cuda:0')
[2024-07-24 10:29:27,272][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 2820],
        [ 4671],
        [13573],
        [15125],
        [14496],
        [16209],
        [16536],
        [16590],
        [15917],
        [15247],
        [11147],
        [15210],
        [12944],
        [15188],
        [15923]], device='cuda:0')
[2024-07-24 10:29:27,273][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[9348],
        [5778],
        [2302],
        [1317],
        [1314],
        [1488],
        [1472],
        [1485],
        [1482],
        [1488],
        [1610],
        [1576],
        [1582],
        [1248],
        [1986]], device='cuda:0')
[2024-07-24 10:29:27,274][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[47498],
        [48337],
        [41359],
        [41630],
        [43218],
        [45153],
        [45205],
        [45397],
        [45420],
        [45570],
        [46077],
        [46451],
        [46715],
        [46432],
        [47340]], device='cuda:0')
[2024-07-24 10:29:27,276][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[24148],
        [20206],
        [38259],
        [36018],
        [27260],
        [29348],
        [24626],
        [26755],
        [26172],
        [25119],
        [31724],
        [25749],
        [24942],
        [34523],
        [35402]], device='cuda:0')
[2024-07-24 10:29:27,277][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[9034],
        [9034],
        [9034],
        [9034],
        [9034],
        [9034],
        [9034],
        [9034],
        [9034],
        [9034],
        [9034],
        [9034],
        [9034],
        [9034],
        [9034]], device='cuda:0')
[2024-07-24 10:29:27,323][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:27,324][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,324][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,325][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,325][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,326][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,326][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,327][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,327][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,327][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,328][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,328][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,328][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,329][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1950, 0.8050], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,329][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0858, 0.9142], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,329][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2139, 0.7861], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,330][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3394, 0.6606], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,330][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4776, 0.5224], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,330][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4464, 0.5536], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,331][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0399, 0.9601], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,331][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.3934, 0.6066], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,331][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2543, 0.7457], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,332][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3782, 0.6218], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,333][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([3.5468e-04, 9.9965e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,335][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1300, 0.8700], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,336][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Jennifer] are: tensor([0.0039, 0.0145, 0.9816], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,336][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Jennifer] are: tensor([9.0485e-05, 3.3772e-04, 9.9957e-01], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,337][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Jennifer] are: tensor([0.0029, 0.0066, 0.9905], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,337][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Jennifer] are: tensor([0.0061, 0.0164, 0.9775], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,337][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Jennifer] are: tensor([0.2679, 0.2342, 0.4980], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,338][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Jennifer] are: tensor([0.1967, 0.1123, 0.6910], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,338][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Jennifer] are: tensor([0.0239, 0.2502, 0.7258], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,338][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Jennifer] are: tensor([0.0621, 0.0558, 0.8821], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,339][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Jennifer] are: tensor([0.0218, 0.0315, 0.9467], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,339][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Jennifer] are: tensor([0.5014, 0.2017, 0.2970], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,340][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Jennifer] are: tensor([0.0048, 0.9640, 0.0313], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,341][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Jennifer] are: tensor([0.2123, 0.1276, 0.6602], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,342][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0007, 0.0024, 0.3396, 0.6573], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,343][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([1.2859e-05, 7.5115e-05, 7.2823e-01, 2.7169e-01], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,344][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([3.1385e-04, 9.9420e-04, 2.2769e-01, 7.7100e-01], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,345][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([7.5128e-04, 1.3198e-03, 9.4611e-02, 9.0332e-01], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,346][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0617, 0.0453, 0.0383, 0.8547], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,347][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1335, 0.0607, 0.3267, 0.4791], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,349][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0092, 0.1235, 0.2927, 0.5746], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,350][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0097, 0.0141, 0.6347, 0.3415], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,351][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0018, 0.0050, 0.6199, 0.3734], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,353][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1407, 0.0778, 0.6008, 0.1807], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,354][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([2.9457e-04, 8.0218e-02, 3.8339e-03, 9.1565e-01], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,355][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([6.8486e-05, 2.6231e-04, 7.9172e-01, 2.0795e-01], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,356][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Megan] are: tensor([0.0006, 0.0028, 0.5487, 0.4458, 0.0021], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,357][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Megan] are: tensor([2.7584e-06, 4.3621e-05, 6.8543e-01, 3.1448e-01, 4.3580e-05],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,358][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Megan] are: tensor([1.9113e-04, 9.3737e-04, 5.4966e-01, 4.4834e-01, 8.7252e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,359][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Megan] are: tensor([0.0027, 0.0068, 0.3502, 0.6361, 0.0041], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,361][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Megan] are: tensor([0.1297, 0.1292, 0.0775, 0.6587, 0.0050], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,362][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Megan] are: tensor([0.4832, 0.2213, 0.0617, 0.1049, 0.1289], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,363][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Megan] are: tensor([0.0082, 0.1363, 0.2126, 0.3490, 0.2938], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,365][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Megan] are: tensor([0.0294, 0.0456, 0.6179, 0.2529, 0.0542], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,366][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Megan] are: tensor([0.0011, 0.0037, 0.4625, 0.5280, 0.0047], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,368][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Megan] are: tensor([0.0344, 0.0588, 0.5441, 0.2592, 0.1035], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,368][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Megan] are: tensor([7.2425e-05, 5.7293e-02, 8.6376e-04, 9.2546e-01, 1.6316e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,368][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Megan] are: tensor([3.3595e-06, 3.7777e-05, 8.3707e-01, 1.6286e-01, 2.1635e-05],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,369][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ had] are: tensor([1.8468e-04, 8.6083e-04, 2.5062e-01, 5.7938e-01, 1.6247e-03, 1.6733e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,369][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ had] are: tensor([4.2349e-06, 3.2582e-05, 7.1060e-01, 2.7982e-01, 6.1248e-05, 9.4846e-03],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,369][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ had] are: tensor([4.9200e-05, 2.4918e-04, 3.3216e-01, 5.6519e-01, 3.4676e-04, 1.0201e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,370][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ had] are: tensor([1.9534e-04, 4.5543e-04, 1.2120e-01, 8.4316e-01, 5.2407e-04, 3.4465e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,370][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0374, 0.0286, 0.0535, 0.8643, 0.0012, 0.0151], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,370][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0143, 0.0132, 0.1747, 0.6277, 0.0914, 0.0787], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,370][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0032, 0.0657, 0.1552, 0.3532, 0.2223, 0.2004], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,371][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0018, 0.0028, 0.7467, 0.1574, 0.0049, 0.0864], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,371][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0008, 0.0022, 0.4636, 0.4254, 0.0029, 0.1051], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,372][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0131, 0.0130, 0.5066, 0.2898, 0.0780, 0.0994], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,373][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ had] are: tensor([4.4658e-05, 4.1755e-02, 1.0930e-03, 8.9865e-01, 1.9688e-02, 3.8768e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,373][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ had] are: tensor([8.7913e-07, 6.5938e-06, 9.2593e-01, 7.2763e-02, 6.0793e-06, 1.2903e-03],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,375][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0007, 0.0030, 0.4657, 0.4451, 0.0030, 0.0795, 0.0030],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,376][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([9.7960e-06, 1.2868e-04, 6.5828e-01, 3.3195e-01, 1.4062e-04, 9.3800e-03,
        1.0706e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,376][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([4.8350e-04, 2.1920e-03, 5.8227e-01, 3.6009e-01, 1.7920e-03, 5.1475e-02,
        1.7017e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,378][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0051, 0.0111, 0.3414, 0.5229, 0.0088, 0.0995, 0.0113],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,379][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1204, 0.1148, 0.1019, 0.5339, 0.0161, 0.0668, 0.0461],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,380][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0167, 0.0212, 0.2337, 0.5448, 0.0473, 0.1228, 0.0135],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,382][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0117, 0.0937, 0.1042, 0.1722, 0.1469, 0.1221, 0.3492],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,383][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0231, 0.0370, 0.5292, 0.1612, 0.0545, 0.1536, 0.0415],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,385][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0020, 0.0066, 0.3399, 0.5525, 0.0074, 0.0849, 0.0067],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,386][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0072, 0.0137, 0.4426, 0.3796, 0.0260, 0.1179, 0.0130],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,387][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([4.5828e-05, 2.7406e-02, 2.0465e-03, 8.2651e-01, 2.5151e-02, 8.5908e-02,
        3.2931e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,388][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([4.9373e-06, 5.5198e-05, 8.1707e-01, 1.7928e-01, 3.4872e-05, 3.5262e-03,
        3.0476e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,389][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ long] are: tensor([3.9855e-04, 1.9984e-03, 4.4959e-01, 4.7073e-01, 1.9244e-03, 7.1417e-02,
        1.9823e-03, 1.9609e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,389][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ long] are: tensor([7.0844e-06, 9.6638e-05, 6.5704e-01, 3.3348e-01, 1.0623e-04, 9.1188e-03,
        8.3118e-05, 7.2410e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,390][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ long] are: tensor([3.3268e-04, 1.5741e-03, 5.5409e-01, 3.8537e-01, 1.3121e-03, 5.4859e-02,
        1.2552e-03, 1.2028e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,392][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0033, 0.0075, 0.3271, 0.5459, 0.0061, 0.0945, 0.0080, 0.0076],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,393][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0998, 0.1000, 0.1013, 0.5569, 0.0114, 0.0649, 0.0398, 0.0261],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,395][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0061, 0.0104, 0.1751, 0.6638, 0.0175, 0.1143, 0.0069, 0.0059],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,396][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0093, 0.0623, 0.0724, 0.1259, 0.0892, 0.1011, 0.2984, 0.2413],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,397][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0148, 0.0246, 0.5221, 0.1826, 0.0384, 0.1593, 0.0291, 0.0292],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,399][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0015, 0.0049, 0.3264, 0.5668, 0.0056, 0.0848, 0.0051, 0.0050],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,400][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0047, 0.0096, 0.3297, 0.5036, 0.0184, 0.1146, 0.0094, 0.0100],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,400][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ long] are: tensor([1.0089e-05, 1.6819e-02, 5.3985e-04, 5.6079e-01, 1.1680e-02, 4.2276e-02,
        2.6654e-02, 3.4123e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,400][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ long] are: tensor([1.8301e-06, 2.4717e-05, 8.3346e-01, 1.6372e-01, 1.4600e-05, 2.7584e-03,
        1.2892e-05, 1.1267e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,400][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0011, 0.0044, 0.4756, 0.4134, 0.0044, 0.0884, 0.0043, 0.0044, 0.0041],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,401][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([2.2139e-05, 2.5871e-04, 6.2811e-01, 3.5726e-01, 2.8623e-04, 1.3397e-02,
        2.2593e-04, 1.9922e-04, 2.4595e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,401][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0010, 0.0039, 0.5762, 0.3438, 0.0032, 0.0628, 0.0030, 0.0029, 0.0032],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,401][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0090, 0.0180, 0.3792, 0.4151, 0.0148, 0.1115, 0.0179, 0.0176, 0.0169],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,402][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.1092, 0.1077, 0.1372, 0.3165, 0.0303, 0.0959, 0.0613, 0.0474, 0.0945],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,402][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0097, 0.0152, 0.2682, 0.4892, 0.0363, 0.1445, 0.0127, 0.0133, 0.0109],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,402][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([2.7222e-04, 1.3337e-02, 1.0392e-01, 1.5756e-01, 9.7830e-02, 1.1651e-01,
        2.7335e-01, 2.2629e-01, 1.0931e-02], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,403][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0331, 0.0499, 0.3859, 0.1316, 0.0706, 0.1586, 0.0570, 0.0594, 0.0539],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,405][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0039, 0.0111, 0.3382, 0.5005, 0.0117, 0.1023, 0.0112, 0.0110, 0.0101],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,406][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0114, 0.0199, 0.4143, 0.3178, 0.0381, 0.1324, 0.0203, 0.0230, 0.0229],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,407][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([2.8111e-05, 3.0856e-02, 2.1359e-03, 4.8583e-01, 2.1520e-02, 7.9420e-02,
        3.1794e-02, 3.4558e-01, 2.8398e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,408][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([2.8419e-05, 2.3199e-04, 7.6499e-01, 2.2556e-01, 1.6261e-04, 8.6105e-03,
        1.4109e-04, 1.2644e-04, 1.4747e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,409][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0014, 0.0055, 0.4707, 0.3987, 0.0057, 0.0966, 0.0054, 0.0056, 0.0051,
        0.0054], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,410][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([2.6064e-05, 2.9426e-04, 6.3055e-01, 3.5193e-01, 3.5896e-04, 1.5764e-02,
        2.6989e-04, 2.4235e-04, 2.8741e-04, 2.7948e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,411][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0012, 0.0046, 0.5876, 0.3244, 0.0039, 0.0635, 0.0036, 0.0035, 0.0038,
        0.0039], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,413][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0104, 0.0201, 0.3668, 0.3893, 0.0173, 0.1179, 0.0202, 0.0203, 0.0192,
        0.0186], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,414][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0930, 0.0936, 0.1254, 0.2634, 0.0356, 0.0963, 0.0612, 0.0483, 0.0856,
        0.0977], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,416][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0281, 0.0342, 0.2771, 0.3422, 0.0776, 0.1310, 0.0251, 0.0237, 0.0262,
        0.0348], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,417][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([1.6172e-04, 1.1493e-02, 1.2144e-01, 1.8048e-01, 1.3144e-01, 1.1560e-01,
        2.3418e-01, 1.9146e-01, 8.5028e-03, 5.2445e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,418][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0361, 0.0532, 0.3456, 0.1104, 0.0752, 0.1436, 0.0608, 0.0633, 0.0576,
        0.0542], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,420][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0040, 0.0118, 0.3021, 0.5198, 0.0125, 0.1042, 0.0120, 0.0118, 0.0107,
        0.0111], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,421][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0183, 0.0307, 0.3914, 0.2709, 0.0497, 0.1125, 0.0292, 0.0303, 0.0344,
        0.0326], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,422][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([2.2618e-05, 8.7557e-03, 1.1451e-03, 2.0141e-01, 1.3012e-02, 3.8320e-02,
        1.8489e-02, 2.8597e-01, 1.9005e-03, 4.3097e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,423][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([4.0590e-05, 3.0885e-04, 7.4355e-01, 2.4447e-01, 2.2812e-04, 1.0611e-02,
        1.9648e-04, 1.7811e-04, 1.9904e-04, 2.2090e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,424][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([2.5792e-04, 1.1125e-03, 3.4892e-01, 2.6619e-01, 2.0953e-03, 1.0067e-01,
        1.3438e-03, 1.3067e-03, 1.4455e-03, 1.4685e-03, 2.7519e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,425][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([8.6557e-06, 6.7023e-05, 8.3162e-01, 1.3239e-01, 1.5042e-04, 6.0312e-03,
        5.7938e-05, 5.2607e-05, 7.4627e-05, 6.7673e-05, 2.9479e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,425][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([2.0433e-04, 8.1078e-04, 3.7126e-01, 3.4761e-01, 1.0242e-03, 8.2906e-02,
        7.3913e-04, 7.6451e-04, 8.2727e-04, 7.8528e-04, 1.9307e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,427][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0010, 0.0019, 0.1367, 0.4943, 0.0022, 0.0365, 0.0024, 0.0023, 0.0023,
        0.0022, 0.3182], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,428][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0862, 0.0543, 0.0280, 0.4875, 0.0015, 0.0109, 0.0110, 0.0048, 0.0362,
        0.0616, 0.2178], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,430][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1832, 0.0560, 0.0383, 0.0366, 0.1415, 0.0172, 0.0221, 0.0142, 0.0494,
        0.1499, 0.2917], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,431][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0023, 0.0308, 0.0914, 0.1620, 0.1403, 0.0926, 0.1644, 0.1298, 0.0184,
        0.0164, 0.1516], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,432][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0053, 0.0089, 0.4568, 0.2327, 0.0197, 0.1319, 0.0095, 0.0093, 0.0087,
        0.0090, 0.1081], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,432][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0006, 0.0021, 0.6073, 0.2239, 0.0036, 0.0832, 0.0024, 0.0025, 0.0020,
        0.0020, 0.0704], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,432][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0918, 0.0514, 0.1429, 0.0036, 0.2990, 0.0109, 0.0386, 0.0497, 0.0812,
        0.0864, 0.1445], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,433][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([2.2244e-05, 1.2657e-02, 4.4136e-04, 2.0511e-01, 8.3060e-03, 1.9581e-02,
        1.6011e-02, 2.0186e-01, 1.3224e-03, 4.9103e-01, 4.3659e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,433][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([1.0959e-05, 6.2656e-05, 8.5326e-01, 1.1295e-01, 6.2976e-05, 3.6874e-03,
        4.2771e-05, 4.8484e-05, 4.8531e-05, 4.8816e-05, 2.9776e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,433][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0011, 0.0045, 0.4499, 0.3555, 0.0047, 0.0858, 0.0045, 0.0047, 0.0042,
        0.0044, 0.0770, 0.0036], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,434][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([1.8105e-05, 2.2299e-04, 5.7925e-01, 3.7309e-01, 2.9195e-04, 1.5839e-02,
        2.1575e-04, 1.9520e-04, 2.2291e-04, 2.1486e-04, 3.0281e-02, 1.5698e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,434][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0010, 0.0038, 0.5302, 0.3093, 0.0032, 0.0541, 0.0030, 0.0029, 0.0031,
        0.0032, 0.0835, 0.0027], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,434][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0085, 0.0171, 0.3393, 0.3351, 0.0145, 0.1049, 0.0168, 0.0170, 0.0161,
        0.0156, 0.1008, 0.0144], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,436][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0623, 0.0660, 0.1129, 0.1995, 0.0351, 0.0912, 0.0494, 0.0419, 0.0627,
        0.0687, 0.1356, 0.0748], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,437][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0107, 0.0161, 0.2281, 0.2623, 0.0593, 0.1083, 0.0149, 0.0156, 0.0136,
        0.0159, 0.2396, 0.0156], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,438][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([1.2503e-05, 3.4597e-03, 1.1098e-01, 1.9305e-01, 8.9989e-02, 1.0729e-01,
        1.7400e-01, 1.2384e-01, 2.3159e-03, 1.3236e-03, 1.9358e-01, 1.6674e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,439][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0329, 0.0489, 0.3055, 0.0914, 0.0677, 0.1268, 0.0557, 0.0590, 0.0529,
        0.0494, 0.0669, 0.0429], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,441][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0029, 0.0090, 0.2552, 0.4620, 0.0094, 0.0847, 0.0092, 0.0089, 0.0082,
        0.0085, 0.1351, 0.0069], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,442][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0143, 0.0245, 0.3288, 0.1945, 0.0432, 0.0963, 0.0245, 0.0268, 0.0286,
        0.0268, 0.1648, 0.0270], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,443][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([1.4882e-06, 9.3647e-03, 3.4983e-04, 2.0233e-01, 5.1128e-03, 2.0986e-02,
        7.1862e-03, 1.0873e-01, 1.0720e-03, 5.9939e-01, 4.4945e-02, 5.3397e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,444][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([5.2367e-05, 3.8150e-04, 7.0962e-01, 2.5685e-01, 2.9148e-04, 1.2209e-02,
        2.5101e-04, 2.2750e-04, 2.4838e-04, 2.7408e-04, 1.9374e-02, 2.2146e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,446][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Megan] are: tensor([0.0009, 0.0042, 0.4782, 0.3583, 0.0036, 0.0718, 0.0039, 0.0040, 0.0037,
        0.0040, 0.0603, 0.0032, 0.0038], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,446][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Megan] are: tensor([1.6099e-05, 2.0748e-04, 6.6479e-01, 3.0295e-01, 2.0283e-04, 1.0878e-02,
        1.6822e-04, 1.4948e-04, 1.9003e-04, 1.8439e-04, 1.9934e-02, 1.3942e-04,
        1.9000e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,448][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Megan] are: tensor([0.0007, 0.0029, 0.5556, 0.2983, 0.0023, 0.0529, 0.0022, 0.0022, 0.0024,
        0.0024, 0.0735, 0.0020, 0.0025], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,449][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Megan] are: tensor([0.0068, 0.0146, 0.3309, 0.3731, 0.0104, 0.0899, 0.0138, 0.0135, 0.0130,
        0.0129, 0.0979, 0.0118, 0.0114], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,451][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Megan] are: tensor([0.0904, 0.0886, 0.0713, 0.2110, 0.0141, 0.0454, 0.0391, 0.0277, 0.0687,
        0.0855, 0.1060, 0.1075, 0.0448], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,452][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Megan] are: tensor([0.0782, 0.0587, 0.0681, 0.1084, 0.0380, 0.0796, 0.0373, 0.0335, 0.0487,
        0.0835, 0.2153, 0.0985, 0.0521], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,454][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Megan] are: tensor([0.0033, 0.0337, 0.0654, 0.0779, 0.0825, 0.0750, 0.2101, 0.2112, 0.0322,
        0.0194, 0.0924, 0.0071, 0.0898], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,455][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Megan] are: tensor([0.0276, 0.0428, 0.3099, 0.1117, 0.0542, 0.1257, 0.0474, 0.0493, 0.0452,
        0.0422, 0.0652, 0.0366, 0.0423], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,457][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Megan] are: tensor([0.0025, 0.0075, 0.3183, 0.4333, 0.0085, 0.0827, 0.0075, 0.0074, 0.0068,
        0.0069, 0.1054, 0.0058, 0.0073], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,458][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Megan] are: tensor([0.0185, 0.0301, 0.3068, 0.1462, 0.0529, 0.0994, 0.0291, 0.0329, 0.0340,
        0.0325, 0.1424, 0.0328, 0.0424], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,459][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Megan] are: tensor([2.8422e-05, 6.8783e-03, 3.0636e-04, 1.8129e-01, 3.5585e-03, 2.2040e-02,
        1.8325e-02, 1.6464e-01, 1.1324e-03, 5.2745e-01, 6.9543e-02, 6.3132e-04,
        4.1748e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,460][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Megan] are: tensor([1.7221e-05, 1.6151e-04, 7.9492e-01, 1.8708e-01, 9.9573e-05, 6.8488e-03,
        9.0608e-05, 8.4098e-05, 9.6774e-05, 1.0745e-04, 1.0320e-02, 8.5763e-05,
        8.5129e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,461][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0009, 0.0024, 0.0501, 0.0755, 0.0051, 0.0592, 0.0030, 0.0030, 0.0031,
        0.0031, 0.1900, 0.0028, 0.0047, 0.5972], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,462][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ said] are: tensor([2.0984e-04, 5.5132e-04, 3.9128e-01, 1.3067e-01, 1.5294e-03, 1.6097e-02,
        6.0077e-04, 5.3158e-04, 7.0633e-04, 5.9709e-04, 5.6073e-02, 6.1532e-04,
        9.1306e-04, 3.9962e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,463][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0008, 0.0019, 0.1195, 0.1221, 0.0027, 0.0651, 0.0021, 0.0024, 0.0022,
        0.0019, 0.1321, 0.0017, 0.0025, 0.5430], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,463][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0010, 0.0017, 0.0670, 0.2157, 0.0020, 0.0218, 0.0022, 0.0019, 0.0022,
        0.0020, 0.1702, 0.0018, 0.0021, 0.5082], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,464][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0394, 0.0267, 0.0386, 0.3162, 0.0021, 0.0153, 0.0078, 0.0042, 0.0207,
        0.0319, 0.1904, 0.0506, 0.0138, 0.2423], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,464][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0206, 0.0145, 0.0608, 0.1144, 0.0643, 0.0590, 0.0138, 0.0105, 0.0140,
        0.0292, 0.3236, 0.0301, 0.0351, 0.2102], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,464][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0013, 0.0223, 0.0748, 0.1433, 0.1007, 0.0819, 0.1356, 0.1075, 0.0127,
        0.0114, 0.1381, 0.0037, 0.0596, 0.1071], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,465][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0135, 0.0128, 0.2864, 0.1577, 0.0200, 0.1173, 0.0134, 0.0127, 0.0129,
        0.0137, 0.0793, 0.0125, 0.0142, 0.2337], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,465][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0019, 0.0034, 0.3423, 0.1304, 0.0050, 0.0700, 0.0042, 0.0046, 0.0033,
        0.0033, 0.0427, 0.0029, 0.0037, 0.3821], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,466][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.1455, 0.0324, 0.0084, 0.0004, 0.3046, 0.0079, 0.0323, 0.0565, 0.0549,
        0.0616, 0.0177, 0.0873, 0.1361, 0.0544], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,466][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ said] are: tensor([1.1798e-04, 8.6914e-03, 2.7349e-04, 1.7075e-01, 5.6861e-03, 1.2549e-02,
        2.6028e-02, 3.9293e-01, 6.0404e-04, 3.3463e-01, 4.1506e-02, 7.7115e-04,
        3.3590e-03, 2.1016e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,467][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0882, 0.0348, 0.0290, 0.0285, 0.0656, 0.0855, 0.0510, 0.0801, 0.0600,
        0.0489, 0.2126, 0.0512, 0.0654, 0.0993], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,468][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([8.3433e-05, 3.3754e-04, 4.6064e-02, 3.6623e-02, 7.2349e-04, 2.3693e-02,
        4.4771e-04, 4.4929e-04, 4.6315e-04, 4.6897e-04, 6.6558e-02, 3.8988e-04,
        7.0765e-04, 5.9098e-01, 2.3201e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,468][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([5.1123e-06, 4.0045e-05, 3.6313e-01, 6.0775e-02, 1.0974e-04, 4.3752e-03,
        3.9130e-05, 3.6262e-05, 4.5776e-05, 4.0773e-05, 1.5686e-02, 3.4993e-05,
        6.1537e-05, 4.3013e-01, 1.2549e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,469][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([1.6328e-04, 5.8497e-04, 1.6863e-01, 5.9441e-02, 6.3751e-04, 2.9359e-02,
        4.8940e-04, 5.7772e-04, 6.0557e-04, 5.3644e-04, 3.4195e-02, 5.0440e-04,
        6.5758e-04, 4.7078e-01, 2.3283e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,470][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.6177e-04, 3.7006e-04, 5.6041e-02, 1.2434e-01, 4.9788e-04, 1.4003e-02,
        4.9693e-04, 5.0583e-04, 4.5205e-04, 4.1289e-04, 9.3980e-02, 3.5498e-04,
        4.7464e-04, 4.0792e-01, 2.9999e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,472][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0243, 0.0200, 0.0294, 0.3069, 0.0015, 0.0111, 0.0055, 0.0030, 0.0138,
        0.0216, 0.1360, 0.0333, 0.0091, 0.1238, 0.2608], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,473][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0369, 0.0173, 0.0227, 0.0344, 0.0649, 0.0198, 0.0114, 0.0095, 0.0179,
        0.0419, 0.1484, 0.0482, 0.0452, 0.1172, 0.3642], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,474][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0015, 0.0225, 0.0710, 0.1186, 0.0986, 0.0704, 0.1258, 0.1003, 0.0132,
        0.0114, 0.1102, 0.0039, 0.0565, 0.0873, 0.1089], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,475][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0035, 0.0053, 0.2417, 0.1431, 0.0111, 0.0709, 0.0056, 0.0057, 0.0054,
        0.0056, 0.0671, 0.0047, 0.0063, 0.2292, 0.1949], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,477][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0005, 0.0015, 0.3055, 0.0935, 0.0025, 0.0645, 0.0019, 0.0021, 0.0014,
        0.0014, 0.0340, 0.0012, 0.0016, 0.3071, 0.1811], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,478][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1006, 0.0336, 0.0167, 0.0006, 0.2424, 0.0078, 0.0302, 0.0471, 0.0578,
        0.0592, 0.0258, 0.0823, 0.1272, 0.1000, 0.0687], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,479][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([3.0886e-05, 9.7101e-03, 4.6742e-04, 1.6503e-01, 7.4851e-03, 1.5204e-02,
        1.2377e-02, 1.5399e-01, 1.4855e-03, 4.1398e-01, 3.7297e-02, 8.6238e-04,
        8.8669e-03, 7.0523e-03, 1.6616e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,480][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.8084e-04, 6.1814e-04, 2.3808e-01, 5.5821e-02, 9.7205e-04, 1.8578e-02,
        6.3256e-04, 8.5208e-04, 6.8548e-04, 6.1338e-04, 6.7514e-02, 5.4780e-04,
        7.1964e-04, 4.5982e-01, 1.5426e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,526][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:27,527][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,527][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,527][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,528][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,528][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,528][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,529][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,529][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,530][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,531][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,532][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,533][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,534][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1950, 0.8050], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,536][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0858, 0.9142], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,537][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2139, 0.7861], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,538][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3394, 0.6606], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,548][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.4280, 0.5720], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,550][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4805, 0.5195], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,551][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1609, 0.8391], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,553][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3934, 0.6066], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,554][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.2543, 0.7457], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,555][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.3782, 0.6218], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,557][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.3602, 0.6398], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,558][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1300, 0.8700], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,558][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Jennifer] are: tensor([0.0039, 0.0145, 0.9816], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,558][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Jennifer] are: tensor([9.0485e-05, 3.3772e-04, 9.9957e-01], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,559][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Jennifer] are: tensor([0.0029, 0.0066, 0.9905], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,559][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Jennifer] are: tensor([0.0061, 0.0164, 0.9775], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,559][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Jennifer] are: tensor([0.1137, 0.1190, 0.7673], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,560][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Jennifer] are: tensor([0.0471, 0.0363, 0.9166], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,560][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Jennifer] are: tensor([0.0096, 0.0280, 0.9624], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,560][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Jennifer] are: tensor([0.0621, 0.0558, 0.8821], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,561][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Jennifer] are: tensor([0.0218, 0.0315, 0.9467], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,562][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Jennifer] are: tensor([0.5014, 0.2017, 0.2970], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,563][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Jennifer] are: tensor([0.0117, 0.0078, 0.9805], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,564][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Jennifer] are: tensor([0.2123, 0.1276, 0.6602], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,565][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0007, 0.0024, 0.3396, 0.6573], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,566][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([1.2859e-05, 7.5115e-05, 7.2823e-01, 2.7169e-01], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,567][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([3.1385e-04, 9.9420e-04, 2.2769e-01, 7.7100e-01], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,568][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([7.5128e-04, 1.3198e-03, 9.4611e-02, 9.0332e-01], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,569][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0058, 0.0063, 0.0147, 0.9732], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,571][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1277, 0.0549, 0.4833, 0.3341], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,572][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([7.1229e-04, 2.6083e-03, 8.7905e-02, 9.0877e-01], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,573][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0097, 0.0141, 0.6347, 0.3415], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,574][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0018, 0.0050, 0.6199, 0.3734], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,576][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1407, 0.0778, 0.6008, 0.1807], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,577][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0076, 0.0044, 0.9843, 0.0037], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,578][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([6.8486e-05, 2.6231e-04, 7.9172e-01, 2.0795e-01], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,580][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Megan] are: tensor([0.0006, 0.0028, 0.5487, 0.4458, 0.0021], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,581][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Megan] are: tensor([2.7584e-06, 4.3621e-05, 6.8543e-01, 3.1448e-01, 4.3580e-05],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,581][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Megan] are: tensor([1.9113e-04, 9.3737e-04, 5.4966e-01, 4.4834e-01, 8.7252e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,583][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Megan] are: tensor([0.0027, 0.0068, 0.3502, 0.6361, 0.0041], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,584][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Megan] are: tensor([0.0338, 0.0511, 0.1287, 0.7578, 0.0287], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,586][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Megan] are: tensor([0.0406, 0.0442, 0.3905, 0.4421, 0.0827], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,587][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Megan] are: tensor([2.4075e-04, 1.7709e-03, 2.6633e-01, 7.3079e-01, 8.6699e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,588][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Megan] are: tensor([0.0294, 0.0456, 0.6179, 0.2529, 0.0542], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,589][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Megan] are: tensor([0.0011, 0.0037, 0.4625, 0.5280, 0.0047], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,590][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Megan] are: tensor([0.0344, 0.0588, 0.5441, 0.2592, 0.1035], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,590][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Megan] are: tensor([0.0027, 0.0036, 0.9858, 0.0048, 0.0030], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,590][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Megan] are: tensor([3.3595e-06, 3.7777e-05, 8.3707e-01, 1.6286e-01, 2.1635e-05],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,591][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([1.8468e-04, 8.6083e-04, 2.5062e-01, 5.7938e-01, 1.6247e-03, 1.6733e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,591][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([4.2349e-06, 3.2582e-05, 7.1060e-01, 2.7982e-01, 6.1248e-05, 9.4846e-03],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,591][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([4.9200e-05, 2.4918e-04, 3.3216e-01, 5.6519e-01, 3.4676e-04, 1.0201e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,592][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([1.9534e-04, 4.5543e-04, 1.2120e-01, 8.4316e-01, 5.2407e-04, 3.4465e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,592][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0025, 0.0032, 0.0340, 0.9378, 0.0021, 0.0205], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,592][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0168, 0.0112, 0.1730, 0.6229, 0.0562, 0.1200], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,593][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([1.8274e-04, 1.0520e-03, 1.2579e-01, 8.4276e-01, 6.8429e-04, 2.9532e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,595][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0018, 0.0028, 0.7467, 0.1574, 0.0049, 0.0864], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,596][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0008, 0.0022, 0.4636, 0.4254, 0.0029, 0.1051], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,597][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0131, 0.0130, 0.5066, 0.2898, 0.0780, 0.0994], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,598][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([1.6570e-03, 1.1944e-03, 9.9389e-01, 1.0082e-03, 1.3993e-03, 8.4724e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,599][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([8.7913e-07, 6.5938e-06, 9.2593e-01, 7.2763e-02, 6.0793e-06, 1.2903e-03],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,600][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0007, 0.0030, 0.4657, 0.4451, 0.0030, 0.0795, 0.0030],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,601][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([9.7960e-06, 1.2868e-04, 6.5828e-01, 3.3195e-01, 1.4062e-04, 9.3800e-03,
        1.0706e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,602][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([4.8350e-04, 2.1920e-03, 5.8227e-01, 3.6009e-01, 1.7920e-03, 5.1475e-02,
        1.7017e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,604][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0051, 0.0111, 0.3414, 0.5229, 0.0088, 0.0995, 0.0113],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,605][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0297, 0.0424, 0.1336, 0.6049, 0.0312, 0.1194, 0.0389],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,606][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0115, 0.0132, 0.2691, 0.5035, 0.0282, 0.1597, 0.0148],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,607][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([4.3550e-04, 2.7901e-03, 2.9469e-01, 6.5700e-01, 1.8148e-03, 4.0849e-02,
        2.4181e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,609][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0231, 0.0370, 0.5292, 0.1612, 0.0545, 0.1536, 0.0415],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,610][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0020, 0.0066, 0.3399, 0.5525, 0.0074, 0.0849, 0.0067],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,611][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0072, 0.0137, 0.4426, 0.3796, 0.0260, 0.1179, 0.0130],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,613][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0039, 0.0061, 0.9704, 0.0060, 0.0054, 0.0039, 0.0042],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,614][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([4.9373e-06, 5.5198e-05, 8.1707e-01, 1.7928e-01, 3.4872e-05, 3.5262e-03,
        3.0476e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,615][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([3.9855e-04, 1.9984e-03, 4.4959e-01, 4.7073e-01, 1.9244e-03, 7.1417e-02,
        1.9823e-03, 1.9609e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,615][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([7.0844e-06, 9.6638e-05, 6.5704e-01, 3.3348e-01, 1.0623e-04, 9.1188e-03,
        8.3118e-05, 7.2410e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,616][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([3.3268e-04, 1.5741e-03, 5.5409e-01, 3.8537e-01, 1.3121e-03, 5.4859e-02,
        1.2552e-03, 1.2028e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,618][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0033, 0.0075, 0.3271, 0.5459, 0.0061, 0.0945, 0.0080, 0.0076],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,619][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0233, 0.0346, 0.1454, 0.5810, 0.0258, 0.1259, 0.0336, 0.0304],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,621][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0067, 0.0086, 0.2043, 0.5724, 0.0197, 0.1675, 0.0101, 0.0107],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,621][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([2.9293e-04, 2.0370e-03, 2.9697e-01, 6.5844e-01, 1.2586e-03, 3.7719e-02,
        1.7565e-03, 1.5238e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,622][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0148, 0.0246, 0.5221, 0.1826, 0.0384, 0.1593, 0.0291, 0.0292],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,622][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0015, 0.0049, 0.3264, 0.5668, 0.0056, 0.0848, 0.0051, 0.0050],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,622][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0047, 0.0096, 0.3297, 0.5036, 0.0184, 0.1146, 0.0094, 0.0100],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,623][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0026, 0.0046, 0.9690, 0.0073, 0.0041, 0.0042, 0.0034, 0.0048],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,623][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([1.8301e-06, 2.4717e-05, 8.3346e-01, 1.6372e-01, 1.4600e-05, 2.7584e-03,
        1.2892e-05, 1.1267e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,623][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0011, 0.0044, 0.4756, 0.4134, 0.0044, 0.0884, 0.0043, 0.0044, 0.0041],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,624][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([2.2139e-05, 2.5871e-04, 6.2811e-01, 3.5726e-01, 2.8623e-04, 1.3397e-02,
        2.2593e-04, 1.9922e-04, 2.4595e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,624][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0010, 0.0039, 0.5762, 0.3438, 0.0032, 0.0628, 0.0030, 0.0029, 0.0032],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,626][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0090, 0.0180, 0.3792, 0.4151, 0.0148, 0.1115, 0.0179, 0.0176, 0.0169],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,627][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0420, 0.0552, 0.1691, 0.3874, 0.0452, 0.1432, 0.0533, 0.0498, 0.0548],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,628][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0164, 0.0181, 0.2750, 0.3923, 0.0408, 0.1891, 0.0221, 0.0244, 0.0218],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,630][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0008, 0.0042, 0.3590, 0.5709, 0.0030, 0.0514, 0.0037, 0.0034, 0.0037],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,631][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0331, 0.0499, 0.3859, 0.1316, 0.0706, 0.1586, 0.0570, 0.0594, 0.0539],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,632][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0039, 0.0111, 0.3382, 0.5005, 0.0117, 0.1023, 0.0112, 0.0110, 0.0101],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,634][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0114, 0.0199, 0.4143, 0.3178, 0.0381, 0.1324, 0.0203, 0.0230, 0.0229],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,635][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0052, 0.0091, 0.9355, 0.0096, 0.0084, 0.0072, 0.0068, 0.0095, 0.0087],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,636][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([2.8419e-05, 2.3199e-04, 7.6499e-01, 2.2556e-01, 1.6261e-04, 8.6105e-03,
        1.4109e-04, 1.2644e-04, 1.4747e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,638][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0014, 0.0055, 0.4707, 0.3987, 0.0057, 0.0966, 0.0054, 0.0056, 0.0051,
        0.0054], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,639][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([2.6064e-05, 2.9426e-04, 6.3055e-01, 3.5193e-01, 3.5896e-04, 1.5764e-02,
        2.6989e-04, 2.4235e-04, 2.8741e-04, 2.7948e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,640][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0012, 0.0046, 0.5876, 0.3244, 0.0039, 0.0635, 0.0036, 0.0035, 0.0038,
        0.0039], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,642][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0104, 0.0201, 0.3668, 0.3893, 0.0173, 0.1179, 0.0202, 0.0203, 0.0192,
        0.0186], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,643][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0422, 0.0542, 0.1581, 0.3515, 0.0465, 0.1369, 0.0531, 0.0490, 0.0539,
        0.0546], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,644][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0245, 0.0260, 0.2767, 0.3356, 0.0515, 0.1646, 0.0298, 0.0310, 0.0306,
        0.0297], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,646][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0009, 0.0050, 0.3481, 0.5663, 0.0037, 0.0581, 0.0045, 0.0041, 0.0044,
        0.0049], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,647][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0361, 0.0532, 0.3456, 0.1104, 0.0752, 0.1436, 0.0608, 0.0633, 0.0576,
        0.0542], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,649][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0040, 0.0118, 0.3021, 0.5198, 0.0125, 0.1042, 0.0120, 0.0118, 0.0107,
        0.0111], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,650][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0183, 0.0307, 0.3914, 0.2709, 0.0497, 0.1125, 0.0292, 0.0303, 0.0344,
        0.0326], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,652][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0059, 0.0101, 0.9174, 0.0101, 0.0099, 0.0083, 0.0078, 0.0109, 0.0099,
        0.0096], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,653][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([4.0590e-05, 3.0885e-04, 7.4355e-01, 2.4447e-01, 2.2812e-04, 1.0611e-02,
        1.9648e-04, 1.7811e-04, 1.9904e-04, 2.2090e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,653][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([2.5792e-04, 1.1125e-03, 3.4892e-01, 2.6619e-01, 2.0953e-03, 1.0067e-01,
        1.3438e-03, 1.3067e-03, 1.4455e-03, 1.4685e-03, 2.7519e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,653][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([8.6557e-06, 6.7023e-05, 8.3162e-01, 1.3239e-01, 1.5042e-04, 6.0312e-03,
        5.7938e-05, 5.2607e-05, 7.4627e-05, 6.7673e-05, 2.9479e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,654][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([2.0433e-04, 8.1078e-04, 3.7126e-01, 3.4761e-01, 1.0242e-03, 8.2906e-02,
        7.3913e-04, 7.6451e-04, 8.2727e-04, 7.8528e-04, 1.9307e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,654][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0010, 0.0019, 0.1367, 0.4943, 0.0022, 0.0365, 0.0024, 0.0023, 0.0023,
        0.0022, 0.3182], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,655][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0151, 0.0146, 0.0164, 0.4301, 0.0067, 0.0139, 0.0129, 0.0092, 0.0150,
        0.0167, 0.4493], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,655][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1016, 0.0414, 0.1475, 0.0171, 0.2137, 0.0319, 0.0365, 0.0404, 0.0652,
        0.0703, 0.2344], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,656][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([2.8200e-04, 1.5143e-03, 7.0060e-02, 4.4576e-01, 9.7173e-04, 2.1181e-02,
        1.3906e-03, 1.1372e-03, 1.4899e-03, 1.8692e-03, 4.5434e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,656][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0053, 0.0089, 0.4568, 0.2327, 0.0197, 0.1319, 0.0095, 0.0093, 0.0087,
        0.0090, 0.1081], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,657][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0006, 0.0021, 0.6073, 0.2239, 0.0036, 0.0832, 0.0024, 0.0025, 0.0020,
        0.0020, 0.0704], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,659][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0918, 0.0514, 0.1429, 0.0036, 0.2990, 0.0109, 0.0386, 0.0497, 0.0812,
        0.0864, 0.1445], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,660][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0028, 0.0021, 0.9794, 0.0013, 0.0030, 0.0012, 0.0014, 0.0023, 0.0024,
        0.0022, 0.0020], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,661][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([1.0959e-05, 6.2656e-05, 8.5326e-01, 1.1295e-01, 6.2976e-05, 3.6874e-03,
        4.2771e-05, 4.8484e-05, 4.8531e-05, 4.8816e-05, 2.9776e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,662][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0011, 0.0045, 0.4499, 0.3555, 0.0047, 0.0858, 0.0045, 0.0047, 0.0042,
        0.0044, 0.0770, 0.0036], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,663][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([1.8105e-05, 2.2299e-04, 5.7925e-01, 3.7309e-01, 2.9195e-04, 1.5839e-02,
        2.1575e-04, 1.9520e-04, 2.2291e-04, 2.1486e-04, 3.0281e-02, 1.5698e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,664][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0010, 0.0038, 0.5302, 0.3093, 0.0032, 0.0541, 0.0030, 0.0029, 0.0031,
        0.0032, 0.0835, 0.0027], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,666][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0085, 0.0171, 0.3393, 0.3351, 0.0145, 0.1049, 0.0168, 0.0170, 0.0161,
        0.0156, 0.1008, 0.0144], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,667][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0329, 0.0421, 0.1319, 0.2727, 0.0384, 0.1175, 0.0419, 0.0395, 0.0421,
        0.0423, 0.1577, 0.0409], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,669][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0161, 0.0176, 0.2049, 0.2126, 0.0372, 0.1226, 0.0210, 0.0227, 0.0214,
        0.0205, 0.2819, 0.0217], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,670][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0006, 0.0037, 0.3164, 0.4938, 0.0028, 0.0487, 0.0033, 0.0030, 0.0032,
        0.0036, 0.1182, 0.0028], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,672][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0329, 0.0489, 0.3055, 0.0914, 0.0677, 0.1268, 0.0557, 0.0590, 0.0529,
        0.0494, 0.0669, 0.0429], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,673][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0029, 0.0090, 0.2552, 0.4620, 0.0094, 0.0847, 0.0092, 0.0089, 0.0082,
        0.0085, 0.1351, 0.0069], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,675][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0143, 0.0245, 0.3288, 0.1945, 0.0432, 0.0963, 0.0245, 0.0268, 0.0286,
        0.0268, 0.1648, 0.0270], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,676][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0045, 0.0084, 0.9178, 0.0095, 0.0085, 0.0081, 0.0067, 0.0094, 0.0081,
        0.0079, 0.0034, 0.0078], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,677][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([5.2367e-05, 3.8150e-04, 7.0962e-01, 2.5685e-01, 2.9148e-04, 1.2209e-02,
        2.5101e-04, 2.2750e-04, 2.4838e-04, 2.7408e-04, 1.9374e-02, 2.2146e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,679][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Megan] are: tensor([0.0009, 0.0042, 0.4782, 0.3583, 0.0036, 0.0718, 0.0039, 0.0040, 0.0037,
        0.0040, 0.0603, 0.0032, 0.0038], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,680][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Megan] are: tensor([1.6099e-05, 2.0748e-04, 6.6479e-01, 3.0295e-01, 2.0283e-04, 1.0878e-02,
        1.6822e-04, 1.4948e-04, 1.9003e-04, 1.8439e-04, 1.9934e-02, 1.3942e-04,
        1.9000e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,681][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Megan] are: tensor([0.0007, 0.0029, 0.5556, 0.2983, 0.0023, 0.0529, 0.0022, 0.0022, 0.0024,
        0.0024, 0.0735, 0.0020, 0.0025], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,683][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Megan] are: tensor([0.0068, 0.0146, 0.3309, 0.3731, 0.0104, 0.0899, 0.0138, 0.0135, 0.0130,
        0.0129, 0.0979, 0.0118, 0.0114], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,684][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Megan] are: tensor([0.0321, 0.0445, 0.1073, 0.2918, 0.0321, 0.0935, 0.0414, 0.0383, 0.0424,
        0.0429, 0.1530, 0.0414, 0.0392], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,685][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Megan] are: tensor([0.0204, 0.0219, 0.1878, 0.1907, 0.0436, 0.1314, 0.0251, 0.0276, 0.0259,
        0.0255, 0.2389, 0.0269, 0.0344], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,687][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Megan] are: tensor([0.0006, 0.0035, 0.3275, 0.5059, 0.0022, 0.0408, 0.0029, 0.0026, 0.0029,
        0.0033, 0.1024, 0.0026, 0.0029], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,688][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Megan] are: tensor([0.0276, 0.0428, 0.3099, 0.1117, 0.0542, 0.1257, 0.0474, 0.0493, 0.0452,
        0.0422, 0.0652, 0.0366, 0.0423], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,689][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Megan] are: tensor([0.0025, 0.0075, 0.3183, 0.4333, 0.0085, 0.0827, 0.0075, 0.0074, 0.0068,
        0.0069, 0.1054, 0.0058, 0.0073], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,690][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Megan] are: tensor([0.0185, 0.0301, 0.3068, 0.1462, 0.0529, 0.0994, 0.0291, 0.0329, 0.0340,
        0.0325, 0.1424, 0.0328, 0.0424], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,690][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Megan] are: tensor([0.0050, 0.0083, 0.9200, 0.0076, 0.0070, 0.0056, 0.0060, 0.0086, 0.0078,
        0.0075, 0.0025, 0.0077, 0.0063], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,691][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Megan] are: tensor([1.7221e-05, 1.6151e-04, 7.9492e-01, 1.8708e-01, 9.9573e-05, 6.8488e-03,
        9.0608e-05, 8.4098e-05, 9.6774e-05, 1.0745e-04, 1.0320e-02, 8.5763e-05,
        8.5129e-05], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,691][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0009, 0.0024, 0.0501, 0.0755, 0.0051, 0.0592, 0.0030, 0.0030, 0.0031,
        0.0031, 0.1900, 0.0028, 0.0047, 0.5972], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,691][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([2.0984e-04, 5.5132e-04, 3.9128e-01, 1.3067e-01, 1.5294e-03, 1.6097e-02,
        6.0077e-04, 5.3158e-04, 7.0633e-04, 5.9709e-04, 5.6073e-02, 6.1532e-04,
        9.1306e-04, 3.9962e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,692][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0008, 0.0019, 0.1195, 0.1221, 0.0027, 0.0651, 0.0021, 0.0024, 0.0022,
        0.0019, 0.1321, 0.0017, 0.0025, 0.5430], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,694][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0010, 0.0017, 0.0670, 0.2157, 0.0020, 0.0218, 0.0022, 0.0019, 0.0022,
        0.0020, 0.1702, 0.0018, 0.0021, 0.5082], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,695][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0087, 0.0072, 0.0233, 0.1815, 0.0062, 0.0184, 0.0074, 0.0060, 0.0085,
        0.0089, 0.2956, 0.0095, 0.0094, 0.4094], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,696][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0622, 0.0276, 0.0420, 0.0129, 0.1887, 0.0590, 0.0339, 0.0385, 0.0408,
        0.0454, 0.1247, 0.0552, 0.1000, 0.1692], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,698][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0022, 0.0043, 0.0291, 0.1283, 0.0042, 0.0345, 0.0050, 0.0046, 0.0051,
        0.0056, 0.2845, 0.0051, 0.0066, 0.4809], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,699][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0135, 0.0128, 0.2864, 0.1577, 0.0200, 0.1173, 0.0134, 0.0127, 0.0129,
        0.0137, 0.0793, 0.0125, 0.0142, 0.2337], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,700][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0019, 0.0034, 0.3423, 0.1304, 0.0050, 0.0700, 0.0042, 0.0046, 0.0033,
        0.0033, 0.0427, 0.0029, 0.0037, 0.3821], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,702][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.1455, 0.0324, 0.0084, 0.0004, 0.3046, 0.0079, 0.0323, 0.0565, 0.0549,
        0.0616, 0.0177, 0.0873, 0.1361, 0.0544], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,704][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0222, 0.0111, 0.6223, 0.0023, 0.0160, 0.0044, 0.0089, 0.0135, 0.0143,
        0.0128, 0.0053, 0.0166, 0.0127, 0.2375], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,705][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0882, 0.0348, 0.0290, 0.0285, 0.0656, 0.0855, 0.0510, 0.0801, 0.0600,
        0.0489, 0.2126, 0.0512, 0.0654, 0.0993], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,706][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([8.3433e-05, 3.3754e-04, 4.6064e-02, 3.6623e-02, 7.2349e-04, 2.3693e-02,
        4.4771e-04, 4.4929e-04, 4.6315e-04, 4.6897e-04, 6.6558e-02, 3.8988e-04,
        7.0765e-04, 5.9098e-01, 2.3201e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,707][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([5.1123e-06, 4.0045e-05, 3.6313e-01, 6.0775e-02, 1.0974e-04, 4.3752e-03,
        3.9130e-05, 3.6262e-05, 4.5776e-05, 4.0773e-05, 1.5686e-02, 3.4993e-05,
        6.1537e-05, 4.3013e-01, 1.2549e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,708][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.6328e-04, 5.8497e-04, 1.6863e-01, 5.9441e-02, 6.3751e-04, 2.9359e-02,
        4.8940e-04, 5.7772e-04, 6.0557e-04, 5.3644e-04, 3.4195e-02, 5.0440e-04,
        6.5758e-04, 4.7078e-01, 2.3283e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,709][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.6177e-04, 3.7006e-04, 5.6041e-02, 1.2434e-01, 4.9788e-04, 1.4003e-02,
        4.9693e-04, 5.0583e-04, 4.5205e-04, 4.1289e-04, 9.3980e-02, 3.5498e-04,
        4.7464e-04, 4.0792e-01, 2.9999e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,710][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0035, 0.0039, 0.0152, 0.2140, 0.0035, 0.0120, 0.0039, 0.0033, 0.0041,
        0.0044, 0.2336, 0.0044, 0.0046, 0.1809, 0.3086], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,712][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0662, 0.0258, 0.0410, 0.0063, 0.1538, 0.0315, 0.0276, 0.0350, 0.0418,
        0.0445, 0.0662, 0.0567, 0.0944, 0.1792, 0.1300], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,713][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([4.5796e-05, 2.3736e-04, 1.4334e-02, 6.0432e-02, 2.2756e-04, 6.8601e-03,
        2.5689e-04, 2.2239e-04, 2.4295e-04, 2.8994e-04, 8.4000e-02, 2.2024e-04,
        3.2573e-04, 3.0925e-01, 5.2305e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,714][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0035, 0.0053, 0.2417, 0.1431, 0.0111, 0.0709, 0.0056, 0.0057, 0.0054,
        0.0056, 0.0671, 0.0047, 0.0063, 0.2292, 0.1949], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,716][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0005, 0.0015, 0.3055, 0.0935, 0.0025, 0.0645, 0.0019, 0.0021, 0.0014,
        0.0014, 0.0340, 0.0012, 0.0016, 0.3071, 0.1811], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,717][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1006, 0.0336, 0.0167, 0.0006, 0.2424, 0.0078, 0.0302, 0.0471, 0.0578,
        0.0592, 0.0258, 0.0823, 0.1272, 0.1000, 0.0687], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,719][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0043, 0.0030, 0.6337, 0.0009, 0.0046, 0.0016, 0.0021, 0.0037, 0.0036,
        0.0032, 0.0026, 0.0041, 0.0034, 0.3258, 0.0033], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,720][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.8084e-04, 6.1814e-04, 2.3808e-01, 5.5821e-02, 9.7205e-04, 1.8578e-02,
        6.3256e-04, 8.5208e-04, 6.8548e-04, 6.1338e-04, 6.7514e-02, 5.4780e-04,
        7.1964e-04, 4.5982e-01, 1.5426e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,721][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:27,722][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[2781],
        [ 250],
        [  95],
        [  12],
        [  50],
        [   2],
        [  35],
        [  24],
        [  50],
        [  82],
        [  23],
        [  38],
        [ 120],
        [   3],
        [   6]], device='cuda:0')
[2024-07-24 10:29:27,723][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[1515],
        [ 248],
        [  16],
        [   3],
        [  21],
        [   1],
        [  19],
        [   9],
        [  28],
        [  42],
        [  13],
        [  14],
        [  56],
        [   3],
        [   6]], device='cuda:0')
[2024-07-24 10:29:27,724][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[41856],
        [43828],
        [50256],
        [49658],
        [50197],
        [49364],
        [50156],
        [50128],
        [50177],
        [50180],
        [50025],
        [50165],
        [50184],
        [48556],
        [47681]], device='cuda:0')
[2024-07-24 10:29:27,725][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[31556],
        [29262],
        [37976],
        [37992],
        [37881],
        [37922],
        [37763],
        [37759],
        [37674],
        [37664],
        [37801],
        [37323],
        [37647],
        [30329],
        [28194]], device='cuda:0')
[2024-07-24 10:29:27,727][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 4969],
        [10396],
        [50213],
        [37989],
        [49198],
        [44236],
        [49474],
        [49255],
        [49474],
        [49561],
        [45406],
        [49105],
        [49321],
        [18937],
        [23046]], device='cuda:0')
[2024-07-24 10:29:27,728][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[30277],
        [40269],
        [48879],
        [49064],
        [49406],
        [49181],
        [49458],
        [49450],
        [49467],
        [49477],
        [49071],
        [49418],
        [49427],
        [48506],
        [47833]], device='cuda:0')
[2024-07-24 10:29:27,730][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[20440],
        [14152],
        [37203],
        [18743],
        [19658],
        [19171],
        [19871],
        [19719],
        [19936],
        [19203],
        [18373],
        [19524],
        [17541],
        [23506],
        [20213]], device='cuda:0')
[2024-07-24 10:29:27,731][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[8479],
        [9198],
        [8650],
        [8847],
        [8467],
        [8802],
        [8578],
        [8735],
        [8457],
        [8266],
        [8204],
        [8374],
        [8069],
        [9163],
        [9423]], device='cuda:0')
[2024-07-24 10:29:27,732][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[18018],
        [ 7178],
        [26109],
        [13713],
        [13350],
        [13522],
        [ 9127],
        [10842],
        [11882],
        [12285],
        [12067],
        [12145],
        [11723],
        [11912],
        [12288]], device='cuda:0')
[2024-07-24 10:29:27,734][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[43415],
        [43720],
        [    1],
        [   22],
        [   11],
        [    3],
        [   20],
        [   29],
        [   55],
        [   63],
        [  102],
        [  100],
        [  118],
        [  634],
        [ 1246]], device='cuda:0')
[2024-07-24 10:29:27,735][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[28370],
        [27541],
        [33638],
        [33548],
        [33243],
        [33420],
        [33029],
        [32947],
        [33089],
        [32971],
        [33632],
        [32515],
        [32837],
        [36000],
        [35758]], device='cuda:0')
[2024-07-24 10:29:27,737][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[34316],
        [35926],
        [47912],
        [47759],
        [47378],
        [47052],
        [46796],
        [46267],
        [46853],
        [46968],
        [45682],
        [47113],
        [47104],
        [41062],
        [45569]], device='cuda:0')
[2024-07-24 10:29:27,738][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[14121],
        [ 1761],
        [ 1478],
        [ 1112],
        [ 1089],
        [ 1031],
        [  978],
        [  909],
        [  851],
        [ 1133],
        [ 1226],
        [ 1325],
        [ 1258],
        [ 1096],
        [ 1371]], device='cuda:0')
[2024-07-24 10:29:27,740][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[35152],
        [33167],
        [41980],
        [39204],
        [39658],
        [40414],
        [39476],
        [39627],
        [38931],
        [38677],
        [39875],
        [38289],
        [39291],
        [30262],
        [32561]], device='cuda:0')
[2024-07-24 10:29:27,741][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[30274],
        [30817],
        [38737],
        [29713],
        [35817],
        [30337],
        [32419],
        [32063],
        [32317],
        [31154],
        [28701],
        [28705],
        [31376],
        [17920],
        [17336]], device='cuda:0')
[2024-07-24 10:29:27,743][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 9637],
        [13036],
        [30145],
        [21955],
        [25853],
        [18832],
        [24074],
        [23843],
        [24288],
        [24213],
        [22146],
        [23889],
        [24471],
        [18910],
        [19110]], device='cuda:0')
[2024-07-24 10:29:27,744][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[37034],
        [21846],
        [19932],
        [19472],
        [19290],
        [19486],
        [19266],
        [19253],
        [19137],
        [19185],
        [19806],
        [18932],
        [19324],
        [19868],
        [19583]], device='cuda:0')
[2024-07-24 10:29:27,745][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[33220],
        [29341],
        [ 7177],
        [ 5889],
        [ 5056],
        [ 5660],
        [ 5243],
        [ 5225],
        [ 5310],
        [ 5347],
        [ 6030],
        [ 5484],
        [ 5483],
        [12233],
        [11453]], device='cuda:0')
[2024-07-24 10:29:27,747][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[16780],
        [17385],
        [ 5213],
        [ 4893],
        [ 4092],
        [ 4786],
        [ 4067],
        [ 4096],
        [ 4009],
        [ 4016],
        [ 5228],
        [ 4211],
        [ 4190],
        [ 6321],
        [ 8404]], device='cuda:0')
[2024-07-24 10:29:27,748][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[6659],
        [5815],
        [8863],
        [9060],
        [7735],
        [8715],
        [6435],
        [6227],
        [5024],
        [4818],
        [7308],
        [4550],
        [4944],
        [5654],
        [7565]], device='cuda:0')
[2024-07-24 10:29:27,750][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[15814],
        [ 8700],
        [ 9399],
        [12415],
        [13420],
        [15630],
        [14886],
        [15507],
        [14353],
        [14011],
        [13692],
        [16091],
        [15695],
        [15574],
        [16118]], device='cuda:0')
[2024-07-24 10:29:27,751][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[23601],
        [21036],
        [13188],
        [ 8642],
        [ 9615],
        [ 8980],
        [ 9840],
        [ 9844],
        [10209],
        [10180],
        [ 9901],
        [10301],
        [10313],
        [11118],
        [11272]], device='cuda:0')
[2024-07-24 10:29:27,753][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[10175],
        [10413],
        [26958],
        [32188],
        [30827],
        [29709],
        [30724],
        [31159],
        [30480],
        [29814],
        [32435],
        [29521],
        [30047],
        [33585],
        [31018]], device='cuda:0')
[2024-07-24 10:29:27,754][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 5957],
        [ 6371],
        [15095],
        [16546],
        [17318],
        [17426],
        [17966],
        [18043],
        [17841],
        [17950],
        [16296],
        [17475],
        [17369],
        [18141],
        [17491]], device='cuda:0')
[2024-07-24 10:29:27,755][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[28116],
        [27858],
        [27662],
        [25979],
        [23375],
        [20049],
        [17157],
        [14107],
        [17140],
        [17449],
        [16608],
        [13190],
        [13785],
        [24709],
        [17040]], device='cuda:0')
[2024-07-24 10:29:27,756][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[21178],
        [27379],
        [20805],
        [20721],
        [20694],
        [20727],
        [20604],
        [20570],
        [20497],
        [20485],
        [20695],
        [20438],
        [20532],
        [17785],
        [16929]], device='cuda:0')
[2024-07-24 10:29:27,757][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 3447],
        [ 3247],
        [ 3347],
        [ 6368],
        [ 6235],
        [ 6034],
        [ 6271],
        [ 6229],
        [ 6392],
        [ 6441],
        [ 6081],
        [ 6447],
        [ 6280],
        [ 8640],
        [14614]], device='cuda:0')
[2024-07-24 10:29:27,758][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[25168],
        [29215],
        [36489],
        [35744],
        [35420],
        [37867],
        [36714],
        [37253],
        [36709],
        [36565],
        [36708],
        [37192],
        [36787],
        [32420],
        [31059]], device='cuda:0')
[2024-07-24 10:29:27,760][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[10332],
        [ 9634],
        [ 5529],
        [ 9327],
        [ 6308],
        [ 8810],
        [ 9170],
        [ 9382],
        [ 8835],
        [ 9588],
        [ 9632],
        [11249],
        [ 9453],
        [11319],
        [13380]], device='cuda:0')
[2024-07-24 10:29:27,761][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[12087],
        [12087],
        [12087],
        [12087],
        [12087],
        [12087],
        [12087],
        [12087],
        [12087],
        [12087],
        [12087],
        [12087],
        [12087],
        [12087],
        [12087]], device='cuda:0')
[2024-07-24 10:29:27,826][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:27,826][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,827][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,827][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,827][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,828][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,828][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,829][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,830][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,830][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,830][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,831][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,831][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:27,831][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.6045, 0.3955], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,832][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.4497, 0.5503], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,832][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4015, 0.5985], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,832][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6141, 0.3859], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,833][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3036, 0.6964], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,833][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.3503, 0.6497], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,833][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4161, 0.5839], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,834][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.4789, 0.5211], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,834][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1707, 0.8293], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,834][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3895, 0.6105], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,835][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4119, 0.5881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,835][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.5204, 0.4796], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:27,835][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Jennifer] are: tensor([0.0944, 0.0870, 0.8186], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,836][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Jennifer] are: tensor([0.1085, 0.1329, 0.7586], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,836][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Jennifer] are: tensor([0.0776, 0.0813, 0.8411], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,836][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Jennifer] are: tensor([0.2913, 0.1804, 0.5283], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,837][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Jennifer] are: tensor([0.0015, 0.0046, 0.9938], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,837][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Jennifer] are: tensor([0.0045, 0.0091, 0.9864], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,837][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Jennifer] are: tensor([0.4847, 0.4544, 0.0609], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,838][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Jennifer] are: tensor([0.0072, 0.0185, 0.9744], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,838][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Jennifer] are: tensor([1.0557e-05, 9.9937e-01, 6.2388e-04], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,838][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Jennifer] are: tensor([0.0204, 0.0271, 0.9524], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,839][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Jennifer] are: tensor([0.1413, 0.1112, 0.7475], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,840][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Jennifer] are: tensor([0.2196, 0.1705, 0.6099], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:27,841][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1042, 0.1170, 0.4649, 0.3139], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,843][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0396, 0.0433, 0.2999, 0.6171], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,844][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0320, 0.0300, 0.3950, 0.5430], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,845][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1257, 0.0703, 0.4326, 0.3714], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,847][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0015, 0.0037, 0.3526, 0.6422], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,848][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0018, 0.0030, 0.4146, 0.5806], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,849][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3468, 0.4164, 0.1104, 0.1264], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,851][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0019, 0.0046, 0.3764, 0.6171], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,852][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([5.9308e-06, 9.9930e-01, 2.6913e-04, 4.2561e-04], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,853][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0050, 0.0080, 0.5588, 0.4282], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,855][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0711, 0.0633, 0.4611, 0.4045], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,856][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1172, 0.1029, 0.4995, 0.2805], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:27,857][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Megan] are: tensor([0.1994, 0.2186, 0.2450, 0.1682, 0.1688], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,859][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Megan] are: tensor([0.1170, 0.1088, 0.2316, 0.5204, 0.0222], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,860][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Megan] are: tensor([0.0955, 0.0720, 0.1249, 0.6941, 0.0134], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,862][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Megan] are: tensor([0.0916, 0.0542, 0.4674, 0.3693, 0.0174], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,863][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Megan] are: tensor([0.0050, 0.0099, 0.3309, 0.6350, 0.0191], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,865][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Megan] are: tensor([0.0012, 0.0024, 0.4272, 0.5626, 0.0066], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,866][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Megan] are: tensor([0.2505, 0.3410, 0.0788, 0.0763, 0.2534], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,866][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Megan] are: tensor([0.0103, 0.0147, 0.3886, 0.5292, 0.0571], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,867][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Megan] are: tensor([5.6818e-04, 9.7188e-01, 6.2731e-03, 1.0605e-02, 1.0677e-02],
       device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,867][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Megan] are: tensor([0.0141, 0.0267, 0.5501, 0.3709, 0.0382], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,867][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Megan] are: tensor([0.0978, 0.1126, 0.3771, 0.3325, 0.0799], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,868][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Megan] are: tensor([0.1660, 0.1171, 0.3127, 0.1562, 0.2480], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:27,868][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0755, 0.0808, 0.2294, 0.1244, 0.0660, 0.4239], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,868][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0152, 0.0173, 0.2347, 0.6066, 0.0045, 0.1216], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,869][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0569, 0.0379, 0.2709, 0.2125, 0.0516, 0.3703], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,869][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0710, 0.0426, 0.4022, 0.2186, 0.0118, 0.2538], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,870][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0008, 0.0016, 0.2074, 0.3386, 0.0060, 0.4457], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,871][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ had] are: tensor([1.8272e-04, 4.2277e-04, 2.7785e-01, 5.1738e-01, 1.4261e-03, 2.0274e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,873][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2048, 0.2555, 0.0659, 0.0993, 0.2925, 0.0821], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,874][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0009, 0.0021, 0.3331, 0.3593, 0.0076, 0.2969], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,875][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ had] are: tensor([4.3424e-05, 9.8652e-01, 1.0067e-03, 1.3624e-03, 2.9134e-03, 8.1563e-03],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,876][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0044, 0.0077, 0.4554, 0.4323, 0.0215, 0.0788], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,877][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0344, 0.0236, 0.1816, 0.1137, 0.0782, 0.5685], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,878][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0834, 0.0711, 0.3427, 0.1619, 0.2049, 0.1360], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:27,880][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2069, 0.1705, 0.1167, 0.0683, 0.1198, 0.1835, 0.1344],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,881][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0408, 0.0473, 0.3048, 0.3897, 0.0219, 0.1626, 0.0329],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,883][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0359, 0.0451, 0.0756, 0.3128, 0.0501, 0.3876, 0.0929],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,884][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1154, 0.0668, 0.2996, 0.2484, 0.0209, 0.2086, 0.0401],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,885][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0068, 0.0139, 0.2022, 0.4959, 0.0148, 0.2458, 0.0206],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,887][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0050, 0.0103, 0.3202, 0.4560, 0.0162, 0.1771, 0.0151],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,888][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1340, 0.1996, 0.1206, 0.0924, 0.1727, 0.0796, 0.2012],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,889][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0222, 0.0305, 0.2165, 0.3007, 0.0795, 0.2926, 0.0580],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,891][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0084, 0.4586, 0.0268, 0.0310, 0.0350, 0.0659, 0.3743],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,892][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0252, 0.0468, 0.4474, 0.2861, 0.0526, 0.1064, 0.0354],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,893][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1217, 0.1623, 0.1716, 0.1688, 0.1055, 0.1420, 0.1282],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,895][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0890, 0.0802, 0.3368, 0.1757, 0.1273, 0.1334, 0.0576],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:27,896][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.1514, 0.1302, 0.1040, 0.0786, 0.0893, 0.1958, 0.1064, 0.1443],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,898][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0379, 0.0458, 0.2809, 0.4225, 0.0144, 0.1526, 0.0248, 0.0211],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,898][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0229, 0.0323, 0.0473, 0.2778, 0.0238, 0.4585, 0.0742, 0.0632],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,899][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0788, 0.0513, 0.2604, 0.2648, 0.0193, 0.2481, 0.0361, 0.0411],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,899][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0043, 0.0099, 0.1679, 0.5224, 0.0112, 0.2531, 0.0162, 0.0149],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,899][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0019, 0.0048, 0.2973, 0.4684, 0.0093, 0.2030, 0.0082, 0.0073],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,900][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.1002, 0.1649, 0.1129, 0.0935, 0.1438, 0.0744, 0.1681, 0.1422],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,900][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0116, 0.0185, 0.1998, 0.3150, 0.0591, 0.3218, 0.0391, 0.0351],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,901][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0051, 0.3381, 0.0222, 0.0293, 0.0271, 0.0592, 0.3085, 0.2106],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,902][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0192, 0.0386, 0.4409, 0.2911, 0.0430, 0.1062, 0.0296, 0.0313],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,903][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0741, 0.1074, 0.1794, 0.1618, 0.0829, 0.1910, 0.1038, 0.0996],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,905][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0785, 0.0733, 0.3152, 0.1878, 0.1160, 0.1268, 0.0547, 0.0476],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:27,906][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.1932, 0.1236, 0.0686, 0.0351, 0.1037, 0.1116, 0.1005, 0.1264, 0.1373],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,907][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0697, 0.0773, 0.2167, 0.1990, 0.0701, 0.1506, 0.0701, 0.0589, 0.0876],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,909][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0501, 0.0655, 0.0524, 0.1911, 0.0370, 0.3315, 0.1149, 0.0842, 0.0733],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,910][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.1775, 0.0952, 0.1272, 0.1226, 0.0393, 0.1514, 0.0705, 0.0812, 0.1352],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,912][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0148, 0.0295, 0.1994, 0.4231, 0.0214, 0.2154, 0.0335, 0.0322, 0.0308],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,913][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0160, 0.0288, 0.2451, 0.3263, 0.0420, 0.2265, 0.0418, 0.0399, 0.0338],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,914][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0969, 0.1432, 0.1053, 0.0653, 0.1197, 0.0639, 0.1343, 0.1167, 0.1548],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,916][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0576, 0.0626, 0.1177, 0.1567, 0.1326, 0.1989, 0.0987, 0.0925, 0.0827],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,917][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0300, 0.1877, 0.0530, 0.0598, 0.0560, 0.0871, 0.1968, 0.1534, 0.1762],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,919][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0414, 0.0715, 0.3324, 0.2011, 0.0663, 0.1112, 0.0550, 0.0551, 0.0662],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,920][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.1599, 0.1789, 0.0707, 0.0658, 0.0838, 0.0557, 0.1092, 0.1116, 0.1644],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,921][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0819, 0.0717, 0.2798, 0.1563, 0.1168, 0.1311, 0.0602, 0.0552, 0.0468],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:27,923][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1666, 0.1075, 0.0686, 0.0278, 0.1001, 0.0958, 0.0875, 0.1108, 0.1177,
        0.1177], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,924][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0596, 0.0680, 0.1997, 0.1621, 0.0848, 0.1463, 0.0715, 0.0599, 0.0756,
        0.0725], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,926][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0408, 0.0593, 0.0624, 0.1848, 0.0473, 0.2874, 0.0982, 0.0780, 0.0644,
        0.0774], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,927][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1451, 0.0832, 0.1093, 0.1046, 0.0382, 0.1354, 0.0706, 0.0781, 0.1194,
        0.1161], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,929][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0158, 0.0320, 0.1783, 0.3855, 0.0237, 0.2151, 0.0372, 0.0367, 0.0343,
        0.0413], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,929][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0186, 0.0326, 0.2334, 0.2944, 0.0494, 0.2079, 0.0450, 0.0443, 0.0374,
        0.0368], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,930][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0829, 0.1191, 0.0990, 0.0577, 0.1025, 0.0578, 0.1121, 0.0993, 0.1275,
        0.1421], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,930][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0605, 0.0617, 0.1117, 0.1302, 0.1319, 0.1675, 0.0941, 0.0879, 0.0795,
        0.0749], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,931][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0414, 0.1434, 0.0568, 0.0604, 0.0565, 0.0811, 0.1532, 0.1236, 0.1318,
        0.1517], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,931][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0452, 0.0746, 0.2790, 0.1682, 0.0694, 0.1038, 0.0584, 0.0585, 0.0689,
        0.0740], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,931][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1326, 0.1528, 0.0563, 0.0517, 0.0746, 0.0456, 0.0946, 0.0952, 0.1356,
        0.1611], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,932][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0843, 0.0741, 0.2561, 0.1368, 0.1094, 0.1232, 0.0611, 0.0553, 0.0483,
        0.0515], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:27,932][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0684, 0.0685, 0.1740, 0.0619, 0.0566, 0.1782, 0.0346, 0.0568, 0.0660,
        0.0606, 0.1745], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,933][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0199, 0.0228, 0.2217, 0.4050, 0.0041, 0.1061, 0.0094, 0.0089, 0.0243,
        0.0276, 0.1503], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,934][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0232, 0.0226, 0.1307, 0.1876, 0.0292, 0.2397, 0.0319, 0.0448, 0.0440,
        0.0392, 0.2070], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,936][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0985, 0.0465, 0.1975, 0.0827, 0.0212, 0.2118, 0.0347, 0.0471, 0.0804,
        0.0539, 0.1258], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,937][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0012, 0.0026, 0.1146, 0.1912, 0.0086, 0.1649, 0.0062, 0.0071, 0.0063,
        0.0052, 0.4920], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,939][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0017, 0.0029, 0.2963, 0.3220, 0.0041, 0.1164, 0.0041, 0.0029, 0.0049,
        0.0045, 0.2402], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,940][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0810, 0.1090, 0.0311, 0.0322, 0.1120, 0.0284, 0.1397, 0.1091, 0.1650,
        0.1725, 0.0199], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,941][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0030, 0.0056, 0.2635, 0.2096, 0.0189, 0.1249, 0.0095, 0.0078, 0.0087,
        0.0072, 0.3413], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,942][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([1.3141e-05, 1.9204e-01, 2.5929e-04, 3.1426e-04, 7.6027e-04, 1.7333e-03,
        1.0949e-01, 5.7135e-02, 2.4650e-01, 3.9094e-01, 8.1208e-04],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,944][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0062, 0.0100, 0.4066, 0.3064, 0.0264, 0.0742, 0.0106, 0.0130, 0.0136,
        0.0113, 0.1217], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,945][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0675, 0.0377, 0.0677, 0.0649, 0.0932, 0.2195, 0.0644, 0.0873, 0.0653,
        0.0650, 0.1673], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,947][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0754, 0.0610, 0.1680, 0.0858, 0.1852, 0.0862, 0.0554, 0.0473, 0.0415,
        0.0410, 0.1533], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:27,948][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.1442, 0.0899, 0.0582, 0.0196, 0.0893, 0.0714, 0.0712, 0.0874, 0.1011,
        0.1038, 0.0532, 0.1106], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,950][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0566, 0.0604, 0.1175, 0.0960, 0.1261, 0.1020, 0.0849, 0.0735, 0.0788,
        0.0675, 0.0741, 0.0626], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,951][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0409, 0.0608, 0.0228, 0.1127, 0.0274, 0.2241, 0.1146, 0.0759, 0.0563,
        0.0789, 0.1340, 0.0519], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,953][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.1567, 0.0734, 0.0523, 0.0523, 0.0352, 0.0711, 0.0675, 0.0731, 0.1101,
        0.1126, 0.0484, 0.1473], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,954][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0237, 0.0409, 0.1309, 0.2368, 0.0288, 0.1340, 0.0460, 0.0425, 0.0423,
        0.0520, 0.1768, 0.0452], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,956][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0227, 0.0362, 0.1721, 0.2005, 0.0536, 0.1393, 0.0472, 0.0491, 0.0411,
        0.0391, 0.1646, 0.0346], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,957][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0732, 0.1062, 0.0629, 0.0401, 0.0869, 0.0416, 0.1014, 0.0879, 0.1166,
        0.1304, 0.0327, 0.1200], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,959][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0874, 0.0693, 0.0591, 0.0637, 0.1231, 0.0863, 0.0977, 0.0882, 0.0898,
        0.0867, 0.0643, 0.0842], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,960][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0246, 0.1189, 0.0485, 0.0542, 0.0434, 0.0728, 0.1326, 0.1061, 0.1143,
        0.1309, 0.0476, 0.1061], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,961][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0354, 0.0586, 0.2300, 0.1487, 0.0600, 0.0898, 0.0486, 0.0506, 0.0571,
        0.0596, 0.1045, 0.0571], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,962][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.1133, 0.1370, 0.0384, 0.0335, 0.0557, 0.0278, 0.0822, 0.0858, 0.1111,
        0.1400, 0.0343, 0.1407], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,962][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0708, 0.0561, 0.2012, 0.1064, 0.1107, 0.1139, 0.0523, 0.0477, 0.0362,
        0.0371, 0.1353, 0.0321], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:27,962][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Megan] are: tensor([0.1294, 0.0922, 0.0460, 0.0232, 0.0639, 0.0634, 0.0642, 0.0834, 0.0949,
        0.0934, 0.0528, 0.1015, 0.0917], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,963][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Megan] are: tensor([0.0614, 0.0635, 0.1614, 0.1672, 0.0283, 0.1031, 0.0397, 0.0344, 0.0687,
        0.0689, 0.0866, 0.0781, 0.0387], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,963][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Megan] are: tensor([0.0337, 0.0427, 0.0392, 0.1586, 0.0139, 0.2411, 0.0673, 0.0552, 0.0480,
        0.0573, 0.1710, 0.0453, 0.0268], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,964][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Megan] are: tensor([0.1318, 0.0703, 0.0880, 0.0694, 0.0246, 0.0763, 0.0452, 0.0521, 0.0911,
        0.0890, 0.0526, 0.1277, 0.0818], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,965][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Megan] are: tensor([0.0092, 0.0195, 0.1527, 0.2849, 0.0161, 0.1526, 0.0237, 0.0234, 0.0201,
        0.0234, 0.2326, 0.0197, 0.0220], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,966][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Megan] are: tensor([0.0096, 0.0183, 0.2317, 0.2665, 0.0240, 0.1466, 0.0244, 0.0231, 0.0201,
        0.0195, 0.1815, 0.0164, 0.0183], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,968][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Megan] are: tensor([0.0659, 0.0994, 0.0546, 0.0351, 0.0754, 0.0337, 0.0912, 0.0786, 0.1074,
        0.1218, 0.0270, 0.1122, 0.0977], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,969][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Megan] are: tensor([0.0325, 0.0398, 0.1208, 0.1361, 0.0910, 0.1571, 0.0620, 0.0587, 0.0498,
        0.0456, 0.1217, 0.0392, 0.0456], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,970][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Megan] are: tensor([0.0063, 0.1434, 0.0139, 0.0179, 0.0183, 0.0322, 0.1348, 0.0974, 0.1386,
        0.1717, 0.0185, 0.1186, 0.0885], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,972][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Megan] are: tensor([0.0277, 0.0500, 0.2707, 0.1609, 0.0455, 0.0802, 0.0366, 0.0374, 0.0461,
        0.0489, 0.1035, 0.0474, 0.0450], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,973][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Megan] are: tensor([0.1001, 0.1150, 0.0444, 0.0415, 0.0431, 0.0324, 0.0711, 0.0721, 0.0974,
        0.1174, 0.0427, 0.1209, 0.1021], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,975][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Megan] are: tensor([0.0787, 0.0642, 0.1857, 0.1014, 0.0948, 0.0899, 0.0490, 0.0438, 0.0391,
        0.0421, 0.1159, 0.0379, 0.0575], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:27,976][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0424, 0.0299, 0.0680, 0.0204, 0.0215, 0.0974, 0.0161, 0.0271, 0.0264,
        0.0260, 0.1129, 0.0322, 0.0324, 0.4476], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,977][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0162, 0.0189, 0.1403, 0.3919, 0.0083, 0.0873, 0.0143, 0.0139, 0.0283,
        0.0251, 0.1101, 0.0292, 0.0135, 0.1026], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,979][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0423, 0.0275, 0.1087, 0.0516, 0.0397, 0.0954, 0.0307, 0.0419, 0.0608,
        0.0455, 0.0984, 0.0704, 0.0776, 0.2095], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,980][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.1434, 0.0613, 0.0508, 0.0197, 0.0255, 0.0675, 0.0403, 0.0487, 0.0905,
        0.0689, 0.0393, 0.1338, 0.0855, 0.1247], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,981][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ said] are: tensor([3.6469e-04, 8.9059e-04, 9.1870e-02, 5.7775e-02, 3.3457e-03, 8.8145e-02,
        1.8931e-03, 2.4609e-03, 1.7043e-03, 1.4589e-03, 1.5417e-01, 1.3195e-03,
        2.9544e-03, 5.9164e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,983][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0028, 0.0043, 0.1062, 0.1700, 0.0103, 0.1570, 0.0100, 0.0080, 0.0089,
        0.0078, 0.1514, 0.0067, 0.0090, 0.3476], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,984][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0794, 0.0747, 0.0117, 0.0151, 0.0977, 0.0174, 0.1189, 0.0915, 0.1304,
        0.1257, 0.0088, 0.1131, 0.1078, 0.0077], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,986][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0031, 0.0059, 0.0915, 0.0909, 0.0271, 0.1068, 0.0148, 0.0136, 0.0108,
        0.0084, 0.2030, 0.0065, 0.0119, 0.4058], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,987][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ said] are: tensor([9.4527e-06, 1.4732e-01, 3.1560e-04, 3.6779e-04, 8.8887e-04, 2.0856e-03,
        1.0236e-01, 5.3084e-02, 1.9901e-01, 3.1865e-01, 1.0922e-03, 9.8711e-02,
        7.4457e-02, 1.6541e-03], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,988][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0058, 0.0075, 0.2921, 0.2652, 0.0342, 0.0766, 0.0111, 0.0155, 0.0129,
        0.0091, 0.0978, 0.0089, 0.0151, 0.1483], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,989][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.1846, 0.0586, 0.0158, 0.0070, 0.0747, 0.0347, 0.0618, 0.0834, 0.0907,
        0.0959, 0.0207, 0.1314, 0.1120, 0.0287], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,991][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0455, 0.0342, 0.0813, 0.0535, 0.2241, 0.0783, 0.0466, 0.0426, 0.0264,
        0.0246, 0.1310, 0.0162, 0.0702, 0.1255], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:27,992][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0356, 0.0338, 0.0524, 0.0208, 0.0261, 0.0723, 0.0174, 0.0285, 0.0298,
        0.0285, 0.0838, 0.0342, 0.0380, 0.3142, 0.1846], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,993][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0154, 0.0196, 0.1642, 0.2826, 0.0038, 0.0769, 0.0083, 0.0077, 0.0200,
        0.0225, 0.1014, 0.0289, 0.0082, 0.1175, 0.1230], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,993][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0094, 0.0106, 0.0659, 0.0635, 0.0220, 0.0998, 0.0153, 0.0210, 0.0222,
        0.0185, 0.0958, 0.0241, 0.0302, 0.1741, 0.3276], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,994][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0532, 0.0323, 0.0586, 0.0279, 0.0166, 0.1142, 0.0290, 0.0392, 0.0537,
        0.0355, 0.0604, 0.0630, 0.0467, 0.2582, 0.1116], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,994][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([2.3086e-04, 5.6288e-04, 2.7118e-02, 3.5145e-02, 1.8088e-03, 4.5691e-02,
        1.3820e-03, 1.6719e-03, 1.2743e-03, 1.0963e-03, 9.4262e-02, 9.8411e-04,
        2.0604e-03, 2.6598e-01, 5.2073e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,995][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0007, 0.0014, 0.1228, 0.1285, 0.0031, 0.0809, 0.0027, 0.0020, 0.0025,
        0.0023, 0.1139, 0.0019, 0.0025, 0.2795, 0.2553], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,995][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0689, 0.0851, 0.0145, 0.0164, 0.0805, 0.0166, 0.1066, 0.0850, 0.1286,
        0.1351, 0.0104, 0.1210, 0.1077, 0.0124, 0.0111], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,996][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0013, 0.0030, 0.0749, 0.0718, 0.0146, 0.0890, 0.0061, 0.0062, 0.0048,
        0.0039, 0.1515, 0.0029, 0.0053, 0.3835, 0.1811], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,997][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([5.7861e-06, 1.5329e-01, 1.3886e-04, 1.6959e-04, 4.8421e-04, 1.1496e-03,
        8.8981e-02, 4.6586e-02, 2.0750e-01, 3.3203e-01, 5.1157e-04, 1.0288e-01,
        6.5330e-02, 6.4383e-04, 3.0152e-04], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,998][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0054, 0.0093, 0.3102, 0.1900, 0.0232, 0.0547, 0.0091, 0.0119, 0.0122,
        0.0099, 0.0769, 0.0098, 0.0135, 0.1675, 0.0965], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:27,999][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1162, 0.0464, 0.0242, 0.0132, 0.0821, 0.0635, 0.0649, 0.0826, 0.0853,
        0.0817, 0.0498, 0.1042, 0.1008, 0.0488, 0.0363], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:28,001][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0759, 0.0581, 0.0786, 0.0406, 0.1722, 0.0548, 0.0478, 0.0432, 0.0364,
        0.0365, 0.0908, 0.0288, 0.0797, 0.1149, 0.0418], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:28,065][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:28,066][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:28,068][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:28,069][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:28,070][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:28,071][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:28,072][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:28,073][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:28,074][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:28,076][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:28,077][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:28,078][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:28,079][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:29:28,080][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.6045, 0.3955], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:28,082][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.5130, 0.4870], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:28,083][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.3990, 0.6010], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:28,084][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6141, 0.3859], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:28,086][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3036, 0.6964], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:28,087][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.3503, 0.6497], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:28,088][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3805, 0.6195], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:28,088][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4789, 0.5211], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:28,088][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9629, 0.0371], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:28,089][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.3632, 0.6368], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:28,089][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.4182, 0.5818], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:28,089][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6224, 0.3776], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:29:28,090][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Jennifer] are: tensor([0.0944, 0.0870, 0.8186], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:28,090][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Jennifer] are: tensor([0.0956, 0.1446, 0.7598], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:28,091][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Jennifer] are: tensor([0.0020, 0.0057, 0.9922], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:28,092][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Jennifer] are: tensor([0.2913, 0.1804, 0.5283], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:28,093][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Jennifer] are: tensor([0.0015, 0.0046, 0.9938], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:28,095][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Jennifer] are: tensor([0.0045, 0.0091, 0.9864], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:28,096][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Jennifer] are: tensor([0.0530, 0.1311, 0.8159], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:28,097][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Jennifer] are: tensor([0.0072, 0.0185, 0.9744], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:28,099][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Jennifer] are: tensor([0.8738, 0.0009, 0.1253], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:28,100][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Jennifer] are: tensor([0.0498, 0.1172, 0.8331], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:28,101][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Jennifer] are: tensor([0.1283, 0.1039, 0.7679], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:28,103][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Jennifer] are: tensor([0.4390, 0.2198, 0.3412], device='cuda:0') for source tokens [Then, Jennifer]
[2024-07-24 10:29:28,104][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1042, 0.1170, 0.4649, 0.3139], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:28,105][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0693, 0.0763, 0.1628, 0.6915], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:28,107][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0039, 0.0068, 0.2140, 0.7753], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:28,108][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1257, 0.0703, 0.4326, 0.3714], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:28,109][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0015, 0.0037, 0.3526, 0.6422], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:28,111][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0018, 0.0030, 0.4146, 0.5806], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:28,112][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0176, 0.0365, 0.3802, 0.5658], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:28,113][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0019, 0.0046, 0.3764, 0.6171], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:28,115][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2627, 0.0034, 0.2030, 0.5309], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:28,116][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0157, 0.0289, 0.1853, 0.7701], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:28,118][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0679, 0.0602, 0.4569, 0.4150], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:28,119][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0678, 0.0440, 0.3770, 0.5112], device='cuda:0') for source tokens [Then, Jennifer and]
[2024-07-24 10:29:28,119][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Megan] are: tensor([0.1994, 0.2186, 0.2450, 0.1682, 0.1688], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:28,120][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Megan] are: tensor([0.1499, 0.1376, 0.1446, 0.4542, 0.1137], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:28,120][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Megan] are: tensor([0.0093, 0.0164, 0.1773, 0.7499, 0.0471], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:28,121][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Megan] are: tensor([0.0916, 0.0542, 0.4674, 0.3693, 0.0174], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:28,121][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Megan] are: tensor([0.0050, 0.0099, 0.3309, 0.6350, 0.0191], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:28,121][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Megan] are: tensor([0.0012, 0.0024, 0.4272, 0.5626, 0.0066], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:28,122][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Megan] are: tensor([0.1125, 0.1995, 0.1689, 0.3937, 0.1254], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:28,122][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Megan] are: tensor([0.0103, 0.0147, 0.3886, 0.5292, 0.0571], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:28,122][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Megan] are: tensor([0.0015, 0.0012, 0.1091, 0.8781, 0.0101], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:28,124][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Megan] are: tensor([0.0017, 0.0062, 0.2714, 0.7157, 0.0051], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:28,125][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Megan] are: tensor([0.0776, 0.0963, 0.4061, 0.3455, 0.0744], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:28,126][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Megan] are: tensor([0.6453, 0.1902, 0.0812, 0.0706, 0.0127], device='cuda:0') for source tokens [Then, Jennifer and Megan]
[2024-07-24 10:29:28,128][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0755, 0.0808, 0.2294, 0.1244, 0.0660, 0.4239], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:28,129][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0336, 0.0303, 0.0860, 0.3525, 0.0125, 0.4852], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:28,130][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0009, 0.0016, 0.0746, 0.2178, 0.0051, 0.7000], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:28,132][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0710, 0.0426, 0.4022, 0.2186, 0.0118, 0.2538], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:28,133][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0008, 0.0016, 0.2074, 0.3386, 0.0060, 0.4457], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:28,134][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([1.8272e-04, 4.2277e-04, 2.7785e-01, 5.1738e-01, 1.4261e-03, 2.0274e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:28,135][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0117, 0.0209, 0.1671, 0.3869, 0.0217, 0.3918], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:28,137][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0009, 0.0021, 0.3331, 0.3593, 0.0076, 0.2969], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:28,138][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([1.6409e-03, 3.1909e-04, 4.7080e-02, 1.1617e-01, 6.2081e-03, 8.2858e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:28,139][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0033, 0.0073, 0.1411, 0.3961, 0.0074, 0.4447], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:28,141][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0298, 0.0203, 0.1603, 0.1026, 0.0755, 0.6114], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:28,142][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.1557, 0.0545, 0.3176, 0.1362, 0.0097, 0.3263], device='cuda:0') for source tokens [Then, Jennifer and Megan had]
[2024-07-24 10:29:28,144][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2069, 0.1705, 0.1167, 0.0683, 0.1198, 0.1835, 0.1344],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:28,145][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0844, 0.0728, 0.1173, 0.1636, 0.1156, 0.3048, 0.1416],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:28,146][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0306, 0.0455, 0.1189, 0.2499, 0.0519, 0.4104, 0.0928],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:28,148][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1154, 0.0668, 0.2996, 0.2484, 0.0209, 0.2086, 0.0401],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:28,149][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0068, 0.0139, 0.2022, 0.4959, 0.0148, 0.2458, 0.0206],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:28,151][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0050, 0.0103, 0.3202, 0.4560, 0.0162, 0.1771, 0.0151],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:28,151][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0716, 0.1165, 0.1268, 0.1848, 0.0918, 0.1897, 0.2188],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:28,152][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0222, 0.0305, 0.2165, 0.3007, 0.0795, 0.2926, 0.0580],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:28,152][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0301, 0.0161, 0.0920, 0.1866, 0.0565, 0.5666, 0.0520],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:28,152][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0135, 0.0323, 0.2648, 0.4022, 0.0174, 0.2334, 0.0364],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:28,153][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1159, 0.1558, 0.1714, 0.1699, 0.1081, 0.1531, 0.1257],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:28,153][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.2284, 0.1056, 0.1718, 0.2148, 0.0262, 0.1875, 0.0657],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a]
[2024-07-24 10:29:28,154][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.1514, 0.1302, 0.1040, 0.0786, 0.0893, 0.1958, 0.1064, 0.1443],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:28,155][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0546, 0.0520, 0.1097, 0.1674, 0.0787, 0.3331, 0.1048, 0.0998],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:28,156][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0121, 0.0217, 0.1352, 0.2676, 0.0293, 0.4357, 0.0478, 0.0507],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:28,158][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0788, 0.0513, 0.2604, 0.2648, 0.0193, 0.2481, 0.0361, 0.0411],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:28,159][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0043, 0.0099, 0.1679, 0.5224, 0.0112, 0.2531, 0.0162, 0.0149],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:28,160][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0019, 0.0048, 0.2973, 0.4684, 0.0093, 0.2030, 0.0082, 0.0073],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:28,162][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0291, 0.0595, 0.1401, 0.2068, 0.0608, 0.2297, 0.1316, 0.1423],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:28,163][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0116, 0.0185, 0.1998, 0.3150, 0.0591, 0.3218, 0.0391, 0.0351],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:28,164][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0286, 0.0120, 0.0749, 0.1546, 0.0509, 0.5894, 0.0448, 0.0449],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:28,166][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0043, 0.0134, 0.2533, 0.3925, 0.0096, 0.2911, 0.0193, 0.0166],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:28,167][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0728, 0.1053, 0.1733, 0.1585, 0.0843, 0.2019, 0.1033, 0.1006],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:28,169][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.1427, 0.0720, 0.1976, 0.2420, 0.0203, 0.2291, 0.0527, 0.0436],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long]
[2024-07-24 10:29:28,170][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.1932, 0.1236, 0.0686, 0.0351, 0.1037, 0.1116, 0.1005, 0.1264, 0.1373],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:28,172][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0923, 0.0730, 0.0787, 0.0707, 0.1535, 0.1776, 0.1288, 0.1180, 0.1074],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:28,173][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0462, 0.0668, 0.1348, 0.1679, 0.0614, 0.2434, 0.0929, 0.0937, 0.0928],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:28,174][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.1775, 0.0952, 0.1272, 0.1226, 0.0393, 0.1514, 0.0705, 0.0812, 0.1352],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:28,176][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0148, 0.0295, 0.1994, 0.4231, 0.0214, 0.2154, 0.0335, 0.0322, 0.0308],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:28,177][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0160, 0.0288, 0.2451, 0.3263, 0.0420, 0.2265, 0.0418, 0.0399, 0.0338],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:28,179][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0752, 0.1144, 0.0694, 0.0670, 0.0851, 0.0895, 0.1744, 0.1708, 0.1543],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:28,180][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0576, 0.0626, 0.1177, 0.1567, 0.1326, 0.1989, 0.0987, 0.0925, 0.0827],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:28,182][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.2651, 0.0381, 0.0759, 0.0860, 0.1165, 0.2284, 0.0796, 0.0741, 0.0364],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:28,182][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0250, 0.0529, 0.2168, 0.2550, 0.0409, 0.2308, 0.0655, 0.0587, 0.0544],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:28,183][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.1546, 0.1728, 0.0703, 0.0664, 0.0895, 0.0593, 0.1097, 0.1135, 0.1640],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:28,183][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.2449, 0.1185, 0.1116, 0.1403, 0.0371, 0.1163, 0.0740, 0.0650, 0.0924],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument]
[2024-07-24 10:29:28,183][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1666, 0.1075, 0.0686, 0.0278, 0.1001, 0.0958, 0.0875, 0.1108, 0.1177,
        0.1177], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:28,184][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0838, 0.0668, 0.0745, 0.0599, 0.1496, 0.1496, 0.1178, 0.1076, 0.0979,
        0.0926], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:28,184][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0505, 0.0717, 0.1126, 0.1327, 0.0607, 0.1936, 0.0920, 0.0932, 0.0945,
        0.0986], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:28,185][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1451, 0.0832, 0.1093, 0.1046, 0.0382, 0.1354, 0.0706, 0.0781, 0.1194,
        0.1161], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:28,185][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0158, 0.0320, 0.1783, 0.3855, 0.0237, 0.2151, 0.0372, 0.0367, 0.0343,
        0.0413], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:28,186][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0186, 0.0326, 0.2334, 0.2944, 0.0494, 0.2079, 0.0450, 0.0443, 0.0374,
        0.0368], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:28,187][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0693, 0.1037, 0.0534, 0.0498, 0.0757, 0.0664, 0.1515, 0.1483, 0.1351,
        0.1468], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:28,188][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0605, 0.0617, 0.1117, 0.1302, 0.1319, 0.1675, 0.0941, 0.0879, 0.0795,
        0.0749], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:28,190][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.2496, 0.0352, 0.0704, 0.0888, 0.1120, 0.2231, 0.0787, 0.0738, 0.0343,
        0.0342], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:28,191][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0293, 0.0569, 0.1840, 0.2223, 0.0473, 0.2032, 0.0703, 0.0649, 0.0587,
        0.0630], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:28,193][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1282, 0.1480, 0.0569, 0.0525, 0.0793, 0.0486, 0.0947, 0.0966, 0.1355,
        0.1599], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:28,194][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2318, 0.1171, 0.0883, 0.1033, 0.0379, 0.0892, 0.0712, 0.0611, 0.0883,
        0.1119], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument,]
[2024-07-24 10:29:28,196][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0684, 0.0685, 0.1740, 0.0619, 0.0566, 0.1782, 0.0346, 0.0568, 0.0660,
        0.0606, 0.1745], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:28,197][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0465, 0.0411, 0.0437, 0.1428, 0.0224, 0.2154, 0.0713, 0.0796, 0.0705,
        0.0719, 0.1949], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:28,199][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0033, 0.0051, 0.0373, 0.1099, 0.0095, 0.2876, 0.0166, 0.0201, 0.0139,
        0.0123, 0.4846], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:28,200][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0985, 0.0465, 0.1975, 0.0827, 0.0212, 0.2118, 0.0347, 0.0471, 0.0804,
        0.0539, 0.1258], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:28,202][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0012, 0.0026, 0.1146, 0.1912, 0.0086, 0.1649, 0.0062, 0.0071, 0.0063,
        0.0052, 0.4920], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:28,203][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0017, 0.0029, 0.2963, 0.3220, 0.0041, 0.1164, 0.0041, 0.0029, 0.0049,
        0.0045, 0.2402], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:28,204][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0328, 0.0577, 0.0701, 0.1608, 0.0226, 0.0953, 0.0846, 0.1091, 0.0928,
        0.0901, 0.1840], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:28,206][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0030, 0.0056, 0.2635, 0.2096, 0.0189, 0.1249, 0.0095, 0.0078, 0.0087,
        0.0072, 0.3413], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:28,207][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([1.3467e-03, 1.2661e-04, 2.2430e-02, 9.7829e-02, 3.8215e-03, 3.4438e-01,
        7.1096e-04, 7.7963e-04, 1.6121e-04, 1.2107e-04, 5.2829e-01],
       device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:28,208][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0112, 0.0170, 0.0744, 0.2465, 0.0165, 0.2670, 0.0445, 0.0469, 0.0380,
        0.0358, 0.2022], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:28,210][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0469, 0.0280, 0.0753, 0.0644, 0.0887, 0.2683, 0.0526, 0.0750, 0.0513,
        0.0491, 0.2004], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:28,211][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2786, 0.0899, 0.0286, 0.0183, 0.0141, 0.0661, 0.0560, 0.0492, 0.0942,
        0.0954, 0.2097], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and]
[2024-07-24 10:29:28,213][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.1442, 0.0899, 0.0582, 0.0196, 0.0893, 0.0714, 0.0712, 0.0874, 0.1011,
        0.1038, 0.0532, 0.1106], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:28,214][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0909, 0.0668, 0.0497, 0.0404, 0.1486, 0.0818, 0.1095, 0.0985, 0.0957,
        0.0903, 0.0430, 0.0849], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:28,214][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0631, 0.0794, 0.0577, 0.0646, 0.0552, 0.1034, 0.0976, 0.0969, 0.0981,
        0.1064, 0.0865, 0.0911], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:28,215][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.1567, 0.0734, 0.0523, 0.0523, 0.0352, 0.0711, 0.0675, 0.0731, 0.1101,
        0.1126, 0.0484, 0.1473], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:28,215][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0237, 0.0409, 0.1309, 0.2368, 0.0288, 0.1340, 0.0460, 0.0425, 0.0423,
        0.0520, 0.1768, 0.0452], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:28,216][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0227, 0.0362, 0.1721, 0.2005, 0.0536, 0.1393, 0.0472, 0.0491, 0.0411,
        0.0391, 0.1646, 0.0346], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:28,216][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0720, 0.1014, 0.0168, 0.0196, 0.0586, 0.0262, 0.1490, 0.1352, 0.1342,
        0.1505, 0.0183, 0.1181], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:28,217][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0874, 0.0693, 0.0591, 0.0637, 0.1231, 0.0863, 0.0977, 0.0882, 0.0898,
        0.0867, 0.0643, 0.0842], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:28,218][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0683, 0.0407, 0.0778, 0.1291, 0.0678, 0.2013, 0.0872, 0.0784, 0.0393,
        0.0395, 0.1357, 0.0348], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:28,219][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0279, 0.0500, 0.1329, 0.1847, 0.0432, 0.1577, 0.0617, 0.0590, 0.0526,
        0.0556, 0.1298, 0.0448], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:28,221][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.1114, 0.1349, 0.0386, 0.0338, 0.0577, 0.0288, 0.0818, 0.0868, 0.1114,
        0.1392, 0.0358, 0.1397], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:28,222][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.3342, 0.1196, 0.0193, 0.0205, 0.0263, 0.0198, 0.0550, 0.0467, 0.0813,
        0.1099, 0.0325, 0.1349], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards]
[2024-07-24 10:29:28,224][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Megan] are: tensor([0.1294, 0.0922, 0.0460, 0.0232, 0.0639, 0.0634, 0.0642, 0.0834, 0.0949,
        0.0934, 0.0528, 0.1015, 0.0917], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:28,225][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Megan] are: tensor([0.0621, 0.0559, 0.0643, 0.0589, 0.1053, 0.1267, 0.0953, 0.0923, 0.0775,
        0.0724, 0.0614, 0.0636, 0.0642], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:28,227][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Megan] are: tensor([0.0228, 0.0369, 0.0820, 0.1297, 0.0389, 0.1951, 0.0617, 0.0644, 0.0511,
        0.0511, 0.1837, 0.0410, 0.0417], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:28,228][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Megan] are: tensor([0.1318, 0.0703, 0.0880, 0.0694, 0.0246, 0.0763, 0.0452, 0.0521, 0.0911,
        0.0890, 0.0526, 0.1277, 0.0818], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:28,230][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Megan] are: tensor([0.0092, 0.0195, 0.1527, 0.2849, 0.0161, 0.1526, 0.0237, 0.0234, 0.0201,
        0.0234, 0.2326, 0.0197, 0.0220], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:28,231][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Megan] are: tensor([0.0096, 0.0183, 0.2317, 0.2665, 0.0240, 0.1466, 0.0244, 0.0231, 0.0201,
        0.0195, 0.1815, 0.0164, 0.0183], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:28,233][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Megan] are: tensor([0.0484, 0.0822, 0.0441, 0.0438, 0.0547, 0.0484, 0.1261, 0.1289, 0.1052,
        0.1127, 0.0394, 0.0845, 0.0816], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:28,234][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Megan] are: tensor([0.0325, 0.0398, 0.1208, 0.1361, 0.0910, 0.1571, 0.0620, 0.0587, 0.0498,
        0.0456, 0.1217, 0.0392, 0.0456], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:28,235][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Megan] are: tensor([0.0628, 0.0175, 0.0619, 0.1282, 0.0584, 0.3044, 0.0490, 0.0440, 0.0167,
        0.0158, 0.2098, 0.0150, 0.0166], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:28,237][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Megan] are: tensor([0.0126, 0.0317, 0.1628, 0.2270, 0.0236, 0.1875, 0.0420, 0.0371, 0.0313,
        0.0328, 0.1615, 0.0234, 0.0266], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:28,238][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Megan] are: tensor([0.0927, 0.1093, 0.0502, 0.0451, 0.0474, 0.0376, 0.0702, 0.0724, 0.0951,
        0.1130, 0.0493, 0.1154, 0.1023], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:28,240][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Megan] are: tensor([0.2189, 0.0985, 0.0494, 0.0575, 0.0195, 0.0549, 0.0536, 0.0448, 0.0692,
        0.0888, 0.0828, 0.1036, 0.0585], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan]
[2024-07-24 10:29:28,241][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0424, 0.0299, 0.0680, 0.0204, 0.0215, 0.0974, 0.0161, 0.0271, 0.0264,
        0.0260, 0.1129, 0.0322, 0.0324, 0.4476], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:28,243][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0278, 0.0221, 0.0246, 0.0596, 0.0227, 0.1579, 0.0416, 0.0451, 0.0380,
        0.0392, 0.1218, 0.0409, 0.0324, 0.3262], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:28,244][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0019, 0.0029, 0.0396, 0.0579, 0.0074, 0.1589, 0.0071, 0.0074, 0.0065,
        0.0060, 0.3539, 0.0061, 0.0088, 0.3356], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:28,245][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.1434, 0.0613, 0.0508, 0.0197, 0.0255, 0.0675, 0.0403, 0.0487, 0.0905,
        0.0689, 0.0393, 0.1338, 0.0855, 0.1247], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:28,245][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([3.6469e-04, 8.9059e-04, 9.1870e-02, 5.7775e-02, 3.3457e-03, 8.8145e-02,
        1.8931e-03, 2.4609e-03, 1.7043e-03, 1.4589e-03, 1.5417e-01, 1.3195e-03,
        2.9544e-03, 5.9164e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:28,246][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0028, 0.0043, 0.1062, 0.1700, 0.0103, 0.1570, 0.0100, 0.0080, 0.0089,
        0.0078, 0.1514, 0.0067, 0.0090, 0.3476], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:28,246][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0383, 0.0474, 0.0399, 0.0585, 0.0305, 0.0520, 0.0681, 0.0811, 0.0698,
        0.0626, 0.1020, 0.0575, 0.0545, 0.2379], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:28,247][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0031, 0.0059, 0.0915, 0.0909, 0.0271, 0.1068, 0.0148, 0.0136, 0.0108,
        0.0084, 0.2030, 0.0065, 0.0119, 0.4058], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:28,247][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.1743, 0.0008, 0.0142, 0.0203, 0.0114, 0.0839, 0.0017, 0.0016, 0.0008,
        0.0008, 0.4760, 0.0015, 0.0015, 0.2113], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:28,248][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0288, 0.0291, 0.0220, 0.0434, 0.0613, 0.1185, 0.1279, 0.1555, 0.0935,
        0.0733, 0.0414, 0.0600, 0.0889, 0.0565], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:28,248][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.1561, 0.0508, 0.0188, 0.0077, 0.0865, 0.0473, 0.0605, 0.0852, 0.0864,
        0.0887, 0.0300, 0.1188, 0.1157, 0.0474], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:28,249][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.2811, 0.0841, 0.0075, 0.0044, 0.0095, 0.0207, 0.0342, 0.0320, 0.0692,
        0.0887, 0.0623, 0.1211, 0.0636, 0.1215], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said]
[2024-07-24 10:29:28,251][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0356, 0.0338, 0.0524, 0.0208, 0.0261, 0.0723, 0.0174, 0.0285, 0.0298,
        0.0285, 0.0838, 0.0342, 0.0380, 0.3142, 0.1846], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:28,252][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0173, 0.0162, 0.0144, 0.0425, 0.0124, 0.1148, 0.0323, 0.0389, 0.0301,
        0.0307, 0.0901, 0.0292, 0.0229, 0.2432, 0.2649], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:28,254][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0018, 0.0028, 0.0189, 0.0339, 0.0046, 0.1046, 0.0070, 0.0087, 0.0068,
        0.0062, 0.1685, 0.0062, 0.0076, 0.1731, 0.4494], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:28,255][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0532, 0.0323, 0.0586, 0.0279, 0.0166, 0.1142, 0.0290, 0.0392, 0.0537,
        0.0355, 0.0604, 0.0630, 0.0467, 0.2582, 0.1116], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:28,255][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([2.3086e-04, 5.6288e-04, 2.7118e-02, 3.5145e-02, 1.8088e-03, 4.5691e-02,
        1.3820e-03, 1.6719e-03, 1.2743e-03, 1.0963e-03, 9.4262e-02, 9.8411e-04,
        2.0604e-03, 2.6598e-01, 5.2073e-01], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:28,257][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0007, 0.0014, 0.1228, 0.1285, 0.0031, 0.0809, 0.0027, 0.0020, 0.0025,
        0.0023, 0.1139, 0.0019, 0.0025, 0.2795, 0.2553], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:28,259][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0126, 0.0201, 0.0277, 0.0441, 0.0113, 0.0355, 0.0277, 0.0362, 0.0295,
        0.0281, 0.0821, 0.0244, 0.0241, 0.2632, 0.3333], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:28,260][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0013, 0.0030, 0.0749, 0.0718, 0.0146, 0.0890, 0.0061, 0.0062, 0.0048,
        0.0039, 0.1515, 0.0029, 0.0053, 0.3835, 0.1811], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:28,261][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0112, 0.0007, 0.0222, 0.0365, 0.0073, 0.2331, 0.0022, 0.0024, 0.0009,
        0.0007, 0.3713, 0.0009, 0.0012, 0.1831, 0.1262], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:28,263][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0084, 0.0145, 0.0416, 0.0624, 0.0229, 0.1102, 0.0426, 0.0498, 0.0345,
        0.0298, 0.0547, 0.0224, 0.0327, 0.1150, 0.3585], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:28,264][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0871, 0.0366, 0.0289, 0.0141, 0.0902, 0.0850, 0.0583, 0.0775, 0.0733,
        0.0678, 0.0710, 0.0839, 0.0942, 0.0786, 0.0534], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:28,266][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1738, 0.0661, 0.0131, 0.0045, 0.0109, 0.0267, 0.0348, 0.0352, 0.0655,
        0.0722, 0.0627, 0.0960, 0.0592, 0.1869, 0.0925], device='cuda:0') for source tokens [Then, Jennifer and Megan had a long argument, and afterwards Megan said to]
[2024-07-24 10:29:28,267][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:28,269][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[4585],
        [ 404],
        [   2],
        [   1],
        [  10],
        [   2],
        [  31],
        [  14],
        [  41],
        [ 135],
        [   5],
        [ 184],
        [  35],
        [   1],
        [   1]], device='cuda:0')
[2024-07-24 10:29:28,271][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[4748],
        [ 479],
        [  24],
        [   5],
        [   9],
        [   3],
        [  46],
        [  25],
        [  83],
        [ 188],
        [   8],
        [ 255],
        [  53],
        [  11],
        [   7]], device='cuda:0')
[2024-07-24 10:29:28,272][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 4891],
        [ 6585],
        [ 4221],
        [ 5884],
        [ 5711],
        [ 8352],
        [ 7692],
        [ 8099],
        [ 7771],
        [ 7847],
        [ 8328],
        [ 8027],
        [ 8402],
        [14516],
        [14530]], device='cuda:0')
[2024-07-24 10:29:28,273][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[  382],
        [  297],
        [16840],
        [ 1945],
        [ 1554],
        [ 1524],
        [ 2320],
        [ 2035],
        [ 2693],
        [ 2999],
        [ 1811],
        [ 3338],
        [ 1872],
        [ 1417],
        [ 2499]], device='cuda:0')
[2024-07-24 10:29:28,275][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[29163],
        [40070],
        [  394],
        [ 6686],
        [23203],
        [28360],
        [39445],
        [42793],
        [43119],
        [42205],
        [38350],
        [44236],
        [43035],
        [35499],
        [37628]], device='cuda:0')
[2024-07-24 10:29:28,276][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[11532],
        [12989],
        [41939],
        [44546],
        [44668],
        [45906],
        [45860],
        [46055],
        [45313],
        [45083],
        [44929],
        [43145],
        [43067],
        [44529],
        [45892]], device='cuda:0')
[2024-07-24 10:29:28,278][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[29525],
        [26236],
        [10314],
        [11424],
        [11579],
        [12587],
        [12449],
        [12581],
        [12762],
        [13082],
        [15809],
        [15090],
        [14612],
        [18417],
        [20877]], device='cuda:0')
[2024-07-24 10:29:28,279][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[28034],
        [24089],
        [10635],
        [13508],
        [13378],
        [11999],
        [11814],
        [11714],
        [10972],
        [10985],
        [12363],
        [11778],
        [11829],
        [13259],
        [13006]], device='cuda:0')
[2024-07-24 10:29:28,280][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[29143],
        [26956],
        [37116],
        [41181],
        [39230],
        [38169],
        [39431],
        [38651],
        [38674],
        [38547],
        [33393],
        [36298],
        [35745],
        [31350],
        [31583]], device='cuda:0')
[2024-07-24 10:29:28,281][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[44578],
        [43058],
        [18385],
        [26977],
        [25841],
        [28186],
        [28878],
        [29409],
        [29354],
        [29507],
        [29598],
        [31632],
        [30318],
        [32705],
        [32612]], device='cuda:0')
[2024-07-24 10:29:28,282][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[10948],
        [10721],
        [10602],
        [10602],
        [10606],
        [10607],
        [10608],
        [10556],
        [10569],
        [10568],
        [10379],
        [10575],
        [10471],
        [10365],
        [10365]], device='cuda:0')
[2024-07-24 10:29:28,283][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[32122],
        [35497],
        [42785],
        [40964],
        [41038],
        [40532],
        [40840],
        [40719],
        [40153],
        [39754],
        [40291],
        [39118],
        [39502],
        [38485],
        [37465]], device='cuda:0')
[2024-07-24 10:29:28,285][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[35799],
        [35338],
        [ 3498],
        [28460],
        [27619],
        [31434],
        [29536],
        [28805],
        [25552],
        [25072],
        [36063],
        [27764],
        [28485],
        [28897],
        [36533]], device='cuda:0')
[2024-07-24 10:29:28,286][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[25274],
        [ 9021],
        [ 7004],
        [ 3500],
        [ 2127],
        [ 1998],
        [ 2115],
        [ 2016],
        [ 1880],
        [ 1818],
        [ 1042],
        [ 1267],
        [ 1262],
        [  886],
        [  952]], device='cuda:0')
[2024-07-24 10:29:28,288][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[10705],
        [ 9451],
        [ 6627],
        [ 7323],
        [ 7522],
        [ 6609],
        [ 6074],
        [ 5683],
        [ 5264],
        [ 7320],
        [ 7089],
        [ 8125],
        [ 6362],
        [ 6945],
        [ 4759]], device='cuda:0')
[2024-07-24 10:29:28,289][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 9283],
        [ 5739],
        [15223],
        [14258],
        [13232],
        [16234],
        [13204],
        [13349],
        [11149],
        [10397],
        [15690],
        [10649],
        [10160],
        [18118],
        [17442]], device='cuda:0')
[2024-07-24 10:29:28,290][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[12844],
        [ 9301],
        [ 7702],
        [ 5545],
        [ 5543],
        [ 5149],
        [ 5445],
        [ 5460],
        [ 6056],
        [ 6174],
        [ 4999],
        [ 6179],
        [ 5779],
        [ 5127],
        [ 5087]], device='cuda:0')
[2024-07-24 10:29:28,292][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[32296],
        [29588],
        [ 8821],
        [14856],
        [15456],
        [11626],
        [12417],
        [11979],
        [12603],
        [13293],
        [14228],
        [15707],
        [14066],
        [13407],
        [15972]], device='cuda:0')
[2024-07-24 10:29:28,293][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[17736],
        [23844],
        [10634],
        [ 9018],
        [ 8967],
        [ 8340],
        [ 8155],
        [ 7820],
        [ 7702],
        [ 7505],
        [ 8012],
        [ 7636],
        [ 8054],
        [ 7807],
        [ 7412]], device='cuda:0')
[2024-07-24 10:29:28,295][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[9844],
        [3855],
        [2751],
        [3019],
        [3002],
        [2684],
        [2817],
        [2863],
        [2681],
        [2638],
        [3231],
        [2754],
        [2869],
        [2930],
        [3721]], device='cuda:0')
[2024-07-24 10:29:28,296][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 6055],
        [ 6607],
        [16417],
        [16786],
        [16838],
        [17251],
        [17275],
        [17287],
        [16994],
        [16811],
        [14261],
        [13937],
        [14399],
        [14076],
        [11023]], device='cuda:0')
[2024-07-24 10:29:28,298][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[4499],
        [1771],
        [ 882],
        [ 628],
        [ 635],
        [ 692],
        [ 824],
        [ 896],
        [1159],
        [1204],
        [ 891],
        [1333],
        [1153],
        [1067],
        [1072]], device='cuda:0')
[2024-07-24 10:29:28,299][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[20882],
        [17735],
        [17481],
        [14282],
        [14721],
        [14481],
        [14170],
        [13978],
        [14008],
        [14060],
        [13679],
        [13365],
        [13654],
        [12834],
        [12395]], device='cuda:0')
[2024-07-24 10:29:28,300][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[15424],
        [15432],
        [15447],
        [17019],
        [10806],
        [11977],
        [14762],
        [15411],
        [16611],
        [16666],
        [14352],
        [20079],
        [20025],
        [17213],
        [12781]], device='cuda:0')
[2024-07-24 10:29:28,302][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[11682],
        [ 7109],
        [13723],
        [17486],
        [17029],
        [16697],
        [16578],
        [16570],
        [15889],
        [15749],
        [16094],
        [15595],
        [15925],
        [14052],
        [16657]], device='cuda:0')
[2024-07-24 10:29:28,303][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[12298],
        [20272],
        [ 6478],
        [ 9815],
        [ 9916],
        [16825],
        [14372],
        [15645],
        [16976],
        [17073],
        [17325],
        [17149],
        [15933],
        [16206],
        [17622]], device='cuda:0')
[2024-07-24 10:29:28,305][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[5656],
        [5270],
        [3707],
        [4315],
        [4022],
        [4149],
        [4251],
        [4238],
        [4056],
        [3917],
        [4241],
        [3475],
        [3843],
        [3884],
        [3842]], device='cuda:0')
[2024-07-24 10:29:28,306][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[30831],
        [34046],
        [43097],
        [40804],
        [41746],
        [40245],
        [40769],
        [40723],
        [40330],
        [40298],
        [40851],
        [40071],
        [40133],
        [40165],
        [40312]], device='cuda:0')
[2024-07-24 10:29:28,308][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[36156],
        [37150],
        [37391],
        [38780],
        [39485],
        [39783],
        [41606],
        [42333],
        [40368],
        [38459],
        [38954],
        [38453],
        [40956],
        [36715],
        [39685]], device='cuda:0')
[2024-07-24 10:29:28,309][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[9565],
        [9565],
        [9565],
        [9565],
        [9565],
        [9565],
        [9565],
        [9565],
        [9565],
        [9565],
        [9565],
        [9565],
        [9565],
        [9565],
        [9565]], device='cuda:0')
